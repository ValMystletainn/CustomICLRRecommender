[
    {
        "title": "MOFFlow: Flow Matching for Structure Prediction of Metal-Organic Frameworks",
        "link_suffix": "/forum?id=dNT3abOsLo",
        "link": "https://openreview.net/forum?id=dNT3abOsLo",
        "pdf_link": "https://openreview.net/pdf?id=dNT3abOsLo",
        "keywords": "metal-organic framework, material structure prediction, AI for science",
        "abstract": "Metal-organic frameworks (MOFs) are a class of crystalline materials with promising applications in many areas such as carbon capture and drug delivery. In this work, we introduce MOFFlow, the first deep generative model tailored for MOF structure prediction. Existing approaches, including ab initio calculations and even deep generative models, struggle with the complexity of MOF structures due to the large number of atoms in the unit cells. To address this limitation, we propose a novel Riemannian flow matching framework that reduces the dimensionality of the problem by treating the metal nodes and organic linkers as rigid bodies, capitalizing on the inherent modularity of MOFs. By operating in the $SE(3)$ space, MOFFlow effectively captures the roto-translational dynamics of these rigid components in a scalable way. Our experiment demonstrates that MOFFlow accurately predicts MOF structures containing several hundred atoms, significantly outperforming conventional methods and state-of-the-art machine learning baselines while being much faster."
    },
    {
        "title": "Revisiting MAE pre-training for 3D medical image segmentation",
        "link_suffix": "/forum?id=0JcPJ0CLbx",
        "link": "https://openreview.net/forum?id=0JcPJ0CLbx",
        "pdf_link": "https://openreview.net/pdf?id=0JcPJ0CLbx",
        "keywords": "self-supervised learning, medical image segmentation, foundation models, medical image computing, CNN, nnU-Net",
        "abstract": "Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the potential of vast, untapped clinical datasets, for various downstream applications that suffer from the scarcity of labeled data. While SSL has revolutionized fields like natural language processing and computer vision, their adoption in 3D medical image computing has been limited by three key pitfalls: Small pre-training\ndataset sizes, architectures inadequate for 3D medical image analysis, and insufficient evaluation practices. We address these issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and ii) using a Residual Encoder U-Net architecture within the state-of-the-art nnU-Net framework. iii) A robust development framework, incorporating 5 development and 8 testing brain MRI segmentation datasets, allowed performance-driven design decisions to optimize the simple concept of Masked Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses previous SSL methods but also outperforms the strong nnU-Net baseline by an average of approximately 3 Dice points. Furthermore, our model demonstrates exceptional stability, achieving the highest average rank of 2 out of 7 methods, compared to the second-best method\u2019s mean rank of 3. Our code is made available here."
    },
    {
        "title": "QP-SNN: Quantized and Pruned Spiking Neural Networks",
        "link_suffix": "/forum?id=MiPyle6Jef",
        "link": "https://openreview.net/forum?id=MiPyle6Jef",
        "pdf_link": "https://openreview.net/pdf?id=MiPyle6Jef",
        "keywords": "Spiking Neural Networks, Neuromorphic Computing, Spiking Pruning, Spiking Quantization",
        "abstract": "Brain-inspired Spiking Neural Networks (SNNs) leverage sparse spikes to encode information and operate in an asynchronous event-driven manner, offering a highly energy-efficient paradigm for machine intelligence. However, the current SNN community focuses primarily on performance improvement by developing large-scale models, which limits the applicability of SNNs in resource-limited edge devices. In this paper, we propose a hardware-friendly and lightweight SNN, aimed at effectively deploying high-performance SNN in resource-limited scenarios. Specifically, we first develop a baseline model that integrates uniform quantization and structured pruning, called QP-SNN baseline. While this baseline significantly reduces storage demands and computational costs, it suffers from performance decline. To address this, we conduct an in-depth analysis of the challenges in quantization and pruning that lead to performance degradation and propose solutions to enhance the baseline's performance. For weight quantization, we propose a weight rescaling strategy that utilizes bit width more effectively to enhance the model's representation capability. For structured pruning, we propose a novel pruning criterion using the singular value of spatiotemporal spike activities to enable more accurate removal of redundant kernels. Extensive experiments demonstrate that integrating two proposed methods into the baseline allows QP-SNN to achieve state-of-the-art performance and efficiency, underscoring its potential for enhancing SNN deployment in edge intelligence computing."
    },
    {
        "title": "EarthquakeNPP: Benchmark Datasets for Earthquake Forecasting with Neural Point Processes",
        "link_suffix": "/forum?id=qpz84ykqgv",
        "link": "https://openreview.net/forum?id=qpz84ykqgv",
        "pdf_link": "https://openreview.net/pdf?id=qpz84ykqgv",
        "keywords": "Point Processes, Earthquake Forecasting, Benchmarking, Datasets",
        "abstract": "Classical point process models, such as the epidemic-type aftershock sequence (ETAS) model, have been widely used for forecasting the event times and locations of earthquakes for decades. Recent advances have led to Neural Point Processes (NPPs), which promise greater flexibility and improvements over classical models. However, the currently-used benchmark dataset for NPPs does not represent an up-to-date challenge in the seismological community since it lacks a key earthquake sequence from the region and improperly splits training and testing data. Furthermore, initial earthquake forecast benchmarking lacks a comparison to state-of-the-art earthquake forecasting models typically used by the seismological community. To address these gaps, we introduce EarthquakeNPP: a collection of benchmark datasets to facilitate testing of NPPs on earthquake data, accompanied by a credible implementation of the ETAS model. The datasets cover a range of small to large target regions within California, dating from 1971 to 2021, and include different methodologies for dataset generation. In a benchmarking experiment, we compare three spatio-temporal NPPs against ETAS and find that none outperform ETAS in either spatial or temporal log-likelihood. These results indicate that current NPP implementations are not yet suitable for practical earthquake forecasting. However, EarthquakeNPP will serve as a platform for collaboration between the seismology and machine learning communities with the goal of improving earthquake predictability."
    },
    {
        "title": "RE-Adapt: Reverse Engineered Adaptation of Large Language Models",
        "link_suffix": "/forum?id=ebnyMCM63m",
        "link": "https://openreview.net/forum?id=ebnyMCM63m",
        "pdf_link": "https://openreview.net/pdf?id=ebnyMCM63m",
        "keywords": "Large Language Model, Fine-Tuning, Instruction-Tuning, Reverse Engineer, Adapter, LoRA, DoRA, QA, LLama-3, Gemma, Mistral",
        "abstract": "We introduce RE-Adapt, an approach to fine-tuning large language models on new domains without degrading any pre-existing instruction-tuning. We reverse engineer an adapter which isolates what an instruction-tuned model has learned beyond its corresponding pretrained base model. Importantly, this requires no additional data or training. We can then fine-tune the base model on a new domain and readapt it to instruction following with the reverse engineered adapter. RE-Adapt and our low-rank variant LoRE-Adapt both outperform other methods of fine-tuning, across multiple popular LLMs and datasets, even when the models are used in conjunction with retrieval-augmented generation."
    },
    {
        "title": "Towards Replication-Robust Data Markets",
        "link_suffix": "/forum?id=iTjSqQQ4f8",
        "link": "https://openreview.net/forum?id=iTjSqQQ4f8",
        "pdf_link": "https://openreview.net/pdf?id=iTjSqQQ4f8",
        "keywords": "regression, bayesian inference, collaborative analytics, data markets, game theory",
        "abstract": "Despite widespread adoption of machine learning throughout industry, many firms face a common challenge: relevant datasets are typically distributed amongst market competitors that are reluctant to share information. Recent works propose data markets to provide monetary incentives for collaborative machine learning, where agents share features with each other and are rewarded based on their contribution to improving the predictions others. These contributions are determined by their relative Shapley value, which is computed by treating features as players and their interactions as a characteristic function game. However, in its standard form, this setup further provides an incentive for agents to replicate their data and act under multiple false identities in order to increase their own revenue and diminish that of others, restricting their use in practice. In this work, we develop a replication-robust data market for supervised learning problems. We adopt Pearl\u2019s do-calculus from causal reasoning to refine the characteristic function game by differentiating between observational and interventional conditional probabilities. By doing this, we derive Shapley value-based rewards that are robust to this malicious replication by design, whilst preserving desirable market properties."
    },
    {
        "title": "Towards Realistic Hyperparameter Optimization in Continual Learning",
        "link_suffix": "/forum?id=KxQnhe5UuJ",
        "link": "https://openreview.net/forum?id=KxQnhe5UuJ",
        "pdf_link": "https://openreview.net/pdf?id=KxQnhe5UuJ",
        "keywords": "Contiual Learning, HPO",
        "abstract": "In continual learning (CL)\u2014where a learner trains on a stream of data\u2014standard hyperparameter optimisation (HPO) cannot be applied, as a learner does not have access to all of the data at the same time. This has prompted the development of CL-specific HPO frameworks. The most popular way to tune hyperparameters in CL is to repeatedly train over the whole data stream with different hyperparameter settings. However, thisend-of-trainingHPO is unrealistic as in practice a learner can only see the stream once. Hence, there is an open question:what HPO framework should a practitioner use for a CL problem in reality?This paper answers this question by comparing several realistic HPO frameworks. We find that none of the HPO frameworks considered, including end-of-training HPO, perform consistently better than the rest on popular CL benchmarks. We therefore arrive at a twofold conclusion: a) on the popular CL benchmarks examined, a CL practitioner should select the HPO framework based on other factors, for example compute efficiency and b) to be able to discriminate between HPO frameworks there is a need to move beyond the current most commonly used CL benchmarks."
    },
    {
        "title": "Fantastic Copyrighted Beasts and How (Not) to Generate Them",
        "link_suffix": "/forum?id=ftHNJmogT1",
        "link": "https://openreview.net/forum?id=ftHNJmogT1",
        "pdf_link": "https://openreview.net/pdf?id=ftHNJmogT1",
        "keywords": "copyright, copyrighted characters, alignment, evaluation, image generation models",
        "abstract": "Recent studies show that image and video generation models can be prompted to reproduce copyrighted content from their training data, raising serious legal concerns about copyright infringement. Copyrighted characters (e.g., Mario, Batman) present a significant challenge: at least one lawsuit has already awarded damages based on the generation of such characters. Consequently, commercial services like DALL\u00b7E have started deploying interventions.\nHowever, little research has systematically examined these problems: (1) Can users easily prompt models to generate copyrighted characters, even if it is unintentional?; (2) How effective are the existing mitigation strategies?\nTo address these questions, we introduce a novel evaluation framework with metrics that assess both the generated image\u2019s similarity to copyrighted characters and its consistency with user intent, grounded in a set of popular copyrighted characters from diverse studios and regions.\nWe show that state-of-the-art image and video generation models can still generate characters even if characters' names are not explicitly mentioned, sometimes with only two generic keywords (e.g., prompting with ``videogame, plumber'' consistently generates Nintendo's Mario character). \nWe also introduce semi-automatic techniques to identify such keywords or descriptions that trigger character generation. Within this framework, we study the effectiveness of mitigation strategies, including both existing methods and new strategies we propose. Our findings reveal that commonly used strategies, such as prompt rewriting in DALL\u00b7E, are insufficient as standalone guardrails. These strategies need to be supplemented with other approaches, such as negative prompting, to effectively reduce the unintended generation of copyrighted characters. Our work provides empirical grounding for discussions on copyright mitigation strategies and offers actionable insights for model deployers implementing these safeguards."
    },
    {
        "title": "Transformers and slot encoding for sample efficient physical world modelling",
        "link_suffix": "/forum?id=2H6KhX1kJr",
        "link": "https://openreview.net/forum?id=2H6KhX1kJr",
        "pdf_link": "https://openreview.net/pdf?id=2H6KhX1kJr",
        "keywords": "Transformers, world modeling, slot attention",
        "abstract": "World modelling, i.e. building a representation of the rules that govern the world so as to predict its evolution, is an essential ability for any agent interacting with the physical world. Recent applications of the Transformer architecture to the problem of world modelling from video input show notable improvements in sample efficiency. However, existing approaches tend to work only at the image level thus disregarding that the environment is composed of objects interacting with each other. In this paper, we propose an architecture combining Transformers for world modelling with the slot-attention paradigm, an approach for learning representations of objects appearing in a scene. We describe the resulting neural architecture and report experimental results showing an improvement over the existing solutions in terms of sample efficiency and a reduction of the variation of the performance over the training examples."
    },
    {
        "title": "Improving Graph Generation with Flow Matching and Optimal Transport",
        "link_suffix": "/forum?id=rMyfMS5nMt",
        "link": "https://openreview.net/forum?id=rMyfMS5nMt",
        "pdf_link": "https://openreview.net/pdf?id=rMyfMS5nMt",
        "keywords": "Flow matching generative model, graph generation",
        "abstract": "Generating graph-structured data is crucial in various domains but remains challenging due to the complex interdependencies between nodes and edges. While diffusion models have demonstrated their superior generative capabilities, they often suffer from unstable training and inefficient sampling. To enhance generation performance and training stability, we propose GGFlow, a discrete flow matching generative model incorporating optimal transport for graph structures and it incorporates an edge-augmented graph transformer to enable the direct communications among edges. Additionally, GGFlow introduces a novel goal-guided generation framework to control the generative trajectory of our model towards desired properties. GGFlow demonstrates superior performance on both unconditional and conditional generation tasks, outperforming existing baselines and underscoring its effectiveness and potential for wider application."
    },
    {
        "title": "mOSCAR: A Large-scale Multilingual and Multimodal Document-Level Corpus",
        "link_suffix": "/forum?id=lE9s40eZgJ",
        "link": "https://openreview.net/forum?id=lE9s40eZgJ",
        "pdf_link": "https://openreview.net/pdf?id=lE9s40eZgJ",
        "keywords": "large-scale dataset, vision language models, multilinguality",
        "abstract": "Multimodal Large Language Models (mLLMs) are trained on a large amount of text-image data. While most mLLMs are trained on caption-like data only, Alayrac et al. (2022) showed that additionally training them on interleaved sequences of text and images can lead to the emergence of in-context learning capabilities. However, the dataset they used, M3W, is not public and is only in English. There have been attempts to reproduce their results but the released datasets are English-only. In contrast, current multilingual and multimodal datasets are either composed of caption-like only or medium-scale or fully private data. This limits mLLM research for the 7,000 other languages spoken in the world. We therefore introduce mOSCAR, to the best of our knowledge the first large-scale multilingual and\nmultimodal document corpus crawled from the web. It covers 163 languages, 303M documents, 200B tokens and 1.15B images. We carefully conduct a set of filtering and evaluation steps to make sure mOSCAR is sufficiently safe, diverse and\nof good quality. We additionally train two types of multilingual model to prove the benefits of mOSCAR: (1) a model trained on a subset of mOSCAR and captioning data and (2) a model train on captioning data only. The model additionally trained on mOSCAR shows a strong boost in few-shot learning performance across various multilingual image-text tasks and benchmarks, confirming previous findings for English-only mLLMs. The dataset will be made publicly accessible."
    },
    {
        "title": "Balanced Hyperbolic Embeddings Are Natural Out-of-Distribution Detectors",
        "link_suffix": "/forum?id=83le3arfeA",
        "link": "https://openreview.net/forum?id=83le3arfeA",
        "pdf_link": "https://openreview.net/pdf?id=83le3arfeA",
        "keywords": "Hyperbolic learning, Out-of-distribution detection",
        "abstract": "Out-of-distribution recognition forms an important and well-studied problem in computer vision, with the goal to filter out samples that do not belong to the distribution on which a network has been trained. The conclusion of this paper is simple: a good hierarchical hyperbolic embedding is preferred for discriminating in- and out-of-distribution samples. We introduce Balanced Hyperbolic Learning. We outline a hyperbolic class embedding algorithm that jointly optimizes for hierarchical distortion and balancing between shallow and wide subhierarchies. We can then use the class embeddings as hyperbolic prototypes for classification on in-distribution data. We outline how existing out-of-distribution scoring functions can be generalized to operate with hyperbolic prototypes. Empirical evaluations across 13 datasets and 13 scoring functions show that our hyperbolic embeddings outperform existing out-of-distribution approaches when trained on the same data with the same backbones. We also show that our hyperbolic embeddings outperform other hyperbolic approaches and naturally enable hierarchical out-of-distribution generalization."
    },
    {
        "title": "Incremental Learning with Task-Specific Adapters",
        "link_suffix": "/forum?id=TxIrMD6lAN",
        "link": "https://openreview.net/forum?id=TxIrMD6lAN",
        "pdf_link": "https://openreview.net/pdf?id=TxIrMD6lAN",
        "keywords": "Adaptors, Incremental Learning, Computer Vision, Transfer Learning",
        "abstract": "Incremental learning aims to continuously acquire new knowledge while retaining previously learned information. The existing literature primarily focuses on enhancing model stability to prevent catastrophic forgetting of earlier tasks, often overlooking the challenges posed by inter-task differences, which we argue are the primary cause of catastrophic forgetting. In this paper, we propose a network design consisting of two blocks: one for modeling invariant features shared across all tasks, and another for capturing task-specific information. Specifically, we repurpose adapters, originally introduced for parameter-efficient fine-tuning, as feature modifiers to capture task-specific information, while the backbone network learns invariant features. Our approach can be integrated with existing methods such as elastic weight consolidation (EWC) and learning without forgetting (LwF). Extensive experiments on the CIFAR-100 and ImageNet datasets demonstrate that our adapter-based methods consistently outperform non-adapter counterparts across various learning scenarios, including different task orders and data scales. This study provides an effective solution to the stability-plasticity dilemma in incremental learning."
    },
    {
        "title": "Verifying Properties of Binary Neural Networks Using Sparse Polynomial Optimization",
        "link_suffix": "/forum?id=9c96mGtQVR",
        "link": "https://openreview.net/forum?id=9c96mGtQVR",
        "pdf_link": "https://openreview.net/pdf?id=9c96mGtQVR",
        "keywords": "Binary Neural Networks, Sparse Polynomial Optimization, Semidefinite Programming, Robustness Verification",
        "abstract": "This paper explores methods for verifying the properties of Binary Neural Networks (BNNs), focusing on robustness against adversarial attacks. Despite their lower computational and memory needs, BNNs, like their full-precision counterparts, are also sensitive to input perturbations. Established methods for solving this problem are predominantly based on Satisfiability Modulo Theories and Mixed-Integer Linear Programming techniques, which are characterized by NP complexity and often face scalability issues.\nWe introduce an alternative approach using Semidefinite Programming relaxations derived from sparse Polynomial Optimization. Our approach, compatible with continuous input space, not only mitigates numerical issues associated with floating-point calculations but also enhances verification scalability through the strategic use of tighter first-order semidefinite relaxations. We demonstrate the effectiveness of our method in verifying robustness against both $||.||_\\infty$ and $||.||_2$-based adversarial attacks."
    },
    {
        "title": "ReAttention: Training-Free Infinite Context with Finite Attention Scope",
        "link_suffix": "/forum?id=KDGP8yAz5b",
        "link": "https://openreview.net/forum?id=KDGP8yAz5b",
        "pdf_link": "https://openreview.net/pdf?id=KDGP8yAz5b",
        "keywords": "long context, length extrapolation, large language model, natural language processing",
        "abstract": "The long-context capability of the Large Language Models (LLM) has made significant breakthroughs, but the maximum supported context length remains a critical bottleneck limiting their practical applications. The constraint of context length in LLMs arises from the self-attention mechanism, which cannot effectively and efficiently capture the semantic relationships within infinitely long contexts via the limited pre-trained positional information and attention scope. In this work, we propose \\textbf{ReAttention}, a training-free approach enabling LLM based on the self-attention mechanism to support an infinite context with a finite attention scope under sufficient memory resources. ReAttention performs the position-agnostic top-$k$ attention before the ordinary position-aware self-attention, freeing LLMs from the length extrapolation issue. We validate the performance of ReAttention on the LongBench, L-Eval, and InfiniteBench and demonstrate that it is on par with traditional methods. Furthermore, we also apply ReAttention on mainstream LLMs, including LLaMA3.1-8B and Mistral-v0.3-7B, enabling them to support context lengths of at least 1M and even expanding the context length of LLaMA3.2-3B-chat by 128$\\times$ to 4M without any further training in Needle-In-A-Haystack tests. We also improve the efficiency of ReAttention with Triton and achieve an efficient extrapolation without additional overhead."
    },
    {
        "title": "Graph Fourier Neural Kernels (G-FuNK): Learning Solutions of Nonlinear Diffusive Parametric PDEs on Multiple Domains",
        "link_suffix": "/forum?id=4hdDPa9bpI",
        "link": "https://openreview.net/forum?id=4hdDPa9bpI",
        "pdf_link": "https://openreview.net/pdf?id=4hdDPa9bpI",
        "keywords": "Neural Operator, Graph Neural Networks, Graph Fourier Transform, Partial Differential Equations, Operator Learning, Cardiac Electrophysiology",
        "abstract": "Understanding and predicting the time-dependent dynamics of complex systems governed by non-linear partial differential equations (PDEs), with varying parameters and domains, is a difficult problem that is motivated by applications in many fields. We introduce a novel family of neural operators based on a Graph Fourier Neural Kernel (G-FuNK), for learning solution generators of nonlinear PDEs with varying coefficients, across multiple domains, for which the highest-order term in the PDE is diffusive. G-FuNKs are constructed by combining components that are parameter- and domain-adapted, with others that are not. The latter components are learned from training data, using a variation of Fourier Neural Operators, and are transferred directly across parameters and domains. The former, parameter- and domain-adapted components are constructed as soon as a parameter and a domain on which the PDE needs to be solved are given. They are obtained by constructing a weighted graph on the (discretized) domain, with weights chosen so that the Laplacian on that weighted graph approximates the highest order, diffusive term in the generator of the PDE, which is parameter- and domain-specific, and satisfies the boundary conditions. This approach proves to be a natural way to embed geometric and directionally-dependent information about the domains, allowing for improved generalization to new test domains without need for retraining. Finally, we equip G-FuNK with an integrated ordinary differential equation (ODE) solver to enable the temporal evolution of the system's state. Our experiments demonstrate G-FuNK's ability to accurately approximate heat, reaction diffusion, and cardiac electrophysiology equations on multiple geometries and varying anisotropic diffusivity fields. We achieve low relative errors on unseen domains and fiber fields, significantly speeding up prediction capabilities compared to traditional finite-element solvers."
    },
    {
        "title": "Delay Neural Networks (DeNN) for exploiting temporal information in event-based datasets",
        "link_suffix": "/forum?id=pIJR9uPjy3",
        "link": "https://openreview.net/forum?id=pIJR9uPjy3",
        "pdf_link": "https://openreview.net/pdf?id=pIJR9uPjy3",
        "keywords": "Deep Learning, Synaptic Delays, Spiking Neural Networks, Event-based",
        "abstract": "In Deep Neural Networks (DNN) and Spiking Neural Networks (SNN), the information of a neuron is computed based on the sum of the amplitudes (weights) of the electrical potentials received in input from other neurons. We propose here a new class of neural networks, namely Delay Neural Networks (DeNN), where the information of a neuron is computed based on the sum of its input synaptic delays and on the spike times of the electrical potentials received from other neurons. This way, DeNN are designed to explicitly use exact continuous temporal information of spikes in both forward and backward passes, without approximation. (Deep) DeNN are applied here to images and event-based (audio and visual) data sets. Good performances are obtained, especially for datasets where temporal information is important, with much less parameters than other models."
    },
    {
        "title": "OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text",
        "link_suffix": "/forum?id=kwqhn2VuG4",
        "link": "https://openreview.net/forum?id=kwqhn2VuG4",
        "pdf_link": "https://openreview.net/pdf?id=kwqhn2VuG4",
        "keywords": "Image-text interleaved dataset",
        "abstract": "Image-text interleaved data, consisting of multiple images and texts arranged in a natural document format, aligns with the presentation paradigm of internet data and closely resembles human reading habits. Recent studies have shown that such data aids multimodal in-context learning and maintains the capabilities of large language models during multimodal fine-tuning. However, the limited scale and diversity of current image-text interleaved data restrict the development of multimodal large language models. In this paper, we introduce OmniCorpus, a 10 billion-scale image-text interleaved dataset. Using an efficient data engine, we filter and extract large-scale high-quality documents, which contain 8.6 billion images and 1,696 billion text tokens. Compared to counterparts (e.g., MMC4, OBELICS), our dataset 1) has 15 times larger scales while maintaining good data quality; 2) features more diverse sources, including both English and non-English websites as well as video-centric websites; 3) is more flexible, easily degradable from an image-text interleaved format to pure text corpus and image-text pairs. Through comprehensive analysis and experiments, we validate the quality, usability, and effectiveness of the proposed dataset. We hope this could provide a solid data foundation for future multimodal model research."
    },
    {
        "title": "Towards Realistic Mechanisms That Incentivize Federated Participation and Contribution",
        "link_suffix": "/forum?id=sgHnfLX9Lt",
        "link": "https://openreview.net/forum?id=sgHnfLX9Lt",
        "pdf_link": "https://openreview.net/pdf?id=sgHnfLX9Lt",
        "keywords": "Federated Learning, Mechanisms, Realistic, Utility",
        "abstract": "Edge device participation in federating learning (FL) is typically studied through the lens of device-server communication (e.g., device dropout) and assumes an undying desire from edge devices to participate in FL. As a result, current FL frameworks are flawed when implemented in realistic settings, with many encountering the free-rider dilemma. In a step to push FL towards realistic settings, we propose RealFM: the first federated mechanism that (1) realistically models device utility, (2) incentivizes data contribution and device participation, (3) provably removes the free-rider dilemma, and (4) relaxes assumptions on data homogeneity and data sharing. Compared to previous FL mechanisms, RealFM allows for a non-linear relationship between model accuracy and utility, which improves the utility gained by the server and participating devices. On real-world data, RealFM improves device and server utility, as well as data contribution, by over 3 and 4 magnitudes respectively compared to baselines."
    },
    {
        "title": "Mitigating the Backdoor Effect for Multi-Task Model Merging via Safety-Aware Subspace",
        "link_suffix": "/forum?id=dqMqAaw7Sq",
        "link": "https://openreview.net/forum?id=dqMqAaw7Sq",
        "pdf_link": "https://openreview.net/pdf?id=dqMqAaw7Sq",
        "keywords": "Model Merging; Backdoor Defense; Subspace",
        "abstract": "Model merging has gained significant attention as a cost-effective approach to integrate multiple single-task fine-tuned models into a unified one that can perform well on multiple tasks. However, existing model merging techniques primarily focus on resolving conflicts between task-specific models, they often overlook potential security threats, particularly the risk of backdoor attacks in the open-source model ecosystem. In this paper, we first investigate the vulnerabilities of existing model merging methods to backdoor attacks, identifying two critical challenges: backdoor succession and backdoor transfer. To address these issues, we propose a novel Defense-Aware Merging (DAM) approach that simultaneously mitigates task interference and backdoor vulnerabilities. Specifically, DAM employs a meta-learning-based optimization method with dual masks to identify a shared and safety-aware subspace for model merging. These masks are alternately optimized: the Task-Shared mask identifies common beneficial parameters across tasks, aiming to preserve task-specific knowledge while reducing interference, while the Backdoor-Detection mask isolates potentially harmful parameters to neutralize security threats. This dual-mask design allows us to carefully balance the preservation of useful knowledge and the removal of potential vulnerabilities. Compared to existing merging methods, DAM achieves a more favorable balance between performance and security, reducing the attack success rate by 2-10 percentage points while sacrificing only about 1% in accuracy. Furthermore, DAM exhibits robust performance and broad applicability across various types of backdoor attacks and the number of compromised models involved in the merging process."
    },
    {
        "title": "An Information Criterion for Controlled Disentanglement of Multimodal Data",
        "link_suffix": "/forum?id=3n4RY25UWP",
        "link": "https://openreview.net/forum?id=3n4RY25UWP",
        "pdf_link": "https://openreview.net/pdf?id=3n4RY25UWP",
        "keywords": "Multimodal Representation Learning, Disentanglement, Self-Supervised Learning, Information Theory",
        "abstract": "Multimodal representation learning seeks to relate and decompose information inherent in multiple modalities. By disentangling modality-specific information from information that is shared across modalities, we can improve interpretability and robustness and enable downstream tasks such as the generation of counterfactual outcomes. Separating the two types of information is challenging since they are often deeply entangled in many real-world applications. We propose $\\textbf{Disentangled}$ $\\textbf{S}$elf-$\\textbf{S}$upervised $\\textbf{L}$earning (DisentangledSSL), a novel self-supervised approach for learning disentangled representations. We present a comprehensive analysis of the optimality of each disentangled representation, particularly focusing on the scenario not covered in prior work where the so-called $\\textit{Minimum Necessary Information}$ (MNI) point is not attainable. We demonstrate that \\algo successfully learns shared and modality-specific features on multiple synthetic and real-world datasets and consistently outperforms baselines on various downstream tasks, including prediction tasks for vision-language data, as well as molecule-phenotype retrieval tasks for biological data."
    },
    {
        "title": "Motion-Grounded Video Reasoning: Understanding and Perceiving Motion at Pixel Level",
        "link_suffix": "/forum?id=tEei1bolt3",
        "link": "https://openreview.net/forum?id=tEei1bolt3",
        "pdf_link": "https://openreview.net/pdf?id=tEei1bolt3",
        "keywords": "Motion, Video Grounding, Video Reasoning",
        "abstract": "In this paper, we introduce Motion-Grounded Video Reasoning, a new motion understanding task that requires generating visual answers (video segmentation masks) according to the input question, and hence needs implicit spatiotemporal reasoning and grounding. This task extends existing spatiotemporal grounding work focusing on explicit action/motion grounding, to a more general format by enabling implicit reasoning via questions. To facilitate the development of the new task, we collect a large-scale dataset called GroundMoRe, which comprises 1,673 video clips, 243K object masks that are deliberately designed with 4 question types (Causal, Sequential, Counterfactual, and Descriptive) for benchmarking deep and comprehensive motion reasoning abilities. GroundMoRe uniquely requires models to generate visual answers, providing a more concrete and visually interpretable response than plain texts. It evaluates models on both spatiotemporal grounding and reasoning, fostering to address complex challenges in motion-related video reasoning, temporal perception, and pixel-level understanding. Furthermore, we introduce a novel baseline model named Motion-Grounded Video Reasoning Assistant (MoRA). MoRA incorporates the multimodal reasoning ability from the Multimodal LLM, the pixel-level perception capability from the grounding model (SAM), and the temporal perception ability from a lightweight localization head. MoRA achieves respectable performance on GroundMoRe outperforming the best existing visual grounding baseline model by an average of 28.8% relatively. We hope this novel and challenging task will pave the way for future advancements in robust and general motion understanding via video reasoning segmentation."
    },
    {
        "title": "Emergence of meta-stable clustering in mean-field transformer models",
        "link_suffix": "/forum?id=eBS3dQQ8GV",
        "link": "https://openreview.net/forum?id=eBS3dQQ8GV",
        "pdf_link": "https://openreview.net/pdf?id=eBS3dQQ8GV",
        "keywords": "Mean-field limits, Transformers, Meta-stability, Clustering",
        "abstract": "We model the evolution of tokens within a deep stack of Transformer layers as a continuous-time flow on the unit sphere, governed by a mean-field interacting particle system, building on the framework introduced in Geshkovski et al. (2023). Studying the corresponding mean-field Partial Differential Equation (PDE), which can be interpreted as a Wasserstein gradient flow, in this paper we provide a mathematical investigation of the long-term behavior of this system, with a particular focus on the emergence and persistence of meta-stable phases and clustering phenomena, key elements in applications like next-token prediction. More specifically, we perform a perturbative analysis of the mean-field PDE around the iid uniform initialization and prove that, in the limit of large number of tokens, the model remains close to a meta-stable manifold of solutions with a given structure (e.g., periodicity). Further, the structure characterizing the meta-stable manifold is explicitly identified, as a function of the inverse temperature parameter of the model, by the index maximizing a certain rescaling of Gegenbauer polynomials."
    },
    {
        "title": "Non-linear activation soothes NTK conditioning for wide neural networks: a study in the ReLU case",
        "link_suffix": "/forum?id=2qvFs9d2jt",
        "link": "https://openreview.net/forum?id=2qvFs9d2jt",
        "pdf_link": "https://openreview.net/pdf?id=2qvFs9d2jt",
        "keywords": "ReLU, non-linear activation function, condition number, NTK, neural tangent kernel, convergence rate",
        "abstract": "Non-linear activation functions are well known to improve the expressivity of neural networks, which is the main reason of their wide implementation in neural networks. In this work, we showcase a new and interesting property of certain non-linear activations, focusing on the most popular example of its kind - Rectified Linear Unit (ReLU). By comparing the cases with and without this non-linear activation, we show that the ReLU has the following effects: (a) better data separation, i.e., a larger angle separation for similar data in the feature space of model gradient, and (b) better NTK conditioning, i.e., a smaller condition number of neural tangent kernel (NTK). Furthermore, we show that the ReLU network depth (i.e., with more ReLU activation operations) further magnifies these effects. Note that, without the non-linear activation, i.e., in a linear neural network, the data separation and NTK condition number always remain the same as in the case of a linear model, regardless of the network depth. Our results imply that ReLU activation, as well as the depth of ReLU network, helps improve the worst-case convergence rate of GD, which is closely related to the NTK condition number."
    },
    {
        "title": "SGHormerVQ: Bridging Graph Transformers and Spiking Neural Networks via Spiking Vector Quantization",
        "link_suffix": "/forum?id=I0mQlersGk",
        "link": "https://openreview.net/forum?id=I0mQlersGk",
        "pdf_link": "https://openreview.net/pdf?id=I0mQlersGk",
        "keywords": "graph transformer, spiking neural network, vector quantization",
        "abstract": "Graph Transformers (GTs), which simultaneously integrate message passing and self-attention mechanisms, have achieved promising empirical results in some graph prediction tasks. Although these approaches show the potential of Transformers in capturing long-range graph topology information, issues concerning the quadratic complexity and high computing energy consumption severely impair the scalability of GTs on large-scale graphs. Recently, as brain-inspired neural networks, Spiking Neural Networks (SNNs) provide an energy-saving deep learning option with lower computational and storage overhead via their unique spike-based event-driven biological neurons. Inspired by these characteristics, we propose SGHormerVQ, which bridges efficient Graph Transformers and spiking neural networks via spiking vector quantization. Spiking vector quantization generates implied codebooks with smaller sizes and higher codebook usage to assist self-attention blocks in performing efficient global information aggregation. SGHormerVQ effectively alleviates the reliance on complex machinery (distance measure, auxiliary loss, etc.) and the \\textit{codebook collapse} present in previous vector quantization-based GNNs. In experiments, we compare SGHormerVQ with other state-of-the-art baselines on node classification datasets ranging from small to large. Experimental results show that SGHormerVQ has achieved competitive performances on most datasets while maintaining up to 518\u00d7 faster inference speed compared to other GTs."
    }
]
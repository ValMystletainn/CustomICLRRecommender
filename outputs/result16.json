[{"title": "Solving Nash Equilibrium Scalably via Deep-Learning-Augmented Iterative Algorithms", "link_suffix": "/forum?id=NPLty3VT1c", "link": "https://openreview.net/forum?id=NPLty3VT1c", "pdf_link": "https://openreview.net/pdf?id=NPLty3VT1c", "keywords": "Nash Equilibrium, Game Theory, Deep Learning", "abstract": "Computing the Nash Equilibrium (NE) is a fundamental yet computationally challenging problem in game theory. Although recent approaches have incorporated deep learning techniques to tackle this intractability, most of them still struggle with scalability when the number of players increases, due to the exponential growth of computational cost. Inspired by the efficiency of classical learning dynamics methods, we propose a deep learning-augmented Nash equilibrium solver, named Deep Iterative Nash Equilibrium Solver (DINES), based on a novel framework that integrates deep learning into iterative algorithms to solve Nash Equilibria more efficiently. Our approach effectively reduces time complexity to a polynomial level and mitigates the curse of dimensionality by leveraging query-based access to utility functions rather than requiring the full utility matrix. Experimental results demonstrate that our approach achieves better or comparable approximation accuracy compared to existing methods, while significantly reducing computational expense. This advantage is highlighted in large-scale sparse games, which is previously intractable for most existing deep-learning-based methods.", "title_embedding_index": 750, "title_abs_embedding_index": 775}, {"title": "Controllable Molecule Generation by Sampling in Continuous Parameter Space", "link_suffix": "/forum?id=8OLayNZfvM", "link": "https://openreview.net/forum?id=8OLayNZfvM", "pdf_link": "https://openreview.net/pdf?id=8OLayNZfvM", "keywords": "Molecular generation; bayesian flow networks", "abstract": "Deep generative models have made significant strides for continuous data generation, such as producing realistic images and 3D protein conformations.  However, due to the sensitivity of topological graphs to noise and the constraints of long-range discrete relationships, the generation of purely discrete data\u2014such as topological graphs\u2014remains a long-standing challenge, with property control proving even more elusive. In this paper, we propose a novel molecular graph generative framework, called CtrlMol, to learn the topological graphs of molecules in a differentiable parameter space. Unlike diffusion models that iteratively refine samples, CtrlMol optimizes distribution parameters at different noise levels through a pre-defined Bayesian flow. At each of the sampling step, we leverage a property guided output distribution to have a fine-grained control of the topological structures toward the given property. Experimental results demonstrate CtrlMol outperforms all the competing baselines in generating natural molecule graphs. In addition, CtrlMol advances the state of the art in producing the molecules with the desired properties.", "title_embedding_index": 751, "title_abs_embedding_index": 776}, {"title": "Why Do You Answer Like That? Psychological Analysis on Underlying Connections between LLM's Values and Safety Risks", "link_suffix": "/forum?id=Na28j1Drh7", "link": "https://openreview.net/forum?id=Na28j1Drh7", "pdf_link": "https://openreview.net/pdf?id=Na28j1Drh7", "keywords": "Value Alignment, Personalized LLMs, AI Safety, Phychological Analysis", "abstract": "The application scope of Large Language Models (LLMs) continues to expand, leading to increasing interest in personalized LLMs. However, aligning these models with individual values raises significant safety concerns due to harmful information correlated with certain values. In this paper, we identify specific safety risks in value-aligned LLMs and investigate the psychological principles behind these challenges. Our findings reveal two key insights. First, value-aligned LLMs are more prone to harmful behavior compared to non-fine-tuned models and exhibit slightly higher risks in traditional safety evaluations than other fine-tuned models. Second, these safety issues arise because value-aligned LLMs genuinely understand and act according to the aligned values, which can amplify harmful outcomes. Using a dataset with detailed safety categories, we find significant correlations between value alignment and safety concerns, supported by psychological hypotheses. This study offers insights into the ``black box'' of value alignment and proposes enhancing the safety of value-aligned LLMs by corresponding in-context alignment methods.\nWarning: This paper contains contents that may be offensive or upsetting.", "title_embedding_index": 752, "title_abs_embedding_index": 777}, {"title": "Efficient Scaling of Diffusion Transformers for Text-to-Image Generation", "link_suffix": "/forum?id=iG7qH9Kdao", "link": "https://openreview.net/forum?id=iG7qH9Kdao", "pdf_link": "https://openreview.net/pdf?id=iG7qH9Kdao", "keywords": "diffusion model, text-to-image generation, scaling law, u-vit, dit", "abstract": "We empirically study the scaling properties of various Diffusion Transformers (DiTs) for text-to-image generation by performing extensive and rigorous ablations, including training scaled DiTs ranging from 0.3B upto 8B parameters on datasets up to 600M images.  We find that U-ViT, a pure self-attention based DiT model provides a simpler design and scales more effectively in comparison with cross-attention based DiT variants, which allows straightforward expansion for extra conditions and other modalities. We identify a 2.3B U-ViT model can get better performance than SDXL UNet and other DiT variants in controlled setting. On the data scaling side, we investigate how increasing dataset size and enhanced long caption improve the text-image alignment performance and the learning efficiency.", "title_embedding_index": 753, "title_abs_embedding_index": 778}, {"title": "CWPS: Efficient Channel-Wise Parameter Sharing for Knowledge Transfer", "link_suffix": "/forum?id=xbXydoejvY", "link": "https://openreview.net/forum?id=xbXydoejvY", "pdf_link": "https://openreview.net/pdf?id=xbXydoejvY", "keywords": "Transfer Learning, Multi-Domain Learning, Multi-Task Learning", "abstract": "Knowledge transfer aims to apply existing knowledge to different tasks or new data, and it has extensive applications in multi-domain and multi-task learning.\n    The key to this task is quickly identifying a fine-grained object for knowledge sharing and efficiently transferring knowledge.\n    Current methods, such as fine-tuning, layer-wise parameter sharing, and task-specific adapters, only offer coarse-grained sharing solutions and struggle to effectively search for shared parameters, thus hindering the performance and efficiency of knowledge transfer.\n    To address these issues, we propose Channel-Wise Parameter Sharing (CWPS), a novel fine-grained parameter-sharing method for Knowledge Transfer, which is efficient for parameter sharing, comprehensive, and plug-and-play.\n    For the coarse-grained problem, we first achieve fine-grained parameter sharing by refining the granularity of shared parameters from the level of layers to the level of neurons. The knowledge learned from previous tasks can be utilized through the explicit composition of the model neurons.\n    Besides, we promote an effective search strategy to minimize computational costs, simplifying the process of determining shared weights.\n    In addition, our CWPS has strong composability and generalization ability, which theoretically can be applied to any network consisting of linear and convolution layers.\n    We introduce several datasets in both incremental learning and multi-task learning scenarios. Our method has achieved state-of-the-art precision-to-parameter ratio performance with various backbones, demonstrating its efficiency and versatility.", "title_embedding_index": 754, "title_abs_embedding_index": 779}, {"title": "Balancing Model Efficiency and Performance: Adaptive Pruner for Long-tailed Data", "link_suffix": "/forum?id=wVMzK2Feuu", "link": "https://openreview.net/forum?id=wVMzK2Feuu", "pdf_link": "https://openreview.net/pdf?id=wVMzK2Feuu", "keywords": "Long-tail learning\uff0cNeural network pruning\uff0cMulti-objective Optimization", "abstract": "Long-tailed distribution datasets are prevalent in many machine learning tasks, yet existing neural network models still face significant challenges when handling such data. This paper proposes a novel adaptive pruning strategy, LTAP (Long-Tailed Adaptive Pruner), aimed at balancing model efficiency and performance to better address the challenges posed by long-tailed data distributions. LTAP introduces multi-dimensional importance scoring criteria and designs a dynamic weight adjustment mechanism to adaptively determine the pruning priority of parameters for different classes. By focusing on protecting parameters critical for tail classes, LTAP significantly enhances computational efficiency while maintaining model performance. This method combines the strengths of long-tailed learning and neural network pruning, overcoming the limitations of existing approaches in handling imbalanced data. Extensive experiments demonstrate that LTAP outperforms existing methods on various long-tailed datasets, achieving a good balance between model compression rate, computational efficiency, and classification accuracy. This research provides new insights into solving model optimization problems in long-tailed learning and is significant for improving the performance of neural networks on imbalanced datasets. The code is available at \\url{https://anonymous.4open.science/r/AEFCDAISJ/README.md}.", "title_embedding_index": 755, "title_abs_embedding_index": 780}, {"title": "Local Loss Optimization in the Infinite Width: Stable Parameterization of Predictive Coding Networks and Target Propagation", "link_suffix": "/forum?id=g6syfIrVuS", "link": "https://openreview.net/forum?id=g6syfIrVuS", "pdf_link": "https://openreview.net/pdf?id=g6syfIrVuS", "keywords": "deep learning, feature learning, local learning, predictive coding, target propagation, infinite width, maximal update parameterization (muP)", "abstract": "Local learning, which trains a network through layer-wise local targets and losses, has been studied as an alternative to backpropagation (BP) in neural computation. However, its algorithms often become more complex or require additional hyperparameters due to the locality, making it challenging to identify desirable settings where the algorithm progresses in a stable manner.\nTo provide theoretical and quantitative insights, we introduce  maximal update parameterization ($\\mu$P) in the infinite-width limit for two representative designs of local targets: predictive coding (PC) and target propagation (TP). We verify that $\\mu$P enables hyperparameter transfer across models of different widths.\nFurthermore, our analysis reveals unique and intriguing properties of $\\mu$P that are not present in conventional BP. By analyzing deep linear networks, we find that PC's gradients interpolate between first-order and Gauss-Newton-like gradients, depending on the parameterization.We demonstrate that, in specific standard settings, PC in the infinite-width limit behaves more similarly to the first-order gradient.\nFor TP, even with the standard scaling of the last layer differing from classical $\\mu$P, its local loss optimization favors the feature learning regime over the kernel regime.", "title_embedding_index": 756, "title_abs_embedding_index": 781}, {"title": "Detecting Training Data of Large Language Models via Expectation Maximization", "link_suffix": "/forum?id=asA7vvsgcI", "link": "https://openreview.net/forum?id=asA7vvsgcI", "pdf_link": "https://openreview.net/pdf?id=asA7vvsgcI", "keywords": "large language models, membership inference attack, data contamination, memorization", "abstract": "The widespread deployment of large language models (LLMs) has led to impressive advancements, yet information about their training data, a critical factor in their performance, remains undisclosed. Membership inference attacks (MIAs) aim to determine whether a specific instance was part of a target model's training data. MIAs can offer insights into LLM outputs and help detect and address concerns such as data contamination and compliance with privacy and copyright standards. However, applying MIAs to LLMs presents unique challenges due to the massive scale of pre-training data and the ambiguous nature of membership. Additionally, creating appropriate benchmarks to evaluate MIA methods is not straightforward, as training and test data distributions are often unknown. In this paper, we introduce EM-MIA, a novel MIA method for LLMs that iteratively refines membership scores and prefix scores via an expectation-maximization algorithm, leveraging the duality that the estimates of these scores can be improved by each other. Membership scores and prefix scores assess how each instance is likely to be a member and discriminative as a prefix, respectively. Our method achieves state-of-the-art results on the WikiMIA dataset. To further evaluate EM-MIA, we present OLMoMIA, a benchmark built from OLMo resources, which allows us to control the difficulty of MIA tasks with varying degrees of overlap between training and test data distributions. We believe that EM-MIA serves as a robust MIA method for LLMs and that OLMoMIA provides a valuable resource for comprehensively evaluating MIA approaches, thereby driving future research in this critical area.", "title_embedding_index": 757, "title_abs_embedding_index": 782}, {"title": "Towards Faster Decentralized Stochastic Optimization with Communication Compression", "link_suffix": "/forum?id=CMMpcs9prj", "link": "https://openreview.net/forum?id=CMMpcs9prj", "pdf_link": "https://openreview.net/pdf?id=CMMpcs9prj", "keywords": "Optimization, Decentralized Learning, Federated Learning, Communication Compression", "abstract": "Communication efficiency has garnered significant attention as it is considered the main bottleneck for large-scale decentralized Machine Learning applications in distributed and federated settings. In this regime, clients are restricted to transmitting small amounts of compressed information to their neighbors over a communication graph. Numerous endeavors have been made to address this challenging problem by developing algorithms with compressed communication for decentralized non-convex optimization problems. Despite considerable efforts, current theoretical understandings of the problem are still very limited, and existing algorithms all suffer from various limitations. In particular, these algorithms typically rely on strong, and often infeasible assumptions such as bounded data heterogeneity or require large batch access while failing to achieve linear speedup with the number of clients. In this paper, we introduce MoTEF, a novel approach that integrates communication compression with $\\textbf{Mo}$mentum $\\textbf{T}$racking and $\\textbf{E}$rror $\\textbf{F}$eedback. MoTEF is the first algorithm to achieve an asymptotic rate matching that of distributed SGD under arbitrary data heterogeneity, hence resolving a long-standing theoretical obstacle in decentralized optimization with compressed communication. We provide numerical experiments to validate our theoretical findings and confirm the practical superiority of MoTEF.", "title_embedding_index": 758, "title_abs_embedding_index": 783}, {"title": "Mitigating Spurious Correlations via Group-robust Sample Reweighting", "link_suffix": "/forum?id=aQj9Ifxrl6", "link": "https://openreview.net/forum?id=aQj9Ifxrl6", "pdf_link": "https://openreview.net/pdf?id=aQj9Ifxrl6", "keywords": "distribution shift, subpopulation shift, spurious correlation, influence function", "abstract": "Machine learning models often have uneven performance among subpopulations (a.k.a., groups) in the data distributions. This poses a significant challenge for the models to generalize when the proportions of the groups shift during deployment.\nTo improve robustness to such subpopulation shifts, existing approaches have developed strategies that train models or perform hyperparameter tuning using the group-labeled data to minimize the worst-case loss over groups.\nHowever, a non-trivial amount of high-quality labels is often required to obtain noticeable improvements.\nGiven the costliness of the labels, we propose to adopt a different paradigm to enhance group label efficiency:\nutilizing the group-labeled data as a target set to optimize the weights of other group-unlabeled data.\nWe introduce a two-stage approach called Group-robust Sample Reweighting (GSR) that first learns the representations from group-unlabeled data, and then tinkers the model by iteratively retraining its last layer on the reweighted data.\nOur GSR is theoretically sound, practically lightweight, and effective in improving the robustness to subpopulation shifts. In particular, GSR outperforms the previous state-of-the-art results on standard benchmarks when using the same amount of group labels. Notably, GSR even outperforms approaches that require significantly more group labels.", "title_embedding_index": 759, "title_abs_embedding_index": 784}, {"title": "Non-Commutative Spectral Geometry for Adaptive Quantum-Classical Drug-Target Interaction Prediction", "link_suffix": "/forum?id=kvCKoKfqTd", "link": "https://openreview.net/forum?id=kvCKoKfqTd", "pdf_link": "https://openreview.net/pdf?id=kvCKoKfqTd", "keywords": "Drug-Target Interaction Prediction\uff0cUDA", "abstract": "Drug-target interactions (DTIs) are fundamental and intricate processes essential for the advancement of drug discovery and design. We present a groundbreaking unified framework for drug-target interaction (DTI) prediction that seamlessly integrates advanced concepts from non-commutative geometry, optimal transport theory, and quantum information science. Our approach, Non-Commutative Geometric Adaptation for Molecular Interactions (NCGAMI), reframes the DTI prediction problem within the context of a non-commutative pharmacological manifold, enabling a profound synthesis of classical and quantum perspectives. By leveraging the spectral action principle, we develop a novel domain adaptation technique that minimizes a geometrically motivated functional, yielding optimal transport maps between pharmacological domains. We establish a deep connection between our framework and non-equilibrium statistical mechanics through a fluctuation theorem for domain adaptation, providing fundamental insights into the thermodynamics of the adaptation process. Our unified variational objective, formulated using geometric quantization, incorporates quantum relative entropy and Liouville volume forms, bridging information-theoretic and geometric aspects of the problem. We introduce a quantum adiabatic optimization algorithm for solving this objective, guaranteeing convergence to the optimal solution under specified conditions. Furthermore, we prove that the algebra of observables generated by our model forms a hyperfinite type III$_1$ factor, revealing a profound link between the algebraic structure of DTI prediction and the geometry of optimal transport. This result enables us to characterize the modular automorphism group governing the evolution of adapted distributions. Extensive numerical experiments demonstrate that NCGAMI significantly outperforms existing state-of-the-art methods across a wide range of DTI prediction tasks, achieving unprecedented accuracy and robustness.", "title_embedding_index": 760, "title_abs_embedding_index": 785}, {"title": "Endless Jailbreaks with Bijection Learning", "link_suffix": "/forum?id=xP1radUi32", "link": "https://openreview.net/forum?id=xP1radUi32", "pdf_link": "https://openreview.net/pdf?id=xP1radUi32", "keywords": "jailbreaking, redteaming, AI safety, AI alignment, adversarial robustness, adversarial attacks", "abstract": "Despite extensive safety training, LLMs are vulnerable to adversarial inputs. In this work, we introduce a simple but powerful attack paradigm, bijection learning, that yields a practically endless set of jailbreak prompts. We exploit language models' advanced reasoning capabilities to teach them invertible languages (bijections) in context, pass encoded queries to the model to bypass built-in safety mechanisms, and finally decode responses back into English, yielding helpful replies to harmful requests. Our approach proves effective on a wide range of frontier language models and harm categories. Bijection learning is an automated and universal attack that grows stronger with scale: larger models with more advanced reasoning capabilities are more susceptible to bijection learning jailbreaks despite stronger safety mechanisms.", "title_embedding_index": 761, "title_abs_embedding_index": 786}, {"title": "Rethinking Efficient 3D Equivariant Graph Neural Networks", "link_suffix": "/forum?id=5wxCQDtbMo", "link": "https://openreview.net/forum?id=5wxCQDtbMo", "pdf_link": "https://openreview.net/pdf?id=5wxCQDtbMo", "keywords": "graph neural networks, computational physics, 3D graphs", "abstract": "Understanding complex three-dimensional (3D) structures of graphs is essential for accurately modeling various properties, yet many existing approaches struggle to fully capture the intricate spatial relationships and symmetries inherent in such systems, especially in large-scale, dynamic molecular datasets. These methods often face trade-offs between expressiveness and computational efficiency, limiting their scalability. To address this gap, we propose a novel Geometric Tensor Network (GotenNet) that precisely models the geometric intricacies of 3D graphs while ensuring strict equivariance under the Euclidean group E(3). Our approach directly tackles the expressiveness-efficiency trade-off by leveraging effective geometric tensor representations without relying on irreducible representations or Clebsch-Gordan transforms, thereby reducing computational overhead. We introduce a unified structural embedding, incorporating geometry-aware tensor attention and hierarchical tensor refinement, allowing for flexible and efficient representations for various tasks. The proposed model consistently outperforms state-of-the-art methods in both scalar and higher-order tensor predictions, demonstrating exceptional robustness across diverse datasets, and establishes GotenNet as a versatile and scalable framework for 3D equivariant Graph Neural Networks.", "title_embedding_index": 762, "title_abs_embedding_index": 787}, {"title": "Think or Remember? Detecting and Directing LLMs Towards Memorization or Generalization", "link_suffix": "/forum?id=w4gkS9RsWh", "link": "https://openreview.net/forum?id=w4gkS9RsWh", "pdf_link": "https://openreview.net/pdf?id=w4gkS9RsWh", "keywords": "LLM, generalization, memorization, neuron differentiation, behavior identification, inference-time intervention, behavior control", "abstract": "In this paper, we study fundamental mechanisms of memorization and generalization in Large Language Models (LLMs), drawing inspiration from the functional specialization observed in the human brain. Our study aims to (a) determine whether LLMs exhibit spatial differentiation of neurons for memorization and generalization, (b) predict these behaviors using internal representations, and (c) control them through inference-time interventions. To achieve this, we design specialized datasets to distinguish between memorization and generalization, build up classifiers to predict these behaviors from model hidden states and develop interventions to influence the model in real time. Our experiments reveal that LLMs exhibit neuron-wise differentiation for memorization and generalization, and the proposed intervention mechanism successfully steers the model's behavior as intended. These findings significantly advance the understanding of LLM behavior and demonstrate the potential for enhancing the reliability and controllability of LLMs.", "title_embedding_index": 763, "title_abs_embedding_index": 788}, {"title": "Robust Gaussian Process Regression with Huber Likelihood", "link_suffix": "/forum?id=Gl2nXRzclw", "link": "https://openreview.net/forum?id=Gl2nXRzclw", "pdf_link": "https://openreview.net/pdf?id=Gl2nXRzclw", "keywords": "Gaussian Process Regression, Outlier Handling, Huber Probability Distribution, Laplace Approximation, Gibbs Sampling", "abstract": "Outliers in both covariates and output responses pose significant challenges for Gaussian Process (GP) regression models. We present a novel GP regression approach that effectively integrates the Huber likelihood into the GP framework\u2014without introducing additional parameters to infer. Specifically, we model the likelihood of observed outputs using the Huber probability distribution: this reduces deviations caused by output outliers. For covariate outliers, we introduce a projection pursuit weights\u2014attenuating their influence on the model. To address the analytically intractable, yet unimodal, posterior distribution, we employ Laplace approximation and Gibbs sampling within a Markov Chain Monte Carlo (MCMC) framework. We simplify Gibbs sampling by expressing the likelihood associated with outlying points as normally distributed through the scale mixture representation of the Laplace distribution. This work is particularly important in the field of transmission spectroscopy\u2014where noisy measurements are often neglected in the estimation of planet-to-star radius ratios. We demonstrate the robustness and effectiveness of our method through extensive experiments on synthetic and real-world datasets.", "title_embedding_index": 764, "title_abs_embedding_index": 789}, {"title": "Unveiling Concept Attribution in Diffusion Models", "link_suffix": "/forum?id=kdriw2a8sl", "link": "https://openreview.net/forum?id=kdriw2a8sl", "pdf_link": "https://openreview.net/pdf?id=kdriw2a8sl", "keywords": "generative models, diffusion models, interpretability, concept erasure", "abstract": "Diffusion models have shown remarkable abilities in generating realistic and high-quality images from text prompts. However, a trained model remains black-box; little do we know about the role of its components in exhibiting a concept such as object or style. \n    Recent works employ causal tracing to localize layers storing knowledge in generative models. \n    In this work, we approach from a more general perspective and pose a question: \\textit{``How do model components work jointly to demonstrate knowledge?''}. \n    We adapt component attribution to decompose diffusion models, unveiling how a component contributes to a concept.\n    Our framework allows effective model editing, in particular, we can erase a concept from diffusion models by removing positive components while remaining knowledge of other concepts. \n    Surprisingly, we also show that there exist components that contribute negatively to a concept that has not been discovered in the knowledge localization approach.\n    Experimental results confirm the role of positive and negative components pinpointed by our framework, depicting a complete view of interpreting generative models.", "title_embedding_index": 765, "title_abs_embedding_index": 790}, {"title": "Efficient Automated Circuit Discovery in Transformers using Contextual Decomposition", "link_suffix": "/forum?id=41HlN8XYM5", "link": "https://openreview.net/forum?id=41HlN8XYM5", "pdf_link": "https://openreview.net/pdf?id=41HlN8XYM5", "keywords": "Automated Circuit Discovery, Explainable AI, Interpretation, Machine Learning, Language Models, Transformers", "abstract": "Automated mechanistic interpretation research has attracted great interest due to its potential to scale explanations of neural network internals to large models. Existing automated circuit discovery work relies on activation patching or its approximations to identify subgraphs in models for specific tasks (circuits). They often suffer from slow runtime, approximation errors, and specific requirements of metrics, such as non-zero gradients.\nIn this work, we introduce contextual decomposition for transformers (CD-T) to build interpretable circuits in large language models. CD-T can produce circuits of arbitrary level of abstraction, and is the first able to produce circuits as fine-grained as attention heads at specific sequence positions efficiently.\nCD-T is compatible to all transformer types, and requires no training or manually-crafted examples.\nCD-T consists of a set of mathematical equations to isolate contribution of model features. Through recursively computing contribution of all nodes in a computational graph of a model using CD-T followed by pruning, we are able to reduce circuit discovery runtime from hours to seconds compared to state-of-the-art baselines.\nOn three standard circuit evaluation datasets (indirect object identification, greater-than comparisons, and docstring completion),\nwe demonstrate that CD-T outperforms ACDC and EAP by better recovering the manual circuits with an average of 97% ROC AUC under low runtimes.\nIn addition, we provide evidence that faithfulness of CD-T circuits is not due to random chance by showing our circuits are 80% more faithful than random circuits of up to 60% of the original model size. \nFinally, we show CD-T circuits are able to perfectly replicate original models' behavior(faithfulness  = 1) using fewer nodes than the baselines for all tasks.\nOur results underscore the great promise of CD-T for efficient automated mechanistic interpretability, paving the way for new insights into the workings of large language models.", "title_embedding_index": 766, "title_abs_embedding_index": 791}, {"title": "Towards an Understanding of Graph Sequence Models", "link_suffix": "/forum?id=iaHghgG8NR", "link": "https://openreview.net/forum?id=iaHghgG8NR", "pdf_link": "https://openreview.net/pdf?id=iaHghgG8NR", "keywords": "Graph Learning, Sequence Models, Graph Transformers, Hierarchical Clustering", "abstract": "Modern sequence models (e.g., Transformers, RNNs, gated convolutions, etc.) emerged as dominant backbones of recent deep learning frameworks, mainly due to their efficiency, representational power, and/or ability to capture long-range dependencies. Adopting these sequence models for graph-structured data has recently gained popularity as the alternative to Message Passing Neural Networks (MPNNs). There is, however, a lack of a common foundation about what constitutes a good graph sequence model, and a mathematical description of the benefits and deficiencies of adopting different sequence models for learning on graphs. To this end, we first present Graph Sequence Model (GSM), a unifying framework for adopting sequence models for graphs, consisting of three main steps: (1) Tokenization, which translates the graph into a set of sequences; (2) Local Encoding, which encodes local neighborhoods around each node; and (3) Global Encoding, which employs an scalable sequence model to capture long-range dependencies within the sequences. This framework allows us to understand, evaluate, and compare the power of different sequence model backbones in graph tasks. Our theoretical evaluations of the representation power of Transformers and modern recurrent models through the lens of global and local graph tasks show that there are both negative and positive sides for both types of models. Building on this observation, we present GSM++, a fast hybrid model that uses the Hierarchical Affinity Clustering (HAC) algorithm to tokenize the graph into hierarchical sequences, and then employs a hybrid architecture of Transformer to encode these sequences. Our theoretical and experimental results support the design of GSM++, showing that GSM++ outperforms baselines in most benchmark evaluations.", "title_embedding_index": 767, "title_abs_embedding_index": 792}, {"title": "LLF-Bench: A Benchmark for Interactive Learning from Language Feedback", "link_suffix": "/forum?id=H0UcwHgwEO", "link": "https://openreview.net/forum?id=H0UcwHgwEO", "pdf_link": "https://openreview.net/pdf?id=H0UcwHgwEO", "keywords": "LLM, benchmark, decision making, reinforcement learning", "abstract": "We introduce a new benchmark, LLF-Bench (Learning from Language Feedback Benchmark; pronounced as ``elf-bench''), to evaluate the ability of AI agents to interactively learn from natural language feedback and instructions. Learning from language feedback (LLF) is essential for people, largely because the rich information this feedback provides can help a learner avoid much of trial and error and thereby speed up the learning process. Large Language Models (LLMs) have recently enabled AI agents to comprehend natural language --- and hence AI agents can potentially benefit from language feedback during learning like humans do. But existing interactive benchmarks do not assess this crucial capability: they either use numeric reward feedback or require no learning at all (only planning or information retrieval). LLF-Bench is designed to fill this omission. LLF-Bench is a diverse collection of sequential decision-making tasks that includes user recommendation, poem writing, navigation, and robot control. The objective of an agent is to interactively solve these tasks based on their natural-language instructions and the feedback received after taking actions. Crucially, to ensure that the agent actually learns from the feedback, LLF-Bench implements several randomization techniques to ensure that the task isn't familiar to the agent and that the agent is robust to various verbalizations. In addition, LLF-Bench allows configuring different types of feedback to study how agents respond to them. Together, these features make LLF-Bench a unique research platform for developing and testing LLF agents.", "title_embedding_index": 768, "title_abs_embedding_index": 793}, {"title": "How to Evaluate Reward Models for RLHF", "link_suffix": "/forum?id=cbttLtO94Q", "link": "https://openreview.net/forum?id=cbttLtO94Q", "pdf_link": "https://openreview.net/pdf?id=cbttLtO94Q", "keywords": "RLHF, RL, Reward Model, LLM, Benchmark, Dataset, Evaluation", "abstract": "Reward models are critical to the LLM fine-tuning pipeline, serving as the proxy reference signal during Reinforcement Learning from Human Feedback (RLHF). As a result, the RLHF-ed model\u2019s success strongly depends on the reward model's ability to reproduce human preferences with high fidelity. However, this exact dependence is unknown, making it difficult to know which reward model is best. Undergoing a full RLHF training pipeline to directly probe downstream LLM performance, while the gold standard, is completely impractical given the resource-intensive nature of RLHF. To address this, we study downstream RLHF outcomes to create a predictive reward model evaluation. We ground our evaluations with our large-scale human preference and verifiable correctness preference datasets, compiling 12 metrics across 12 domains. To investigate which reward model metrics are most correlated to RLHF outcomes, we launch a full end-to-end RLHF experiment on a large-scale crowdsourced human preference platform to view real reward model downstream performance as ground truth. Ultimately, we compile our data and findings into Preference Proxy Evaluations (PPE), the first reward model benchmark explicitly linked to post-RLHF real-world human preference performance which we will open-source for public use and further development.", "title_embedding_index": 769, "title_abs_embedding_index": 794}, {"title": "On the Surprising Efficacy of Online Self-Improvement for Embodied Multimodal Foundation Models", "link_suffix": "/forum?id=I0To0G5J7g", "link": "https://openreview.net/forum?id=I0To0G5J7g", "pdf_link": "https://openreview.net/pdf?id=I0To0G5J7g", "keywords": "Robotics, Multimodal Foundation Models, Post-Training, Self-Improvement, Reinforcement Learning", "abstract": "Foundation models trained on web-scale data have revolutionized robotics, but their application to low-level control remains largely limited to behavioral cloning. Drawing inspiration from the sample efficiency and success of reinforcement learning (RL) fine-tuning in large language models (LLMs), we propose a two-stage approach suited to robotics. The first stage, Supervised Fine-Tuning (SFT), fine-tunes pre-trained foundation models using goal-conditioned behavioral cloning and \u201csteps-to-go\u201d prediction objectives. In the second stage, this foundation enables the extraction of a well-shaped reward function and a success detector, eliminating the need for manual reward engineering and real-world instrumentation, and allowing robots to practice autonomously with minimal human supervision. Our experiments on both real-world and simulated robots demonstrate that the combination of SFT and online Self-Improvement is significantly more sample-efficient than supervised learning alone. Furthermore, the combination of our proposed approach with web-scale pre-trained foundation models enables rapid acquisition of new skills, allowing robots to generalize far beyond the behaviors observed in the imitation learning datasets used during training. These findings highlight the transformative potential of combining pre-trained foundation models with online fine-tuning to unlock new levels of autonomy and skill acquisition in robotics.", "title_embedding_index": 770, "title_abs_embedding_index": 795}, {"title": "An Efficient Framework for Crediting Data Contributors of Diffusion Models", "link_suffix": "/forum?id=9EqQC2ct4H", "link": "https://openreview.net/forum?id=9EqQC2ct4H", "pdf_link": "https://openreview.net/pdf?id=9EqQC2ct4H", "keywords": "data attribution, diffusion models, Shapley values", "abstract": "As diffusion models are deployed in real-world settings and their performance driven by training data, appraising the contribution of data contributors is crucial to creating incentives for sharing quality data and to implementing policies for data compensation. Depending on the use case, model performance corresponds to various global properties of the distribution learned by a diffusion model (e.g., overall aesthetic quality). Hence, here we address the problem of attributing global properties of diffusion models to data contributors. The Shapley value provides a principled approach to valuation by uniquely satisfying game-theoretic axioms of fairness. However, estimating Shapley values for diffusion models is computationally impractical because it requires retraining and rerunning inference on many subsets of data contributors. We introduce a method to efficiently retrain and rerun inference for Shapley value estimation, by leveraging model pruning and fine-tuning. We evaluate the utility of our method with three use cases: (i) image quality for a DDPM trained on a CIFAR dataset, (ii) demographic diversity for an LDM trained on CelebA-HQ, and (iii) aesthetic quality for a Stable Diffusion model LoRA-finetuned on Post-Impressionist artworks. Our results empirically demonstrate that our framework can identify important data contributors across global properties, outperforming existing attribution methods for diffusion models.", "title_embedding_index": 771, "title_abs_embedding_index": 796}, {"title": "Weakly-supervised & Uncertainty-aware 3D Gaze Estimation with Geometry-guided Constraints", "link_suffix": "/forum?id=fQoYYtPJFX", "link": "https://openreview.net/forum?id=fQoYYtPJFX", "pdf_link": "https://openreview.net/pdf?id=fQoYYtPJFX", "keywords": "3D geometry; gaze representation learning, 3D gaze estimation", "abstract": "3D eye gaze estimation from monocular images remains to be a challenging task due to the model sensitivity to illumination, occlusion and head pose changes. As the growing interests and demand in in-the-wild 3D gaze estimation under unconstrained environments, the generalization ability has been considered as a crucial performance metric of 3D gaze estimation models.  In this work, we present UGaze-Geo, an uncertainty-aware weakly-supervised framework for 3D gaze estimation. We leverage the general knowledge of human eyeball anatomy and develop multiple geometric constraints. The proposed geometrical constraints contains two types, where the first type is formulated by constructing the mapping function from anatomical 3D eyeball parameters to eye appearance features (eyelid & iris landmarks). The second type of constraints is based on the relationship among head rotation, eyeball rotation and gaze, where we learn a variable that describes \"relative eyeball rotation\" conditioned on current head pose. Both type of constraints are free of gaze labels and are general to any subjects and environmental conditions. We formulate these constraints as loss functions in a probabilistic framework.\nWe evaluate the UGaze-Geo framework on within-domain and four cross-domain gaze estimation tasks to validate the effectiveness of each constraint and the advantage of performing probabilistic gaze estimation. Experimental results indicate that our model achieves SOTA performances on different dataset.", "title_embedding_index": 772, "title_abs_embedding_index": 797}, {"title": "Decentralized Finite-Sum Optimization over Time-Varying Networks", "link_suffix": "/forum?id=C5w86qtcgY", "link": "https://openreview.net/forum?id=C5w86qtcgY", "pdf_link": "https://openreview.net/pdf?id=C5w86qtcgY", "keywords": "convex optimization, decentralized optimization", "abstract": "We consider decentralized time-varying stochastic optimization problems where each of the functions held by the nodes has a finite sum structure. Such problems can be efficiently solved using variance reduction techniques. Our aim is to explore the lower complexity bounds (for communication and number of stochastic oracle calls) and find optimal algorithms. The paper studies strongly convex and nonconvex scenarios. To the best of our knowledge, variance reduced schemes and lower bounds for time-varying graphs have not been studied in the literature. For nonconvex objectives, we obtain lower bounds and develop an optimal method GT-PAGE. For strongly convex objectives, we propose the first decentralized time-varying variance-reduction method ADOM+VR and establish lower bound in this scenario, highlighting the open question of matching the algorithms complexity and lower bounds even in static network case.", "title_embedding_index": 773, "title_abs_embedding_index": 798}, {"title": "Decentralized Optimization with Coupled Constraints", "link_suffix": "/forum?id=AJM52ygi6Y", "link": "https://openreview.net/forum?id=AJM52ygi6Y", "pdf_link": "https://openreview.net/pdf?id=AJM52ygi6Y", "keywords": "decentralized optimization, convex optimization, affine constraints", "abstract": "We consider the decentralized minimization of a separable objective $\\sum_{i=1}^{n} f_i(x_i)$, where the variables are coupled through an affine constraint $\\sum_{i=1}^n\\left(\\mathbf{A}_i x_i - b_i\\right) = 0$.\nWe assume that the functions $f_i$, matrices $\\mathbf{A}_i$, and vectors $b_i$ are stored locally by the nodes of a computational network, and that the functions $f_i$ are smooth and strongly convex.This problem has significant applications in resource allocation and systems control and can also arise in distributed machine learning.\nWe propose lower complexity bounds for decentralized optimization problems with coupled constraints and a first-order algorithm achieving the lower bounds. To the best of our knowledge, our method is also the first linearly convergent first-order decentralized algorithm for problems with general affine coupled constraints.", "title_embedding_index": 774, "title_abs_embedding_index": 799}]
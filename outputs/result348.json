[
    {
        "title": "Text-Guided Visual Prompt Tuning for Vision-Language Models",
        "link_suffix": "/forum?id=7TSrtK4PFU",
        "link": "https://openreview.net/forum?id=7TSrtK4PFU",
        "pdf_link": "https://openreview.net/pdf?id=7TSrtK4PFU",
        "keywords": "Vision Language Model, Prompt Tuning, Zero-shot Learning, Few-shot Learning",
        "abstract": "Prompt tuning has become a crucial technique for adapting pre-trained vision-language models (VLMs) to various downstream tasks. Recent advancements introduce multi-modal learnable prompts to enhance the creation of task-specific classifiers. Despite their utility, these methods commonly encounter challenges in generalizing to unseen classes, as their symmetrically designed visual prompt struggles to capture task-relevant textual knowledge and lacks the flexibility in adjusting to novel test class distributions. To tackle these obstacles, we propose a novel Text-Guided Visual Prompt Tuning (TGVP) method, which uniquely leverages the robust generalizability of textual knowledge to guide the generation of visual prompt. Our method introduces a simple yet effective Text-Knowledge Guidance Module that dynamically incorporates visual prompt with task-relevant textual knowledge through cross-attention mechanism. The generated text-guided visual prompt endows the visual encoder with semantic awareness and thus enhances both generalization and discriminability of VLMs across various scenarios. Comprehensive experiments demonstrate that TGVP significantly outperforms existing methods in base-to-novel generalization, cross-dataset transfer, and domain generalization tasks, offering a substantial improvement in VLM adaptation."
    },
    {
        "title": "Anomalies are Streaming: Continual Learning for Weakly Supervised Video Anomaly Detection",
        "link_suffix": "/forum?id=Y7jJN0VQ4y",
        "link": "https://openreview.net/forum?id=Y7jJN0VQ4y",
        "pdf_link": "https://openreview.net/pdf?id=Y7jJN0VQ4y",
        "keywords": "Weakly supervised video anomaly detection, continual learning",
        "abstract": "Weakly supervised video anomaly detection (WSVAD) aims to locate frame-level anomalies with only video-level annotations provided. However, existing WSVAD methods struggle to adapt to real-world scenarios, where unseen anomalies are continuously introduced, thereby making the training of WSVAD essentially a process of continual learning. In this paper, we pioneer to explore the continual learning for weakly supervised video anomaly detection (CL-WSVAD), seeking to mitigate the catastrophic forgetting when the detection model learns new anomalies. We propose normality representation pre-training prior to continual learning, utilizing potential anomaly texts to guide the model in learning robust normality representations, which improves discrimination from potential incremental anomalies. Additionally, we introduce a mixed-up cross-modal alignment method to assist in adapting the pretrained model on CL-WSVAD. Subsequently, we propose a continual learning framework based on sequentially retaining the learnable text prompts for each type of anomaly, which effectively mitigates catastrophic forgetting. Experiments on our established CL-WSVAD benchmarks demonstrate the superiority of proposed method."
    },
    {
        "title": "Diffusion Models are Evolutionary Algorithms",
        "link_suffix": "/forum?id=xVefsBbG2O",
        "link": "https://openreview.net/forum?id=xVefsBbG2O",
        "pdf_link": "https://openreview.net/pdf?id=xVefsBbG2O",
        "keywords": "Machine learning, evolutionary computation, Evolutionary Algorithms, Diffusion Models, Optimization",
        "abstract": "In a convergence of machine learning and biology, we reveal that diffusion models are evolutionary algorithms. By considering evolution as a denoising process and reversed evolution as diffusion, we mathematically demonstrate that diffusion models inherently perform evolutionary algorithms, naturally encompassing selection, mutation, and reproductive isolation. Building on this equivalence, we propose the Diffusion Evolution method: an evolutionary algorithm utilizing iterative denoising -- as originally introduced in the context of diffusion models -- to heuristically refine solutions in parameter spaces. Unlike traditional approaches, Diffusion Evolution efficiently identifies multiple optimal solutions and outperforms prominent mainstream evolutionary algorithms. Furthermore, leveraging advanced concepts from diffusion models, namely latent space diffusion and accelerated sampling, we introduce Latent Space Diffusion Evolution, which finds solutions for evolutionary tasks in high-dimensional complex parameter space while significantly reducing computational steps. This parallel between diffusion and evolution not only bridges two different fields but also opens new avenues for mutual enhancement, raising questions about open-ended evolution and potentially utilizing non-Gaussian or discrete diffusion models in the context of Diffusion Evolution."
    },
    {
        "title": "Topograph: An Efficient Graph-Based Framework for Strictly Topology Preserving Image Segmentation",
        "link_suffix": "/forum?id=Q0zmmNNePz",
        "link": "https://openreview.net/forum?id=Q0zmmNNePz",
        "pdf_link": "https://openreview.net/pdf?id=Q0zmmNNePz",
        "keywords": "Image Segmentation, Topology, Graph",
        "abstract": "Topological correctness plays a critical role in many image segmentation tasks, yet most networks are trained using pixel-wise loss functions, such as Dice, neglecting topological accuracy. Existing topology-aware methods often lack robust topological guarantees, are limited to specific use cases, or impose high computational costs. \nIn this work, we propose a novel, graph-based framework for topologically accurate image segmentation that is both computationally efficient and generally applicable. Our method constructs a component graph that fully encodes the topological information of both the prediction and ground truth, allowing us to efficiently identify topologically critical regions and aggregate a loss based on local neighborhood information. Furthermore, we introduce a strict topological metric capturing the homotopy equivalence between the union and intersection of prediction-label pairs. We formally prove the topological guarantees of our approach and empirically validate its effectiveness on binary and multi-class datasets, demonstrating state-of-the-art performance with up to fivefold faster loss computation compared to persistent homology methods."
    },
    {
        "title": "Diving into Self-Evolve Training for Multimodal Reasoning",
        "link_suffix": "/forum?id=p8UoIVAcU3",
        "link": "https://openreview.net/forum?id=p8UoIVAcU3",
        "pdf_link": "https://openreview.net/pdf?id=p8UoIVAcU3",
        "keywords": "Large Multimodal Models, Large Language Models, Reinforcement Learning, Multimodal Reasoning, Self-Evolve",
        "abstract": "Reasoning ability is essential for Large Multimodal Models (LMMs). \nIn the absence of multimodal chain-of-thought annotated data, self-evolving training, where the model learns from its own outputs, has emerged as an effective and scalable approach for enhancing reasoning abilities. \nDespite its growing usage, a comprehensive understanding of self-evolving training, particularly in the context of multimodal reasoning, remains limited. In this paper, we delve into the intricacies of self-evolving training for multimodal reasoning, pinpointing three key factors: $\\textbf{Training Method}$, $\\textbf{Reward Model}$, and $\\textbf{Prompt Variation}$. We systematically examine each factor and explore how various configurations affect the training's effectiveness. Our analysis leads to a set of best practices for each factor, aimed at optimizing multimodal reasoning.\nFurthermore, we explore the $\\textbf{Self-Evolution Dynamics}$ during training and the impact of automatic balancing mechanisms in boosting performance. After all the investigations, we present a final recipe for self-evolving training in multimodal reasoning, encapsulating these design choices into a framework we call M-STAR ($\\textbf{M}$ultimodal $\\textbf{S}$elf-evolving $\\textbf{T}$r$\\textbf{a}$ining for $\\textbf{R}$easoning), built on MiniCPM-V 2.5. \nM-STAR achieves 59.5% accuracy on MathVista, surpassing the pre-evolved model by 6.9% absolutely without using additional human annotations. \nWe believe this study fills a significant gap in the understanding of self-evolving training for multimodal reasoning and offers a robust framework for future research. Our policy and reward models, as well as the collected data, will be released to facilitate further investigation in multimodal reasoning."
    },
    {
        "title": "Expanding Expressivity in Transformer Models with M\u00f6biusAttention",
        "link_suffix": "/forum?id=N5qFgohx9u",
        "link": "https://openreview.net/forum?id=N5qFgohx9u",
        "pdf_link": "https://openreview.net/pdf?id=N5qFgohx9u",
        "keywords": "Transformer, Attention, BERT, M\u00f6bius Transformation, NLP, RoPe",
        "abstract": "Attention mechanisms and Transformer architectures have revolutionized Natural Language Processing (NLP) by enabling exceptional modeling of long-range dependencies and capturing intricate linguistic patterns. However, their inherent reliance on linear operations in the form of matrix multiplications limits their ability to fully capture inter-token relationships on their own. We propose M\u00f6biusAttention, a novel approach that integrates M\u00f6bius transformations within the attention mechanism of Transformer-based models. M\u00f6bius transformations are non-linear operations in spaces over complex numbers with the ability to map between various geometries. By incorporating these properties, M\u00f6biusAttention empowers models to learn more intricate geometric relationships between tokens and capture a wider range of information through complex-valued weight vectors. We build and pre-train a BERT and a RoFormer version enhanced with M\u00f6biusAttention, which we then finetune on the GLUE benchmark. We evaluate empirically our approach against the baseline BERT and RoFormer models on a range of downstream tasks. Our approach compares favorably against the baseline models, even with smaller number of parameters suggesting the enhanced expressivity of M\u00f6biusAttention. This research paves the way for exploring the potential of M\u00f6bius transformations in the complex projective space to enhance the expressivity and performance of foundation models."
    },
    {
        "title": "Beyond Interpretability: The Gains of Feature Monosemanticity on Model Robustness",
        "link_suffix": "/forum?id=g6Qc3p7JH5",
        "link": "https://openreview.net/forum?id=g6Qc3p7JH5",
        "pdf_link": "https://openreview.net/pdf?id=g6Qc3p7JH5",
        "keywords": "Representation Learning, Robustness, Polysemanticity, Superposition",
        "abstract": "Deep learning models often suffer from a lack of interpretability due to polysemanticity, where individual neurons are activated by multiple unrelated semantics, resulting in unclear attributions of model behavior. Recent advances in monosemanticity, where neurons correspond to consistent and distinct semantics, have significantly improved interpretability but are commonly believed to compromise accuracy. In this work, we challenge the prevailing belief of the accuracy-interpretability tradeoff, showing that monosemantic features not only enhance interpretability but also bring concrete gains in model performance. Across multiple robust learning scenarios\u2014including input and label noise, few-shot learning, and out-of-domain generalization\u2014our results show that models leveraging monosemantic features significantly outperform those relying on polysemantic features. Furthermore, we provide empirical and theoretical understandings on the robustness gains of feature monosemanticity. Our preliminary analysis suggests that monosemanticity, by promoting better separation of feature representations, leads to more robust decision boundaries. This diverse evidence highlights the generality of monosemanticity in improving model robustness. As a first step in this new direction, we embark on exploring the learning benefits of monosemanticity beyond interpretability, supporting the long-standing hypothesis of linking interpretability and robustness."
    },
    {
        "title": "Exploring a Principled Framework for Deep Subspace Clustering",
        "link_suffix": "/forum?id=7psWohxvxp",
        "link": "https://openreview.net/forum?id=7psWohxvxp",
        "pdf_link": "https://openreview.net/pdf?id=7psWohxvxp",
        "keywords": "deep subspace clustering, self-expressive model, representation learning",
        "abstract": "Subspace clustering is a classical unsupervised learning task, built on a basic assumption that high-dimensional data can be approximated by a union of subspaces (UoS). Nevertheless, the real-world data are often deviating from the UoS assumption. To address this challenge, state-of-the-art deep subspace clustering algorithms attempt to jointly learn UoS representations and self-expressive coefficients. However, the general framework of the existing algorithms suffers from feature collapse and lacks a theoretical guarantee to learn desired UoS representation. In this paper, we present a Principled fRamewOrk for Deep Subspace Clustering (PRO-DSC), which is designed to learn structured representations and self-expressive coefficients in a unified manner. Specifically, in PRO-DSC, we incorporate an effective regularization on the learned representations into the self-expressive model, and prove that the regularized self-expressive model is able to prevent feature space collapse and the learned optimal representations under certain condition lie on a union of orthogonal subspaces. Moreover, we provide a scalable and efficient approach to implement our PRO-DSC and conduct extensive experiments to verify our theoretical findings and demonstrate the superior performance of our proposed deep subspace clustering approach."
    },
    {
        "title": "HELM: Hierarchical Encoding for mRNA Language Modeling",
        "link_suffix": "/forum?id=MMHqnUOnl0",
        "link": "https://openreview.net/forum?id=MMHqnUOnl0",
        "pdf_link": "https://openreview.net/pdf?id=MMHqnUOnl0",
        "keywords": "Messenger RNA (mRNA), Codon structure, Hierarchical modeling, Bio-language model, Property prediction, mRNA sequence generation",
        "abstract": "Messenger RNA (mRNA) plays a crucial role in protein synthesis, with its codon structure directly impacting biological properties. While Language Models (LMs) have shown promise in analyzing biological sequences, existing approaches fail to account for the hierarchical nature of mRNA's codon structure. We introduce Hierarchical Encoding for mRNA Language Modeling (HELM), a novel pre-training strategy that incorporates codon-level hierarchical structure into language model training. HELM modulates the loss function based on codon synonymity, aligning the model's learning process with the biological reality of mRNA sequences. We evaluate HELM on diverse mRNA datasets and tasks, demonstrating that HELM outperforms standard language model pre-training as well as existing foundation model baselines on six diverse downstream property prediction tasks and an antibody region annotation tasks on average by around 8%. Additionally, HELM enhances the generative capabilities of language model, producing diverse mRNA sequences that better align with the underlying true data distribution compared to  non-hierarchical baselines."
    },
    {
        "title": "Stochastic variance-reduced Gaussian variational inference on the Bures-Wasserstein manifold",
        "link_suffix": "/forum?id=iMJpmcYucq",
        "link": "https://openreview.net/forum?id=iMJpmcYucq",
        "pdf_link": "https://openreview.net/pdf?id=iMJpmcYucq",
        "keywords": "Variational inference, Bures-Wasserstein space, Riemannian manifold, optimization",
        "abstract": "Optimization in the Bures-Wasserstein space has been gaining popularity in the machine learning community since it draws connections between variational inference and Wasserstein gradient flows. The variational inference objective function of Kullback\u2013Leibler divergence can be written as the sum of the negative entropy and the potential energy, making forward-backward Euler the method of choice. Notably, the backward step admits a closed-form solution in this case, facilitating the practicality of the scheme. However, the forward step is no longer exact since the Bures-Wasserstein gradient of the potential energy involves \"intractable\" expectations. Recent approaches propose using the Monte Carlo method -- in practice a single-sample estimator -- to approximate these terms, resulting in high variance and poor performance. We propose a novel variance-reduced estimator based on the principle of control variates. We theoretically show that this estimator has a smaller variance than the Monte-Carlo estimator in scenarios of interest. We also prove that variance reduction helps improve the optimization bounds of the current analysis. We demonstrate that the proposed estimator gains order-of-magnitude improvements over the previous Bures-Wasserstein methods."
    },
    {
        "title": "Lower-level Duality Based Penalty Methods for Hyperparameter Optimization",
        "link_suffix": "/forum?id=vIHmkF5rnC",
        "link": "https://openreview.net/forum?id=vIHmkF5rnC",
        "pdf_link": "https://openreview.net/pdf?id=vIHmkF5rnC",
        "keywords": "Bilevel Optimization, Hyperparameter Optimization, Nonsmooth Optimization",
        "abstract": "Hyperparameter optimization (HO) is essential in machine learning and can be structured as a bilevel optimization. However, many existing algorithms designed for addressing nonsmooth lower-level problems involve solving sequential subproblems with high complexity. To tackle this challenge, we introduce penalty methods for solving HO based on strong duality between the lower level problem and its dual. We illustrate that the penalized problem closely approximates the optimal solutions of the original HO under certain conditions. In many real applications, the penalized problem is a weakly-convex objective with proximal-friendly constraints. Furthermore, we develop two fully first-order algorithms to solve the penalized problems. Theoretically, we prove the convergence of the proposed algorithms. We demonstrate the efficiency and superiority of our method across numerical experiments."
    },
    {
        "title": "SelKD: Selective Knowledge Distillation via Optimal Transport Perspective",
        "link_suffix": "/forum?id=H4iVLvRusn",
        "link": "https://openreview.net/forum?id=H4iVLvRusn",
        "pdf_link": "https://openreview.net/pdf?id=H4iVLvRusn",
        "keywords": "Knowledge Distillation, Inverse Optimal Transport",
        "abstract": "Knowledge Distillation (KD) has been a popular paradigm for training a (smaller) student model from its teacher model. However, little research has been done on the practical scenario where only a subset of the teacher's knowledge needs to be distilled, which we term selective KD (SelKD). This demand is especially pronounced in the era of foundation models, where the teacher model can be significantly larger than the student model. To address this issue, we propose to rethink the knowledge distillation problem from the perspective of Inverse Optimal Transport (IOT). Previous Bayesian frameworks mapped each sample to the probabilities of corresponding labels in an end-to-end manner, which fixed the number of classification categories and hindered effective local knowledge transfer. In contrast, IOT calculates from the standpoint of transportation or matching, allowing for the flexible selection of samples and their quantities for matching. Traditional logit-based KD can be viewed as a special case within the IOT framework. Building on this IOT foundation, we formalize this setting in the context of classification, where only selected categories from the teacher's category space are required to be recognized by the student in the context of closed-set recognition, which we call closed-set SelKD, enhancing the student's performance on specific subtasks. Furthermore, we extend the closed-set SelKD, introducing an open-set version of SelKD, where the student model is required to provide a ``not selected\" response for categories outside its assigned task. Experimental results on standard benchmarks demonstrate the superiority of our approach."
    },
    {
        "title": "On Disentangled Training for Nonlinear Transform in Learned Image Compression",
        "link_suffix": "/forum?id=U67J0QNtzo",
        "link": "https://openreview.net/forum?id=U67J0QNtzo",
        "pdf_link": "https://openreview.net/pdf?id=U67J0QNtzo",
        "keywords": "learned image compression\uff0c training efficiency\uff0c auxiliary transform",
        "abstract": "Learned image compression (LIC) has demonstrated superior rate-distortion (R-D) performance compared to traditional codecs, but is challenged by training inefficiency that could incur more than two weeks to train a state-of-the-art model from scratch. Existing LIC methods overlook the slow convergence caused by compacting energy in learning nonlinear transforms. In this paper, we first reveal that such energy compaction consists of two components, \\emph{i.e.}, feature decorrelation and uneven energy modulation. On such basis, we propose a linear auxiliary transform (AuxT) to disentangle energy compaction in training nonlinear transforms. The proposed AuxT obtains coarse approximation to achieve efficient energy compaction such that distribution fitting with the nonlinear transforms can be simplified to fine details. We then develop wavelet-based linear shortcuts (WLSs) for AuxT that leverages wavelet-based downsampling and orthogonal linear projection for feature decorrelation and subband-aware scaling for uneven energy modulation. AuxT is lightweight and plug-and-play to be integrated into diverse LIC models to address the slow convergence issue. Experimental results demonstrate that the proposed approach can accelerate training of LIC models by 2 to 3 times and simultaneously achieves an average 1% BD-rate reduction. To our best knowledge, this is the first successful attempt that can significantly improve the convergence of LIC with comparable or superior rate-distortion performance."
    },
    {
        "title": "Low-Rank Interconnected Adaptation across Layers",
        "link_suffix": "/forum?id=hYe0o7mnwM",
        "link": "https://openreview.net/forum?id=hYe0o7mnwM",
        "pdf_link": "https://openreview.net/pdf?id=hYe0o7mnwM",
        "keywords": "parameter-efficient fine-tuning, low-rank adaptation, foundation model",
        "abstract": "Low-rank adaptation (LoRA) is a powerful parameter-efficient fine-tuning method that utilizes low-rank projectors $A$ and $B$ to learn weight updates $\\Delta W$ for adaptation targets $W$. Previous research has shown that LoRA is essentially a gradient compressor, performing random projections on the gradient using a fixed projection matrix $A_0$. However, this setup restricts the overall weight update to be low-rank, which limits the adaptation performance. In this paper, we propose low-rank interconnected adaptation across layers (Lily). Specifically, we employ a hierarchical framework where low-dimensional projectors (LPs) retained for downward projection at a particular level, while globally-shared high-dimensional projector (HP) experts perform upward projection across all levels of layers. Lily uniquely connects each LP to all HP experts, therefore the gradient projections are no longer dominated by fixed projection matrices, but rather by selective combinations of all the projectors, thereby breaking the low-rank constraint of LoRA. Furthermore, Lily's cross-layer connections facilitate the capture of intricate information and dependencies across different layers, thereby enhancing the model's representational capabilities. Experiments across various modalities, architectures, and model sizes underscore Lily's great performance and efficiency."
    },
    {
        "title": "Measuring, Evaluating and Improving Logical Consistency in Large Language Models",
        "link_suffix": "/forum?id=kJgi5ykK3t",
        "link": "https://openreview.net/forum?id=kJgi5ykK3t",
        "pdf_link": "https://openreview.net/pdf?id=kJgi5ykK3t",
        "keywords": "LLM judgement, Logical consistency",
        "abstract": "Recent research in Large Language Models (LLMs) has shown promising progress related to LLM alignment with human preferences. LLM-empowered decision-making systems are expected to be predictable, reliable and trustworthy, which implies being free from paradoxes or contradictions that could undermine their credibility and validity. However, LLMs still exhibit inconsistent and biased behaviour when making decisions or judgements. In this work, we focus on studying logical consistency of LLMs as a prerequisite for more reliable and trustworthy systems. Logical consistency ensures that decisions are based on a stable and coherent understanding of the problem, reducing the risk of erratic or contradictory outputs.\nWe first propose a universal framework to quantify the logical consistency via three fundamental proxies: transitivity, commutativity and negation invariance. We then evaluate logical consistency, using the defined measures, of a wide range of LLMs, demonstrating that it can serve as a strong proxy for overall robustness. Additionally, we introduce a data refinement and augmentation technique that enhances the logical consistency of LLMs without sacrificing alignment to human preferences. It augments noisy and sparse pairwise-comparison annotations by estimating a partially or totally ordered preference rankings using rank aggregation methods. Finally, we show that logical consistency impacts the performance of LLM-based logic-dependent algorithms, where LLMs serve as logical operators."
    },
    {
        "title": "Leveraging Anthropometric Measurements to Improve Human Mesh Estimation and Ensure Consistent Body Shapes",
        "link_suffix": "/forum?id=qYniSDqk8a",
        "link": "https://openreview.net/forum?id=qYniSDqk8a",
        "pdf_link": "https://openreview.net/pdf?id=qYniSDqk8a",
        "keywords": "Computer Vision, Human Pose Estimation, 3D Human Pose Estimation, Human Mesh Estimation, Human Mesh Recovery, Anthropometric Measurements",
        "abstract": "The basic body shape of a person does not change within a single video. However, most SOTA human mesh estimation (HME) models output a slightly different body shape for each video frame, which results in inconsistent body shapes for the same person. In contrast, we leverage anthropometric measurements like tailors are already obtaining from humans for centuries. We create a model called A2B that converts such anthropometric measurements to body shape parameters of human mesh models. Moreover, we find that finetuned SOTA 3D human pose estimation (HPE) models outperform HME models regarding the precision of the estimated keypoints. We show that applying inverse kinematics (IK) to the results of such a 3D HPE model and combining the resulting body pose with the A2B body shape leads to superior and consistent human meshes for challenging datasets like ASPset or fit3D, where we can lower the MPJPE by over 30 mm compared to SOTA HME models. Further, replacing HME models estimates of the body shape parameters with A2B model results not only increases the performance of these HME models, but also leads to consistent body shapes."
    },
    {
        "title": "DeepLTL: Learning to Efficiently Satisfy Complex LTL Instructions",
        "link_suffix": "/forum?id=9pW2J49flQ",
        "link": "https://openreview.net/forum?id=9pW2J49flQ",
        "pdf_link": "https://openreview.net/pdf?id=9pW2J49flQ",
        "keywords": "reinforcement learning, linear temporal logic, ltl, generalization",
        "abstract": "Linear temporal logic (LTL) has recently been adopted as a powerful formalism for specifying complex, temporally extended tasks in reinforcement learning (RL). However, learning policies that efficiently satisfy arbitrary specifications not observed during training remains a challenging problem. Existing approaches suffer from several shortcomings: they are often only applicable to the finite-horizon fragment of LTL, are restricted to suboptimal solutions, and do not adequately handle safety constraints. In this work, we propose a novel learning approach to address these concerns. Our method leverages the structure of B\u00fcchi automata, which explicitly represent the semantics of LTL specifications, to learn policies conditioned on sequences of truth assignments that lead to satisfying the desired formulae. Experiments in a variety of discrete and continuous domains demonstrate that our approach is able to zero-shot satisfy a wide range of finite- and infinite-horizon specifications, and outperforms existing methods in terms of both satisfaction probability and efficiency."
    },
    {
        "title": "MeshMask: Physics-Based Simulations with Masked Graph Neural Networks",
        "link_suffix": "/forum?id=bFHR8hNk4I",
        "link": "https://openreview.net/forum?id=bFHR8hNk4I",
        "pdf_link": "https://openreview.net/pdf?id=bFHR8hNk4I",
        "keywords": "graph networks, simulation, mesh, physics",
        "abstract": "We introduce a novel masked pre-training technique for graph neural networks (GNNs) applied to computational fluid dynamics (CFD) problems. By randomly masking up to 40% of input mesh nodes during pre-training, we force the model to learn robust representations of complex fluid dynamics. We pair this masking strategy with an asymmetric encoder-decoder architecture and gated multi-layer perceptrons to further enhance performance. The proposed method achieves state-of-the-art results on seven CFD datasets, including a new challenging dataset of 3D intracranial aneurysm simulations with over 250,000 nodes per mesh. Moreover, it significantly improves model performance and training efficiency across such diverse range of fluid simulation tasks. We demonstrate improvements of up to 60% in long-term prediction accuracy compared to previous best models, while maintaining similar computational costs. Notably, our approach enables effective pre-training on multiple datasets simultaneously, significantly reducing the time and data required to achieve high performance on new tasks.\nThrough extensive ablation studies, we provide insights into the optimal masking ratio, architectural choices, and training strategies."
    },
    {
        "title": "Best Possible Q-Learning",
        "link_suffix": "/forum?id=VA1tNAsDiC",
        "link": "https://openreview.net/forum?id=VA1tNAsDiC",
        "pdf_link": "https://openreview.net/pdf?id=VA1tNAsDiC",
        "keywords": "reinforcement learning, multi-agent reinforcement learning",
        "abstract": "Fully decentralized learning, where the global information, \\textit{i.e.}, the actions of other agents, is inaccessible, is a fundamental challenge in cooperative multi-agent reinforcement learning. However, the convergence and optimality of most decentralized algorithms are not theoretically guaranteed, since the transition probabilities are non-stationary as all agents are updating policies simultaneously. To tackle this challenge, we propose \\textit{best possible operator}, a novel decentralized operator, and prove that the policies of cooperative agents will converge to the optimal joint policy if each agent independently updates its individual state-action value by the operator when there is only one optimal joint policy. Further, to make the update more efficient and practical, we simplify the operator and prove that the convergence and optimality still hold with the simplified one. By instantiating the simplified operator, the derived fully decentralized algorithm, \\textit{best possible Q-learning} (BQL), does not suffer from non-stationarity. Empirically, we show that BQL achieves remarkable improvement over baselines in a variety of cooperative multi-agent tasks."
    },
    {
        "title": "EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents",
        "link_suffix": "/forum?id=Ey8KcabBpB",
        "link": "https://openreview.net/forum?id=Ey8KcabBpB",
        "pdf_link": "https://openreview.net/pdf?id=Ey8KcabBpB",
        "keywords": "Embodied Artificial Intelligence, LLM Multi-agent System, Multi-robot System, Task Planning",
        "abstract": "Heterogeneous multi-robot systems (HMRS) have emerged as a powerful ap-\nproach for tackling complex tasks that single robots cannot manage alone. Current\nlarge-language-model-based multi-agent systems (LLM-based MAS) have shown\nsuccess in areas like software development and operating systems, but applying\nthese systems to robot control presents unique challenges. In particular, the ca-\npabilities of each agent in a multi-robot system are inherently tied to the physical\ncomposition of the robots, rather than predefined roles. To address this issue,\nwe introduce a novel multi-agent framework designed to enable effective collab-\noration among heterogeneous robots with varying embodiments and capabilities,\nalong with a new benchmark named Habitat-MAS. One of our key designs is\nRobot Resume: Instead of adopting human-designed role play, we propose a self-\nprompted approach, where agents comprehend robot URDF files and call robot\nkinematics tools to generate descriptions of their physics capabilities to guide\ntheir behavior in task planning and action execution. The Habitat-MAS bench-\nmark is designed to assess how a multi-agent framework handles tasks that require\nembodiment-aware reasoning, which includes 1) manipulation, 2) perception, 3)\nnavigation, and 4) comprehensive multi-floor object rearrangement. The experi-\nmental results indicate that the robot\u2019s resume and the hierarchical design of our\nmulti-agent system are essential for the effective operation of the heterogeneous\nmulti-robot system within this intricate problem context."
    },
    {
        "title": "Watch Less, Do More: Implicit Skill Discovery for Video-Conditioned Policy",
        "link_suffix": "/forum?id=hgvERMkXOx",
        "link": "https://openreview.net/forum?id=hgvERMkXOx",
        "pdf_link": "https://openreview.net/pdf?id=hgvERMkXOx",
        "keywords": "video-conditioned policy, compositional generalization",
        "abstract": "In this paper, we study the problem of video-conditioned policy learning. While previous works mostly focus on learning policies that perform a single skill specified by the given video, we take a step further and aim to learn a policy that can perform multiple skills according to the given video, and generalize to unseen videos by recombining these skills. To solve this problem, we propose our algorithm, Watch-Less-Do-More, an information bottleneck-based imitation learning framework for implicit skill discovery and video-conditioned policy learning. In our method, an information bottleneck objective is employed to control the information contained in the video representation, ensuring that it only encodes information relevant to the current skill (Watch-Less). By discovering potential skills from training videos, the learned policy is able to recombine them and generalize to unseen videos to achieve compositional generalization (Do-More). To evaluate our method, we perform extensive experiments in various environments and show that our algorithm substantially outperforms baselines (up to 2x) in terms of compositional generalization ability."
    },
    {
        "title": "Learning Policy Committees for Effective Personalization in MDPs with Diverse Tasks",
        "link_suffix": "/forum?id=IZB8H50V1S",
        "link": "https://openreview.net/forum?id=IZB8H50V1S",
        "pdf_link": "https://openreview.net/pdf?id=IZB8H50V1S",
        "keywords": "Multi-task reinforcement learning, meta reinforcement learning, personalized reinforcement learning",
        "abstract": "Many dynamic decision problems, such as robotic control, involve a series of tasks, many of which are unknown at training time. Typical approaches for these problems, such as multi-task and meta reinforcement learning, do not generalize well when the tasks are diverse. We propose a general framework to address this issue. In our framework, the goal is to learn a set of policies\u2014a policy committee\u2014such that at least one is near-optimal for most tasks that may be encountered at execution time. While we show that even a special case of this problem is inapproximable, we present two effective algorithmic approaches for it. The first of these yields provably approximation guarantees, albeit in small-dimensional settings (the best we can do due to inapproximability), whereas the second is a general and practical gradient-based approach. In addition, we provide provable sample complexity bounds for few-shot learning settings. Our experiments in personalized and multi-task RL settings using MuJoCo and Meta-World benchmarks show that the proposed approach outperforms state-of-the-art multi-task, meta-, and personalized RL baselines on training and test tasks, as well as in few-shot learning, often by a large margin."
    },
    {
        "title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries",
        "link_suffix": "/forum?id=H25xduunIK",
        "link": "https://openreview.net/forum?id=H25xduunIK",
        "pdf_link": "https://openreview.net/pdf?id=H25xduunIK",
        "keywords": "evaluation, LLMs",
        "abstract": "The rapid development and dynamic nature of large language models (LLMs) make it difficult for conventional quantitative benchmarks to accurately assess their capabilities. We propose report cards, which are human-interpretable, natural language summaries of model behavior for specific skills or topics. We develop a framework to evaluate report cards based on three criteria: specificity (ability to distinguish between models), faithfulness (accurate representation of model capabilities), and interpretability (clarity and relevance to humans). We also propose an iterative algorithm for generating report cards without human supervision and explore its efficacy by ablating various design choices. Through experimentation with popular LLMs, we demonstrate that report cards provide insights beyond traditional benchmarks and can help address the need for a more interpretable and holistic evaluation of LLMs."
    },
    {
        "title": "UniVIEDM: A Diffusion Model to Unify Visual Information Extraction Subtasks",
        "link_suffix": "/forum?id=V6AI97jJ3J",
        "link": "https://openreview.net/forum?id=V6AI97jJ3J",
        "pdf_link": "https://openreview.net/pdf?id=V6AI97jJ3J",
        "keywords": "Visual Information Extraction",
        "abstract": "Visual Information Extraction (VIE) focuses on extracting named entities and their relationships from visually rich document images. Traditionally, VIE systems rely on three separate models to handle three distinct subtasks, but the emerging trend in research is to design a single model that can address all of these tasks simultaneously. However, current methods face quadratic computational complexity when extracting entity relationships, as they must iterate over all token pairs. To address this issue, this paper introduces a Unified VIE Diffusion Model (UniVIEDM) for all tasks within VIE. UniVIEDM generates entity labels and their relationships conditioned on their plane coordinates, greatly reducing the computational complexity. UniVIEDM represents the layout of each visually rich document as a plane graph and converts the three subtasks into plane graph generation problems. During the pre-training stage, UniVIEDM leverages a jump-diffusion process to learn to generate valid sets of bounding boxes for all words and line segments connecting different boxes. During the fine-tuning stage, UniVIEDM employs a continuous-time Markov chain diffusion model to learn to predict the labels of boxes and line segments based on their coordinate features."
    },
    {
        "title": "EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions",
        "link_suffix": "/forum?id=TspmMMOG7X",
        "link": "https://openreview.net/forum?id=TspmMMOG7X",
        "pdf_link": "https://openreview.net/pdf?id=TspmMMOG7X",
        "keywords": "LLM, Multi-Modal, Vision-Language, Speech-Language",
        "abstract": "GPT-4o, an omni-modal model that enables vocal conversations with diverse emotions and tones, marks a milestone for omni-modal foundation models. However, empowering Large Language Models to perceive and generate images, texts, and speeches end-to-end with publicly available data remains challenging in the open-source community. Existing vision-language models rely on external tools for the speech processing, while speech-language models still suffer from limited or even without vision-understanding abilities. To address this gap, we propose EMOVA (EM-otionally Omni-present Voice Assistant), to enable Large Language Models with end-to-end speech capabilities while maintaining the leading vision-language performance. With a semantic-acoustic disentangled speech tokenizer, we notice surprisingly that omni-modal alignment can further enhance vision-language and speech abilities compared with the corresponding bi-modal aligned counterparts. Moreover, a lightweight style module is proposed for flexible speech style controls (e.g., emotions and pitches). For the first time, EMOVA achieves state-of-the-art performance on both the vision-language and speech benchmarks, and meanwhile, supporting omni-modal emotional spoken dialogue."
    }
]
[{"title": "Integrating Geodesic Interpolation and Flow Matching for Non-Autoregressive Text Generation in Logit Space", "link_suffix": "/forum?id=44WiKy8THW", "link": "https://openreview.net/forum?id=44WiKy8THW", "pdf_link": "https://openreview.net/pdf?id=44WiKy8THW", "keywords": "Flow Matching, Non-autoregressive text generation", "abstract": "Non-autoregressive language models are emerging as effective alternatives to autoregressive models in natural language processing, enabling simultaneous token generation. This study presents a novel flow matching approach using Kullback-Leibler (KL) divergence geodesics to interpolate between initial and target distributions for discrete sequences. We establish a loss function that maximizes the conditional likelihood of discrete tokens, demonstrating that its maximizer corresponds to the flow matching velocity under logit interpolation. While initial tests on the TinyStories dataset yielded unsatisfactory results, we introduce an empirical sampling scheme based on a pretrained denoiser, which significantly improves performance.", "title_embedding_index": 3800, "title_abs_embedding_index": 3825}, {"title": "Approaching Deep Learning through the Spectral Dynamics of Weights", "link_suffix": "/forum?id=PJjHILiQHC", "link": "https://openreview.net/forum?id=PJjHILiQHC", "pdf_link": "https://openreview.net/pdf?id=PJjHILiQHC", "keywords": "simplicity bias, grokking, lottery tickets, linear mode connectivity", "abstract": "We propose an empirical approach centered on the spectral dynamics of weights---the behavior of singular values and vectors during optimization---to unify and clarify several phenomena in deep learning. We identify a consistent bias in optimization across various experiments, from small-scale ``grokking'' to large-scale tasks like image classification with ConvNets, image generation with UNets, speech recognition with LSTMs, and language modeling with Transformers. We also demonstrate that weight decay enhances this bias beyond its role as a norm regularizer, even in practical systems. Moreover, we show that these spectral dynamics distinguish memorizing networks from generalizing ones, offering a novel perspective on this longstanding conundrum. Additionally, we leverage spectral dynamics to explore the emergence of well-performing sparse subnetworks (lottery tickets) and the structure of the loss surface through linear mode connectivity. Our findings suggest that spectral dynamics provide a coherent framework to better understand the behavior of neural networks across diverse settings.", "title_embedding_index": 3801, "title_abs_embedding_index": 3826}, {"title": "INDOOR-3.6M : A Multi-Modal Image Dataset for Indoor Geolocation", "link_suffix": "/forum?id=BQfAqi3Xq3", "link": "https://openreview.net/forum?id=BQfAqi3Xq3", "pdf_link": "https://openreview.net/pdf?id=BQfAqi3Xq3", "keywords": "geolocation, multimodal, indoor, deep learning, dataset benchmark, geolocalization", "abstract": "Indoor image geolocation, the task of determining the location of an indoor scene based on visual content, presents unique challenges due to the constrained and repetitive nature of indoor spaces. Current geolocation methods, while advanced in outdoor contexts, struggle to perform accurately in indoor environments due to the lack of diverse and representative indoor datasets. To address this gap, we introduce INDOOR-3.6M, a large-scale dataset of geotagged indoor imagery spanning various residential, commercial, and public spaces from around the world. In addition to the data set, we propose a new sampling methodology to ensure geographic diversity and balance. We also introduce INDOOR-15K, a benchmark for evaluating indoor-specific geolocation models. Finally, we demonstrate the dataset\u2019s utility by introducing IndoorGeoCLIP, a specialized version of the GeoCLIP model fine-tuned using our dataset, which outperforms GeoCLIP on our test set.", "title_embedding_index": 3802, "title_abs_embedding_index": 3827}, {"title": "Self-Attention-Based Contextual Modulation Improves Neural System Identification", "link_suffix": "/forum?id=JeLqFpFzwX", "link": "https://openreview.net/forum?id=JeLqFpFzwX", "pdf_link": "https://openreview.net/pdf?id=JeLqFpFzwX", "keywords": "self-attention, incremental learning, neural prediction, contextual modulation", "abstract": "Convolutional neural networks (CNNs) have been shown to be state-of-the-art models for visual cortical neurons. Cortical neurons in the primary visual cortex are sensitive to contextual information mediated by extensive horizontal and feedback connections. Standard CNNs integrate global contextual information to model contextual modulation via two mechanisms: successive convolutions and a fully connected readout layer. In this paper, we find that self-attention (SA), an implementation of non-local network mechanisms, can improve neural response predictions over parameter-matched CNNs in two key metrics: tuning curve correlation and peak tuning. We introduce peak tuning as a metric to evaluate a model's ability to capture a neuron's feature preference. We factorize networks to assess each context mechanism, revealing that information in the local receptive field is most important for modeling overall tuning, but surround information is critically necessary for characterizing the tuning peak. We find that self-attention can replace posterior spatial-integration convolutions when learned incrementally, and is further enhanced in the presence of a fully connected readout layer, suggesting that the two context mechanisms are complementary. Finally, we find that decomposing receptive field learning and contextual modulation learning in an incremental manner may be an effective and robust mechanism for learning surround-center interactions.", "title_embedding_index": 3803, "title_abs_embedding_index": 3828}, {"title": "How do diffusion models learn and generalize on abstract rules for reasoning?", "link_suffix": "/forum?id=DLBlR0rea5", "link": "https://openreview.net/forum?id=DLBlR0rea5", "pdf_link": "https://openreview.net/pdf?id=DLBlR0rea5", "keywords": "Generative model, Reasoning, Raven\u2019s Progressive Matrix, Diffusion, Scaling law, Stochastic interpolant", "abstract": "Diffusion models excel in generating and completing patterns in images. \nBut how good is their ability to learn hidden rules from samples and to generate and reason according to such rules or even generalize to similar rules? \nWe trained a wide family of unconditional diffusion models on Raven's progression matrix task to precisely study this. We quantified their capability to generate structurally consistent samples and complete missing parts according to hidden rules. \nWe found diffusion models can synthesize novel samples consistent with rules without memorizing the training set, much better than GPT2 trained on the same data. They memorized and recombined local parts of the training samples to create new rule-conforming samples. \nWhen tasked to complete the missing panel with inpainting techniques, advanced sampling techniques were needed to perform well. Further, their pattern completion capability can generalize to rules unseen during training. \nFurther, through generative training on rule data, a robust rule representation rapidly emerged in the diffusion model, which could linearly classify rules at 99.8% test accuracy. \nOur results suggest diffusion training is a useful paradigm for reasoning and learning representations for downstream tasks even for abstract rules data.", "title_embedding_index": 3804, "title_abs_embedding_index": 3829}, {"title": "STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making", "link_suffix": "/forum?id=jwGPmIqE99", "link": "https://openreview.net/forum?id=jwGPmIqE99", "pdf_link": "https://openreview.net/pdf?id=jwGPmIqE99", "keywords": "LLM Agent, Strategic Decision Making, Markov Decision Making Process", "abstract": "Large Language Models (LLMs) have revolutionized natural language processing, showing remarkable linguistic proficiency and reasoning capabilities. However, their application in strategic multi-agent decision-making environments is hampered by significant limitations including poor mathematical reasoning, difficulty in following instructions, and a tendency to generate incorrect information. These deficiencies hinder their performance in strategic and interactive tasks that demand adherence to nuanced game rules, long-term planning, exploration in unknown environments, and anticipation of opponents' moves. To overcome these obstacles, this paper presents a novel LLM agent framework equipped with memory and specialized tools to enhance their strategic decision-making capabilities. We deploy the tools in a number of economically important environments, in particular bilateral bargaining and multi-agent and dynamic mechanism design. We employ quantitative metrics to assess the framework's performance in various strategic decision-making problems. Our findings establish that our enhanced framework significantly improves the strategic decision-making capability of LLMs. While we highlight the inherent limitations of current LLM models, we demonstrate the improvements through targeted enhancements, suggesting a promising direction for future developments in LLM applications for interactive environments.", "title_embedding_index": 3805, "title_abs_embedding_index": 3830}, {"title": "Algorithm for Concept Extrapolation: Diverse Generalization via Selective Disagreement", "link_suffix": "/forum?id=lcF4BkhPBv", "link": "https://openreview.net/forum?id=lcF4BkhPBv", "pdf_link": "https://openreview.net/pdf?id=lcF4BkhPBv", "keywords": "domain adaptation, spurious correlations, simplicity bias, diverse ensembles", "abstract": "Standard deep learning approaches often struggle to handle out-of-distribution data, especially when the distributional shift breaks spurious correlations. While some approaches to handling spurious correlations under distributional shift aim to separate causal and spurious features without access to target distribution data, they rely on labeled data from different domains or contingent assumptions about the nature of neural representations. Existing methods that do make use of unlabeled target data make strict assumptions about the target data distribution. To overcome these limitations, we present the Algorithm for Concept Extrapolation (ACE). Using an exponentially-weighted disagreement loss to maximize disagreement on target instances \\textit{that break spurious correlations}, ACE achieves state of the art performance on spurious complete correlation benchmarks. We also show ACE is robust to unlabeled target distributions where spurious and ground truth features are not statistically independent. Finally, we demonstrate the applicability of ACE for handling goal-misgeneralization in deep reinforcement learning, with our ``ACE agent'' achieving a 16% higher level completion rate in the CoinRun goal misgeneralisation problem when the coin is randomly placed in the level.", "title_embedding_index": 3806, "title_abs_embedding_index": 3831}, {"title": "Epistemic Integrity in Large Language Models", "link_suffix": "/forum?id=KSPBh07jEO", "link": "https://openreview.net/forum?id=KSPBh07jEO", "pdf_link": "https://openreview.net/pdf?id=KSPBh07jEO", "keywords": "uncertainty, assertiveness, persuasion, calibration, misinformation", "abstract": "Large language models are increasingly relied upon as sources of information, but their propensity for generating false or misleading statements with high confidence poses risks for users and society. In this paper, we confront the critical problem of epistemic miscalibration\u2014where a model's linguistic assertiveness fails to reflect its true internal certainty. We introduce a new human-labeled dataset and a novel method for measuring the linguistic assertiveness of Large Language Models which cuts error rates by over 50% relative to previous benchmarks. Validated across multiple datasets, our method reveals a stark misalignment between how confidently models linguistically present information and their actual accuracy. Further human evaluations confirm the severity of this miscalibration. This evidence underscores the urgent risk of the overstated certainty Large Language Models hold which may mislead users on a massive scale. Our framework provides a crucial step forward in diagnosing and correcting this miscalibration, offering a path to safer and more trustworthy AI across domains.", "title_embedding_index": 3807, "title_abs_embedding_index": 3832}, {"title": "Benchmark for Temporal, Ambiguous, and Grounded Embodied Question-Answering", "link_suffix": "/forum?id=toqQYz2N2X", "link": "https://openreview.net/forum?id=toqQYz2N2X", "pdf_link": "https://openreview.net/pdf?id=toqQYz2N2X", "keywords": "embodied question answering, episodic memory question answering, ambiguity", "abstract": "The problem of question ambiguity, while highlighted as an open issue, is often overlooked in the literature on Embodied Question Answering (EQA) and Episodic Memory Question Answering (EM-EQA). This paper proposes a structured approach to handle ambiguity in the egocentric data. Our benchmark, called TAG-EQA, utilizes spatial and temporal grounding to distinguish between objects, positions, and events and ensures that obtained structured answers preserve information fully while effectively resolving ambiguity. We introduce a new dataset, specifically designed for ambiguous grounded Episodic Memory QA. The dataset incorporates situated spatial reasoning, temporal conditions, and diverse visual features. Our new evaluation procedure tackles grounded natural language answers. It reveals that some of the most modern approaches still struggle with efficient information extraction and processing in ambiguous scenarios. We hope that TAG-EQA will serve as both a valuable tool for generating complex EM-EQA data and that the proposed evaluation benchmark will propel progress in agentic AI and embodied reasoning.", "title_embedding_index": 3808, "title_abs_embedding_index": 3833}, {"title": "Improved Sample Complexity for Private Nonsmooth Nonconvex Optimization", "link_suffix": "/forum?id=0RHMnPj8no", "link": "https://openreview.net/forum?id=0RHMnPj8no", "pdf_link": "https://openreview.net/pdf?id=0RHMnPj8no", "keywords": "Differential privacy, nonconvex optimization, nonsmooth optimization, Goldstein stationarity", "abstract": "We study differentially private (DP) optimization algorithms for stochastic and empirical\nobjectives which are neither smooth nor convex, and propose methods that return a Goldstein-stationary point with sample complexity bounds that improve on existing works.\nWe start by providing a single-pass $(\\epsilon,\\delta)$-DP algorithm that\nreturns an $(\\alpha,\\beta)$-stationary point as long as the dataset is of size $\\widetilde{\\Omega}\\left(1/\\alpha\\beta^{3}+d/\\epsilon\\alpha\\beta^{2}+d^{3/4}/\\epsilon^{1/2}\\alpha\\beta^{5/2}\\right)$,\nwhich is $\\Omega(\\sqrt{d})$ times smaller than the algorithm of \\citet{zhang2023private} for this task,\nwhere $d$ is the dimension.\nWe then provide a multi-pass polynomial time algorithm which further improves the sample complexity to $\\widetilde{\\Omega}\\left(d/\\beta^2+d^{3/4}/\\epsilon\\alpha^{1/2}\\beta^{3/2}\\right)$,\nby designing a sample efficient ERM algorithm,\nand proving that Goldstein-stationary points generalize from the empirical loss to the population loss.", "title_embedding_index": 3809, "title_abs_embedding_index": 3834}, {"title": "Sharp Generalization for Nonparametric Regression by Over-Parameterized Neural Networks: A Distribution-Free Analysis", "link_suffix": "/forum?id=WH9NhxOeu9", "link": "https://openreview.net/forum?id=WH9NhxOeu9", "pdf_link": "https://openreview.net/pdf?id=WH9NhxOeu9", "keywords": "Nonparametric Regression, Over-Parameterized Neural Networks, Minimax Optimal Rates", "abstract": "Sharp generalization bound for neural networks trained by gradient descent (GD) is of central interest in statistical learning theory and deep learning. In this paper, we consider nonparametric regression\nby an over-parameterized two-layer NN trained by GD. We show that, if the neural network is trained by GD with early stopping, then the trained network renders a sharp rate of the nonparametric regression risk of $\\cO(\\eps_n^2)$, which is the same rate as that for kernel regression trained by GD with early stopping, where $\\eps_n$ is the critical population rate of the Neural Tangent Kernel (NTK) associated with the network and $n$ is the size of the training data. It is remarked that our result does not require distributional assumptions on the training data, in a strong contrast with many existing results which rely on specific distributions such as the spherical uniform data distribution or distributions satisfying certain restrictive conditions.\nAs a special case of our general result, when the eigenvalues of the associated NTK\ndecay at a rate of $\\lambda_j \\asymp j^{-\\frac{d}{d-1}}$ for $j \\ge 1$ which happens if the training data is distributed uniformly on the unit sphere in $\\RR^d$, we immediately obtain the minimax optimal rate of\n$\\cO(n^{-\\frac{d}{2d-1}})$, which is the major results of several existing works in this direction. The neural network width in our general result is lower bounded by a function of only $n,d,\\eps_n$, and such width does not depend on the minimum eigenvalue of the empirical NTK matrix whose lower bound usually requires additional assumptions on the training data.\nOur results are built upon two significant technical results which are of independent interest. First, uniform convergence to the NTK is established during the training process by GD, so that we can have a nice decomposition of the neural network function at any step of the GD into a function in the Reproducing\nKernel Hilbert Space associated with the NTK and an error function with a small $L^{\\infty}$-norm. Second, local Rademacher complexity is employed\nto tightly bound the Rademacher complexity of the function class comprising all the possible neural network functions obtained by GD.", "title_embedding_index": 3810, "title_abs_embedding_index": 3835}, {"title": "Computing Optimal Regularizers for Online Linear Optimization", "link_suffix": "/forum?id=Md783Qa2JX", "link": "https://openreview.net/forum?id=Md783Qa2JX", "pdf_link": "https://openreview.net/pdf?id=Md783Qa2JX", "keywords": "mirror descent, online convex optimization, online linear optimization, minimax optimal rate, adversarial online learning", "abstract": "Follow-the-Regularized-Leader (FTRL) algorithms are a popular class of learning algorithms for online linear optimization (OLO) that guarantee sub-linear regret, but the choice of regularizer can significantly impact dimension-dependent factors in the regret bound. We present an algorithm that takes as input convex and symmetric action sets and loss sets for a specific OLO instance, and outputs a regularizer such that running FTRL with this regularizer guarantees regret within a universal constant factor of the best possible regret bound. In particular, for any choice of (convex, symmetric) action set and loss set we prove that there exists an instantiation of FTRL which achieves regret within a constant factor of the best possible learning algorithm, strengthening the universality result of Srebro et al., 2011.Our algorithm requires preprocessing time and space exponential in the dimension $d$ of the OLO instance, but can be run efficiently online assuming a membership and linear optimization oracle for the action and loss sets, respectively (and is fully polynomial time for the case of constant dimension $d$). We complement this with a lower bound showing that even deciding whether a given regularizer is $\\alpha$-strongly-convex with respect to a given norm is NP-hard.", "title_embedding_index": 3811, "title_abs_embedding_index": 3836}, {"title": "Dataset Distillation via Knowledge Distillation: Towards Efficient Self-Supervised Pre-training of Deep Networks", "link_suffix": "/forum?id=c61unr33XA", "link": "https://openreview.net/forum?id=c61unr33XA", "pdf_link": "https://openreview.net/pdf?id=c61unr33XA", "keywords": "dataset distillation, self-supervised learning", "abstract": "Dataset distillation (DD) generates small synthetic datasets that can efficiently train deep networks with a limited amount of memory and compute. Despite the success of DD methods for supervised learning, DD for self-supervised pre-training of deep models has remained unaddressed. Pre-training on unlabeled data is crucial for efficiently generalizing to downstream tasks with limited labeled data. In this work, we propose the first effective DD method for SSL pre-training. First, we show, theoretically and empirically, that naiive application of supervised DD methods to SSL fails, due to the high variance of the SSL gradient. Then, we address this issue by relying on insights from knowledge distillation (KD) literature. Specifically, we train a small student model to match the representations of a larger teacher model trained with SSL. Then, we generate a small synthetic dataset by matching the training trajectories of the student models. As the KD objective has considerably lower variance than SSL, our approach can generate synthetic datasets that can successfully pre-train high-quality encoders. Through extensive experiments, we show that our distilled sets lead to up to 13% higher accuracy than prior work, on a variety of downstream tasks, in the presence of limited labeled data.", "title_embedding_index": 3812, "title_abs_embedding_index": 3837}, {"title": "AutoHijacker: Automatic Indirect Prompt Injection Against Black-box LLM Agents", "link_suffix": "/forum?id=2VmB01D9Ef", "link": "https://openreview.net/forum?id=2VmB01D9Ef", "pdf_link": "https://openreview.net/pdf?id=2VmB01D9Ef", "keywords": "Large Language Model, Prompt Injection Attack, LLM Agent", "abstract": "Although large Language Models (LLMs) and LLM agents have been widely adopted, they are vulnerable to indirect prompt injection attacks, where malicious external data is injected to manipulate model behaviors. Existing evaluations of LLM robustness against such attacks are limited by handcrafted methods and reliance on white-box or gray-box access\u2014conditions unrealistic in practical deployments. To bridge this gap, we propose AutoHijacker, an automatic indirect black-box prompt injection attack. Built on the concept of LLM-as-optimizers, AutoHijacker introduces a batch-based optimization framework to handle sparse feedback and also leverages a trainable memory to enable effective generation of indirect prompt injections without continuous querying. Evaluations on two public benchmarks, AgentDojo and Open-Prompt-Injection, show that AutoHijacker outperforms 11 baseline attacks and achieves state-of-the-art performance without requiring external knowledge like user instructions or model configurations, and also demonstrates higher average attack success rates against 8 various defenses. Additionally, AutoHijacker successfully attacks a commercial LLM agent platform, achieving a 71.9% attack success rate in both document interaction and website browsing tasks.", "title_embedding_index": 3813, "title_abs_embedding_index": 3838}, {"title": "A Clustering Baseline for Object-Centric Representations", "link_suffix": "/forum?id=Z56fPyx7GL", "link": "https://openreview.net/forum?id=Z56fPyx7GL", "pdf_link": "https://openreview.net/pdf?id=Z56fPyx7GL", "keywords": "object-centric representations, self-supervised learning", "abstract": "Object-centric learning aims to discover and represent visual entities as a small set of vectors and masks, which can be later used for downstream tasks.\nRecent methods for object-centric learning build upon vision foundation models trained with self supervision because of the rich semantic features they produce.\nHowever, these methods often require additional training, offer limited flexibility, and are optimized for a specific granularity of objects, e.g. to maximize segmentation metrics on a test dataset.In this work, we demonstrate how to discover objects and parts with a simple clustering algorithm applied to the features of an off-the-shelf backbone.\nK-means, as the clustering method of choice, is fast and flexible, produces interpretable masks, preserves the quality of the backbone embeddings, does not require additional training, and can be applied multiple times to capture different part/whole structures, e.g. a laptop and its keyboard.\nThe resulting representation is a small set of object tokens that compactly summarizes the image contents.We evaluate the quality of such a representation on a variety of downstream tasks including scene classification and action recognition in videos, showing that it surpasses the performance of fine-tuned object-centric learning methods.\nFurthermore, we evaluate the corresponding object masks for unsupervised segmentation on annotated datasets.\nThough not as pixel-perfect as specialized methods, we show that they effectively capture real-world objects and parts at various granularity.", "title_embedding_index": 3814, "title_abs_embedding_index": 3839}, {"title": "Robotouille: An Asynchronous Planning Benchmark for LLM Agents", "link_suffix": "/forum?id=OhUoTMxFIH", "link": "https://openreview.net/forum?id=OhUoTMxFIH", "pdf_link": "https://openreview.net/pdf?id=OhUoTMxFIH", "keywords": "benchmark, llm, agents, planning", "abstract": "Effective asynchronous planning, or the ability to efficiently reason and plan over states and actions that must happen in parallel or sequentially, is essential for agents that must account for time delays, reason over diverse long-horizon tasks, and collaborate with other agents. While large language model (LLM) agents show promise in high-level task planning, current benchmarks focus primarily on short-horizon tasks and do not evaluate such asynchronous planning capabilities. We introduce Robotouille, a challenging benchmark environment designed to test LLM agents' ability to handle asynchronous, long-horizon, and multi-agent scenarios. These datasets capture increasingly complex planning challenges that go beyond existing benchmarks, particularly in their requirement for agents to manage overlapping tasks, interruptions, and collaboration. Our results show that ReAct (gpt-4o) achieves 47% on synchronous tasks but only 11% on asynchronous tasks, highlighting significant room for improvement. We further analyze failure modes, demonstrating the need for LLM agents to better incorporate long-horizon feedback and self-audit their reasoning during task execution.", "title_embedding_index": 3815, "title_abs_embedding_index": 3840}, {"title": "Dynamic Skill Adaptation for Large Language Models", "link_suffix": "/forum?id=whXHZIaRVB", "link": "https://openreview.net/forum?id=whXHZIaRVB", "pdf_link": "https://openreview.net/pdf?id=whXHZIaRVB", "keywords": "Large Language Models, Skill Adaptation, Skill Graph", "abstract": "We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework to adapt novel and complex skills to Large Language Models (LLMs). Compared with previous work which learns from human-curated and static data in random orders, we propose to first automatically generate and organize the training data by mimicking the learning pathways of human and then dynamically tailor the training data based on the training dynamics. Specifically, inspired by the learning structures and teaching strategies in the human education system, we first construct a skill graph by decomposing complex skills into sub-skills and arranging them based on their dependencies in human syllables. For every skill, we utilize LLMs to generate both textbook-like data which contains detailed descriptions of skills for pre-training and exercise-like data which targets at explicitly utilizing the skills to solve problems for instruction-tuning. Furthermore, during the instruction-tuning, we dynamically update the training data which down-weight easy-to-learn examples, generate more complex examples, and filter out data with errors.  Experiments on large language models such as LLAMA and Mistral demonstrate the effectiveness of our proposed methods in adapting math reasoning skills and social study skills.", "title_embedding_index": 3816, "title_abs_embedding_index": 3841}, {"title": "IO-LVM: Inverse optimization latent variable models with applications to inferring and explaining paths", "link_suffix": "/forum?id=prTI7MSt2X", "link": "https://openreview.net/forum?id=prTI7MSt2X", "pdf_link": "https://openreview.net/pdf?id=prTI7MSt2X", "keywords": "deep learning, path planning, latent space", "abstract": "Learning representations from solutions of constrained optimization problems (COPs) with unknown cost functions is challenging, as models like (Variational) Autoencoders struggle to capture constraints to decode structured outputs. We propose an inverse optimization latent variable model (IO-LVM) that constructs a latent space of COP costs based on observed decisions, enabling the inference of feasible and meaningful solutions by reconstructing them with a COP solver. To achieve this, we leverage estimated gradients of a Fenchel-Young loss through a non-differentiable deterministic solver while shaping the embedding space. In contrast to established Inverse Optimization or Inverse Reinforcement Learning methods, which typically identify a single or context-conditioned cost function, we exploit the learned representation to capture underlying COP cost structures and identify solutions likely originating from different agents, each using distinct or slightly different cost functions when making decisions. Using both synthetic and actual ship routing data, we validate our approach through experiments on path planning problems using the Dijkstra algorithm, demonstrating the interpretability of the latent space and its effectiveness in path inference and path distribution reconstruction.", "title_embedding_index": 3817, "title_abs_embedding_index": 3842}, {"title": "Towards Learning to Reason at Pre-Training Scale", "link_suffix": "/forum?id=BGnm7Lo8oW", "link": "https://openreview.net/forum?id=BGnm7Lo8oW", "pdf_link": "https://openreview.net/pdf?id=BGnm7Lo8oW", "keywords": "large language models, self-improvement, reasoning", "abstract": "Prompting a Large Language Model (LLM) to output Chain-of-Thought (CoT) reasoning improves performance on complex problem-solving tasks. Further, several popular approaches exist to ``self-improve\" the abilities of LLMs to use CoT on tasks where supervised (question, answer) datasets are available. However, an emerging line of work explores whether self-improvement is possible without supervised datasets, instead utilizing the same large, general-purpose text corpora as used during pre-training. These pre-training datasets encompass large parts of human knowledge and dwarf all finetuning datasets in size. Self-improving CoT abilities on such general datasets could enhance reasoning for any general-purpose text generation task, and doing so at pre-training scale may unlock unprecedented reasoning abilities. In this paper, we outline the path towards self-improving CoT reasoning at pre-training scale and address fundamental challenges in this direction. We start by framing this as a reinforcement learning problem: given the first $n$ tokens from a large pre-training corpus, the model generates a CoT and receives a reward based on how well the CoT helps predict the following $m$ tokens. We then investigate a fundamental question: What constitutes a suitable reward function for learning to reason during general language modelling?\nWe outline the desirable qualities of such a reward function and empirically demonstrate how different functions affect what reasoning is learnt and where reasoning is rewarded. Using these insights, we introduce a novel reward function called Reasoning Advantage (RA) that facilitates self-improving CoT reasoning on free-form question-answering (QA) data, where answers are unstructured and difficult to verify. Equipped with a suitable reward function, we explore the optimization of it on general-purpose text using offline RL. Our analysis indicates that future work should investigate more powerful optimisation algorithms, potentially moving towards more online algorithms that better explore the space of CoT generations.", "title_embedding_index": 3818, "title_abs_embedding_index": 3843}, {"title": "Stable GNN Embeddings for Relational Data", "link_suffix": "/forum?id=Zltr2XVjDq", "link": "https://openreview.net/forum?id=Zltr2XVjDq", "pdf_link": "https://openreview.net/pdf?id=Zltr2XVjDq", "keywords": "GNN, stability, database embeddings", "abstract": "Graph neural networks (GNNs) are a valuable tool for extracting meaningful representations from graph-structured data. Graphs, like relational databases, represent relationships between entities. Recent research has explored the potential of using GNNs for downstream tasks on relational data, such as entity resolution and missing value imputation. However, applying GNNs to relational databases presents two challenges. The first challenge is data conversion: relational databases, organized as tables connected by key / foreign key constraints,\nmust be transformed into graphs without losing essential information. The second challenge is ensuring that the embedding technique can adapt to the dynamic nature of databases. When a database is updated, the embeddings of the resulting database should be recomputable efficiently. This requires that previously computed embeddings remain stable despite changes to the data.Motivated by using GNNs for relational databases, we study stability, i.e., how much the embeddings generated by a GNN change when the input graph undergoes modifications. Building upon the work of Gama et al. (2020), which established a limit for the distance between embeddings of similar graphs, we focus on node-level stability for GNN embeddings, particularly when the graphs originate from relations. We propose several techniques for transforming relational databases into graphs. To assess the effectiveness of these methods, we conduct experiments using the TPC-E database benchmark and analyze their stability.", "title_embedding_index": 3819, "title_abs_embedding_index": 3844}, {"title": "The Sky Is The Limit When Clustering Is Equated With Disentanglement", "link_suffix": "/forum?id=OUo50cxU21", "link": "https://openreview.net/forum?id=OUo50cxU21", "pdf_link": "https://openreview.net/pdf?id=OUo50cxU21", "keywords": "Disentangled Representation Learning, Clustering, Factors of Variation, Variational Autoencoders (VAEs), Generative Models, Synthetic Image Data", "abstract": "Disentangled representation learning allows data to be mapped to a latent space where factors of variation can be individually manipulated. These factors define a direct notion of similarity between observations that naturally groups them into clusters with shared factors of variation. While this has been empirically shown to be effective on simple datasets, it is unclear how or when complex real-world data can be disentangled into representations that allow the same degree of manipulation and clustering. To advance the field of disentangled representation learning and clustering, we provide a new theoretical perspective by equating disentanglement with clustering by using factors of variation as a measure of element-wise similarity. This leads to a simple yet important observation: Instead of explicitly clustering the elements of a dataset, we can implicitly cluster them by learning to represent and generate the elements of each cluster. Furthermore, this observation reveals that implicit clusters have a lower bound because (I) explicit clusters are a subset of implicit clusters, and (II) implicit clusters can generate novel elements not present in the finite dataset through combinatorial generalization. Building on these insights, we derive an implicit neural clustering approach based on identifying factors of variation in the latent space. We validate our findings through experiments on synthetic image data and empirical evidence from related state-of-the-art works. This demonstrates the practical relevance of our approach and promising potential for synthesizing complete datasets from limited data, addressing data distribution gaps, improving interpretability in cluster analysis, enhancing SSL and classification tasks, and reducing data storage space.", "title_embedding_index": 3820, "title_abs_embedding_index": 3845}, {"title": "Mask R-CNN for Automated Multi-Species Malaria Parasite Detection", "link_suffix": "/forum?id=gbJNFxcicC", "link": "https://openreview.net/forum?id=gbJNFxcicC", "pdf_link": "https://openreview.net/pdf?id=gbJNFxcicC", "keywords": "Mask R-CNN, malaria parasite detection, Plasmodium species, deep learning, instance segmentation, microscopic image analysis", "abstract": "This study investigates the automatic detection and segmentation of malaria parasites across various Plasmodium species using Mask R-CNN, an advanced deep-learning architecture. Expanding on earlier studies in digital malaria diagnosis, we apply pixel-level segmentation to overcome the drawbacks of previous approaches. 971 microscopic pictures of four Plasmodium species\u2014P. falciparum, P. malariae, P. ovale, and P. vivax\u2014taken from Rwanda's healthcare facilities make up our dataset. This dataset was used to train the Mask R-CNN model, which produced excellent mean average precision (mAP) scores for all species, with P. vivax and P. malariae showing the most excellent performance with mAP 0.9575 and mAP 0.9459, respectively. Compared to earlier techniques, this method shows notable advances in parasite localization and delineation, suggesting the possibility of more precise and effective malaria diagnosis in clinical settings.", "title_embedding_index": 3821, "title_abs_embedding_index": 3846}, {"title": "Progressive Compression with Universally Quantized Diffusion Models", "link_suffix": "/forum?id=CxXGvKRDnL", "link": "https://openreview.net/forum?id=CxXGvKRDnL", "pdf_link": "https://openreview.net/pdf?id=CxXGvKRDnL", "keywords": "diffusion, generative modeling, compression, universal quantization", "abstract": "Diffusion probabilistic models have achieved mainstream success in many generative modeling tasks, from image generation to inverse problem solving. A distinct feature of these models is that they correspond to deep hierarchical latent variable models optimizing a variational evidence lower bound (ELBO) on the data likelihood.\nDrawing on a basic connection between likelihood modeling and compression, we explore the potential of diffusion models for progressive coding, resulting in a sequence of bits that can be incrementally transmitted and decoded with progressively improving reconstruction quality.\nUnlike prior work based on Gaussian diffusion or conditional diffusion models, we propose a new form of diffusion model with uniform noise in the forward process, whose negative ELBO corresponds to the end-to-end compression cost using universal quantization.\nWe obtain promising first results on image compression, achieving competitive rate-distortion-realism results on a wide range of bit-rates with a single model, bringing neural codecs a step closer to practical deployment.", "title_embedding_index": 3822, "title_abs_embedding_index": 3847}, {"title": "Neural Architecture Search by Learning a Hierarchical Search Space", "link_suffix": "/forum?id=CvrXy1jVLh", "link": "https://openreview.net/forum?id=CvrXy1jVLh", "pdf_link": "https://openreview.net/pdf?id=CvrXy1jVLh", "keywords": "Neural Architecture Search, Monte-Carlo Tree Search, Hierarchical Search Space, Hierarchical Clustering", "abstract": "Monte Carlo Tree Search (MCTS) is a powerful tool for many non-differentiable search related problems such as adversarial games. However, the performance of such approach highly depends on the order of the nodes that are considered at each branching of the tree. If the first branches are not discriminative enough, i.e. they cannot distinguish between promising and deceiving configurations for the final task, the efficiency of the search is exponentially reduced. While in some cases the order of the branching is given as part of the problem (e.g. in chess the sequential order of the moves is defined by the game), in others, such as Neural Architecture Search (NAS), the visiting order of the tree is not important, and only the final architecture matters. In this paper, we study and analyze several sampling methods and branching alternatives for MCTS and propose to learn the branching by hierarchical clustering of architectures based on their similarity. The similarity is measured by the pairwise distance of output vectors of architectures. Experimental results on two challenging benchmarks on CIFAR10 and ImageNet show that MCTS, if provided with a good branching hierarchy, can yield promising solutions more efficiently than other approaches for NAS problems.", "title_embedding_index": 3823, "title_abs_embedding_index": 3848}, {"title": "Learn-by-interact: A Data-Centric Framework For Self-Adaptive Agents in Realistic Environments", "link_suffix": "/forum?id=3UKOzGWCVY", "link": "https://openreview.net/forum?id=3UKOzGWCVY", "pdf_link": "https://openreview.net/pdf?id=3UKOzGWCVY", "keywords": "Data synthesis, Agent, Adaptation", "abstract": "Autonomous agents powered by large language models (LLMs) have the potential to enhance human capabilities, assisting with digital tasks from sending emails to performing data analysis.   The abilities of existing LLMs at such tasks are often hindered by the lack of high-quality agent data from the corresponding environments they interact with.  We propose LEARN-BY-INTERACT, a data-centric framework to adapt LLM agents to any given environments without human annotations.   LEARN-BY-INTERACT synthesizes trajectories of agent-environment interactions based on documentations, and constructs instructions by summarizing or abstracting the interaction histories, a process called backward construction. We assess the quality of our synthetic data by using them in both training-based scenarios and training-free in-context learning (ICL), where we craft innovative retrieval approaches optimized for agents. Extensive experiments on SWE-bench, WebArena, OSWorld, and Spider2-V spanning across realistic coding, web, and desktop environments show the effectiveness of LEARN-BY-INTERACT in various downstream agentic tasks \u2014 baseline results are improved up to 11.1% for ICL with Claude-3.5 and 23.1% for training with Codestral-22B. We further demonstrate the critical role of backward construction, which provides up to 10.6% improvement for training.  Our ablation studies demonstrate the efficiency provided by our synthesized data in ICL and the superiority of our retrieval pipeline over alternative approaches like conventional retrieval-augmented generation (RAG). We expect that LEARN-BY-INTERACT will serve as a foundation for agent data synthesis as LLMs are increasingly deployed at real-world environments.", "title_embedding_index": 3824, "title_abs_embedding_index": 3849}]
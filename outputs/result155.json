[{"title": "Exploring Local Memorization in Diffusion Models via Bright Ending Attention", "link_suffix": "/forum?id=p4cLtzk4oe", "link": "https://openreview.net/forum?id=p4cLtzk4oe", "pdf_link": "https://openreview.net/pdf?id=p4cLtzk4oe", "keywords": "Diffusion Models, Local Memorization, Bright Ending Attention", "abstract": "In this paper, we identify and leverage a novel `bright ending' (BE) anomaly in diffusion models prone to memorizing training images to address a new task: locating localized memorization regions within these models. BE refers to a distinct cross-attention pattern observed in text-to-image generations using diffusion models. Specifically, memorized image patches exhibit significantly greater attention to the end token during the final inference step compared to non-memorized patches. This attention map effectively highlights regions where the generated image replicates training data. Furthermore, driven by our observation that local memorization significantly underperforms in existing tasks of measuring, detecting, and mitigating memorization in diffusion models compared to global memorization, we propose a simple yet effective method to integrate BE and the results of the new localization task into these existing frameworks. This integration effectively improves their performances by narrowing the performance gap caused by local memorization. Our results not only demonstrate the successful execution of the new localization task but also establish new state-of-the-art performance across all existing tasks, underscoring the significance of the BE phenomenon.", "title_embedding_index": 7700, "title_abs_embedding_index": 7725}, {"title": "A Theory of Multi-Agent Generative Flow Networks", "link_suffix": "/forum?id=4oQHCmnM8R", "link": "https://openreview.net/forum?id=4oQHCmnM8R", "pdf_link": "https://openreview.net/pdf?id=4oQHCmnM8R", "keywords": "Generative Model", "abstract": "Generative flow networks utilize a flow-matching loss to learn a stochastic policy for generating objects from a sequence of actions, such that the probability of generating a pattern can be proportional to the corresponding given reward. However, a theoretical framework for multi-agent generative flow networks (MA-GFlowNets) has not yet been proposed. In this paper, we propose the theory framework of MA-GFlowNets, which can be applied to multiple agents to generate objects collaboratively through a series of joint actions. We further propose four algorithms: a centralized flow network for centralized training of MA-GFlowNets, an independent flow network for decentralized execution, a joint flow network for achieving centralized training with decentralized execution, and its updated conditional version. Joint Flow training is based on a local-global principle allowing to train a collection of (local) GFN as a unique (global) GFN. This principle provides a loss of reasonable complexity and allows to leverage usual results on GFN to provide theoretical guarantees that the independent policies generate samples with probability proportional to the reward function. Experimental results demonstrate the superiority of the proposed framework compared to reinforcement learning and MCMC-based methods.", "title_embedding_index": 7701, "title_abs_embedding_index": 7726}, {"title": "On the Adversarial Vulnerability of Label-Free Test-Time Adaptation", "link_suffix": "/forum?id=N0ETIi580T", "link": "https://openreview.net/forum?id=N0ETIi580T", "pdf_link": "https://openreview.net/pdf?id=N0ETIi580T", "keywords": "Test Time Adaptation, Adversarial Attack", "abstract": "Despite the success of Test-time adaptation (TTA), recent work has shown that adding relatively small adversarial perturbations to a limited number of samples leads to significant performance degradation. Therefore, it is crucial to rigorously evaluate existing TTA algorithms against relevant threats and implement appropriate security countermeasures. Importantly, existing threat models assume test-time samples will be labeled, which is impractical in real-world scenarios. To address this gap, we propose a new attack algorithm that does not rely on\naccess to labeled test samples, thus providing a concrete way to assess the security vulnerabilities of TTA algorithms. Our attack design is grounded in theoretical foundations and can generate strong attacks against different state of the art TTA methods. In addition, we show that existing defense mechanisms are almost ineffective, which emphasizes the need for further research on TTA security. Through extensive experiments on CIFAR10-C, CIFAR100-C, and ImageNet-C, we demonstrate that our proposed approach closely matches the performance of state-of-the-art attack benchmarks, even without access to labeled samples. In certain cases, our approach generates stronger attacks, e.g., more than 4% higher error rate on CIFAR10-C.", "title_embedding_index": 7702, "title_abs_embedding_index": 7727}, {"title": "Strength Estimation and Human-Like Strength Adjustment in Games", "link_suffix": "/forum?id=CvjXlsBLCX", "link": "https://openreview.net/forum?id=CvjXlsBLCX", "pdf_link": "https://openreview.net/pdf?id=CvjXlsBLCX", "keywords": "Bradley-Terry Model, Strength Estimation, Strength Adjustment, Human-like Playing Style, Monte-Carlo Tree Search, Go, Chess", "abstract": "Strength estimation and adjustment are crucial in designing human-AI interactions, particularly in games where AI surpasses human players.\nThis paper introduces a novel strength system, including a strength estimator (SE) and an SE-based Monte Carlo tree search, denoted as SE-MCTS, which predicts strengths from games and offers different playing strengths with human styles.\nThe strength estimator calculates strength scores and predicts ranks from games without direct human interaction.\nSE-MCTS utilizes the strength scores in a Monte Carlo tree search to adjust playing strength and style.\nWe first conduct experiments in Go, a challenging board game with a wide range of ranks.\nOur strength estimator significantly achieves over 80% accuracy in predicting ranks by observing 15 games only, whereas the previous method reached 49% accuracy for 100 games.\nFor strength adjustment, SE-MCTS successfully adjusts to designated ranks while achieving a 51.33% accuracy in aligning to human actions, outperforming a previous state-of-the-art, with only 42.56% accuracy.\nTo demonstrate the generality of our strength system, we further apply SE and SE-MCTS to chess and obtain consistent results.\nThese results show a promising approach to strength estimation and adjustment, enhancing human-AI interactions in games.", "title_embedding_index": 7703, "title_abs_embedding_index": 7728}, {"title": "A Causal Lens for Evaluating Faithfulness Metrics", "link_suffix": "/forum?id=yDICgRUj5s", "link": "https://openreview.net/forum?id=yDICgRUj5s", "pdf_link": "https://openreview.net/pdf?id=yDICgRUj5s", "keywords": "faithfulness, diagonsticity, natural language explanations, interpretability, model editing", "abstract": "The increasing capabilities of Large Language Models (LLMs) have made natural language explanations a promising alternative to traditional feature attribution methods for model interpretability. However, while these explanations may seem plausible, they can fail to reflect the model's underlying reasoning faithfully. The idea of faithfulness is critical for assessing the alignment between the explanation and the model's true decision-making mechanisms. Although several faithfulness metrics have been proposed, they lack a unified evaluation framework. To address this limitation, we introduce Causal Diagnosticity, a new evaluation framework for comparing faithfulness metrics in natural language explanations. Our framework extends the idea of diagnosticity to the faithfulness metrics for natural language explanations by using model editing to generate faithful and unfaithful explanation pairs. We introduce a benchmark consisting of three tasks: fact-checking, analogy, and object counting, and evaluate a diverse set of faithfulness metrics, including post-hoc explanation-based and chain-of-thought (CoT)-based methods. Our results show that while CC-SHAP significantly outperforms other metrics, there is substantial room for improvement. This work lays the foundation for future research in developing more faithful natural language explanations, highlighting the need for improved metrics and more reliable interpretability methods in LLMs.", "title_embedding_index": 7704, "title_abs_embedding_index": 7729}, {"title": "Discrete Copula Diffusion", "link_suffix": "/forum?id=FXw0okNcOb", "link": "https://openreview.net/forum?id=FXw0okNcOb", "pdf_link": "https://openreview.net/pdf?id=FXw0okNcOb", "keywords": "discrete diffusion models, copula", "abstract": "Discrete diffusion models have recently shown significant progress in modeling complex data, such as natural languages and DNA sequences. However, unlike diffusion models for continuous data, which can generate high-quality samples in just a few denoising steps, modern discrete diffusion models still require hundreds or even thousands of denoising steps to perform well. In this paper, we identify a fundamental limitation that prevents discrete diffusion models from achieving strong performance with fewer steps -- they fail to capture dependencies between output variables at each denoising step. To address this issue, we provide a formal explanation and introduce a general approach to supplement the missing dependency information by incorporating another deep generative model, termed the copula model. Our method does not require fine-tuning either the diffusion model or the copula model, yet it enables high-quality sample generation with significantly fewer denoising steps. When we apply this approach to autoregressive copula models, the combined model outperforms both models individually in unconditional and conditional text generation. Specifically, the hybrid model achieves better (un)conditional text generation using 8 to 32 times fewer denoising steps than the diffusion model alone. In addition to presenting an effective discrete diffusion generation algorithm, this paper emphasizes the importance of modeling inter-variable dependencies in discrete diffusion.", "title_embedding_index": 7705, "title_abs_embedding_index": 7730}, {"title": "Adaptive Energy Alignment for Accelerating Test-Time Adaptation", "link_suffix": "/forum?id=sEMJ1PLSZR", "link": "https://openreview.net/forum?id=sEMJ1PLSZR", "pdf_link": "https://openreview.net/pdf?id=sEMJ1PLSZR", "keywords": "Test-Time Adaptation (TTA), Out-of-domain (OOD), Energy-based Model (EBM)", "abstract": "In response to the increasing demand for tackling out-of-domain (OOD) scenarios, test-time adaptation (TTA) has garnered significant research attention in recent years. To adapt a source pre-trained model to target samples without getting access to their labels, existing approaches have typically employed entropy minimization (EM) loss as a primary objective function. In this paper, we propose an adaptive energy alignment (AEA) solution that achieves fast online TTA. We start from the re-interpretation of the EM loss by decomposing it into two energy-based terms with conflicting roles, showing that the EM loss can potentially hinder the assertive model adaptation. Our AEA addresses this challenge by strategically reducing the energy gap between the source and target domains during TTA, aiming to  effectively align the target domain with the source domains and thus to accelerate adaptation. We specifically propose two novel strategies, each contributing a necessary component for TTA: (i) aligning the energy level of each target sample with the energy zone of the source domain that the pre-trained model is already familiar with, and (ii) precisely guiding the direction of the energy alignment by matching the class-wise correlations between the source and target domains. Our approach demonstrates its effectiveness on various domain shift datasets including CIFAR10-C, CIFAR100-C, and TinyImageNet-C.", "title_embedding_index": 7706, "title_abs_embedding_index": 7731}, {"title": "Algorithmic Language Models with Neurally Compiled Libraries", "link_suffix": "/forum?id=tyFGIjNzlj", "link": "https://openreview.net/forum?id=tyFGIjNzlj", "pdf_link": "https://openreview.net/pdf?id=tyFGIjNzlj", "keywords": "neural compilation, program synthesis, reasoning, algorithms, planning, large language models, fine tuning, tool use", "abstract": "Important reasoning tasks such as planning are fundamentally algorithmic, meaning that solving these tasks robustly requires inducing the underlying algorithms, rather than shortcuts. Large Language Models lack true algorithmic ability primarily because of the limitations of neural network optimization algorithms, their optimization data and optimization objective, but also due to the inexpressivity of the transformer architecture. To address this lack of algorithmic ability, our paper proposes augmenting LLMs with an internal reasoning module. This module contains a library of fundamental operations and sophisticated differentiable programs, so that common algorithms do not need to be learned from scratch. To accomplish this, we add memory, registers, basic operations, and adaptive recurrence to a billion-parameter scale transformer architecture built on LLaMA3.2. Then, we define a method for directly compiling algorithms into a differentiable starting library, which is used natively and propagates gradients for optimization. In this paper, we study the feasibility of this augmentation by fine-tuning an augmented LLaMA 3.2 on simple algorithmic tasks with variable computational depth, such as a recursive fibonacci algorithm or insertion sort.", "title_embedding_index": 7707, "title_abs_embedding_index": 7732}, {"title": "Unsupervised Disentanglement of Content and Style via Variance-Invariance Constraints", "link_suffix": "/forum?id=Lut5t3qElA", "link": "https://openreview.net/forum?id=Lut5t3qElA", "pdf_link": "https://openreview.net/pdf?id=Lut5t3qElA", "keywords": "Unsupervised learning, Interpretable representation learning, Emergent knowledge, Self-supervised learning", "abstract": "We contribute an unsupervised method that effectively learns disentangled content and style representations from sequences of observations. Unlike most disentanglement algorithms that rely on domain-specific labels or knowledge, our method is based on the insight of domain-general statistical differences between content and style --- content varies more among different fragments within a sample but maintains an invariant vocabulary across data samples, whereas style remains relatively invariant within a sample but exhibits more significant variation across different samples. We integrate such inductive bias into an encoder-decoder architecture and name our method after V3 (variance-versus-invariance). Experimental results show that V3 generalizes across multiple domains and modalities, successfully learning disentangled content and style representations, such as pitch and timbre from music audio, digit and color from images of hand-written digits, and action and character appearance from simple animations. V3 demonstrates strong disentanglement performance compared to existing unsupervised methods, along with superior out-of-distribution generalization and few-shot learning capabilities compared to supervised counterparts. Lastly, symbolic-level interpretability emerges in the learned content codebook, forging a near one-to-one alignment between machine representation and human knowledge.", "title_embedding_index": 7708, "title_abs_embedding_index": 7733}, {"title": "General Skeleton Semantics Learning with Probabilistic Masked Context Reconstruction for Skeleton-Based Person Re-Identification", "link_suffix": "/forum?id=b9VSMQZl0j", "link": "https://openreview.net/forum?id=b9VSMQZl0j", "pdf_link": "https://openreview.net/pdf?id=b9VSMQZl0j", "keywords": "General skeleton semantics learning, Generality Assessment, Skeleton-based person re-identification, Probabilistic masked reconstruction, Spatial-temporal context learning", "abstract": "Person re-identification (re-ID) via skeleton data is an emerging topic with immense potential for safety-critical applications. Existing methods usually utilize spatial or temporal skeleton semantics learning (SSL) tasks to facilitate skeleton representation learning, while most SSL tasks aremodel-dependentand lack the ability to capture general fine-grained (e.g., joint-level) spatial-temporal skeleton patterns under different model architectures. To delve into multi-faceted generality of SSL tasks, we first propose an SSL generality assessment framework termedSCUTthat identifies four key SSL properties:Spatial-temporal effectiveness,Co-training compatibility,Unsupervised trainability, andTask transformability. By formulating systematic evaluation criteria for each property, SCUT enables both qualitative and quantitative analysis of SSL generality under varying models and scenarios. Motivated by SCUT to fully harness skeleton context for semantics learning, we further devise a genericProbabilisticMasked Spatial-Temporal contextReconstruction (Prompter) task to enhance performance of skeleton-based person re-ID models. Specifically, Prompter first probabilistically and independently masks joints' structural locations to generatespatial context, and then randomly conceal their motion trajectories to formtemporal context. \nThrough combining both spatial and temporal skeleton context representations to jointly reconstruct and infer skeleton sequences, Prompter encourages the model to capture general valuable spatial-temporal skeleton patterns for person re-ID. Empirical evaluations on SCUT and five benchmark datasets demonstrate the superiority of Prompter to most state-of-the-art SSL tasks. We further validate its general effectiveness in different skeleton modeling, RGB-estimated or cross-domain scenarios", "title_embedding_index": 7709, "title_abs_embedding_index": 7734}, {"title": "InversionGNN: A Dual Path Network for Multi-Property Molecular Optimization", "link_suffix": "/forum?id=nYPuSzGE3X", "link": "https://openreview.net/forum?id=nYPuSzGE3X", "pdf_link": "https://openreview.net/pdf?id=nYPuSzGE3X", "keywords": "multi-objective drug discovery", "abstract": "Exploring chemical space to find novel molecules that simultaneously satisfy multiple properties is crucial in drug discovery. However, existing methods often struggle with trading off multiple properties due to the conflicting or correlated nature of chemical properties.  To tackle this issue, we introduce InversionGNN framework, an effective yet sample-efficient dual-path graph neural network (GNN) for multi-objective drug discovery.  In the direct prediction path of InversionGNN, we train the model for multi-property prediction to acquire knowledge of the optimal combination of functional groups.\nThen the learned chemical knowledge helps the inversion generation path to generate molecules with required properties. \nIn order to decode the complex knowledge of multiple properties in the inversion path, we propose a gradient-based pareto search method to balance conflicting properties and generate Pareto optimal molecules. \nAdditionally, InversionGNN is able to search the full Pareto front approximately in discrete chemical space. Comprehensive experimental evaluations show that InversionGNN is both effective and sample-efficient in various real-world discrete multi-objective settings including drug discovery.", "title_embedding_index": 7710, "title_abs_embedding_index": 7735}, {"title": "Model-Enhanced Adversarial Inverse Reinforcement Learning with Model Estimation Reward Shaping in Stochastic Environments", "link_suffix": "/forum?id=Z8XALH7RLv", "link": "https://openreview.net/forum?id=Z8XALH7RLv", "pdf_link": "https://openreview.net/pdf?id=Z8XALH7RLv", "keywords": "Inverse Reinforcement Learning; Model-based Approach;", "abstract": "In this paper, we aim to tackle the limitation of the Adversarial Inverse Reinforcement Learning (AIRL) method in stochastic environments where theoretical results cannot hold and performance is degraded. To address this issue, we propose a novel method which infuses the dynamics information into the reward shaping with the theoretical guarantee for the induced optimal policy in the stochastic environments. Incorporating our novel model-enhanced rewards, we present a novel Model-Enhanced AIRL framework, which integrates transition model estimation directly into reward shaping. Furthermore, we provide a comprehensive theoretical analysis of the reward error bound and performance difference bound for our method. The experimental results in MuJoCo benchmarks show that our method can achieve superior performance in stochastic environments and competitive performance in deterministic environments, with significant improvement in sample efficiency, compared to existing baselines.", "title_embedding_index": 7711, "title_abs_embedding_index": 7736}, {"title": "Large-Scale Training Data Attribution with Efficient Influence Functions", "link_suffix": "/forum?id=jZw0CWXuDc", "link": "https://openreview.net/forum?id=jZw0CWXuDc", "pdf_link": "https://openreview.net/pdf?id=jZw0CWXuDc", "keywords": "data attribution, influence functions, LLMs, interpretability", "abstract": "Training data attribution (TDA) quantifies the contribution of individual training examples to model predictions, enabling a range of applications such as data curation, data citation, and model debugging. However, applying existing TDA methods to recent large models and training datasets has been largely limited by prohibitive compute and memory costs. In this work, we focus on influence functions, a popular gradient-based TDA method, and significantly improve its scalability with an efficient gradient projection strategy called LoGra that leverages the gradient structure in backpropagation. We then provide a theoretical motivation of gradient projection approaches to influence functions to promote trust in the TDA process. Lastly, we lower the barrier to implementing TDA systems by introducing LogIX, a software package that can transform existing training code into TDA code with minimal effort. In our TDA experiments, LoGra achieves competitive accuracy against more expensive baselines while showing up to 6,500x improvement in throughput and 5x reduction in GPU memory usage when applied to Llama3-8B-Instruct and the 1B-token dataset.", "title_embedding_index": 7712, "title_abs_embedding_index": 7737}, {"title": "Dynamic Elimination For PAC Optimal Item Selection From Relative Feedback", "link_suffix": "/forum?id=zCJqgXnV7f", "link": "https://openreview.net/forum?id=zCJqgXnV7f", "pdf_link": "https://openreview.net/pdf?id=zCJqgXnV7f", "keywords": "probably approximately correct, optimal item selection, relative feedback, multi armed bandits, Plackett Luce Model, Condorcet winner, Bayesian updates, active learning", "abstract": "We study the problem of best-item identification from relative feedback where a learner adaptively plays subsets of items and receives stochastic feedback in the form of the best item in the set. We propose an algorithm - Dynamic Elimination (DE) - that dynamically prunes sub-optimal items from contention to efficiently identify the best item and show a strong sample complexity upper bound for it. We further formalize the notion of inferred updates to obtain estimates on item win rates without directly playing them by leveraging item correlation information. We propose the Dynamic Elimination by Correlation (DEBC) algorithm as an extension to DE with inferred updates. We show through extensive experiments that DE and DEBC significantly outperform all existing baselines across multiple datasets in various settings.", "title_embedding_index": 7713, "title_abs_embedding_index": 7738}, {"title": "Exploring The Loss Landscape Of Regularized Neural Networks Via Convex Duality", "link_suffix": "/forum?id=4xWQS2z77v", "link": "https://openreview.net/forum?id=4xWQS2z77v", "pdf_link": "https://openreview.net/pdf?id=4xWQS2z77v", "keywords": "Convex duality, Machine Learning Theory, Loss Landscape, Optimal Sets", "abstract": "We discuss several aspects of the loss landscape of regularized neural networks: the structure of stationary points, connectivity of optimal solutions, path with non-increasing loss to arbitrary global optimum, and the nonuniqueness of optimal solutions, by casting the problem into an equivalent convex problem and considering its dual. Starting from two-layer neural networks with scalar output, we first characterize the solution set of the convex problem using its dual and further characterize all stationary points. With the characterization, we show that the topology of the global optima goes through a phase transition as the width of the network changes, and construct counterexamples where the problem may have a continuum of optimal solutions. Finally, we show that the solution set characterization and connectivity results can be extended to different architectures, including two layer vector-valued neural networks and parallel three-layer neural networks.", "title_embedding_index": 7714, "title_abs_embedding_index": 7739}, {"title": "Incremental Exploits: Efficient Jailbreaks on Large Language Models with Multi-round Conversational Jailbreaking", "link_suffix": "/forum?id=KyKTjRtyNG", "link": "https://openreview.net/forum?id=KyKTjRtyNG", "pdf_link": "https://openreview.net/pdf?id=KyKTjRtyNG", "keywords": "Large Language Models, Model Vulnerabilities, Multi-round Conversational Jailbreaking", "abstract": "As large language models (LLMs) become widely deployed across various domains, security concerns---particularly jailbreak attacks that bypass built-in safety mechanisms---have emerged as significant risks. Existing jailbreak methods focus mainly on single-turn interactions and face limitations in generalizability and practicality. In this paper, we propose a novel method called Multi-round Conversational Jailbreaking (MRCJ), which exploits the unintended competition between a LLMs' safety alignment and its in-context learning objectives during extended conversations. By incrementally introducing increasingly malicious content, the LLMs' tendency to maintain contextual consistency can override its safety protocols, ultimately leading to harmful outputs. To facilitate conversation flow generation, we developed a dataset containing 12,000 questions, categorized into six types of security topics, and classified across four levels of severity, spanning ten languages. Compared to existing methods, MRCJ demonstrates superior efficiency, applicability, and effectiveness by fully exploiting the potential of multi-round conversations. In experiments, MRCJ achieves a jailbreak success rate of over 90% across widely-used LLMs, requiring fewer than five queries on average, and significantly outperforms baselines on both metrics. Our findings expose vulnerabilities in current LLMs during extended conversations and highlight the need for improved safety mechanisms that consider multi-round interactions. The source code and dataset are available at (URL omitted for double-blind reviewing; code available in supplementary materials).", "title_embedding_index": 7715, "title_abs_embedding_index": 7740}, {"title": "UDC-VIT: A Real-World Video Dataset for Under-Display Cameras", "link_suffix": "/forum?id=DNBwlQYA90", "link": "https://openreview.net/forum?id=DNBwlQYA90", "pdf_link": "https://openreview.net/pdf?id=DNBwlQYA90", "keywords": "Under-Display Camera, Dataset, Benchmark, Alignment, Flare", "abstract": "Under Display Camera (UDC) is an advanced imaging system that places a digital camera lens underneath a display panel, effectively concealing the camera. However, the display panel significantly degrades captured images or videos, introducing low transmittance, blur, noise, and flare issues. Tackling such issues is challenging because of the complex degradation of UDCs, including diverse flare patterns. Despite extensive research on UDC images and their restoration models, studies on videos have yet to be significantly explored. While two UDC video datasets exist, they primarily focus on unrealistic or synthetic UDC degradation rather than real-world UDC degradation. In this paper, we propose a real-world UDC video dataset called UDC-VIX. Unlike existing datasets, only UDC-VIX exclusively includes human motions that target facial recognition. We propose a video-capturing system to simultaneously acquire non-degraded and UDC-degraded videos of the same scene. Then, we align a pair of captured videos frame by frame, using discrete Fourier transform (DFT). We compare UDC-VIX with seven representative UDC still image datasets and two existing UDC video datasets. Using six deep-learning models, we compare UDC-VIX and an existing synthetic UDC video dataset. The results indicate the ineffectiveness of models trained on earlier synthetic UDC video datasets, as they do not reflect the actual characteristics of UDC-degraded videos. We also demonstrate the importance of effective UDC restoration by evaluating face recognition accuracy concerning PSNR, SSIM, and LPIPS scores. UDC-VIX enables further exploration in the UDC video restoration and offers better insights into the challenge. UDC-VIX is available at our project site.", "title_embedding_index": 7716, "title_abs_embedding_index": 7741}, {"title": "Solving Blind Non-linear Forward and Inverse Problem for Audio Applications", "link_suffix": "/forum?id=mlPTNEIsgb", "link": "https://openreview.net/forum?id=mlPTNEIsgb", "pdf_link": "https://openreview.net/pdf?id=mlPTNEIsgb", "keywords": "audio effect, zero-shot system identification, inverse problem, diffusion model, sequential monte carlo", "abstract": "We propose a novel framework to address the blind forward and inverse problems, where the goal is to infer either the function or the input signal solely from the output signal without access to the other. These problems are challenging due to the highly nonlinear and complex nature of the forward operator\u2014the function mapping between the input and output signals. To tackle the blind forward problem, we introduce a reference encoder that analyzes the reference output (wet signal) to approximate an arbitrary forward operator. For the blind inverse problem, the approximated forward operator is leveraged to guide both the training and inference stages of a diffusion model, enabling a more accurate reconstruction of the input signal. Furthermore, we propose a twisted particle filtering method to enhance the model's performance in solving the inverse problem. Our framework significantly improves the handling of these complex signal-processing tasks, offering new insights into forward and inverse problem-solving strategies in nonlinear systems. Codes are available at \\url{https://github.com/BlindForwardInverse/BlindForwardInverseAnonymous}", "title_embedding_index": 7717, "title_abs_embedding_index": 7742}, {"title": "Mix-LN: Unleashing the Power of Deeper Layers by Combining Pre-LN and Post-LN", "link_suffix": "/forum?id=BChpQU64RG", "link": "https://openreview.net/forum?id=BChpQU64RG", "pdf_link": "https://openreview.net/pdf?id=BChpQU64RG", "keywords": "large language model, layer normalization, mix-Layer Normalization", "abstract": "Large Language Models (LLMs) have achieved remarkable success, yet recent findings reveal that their deeper layers often contribute minimally and can be pruned without affecting overall performance.  While some view this as an opportunity for model compression, we identify it as a training shortfall rooted in the widespread use of Pre-Layer Normalization (Pre-LN). We demonstrate that Pre-LN, commonly employed in models like GPT and LLaMA, leads to diminished gradient norms in its deeper layers, reducing their effectiveness. In contrast, Post-Layer Normalization (Post-LN) preserves larger gradient norms in deeper layers but suffers from vanishing gradients in earlier layers. To address this, we introduce Mix-LN, a novel normalization technique that combines the strengths of Pre-LN and Post-LN within the same model. Mix-LN applies Post-LN to the earlier layers and Pre-LN to the deeper layers, ensuring more uniform gradient norms across layers. This allows all parts of the network\u2014both shallow and deep layers\u2014to contribute effectively to training. Extensive experiments with various model sizes demonstrate that Mix-LN consistently outperforms both Pre-LN and Post-LN, promoting more balanced, healthier gradient norms throughout the network, and enhancing the overall quality of LLM pre-training. Furthermore, we demonstrate that models pre-trained with Mix-LN learn better compared to those using Pre-LN or Post-LN during supervised fine-tuning, highlighting the critical importance of high-quality deep layers. By effectively addressing the inefficiencies of deep layers in current LLMs, Mix-LN unlocks their potential, enhancing model capacity without increasing model size. Our code is submitted.", "title_embedding_index": 7718, "title_abs_embedding_index": 7743}, {"title": "Auto-Ensemble Structure Learning of Large Gaussian Bayesian Networks", "link_suffix": "/forum?id=UAkVjK00Wv", "link": "https://openreview.net/forum?id=UAkVjK00Wv", "pdf_link": "https://openreview.net/pdf?id=UAkVjK00Wv", "keywords": "Structure learning, Large Bayesian Network, Ensemble Method", "abstract": "Learning the structure of Bayesian networks (BNs) from data is challenging, especially for datasets involving a large number of variables. The recently proposed divide-and-conquer (D&D) strategies present a promising approach for learning large BNs. However, they still face a main issue of unstable learning accuracy across subproblems. In this work, we introduce the idea of employing structure learning ensemble (SLE), which combines multiple BN structure learning algorithms together, to consistently achieve high learning accuracy across various problems. We further propose an automatic approach called Auto-SLE for constructing near-optimal SLEs, addressing the challenge of manually designing effective SLEs. The automatically constructed SLE is then integrated into a D&D framework. Extensive experiments \ufb01rmly show the superiority of our method over existing methods in learning large BNs, achieving accuracy improvement usually by 30%\u223c225% on datasets involving 10,000 variables. Furthermore, our method generalizes very well to datasets with many more variables and different network characteristics than those present in the training data for constructing the SLE. These results indicate the signi\ufb01cant potential of employing automatic construction of SLEs for BN structure learning.", "title_embedding_index": 7719, "title_abs_embedding_index": 7744}, {"title": "Patch-Wise Automatic Segmentation for Real-Time PCB Inspection", "link_suffix": "/forum?id=6I0jPeH5Pw", "link": "https://openreview.net/forum?id=6I0jPeH5Pw", "pdf_link": "https://openreview.net/pdf?id=6I0jPeH5Pw", "keywords": "Automated Optical Inspection, Printed Circuit Board, Patch-Wise, Automatic Segmentation, YOLOv7", "abstract": "Automated Optical Inspection (AOI) systems play a pivotal role in ensuring quality control during Printed Circuit Board (PCB) manufacturing. However, the current AOI systems necessitate manual setting of the region of interest (ROI) for all components. To address this, we propose a patch-based preprocessing technique, dividing high-resolution PCB images into small 1024 \u00d7 1024 pixel patches and employing the YOLOv7 segmentation model for real-time component ROI segmentation. Our method consistently delivered high accuracy across various PCB components, irrespective of background color, and demonstrated robust performance even with complex structures containing small components. It achieved impressive outcomes, with an average IoU, F1 score, pixel accuracy, and mAP of 0.8889, 0.9401, 0.9961, and 0.8255, respectively. Specifically, utilizing Feature Pyramid Network (FPN) and Path Aggregation Network (PAN) in YOLOv7's multi-resolution processing allowed us to accurately segment PCB components of various sizes and process them in real-time. This study underscores the potential of automating real-time component ROI segmentation in the PCB manufacturing process to enhance production speed and quality control.", "title_embedding_index": 7720, "title_abs_embedding_index": 7745}, {"title": "SAR2Earth: A SAR-to-EO Translation Dataset for Remote Sensing Applications", "link_suffix": "/forum?id=JigWdDArjb", "link": "https://openreview.net/forum?id=JigWdDArjb", "pdf_link": "https://openreview.net/pdf?id=JigWdDArjb", "keywords": "AI for social good, \bDataset, SAR-to-EO translation, Benchmark", "abstract": "Electro-optical (EO) images are essential to a wide range of remote sensing applications. With the advent of data-driven models, the efficiency of EO image analysis has significantly improved, enabling faster and more effective outcomes in these applications. However, EO images have inherent limitations\u2014they cannot penetrate cloud cover and are unable to capture imagery at night. To overcome these challenges, synthetic aperture radar (SAR) images are employed, as they can operate effectively regardless of weather conditions or time of day. Despite this advantage, SAR images come with their own difficulties: they are affected by speckle noise, complicating analysis, and existing algorithms developed for EO imagery are not directly transferable to SAR data. To address these issues, we introduce SAR2Earth, a benchmark dataset specifically designed for SAR-to-EO translation. By translating SAR images into EO-like representations, SAR2Earth allows the extensive range of algorithms developed for EO imagery to be applied effectively to SAR data. The dataset consists of 18 spatially aligned pairs of SAR and EO images, collected from 8 distinct regions encompassing both urban and rural. We provide comprehensive evaluations, detailed model analyses, and extensive experimental results. All codes and datasets will be made publicly available athttps://sar2earth.github.io.", "title_embedding_index": 7721, "title_abs_embedding_index": 7746}, {"title": "BAP: BRANCH-AWARE PARALLEL EXECUTION FOR FASTER DNN INFERENCE ON MOBILE CPUS", "link_suffix": "/forum?id=Keoih8ebp0", "link": "https://openreview.net/forum?id=Keoih8ebp0", "pdf_link": "https://openreview.net/pdf?id=Keoih8ebp0", "keywords": "Neural Networks, Model Parallelism, Edge Devices, ASR Models, Transformers, Mobile CPUs", "abstract": "The growing demand for real-time applications on edge devices underscores the need for faster inference of complex deep neural network (DNN) models. Although mobile devices increasingly incorporate specialized processors like GPUs and TPUs, modern DNN models such as Whisper and Vision Transformers often involve dynamic control flows and tensor operations that are incompatible and unsupported on current frameworks with these mobile accelerators. CPU presents the most viable option to improve inference latency on mobile devices due to their widespread availability, substantial memory caches, and ability to support all types of tensor operations. However, existing CPU optimization techniques focus on sequential execution, overlooking potential parallelization within Automatic Speech Recognition (ASR) and transformer-based models, leading to inefficiencies. This work introduces a novel runtime model analysis pipeline that extracts layer and branch structures from DNN model graphs to identify parallelizable branches. We propose BAP, a branch-aware memory allocation strategy that isolates memory arenas for parallel branches, enhancing cache locality and reducing memory contention. Additionally, we leverage CPU multithreading to execute these branches concurrently, optimizing thread management and memory access to minimize overhead. Evaluated on ASR models and transformer-based models, our approach reduces inference latency by up to 38.5%, decreases memory allocation requirements by up to 15.6x and saves up to 20.2% energy cost compared to the TFLite naive memory allocation.", "title_embedding_index": 7722, "title_abs_embedding_index": 7747}, {"title": "Exploring the Impact of Activation Functions in Training Neural ODEs", "link_suffix": "/forum?id=AoraWUmpLU", "link": "https://openreview.net/forum?id=AoraWUmpLU", "pdf_link": "https://openreview.net/pdf?id=AoraWUmpLU", "keywords": "Neural ODEs, Gradient Descent, Neural Tangent Kernel (NTK)", "abstract": "Neural Ordinary Differential Equations (ODEs) have been successful in various applications due to their continuous nature and parameter-sharing efficiency. However, these unique characteristics also introduce challenges in training, particularly with respect to gradient computation accuracy and convergence analysis. In this paper, we address these challenges by investigating the impact of activation functions. We demonstrate that the properties of activation functions\u2014specifically smoothness and nonlinearity\u2014are critical to the training dynamics. Smooth activation functions guarantee globally unique solutions for both forward and backward ODEs, while sufficient nonlinearity is essential for maintaining the spectral properties of the Neural Tangent Kernel (NTK) during training. Together, these properties enable us to establish the global convergence of Neural ODEs under gradient descent in overparameterized regimes. Our theoretical findings are validated by numerical experiments, which not only support our analysis but also provide practical guidelines for scaling Neural ODEs, potentially leading to faster training and improved performance in real-world applications.", "title_embedding_index": 7723, "title_abs_embedding_index": 7748}, {"title": "EmbedLLM: Learning Compact Representations of Large Language Models", "link_suffix": "/forum?id=Fs9EabmQrJ", "link": "https://openreview.net/forum?id=Fs9EabmQrJ", "pdf_link": "https://openreview.net/pdf?id=Fs9EabmQrJ", "keywords": "Large Language Models, Representation Learning, Model Routing", "abstract": "With hundreds of thousands of language models available on Huggingface today, efficiently evaluating and utilizing these models across various downstream tasks has become increasingly critical. Many existing methods repeatedly learn task-specific representations of Large Language Models (LLMs), which leads to inefficiencies in both time and computational resources. To address this, we propose EmbedLLM, a framework designed to learn compact vector representations of LLMs that facilitate downstream applications involving many models, such as model routing. We introduce an encoder-decoder approach for learning such embedding, along with a systematic framework to evaluate their effectiveness. Empirical results show that EmbedLLM outperforms prior methods in model routing. Additionally, we demonstrate that our method can forecast a model's performance on multiple benchmarks, without incurring additional inference cost. Extensive probing experiments validate that the learned embeddings capture key model characteristics, e.g. whether the model is specialized for coding tasks, even without being explicitly trained on them. We open source our dataset, code and embedder to facilitate further research and application.", "title_embedding_index": 7724, "title_abs_embedding_index": 7749}]
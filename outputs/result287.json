[{"title": "CLIP2LE\uff1aA  Label Enhancement Fair Representation Method via CLIP", "link_suffix": "/forum?id=Wl5HGuFYVp", "link": "https://openreview.net/forum?id=Wl5HGuFYVp", "pdf_link": "https://openreview.net/pdf?id=Wl5HGuFYVp", "keywords": "Label enhancement, CLIP", "abstract": "Label enhancement is a novel label shift strategy that aims to integrate the feature space with the logical label space to obtain a high-quality label distribution. This label distribution can serve as a soft target for algorithmic learning, akin to label smoothing, thereby enhancing the performance of various learning paradigms including multi-label learning, single positive label learning and partial-label learning. However, limited by dataset type and annotation inaccuracy, the same label enhancement algorithm on different datasets struggles to achieve consistent performance, for reasons derived from the following two insights: 1) Differential Contribution of Feature Space and Logical Label Space: The feature space and logical label space of different datasets contribute differently to generating an accurate label distribution; 2) Presence of Noise and Incorrect Labels: Some datasets contain noise and inaccurately labeled samples, leading to divergent outputs for similar inputs. To address these challenges, we propose leveraging CLIP (Contrastive Language-Image Pretraining) as a foundational strategy, treating the feature space and the logical label space as two distinct modalities. By recoding these modalities before applying the label enhancement algorithm, we aim to achieve a fair and robust representation. Extensive experimental results demonstrate the effectiveness of our approach to help existing label enhancement algorithms improve their performance on several benchmarks.", "title_embedding_index": 14300, "title_abs_embedding_index": 14325}, {"title": "Practical Kernel Learning for Kernel-based Conditional Independent Test", "link_suffix": "/forum?id=GPcSYm89wK", "link": "https://openreview.net/forum?id=GPcSYm89wK", "pdf_link": "https://openreview.net/pdf?id=GPcSYm89wK", "keywords": "kernel selection, conditional independence, hypothesis testing", "abstract": "Conditional independence (CI) test stands as a fundamental and challenging task within modern statistics and machine learning. One pivotal class of methods for assessing conditional independence encompasses kernel-based approaches, known for their capability to identify general conditional dependence without necessitating assumptions about the conditional relationship or resorting to the simulation of intricate conditional distributions. As with any method utilizing kernels, selecting the appropriate kernel in kernel-based CI methods is critical for ensuring heightened test power and precise identification of conditional relationship. However, current methods typically involve the manual heuristic selection of kernel parameters, neglecting the inherent characteristics of the data and potentially leading to errors. In this paper, we propose a kernel parameter selection approach for the Kernel-based Conditional Independence test method (KCI). We decompose the statistic of KCI and treat the kernel applied on the conditioning set as a trainable component. The kernel parameters involved are then learned by maximizing the ratio of the estimated statistic to its variance, which approximates the test power at large sample sizes. Therefore, our method can learn the kernel parameters with increased test power at a very small additional computation cost. Extensive experiments demonstrate the effectiveness of our proposed approach in conditional independence testing and its enhancements to constrain-based causal discovery.", "title_embedding_index": 14301, "title_abs_embedding_index": 14326}, {"title": "Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning", "link_suffix": "/forum?id=7WUdjDhF38", "link": "https://openreview.net/forum?id=7WUdjDhF38", "pdf_link": "https://openreview.net/pdf?id=7WUdjDhF38", "keywords": "Foundation model, Zero-Shot Learning, Vectorized Databases", "abstract": "Foundation models have become a cornerstone in deep learning, with techniques like Low-Rank Adaptation (LoRA) offering efficient fine-tuning of large models. Similarly, methods such as Retrieval-Augmented Generation (RAG), which leverage vectorized databases, have further improved model performance by grounding outputs in external information. While these approaches have demonstrated notable success, they often require extensive training or labeled data, which can limit their adaptability in resource-constrained environments. To address these challenges, we introduce Retrieval-based Parameter Ensemble (RPE), a new method that creates a vectorized database of LoRAs, enabling efficient retrieval and application of model adaptations to new tasks. RPE minimizes the need for extensive training and eliminates the requirement for labeled data, making it particularly effective for zero-shot learning. Additionally, RPE is well-suited for privacy-sensitive domains like healthcare, as it modifies model parameters without accessing raw data. When applied to tasks such as medical report generation and image segmentation, RPE not only proved effective but also surpassed supervised fine-tuning methods in certain cases, highlighting its potential to enhance both computational efficiency and privacy in deep learning applications.", "title_embedding_index": 14302, "title_abs_embedding_index": 14327}, {"title": "Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach", "link_suffix": "/forum?id=g3aGMMFHW0", "link": "https://openreview.net/forum?id=g3aGMMFHW0", "pdf_link": "https://openreview.net/pdf?id=g3aGMMFHW0", "keywords": "large language model, uncertainty estimation, calibration, supervised learning", "abstract": "In this paper, we study the problem of uncertainty estimation and calibration for LLMs. We begin by formulating the uncertainty estimation problem, a relevant yet underexplored area in existing literature. We then propose a supervised approach that leverages labeled datasets to estimate the uncertainty in LLMs' responses. Based on the formulation, we illustrate the difference between the uncertainty estimation for LLMs and that for standard ML models and explain why the hidden neurons of the LLMs may contain uncertainty information. Our designed approach demonstrates the benefits of utilizing hidden activations to enhance uncertainty estimation across various tasks and shows robust transferability in out-of-distribution settings. We distinguish the uncertainty estimation task from the uncertainty calibration task and show that better uncertainty estimation leads to better calibration performance. Furthermore, our method is easy to implement and adaptable to different levels of model accessibility including black box, grey box, and white box.", "title_embedding_index": 14303, "title_abs_embedding_index": 14328}, {"title": "HyperDPO: Hypernetwork-based Multi-Objective Fine-Tuning Framework", "link_suffix": "/forum?id=qBKA2844I4", "link": "https://openreview.net/forum?id=qBKA2844I4", "pdf_link": "https://openreview.net/pdf?id=qBKA2844I4", "keywords": "Direct Preference Optimization, Multi-Objective Optimization, Hypernetwork, Alignment", "abstract": "In LLM alignment and many other ML applications, one often faces theMulti-Objective Fine-Tuning (MOFT)problem,i.e.fine-tuning an existing model with datasets labeled w.r.t. different objectives simultaneously. To address the challenge, we propose theHyperDPOframework, a hypernetwork-based approach that extends the Direct Preference Optimization (DPO) technique, originally developed for efficient LLM alignment with preference data, to accommodate the MOFT settings. By substituting the Bradley-Terry-Luce model in DPO with the Plackett-Luce model, our framework is capable of handling a wide range of MOFT tasks that involve listwise ranking datasets. Compared with previous approaches, HyperDPO enjoys an efficient one-shot training process for profiling the Pareto front of auxiliary objectives, and offers flexible post-training control over trade-offs. Additionally, we propose a novelHyper Prompt Tuningdesign, that conveys continuous weight across objectives to transformer-based models without altering their architecture. We demonstrate the effectiveness and efficiency of the HyperDPO framework through its applications to various tasks, including Learning-to-Rank (LTR) and LLM alignment, highlighting its viability for large-scale ML deployments.", "title_embedding_index": 14304, "title_abs_embedding_index": 14329}, {"title": "AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?", "link_suffix": "/forum?id=kUsXwE98Cs", "link": "https://openreview.net/forum?id=kUsXwE98Cs", "pdf_link": "https://openreview.net/pdf?id=kUsXwE98Cs", "keywords": "Large Vision-Language Model, automatic evaluation, benchmark", "abstract": "Large Vision-Language Models (LVLMs) have become essential for advancing the integration of visual and linguistic information, facilitating a wide range of complex applications and tasks. However, the evaluation of LVLMs presents significant challenges as the evaluation benchmark always demands lots of human cost for its construction, and  remains static, lacking flexibility once constructed. Even though automatic evaluation has been explored in textual modality, the visual modality remains under-explored. As a result, in this work, we address a question: \"Can LVLMs serve as a path to automatic benchmarking?\". We introduce AutoBench-V, an automated framework for serving evaluation on demand, i.e., benchmarking LVLMs based on specific aspects of model capability. Upon receiving an evaluation capability, AutoBench-V leverages text-to-image models to generate relevant image samples and then utilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing the evaluation process efficiently and flexibly. Through an extensive evaluation of seven popular LVLMs across five demanded user inputs, i.e., evaluation capabilities), the framework shows effectiveness and reliability. We observe the following: (1) Our constructed benchmark accurately reflects varying task difficulties; (2) As task difficulty rises, the performance gap between models widens; and (3) While models exhibit strong performance in abstract level understanding, they underperform in details reasoning tasks; and (4) Constructing a dataset with varying levels of difficulties is critical for a comprehensive and exhaustive evaluation. Overall, AutoBench-V not only successfully utilizes LVLMs for automated benchmarking but also reveals that LVLMs as judges have significant potential in various domains.", "title_embedding_index": 14305, "title_abs_embedding_index": 14330}, {"title": "DRL: Decomposed Representation Learning for Tabular Anomaly Detection", "link_suffix": "/forum?id=CJnceDksRd", "link": "https://openreview.net/forum?id=CJnceDksRd", "pdf_link": "https://openreview.net/pdf?id=CJnceDksRd", "keywords": "Anomaly detection, Tabular data, Tabular representation learning", "abstract": "Anomaly detection, indicating to identify the anomalies that significantly deviate from the majority normal instances of data, has been an important role in machine learning and related applications. Despite the significant success achieved in anomaly detection on image and text data, the accurate Tabular Anomaly Detection (TAD) has still been hindered due to the lack of clear prior semantic information in the tabular data. Most state-of-the-art TAD studies are along the line of reconstruction, which first reconstruct training data and then use reconstruction errors to decide anomalies; however, reconstruction on training data can still hardly distinguish anomalies due to the data entanglement in their representations. To address this problem, in this paper, we propose a novel approach Decomposed Representation Learning (DRL), to re-map data into a tailor-designed constrained space, in order to capture the underlying shared patterns of normal samples and differ anomalous patterns for TAD.\nSpecifically, we enforce the representation of each normal sample in the latent space to be decomposed into a weighted linear combination of randomly generated orthogonal basis vectors, where these basis vectors are both data-free and training-free.\nFurthermore, we enhance the discriminative capability between normal and anomalous patterns in the latent space by introducing a novel constraint that amplifies the discrepancy between these two categories, supported by theoretical analysis. \nFinally, extensive experiments on 40 tabular datasets and 15 competing tabular anomaly detection algorithms show that our method achieves state-of-the-art performance.", "title_embedding_index": 14306, "title_abs_embedding_index": 14331}, {"title": "TinyMem: Condensing Multimodal Memory for Long-form Video Action Detection", "link_suffix": "/forum?id=9DSUwiYJP3", "link": "https://openreview.net/forum?id=9DSUwiYJP3", "pdf_link": "https://openreview.net/pdf?id=9DSUwiYJP3", "keywords": "Long-form Video Understanding, Multimodal Understanding", "abstract": "Despite the great advances in video understanding with deep neural networks, current solutions still struggle with input videos that last for minutes, if not hours. To mitigate this issue, existing approaches typically build a memory cache with dense visual embedding on video transformers to model the long-range spatiotemporal dependencies. However, even with hundreds of extended memory tokens, their results remain unsatisfactory. \nIn this paper, we argue that more compact yet informative memory embeddings can effectively improve performance. To this end, we introduce TinyMem, a model built upon tiny multimodal memory for long-form video action detection. In particular, we condense redundant video content into succinct descriptions to derive abstract text semantics. Subsequently, we integrate visual embedding condensed by regions with text embedding. TinyMem beats a range of state-of-the-art models on AVA v2.2, Epic-Kitchens-100 and Breakfast with highly condensed memory, e.g., 37.4 mAP with TinyMem-24-12 on AVA v2.2 while using 5 times fewer memory tokens than the baseline with dense visual memory embedding.", "title_embedding_index": 14307, "title_abs_embedding_index": 14332}, {"title": "Explainable Concept Generation through Vision-Language Preference Learning", "link_suffix": "/forum?id=9fMNxWDZsP", "link": "https://openreview.net/forum?id=9fMNxWDZsP", "pdf_link": "https://openreview.net/pdf?id=9fMNxWDZsP", "keywords": "Concept based Explainable AI, Vision-Language Models, Reinforcement Learning", "abstract": "Concept-based explanations have become a popular choice for explaining deep neural networks post-hoc because, unlike most other explainable AI techniques, they can be used to test high-level visual \"concepts\" that are not directly related to feature attributes. For instance, the concept of \"stripes\" is important to classify an image as a zebra. Concept-based explanation methods, however, require practitioners to guess and collect multiple candidate concept image sets, which can often be imprecise and labor-intensive. Addressing this limitation, in this paper, we frame concept image set creation as an image generation problem. However, since naively using a generative model does not result in meaningful concepts, we devise a reinforcement learning-based preference optimization (RLPO) algorithm that fine-tunes the vision-language generative model from approximate textual descriptions of concepts. Through a series of experiments, we demonstrate the capability of our method to articulate complex and abstract concepts which aligns with the test class that are otherwise challenging to craft manually. In addition to showing the efficacy and reliability of our method, we show how our method can be used as a diagnostic tool for analyzing neural networks.", "title_embedding_index": 14308, "title_abs_embedding_index": 14333}, {"title": "Decoupled Alignment for Robust Plug-and-Play Adaptation", "link_suffix": "/forum?id=lwTTZkDWoT", "link": "https://openreview.net/forum?id=lwTTZkDWoT", "pdf_link": "https://openreview.net/pdf?id=lwTTZkDWoT", "keywords": "Jailbreak Aligner, Memory Editing", "abstract": "We introduce a low-resource safety enhancement method for aligning large language models (LLMs) without the need for supervised fine-tuning (SFT) or reinforcement learning from human feedback (RLHF).Our main idea is to exploit knowledge distillation to extract the alignment information from existing well-aligned LLMs and integrate it into unaligned LLMs in a plug-and-play fashion. Methodology, we employ delta debugging to identify the critical components of knowledge necessary for effective distillation. On the harmful question dataset, our method significantly enhances the average defense success rate by approximately 14.41%, reaching as high as 51.39%, in 17 unaligned pre-trained LLMs, without compromising performance.", "title_embedding_index": 14309, "title_abs_embedding_index": 14334}, {"title": "Codev-Bench: How Do LLMs Understand Developer-Centric Code Completion?", "link_suffix": "/forum?id=c2C2NQKjZw", "link": "https://openreview.net/forum?id=c2C2NQKjZw", "pdf_link": "https://openreview.net/pdf?id=c2C2NQKjZw", "keywords": "code completion, code generation, large language models, software engineering", "abstract": "Code completion, a key downstream task in code generation, is one of the most frequent and impactful methods for enhancing developer productivity in software development. As intelligent completion tools evolve, we need a robust evaluation benchmark that enables meaningful comparisons between products and guides future advancements. However, existing benchmarks focus more on coarse-grained tasks without industrial analysis resembling general code generation rather than the real-world scenarios developers encounter. Moreover, these benchmarks often rely on costly and time-consuming human annotation, and the standalone test cases fail to leverage minimal tests for maximum repository-level understanding and code coverage. To address these limitations, we first analyze business data from an industrial code completion tool and redefine the evaluation criteria to better align with the developer's intent and desired completion behavior throughout the coding process\nBased on these insights, we introduce Codev-Agent, an agent-based system that automates repository crawling, constructs execution environments, extracts dynamic calling chains from existing unit tests, and generates new test samples to avoid data leakage, ensuring fair and effective comparisons. Using Codev-Agent, we present the Code-Development Benchmark (Codev-Bench), a fine-grained, real-world, repository-level, and developer-centric evaluation framework. Codev-Bench assesses whether a code completion tool can capture a developer's immediate intent and suggest appropriate code across diverse contexts, providing a more realistic benchmark for code completion in modern software development.", "title_embedding_index": 14310, "title_abs_embedding_index": 14335}, {"title": "FreeSplatter: Pose-free Gaussian Splatting for Sparse-view 3D Reconstruction", "link_suffix": "/forum?id=VpGsy4hKMc", "link": "https://openreview.net/forum?id=VpGsy4hKMc", "pdf_link": "https://openreview.net/pdf?id=VpGsy4hKMc", "keywords": "Gaussian Splatting, 3D Reconstruction, Sparse-view Reconstruction, Camera Pose Estimation, Large Reconstruction Models", "abstract": "Existing sparse-view reconstruction models heavily rely on accurate known camera poses. However, deriving camera extrinsics and intrinsics from sparse-view images poses significant challenges. In this work, we present FreeSplatter, a highly scalable, feed-forward reconstruction framework capable of generating high-quality 3D Gaussians from uncalibrated sparse-view images and recovering their camera parameters in mere seconds. FreeSplatter is built upon a streamlined transformer architecture, consisting of sequential self-attention blocks that facilitate information exchange among multi-view image tokens and decode them into pixel-wise 3D Gaussian primitives. The predicted Gaussian primitives are situated in a unified reference frame, enabling high-fidelity 3D modeling and instant camera parameter estimation with off-the-shelf solvers. To cater to both object-centric and scene-level reconstruction, we train two model variants of FreeSplatter on a large amount of data. In both scenarios, FreeSplatter outperforms state-of-the-art baselines in terms of reconstruction quality and pose estimation accuracy. Furthermore, we showcase FreeSplatter's potential in enhancing the productivity of downstream applications, such as text/image-to-3D content creation.", "title_embedding_index": 14311, "title_abs_embedding_index": 14336}, {"title": "A Theoretically-Principled Sparse, Connected, and Rigid Graph Representation of Molecules", "link_suffix": "/forum?id=OIvg3MqWX2", "link": "https://openreview.net/forum?id=OIvg3MqWX2", "pdf_link": "https://openreview.net/pdf?id=OIvg3MqWX2", "keywords": "Graph representation, sparsity, connectivity, rigidity, molecules, learning", "abstract": "Graph neural networks (GNNs) -- learn graph representations by exploiting graph's sparsity, connectivity, and symmetries -- have become indispensable for learning geometric data like molecules. However, the most used graphs (e.g., radial cutoff graphs) in molecular modeling lack theoretical guarantees for achieving connectivity and sparsity simultaneously, which are essential for the performance and scalability of GNNs. Furthermore, existing widely used graph construction methods for molecules lack rigidity, limiting GNNs' ability to exploit graph nodes' spatial arrangement. In this paper, we introduce a new hyperparameter-free graph construction of molecules and beyond with sparsity, connectivity, and rigidity guarantees. Remarkably, our method consistently generates connected and sparse graphs with the edge-to-node ratio being bounded above by 3. Our graphs' rigidity guarantees that edge distances and dihedral angles are sufficient to uniquely determine general spatial arrangements of atoms. We substantiate the effectiveness and efficiency of our proposed graphs in various molecular modeling benchmarks.", "title_embedding_index": 14312, "title_abs_embedding_index": 14337}, {"title": "RA-TTA: Retrieval-Augmented Test-Time Adaptation for Vision-Language Models", "link_suffix": "/forum?id=V3zobHnS61", "link": "https://openreview.net/forum?id=V3zobHnS61", "pdf_link": "https://openreview.net/pdf?id=V3zobHnS61", "keywords": "vision-language models, test-time adaptation, retrieval-augmented strategy", "abstract": "Vision-language models (VLMs) are known to be susceptible to distribution shifts between pre-training data and test data, and test-time adaptation (TTA) methods for VLMs have been proposed to mitigate the detrimental impact of the distribution shifts. However, the existing methods solely rely on the internal knowledge encoded within the parameters, which are constrained to pre-training data. To complement the limitation of the internal knowledge, we proposeretrieval-augmented-TTA (RA-TTA)for adapting VLMs to test distribution usingexternalknowledge obtained from a web-scale image database. Fully exploiting the bi-modality of VLMs, fine-grainedtext descriptionsare used both for retrieving proper external images and refining VLMs' predictions with the retrieved external images. As a result, the pivotal features of test images are more precisely recognized through the text descriptions. \nExtensive evaluations on 17 datasets validate that RA-TTA outperforms the state-of-the-art methods by 2.49-8.45% on average.", "title_embedding_index": 14313, "title_abs_embedding_index": 14338}, {"title": "MLAE: Masked LoRA Experts for Visual Parameter-Efficient Fine-Tuning", "link_suffix": "/forum?id=ZEO9ibXr46", "link": "https://openreview.net/forum?id=ZEO9ibXr46", "pdf_link": "https://openreview.net/pdf?id=ZEO9ibXr46", "keywords": "Visual Parameter-Efficient Fine-Tuning, Pre-trained vision foundation models, Masking", "abstract": "In response to the challenges posed by the extensive parameter updates required for full fine-tuning of large-scale pre-trained models, parameter-efficient fine-tuning (PEFT) methods, exemplified by Low-Rank Adaptation (LoRA), have emerged. LoRA simplifies the fine-tuning process but may still struggle with a certain level of redundancy in low-rank matrices and limited effectiveness from merely increasing their rank. To address these issues, a natural idea is to enhance the independence and diversity of the learning process for the low-rank matrices. Therefore, we propose Masked LoRA Experts (MLAE), an innovative approach that applies the concept of masking to visual PEFT. Our method incorporates a cellular decomposition strategy that transforms a low-rank matrix into independent rank-1 submatrices, or \"experts\", thus enhancing independence. Additionally, we introduce a binary mask matrix that selectively activates these experts during training to promote more diverse and anisotropic learning, based on expert-level dropout strategies. Our investigations reveal that this selective activation not only enhances performance but also fosters a more diverse acquisition of knowledge with a marked decrease in parameter similarity among MLAE, significantly boosting the quality of the model while barely increasing the parameter count. Remarkably, MLAE achieves new state-of-the-art (SOTA) performance with an average accuracy score of 78.8% on the VTAB-1k benchmark and 90.9% on the FGVC benchmark, surpassing the previous SOTA method by an average of 0.8% on both benchmarks with approximately half parameters.", "title_embedding_index": 14314, "title_abs_embedding_index": 14339}, {"title": "Training-free Camera Control for Video Generation", "link_suffix": "/forum?id=KI1zldOFz9", "link": "https://openreview.net/forum?id=KI1zldOFz9", "pdf_link": "https://openreview.net/pdf?id=KI1zldOFz9", "keywords": "controllable generation, prior knowledge, training-free", "abstract": "We propose a training-free and robust solution to offer camera movement control for off-the-shelf video diffusion models. Unlike previous work, our method does not require any supervised finetuning on camera-annotated datasets or self-supervised training via data augmentation. Instead, it can be plugged and played with most pretrained video diffusion models and generate camera controllable videos with a single image or text prompt as input. The inspiration of our work comes from the layout prior that intermediate latents hold towards generated results, thus rearranging noisy pixels in them will make output content reallocated as well. As camera move could also be seen as a kind of pixel rearrangement caused by perspective change, videos could be reorganized following specific camera motion if their noisy latents change accordingly. Established on this, we propose our method CamTrol, which enables robust camera control for video diffusion models. It is achieved by a two-stage process. First, we model image layout rearrangement through explicit camera movement in 3D point cloud space. Second, we generate videos with camera motion using layout prior of noisy latents formed by a series of rearranged images. Extensive experiments have demonstrated the robustness our method holds in controlling camera motion of generated videos. Furthermore, we show that our method can produce impressive results in generating 3D rotation videos with dynamic content.", "title_embedding_index": 14315, "title_abs_embedding_index": 14340}, {"title": "CFD: Learning Generalized Molecular Representation via Concept-Enhanced Feedback Disentanglement", "link_suffix": "/forum?id=CsOIYMOZaV", "link": "https://openreview.net/forum?id=CsOIYMOZaV", "pdf_link": "https://openreview.net/pdf?id=CsOIYMOZaV", "keywords": "Molecular Representation, Generalization, Feedback Disentanglement, Concepts", "abstract": "To accelerate biochemical research, e.g., drug and protein discovery, molecular representation learning (MRL) has attracted much attention. However, most existing methods follow the closed-set assumption that training and testing data share identical distribution, which limits their generalization abilities in out-of-distribution (OOD) cases. In this paper, we explore designing a new disentangled mechanism for learning generalized molecular representation that exhibits robustness against distribution shifts. And an approach of Concept-Enhanced Feedback Disentanglement (CFD) is proposed, whose goal is to exploit the feedback mechanism to learn distribution-agnostic representation. Specifically, we first propose two dedicated variational encoders to separately decompose distribution-agnostic and spurious features. Then, a set of molecule-aware concepts are tapped to focus on invariant substructure characteristics. By fusing these concepts into the disentangled distribution-agnostic features, the generalization ability of the learned molecular representation could be further enhanced. Next, we execute iteratively the disentangled operations based on a feedback received from the previous output. Finally, based on the outputs of multiple feedback iterations, we construct a self-supervised objective to promote the variational encoders to possess the disentangled capability. In the experiments, our method is verified on multiple real-world molecular datasets. The significant performance gains over state-of-the-art baselines demonstrate that our method can effectively disentangle generalized molecular representation in the presence of various distribution shifts.", "title_embedding_index": 14316, "title_abs_embedding_index": 14341}, {"title": "ADAPT: Alzheimer's Diagnosis through Adaptive Profiling Transformers", "link_suffix": "/forum?id=SvpwQfO9H1", "link": "https://openreview.net/forum?id=SvpwQfO9H1", "pdf_link": "https://openreview.net/pdf?id=SvpwQfO9H1", "keywords": "Deep Learning for healthcare, Alzheimer's Diagnosis", "abstract": "Automated diagnosis of Alzheimer\u2019s Disease (AD) from brain imaging, such as\nmagnetic resonance imaging (MRI), has become increasingly important and has\nattracted the community to contribute many deep learning methods. However,\nmany of these methods are facing a trade-off that 3D models tend to be inefficient\nin training and inferencing while 2D models cannot capture the full 3D intricacies\nfrom the data. In this paper, we introduce a new model structure for diagnosing AD,\nand it can complete with 3D model\u2019s performances while essentially is a 2D method\n(thus computationally efficient). While the core idea lies in building different blocks\non different views according to physicians\u2019 diagnosing perspectives, we introduce\nmultiple components that can further benefit the model in this new perspective,\nincluding adaptively selecting the number of sclices in each dimension, and the new\nattention mechanism. In addition, we also introduce a morphology augmentation,\nwhich also barely introduces new computational loads, but can help improve the\ndiagnosis performances due to its alignment to the pathology of AD. We name\nour method ADAPT, which stands for Alzheimer\u2019s Diagnosis through Adaptive\nProfiling Transformers. We test our model from a practical perspective (the testing\ndomains do not appear in the training one): the diagnosis accuracy favors our\nADAPT with 4.5% improvement, while ADAPT uses at leat 14% less parameters\nthan the state-of-the-art models.", "title_embedding_index": 14317, "title_abs_embedding_index": 14342}, {"title": "A Catalyst Framework for the Quantum Linear System Problem via the Proximal Point Algorithm", "link_suffix": "/forum?id=XaARrKTNh3", "link": "https://openreview.net/forum?id=XaARrKTNh3", "pdf_link": "https://openreview.net/pdf?id=XaARrKTNh3", "keywords": "quantum linear system problem, proximal point algorithm, quantum algorithm, catalyst", "abstract": "Solving systems of linear equations is a fundamental problem, but it can be computationally intensive for classical algorithms in high dimensions. Existing quantum algorithms can achieve exponential speedups for the quantum linear system problem (QLSP) in terms of the problem dimension, but even such a theoretical advantage is bottlenecked by the condition number of the coefficient matrix. In this work, we propose a new quantum algorithm for QLSP inspired by the classical proximal point algorithm (PPA). Our proposed method can be viewed as a meta-algorithm that allows inverting a modified matrix via an existing \\texttt{QLSP_solver}, thereby directly approximating the solution vector instead of approximating the inverse of the coefficient matrix. By carefully choosing the step size $\\eta$, the proposed algorithm can effectively precondition the linear system to mitigate the dependence on condition numbers that hindered the applicability of previous approaches. Importantly, this is the first framework for QLSP where a tunable parameter $\\eta$ allows the user to control the trade-off between the runtime and the approximation error.", "title_embedding_index": 14318, "title_abs_embedding_index": 14343}, {"title": "Binarized Convolutional Neural Networks with Channel Quadrupling and Smooth Downsampling", "link_suffix": "/forum?id=WVWlO2tium", "link": "https://openreview.net/forum?id=WVWlO2tium", "pdf_link": "https://openreview.net/pdf?id=WVWlO2tium", "keywords": "Binarized Convolutional Neural Networks, Image Classification, Image Segmentation, Mobile-Friendly Convolutional Neural Networks", "abstract": "This paper proposes novel binarized convolutional neural networks (BCNNs) namedQB-NetandQSB-Net, specifically designed toQuadruple the number of channels and incorporate a so-calledSmooth downsampling inBCNNs for low-cost mobile environments. The proposed models combine FP32 depthwise separable (DS) convolutions with binarized $1 \\times 1$ pointwise convolutions, offering reduced computational costs in the pointwise convolutions. To enhance the degraded performance of the above naive combination, the proposed models start with a small number of channels in shallow layers and expand them during downsampling by a factor of four, effectively managing model complexity in the downsampling. The proposed model structure maintains low computational costs in the shallow blocks and increases model complexity in the deep blocks, providing a wider dynamic range to manage information in the frequency domain. As a result, the proposed models overcome the limitations of existing BCNNs, delivering improved performance while reducing the total computational costs. For further performance enhancements, we propose a novel smooth downsampling with heightwise and widthwise sequential downsampling steps, doubling the number of channels at each step. Besides, we show that the channelwise self-attention (SE) is applicable with minimal additional computational costs in the proposed models. Besides, multiple binarized convolutions in the fully-connected (FC) layer reduce storage costs without requiring 8-bit quantized convolutions. Experimental results demonstrate the efficiency of the proposed models in terms of performance, computational costs, and inference latency on real hardware. Notably, the QSB-Net-Large with SE achieve 71.2% Top-1 accuracy on ImageNet-1K and 69.2 mean intersection over union (mIoU) in the semantic segmentation on the PASCAL VOC dataset, outperforming other counterparts.", "title_embedding_index": 14319, "title_abs_embedding_index": 14344}, {"title": "RouGE: Learning Gated Experts for Segment Anything in the Wild", "link_suffix": "/forum?id=IKeYXtjvPL", "link": "https://openreview.net/forum?id=IKeYXtjvPL", "pdf_link": "https://openreview.net/pdf?id=IKeYXtjvPL", "keywords": "PEFT\uff0creal-world degradation\uff0c segment anything model\uff0c robustness enhancement", "abstract": "Segment anything model (SAM) and its variants have recently shown promising performance as foundation models. However, existing SAM-based models can only handle scenarios seen during training, and usually suffer unstable performance when transferring to real-world unseen data, such as low-light, rainy or blurred images, which is crucial for applications such as autopilot. Therefore, adapting SAM-based models for real-world degradation while not impairing its original ability remains an open challenge. In this work, we propose a novel gated Mixture-of-Experts (MoE) structure, called RouGE, to improve the robustness of SAM-based models. Specifically, RouGE uses multiple lightweight probability gates to decompose complex real-world image conditions and judge whether the feature needs to be adjusted as well as to what extent the adjustment needs to be done, then handle them differently with a set of low-rank experts. During the inference stage, RouGE processes input images in a completely blind manner thus improving the model's performance in real-world scenarios. Extensive experiments demonstrate that RouGE consistently achieves state-of-the-art results on both degraded and clean images compared with other methods while tuning only 1.5% of parameters.", "title_embedding_index": 14320, "title_abs_embedding_index": 14345}, {"title": "Towards Unbiased Learning in Semi-Supervised Semantic Segmentation", "link_suffix": "/forum?id=85G2t3yklD", "link": "https://openreview.net/forum?id=85G2t3yklD", "pdf_link": "https://openreview.net/pdf?id=85G2t3yklD", "keywords": "Semi-Supervised Semantic Segmentation", "abstract": "Semi-supervised semantic segmentation aims to learn from a limited amount of labeled data and a large volume of unlabeled data, which has witnessed impressive progress with the recent advancement of deep neural networks. However, existing methods tend to neglect the fact of class imbalance issues, leading to the Matthew effect, that is, the poorly calibrated model\u2019s predictions can be biased to- wards the majority classes and away from minority classes with fewer samples. In this work, we analyze the Matthew effect present in previous methods that hinder model learning from a discriminative perspective. In light of this background, we integrate generative models into semi-supervised learning, taking advantage of its their better class-imbalance tolerance. To this end, we propose DiffMatch to formulate the semi-supervised semantic segmentation task as a conditional discrete data generation problem to alleviate the Matthew effect of discriminative solutions from a generative perspective. Plus, to further reduce the risk of overfitting to the head classes and to increase coverage of the tail class distribution, we mathematically derive a debiased adjustment to adjust the conditional reverse probability towards unbiased predictions during each sampling step. Extensive experimental results on various domains (natural image/remote sensing image/medical image domains) across multiple benchmarks, especially in the most limited label scenarios with the most serious class imbalance issues, demonstrate that DiffMatch performs favorably against state-of-the-art methods. Code and models will be made available to facilitate future research.", "title_embedding_index": 14321, "title_abs_embedding_index": 14346}, {"title": "Multi-Objective Alignment of LLMs with ORPO using Self-Judgement", "link_suffix": "/forum?id=aYYZBPoSHb", "link": "https://openreview.net/forum?id=aYYZBPoSHb", "pdf_link": "https://openreview.net/pdf?id=aYYZBPoSHb", "keywords": "LLMs, preference optimization, self-judgement, LLM-as-a-judge, supervised fine-tuning, multi-objective optimization, multi-task learning, supervised learning", "abstract": "The alignment of Large Language Models (LLMs) is achieved through fine-tuning with human preference data, where preference optimization has become a critical part of the process. Many methods have scaled LLM performance by incorporating self-judgement, highlighting the importance of unifying LLM-as-a-judge with the alignment process. One such method, called Self-rewarding LLMs, iteratively samples new data from the model to improve alignment using self-judgement. Since this additional data is generated by the LLM, we argue that similar improvements can be achieved without new data. We propose a method that reuses alignment data in the form of a self-judgement classification task and defines a multi-objective optimization problem. Our self-judgement task is derived from a simple transformation of the primary alignment data, asking the LLM to select the superior response. It introduces no new data beyond the existing alignment data. Thus, we claim the improvements are due to positive interference between the two tasks. We focus on a direct preference optimization method called Odds-Ratio Preference Optimization (ORPO). We conduct a thorough study of linear scalarization on two objectives and introduce two alternative approaches that vary the emphasis on alignment versus self-judgement objectives. Our results on Mistral 7B indicate a promising direction for fine-tuning LLMs on multiple objectives, particularly for improving performance on related tasks without additional natural language data.", "title_embedding_index": 14322, "title_abs_embedding_index": 14347}, {"title": "Causal Effect Estimation with Mixed Latent Confounders and Post-treatment Variables", "link_suffix": "/forum?id=qe1CsfnN1W", "link": "https://openreview.net/forum?id=qe1CsfnN1W", "pdf_link": "https://openreview.net/pdf?id=qe1CsfnN1W", "keywords": "causal effect estimation, latent post-treatment bias, identifiable VAE", "abstract": "Causal inference from observational data has attracted considerable attention among researchers. One main obstacle to drawing valid causal conclusions is handling of confounders. As the direct measurement of confounders may not always be feasible, recent methods seek to address the confounding bias via proxy variables, i.e., variables postulated to be causally related to unobserved confounders. However, the selected proxies may scramble both latent confounders and latent post-treatment variables in practice, where existing methods risk biasing the estimation by unintentionally controlling for variables affected by the treatment. In this paper, we systematically investigate the bias of latent post-treatment variables, i.e., latent post-treatment bias, in causal effect estimation. We first derive the bias of existing covariate adjustment-based methods when selected proxies scramble both latent confounders and latent post-treatment variables, which we demonstrate can be arbitrarily bad. We then propose a novel Confounder-identifiable VAE (CiVAE) to address the bias. CiVAE is built upon a mild assumption that the prior of latent variables that generate the proxy belongs to a general exponential family with at least one invertible sufficient statistic in the factorized part. Based on this assumption, we show that latent confounders and latent post-treatment variables can be individually identified up to simple bijective transformations. We then prove that with individual identification, the intractable disentanglement problem of latent confounders and post-treatment variables can be transformed to a tractable conditional independence test problem. Finally, we prove that the true causal effects can be unbiasedly estimated with transformed confounders inferred by CiVAE. Experiments on both simulated and real-world datasets demonstrate that CiVAE is significantly more robust to latent post-treatment bias than existing methods.", "title_embedding_index": 14323, "title_abs_embedding_index": 14348}, {"title": "Dynamic Neural Graph: Facilitating Temporal Dynamics Learning in Deep Weight Space", "link_suffix": "/forum?id=CkoomnLfpS", "link": "https://openreview.net/forum?id=CkoomnLfpS", "pdf_link": "https://openreview.net/pdf?id=CkoomnLfpS", "keywords": "Dynamic Graph neural networks, Deep weight space, Implicit neural representations, Networks for networks, Neural graphs", "abstract": "The rapid advancements in using neural networks as implicit data representations have attracted significant interest in developing machine learning methods that analyze and process the weight spaces of other neural networks. However, efficiently handling these high-dimensional weight spaces remains challenging. Existing methods often overlook the sequential nature of layer-by-layer processing in neural network inference. In this work, we propose a novel approach using dynamic graphs to represent neural network parameters, capturing the temporal dynamics of inference. Our Dynamic Neural Graph Encoder (DNG-Encoder) processes these graphs, preserving the sequential nature of neural processing. Additionally, we also leverage DNG-Encoder to develop INR2JLS for facilitate downstream applications, such as classifying INRs.  Our approach demonstrates significant improvements across multiple tasks, surpassing the state-of-the-art INR classification accuracy by approximately 10% on the CIFAR-100-INR. The source\ncode has been made available in the supplementary materials.", "title_embedding_index": 14324, "title_abs_embedding_index": 14349}]
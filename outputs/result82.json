[
    {
        "title": "WardropNet: Traffic Flow Predictions via Equilibrium-Augmented Learning",
        "link_suffix": "/forum?id=7FHSPd3SRE",
        "link": "https://openreview.net/forum?id=7FHSPd3SRE",
        "pdf_link": "https://openreview.net/pdf?id=7FHSPd3SRE",
        "keywords": "structured learning, combinatorial optimization augmented machine learning, traffic equilibrium prediction",
        "abstract": "When optimizing transportation systems, anticipating traffic flows is a central element. Yet, computing such traffic equilibria remains computationally expensive. Against this background, we introduce a novel combinatorial optimization augmented neural network architecture that allows for fast and accurate traffic flow predictions. We propose WardropNet, a neural network that combines classical layers with a subsequent equilibrium layer: the first ones inform the latter by predicting the parameterization of the equilibrium problem's latency functions. Using supervised learning we minimize the difference between the actual traffic flow and the predicted output. We show how to leverage a Bregman divergence fitting the geometry of the equilibria, which allows for end-to-end learning. WardropNet outperforms pure learning-based approaches in predicting traffic equilibria for realistic and stylized traffic scenarios. On realistic scenarios, WardropNet improves on average for time-invariant predictions by up to 72% and for time-variant predictions by up to 23% over pure learning-based approaches."
    },
    {
        "title": "Channel-Wise Mixed-Precision Quantization for Large Language Models",
        "link_suffix": "/forum?id=M8uf26TbrC",
        "link": "https://openreview.net/forum?id=M8uf26TbrC",
        "pdf_link": "https://openreview.net/pdf?id=M8uf26TbrC",
        "keywords": "Quantization, Large language models, Mixed-precision quantization",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable success across a wide range of language tasks, but their deployment on edge devices remains challenging due to the substantial memory requirements imposed by their large parameter sizes. Weight-only quantization presents a promising solution to reduce the memory footprint of LLMs. However, existing approaches primarily focus on integer-bit quantization, limiting their adaptability to fractional-bit quantization tasks and preventing the full utilization of available storage space on devices. In this paper, we introduce Channel-Wise Mixed-Precision Quantization (CMPQ), a novel mixed-precision quantization method that allocates quantization precision in a channel-wise pattern based on activation distributions. By assigning different precision levels to different weight channels, CMPQ can adapt to any bit-width constraint. CMPQ employs a non-uniform quantization strategy and incorporates two outlier extraction techniques that collaboratively preserve the critical information, thereby minimizing the quantization loss. Experiments on different sizes of LLMs demonstrate that CMPQ not only enhances performance in integer-bit quantization tasks but also achieves significant performance gains with a modest increase in memory usage. CMPQ thus represents an adaptive and effective approach to LLM quantization, offering substantial benefits across diverse device capabilities."
    },
    {
        "title": "A shot of Cognac to forget bad memories: Corrective Unlearning in GNNs",
        "link_suffix": "/forum?id=sRdByVBvZq",
        "link": "https://openreview.net/forum?id=sRdByVBvZq",
        "pdf_link": "https://openreview.net/pdf?id=sRdByVBvZq",
        "keywords": "Unlearning, Graphs, Graph Neural Networks, GNN, Attacks, Manipulations, Removal",
        "abstract": "Graph Neural Networks (GNNs) are increasingly being used for a variety of ML applications on graph data.  As graph data does not follow the independently and identically distributed (i.i.d) assumption, adversarial manipulations or incorrect data can propagate to other datapoints through message passing, deteriorating the model's performance. To allow model developers to remove the adverse effects of manipulated entities from a trained GNN, we study the recently formulated problem ofCorrective Unlearning. We find that current graph unlearning methods fail to unlearn the effect of manipulations even when the whole manipulated set is known. We introduce a new graph unlearning method,Cognac, which can unlearn the effect of the manipulation set even when only $5$% of it is identified. It recovers most of the performance of a strong oracle with fully corrected training data, even beating retraining from scratch without the deletion set while being 8x more efficient. We hope our work guides GNN developers in fixing harmful effects due to issues in real-world data post-training."
    },
    {
        "title": "Reinforcement Learning from Wild Animal Videos",
        "link_suffix": "/forum?id=1EJIax7ekV",
        "link": "https://openreview.net/forum?id=1EJIax7ekV",
        "pdf_link": "https://openreview.net/pdf?id=1EJIax7ekV",
        "keywords": "Legged Locomotion, Imitation Learning from Videos, Reinforcement Learning",
        "abstract": "We propose to learn legged robot locomotion skills by watching thousands of wild animal videos from the internet, such as those featured in nature documentaries. Indeed, such videos offer a rich and diverse collection of plausible motion examples, which could inform how robots should move. To achieve this, we introduce Reinforcement Learning from Wild Animal Videos (RLWAV), a method to ground these motions into physical robots. We first train a video classifier on a large-scale animal video dataset to recognize actions from RGB clips of animals in their natural habitats. We then train a multi-skill policy to control a robot in a physics simulator, using the classification score of a third-person camera capturing videos of the robot's movements as a reward for reinforcement learning. Finally, we directly transfer the learned policy to a real quadruped Solo. Remarkably, despite the extreme gap in both domain and embodiment between animals in the wild and robots, our approach enables the policy to learn diverse skills such as walking, jumping, and keeping still, without relying on reference trajectories nor hand-designed rewards."
    },
    {
        "title": "To Clip or not to Clip: the Dynamics of SGD with Gradient Clipping in High-Dimensions",
        "link_suffix": "/forum?id=jmN1zXMq0O",
        "link": "https://openreview.net/forum?id=jmN1zXMq0O",
        "pdf_link": "https://openreview.net/pdf?id=jmN1zXMq0O",
        "keywords": "gradient clipping, high-dimensional probability, stochastic optimization, deep learning theory",
        "abstract": "The success of modern machine learning is due in part to the adaptive optimization methods that have been developed to deal with the difficulties of training large models over complex datasets. One such method is gradient clipping: a practical procedure with limited theoretical underpinnings. In this work, we study clipping in a least squares problem under streaming SGD. We develop a theoretical analysis of the learning dynamics in the limit of large intrinsic dimension—a model and dataset dependent notion of dimensionality. In this limit we find a deterministic equation that describes the evolution of the loss and demonstrate that this equation predicts the path of clipped SGD on synthetic, CIFAR10, and Wikitext2 data. We show that with Gaussian noise clipping cannot improve SGD performance. Yet, in other noisy settings, clipping can provide benefits with tuning of the clipping threshold. We propose a simple heuristic for near optimal scheduling of the clipping threshold which requires the tuning of only one hyperparameter. We conclude with a discussion about the links between high-dimensional clipping and neural network training."
    },
    {
        "title": "Towards Fully Autonomous Driving with Automated Commonsense Reasoning",
        "link_suffix": "/forum?id=V1N6MmDY27",
        "link": "https://openreview.net/forum?id=V1N6MmDY27",
        "pdf_link": "https://openreview.net/pdf?id=V1N6MmDY27",
        "keywords": "Commonsense Reasoning, Autonomous Vehicles, Uncertainty",
        "abstract": "Autonomous Vehicle (AV) technology has been heavily researched and sought after, yet there are no SAE Level 5 AVs available today in the marketplace. We contend that over-reliance on machine learning technology is the main reason. Use of automated commonsense reasoning technology, we believe, can help achieve SAE Level 5 autonomy. In this paper, we show how automated commonsense reasoning technology can be deployed in situations where not enough data is available to train a machine learning model for autonomous driving. Specifically, we consider two situations where (i) a traffic signal is malfunctioning at an intersection and (ii) all the cars ahead are slowing down and steering away due to an unexpected obstruction (e.g., animals on the road). We show that in such situations, our commonsense reasoning based solution performs correctly. We also provide a pathway for efficiently invoking commonsense reasoning by measuring uncertainty in the computer vision model and using commonsense reasoning to handle uncertain scenarios. We describe our experiments conducted using the CARLA simulator and the results obtained. The main contribution of our research is to show that automated commonsense reasoning provides an effective pathway to reach SAE level 5 automation."
    },
    {
        "title": "Discrete Diffusion Schrödinger Bridge Matching for Graph Transformation",
        "link_suffix": "/forum?id=tQyh0gnfqW",
        "link": "https://openreview.net/forum?id=tQyh0gnfqW",
        "pdf_link": "https://openreview.net/pdf?id=tQyh0gnfqW",
        "keywords": "Schrödinger Bridge, Discrete Diffusion Model, Molecular Optimization",
        "abstract": "Transporting between arbitrary distributions is a fundamental goal in generative modeling.\nRecently proposed diffusion bridge models provide a potential solution, but they rely on a joint distribution that is difficult to obtain in practice.\nFurthermore, formulations based on continuous domains limit their applicability to discrete domains such as graphs.\nTo overcome these limitations, we propose Discrete Diffusion Schrödinger Bridge Matching (DDSBM), a novel framework that utilizes continuous-time Markov chains to solve the SB problem in a high-dimensional discrete state space.\nOur approach extends Iterative Markovian Fitting to discrete domains, and we have proved its convergence to the SB.\nFurthermore, we adapt our framework for the graph transformation, and show that our design choice of underlying dynamics characterized by independent modifications of nodes and edges can be interpreted as the entropy-regularized version of optimal transport with a cost function described by the graph edit distance.\nTo demonstrate the effectiveness of our framework, we have applied DDSBM to molecular optimization in the field of chemistry.\nExperimental results demonstrate that DDSBM effectively optimizes molecules' property-of-interest with minimal graph transformation, successfully retaining other features.\nCode is availablehere."
    },
    {
        "title": "Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models",
        "link_suffix": "/forum?id=pWdUcV5axb",
        "link": "https://openreview.net/forum?id=pWdUcV5axb",
        "pdf_link": "https://openreview.net/pdf?id=pWdUcV5axb",
        "keywords": "Hallucination, multimodal large language models",
        "abstract": "Visual hallucination (VH) occurs when a multimodal large language model (MLLM) generates responses with incorrect visual details for prompts. Existing methods for generating VH test cases primarily rely on human annotations, typically in the form of triples: (image, question, answer). In this paper, we introduce VHExpansion, the first automated method for expanding VH test cases for MLLMs. Given an initial VH test case, VHExpansion automatically expands it by perturbing the question and answer through negation as well as modifying the image using both common and adversarial perturbations. Additionally, we propose a new evaluation metric, symmetric accuracy, which measures the proportion of correctly answered VH test-case pairs. Each pair consists of a test case and its negated counterpart. Our theoretical analysis shows that symmetric accuracy is an unbiased evaluation metric that remains unaffected by the imbalance of VH testing cases with varying answers when an MLLM is randomly guessing the answers, whereas traditional accuracy is prone to such imbalance. We apply VHExpansion to expand three VH datasets annotated manually and use these expanded datasets to benchmark seven MLLMs. Our evaluation shows that VHExpansion effectively identifies more VH test cases. Moreover, symmetric accuracy, being unbiased, leads to different conclusions about the vulnerability of MLLMs to VH compared to traditional accuracy metric. Finally, we show that fine-tuning MLLMs on the expanded VH dataset generated by VHExpansion mitigates VH more effectively than fine-tuning on the original, manually annotated dataset. We will publish code and data upon paper acceptance."
    },
    {
        "title": "Breaking Mental Set to Improve Reasoning through Diverse Multi-Agent Debate",
        "link_suffix": "/forum?id=t6QHYUOQL7",
        "link": "https://openreview.net/forum?id=t6QHYUOQL7",
        "pdf_link": "https://openreview.net/pdf?id=t6QHYUOQL7",
        "keywords": "Multi-Agent Debate, Large Language Models, Multimodal Large Language Models, Prompting, Self-Correction, Reasoning",
        "abstract": "Large Language Models (LLMs) have seen significant progress but continue to struggle with persistent reasoning mistakes. Previous methods of self-reflection have been proven limited due to the models’ inherent fixed thinking patterns. While Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents, it often employs the same reasoning methods, even though assigning different personas to models. This leads to a “fixed mental set,” where models rely on homogeneous thought processes without exploring alternative perspectives. In this paper, we introduce Diverse Multi-Agent Debate (DMAD), a method that encourages agents to think with distinct reasoning approaches. By leveraging diverse problem-solving strategies, each agent can gain insights from different perspectives, refining its responses through discussion and collectively arriving at the optimal solution. DMAD effectively breaks the limitations of fixed mental sets. We evaluate DMAD against various prompting techniques, including self-reflection and traditional MAD, across multiple benchmarks using both LLMs and Multimodal LLMs. Our experiments show that DMAD consistently outperforms other methods, delivering better results than MAD in fewer rounds."
    },
    {
        "title": "Dynamic Gradient Alignment for Online Data Mixing",
        "link_suffix": "/forum?id=O3SatrdL97",
        "link": "https://openreview.net/forum?id=O3SatrdL97",
        "pdf_link": "https://openreview.net/pdf?id=O3SatrdL97",
        "keywords": "LLM pretraining, data reweighing, data mixing",
        "abstract": "The composition of training data mixtures is critical for effectively training large language models (LLMs), as it directly impacts their performance on downstream tasks. Our goal is to identify an optimal data mixture to specialize an LLM for a specific task with access to only a few examples. Traditional approaches to this problem include ad-hoc reweighting methods, importance sampling, and gradient alignment techniques.\nThis paper focuses on gradient alignment and introduces Dynamic Gradient Alignment (DGA), a scalable online gradient alignment algorithm. DGA dynamically estimates the pre-training data mixture on which the models' gradients align as well as possible with those of the model on the specific task.\nDGA is the first gradient alignment approach that incurs minimal overhead compared to standard pre-training and outputs a competitive model, eliminating the need for retraining the model. Experimentally, we demonstrate significant improvements over importance sampling in two key scenarios: (i) when the pre-training set is small and importance sampling overfits due to limited data; and (ii) when there is insufficient specialized data, trapping importance sampling on narrow pockets of data.\nOur findings underscore the effectiveness of gradient alignment methods in optimizing training data mixtures, particularly in data-constrained environments, and offer a practical solution for enhancing LLM performance on specific tasks with limited data availability."
    },
    {
        "title": "Speaking Guided by Listening: Unsupervised Text-to-Speech Generative Model Guided by End-to-End Speech Recognition",
        "link_suffix": "/forum?id=Hd4jB1ErMk",
        "link": "https://openreview.net/forum?id=Hd4jB1ErMk",
        "pdf_link": "https://openreview.net/pdf?id=Hd4jB1ErMk",
        "keywords": "Text-to-speech, Diffusion, Unsupervised learning",
        "abstract": "We propose to utilize end-to-end automatic speech recognition (E2EASR) as a guidance model to realize unsupervised text-to-speech (TTS). An unconditional score-based generative model (SGM) is trained with untranscribed speech data. In the sampling stage, the unconditional score estimated by the SGM is combined with the gradients from ASR models by the Bayes rule to get the conditional score. We use a set of small ASR models trained only on $80$-hour labeled ASR data to guide the unconditional SGM and generate speech with high-quality scores in both objective and subjective evaluation. Similarly, we can also use additional speaker verification models to control speaker identity for the synthesized speech. That allows us to do the zero-shot TTS for the target speaker with a few seconds of enrollment speech. Our best unsupervised synthesized speech gets $\\sim8%$ word error rate in testing, and the best speaker-controlled TTS gets $3.3$ mean opinion score (MOS) in the speaker similarly testing."
    },
    {
        "title": "SubTrack your Grad: Gradient Subspace Tracking for Memory-Efficient LLM Training and Fine-Tuning",
        "link_suffix": "/forum?id=nR0n4R1Ck2",
        "link": "https://openreview.net/forum?id=nR0n4R1Ck2",
        "pdf_link": "https://openreview.net/pdf?id=nR0n4R1Ck2",
        "keywords": "large language models, memory-efficient fine-tuning, memory-efficient pre-training, optimization, subspace tracking, gradient space, low-rank optimization",
        "abstract": "Training and fine-tuning Large Language Models (LLMs) demand significant computational resources and time due to their large model sizes and optimizer states. To mitigate these challenges and improve accessibility, several memory-efficient methods have been developed. Methods such as Low-Rank Adaptation (LoRA) optimize model weights within a low-rank subspace, while Gradient Low-Rank Projection (GaLore) projects gradients into a lower-dimensional space to decrease memory footprint. In this paper, we propose Gradient Subspace Tracking (SubTrack-Grad), a method that confines optimization to a compact core subspace of the gradient matrices and dynamically tracks its changes using the geometry of Grassmannian manifolds. SubTrack-Grad efficiently updates its subspace estimation by leveraging estimation errors and previously identified subspaces. Our results demonstrate that even with rank-1 updates to the underlying subspace, SubTrack-Grad achieves comparable or superior performance to GaLore, while reducing runtime by approx. 15% on an average and up to 20.57% on some datasets. Furthermore, SubTrack-Grad exhibits only a minimal runtime increase compared to GaLore when the update frequency is increased, while controlling the extent of changes via rank-1 updates, allows more frequent updates without negatively impacting convergence."
    },
    {
        "title": "Predicting Spatial Transcriptomics from Histology Images via Biologically Informed Flow Matching",
        "link_suffix": "/forum?id=sYrdb3mhM4",
        "link": "https://openreview.net/forum?id=sYrdb3mhM4",
        "pdf_link": "https://openreview.net/pdf?id=sYrdb3mhM4",
        "keywords": "Spatial Transcriptomics; Histology Images",
        "abstract": "Spatial transcriptomics (ST) has emerged as a promising technology to bridge the gap between histology imaging and gene expression profiling. However, its application to medical diagnosis is limited due to its low throughput and the need for specialized experimental facilities. To address this issue, we develop STFlow, a flow-based generative model to predict spatial transcriptomics from whole-slide histology images. STFlow is trained with a biologically-informed flow matching algorithm that iteratively refines predicted gene expression values, where we choose zero-inflated negative binomial distribution as a prior distribution to incorporate the inductive bias of gene expression data. Compared to previous methods that predict the gene expression of each spot independently, STFlow models the interaction of genes across different spots to account for potential gene regulatory effects. On a recently curated HEST-1k benchmark, we demonstrate STFlow substantially outperforms all baselines including pathology foundation models, with over 18% relative improvement over current state-of-the-art."
    },
    {
        "title": "Tight Lower Bounds under Asymmetric High-Order Hölder Smoothness and Uniform Convexity",
        "link_suffix": "/forum?id=fMTPkDEhLQ",
        "link": "https://openreview.net/forum?id=fMTPkDEhLQ",
        "pdf_link": "https://openreview.net/pdf?id=fMTPkDEhLQ",
        "keywords": "Convex Optimization, Uniform Convexity, Lower Bound, High-Order Method, Regularization, Hölder Smoothness",
        "abstract": "In this paper, we provide tight lower bounds for the oracle complexity of minimizing high-order Hölder smooth and uniformly convex functions. Specifically, for a function whose $p^{th}$-order derivatives are Hölder continuous with degree $\\nu$ and parameter $H$, and that is uniformly convex with degree $q$ and parameter $\\sigma$, we focus on two asymmetric cases: (1) $q > p + \\nu$, and (2) $q < p+\\nu$. Given up to $p^{th}$-order oracle access, we establish worst-case oracle complexities of $\\Omega\\left( \\left( \\frac{H}{\\sigma}\\right)^\\frac{2}{3(p+\\nu)-2}\\left( \\frac{\\sigma}{\\epsilon}\\right)^\\frac{2(q-p-\\nu)}{q(3(p+\\nu)-2)}\\right)$ in the first case with an $\\ell_\\infty$-ball-truncated-Gaussian smoothed hard function and $\\Omega\\left(\\left(\\frac{H}{\\sigma}\\right)^\\frac{2}{3(p+\\nu)-2}+ \\log\\log\\left(\\left(\\frac{\\sigma^{p+\\nu}}{H^q}\\right)^\\frac{1}{p+\\nu-q}\\frac{1}{\\epsilon}\\right)\\right)$ in the second case, for reaching an $\\epsilon$-approximate solution in terms of the optimality gap. Our analysis generalizes previous lower bounds for functions under first- and second-order smoothness as well as those for uniformly convex functions, and furthermore our results match the corresponding upper bounds in this general setting."
    },
    {
        "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
        "link_suffix": "/forum?id=rAylWUIKtu",
        "link": "https://openreview.net/forum?id=rAylWUIKtu",
        "pdf_link": "https://openreview.net/pdf?id=rAylWUIKtu",
        "keywords": "Language Models, Datasets and Benchmarks, Model Evaluation, Data Contamination, Evaluation Gaming",
        "abstract": "The training data for many Large Language Models (LLMs) is contaminated with test data. This means that public benchmarks used to assess LLMs are compromised, suggesting a performance gap between benchmark scores and actual capabilities. Ideally, a private holdout set could be used to accurately verify scores. Unfortunately, such datasets do not exist for most benchmarks, and post-hoc construction of sufficiently similar datasets is non-trivial. To address these issues, we introduce a systematic methodology for (i) retrospectively constructing a holdout dataset for a target dataset, (ii) demonstrating the statistical indistinguishability of this retro-holdout dataset, and (iii) comparing LLMs on the two datasets to quantify the performance gap due to the dataset's public availability. Applying these methods to TruthfulQA, we construct and release Retro-Misconceptions, on which we evaluate twenty LLMs and find that some have inflated scores by as much as 16 percentage points. Our results demonstrate that public benchmark scores do not always accurately assess model properties, and underscore the importance of improved data practices in the field."
    },
    {
        "title": "Vietnamese Text-to-SQL with Large Language Models: A Comprehensive Approach",
        "link_suffix": "/forum?id=cWFLrctwuE",
        "link": "https://openreview.net/forum?id=cWFLrctwuE",
        "pdf_link": "https://openreview.net/pdf?id=cWFLrctwuE",
        "keywords": "Text-to-SQL, Large Language Models, Few-shot, Chain-of-thought, Mini Schema, ViText2SQL, SQL",
        "abstract": "In the current era of Artificial Intelligence (AI), the realm of database querying is experiencing a profound evolution. With the recent emergence of Large Language Models (LLMs), with a particular emphasis on Vietnamese in this study, a promising opportunity arises to bridge the gap between human language and database interactions. In this paper, we embark on realizing this vision through a three-pronged approach. Firstly, we introduce a few-shot learning method designed to enhance the database schema comprehension of Vietnamese LLMs. Secondly, we employ a chain-of-thought technique to systematically guide LLMs in capturing complex natural language expressions for SQL generation. Thirdly, we introduce a novel method to streamline the input schema by removing redundant parts and retaining only the parts that are truly relevant to enhance the efficiency and accuracy of the SQL generation process. Finally, we experimented with a combination of few-shot, chain-of-thought learning, and schema-enhancing methods. Through experimentation with augmented datasets, we observe encouraging initial results. Our approach outperforms the current state-of-the-art model by 23% in exact matching on the Vietnamese ViText2SQL dataset. We achieved this result with a single pretraining step and one epoch of retraining, compared to the SoTA model's 10 epochs. These findings demonstrate the effectiveness of our method and its potential for Vietnamese text-to-SQL applications."
    },
    {
        "title": "Learning on LoRAs: GL-Equivariant Processing of Low-Rank Weight Spaces for Large Finetuned Models",
        "link_suffix": "/forum?id=cZOPrf5WLu",
        "link": "https://openreview.net/forum?id=cZOPrf5WLu",
        "pdf_link": "https://openreview.net/pdf?id=cZOPrf5WLu",
        "keywords": "LoRA, Weight-space learning, Foundation models, Finetuning, Equivariance",
        "abstract": "Low-rank adaptations (LoRAs) have revolutionized the finetuning of large foundation models, enabling efficient adaptation even with limited computational resources. The resulting proliferation of LoRAs presents exciting opportunities for applying machine learning techniques that take these low-rank weights themselves as inputs.  In this paper, we investigate the potential of Learning on LoRAs (LoL), a paradigm where LoRA weights serve as input to machine learning models. For instance, an LoL model that takes in LoRA weights as inputs could predict the performance of the finetuned model on downstream tasks, detect potentially harmful finetunes, or even generate novel model edits without traditional training methods.  We first identify the inherent parameter symmetries of low rank decompositions of weights, which differ significantly from the parameter symmetries of standard neural networks. To efficiently process LoRA weights, we develop several symmetry-aware invariant or equivariant LoL models, using tools such as canonicalization, invariant featurization, and equivariant layers. We finetune thousands of text-to-image diffusion models and language models to collect datasets of LoRAs. In numerical experiments on these datasets, we show that our LoL architectures are capable of processing low rank weight decompositions to predict CLIP score, finetuning data attributes, finetuning data membership, and accuracy on downstream tasks."
    },
    {
        "title": "CBM-zero: Concept Bottleneck Model With Zero Performance Loss",
        "link_suffix": "/forum?id=wpL3otU9eY",
        "link": "https://openreview.net/forum?id=wpL3otU9eY",
        "pdf_link": "https://openreview.net/pdf?id=wpL3otU9eY",
        "keywords": "interpretability, explainability, concept bottleneck model",
        "abstract": "Interpreting machine learning models with high-level, human-understandable \\emph{concepts} has gained increasing interest. The concept bottleneck model (CBM) is a popular approach to providing interpretable models, relying on first predicting the presence of concepts in a given input, and then using these concept scores to predict a label of interest. Yet, CBMs suffer from lower accuracy compared with standard black-box models, as they use a surrogate (and thus, interpretable) predictor in lieu of the original model. In this work, we propose an approach that allows us to find a CBM in any standard black-box model via an invertible mapping from its latent space to an interpretable concept space. This method preserves the original black-box model's prediction and thus has zero performance drop while providing human-understandable explanations. We evaluate the accuracy and interpretability of our method across various benchmarks, demonstrating state-of-the-art explainability metrics while enjoying superior accuracy."
    },
    {
        "title": "LayoutRL: A Reinforcement Learning-Based Approach to Keyboard Layout Optimization",
        "link_suffix": "/forum?id=feykAFeSfq",
        "link": "https://openreview.net/forum?id=feykAFeSfq",
        "pdf_link": "https://openreview.net/pdf?id=feykAFeSfq",
        "keywords": "Layout Optimization, Ergonomics, Data-driven Optimization, Interaction Design, Reinforcement learning, HCI",
        "abstract": "Keyboards are a key interface between humans and computers, with character arrangements offering numerous layout possibilities. Many existing designs follow standardized ergonomic principles and explore Pareto-optimality in multi-objective functions using metaheuristics or deep learning. In this work, we propose a reinforcement learning-based approach to designing optimized keyboard layouts that integrate both technical and ergonomic considerations. Our results demonstrate that reinforcement learning optimization can produce layouts more efficiently than conventional designs, such as the \"QWERTY\" keyboard. Specifically, our approach achieves approximately an 12.4% improvement in ergonomic parameters over traditional keyboards, underscoring the potential for a more data-driven, systematic approach to keyboard layout optimization."
    },
    {
        "title": "Generalization of FedAvg Under Constrained Polyak-Lojasiewicz Type Conditions: A Single Hidden Layer Neural Network Analysis",
        "link_suffix": "/forum?id=b9ZG7cI8ic",
        "link": "https://openreview.net/forum?id=b9ZG7cI8ic",
        "pdf_link": "https://openreview.net/pdf?id=b9ZG7cI8ic",
        "keywords": "FedAvg, Linear Convergence, Generalization, Neural Network",
        "abstract": "In this work, we study the optimization and the generalization performance of the widely used FedAvg algorithm for solving Federated Learning (FL) problems. We analyze the generalization performance of FedAvg by handling the optimization error and the Rademacher complexity. Towards handling optimization error, we propose novel constrained Polyak-Lojasiewicz (PL)-type conditions on the objective function that ensure the existence of a global optimal to which FedAvg converges linearly after $\\mathcal{O}( \\log ({1}/{\\epsilon}))$ rounds of communication, where $\\epsilon$ is the desired optimality gap. Importantly, we demonstrate that a class of single hidden layer neural networks satisfies the proposed constrained PL-type conditions required to establish the linear convergence of FedAvg as long as $m > {nK}/{d}$, where $m$ is the width of the neural network, $K$ is the number of clients, $n$ is the number of samples at each client, and $d$ is the feature dimension. We then bound the Rademacher complexity for this class of neural networks and establish that both Rademacher complexity and the generalization error of FedAvg decrease at an optimal rate of $\\mathcal{O}({1}/{\\sqrt{n}})$. We further show that increasing the number of clients $K$ decreases the generalization error at the rate of $\\mathcal{O}({1}/{\\sqrt{n}} + {1}/{\\sqrt{nK}})$."
    },
    {
        "title": "Sparsing Law: Towards Large Language Models with Greater Activation Sparsity",
        "link_suffix": "/forum?id=B9XP2R9LtG",
        "link": "https://openreview.net/forum?id=B9XP2R9LtG",
        "pdf_link": "https://openreview.net/pdf?id=B9XP2R9LtG",
        "keywords": "activation sparsity, large language model",
        "abstract": "Activation sparsity denotes the existence of substantial weakly-contributed elements within activation outputs that can be eliminated, benefiting many important applications concerned with large language models (LLMs), such as computation acceleration and model interpretability. Although promoting greater activation sparsity within LLMs deserves deep studies, existing works lack comprehensive and quantitative research on the correlation between activation sparsity and potentially influential factors. In this paper, we present a comprehensive study on the quantitative scaling properties and influential factors of the activation sparsity within decoder-only Transformer-based LLMs. Specifically, we propose PPL-$p%$ sparsity, a precise and performance-aware activation sparsity metric that is applicable to any activation function. Through extensive experiments, we find several important phenomena. Firstly, different activation functions (i.e., ReLU and SiLU) exhibit comparable performance but opposite training-time sparsity trends. The activation ratio (i.e., $1-\\mathrm{sparsity\\ ratio}$) evolves as a convergent increasing power-law and decreasing logspace power-law with the amount of training data for SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate that ReLU is more efficient as the activation function than SiLU and can leverage more training data to improve activation sparsity. Secondly, the activation ratio linearly increases with the width-depth ratio below a certain bottleneck point, indicating the potential advantage of a deeper architecture at a fixed parameter scale. Finally, at similar width-depth ratios, we surprisingly find that the limit value of activation sparsity varies weakly with the parameter scale, i.e., the activation patterns within LLMs are insensitive to the parameter scale. These empirical laws towards LLMs with greater activation sparsity have important implications for making LLMs more efficient and interpretable."
    },
    {
        "title": "Resolution Attack: Exploiting Image Compression to Deceive Deep Neural Networks",
        "link_suffix": "/forum?id=OFukl9Qg8P",
        "link": "https://openreview.net/forum?id=OFukl9Qg8P",
        "pdf_link": "https://openreview.net/pdf?id=OFukl9Qg8P",
        "keywords": "Resolution Attack、Image Generation、Deep Learning Robustness、Image Classification",
        "abstract": "Model robustness is essential for ensuring the stability and reliability of machine learning systems. Despite extensive research on various aspects of model robustness, such as adversarial robustness and label noise robustness, the exploration of robustness towards different resolutions, particularly high-resolution images, remains less explored. To address this gap, we introduce a novel form of attack: the resolution attack. This attack aims to deceive both classifiers and human observers by generating images that exhibit different semantics across different resolutions. To implement the resolution attack, we propose an automated framework capable of generating dual-semantic images in a zero-shot manner. Specifically, we leverage large-scale diffusion models for their comprehensive ability to construct images and propose a staged denoising strategy to achieve a smoother transition across resolutions. Through the proposed framework, we conduct resolution attacks against various off-the-shelf classifiers. The experimental results exhibit high attack success rate, which not only validates the effectiveness of our proposed framework but also reveals the vulnerability of current classifiers towards different resolutions. Additionally, our framework, which incorporates features from two distinct objects, serves as a competitive tool for applications such as face swapping and facial camouflage. We will release our code to the public upon acceptance."
    },
    {
        "title": "PolygoNet: Leveraging Simplified Polygonal Representation for Effective Shape Classification",
        "link_suffix": "/forum?id=x4lmFlfFKX",
        "link": "https://openreview.net/forum?id=x4lmFlfFKX",
        "pdf_link": "https://openreview.net/pdf?id=x4lmFlfFKX",
        "keywords": "Shape Classification; Polygonal representation; Computational Efficiency; Self-Attention Mechanism;",
        "abstract": "Deep learning models have achieved significant success in various image-related tasks. However, they often encounter challenges related to computational complexity and overfitting. In this paper, we propose an approach that leverages efficient polygonal representations of input images by utilizing either dominant points or coordinates of contours. Our method transforms input images into polygonal forms using one of these techniques, which are then employed to train deep neural networks. This representation offers a concise and flexible depiction of images. By converting images into either dominant points or contour coordinates, we substantially reduce the computational burden associated with processing large image datasets. This reduction not only accelerates the training process but also conserves computational resources, rendering our approach suitable for real-time applications and resource-constrained environments. Additionally, these representations facilitate improved generalization of the trained models. Both dominant points and contour coordinates inherently capture essential features of the input images while filtering out noise and irrelevant details, providing an inherent regularization effect that mitigates overfitting. Our approach results in lightweight models that can be efficiently deployed on edge devices, making it highly applicable for scenarios with limited computational resources. Despite the reduced complexity, our method achieve performance comparable to state-of-the-art methods that use full images as input. We validate our approach through extensive experiments on benchmark datasets, demonstrating its effectiveness in reducing computation, preventing overfitting, and enabling deployment on edge computing platforms. Overall, this work presents a methodology in image processing that leverages polygonal representations through either dominant points or contour coordinates to streamline computations, mitigate overfitting, and produce lightweight models suitable for edge computing. These findings indicate that this approach holds significant potential for advancing the field of deep learning by enabling efficient, accurate, and scalable solutions in real-world applications. The code for the experiments of the paper are provided at \\url{https://anonymous.4open.science/r/PolygoNet-7374}"
    },
    {
        "title": "On the Diversity of Synthetic Data and its Impact on Training Large Language Models",
        "link_suffix": "/forum?id=oqsQbn4XfT",
        "link": "https://openreview.net/forum?id=oqsQbn4XfT",
        "pdf_link": "https://openreview.net/pdf?id=oqsQbn4XfT",
        "keywords": "Synthetic Data Pre-training, Large Language Models",
        "abstract": "The rise of Large Language Models (LLMs) has accentuated the need for diverse, high-quality pre-training data. \nSynthetic data emerges as a viable solution to the challenges of data scarcity and inaccessibility.\nWhile previous literature has focused predominantly on the quality and quantity of real data, our work enables the measurement of diversity in synthetic data and explores its impact on LLM performance. \nWe study the downstream effects of synthetic data diversity during both the pre-training and fine-tuning stages by introducing a new diversity metric, LLM cluster-agent, designed to evaluate the diversity of synthetic datasets. \nThrough a series of controlled experiments with models of 350M and 1.4B parameters, we demonstrate that the proposed cluster-based LLM scoring of diversity correlates positively with both pre-training and supervised fine-tuning performance. \nOur findings also reveal that synthetic data diversity in pre-training affects supervised fine-tuning more significantly than pre-training itself, even for smaller models. \nWe hope this study advances our understanding of the optimal use of synthetic data in LLM training and opens new avenues for efficient data generation processes."
    },
    {
        "title": "SLMRec: Empowering Small Language Models for Sequential Recommendation",
        "link_suffix": "/forum?id=G4wARwjF8M",
        "link": "https://openreview.net/forum?id=G4wARwjF8M",
        "pdf_link": "https://openreview.net/pdf?id=G4wARwjF8M",
        "keywords": "Large Language Models; Knowledge Distillation",
        "abstract": "Sequential Recommendation (SR) task involves predicting the next item a user is likely to interact with, given their past interactions. \nThe SR models examine the sequence of a user's actions to discern more complex behavioral patterns and temporal dynamics. \nRecent research demonstrates the great impact of LLMs on sequential recommendation systems, either viewing sequential recommendation as language modeling or serving as the backbone for user representation. Although these methods deliver outstanding performance, there is scant evidence of the necessity of a large language model and how large the language model is needed, especially in the sequential recommendation scene. Meanwhile, due to the huge size of LLMs, it is inefficient and impractical to apply a LLM-based model in real-world platforms that often need to process billions of traffic logs daily. In this paper, we explore the influence of LLMs' depth by conducting extensive experiments on large-scale industry datasets. Surprisingly, our motivational experiments reveal that most intermediate layers of LLMs are redundant, indicating that pruning the remaining layers can still maintain strong performance.\nMotivated by this insight, we empower small language models for SR, namely SLMRec, which adopt a simple yet effective knowledge distillation method. Moreover, SLMRec is orthogonal to other post-training efficiency techniques, such as quantization and pruning, so that they can be leveraged in combination. Comprehensive experimental results illustrate that the proposed SLMRec model attains the best performance using only 13% of the parameters found in LLM-based recommendation models while simultaneously achieving up to 6.6x and 8.0x speedups in training and inference time costs, respectively. Besides, we provide a theoretical justification for why small language models can perform comparably to large language models in SR."
    }
]
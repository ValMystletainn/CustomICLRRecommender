[
    {
        "title": "Bayesian Binary Search",
        "link_suffix": "/forum?id=PiOhaDXuXa",
        "link": "https://openreview.net/forum?id=PiOhaDXuXa",
        "pdf_link": "https://openreview.net/pdf?id=PiOhaDXuXa",
        "keywords": "bayesian, binary search, bitcoin, lightning network",
        "abstract": "We present Bayesian Binary Search (BBS), a novel probabilistic variant of the classical binary search/bisection algorithm. BBS leverages machine learning/statistical techniques to estimate the probability density of the search space and modifies the bisection step to split based on probability density rather than the traditional midpoint, allowing for the learned distribution of the search space to guide the search algorithm. Search space density estimation can flexibly\nbe performed using supervised probabilistic machine learning techniques (e.g., Gaussian process regression, Bayesian neural networks, quantile regression) or unsupervised learning algorithms (e.g., Gaussian mixture models, kernel density estimation (KDE), maximum likelihood estimation (MLE)). We demonstrate significant efficiency gains of using BBS on both simulated data across a variety of distributions and in a real-world binary search use case of probing channel balances in the Bitcoin Lightning Network, for which we have deployed the BBS algorithm in a production setting."
    },
    {
        "title": "Model-Driven Labeled Data Free Fine-tuning",
        "link_suffix": "/forum?id=nA9SCxGy2M",
        "link": "https://openreview.net/forum?id=nA9SCxGy2M",
        "pdf_link": "https://openreview.net/pdf?id=nA9SCxGy2M",
        "keywords": "Fine-tuning, unsupervised learning, foundation models",
        "abstract": "Supervised fine-tuning is a prevalent technique for boosting model performance. However, it heavily depends on extensive training over labeled data. This paper introduces a novel model-driven fine-tuning method that operates independently of supervised training and labeled data. By harnessing the collective intelligence of a diverse model pool, our method enhances individual model performance through a two-phase process. Initially, we consolidate the expertise of the models within the pool to create a general meta-model. This meta-model then serves as a guide for iteratively fine-tuning the original models in a few shots, promoting a synergistic improvement in performance. Our experimental results show that this model-driven approach not only surpasses the performance of full-parameter fine-tuning models but also does so without the need for supervised training. This breakthrough offers a cost-effective and scalable alternative to traditional supervised fine-tuning, addressing the challenge of data scarcity and paving the way for future research in unsupervised model enhancement. Our work represents a significant step towards making fine-tuning techniques more accessible and practical in environments where labeled data is limited or even unavailable."
    },
    {
        "title": "DataSciBench: An LLM Agent Benchmark for Data Science",
        "link_suffix": "/forum?id=BltaWJZMeR",
        "link": "https://openreview.net/forum?id=BltaWJZMeR",
        "pdf_link": "https://openreview.net/pdf?id=BltaWJZMeR",
        "keywords": "data science, data analysis and visualization, benchmarking language model, large language models",
        "abstract": "This paper presents DataSciBench, a comprehensive benchmark for evaluating Large Language Model (LLM) capabilities in data science.\nRecent related benchmarks have primarily focused on single tasks, easily obtainable ground truth, and straightforward evaluation metrics, which limits the scope of tasks that can be evaluated. In contrast, DataSciBench is constructed based on a more comprehensive and curated collection of natural and challenging prompts. We develop a semi-automated pipeline for generating ground truth (GT) and validating evaluation metrics. This pipeline utilizes and implements an LLM-based self-consistency strategy to produce accurate GT by leveraging collected prompts, predefined task types, and aggregate metrics. Furthermore, it employs a careful approach to filter a high-quality Task - Function - Code (TFC) list and assess each code execution outcome within TFC based on precisely defined metrics and programmatic rules. Our experimental framework involves testing 6 API-based models, 8 open-source general models, and 9 open-source code generation models using the diverse set of prompts we have gathered. Through this approach, we aim to provide a more comprehensive and rigorous evaluation of LLMs in the domain of data science, shedding light on their strengths and weaknesses. Experimental results demonstrate that API-based models greatly outperform open-sourced models on all metrics except for VLM-as-a-judge and Deepseek-Coder-33b-instruct achieves the highest score among open-sourced models."
    },
    {
        "title": "Unsupervised Learning of Categorical Structure",
        "link_suffix": "/forum?id=IwxxnY98sf",
        "link": "https://openreview.net/forum?id=IwxxnY98sf",
        "pdf_link": "https://openreview.net/pdf?id=IwxxnY98sf",
        "keywords": "geometry, interpretability, abstraction, factorization, compositionality, disentanglement, hierarchy",
        "abstract": "Humans are known to reason using logic and abstract categories, and yet most state of the art neural models use continuous distributed representations. These representations offer impressive gradient-based learning capabilities, but it is often difficult to know what symbolic algorithm the network might implicitly be implementing, if any. We find that there are representational geometries that naturally suggest a symbolic structure, which can be expressed in terms of binary components. We show that we can recover this structure by fitting the geometry of this binary embedding to the representational geometry of the original objects. After establishing general facts and providing some intuitions, we present two algorithms that work on low-rank or full-rank data, respectively. We assess their reliability on simulated data, and then use them to interpret neural word embeddings, in which we expect a compositional structure."
    },
    {
        "title": "Hierarchical Subspaces of Policies for Continual Offline Reinforcement Learning",
        "link_suffix": "/forum?id=G6iREzfcZ7",
        "link": "https://openreview.net/forum?id=G6iREzfcZ7",
        "pdf_link": "https://openreview.net/pdf?id=G6iREzfcZ7",
        "keywords": "Reinforcement Learning, Continual Reinforcement Learning, Offline Learning, Hierarchical Policies, Navigation",
        "abstract": "In dynamic domains such as autonomous robotics and video game simulations, agents must continuously adapt to new tasks while retaining previously acquired skills. This ongoing process, known as Continual Reinforcement Learning, presents significant challenges, including the risk of forgetting past knowledge and the need for scalable solutions as the number of tasks increases. To address these issues, we introduce HIerarchical LOW-rank Subspaces of Policies (HILOW), a novel framework designed for continual learning in offline navigation settings. HILOW leverages hierarchical policy subspaces to enable flexible and efficient adaptation to new tasks while preserving existing knowledge. We demonstrate, through a careful experimental study,  the effectiveness of our method in both classical MuJoCo maze environments and complex video game-like simulations, showcasing competitive performance and satisfying adaptability according to classical continual learning metrics, in particular regarding memory usage. Our work provides a promising framework for real-world applications where continuous learning from pre-collected data is essential."
    },
    {
        "title": "R2: A LLM Based Novel-to-Screenplay Generation Framework with Causal Plot Graphs",
        "link_suffix": "/forum?id=Sxi6gBtJcI",
        "link": "https://openreview.net/forum?id=Sxi6gBtJcI",
        "pdf_link": "https://openreview.net/pdf?id=Sxi6gBtJcI",
        "keywords": "Novel-to-Screenplay Generation, Plot Graphs, Large Lanuage Models, Self-Refinement",
        "abstract": "Automatically adapting novels into screenplays is important for the TV, film, or opera industries to promote products with low costs. The strong performances of large language models (LLMs) in long-text generation call us to propose a LLM based framework Reader-Rewriter (R$^2$) for this task. However, there are two fundamental challenges here. First, the LLM hallucinations may cause inconsistent plot extraction and screenplay generation. Second, the causality-embedded plot lines should be effectively extracted for coherent rewriting. Therefore, two corresponding tactics are proposed: 1) A hallucination-aware refinement method (HAR) to iteratively discover and eliminate the affections of hallucinations; and 2) a causal plot-graph construction method (CPC) based on a greedy cycle-breaking algorithm to efficiently construct plot lines with event causalities. Recruiting those efficient techniques, R$^2$ utilizes two modules to mimic the human screenplay rewriting process: The Reader module adopts a sliding window and CPC to build the causal plot graphs, while the Rewriter module generates first the scene outlines based on the graphs and then the screenplays. HAR is integrated into both modules for accurate inferences of LLMs. Experimental results demonstrate the superiority of R$^2$, which substantially outperforms three existing approaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison at the overall win rate for GPT-4o."
    },
    {
        "title": "Large Language Model Critics for Execution-Free Evaluation of Code Changes",
        "link_suffix": "/forum?id=gDWkImLIKd",
        "link": "https://openreview.net/forum?id=gDWkImLIKd",
        "pdf_link": "https://openreview.net/pdf?id=gDWkImLIKd",
        "keywords": "Code Evaluation; Large Language Models; Execution-free Evaluation; Agents",
        "abstract": "Large language models (LLMs) offer a promising way forward for automating software engineering tasks, such as bug fixes, feature additions, etc., via multi-step LLM-based agentic workflows. However, existing metrics for evaluating such workflows, mainly  build status and occasionally log analysis, are too sparse and limited in providing the information needed to assess the quality of changes made. In this work, we designed LLM-based critics to derive well-structured and rigorous intermediate/step-level, execution-free evaluation proxies for repo-level code changes. Importantly, we assume access to the gold patch for the problem (i.e., reference-aware) to assess both semantics and executability of generated patches. With the gold test patch as a reference, we predict executability of all editing locations with an accuracy of 91.6%, aggregating which, we can predict the build status in 82.1% of the instances in SWE-bench. In particular, such an execution-focused LLM critic outperforms other reference-free and reference-aware LLM critics by 38.9% to 72.5%. Moreover, we demonstrate the usefulness of such a reference-aware framework in comparing patches generated by different agentic workflows. Finally, we open-source the library developed for this project, which allow further usage for either other agentic workflows or other benchmarks."
    },
    {
        "title": "Multimodal Graph-LLM: Leveraging Graph-Enhanced LLMs for Multimodal Healthcare Predictions",
        "link_suffix": "/forum?id=Gh1XW314zF",
        "link": "https://openreview.net/forum?id=Gh1XW314zF",
        "pdf_link": "https://openreview.net/pdf?id=Gh1XW314zF",
        "keywords": "EHR, multimodal, LLM, graphs, healthcare",
        "abstract": "Multimodal healthcare research is crucial for improving clinical decision-making by integrating diverse data types, such as clinical notes, lab results, and imaging. Large Language Models (LLMs) are widely recognized for their exceptional text-based reasoning capabilities, making them effective in processing complex clinical narratives. However, they struggle to incorporate multimodal data, limiting their broader applicability in healthcare analysis. In this work, we propose MG-LLM (Multimodal Graph-LLM), a novel framework that leverages the strengths of LLMs while enhancing them with multimodal alignment and data integration through Graph Neural Networks (GNNs). GNNs propagate information across similar patients, model temporal relationships between visits, and align information from different modalities, creating enriched multimodal context vectors. These context vectors are then injected into the intermediate layers of the LLM, allowing it to harness both textual reasoning and multimodal data for more accurate predictions. We evaluate MG-LLM on the MIMIC-IV and MIMIC-CXR datasets, demonstrating significant improvements in clinical prediction tasks compared to baseline models. Our results showcase the potential of combining the text reasoning power of LLMs with GNN-driven multimodal alignment for robust, comprehensive healthcare analysis."
    },
    {
        "title": "Quantum (Inspired)D2-sampling with Applications",
        "link_suffix": "/forum?id=tDIL7UXmSS",
        "link": "https://openreview.net/forum?id=tDIL7UXmSS",
        "pdf_link": "https://openreview.net/pdf?id=tDIL7UXmSS",
        "keywords": "quantum, clustering, k-means++",
        "abstract": "$D^2$-sampling is a fundamental component of sampling-based clustering algorithms such as $k$-means++. Given a dataset  $V \\subset \\mathbb{R}^d$ with $N$ points and a center set $C \\subset \\mathbb{R}^d$, $D^2$-sampling refers to picking a point from $V$ where the sampling probability of a point is proportional to its squared distance from the nearest center in $C$. Starting with empty $C$ and iteratively $D^2$-sampling and updating $C$ in $k$ rounds is precisely $k$-means++ seeding that runs in $O(Nkd)$ time and gives $O(\\log{k})$-approximation in expectation for the $k$-means problem. We give a quantum algorithm for (approximate) $D^2$-sampling in the QRAM model that results in a quantum implementation of $k$-means++ that runs in time $\\tilde{O}(\\zeta^2 k^2)$. Here $\\zeta$ is the aspect ratio (i.e., largest to smallest interpoint distance), and $\\tilde{O}$ hides polylogarithmic factors in $N, d, k$. It can be shown through a robust approximation analysis of $k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation guarantee. Further, we show that our quantum algorithm for $D^2$-sampling can be 'dequantized' using the sample-query access model of Tang (PhD Thesis, Ewin Tang, University of Washington, 2023). This results in a fast quantum-inspired classical implementation of $k$-means++, which we call QI-$k$-means++, with a running time $O(Nd) + \\tilde{O}(\\zeta^2k^2d)$, where the $O(Nd)$ term is for setting up the sample-query access data structure. Experimental investigations show promising results for QI-$k$-means++ on large datasets with bounded aspect ratio. Finally, we use our quantum $D^2$-sampling with the known $ D^2$-sampling-based classical approximation scheme (i.e., $(1+\\varepsilon)$-approximation for any given $\\varepsilon>0$) to obtain the first quantum approximation scheme for the $k$-means problem with polylogarithmic running time dependence on $N$."
    },
    {
        "title": "Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations",
        "link_suffix": "/forum?id=0pbxX2jatP",
        "link": "https://openreview.net/forum?id=0pbxX2jatP",
        "pdf_link": "https://openreview.net/pdf?id=0pbxX2jatP",
        "keywords": "Language Models, AI Safety, Natural Language Processing, Inconsistency, Transparency, Military",
        "abstract": "There is an increasing interest in using language models (LMs) for automated decision-making, with multiple countries actively testing LMs to aid in military crisis decision-making. To scrutinize relying on LM decision-making in high-stakes settings, we examine the inconsistency of responses in a crisis simulation (\"wargame\"), similar to reported tests conducted by the US military. Prior work illustrated escalatory tendencies and varying levels of aggression among LMs but were constrained to simulations with pre-defined actions. This was due to the challenges associated with quantitatively measuring semantic differences and evaluating natural language decision-making without relying on pre-defined actions. In this work, we query LMs for free form responses and use a metric based on BERTScore to measure response inconsistency quantitatively. Leveraging the benefits of BERTScore, we show that the inconsistency metric is robust to linguistic variations that preserve semantic meaning in a question-answering setting across text lengths. We show that all five tested LMs exhibit levels of inconsistency that indicate semantic differences, even when adjusting the wargame setting, anonymizing involved conflict countries, or adjusting the sampling temperature parameter $T$. Further qualitative evaluation shows that models recommend courses of action that share few to no similarities. We also study the impact of different prompt sensitivity variations on inconsistency at temperature $T = 0$. We find that inconsistency due to semantically equivalent prompt variations can exceed response inconsistency from temperature sampling for most studied models across different levels of ablations. Given the high-stakes nature of military deployment, we recommend further consideration be taken before using LMs to inform military decisions or other cases of high-stakes decision-making."
    },
    {
        "title": "Non-Adversarial Inverse Reinforcement Learning via Successor Feature Matching",
        "link_suffix": "/forum?id=LvRQgsvd5V",
        "link": "https://openreview.net/forum?id=LvRQgsvd5V",
        "pdf_link": "https://openreview.net/pdf?id=LvRQgsvd5V",
        "keywords": "Inverse Reinforcement Learning, Imitation Learning, Successor Features",
        "abstract": "In inverse reinforcement learning (IRL), an agent seeks to replicate expert demonstrations through interactions with the environment. Traditionally, IRL is treated as an adversarial game, where an adversary searches over reward models, and a learner optimizes the reward through repeated RL procedures.\nThis game-solving approach is both computationally expensive and difficult to stabilize.\nIn this work, we propose a novel approach to IRL by direct policy optimization: exploiting a linear factorization of the return as the inner product of successor features and a reward vector, we design an IRL algorithm by policy gradient descent on the gap between the learner and expert features.\nOur non-adversarial method does not require learning a reward function and can be solved seamlessly with existing actor-critic RL algorithms.\nRemarkably, our approach works in state-only settings without expert action labels, a setting which behavior cloning (BC) cannot solve.\nEmpirical results demonstrate that our method learns from as few as a single expert demonstration and achieves improved performance on various control tasks."
    },
    {
        "title": "Distribution Shift Aware Neural Feature Transformation",
        "link_suffix": "/forum?id=TXjYOslkUh",
        "link": "https://openreview.net/forum?id=TXjYOslkUh",
        "pdf_link": "https://openreview.net/pdf?id=TXjYOslkUh",
        "keywords": "Feature Transformation, Out-of-Distribution (OOD), Data-centric AI",
        "abstract": "Feature transformation, as a core task of Data-centric AI (DCAI), aims to improve the original feature set to enhance AI capabilities. In dynamic real-world environments, where there exists a distribution shift, feature knowledge may not be transferable between data. This matter prompts a distribution shift feature transformation (DSFT) problem. Prior research works for feature transformation either depend on domain expertise, rely on a linear assumption, prove inefficient for large feature spaces, or demonstrate vulnerability to imperfect data. Furthermore, existing techniques for addressing the distribution shift cannot be directly applied to discrete search problems. DSFT presents two primary challenges: 1) How can we reformulate and solve feature transformation as a learning problem? and 2) What mechanisms can integrate shift awareness into such a learning paradigm? To tackle these challenges, we leverage a unique Shift-aware Representation-Generation Perspective. To formulate a learning scheme, we construct a representation-generation framework: 1) representation step: encoding transformed feature sets into embedding vectors; 2) generation step: pinpointing the best embedding and decoding as a transformed feature set. To mitigate the issue of distribution shift, we propose three mechanisms: 1) shift-resistant representation, where embedding dimension decorrelation and sample reweighing are integrated to extract the true representation that contains invariant information under distribution shift; 2) flatness-aware generation, where several suboptimal embeddings along the optimization trajectory are averaged to obtain a robust optimal embedding, proving effective for diverse distribution; and 3) shift-aligned pre and post-processing, where normalizing and denormalizing align and recover distribution gaps between training and testing data. Ultimately, extensive experiments are conducted to indicate the effectiveness, robustness, and trackability of our proposed framework."
    },
    {
        "title": "MAGE: Leveraging LLMs for Automated Mapper Generation in Parallel Programming",
        "link_suffix": "/forum?id=iM7MfzbF1B",
        "link": "https://openreview.net/forum?id=iM7MfzbF1B",
        "pdf_link": "https://openreview.net/pdf?id=iM7MfzbF1B",
        "keywords": "large language models, reinforcement learning, domain-specific language, discrete optimization, performance optimization",
        "abstract": "Efficiently mapping tasks to processors and data to memories is a cornerstone of parallel programming to achieve high performance. Traditionally, this critical task has been handled by expert-crafted mapper programs, tailored for specific machine architectures and problem domains. However, creating customized mappers for each unique application is labor-intensive and time-consuming. Large language models (LLMs) have recently demonstrated remarkable capabilities in understanding and generating code, as well as in self-improvement for optimizing specific performance metrics. Inspired by these advancements, we introduce the task of mapper generation (MAGE), which frames generating high-performance mappers as a discrete optimization problem aimed at maximizing compute throughput. To solve this optimization problem, we leverage reinforcement learning (RL) to guide LLMs in the mapper generation process. At the core of our approach lies a novel domain-specific language (DSL), which provides a high-level interface for LLMs to generate the mapper code without getting entangled with complicated, low-level system programming. Moreover, our DSL defines a structured and constrained search space for RL to explore, guiding LLMs to discover the optimal mapping policy. The evaluation shows that our LLM-generated mappers can surpass expert-written mappers in performance, achieving up to 34% speedup across 9 benchmarks. Notably, our approach improves the throughput of parallel matrix multiplication algorithms by up to 31%, reducing development time from several days to just a few minutes."
    },
    {
        "title": "GEPCode: A Context-Aware 1M-Parameters Graph-Based Language Model for Source Code",
        "link_suffix": "/forum?id=DgGdQo3iIR",
        "link": "https://openreview.net/forum?id=DgGdQo3iIR",
        "pdf_link": "https://openreview.net/pdf?id=DgGdQo3iIR",
        "keywords": "graph neural network, graph language model, source code optimization",
        "abstract": "The pursuit of optimal conditions for software execution poses a complex challenge. This task can be automated by harnessing the structured nature of programming languages, especially from compiler intermediate representations of code (IR). The manipulation of source code using Large Language Models (LLMs) is a thriving area of study in Natural Language Processing (NLP) literature. However, in this study we illustrate how we can circumvent the need for exceedingly large models by employing domain-specific language models. These models have a reduced number of parameters but retain the ability to capture the relationships within source code elements. We introduce GEPCode, a graph neural network designed to model IR with the flexibility to adapt to new tasks. This flexibility is obtained through special \"meta\" nodes, that allow for the representation of additional task-dependent contextual information. Pre-training is performed by solving node and graph-level tasks, resulting in a general language model. After a fine-tuning phase on two downstream tasks, Device Mapping and Algorithm Classification, we achieve average accuracy results of 88.9% (NVIDIA) and 92.3% (AMD) for the former and 97.2% for the latter. Comparing our methodology with state-of-the-art models trained from scratch, our results are similar or better, yet providing a more flexible model. Moreover, we achieve similar accuracy results in downstream tasks compared to state-of-the-art pre-trained language models based on Transformers, while utilizing 100 times fewer parameters."
    },
    {
        "title": "A Hierarchical Language Model Design For Interpretable Graph Reasoning",
        "link_suffix": "/forum?id=DRSSLefryd",
        "link": "https://openreview.net/forum?id=DRSSLefryd",
        "pdf_link": "https://openreview.net/pdf?id=DRSSLefryd",
        "keywords": "Language models, Interpretability, Graph reasoning",
        "abstract": "Large language models (LLMs) have seen an increased adoption for tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering, and knowledge probing. However, despite their remarkable success in text-based tasks, LLMs' capabilities in understanding explicit graph structures remain limited, preventing them from fully replacing Graph Neural Networks (GNNs) in graph-centric applications. In this work, we introduce a Hierarchical Language Model (HLM-G) Design that employs a two-block architecture to effectively capture local and global graph information, significantly enhancing graph structure understanding. Our model achieves a new state-of-the-art in graph understanding, outperforming both GNN and LLM baselines. It demonstrates robustness to variations in graph-descriptive prompts, overcoming a key limitation of existing LLMs. Furthermore, we demonstrate the interpretability of our model using intrinsic attention weights and established explainers. Comprehensive evaluations across diverse real-world datasets, covering node, link, and graph-level tasks, highlight our model's superior generalization capabilities, marking a significant advancement in the application of LLMs to graph-centric tasks."
    },
    {
        "title": "A Large Recurrent Action Model: xLSTM enables Fast Inference for Robotics Tasks",
        "link_suffix": "/forum?id=T1pUS4GZZq",
        "link": "https://openreview.net/forum?id=T1pUS4GZZq",
        "pdf_link": "https://openreview.net/pdf?id=T1pUS4GZZq",
        "keywords": "reinforcement learning, rnn, xlstm, mamba, multi-task, robotics",
        "abstract": "In recent years, there has been a trend in the field of Reinforcement Learning (RL) towards large action models trained offline on large-scale datasets via sequence modeling. Existing models are primarily based on the Transformer architecture, which results in powerful agents. However, due to slow inference times, Transformer-based approaches are impractical for real-time applications, such as robotics. Recently, modern recurrent architectures, such as xLSTM and Mamba, have been proposed that exhibit parallelization benefits during training similar to the Transformer architecture while offering fast inference. In this work, we study the aptitude of these modern recurrent architectures for large action models. Consequently, we propose a Large Recurrent Action Model (LRAM) with an xLSTM at its core that comes with linear-time inference complexity and natural sequence length extrapolation abilities. Experiments on 432 tasks from 6 domains show that LRAM compares favorably to Transformers in terms of performance and speed."
    },
    {
        "title": "Robust Graph Attention for Graph Adversarial Attacks: An Information Bottleneck Inspired Approach",
        "link_suffix": "/forum?id=lTL4t68BNc",
        "link": "https://openreview.net/forum?id=lTL4t68BNc",
        "pdf_link": "https://openreview.net/pdf?id=lTL4t68BNc",
        "keywords": "Graph Adversarial Attacks, Robust Graph Attention, Information Bottleneck",
        "abstract": "Graph Neural Networks (GNNs) have shown exceptional performance in learning node representations for node-level tasks such as node classification. However, traditional message-passing mechanisms solely based on graph structure in GNNs make them vulnerable to adversarial attacks. Attention-based GNNs have been utilized to improve the robustness of GNNs due to their capabilities to selectively emphasize informative signals over noisy or less relevant ones. However, existing works on robust graph attention methods do not realize the correlation between improved robustness and better adherence to the IB principle of attention-based GNNs. In this work, we find that the IB loss of attention-based GNNs is a strong indicator of their robustness against variant graph adversarial attacks. Attention-based GNNs with lower IB loss learn node representations that correlate less to the input training data while aligning better with the target outputs. Due to better adhering to the IB principle, attention-based GNNs with lower IB loss usually show stronger robustness against graph adversarial attacks. Inspired by such observation, we propose a novel graph attention method termed Robust Graph Attention inspired by Information Bottleneck, or RGA-IB, which explicitly minimizes the IB loss of a multi-layer GNN through a carefully designed graph attention mechanism.\nExtensive experiment results on semi-supervised node classification under variant graph adversarial attacks show that GNNs equipped with RGA-IB exhibit lower IB loss, which indicates better adherence to the IB principle, and show significantly improved node classification accuracy under graph adversarial attacks compared to existing robust GNNs. The code of RGA-IB is available at \\url{https://anonymous.4open.science/r/RGA-IB-A47F/}."
    },
    {
        "title": "Embodied Referring Expression Comprehension Through Multimodal Residual Learning",
        "link_suffix": "/forum?id=oMkHoJjLXB",
        "link": "https://openreview.net/forum?id=oMkHoJjLXB",
        "pdf_link": "https://openreview.net/pdf?id=oMkHoJjLXB",
        "keywords": "embodied, multimodal, visual-language",
        "abstract": "Comprehending embodied interactions within real-world settings poses a considerable challenge, attributed to the multifaceted nature of human interactions and the variability of environments, necessitating the development of comprehensive benchmark datasets and multimodal learning models. Existing datasets do not adequately represent the full spectrum of human interactions, are limited by perspective bias, rely on single viewpoints, have insufficient nonverbal gesture capture, and have a predominant focus on indoor settings. To address these gaps, we present an Embodied Referring Expressions dataset (called Refer360), which contains an extensive collection of embodied verbal and nonverbal interaction data captured from various viewpoints across various indoor and outdoor settings. In conjunction with this benchmark dataset, we propose a novel multimodal guided residual module (MuRes) that helps the existing multimodal models to improve their representations. This guided residual module acts as an information bottleneck to extract salient modality-specific representations, and reinforcing these to the pre-trained representations produces robust complementary representations for downstream tasks. Our extensive experimental analysis of our benchmark Refer360 dataset reveals that existing multimodal models alone fail to capture human interactions in real-world scenarios comprehensively for embodied referring expression comprehension tasks. Building on these findings, a thorough analysis of four benchmark datasets demonstrates superior performance by augmenting MuRes into current multimodal models, highlighting its capability to improve the understanding and interaction with human-centric environments. This paper offers a benchmark for the research community and marks a stride towards developing robust systems adept at navigating the complexities of real-world human interactions."
    },
    {
        "title": "Can You Trust Your Experiments? Generalizability of Experimental Studies",
        "link_suffix": "/forum?id=ja5nxiozl8",
        "link": "https://openreview.net/forum?id=ja5nxiozl8",
        "pdf_link": "https://openreview.net/pdf?id=ja5nxiozl8",
        "keywords": "Generalizability, Replicability, External Validity, Experiment, Experimental Study, Benchmark, Evaluation",
        "abstract": "Experimental studies are a cornerstone of Machine Learning (ML) research. \nA common and often implicit assumption is that the study's results will generalize beyond the study itself, e.g., to new data.\nThat is, repeating the same study under different conditions will likely yield similar results. \nExisting frameworks to measure generalizability, borrowed from the casual inference literature, cannot capture the complexity of the results and the goals of an ML study. \nThe problem of measuring generalizability in the more general ML setting is thus still open, also due to the lack of a mathematical formalization of experimental studies.\nIn this paper, we propose such a formalization, use it to develop a framework to quantify generalizability, and propose an instantiation based on rankings and the Maximum Mean Discrepancy.\nWe show how this latter offers insights into the desirable number of experiments for a study. \nFinally, we investigate the generalizability of two recently published experimental studies."
    },
    {
        "title": "Soup to go: mitigating forgetting during continual learning with model averaging",
        "link_suffix": "/forum?id=n2EU4PUrJP",
        "link": "https://openreview.net/forum?id=n2EU4PUrJP",
        "pdf_link": "https://openreview.net/pdf?id=n2EU4PUrJP",
        "keywords": "Continual learning, model merging, fine-tuning",
        "abstract": "In continual learning with pretrained large language models (LLMs), where data from instruction fine-tuning (IFT) tasks arrives in a sequence, fine-tuning on later tasks will often lead to performance degradation on earlier tasks. \nThis is especially pronounced when the IFT tasks come from diverse domains.\nIn this setting, how can we mitigate catastrophic forgetting of earlier tasks and retain what the LLM has learned?\nInspired by a classical continual learning method, L2 penalty to previous weights, we propose Sequential Fine-tuning with Averaging (SFA), a method that merges models with earlier checkpoints trained on previous tasks during the course of training. \nSOTA approaches typically maintain a data buffer of past tasks or impose a penalty at each gradient step. However, our method achieves comparable results without the need to store past data, or multiple copies of parameters for each gradient step. \nFurthermore, our method outperforms penalty methods like L2 regression and EWC, as well as other common merging techniques such as Task Arithmetic, and TIES Merging.\nFinally, we show that using our method, a single model can simultaneously perform well on a range of fine-tuning tasks in diverse domains, including Math, Law and Code."
    },
    {
        "title": "Leveraging Color Channel Independence for Improved Unsupervised Object Detection",
        "link_suffix": "/forum?id=gRrjx9GzRP",
        "link": "https://openreview.net/forum?id=gRrjx9GzRP",
        "pdf_link": "https://openreview.net/pdf?id=gRrjx9GzRP",
        "keywords": "object detection, visual reasoning, segmentation, unsupervised learning, object centric representation learning, computer vision",
        "abstract": "Object-centric architectures can learn to extract distinct object representations from visual scenes, enabling downstream applications on the object level. \nSimilarly to autoencoder-based image models, object-centric approaches have been trained on the unsupervised reconstruction loss of images encoded by RGB color spaces. \nIn our work, we challenge the common assumption that RGB images are the optimal target for unsupervised learning in computer vision.\nWe discuss conceptually and empirically that other color spaces, such as HSV, bear essential characteristics for object-centric representation learning, like robustness to lighting conditions. We further show that models improve when requiring them to predict additional color channels.\nSpecifically, we propose the RGB-S space, which extends RGB with HSV's saturation component and leads to markedly better reconstruction and disentanglement for five common evaluation datasets.\nThe use of composite color spaces can be implemented with basically no computational overhead, is agnostic of the models' architecture, and is universally applicable across a wide range of visual computing tasks and training types. \nThe findings of our approach encourage additional investigations in computer vision tasks beyond object-centric learning."
    },
    {
        "title": "Generalization from Starvation: Hints of Universality in LLM Knowledge Graph Learning",
        "link_suffix": "/forum?id=f7aWmxgSN4",
        "link": "https://openreview.net/forum?id=f7aWmxgSN4",
        "pdf_link": "https://openreview.net/pdf?id=f7aWmxgSN4",
        "keywords": "Knowledge Graph Learning, Interpretability, Generalization, Universality",
        "abstract": "Motivated by interpretability and reliability, we investigate how neural networks represent knowledge during graph learning. We find hints of universality, where equivalent representations are learned across a range of model sizes (from $10^2$ to $10^9$ parameters) and contexts (MLP toy models, LLM in-context learning and LLM training). We show that these attractor representations optimize generalization to unseen examples by exploiting properties of knowledge graph relations (e.g. symmetry and meta-transitivity). We find experimental support for such universality by showing that LLMs and simpler neural networks can be successfully stitched, i.e., by stitching the first part of one model to the last part of another, mediated only by an affine or almost affine transformation. We hypothesize that this dynamic toward simplicity and generalization is driven by ``intelligence from starvation”: where overfitting is minimized by pressure to minimize the use of resources that are either scarce or competed for against other tasks."
    },
    {
        "title": "MatExpert: Decomposing Materials Discovery By Mimicking Human Experts",
        "link_suffix": "/forum?id=AUBvo4sxVL",
        "link": "https://openreview.net/forum?id=AUBvo4sxVL",
        "pdf_link": "https://openreview.net/pdf?id=AUBvo4sxVL",
        "keywords": "Material Discovery, Large Language Models (LLMs), Material Generation, Crystal Structure Generation, Contrastive Learning",
        "abstract": "Material discovery is a critical research area with profound implications for various industries. In this work, we introduce MatExpert, a novel framework that leverages Large Language Models (LLMs) and contrastive learning to accelerate the discovery and design of new solid-state materials. Inspired by the workflow of human materials design experts, our approach integrates three key stages: retrieval, transition, and generation. First, in the retrieval stage, MatExpert identifies an existing material that closely matches the desired criteria. Second, in the transition stage, MatExpert outlines the necessary modifications to transform this material formulation to meet specific requirements outlined by the initial user query. Third, in the generation state, MatExpert performs detailed computations and structural generation to create a new material based on the provided information. Our experimental results demonstrate that MatExpert outperforms state-of-the-art methods in material generation tasks, achieving superior performance across various metrics including validity, distribution, and stability. As such, MatExpert represents a meaningful advancement in computational material discovery using langauge-based generative models."
    },
    {
        "title": "EMERGENCE OF GROUNDED, OPTIMALLY COMPOSITIONAL SPATIAL LANGUAGE AMONG HOMOGENEOUS AGENTS",
        "link_suffix": "/forum?id=nyuaoVnVCa",
        "link": "https://openreview.net/forum?id=nyuaoVnVCa",
        "pdf_link": "https://openreview.net/pdf?id=nyuaoVnVCa",
        "keywords": "multi-agent reinforcement learning, Language Emergence, Cultural Evolution",
        "abstract": "A mechanism of effective communication is integral to human existence. An\nessential aspect of a functional communication scheme among a rational human\npopulation involves an efficient,  adaptive, and coherent apparatus to convey one’s goal to others. Such an effective macro characteristic can\nemerge in a finite population through adaptive learning via trial and error\nat the individual (micro) level, with nearly consistent individual learning faculty and experience across the population. In this paper, we study and hypothesize\n pertinent aspects of glossogenetics, specifically primal human communication mechanisms, through computational modeling. In particular, we model the\nprocess as a language game within the fabric of a decentralized, multi-agent\ndeep reinforcement learning setting, where the agents with local learning and neural\ncognitive faculties interact through a series of dialogues. Our homogeneous agents seek to achieve the principle of least effort and overcome the poverty of stimulus through efficient concept selection, guided feedback and mirror learning. In our examinations,\nwe observe the emergence of successful and structured communication among static and dynamic agent populations through consistent and continual learning."
    },
    {
        "title": "Wasserstein Flow Matching: Generative modeling over families of distributions",
        "link_suffix": "/forum?id=HB4lr0ykTi",
        "link": "https://openreview.net/forum?id=HB4lr0ykTi",
        "pdf_link": "https://openreview.net/pdf?id=HB4lr0ykTi",
        "keywords": "Optimal Transport, Flow Matching, Point Clouds, Generative Modeling, Single Cell",
        "abstract": "Generative modeling typically concerns the transport of a single source distribution to a single target distribution by learning (i.e., regressing onto) simple probability flows. However, in modern data-driven fields such as computer graphics and single-cell genomics, samples (say, point-clouds) from datasets can themselves be viewed as distributions (as, say, discrete measures). In these settings, the standard generative modeling paradigm of flow matching would ignore the relevant geometry of the samples. To remedy this, we propose \\emph{Wasserstein flow matching} (WFM), which appropriately lifts flow matching onto families of distributions by appealing to the Riemannian nature of the Wasserstein geometry. Our algorithm leverages theoretical and computational advances in (entropic) optimal transport, as well as the attention mechanism in our neural network architecture. We present two novel algorithmic contributions. First, we demonstrate how to perform generative modeling over Gaussian distributions, where we generate representations of granular cell states from single-cell genomics data. Secondly, we show that WFM can learn flows between high-dimensional and variable sized point-clouds and synthesize cellular microenvironments from spatial transcriptomics datasets. Code is available athttps://github.com/WassersteinFlowMatching/WassersteinFlowMatching"
    }
]
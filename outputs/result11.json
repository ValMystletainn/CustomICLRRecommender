[
    {
        "title": "Two Heads are Better than One: Retrieval Augmented LLM for Question Answering with External Knowledge Attention",
        "link_suffix": "/forum?id=5swfKRkCx7",
        "link": "https://openreview.net/forum?id=5swfKRkCx7",
        "pdf_link": "https://openreview.net/pdf?id=5swfKRkCx7",
        "keywords": "question answering, large language modeling, retrieval augmented generation, knowledge",
        "abstract": "Retrieval-augmented generation (RAG) of large language models (LLMs) has recently attracted significant attention owing to their ability to address knowledge gaps in generating reliable answers for specific questions. Existing RAG approaches typically optimize the knowledge processing by filtering out irrelevant or incorrect information and restructuring it for model input, improving the accuracy of answers to given questions. A general approach in doing so is to combine the retrieved knowledge with the input inquiry, which are then fed into the LLM to produce an answer. This approach requires the LLM to have strong knowledge comprehension and reasoning capabilities to effectively utilize the useful information, which may lead to errors when it fails to correctly interpret relevant knowledge. In this paper, we propose a novel approach to augmenting LLMs with external knowledge attention for question answering (QA), where the attention is functionalized as an extra head that integrated with the internal heads used in LLMs. We develop a memory-based mechanism that dynamically controls the degree of knowledge integration with the extra head based on the relationship between the question and the retrieved knowledge, and allows for differentiated fusion of external knowledge and LLM ability at its different layers. Experiments on both general and specific-domain QA tasks demonstrate the effectiveness of our approach, highlighting its potential to optimize LLMs for similar challenges."
    },
    {
        "title": "Exploring Compositionality in Vision Transformers using Wavelet Representations",
        "link_suffix": "/forum?id=9dFCm4uZo8",
        "link": "https://openreview.net/forum?id=9dFCm4uZo8",
        "pdf_link": "https://openreview.net/pdf?id=9dFCm4uZo8",
        "keywords": "Vision Transfomers, Explainability, Compositionality, Latent Representations",
        "abstract": "Insights into the workings of the transformer have been elicited by analyzing its representations when trained and tested on language data. In this paper, we turn an analytical lens to the representations of variants of the Vision Transformers. This work is aimed to gain insights into the geometric structure of the latent spaces of each encoding layer. We use representation-similarity measures, and representation-visualization approaches to analyse the impact of training regimes on the latent manifolds learned. We then use our approach to design a test for quantifying the extent to which these latent manifolds respect the compositional structure of the input space. We restrict our analysis to compositional structure induced by the Discrete Wavelet Transform (DWT). Interestingly, our empirical analysis reveals that ViT patch representations give notions of compositionality with respect to the DWT primitives."
    },
    {
        "title": "UniCBE: An Uniformity-driven Comparing Based Evaluation Framework with Unified Multi-Objective Optimization",
        "link_suffix": "/forum?id=rpwGUtTeA5",
        "link": "https://openreview.net/forum?id=rpwGUtTeA5",
        "pdf_link": "https://openreview.net/pdf?id=rpwGUtTeA5",
        "keywords": "evaluation, efficient, scalability, accuracy, convergence",
        "abstract": "Human preference plays a significant role in measuring large language models and guiding them to align with human values. Unfortunately, current comparing-based evaluation (CBE) methods typically focus on a single optimization objective, failing to effectively utilize scarce yet valuable preference signals. To address this, we delve into key factors that can enhance the accuracy, convergence, and scalability of CBE: suppressing sampling bias, balancing descending process of uncertainty, and mitigating updating uncertainty.\nFollowing the derived guidelines, we propose UniCBE, a unified uniformity-driven CBE framework which simultaneously optimize these core objectives by constructing and integrating three decoupled sampling probability matrices, each designed to ensure uniformity in specific aspects. We further ablate the optimal tuple sampling and preference aggregation strategies to achieve efficient CBE.\nOn the AlpacaEval benchmark, UniCBE saves over 17% of evaluation budgets while achieving a Pearson correlation with ground truth exceeding 0.995, demonstrating excellent accuracy and convergence. In scenarios where new models are continuously introduced, UniCBE can even save over 50% of evaluation costs, highlighting its improved scalability."
    },
    {
        "title": "TeacherActivityNet: A Novel Dataset for Monitoring Faculty Activities in Office Settings",
        "link_suffix": "/forum?id=TadxJc1XAE",
        "link": "https://openreview.net/forum?id=TadxJc1XAE",
        "pdf_link": "https://openreview.net/pdf?id=TadxJc1XAE",
        "keywords": "Workplace Monitoring, Activity Tracking, YOLOTAN, TeacherActivityNet, Computer Vision",
        "abstract": "In this paper, we introduce a novel dataset for monitoring the activities of faculty members in academic office environments. Advances in computer vision have enabled the automation of workplace monitoring, particularly in educational institutions, where tracking faculty activities presents significant challenges and ethical considerations. Traditional methods of manual supervision are labor-intensive and prone to human error, underscoring the potential of automated video analysis as a more efficient solution. While substantial progress has been made in Human Activity Recognition (HAR) across various domains, research specifically focused on monitoring faculty activities in office settings is limited. Most existing studies concentrate on classroom and student monitoring, revealing a critical gap in faculty surveillance.\nThis paper seeks to address that gap by introducing TeacherActivityNet, a novel video dataset designed to recognize teachers' activities in academic offices, encompassing nine distinct action classes. We tweak the YOLOv8n architecture to propose our model, Teacher Activity Net (YOLOTAN), which is then fine-tuned using our dataset, achieving an average precision of 74.9%, significantly outperforming benchmark models. A comparative analysis of our dataset and methods against existing solutions highlights the potential of TeacherActivityNet to improve automated faculty monitoring systems. The dataset, trained models, and accompanying code are available athttps://tinyurl.com/4ub94phh"
    },
    {
        "title": "Think Then React: Towards Unconstrained Action-to-Reaction Motion Generation",
        "link_suffix": "/forum?id=UxzKcIZedp",
        "link": "https://openreview.net/forum?id=UxzKcIZedp",
        "pdf_link": "https://openreview.net/pdf?id=UxzKcIZedp",
        "keywords": "Human Reaction Generation, 3D Human Motion, Large Language Model",
        "abstract": "Despite recent advancements in single-person motion generation, it is still challenging to well handle unconstrained action-to-reaction generation for three reasons: 1) the absence of a unified motion representation that encompasses both egocentric pose and absolute space features, 2) the instability during inference due to lack of constraints~(e.g., text prompts), and 3) the insufficient utilization of text-motion training data in unconstrained scenario. To address these challenges, we introduce Think-Then-React (TTR), a large language model-based framework designed to generate online and unconstrained human-like reactions. First, we propose a unified space-pose token representation, combining both egocentric pose and absolute space features to enhance action understanding and reaction generation. Second, TTR unifies two processes during inference: a thinking process that infers action intentions, and a reacting process that predicts precise and semantically appropriate reactions based on the inferred intention. Furthermore, we introduce a multi-task training strategy, that enables us to effectively leverage both motion and text data. Extensive experiments demonstrate that TTR outperforms existing baselines, achieving significant improvements in evaluation metrics, such as reducing FID from 3.988 to 1.942."
    },
    {
        "title": "M-Longdoc: A Benchmark For Multimodal Super-Long Document Understanding And A Retrieval-Aware Tuning Framework",
        "link_suffix": "/forum?id=5zjsZiYEnr",
        "link": "https://openreview.net/forum?id=5zjsZiYEnr",
        "pdf_link": "https://openreview.net/pdf?id=5zjsZiYEnr",
        "keywords": "multimodal, document, benchmark, retrieval",
        "abstract": "The ability to understand and answer questions over documents can be useful in many business and practical applications. However, documents often contain lengthy and diverse multimodal contents such as texts, figures, and tables, which are very time-consuming for humans to read thoroughly. Hence, there is an urgent need to develop effective and automated methods to aid humans in this task. In this work, we introduce M-LongDoc, a benchmark of 851 samples, and an automated framework to evaluate the performance of large multimodal models. We further propose a retrieval-aware tuning approach for efficient and effective multimodal document reading. Compared to existing works, our benchmark consists of more recent and lengthy documents with hundreds of pages, while also requiring open-ended solutions and not just extractive answers. To our knowledge, our training framework is the first to directly address the retrieval setting for multimodal long documents. To enable tuning open-source models, we construct a training corpus in a fully automatic manner for the question-answering task over such documents. Experiments show that our tuning approach achieves a relative improvement of 4.6% for the correctness of model responses, compared to the baseline open-source models."
    },
    {
        "title": "Learning by Causality to Improve Channel Dependency Modeling in Multivariate Time Series Forecasting",
        "link_suffix": "/forum?id=VojvkUEq8q",
        "link": "https://openreview.net/forum?id=VojvkUEq8q",
        "pdf_link": "https://openreview.net/pdf?id=VojvkUEq8q",
        "keywords": "Multivariate Time Series Forecasting, Channel Dependency, Deep Learning",
        "abstract": "Beyond the conventional long-term temporal dependency modeling, multivariate time series (MTS) forecasting has rapidly shifted toward channel dependency (CD) modeling. This shift significantly improves modeling quality by fully leveraging both multivariate relationships and temporal dependencies. Recent methods primarily model channel dependency through correlation learning (e.g., crossattention) or non-trainable statistical techniques (e.g., cross-correlation). However, these approaches struggle to fully capture the intrinsic relationships within MTS, particularly those stemming from directed cause-effect (i.e., causality) and nonstationary variates originating from diverse sources. In addition, causality may arise from the signals with different temporal behaviors, such as varying periodicity or discrete event sequences, which is not sufficiently discussed before. In this paper, we propose CALAS (Causality-enhanced Attention with Learnable and Adaptive Spacing), the first end-to-end learning method for MTS forecasting that uncover causality among variates without relying on statistical measures or prior knowledge. To model underlying causality, which consists of causal strength and propagation delay, we newly design a hypernetworks-based 1D convolutions mechanism. Inspired by dilated convolution with learnable spacings (DCLS) and spiking neural networks (SNNs), we extend discrete time delay into a continuous Gaussian kernel. Combining the hypernetworks-generated Gaussian kernel and convolutional weights (i.e., attention or causal strength), we achieve the end-to-end dynamic causality modeling mechanism. This mechanism enhances the model’s ability to capture time-varying causality across multi-source variates, ultimately improving the prediction accuracy, quality, and interpretability. For evaluation, we conduct extensive experiments with six real-world datasets and qualitative analysis to demonstrate CALAS’s superiority in capturing varying causality in a data-agnostic manner. The experiment results indicate that CALAS has significantly improved MTS forecasting accuracy compared to state-of-the-art methods by dynamically modeling causality among variates."
    },
    {
        "title": "Active Gaze Behavior Boosts Self-Supervised Object Learning",
        "link_suffix": "/forum?id=dPqfgsYn6l",
        "link": "https://openreview.net/forum?id=dPqfgsYn6l",
        "pdf_link": "https://openreview.net/pdf?id=dPqfgsYn6l",
        "keywords": "Gaze behavior, Self-supervised learning, Time-based augmentations, Object recognition",
        "abstract": "Due to significant variations in the projection of the same object from different viewpoints, machine learning algorithms struggle to recognize the same object across various perspectives. In contrast, toddlers quickly learn to recognize objects from different viewpoints with almost no supervision. Recent works argue that toddlers develop this ability by mapping close-in-time visual inputs to similar representations while interacting with objects. High acuity vision is only available in the central visual field, which may explain why toddlers (much like adults) constantly move their gaze around during such interactions. It is unclear whether/how much toddlers curate their visual experience through these eye movements to support learning object representations. In this work, we explore whether a bio inspired visual learning model can harness toddlers’ gaze behavior during a play session to develop view-invariant object recognition. Exploiting head-mounted eye tracking during dyadic play, we simulate toddlers’ central visual field experience by cropping image regions centered on the gaze location. This visual stream feeds a time-based self-supervised learning algorithm. Our experiments demonstrate that toddlers’ gaze strategy supports the learning of invariant object representations. Our analysis also reveals that the limited size of the central visual field where acuity is high is crucial for this. We further find that toddlers’ visual experience elicits more robust representations compared to adults’ mostly because toddlers look at objects they hold themselves for longer bouts. Overall, our work reveals how toddlers’ gaze behavior supports self-supervised learning of view-invariant object recognition."
    },
    {
        "title": "Efficient Full-Context Retrieval for Long Documents",
        "link_suffix": "/forum?id=NJUzUq2OIi",
        "link": "https://openreview.net/forum?id=NJUzUq2OIi",
        "pdf_link": "https://openreview.net/pdf?id=NJUzUq2OIi",
        "keywords": "Long-context retrieval, Efficient language models, Mamba architecture, Synthetic data generation",
        "abstract": "We present a novel retrieval model for long document understanding, leveraging the Mamba architecture’s linear-time processing capabilities. Our model performs retrieval in the full document context, enabling more accurate information extraction. To address the scarcity of long-context retrieval data, we explore synthetic data generation techniques, finding link-based generation most effective. Our 130M model, paired with an LLM generator, outperforms the best 7B retriever, and we observe even stronger performance with the 1.3B model. These results, evaluated on a wide range of long-form content including financial reports, government documents, and creative works, demonstrate our model’s potential for improving long document understanding in resource-constrained environments. Our approach paves the way for more efficient processing of complex documents across various fields."
    },
    {
        "title": "Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Model Evaluation",
        "link_suffix": "/forum?id=Gv4uHroun5",
        "link": "https://openreview.net/forum?id=Gv4uHroun5",
        "pdf_link": "https://openreview.net/pdf?id=Gv4uHroun5",
        "keywords": "evaluation, efficient, benchmark",
        "abstract": "Evaluating models on large benchmarks can be very resource-intensive, especially during a period of rapid model iteration. Existing efficient evaluation methods approximate the performance of target models by assessing them on a small static coreset derived from publicly available evaluation results of source models. However, these approaches rely on the assumption that each target model has a high prediction consistency with source models, which doesn’t generalize well in practice, leading to inaccurate performance estimates. To fill this gap, we propose TailoredBench, a method that provides customized evaluations tailored to each target model. Specifically, a Global-coreset is first constructed as a probe to identify the most consistent source models for the target models with an adaptive source model selection strategy. Afterwards, a scalable K-Medoids clustering algorithm is proposed to extend the Global-coreset to tailored Native-coreset for each target model. According to the predictions on respective Native-coreset, we estimate the overall performance of target models with a calibrated restoration strategy. Comprehensive experiments on five benchmarks across more than 300 models demonstrate that compared to best performing baselines, TailoredBench achieves an average reduction of 24.8% in the MAE of accuracy estimates, showcasing strong effectiveness and generalizability."
    },
    {
        "title": "Rapid Selection and Ordering of In-Context Demonstrations via Prompt Embedding Clustering",
        "link_suffix": "/forum?id=1Iu2Yte5N6",
        "link": "https://openreview.net/forum?id=1Iu2Yte5N6",
        "pdf_link": "https://openreview.net/pdf?id=1Iu2Yte5N6",
        "keywords": "in-context learning, order sensitivity, LLMs, clustering, cluster-based search, positional encoding, attention mask, serial-position effect, cluster-based search",
        "abstract": "While Large Language Models (LLMs) excel at in-context learning (ICL) using just a few demonstrations, their performances are sensitive to demonstration orders. The reasons behind this sensitivity remain poorly understood. In this paper, we investigate the prompt embedding space to bridge the gap between the order sensitivity of ICL with inner workings of decoder-only LLMs, uncovering the clustering property: prompts sharing the first and last demonstrations have closer embeddings. We explain this property through extensive theoretical analyses and empirical evidences. Our finding suggests that the positional encoding and the causal attention mask are key contributors to the clustering phenomenon. Leveraging this clustering insight, we introduce Cluster-based Search, a novel method that accelerates the selection and ordering of demonstrations in self-adaptive ICL settings. Our approach substantially decreases the time complexity from factorial to quadratic, saving 92% to nearly 100% execution time while maintaining comparable performance to exhaustive search."
    },
    {
        "title": "Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs",
        "link_suffix": "/forum?id=ywgwArtbDq",
        "link": "https://openreview.net/forum?id=ywgwArtbDq",
        "pdf_link": "https://openreview.net/pdf?id=ywgwArtbDq",
        "keywords": "CAPTCHAs, Adversarial examples, Vision models, Robust models",
        "abstract": "Modern CAPTCHAs often rely on vision tasks that are supposedly hard for computers but easy for humans. Although image recognition models pose a significant threat to such CAPTCHAs, they can be fooled by hiding ``random'' noise in images. However, these methods are model-specific and thus can not aid CAPTCHAs in fooling all models. \n    We show in this work that by allowing for more significant changes to the images while preserving the semantic information and keeping it solvable by humans, we can fool many state-of-the-art models. Specifically, we demonstrate that by adding masks of various intensities the Top 1 Accuracy (Acc@1) drops by more than 50%-points for all models, and supposedly robust models such as vision transformers see an Acc@1 drop of 80%-points. \n    These masks can therefore effectively fool modern image classifiers, thus showing that machines have not caught up with humans -- yet."
    },
    {
        "title": "Alignment-Aware Model Extraction Attacks on Large Language Models",
        "link_suffix": "/forum?id=AKsfpHc9sN",
        "link": "https://openreview.net/forum?id=AKsfpHc9sN",
        "pdf_link": "https://openreview.net/pdf?id=AKsfpHc9sN",
        "keywords": "Model Extraction Attack, Large Language Models, Alignment",
        "abstract": "Model extraction attacks (MEAs) on large language models (LLMs) have received increasing attention in recent research. However, existing attack methods typically adapt the extraction strategies originally developed for deep neural networks (DNNs). They neglect the underlying inconsistency between the training tasks of MEA and LLM alignment, leading to suboptimal attack performance. To tackle this issue, we propose Locality Reinforced Distillation (LoRD), a novel model extraction algorithm specifically designed for LLMs. In particular, LoRD employs a newly defined policy-gradient-style training task that utilizes the responses of victim model as the signal to guide the crafting of preference for the local model. Theoretical analyses demonstrate that i) the convergence procedure of LoRD in model extraction is consistent with the alignment procedure of LLMs, and ii) LoRD can reduce query complexity while mitigating watermark protection through exploration-based stealing. Extensive experiments on domain-specific extractions validate the superiority of our method in extracting various state-of-the-art commercial LLMs."
    },
    {
        "title": "NetMoE: Accelerating MoE Training through Dynamic Sample Placement",
        "link_suffix": "/forum?id=1qP3lsatCR",
        "link": "https://openreview.net/forum?id=1qP3lsatCR",
        "pdf_link": "https://openreview.net/pdf?id=1qP3lsatCR",
        "keywords": "Mixture of Experts, All-to-All communication, Distributed training",
        "abstract": "Mixture of Experts (MoE) is a widely used technique to expand model sizes for better model quality while maintaining the computation cost constant. In a nutshell, an MoE model consists of multiple experts in each model layer and routes the training tokens to only a fixed number of experts rather than all. In distributed training, as experts are distributed among different GPUs, All-to-All communication is necessary to exchange the training tokens among the GPUs after each time of expert routing. Due to the frequent and voluminous data exchanges, All-to-All communication has become a notable challenge to training efficiency.In this paper, we manage to accelerate All-to-All communication in MoE models from the training sample perspective, which is unexplored so far. In particular, we put forward the observation that tokens in the same training sample have certain levels of locality in expert routing. Motivated by this, we develop \\name, which takes such locality into account and dynamically rearranges the placement of training samples to minimize All-to-All communication costs. Specifically, we model the All-to-All communication given the sample placement and formulate an integer programming problem to deduce the optimal placement in polynomial time. Experiments with 32 GPUs show that \\name achieves a maximum efficiency improvement of $1.67 \\times$ compared with state-of-the-art MoE training frameworks."
    },
    {
        "title": "Asymptotic Analysis of Two-Layer Neural Networks after One Gradient Step under Gaussian Mixtures Data with Structure",
        "link_suffix": "/forum?id=tNn6Hskmti",
        "link": "https://openreview.net/forum?id=tNn6Hskmti",
        "pdf_link": "https://openreview.net/pdf?id=tNn6Hskmti",
        "keywords": "deep learning theory, random features, Gaussian equivalence, universality, high-dimensional asymptotics",
        "abstract": "In this work, we study the training and generalization performance of two-layer neural networks (NNs) after one gradient descent step under structured data modeled by Gaussian mixtures. While previous research has extensively analyzed this model under isotropic data assumption, such simplifications overlook the complexities inherent in real-world datasets. Our work addresses this limitation by analyzing two-layer NNs under Gaussian mixture data assumption in the asymptotically proportional limit, where the input dimension, number of hidden neurons, and sample size grow with finite ratios. We characterize the training and generalization errors by leveraging recent advancements in Gaussian universality. Specifically, we prove that a high-order polynomial model performs equivalent to the non-linear neural networks under certain conditions. The degree of the equivalent model is intricately linked to both the \"data spread\" and the learning rate employed during one gradient step. Through extensive simulations, we demonstrate the equivalence between the original model and its polynomial counterpart across various regression and classification tasks. Additionally, we explore how different properties of Gaussian mixtures affect learning outcomes. Finally, we illustrate experimental results on Fashion-MNIST classification, indicating that our findings can translate to realistic data."
    },
    {
        "title": "Offline Safe Policy Optimization From Human Feedback",
        "link_suffix": "/forum?id=X5tBNz4qtl",
        "link": "https://openreview.net/forum?id=X5tBNz4qtl",
        "pdf_link": "https://openreview.net/pdf?id=X5tBNz4qtl",
        "keywords": "Offline PbRL, Safety Alignment",
        "abstract": "Offline preference-based reinforcement learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, and then use constrained RL to optimize a safe policy. However, inaccuracies in the reward and cost learning can impair performance when used with constrained RL methods. To address these challenges, (a) we introduce a framework that learns a policy based on pairwise preferences regarding the agent’s behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments, without access to ground-truth rewards or costs; (b) we combine the preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved using a Lagrangian method that directly learns reward maximizing safe policy without explicitly learning reward and cost models, avoiding the need for constrained RL; (c) to evaluate our approach, we construct new datasets with synthetic human feedback, built upon a well-established offline safe RL benchmark. Empirically, our method successfully learns safe policies with high rewards, outperforming baselines with ground-truth reward and cost, as well as state-of-the-art RLHF approaches."
    },
    {
        "title": "A General Feature Attribution Framework under a Black-box Setting",
        "link_suffix": "/forum?id=OW9elPTHcE",
        "link": "https://openreview.net/forum?id=OW9elPTHcE",
        "pdf_link": "https://openreview.net/pdf?id=OW9elPTHcE",
        "keywords": "Explainability, Feature Attribution, Black-box Setting, Query-level Access",
        "abstract": "Feature attribution is widely accepted as a form of explanation for reasoning machine decisions, indicating the proportion of each feature's contribution to an inquired decision. \nWhile most efforts have focused on determining attributions through exact gradient measurements, recent work has adopted gradient estimation to derive explanatory information requiring only query-level access – a restricted yet more practical accessibility assumption known as the black-box setting. \nFollowing this direction, this paper extends the idea of utilizing estimated gradients to a broader framework and introduces GEFA (Gradient-Estimation-based explanation For All). Unlike the previous attempt that focused on explaining image classifiers, the proposed explainer derives feature attributions in a proxy space, making it generally applicable to arbitrary black-box models, regardless of input type. \nIn addition to its close relationship with Integrated Gradients, we find, surprisingly, that our approach – a path method built upon estimated gradients – outputs unbiased estimates of Shapley Values. By avoiding the potential information waste sourced from computing marginal contributions, it improves the quality of derived explanations, as demonstrated by our quantitative evaluations."
    },
    {
        "title": "Boosting Long-Context LLM Inference Efficiency with Intra-Layer Attention Similarity",
        "link_suffix": "/forum?id=G1fzW97QKR",
        "link": "https://openreview.net/forum?id=G1fzW97QKR",
        "pdf_link": "https://openreview.net/pdf?id=G1fzW97QKR",
        "keywords": "Long context LLM, attention similarity, window attention",
        "abstract": "The increasing context window size in Large Language Models (LLMs), such as the GPT and LLaMA series, has improved their ability to tackle complex, long-text tasks, but at the cost of inference efficiency, particularly regarding memory and computational complexity. Existing methods, including selective token retention and window-based attention, improve efficiency but risk discarding important tokens needed for future text generation. In this paper, we propose an approach that enhances LLM efficiency without token loss by reducing the memory and computational load of less important tokens, rather than discarding them. \n    We address two challenges: 1) investigating the distribution of important tokens in the context, discovering recent tokens are more important than distant tokens in context, and 2) optimizing resources for distant tokens by sharing attention scores across layers. The experiments show that our method saves $35$% KV cache without compromising the performance."
    },
    {
        "title": "Revolutionizing AI Companion in FPS Games",
        "link_suffix": "/forum?id=sHUstMPM6Z",
        "link": "https://openreview.net/forum?id=sHUstMPM6Z",
        "pdf_link": "https://openreview.net/pdf?id=sHUstMPM6Z",
        "keywords": "Human-AI collaboration, AI Companion, Game AI system",
        "abstract": "Traditionally, players in first-person shooter (FPS) games have been limited to communicating with AI companions using simple commands like “attack,” “defend,” or “retreat” due to the constraints of existing input methods such as hotkeys and command wheels. One major limitation of these simple commands is the lack of target specificity, as the numerous targets in a 3D virtual environment are difficult to specify using existing input methods. This limitation hinders players’ ability to issue complex tactical instructions such as “clear the second floor,” “take cover behind that tree,” or “retreat to the river.” To overcome this limitation, this paper introduces the $\\textbf{A}$I $\\textbf{C}$ompanion with $\\textbf{V}$oice $\\textbf{I}$nteraction $(\\textbf{ACVI})$, the first-ever AI system that allows players to interact with FPS AI companions through natural language. Deployed in the popular FPS game $\\textit{Arena Breakout: Infinite}$, this revolutionary feature creates the most immersive experience for players, enabling them to work with human-like AI. ACVI is not confined to executing limited commands through simple rule-based systems. Instead, it allows players to engage in real-time voice interactions with AI teammates. By integrating various natural language processing techniques within a confidence-based selection framework, it achieves rapid and accurate decomposition of complex commands and intent reasoning. Moreover, ACVI employs a multi-modal dynamic entity retrieval method for environmental perception, aligning human intentions with decision-making elements. It can accurately comprehend complex voice commands and delivers real-time behavioral responses and vocal feedback to provide close tactical collaboration to players. Additionally, it can identify more than 17,000 objects in the game, including buildings, vehicles, grasslands, and collectible items, and has the ability to accurately distinguish different colors and materials."
    },
    {
        "title": "BID: Broad Incremental for Android Malware Detection",
        "link_suffix": "/forum?id=ctzGqxE3O0",
        "link": "https://openreview.net/forum?id=ctzGqxE3O0",
        "pdf_link": "https://openreview.net/pdf?id=ctzGqxE3O0",
        "keywords": "Broad learning system, Android malware detection, Incremental learning, Relational structure",
        "abstract": "With the rapid rise of mobile devices, the threat of malware targeting these platforms has escalated significantly. The fast-paced evolution of Android malware and new attack patterns frequently introduce substantial challenges for detection systems. Although many methods have achieved excellent results, they need to be retrained when faced with new attack modes or observation objects, and it is challenging to attain dynamic updates. To address this issue, we propose a novel Broad Incremental Detection (BID) method for real-time Android malware detection. Our method leverages incremental function to achieve dynamic adaptation to the growing variety of malware attacks while maintaining high computational efficiency, benefiting from its lightweight shallow network architecture. We also develop relational structures to capture complex relations and features of history attacks by fine-turning the network's weights unsupervised. Experimental results across three datasets demonstrate that BID achieves superior detection accuracy and computational efficiency compared to state-of-the-art approaches. Our work presents a robust, flexible, and lightweight framework for dynamic Android malware detection."
    },
    {
        "title": "OCEAN: Offline Chain-of-thought Evaluation and Alignment in Large Language Models",
        "link_suffix": "/forum?id=rlgplAuN2p",
        "link": "https://openreview.net/forum?id=rlgplAuN2p",
        "pdf_link": "https://openreview.net/pdf?id=rlgplAuN2p",
        "keywords": "chain-of-thought, large language models, offline policy evaluation",
        "abstract": "Offline evaluation of LLMs is crucial in understanding their capacities, though current methods remain underexplored in existing research. In this work, we focus on the offline evaluation of the chain-of-thought capabilities and show how to optimize LLMs based on the proposed evaluation method. To enable offline feedback with rich knowledge and reasoning paths, we use knowledge graphs (e.g., Wikidata5m) to provide feedback on the generated chain of thoughts. Due to the heterogeneity between LLM reasoning and knowledge graph structures, direct interaction and feedback from knowledge graphs on LLM behavior are challenging, as they require accurate entity linking and grounding of LLM-generated chains of thought in the knowledge graph. To address the above challenge, we propose an offline chain-of-thought evaluation framework, OCEAN, which models chain- of-thought reasoning in LLMs as a Markov Decision Process (MDP), and evaluate the policy’s alignment with knowledge graph preference modeling. To overcome the reasoning heterogeneity and grounding problems, we leverage on-policy knowledge graph exploration and reinforcement learning to model a knowledge graph policy that generates token-level likelihood distributions for LLM-generated chain-of-thought reasoning paths, simulating knowledge graph reasoning preference. Then we incorporate the knowledge-graph feedback on the validity and alignment of the generated reasoning paths into inverse propensity scores and propose KG-IPS estimator. Theoretically, we prove the unbiasedness of the proposed KG-IPS estimator and provide a lower bound on its variance. With the off-policy evaluated value function, we can directly enable off-policy optimization to further enhance chain-of-thought alignment. Our empirical study shows that OCEAN can be efficiently optimized for generating chain-of-thought reasoning paths with higher estimated values without affecting LLMs’ general abilities in downstream tasks or their internal knowledge."
    },
    {
        "title": "Unraveling the Complexity of Memory in RL Agents: an Approach for Classification and Evaluation",
        "link_suffix": "/forum?id=2NqrA1wYi6",
        "link": "https://openreview.net/forum?id=2NqrA1wYi6",
        "pdf_link": "https://openreview.net/pdf?id=2NqrA1wYi6",
        "keywords": "memory-based RL, memory, pomdp",
        "abstract": "The incorporation of memory into agents is essential for numerous tasks within the domain of Reinforcement Learning (RL). In particular, memory is paramount for tasks that require the utilization of past information, adaptation to novel environments, and improved sampling efficiency. However, the term ``memory'' encompasses a wide range of concepts, which, coupled with the lack of a unified methodology for validating an agent's memory, leads to erroneous judgments about agents' memory capabilities and prevents objective comparison with other memory-enhanced agents. This paper aims to streamline the concept of memory by providing precise definitions of agent memory types, such as long-term versus short-term memory and declarative versus procedural memory, inspired by cognitive science. \nUsing these definitions, we categorize different classes of agent memory, propose a robust experimental methodology for evaluating the memory capabilities of RL agents, and standardize evaluations. Furthermore, we empirically demonstrate the importance of adhering to the proposed methodology when evaluating different types of agent memory by conducting experiments with different RL agents and what its violation leads to."
    },
    {
        "title": "Honesty to Subterfuge: In-Context Reinforcement Learning Can Make Honest Models Reward Hack",
        "link_suffix": "/forum?id=to4PdiiILF",
        "link": "https://openreview.net/forum?id=to4PdiiILF",
        "pdf_link": "https://openreview.net/pdf?id=to4PdiiILF",
        "keywords": "Large Language Model, Deception, specification gaming, Reward Hacking, Evaluations, in-context reinforcement learning, in-context learning, iterative reflection, gpt-4o-mini, gpt-4o, o1-mini, o1-preview",
        "abstract": "Previous work has shown that training “helpful-only” LLMs with reinforcement learning on a curriculum of gameable environments can lead models to generalize to egregious specification gaming, such as editing their own reward function or modifying task checklists to appear more successful. We show that gpt-4o, gpt-4o-mini, o1-preview, and o1-mini — frontier models trained to be helpful, harmless, and honest — can engage in specification gaming without training on a curriculum of tasks, purely from in-context iterative reflection (which we call in-context reinforcement learning, “ICRL”). We also show that using ICRL to generate highly-rewarded outputs for expert iteration (compared to the standard expert iteration reinforcement learning algorithm) may increase gpt-4o-mini's propensity to learn specification-gaming policies, generalizing (in very rare cases) to the most egregious strategy where gpt-4o-mini edits its own reward function. Our results point toward the strong ability of in-context reflection to discover rare specification-gaming strategies that models might not exhibit zero-shot or with normal training, highlighting the need for caution when relying on alignment of LLMs in zero-shot settings."
    },
    {
        "title": "Video Generation with Learned Action Prior",
        "link_suffix": "/forum?id=VAvZ4oinpa",
        "link": "https://openreview.net/forum?id=VAvZ4oinpa",
        "pdf_link": "https://openreview.net/pdf?id=VAvZ4oinpa",
        "keywords": "Stochastic Video Generation, Variational Inference",
        "abstract": "Long-term stochastic video generation remains challenging, especially with moving cameras. This scenario introduces complex interactions between camera movement and observed pixels, resulting in intricate spatio-temporal dynamics and partial observability issues. Current approaches often focus on pixel-level image reconstruction, neglecting explicit modeling of camera motion dynamics. Our proposed solution incorporates camera motion or action as an extended part of the observed image state, employing a multi-modal learning framework to simultaneously model both image and action. We introduce three models: (i) Video Generation with Learning Action Prior (VG-LeAP) that treats the image-action pair as an augmented state generated from a single latent stochastic process and uses variational inference to learn the image-action latent prior; (ii) Causal-LeAP, which establishes a causal relationship between action and the observed image frame, and learns a seperate action prior, conditioned on the observed image states along with the image prior; and (iii) RAFI, which integrates the augmented image-action state concept with a conditional flow matching framework, demonstrating that this action-conditioned image generation concept can be extended to other transformer-based architectures. Through comprehensive empirical studies on robotic video dataset, RoAM, we highlight the importance of multi-modal training in addressing partially observable video generation problems."
    },
    {
        "title": "U-MATH: A University-Level Benchmark for Evaluating Mathematical Skills in LLMs",
        "link_suffix": "/forum?id=xlxGsX1pc7",
        "link": "https://openreview.net/forum?id=xlxGsX1pc7",
        "pdf_link": "https://openreview.net/pdf?id=xlxGsX1pc7",
        "keywords": "Large Language Models (LLMs), Mathematical Reasoning, Benchmarking, University-Level Mathematics, Multimodal, Automatic Evaluation, Solution Assessment",
        "abstract": "The current evaluation of mathematical skills in LLMs is limited, as existing benchmarks are relatively small, primarily focus on elementary and high-school problems, or lack diversity in topics. Additionally, the inclusion of visual elements in tasks remains largely under-explored.To address these gaps, we introduceU-MATH, a novel benchmark of 1,125 unpublished open-ended university-level problems sourced from teaching materials. It is balanced across six core subjects, with 20% of problems requiring image understanding. Given the open-ended nature of U-MATH problems, we employ an LLM to judge the correctness of generated solutions. To this end, we release$\\boldsymbol\\mu$-MATH, an additional dataset to evaluate the LLMs' capabilities in assessing solutions.The evaluation of general domain, math-specific, and multimodal LLMs highlights the challenges presented by U-MATH. Our findings reveal that LLMs achieve a maximum accuracy of only 53% on text-based tasks, with even lower 30% on visual problems. The solution assessment proves challenging for LLMs, with the best LLM judge having an F1-score of 76% on $\\mu$-MATH.We open-source U-MATH, $\\mu$-MATH, and evaluation code on GitHub."
    }
]
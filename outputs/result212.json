[{"title": "From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by Step", "link_suffix": "/forum?id=fRPmc94QeH", "link": "https://openreview.net/forum?id=fRPmc94QeH", "pdf_link": "https://openreview.net/pdf?id=fRPmc94QeH", "keywords": "implicit reasoning, chain of thought", "abstract": "When leveraging language models for reasoning tasks, generating explicit chain-of-thought (CoT) steps often proves essential for achieving high accuracy in final outputs. In this paper, we investigate if models can be taught to internalize these CoT steps. To this end, we propose a simple yet effective method for internalizing CoT steps: starting with a model trained for explicit CoT reasoning, we gradually remove the intermediate steps and finetune the model. This process allows the model to internalize the intermediate reasoning steps, thus simplifying the reasoning process while maintaining high performance. Our approach enables training a GPT-2 Small model to solve 20-by-20 multiplication with 99.5% accuracy while being 26 times faster than explicit CoT, whereas standard training cannot solve beyond 4-by-4 multiplication. Furthermore, our method proves effective on larger language models, such as Mistral 7B, achieving over 50% accuracy on GSM8K without producing any intermediate steps.", "title_embedding_index": 10550, "title_abs_embedding_index": 10575}, {"title": "A Diffusion-based Generative Approach for Model-free Finite-time Control of Complex Systems", "link_suffix": "/forum?id=A67BCisI3F", "link": "https://openreview.net/forum?id=A67BCisI3F", "pdf_link": "https://openreview.net/pdf?id=A67BCisI3F", "keywords": "Complex Network, Dynamic Control, Generative Model, Diffusion Model, AI for Science", "abstract": "Complex systems with nonlinear dynamics pose significant challenges for finite-time optimal control, especially when accurate system models are unavailable. This paper introduces DIFOCON (DIffusion Finite-time Optimal CONtrol), a novel data-driven framework for finite-time optimal control that operates without prior knowledge of system parameters or dynamics. DIFOCON reformulates the control problem as a generative task, optimizing control signal trajectories to guide systems to target states within a finite time. Our approach utilizes a diffusion model with a dual-Unet architecture to capture nonlinear system dynamics and generate entire control sequences in a single step. Additionally, an inverse dynamics module is integrated to ensure that the generated control signals are appropriate for complex systems. To further enhance performance, we propose a retraining strategy that improves out-of-distribution generalization. Experiments on two nonlinear complex systems demonstrate DIFOCON's superior performance, reducing target loss by over 26.9% and control energy by over 15.8% compared to baselines while achieving up to 4 times faster convergence in practical steering tasks. The implementation of this work can be found athttps://anonymous.4open.science/r/DIFOCON-C019/.", "title_embedding_index": 10551, "title_abs_embedding_index": 10576}, {"title": "A Versatile Influence Function for Data Attribution with Non-Decomposable Loss", "link_suffix": "/forum?id=p85TNN62KD", "link": "https://openreview.net/forum?id=p85TNN62KD", "pdf_link": "https://openreview.net/pdf?id=p85TNN62KD", "keywords": "influence function, data attribution", "abstract": "Influence function, a technique rooted in robust statistics, has been adapted in modern machine learning for a novel application: data attribution---quantifying how individual training data points affect a model's predictions. However, the common derivation of influence functions in the data attribution literature is limited to loss functions that decompose into a sum of individual data point losses, with the most prominent examples known as M-estimators. This restricts the application of influence functions to more complex learning objectives, which we refer to as non-decomposable losses, such as contrastive or ranking losses, where a unit loss term depends on multiple data points and cannot be decomposed further. In this work, we bridge this gap by revisiting the general formulation of influence function from robust statistics, which extends beyond M-estimators. Based on this formulation, we propose a novel method, the Versatile Influence Function (VIF), that can be straightforwardly applied to machine learning models trained with any non-decomposable loss. In comparison to the classical approach in statistics, the proposed VIF is designed to fully leverage the power of auto-differentiation, hereby eliminating the need for case-specific derivations of each loss function. We demonstrate the effectiveness of VIF across three examples: Cox regression for survival analysis, node embedding for network analysis, and listwise learning-to-rank for information retrieval. In all cases, the influence estimated by VIF closely resembles the results obtained by brute-force leave-one-out retraining, while being up to 1000 times faster to compute. We believe VIF represents a significant advancement in data attribution, enabling efficient influence-function-based attribution across a wide range of machine learning paradigms, with broad potential for practical use cases.", "title_embedding_index": 10552, "title_abs_embedding_index": 10577}, {"title": "UNComp: Uncertainty-Aware Long-context Compressor for Efficient Large Language Model Inference", "link_suffix": "/forum?id=28oMPC5bcE", "link": "https://openreview.net/forum?id=28oMPC5bcE", "pdf_link": "https://openreview.net/pdf?id=28oMPC5bcE", "keywords": "KV Cache, GQA, Matrix entropy, Uncertainty, Efficient Inference", "abstract": "Deploying large language models (LLMs) is challenging due to their high memory and computational demands, especially during long-context inference. While key-value (KV) caching accelerates inference by reusing previously computed keys and values, it also introduces significant memory overhead. Existing KV cache compression methods\u2014such as eviction and merging\u2014typically compress the KV cache after it is generated and overlook the eviction of hidden states, failing to improve the speed of the prefilling stage. Additionally, applying a uniform compression rate across different attention heads can harm crucial retrieval heads in needle-in-a-haystack tasks due to excessive compression. In this paper, we propose UNComp, an uncertainty-aware compression scheme that leverages matrix entropy to estimate model uncertainty across layers and heads at the token sequence level. By grouping layers and heads based on their uncertainty, UNComp adaptively compresses both the hidden states and the KV cache. Our method achieves a 1.6x speedup in the prefilling stage and reduces the KV cache to 4.74% of its original size, resulting in a 6.4x increase in throughput and a 1.4x speedup in inference with only a 1.41% performance loss. Remarkably, in needle-in-a-haystack tasks, UNComp outperforms the full-size KV cache even when compressed to 9.38% of its original size. Our approach offers an efficient, training-free Grouped-Query Attention paradigm that can be seamlessly integrated into existing KV cache schemes.", "title_embedding_index": 10553, "title_abs_embedding_index": 10578}, {"title": "The Price of Freedom: Exploring Tradeoffs in Equivariant Tensor Products with Spherical Signals", "link_suffix": "/forum?id=ok5NweADUB", "link": "https://openreview.net/forum?id=ok5NweADUB", "pdf_link": "https://openreview.net/pdf?id=ok5NweADUB", "keywords": "equivariance, tensor product, spherical harmonics, vector spherical harmonics, spherical signals, benchmarking, asymptotics", "abstract": "$E(3)$-equivariant neural networks have demonstrated success across a wide range of 3D modelling tasks. A fundamental operation in these networks is the tensor product, which interacts two geometric features in an equivariant manner to create new features. Due to the high computational complexity of the tensor product, significant effort has been invested to optimize the runtime of this operation. \\citet{gaunt} recently proposed the Gaunt tensor product (GTP) which promises a significant speedup over the naive implementation of the tensor product. However, this method is unable to perform antisymmetric operations which are crucial for tasks involving chirality. In this work, we introduce vector signal tensor product (VSTP) to solve this issue and show how it generalizes to a class of irrep signal tensor products (ISTPs). Finally, we investigate why these tensor products are faster. We find most of the speedup comes at the price of expressivity. Further, we microbenchmarked the various tensor products and find that the theoretical runtime guarantees may differ wildly from empirical performance, demonstrating the need for careful application-specific benchmarking. Our code is linked \\href{https://anonymous.4open.science/r/vector-spherical-harmonics-1231/}{here}.", "title_embedding_index": 10554, "title_abs_embedding_index": 10579}, {"title": "Reassessing How to Compare and Improve the Calibration of Machine Learning Models", "link_suffix": "/forum?id=X0epAjg0hd", "link": "https://openreview.net/forum?id=X0epAjg0hd", "pdf_link": "https://openreview.net/pdf?id=X0epAjg0hd", "keywords": "calibration, proper scoring rules, ECE, kernel regression", "abstract": "A machine learning model is calibrated if its predicted probability for an outcome matches the observed frequency for that outcome conditional on the model prediction. This property has become increasingly important as the impact of machine learning models has continued to spread to various domains. As a result, there are now a dizzying number of recent papers on measuring and improving the calibration of (specifically deep learning) models. In this work, we reassess the reporting of calibration metrics in the recent literature. We show that there exist trivial recalibration approaches that can appear seemingly state-of-the-art unless calibration and prediction metrics (i.e. test accuracy) are accompanied by additional generalization metrics such as negative log-likelihood. We then use a calibration-based decomposition of Bregman divergences to develop a new extension to reliability diagrams that jointly visualizes calibration and generalization error, and show how our visualization can be used to detect trade-offs between calibration and generalization. Along the way, we prove novel results regarding the relationship between full calibration error and confidence calibration error for Bregman divergences. We also establish the consistency of the kernel regression estimator for calibration error used in our visualization approach, which generalizes existing consistency results in the literature.", "title_embedding_index": 10555, "title_abs_embedding_index": 10580}, {"title": "Uncertainty-aware Guided Diffusion for Missing Data in Sequential Recommendation", "link_suffix": "/forum?id=w2HL7yuWE2", "link": "https://openreview.net/forum?id=w2HL7yuWE2", "pdf_link": "https://openreview.net/pdf?id=w2HL7yuWE2", "keywords": "Diffusion Models, Recommender Systems, Missing Data", "abstract": "Denoising diffusion models (DDMs) have shown significant potential in generating oracle items that best match user preference with guidance from user historical interaction sequences. However, the quality of guidance is often compromised by the unpredictable missing data in the observed sequence, leading to suboptimal item generation. To tackle this challenge, we propose a novel uncertainty-aware guided diffusion model (DreamMiss) to alleviate the influence of missing data. The core of DreamMiss is the utilization of a dual-side Thompson sampling (DTS) strategy, which simulates the stochastical mechanism of missing data without disrupting preference evolution. Specifically, we first define dual-side probability models to capture user preference evolution, taking into account both local item continuity and global sequence stability. We then strategically remove items based on these two models with DTS, creating uncertainty-aware guidance for DDMs to generate oracle items. This can achieve DDMs\u2019 consistency regularization, enabling them to resile against uncertain missing data. Additionally, to accelerate sampling in the reverse process, DreamMiss is implemented under the framework of denoising diffusion implicit models (DDIM). Extensive experimental results show that DreamMiss significantly outperforms baselines in sequential recommendation.", "title_embedding_index": 10556, "title_abs_embedding_index": 10581}, {"title": "FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information", "link_suffix": "/forum?id=4ihkxIeTFH", "link": "https://openreview.net/forum?id=4ihkxIeTFH", "pdf_link": "https://openreview.net/pdf?id=4ihkxIeTFH", "keywords": "Optimizer, Adam, Natural gradient descent, Second order optimization, Information geometry, Riemannian geometry, Differential geometry, Tensor calculus, Deep learning, Fisher Information, Hessian, Curvature", "abstract": "This paper establishes a mathematical foundation for the Adam optimizer, elucidating its connection to natural gradient descent through Riemannian and information geometry. We rigorously analyze the diagonal empirical Fisher information matrix (FIM) in Adam, clarifying all detailed approximations and advocating for the use of log probability functions as loss, which should be based on discrete distributions, due to the limitations of empirical FIM. Our analysis uncovers flaws in the original Adam algorithm, leading to proposed corrections such as enhanced momentum calculations, adjusted bias corrections, and gradient clipping. We refine the weight decay term based on our theoretical framework. Our modified algorithm, Fisher Adam (FAdam), demonstrates superior performance across diverse domains including LLM, ASR, and VQ-VAE, achieving SoTA results in ASR.", "title_embedding_index": 10557, "title_abs_embedding_index": 10582}, {"title": "Generalized Principal-Agent Problem with a Learning Agent", "link_suffix": "/forum?id=LqTz13JS2P", "link": "https://openreview.net/forum?id=LqTz13JS2P", "pdf_link": "https://openreview.net/pdf?id=LqTz13JS2P", "keywords": "principal-agent problems, Bayesian persuasion, no-regret learning, no-swap-regret", "abstract": "Generalized principal-agent problems, including Stackelberg games, contract design, and Bayesian persuasion, are a class of economic problems where an agent best responds to a principal's committed strategy. \nWe study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction, we show that: (1) if the agent uses contextual no-regret learning algorithms with regret $\\mathrm{Reg}(T)$, then the principal can guarantee utility at least $U^* - \\Theta\\big(\\sqrt{\\tfrac{\\mathrm{Reg}(T)}{T}}\\big)$, where $U^*$ is the principal's optimal utility in the classic model with a best-responding agent.\n(2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\\mathrm{SReg}(T)$, then the principal cannot obtain utility more than $U^* + O(\\frac{\\mathrm{SReg(T)}}{T})$. \nBut (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret), then the principal can sometimes do significantly better than $U^*$.\nThese results not only refine previous results in Stackelberg games and contract design, but also lead to new results for Bayesian persuasion with a learning agent and all generalized principal-agent problems where the agent does not have private information.", "title_embedding_index": 10558, "title_abs_embedding_index": 10583}, {"title": "Accelerated Online Reinforcement Learning using Auxiliary Start State Distributions", "link_suffix": "/forum?id=QtZsTaqRRE", "link": "https://openreview.net/forum?id=QtZsTaqRRE", "pdf_link": "https://openreview.net/pdf?id=QtZsTaqRRE", "keywords": "reinforcement learning, sample efficiency, robustness", "abstract": "Learning a robust policy that is performant across the state space, in a sample efficient manner, is a long-standing problem in online reinforcement learning (RL). This challenge arises from the inability of algorithms to explore the environment efficiently. Most attempts at efficient exploration tackle this problem in a setting where learning begins from scratch, without prior information available to bootstrap learning. However, such approaches often fail to fully leverage expert demonstrations and simulators that can reset to arbitrary states. These affordances are valuable resources that offer enormous potential to guide exploration and speed up learning. In this paper, we explore how a small number of expert demonstrations and a simulator allowing arbitrary resets can accelerate learning during online RL. We show that by leveraging expert state information to form an auxiliary start state distribution, we significantly improve sample efficiency. Specifically, we show that using a notion of safety to inform the choice of auxiliary distribution significantly accelerates learning. We highlight the effectiveness of our approach by matching or exceeding state-of-the-art performance in sparse reward and dense reward setups, even when competing with algorithms with access to expert actions and rewards. Moreover, we find that the improved exploration ability facilitates learning more robust policies in spare reward, hard exploration environments.", "title_embedding_index": 10559, "title_abs_embedding_index": 10584}, {"title": "Time Transfer: On Optimal Learning Rate and Batch Size In The Infinite Data Limit", "link_suffix": "/forum?id=MLhquJb1qN", "link": "https://openreview.net/forum?id=MLhquJb1qN", "pdf_link": "https://openreview.net/pdf?id=MLhquJb1qN", "keywords": "optimal scaling, muP, hyperparameter transfer, learning rate sensitivity, LLM", "abstract": "One of the main challenges in optimal scaling of large language models (LLMs) is the prohibitive cost of hyperparameter tuning, particularly learning rate $\\eta$ and batch size $B$. While techniques like $\\mu$P (Yang et al., 2022) provide scaling rules for optimal $\\eta$ transfer in the infinite model size limit, the optimal scaling behavior in the infinite data size limit ($T \\to \\infty$) remains unknown. We fill in this gap by observing for the first time an interplay of three optimal $\\eta$ scaling regimes: $\\eta \\propto \\sqrt{T}$, $\\eta \\propto 1$, and $\\eta \\propto 1/\\sqrt{T}$ with transitions controlled by $B$ and its relation to the time-evolving critical batch size $B_\\mathrm{crit} \\propto T$. Furthermore, we show that the optimal batch size is positively correlated with $B_\\mathrm{crit}$: keeping it fixed becomes suboptimal over time even if learning rate is scaled optimally. Surprisingly, our results demonstrate that the observed optimal $\\eta$ and $B$ dynamics are preserved with $\\mu$P model scaling, challenging the conventional view of $B_\\mathrm{crit}$ dependence solely on loss value. Complementing optimality, we examine the sensitivity of loss to changes in learning rate, where we find the sensitivity to decrease with $T \\to \\infty$ and to remain constant with $\\mu$P model scaling. We hope our results make the first step towards a unified picture of the joint optimal data and model scaling.", "title_embedding_index": 10560, "title_abs_embedding_index": 10585}, {"title": "SSLAM: Enhancing Self-Supervised Models with Audio Mixtures for Polyphonic Soundscapes", "link_suffix": "/forum?id=odU59TxdiB", "link": "https://openreview.net/forum?id=odU59TxdiB", "pdf_link": "https://openreview.net/pdf?id=odU59TxdiB", "keywords": "audio self-supervised learning, audio representation learning", "abstract": "Self-supervised pre-trained audio networks have seen widespread adoption in real-world systems, particularly in multi-modal large language models. These networks are often employed in a frozen state, under the assumption that the self-supervised pre-training has sufficiently equipped them to handle real-world audio. However, a critical question remains: how well do these models actually perform in real-world conditions, where audio is typically polyphonic and complex, involving multiple overlapping sound sources? Current audio self-supervised learning (SSL) methods are often benchmarked on datasets predominantly featuring monophonic audio, such as environmental sounds, and speech. As a result, the ability of SSL models to generalize to polyphonic audio, a common characteristic in natural scenarios, remains underexplored. This limitation raises concerns about the practical robustness of SSL models in more realistic audio settings. To address this gap, we introduce Self-Supervised Learning from Audio Mixtures (SSLAM), a novel direction in audio SSL research,  designed to improve the model\u2019s ability to learn from polyphonic data while maintaining strong performance on monophonic data. We thoroughly evaluate SSLAM on standard audio SSL benchmark datasets which are predominantly monophonic and conduct a comprehensive comparative analysis against state-of-the-art (SOTA) methods using a range of high-quality, publicly available polyphonic datasets. SSLAM not only improves model performance on polyphonic audio, but also maintains or exceeds performance on standard audio SSL benchmarks. Notably, it achieves up to a 3.9% improvement on the AudioSet-2M(AS-2M), reaching a mean average precision (mAP) of 50.2. For polyphonic datasets, SSLAM sets new SOTA in both linear evaluation and fine-tuning regimes with performance improvements of up to 9.1%(mAP). These results demonstrate SSLAM's effectiveness in both polyphonic and monophonic soundscapes, significantly enhancing the performance of audio SSL models.", "title_embedding_index": 10561, "title_abs_embedding_index": 10586}, {"title": "Contextually Guided Transformers via Low-Rank Adaptation", "link_suffix": "/forum?id=WYsCKxZc5Y", "link": "https://openreview.net/forum?id=WYsCKxZc5Y", "pdf_link": "https://openreview.net/pdf?id=WYsCKxZc5Y", "keywords": "transformers, hypernetworks", "abstract": "Large Language Models (LLMs) based on Transformers excel at text processing, but their reliance on prompts for specialized behavior introduces computational overhead. We propose a modification to a Transformer architecture that eliminates the need for explicit prompts by learning to encode context into the model's weights. Our Contextually Guided Transformer (CGT) model maintains a contextual summary at each sequence position, allowing it to update the weights on the fly based on the preceding context. This approach enables the model to self-specialize, effectively creating a tailored model for processing information following a given prefix. We demonstrate the effectiveness of our method on synthetic in-context learning tasks and language modeling benchmarks. Furthermore, we introduce techniques for enhancing the interpretability of the learned contextual representations, drawing connections to Variational Autoencoders and promoting smoother, more consistent context encoding. This work offers a novel direction for efficient and adaptable language modeling by integrating context directly into the model's architecture.", "title_embedding_index": 10562, "title_abs_embedding_index": 10587}, {"title": "Sharper Guarantees for Learning Neural Network Classifiers with Gradient Methods", "link_suffix": "/forum?id=h7GAgbLSmC", "link": "https://openreview.net/forum?id=h7GAgbLSmC", "pdf_link": "https://openreview.net/pdf?id=h7GAgbLSmC", "keywords": "generalization bounds, neural networks, optimization, feature learning", "abstract": "In this paper, we study the data-dependent convergence and generalization behavior of gradient methods for neural networks with smooth activation. Our first result is a novel bound on the excess risk of deep networks trained by the logistic loss via an alogirthmic stability analysis. Compared to previous works, our results improve upon the shortcomings of the well-established Rademacher complexity-based bounds. Importantly, the bounds we derive in this paper are tighter, hold even for neural networks of small width, do not scale unfavorably with width, are algorithm-dependent, and consequently capture the role of initialization on the sample complexity of gradient descent for deep nets. Specialized to noiseless data separable with margin $\\gamma$ by neural tangent kernel (NTK) features of a network of width $\\Omega(poly(\\log(n)))$, we show the test-error rate $e^{O(L)}/{\\gamma^2 n}$, where $n$ is the training set size and $L$ denotes the number of hidden layers. This results in an improvement in the test loss bound compared to previous works while maintaining the poly-logarithmic width conditions. We further investigate excess risk bounds for deep nets trained with noisy data, establishing that under a polynomial condition on the network width, gradient descent can achieve the optimal excess risk. Finally, we show that a large step-size significantly improves upon the NTK regime's results in classifying the XOR distribution. In particular, we show for a one-hidden layer neural network of constant width $m$ with quadratic activation and standard Gaussian initialization that SGD with linear sample complexity and with a large step-size $\\eta=m$ reaches the perfect test accuracy after only $\\lceil\\log(d)\\rceil$ iterations, where $d$ is the data dimension.", "title_embedding_index": 10563, "title_abs_embedding_index": 10588}, {"title": "Salutary Labeling with Zero Human Annotation", "link_suffix": "/forum?id=zPRQ7wtwhb", "link": "https://openreview.net/forum?id=zPRQ7wtwhb", "pdf_link": "https://openreview.net/pdf?id=zPRQ7wtwhb", "keywords": "Active learning, influence function", "abstract": "Active learning strategically selects informative unlabeled data points and queries their ground truth labels for model updates. The prevailing assumption in the active learning paradigm is that the acquisition of ground truth labels optimally enhances model performance. However, this assumption may not always hold or maximize learning capacity. Moreover, ground truth annotations incur significant costs due to the need for intensive human labor. In contrast to traditional active learning, this paper proposes salutary labeling, which automatically assigns the most beneficial labels to the most informative samples without human annotation. Specifically, we utilize the influence function, a tool for estimating sample influence, to select newly added samples and assign their salutary labels by choosing the category that maximizes their positive influence. This process eliminates the need for human annotation. Extensive experiments conducted on nine benchmark datasets demonstrate the superior performance of our salutary labeling approach over traditional active learning strategies. Additionally, we provide several in-depth explorations and practical applications including large language model fine-tuning.", "title_embedding_index": 10564, "title_abs_embedding_index": 10589}, {"title": "Adaptive Source Localization on Complex Networks via Conditional Diffusion Model", "link_suffix": "/forum?id=v0O9FrVTt1", "link": "https://openreview.net/forum?id=v0O9FrVTt1", "pdf_link": "https://openreview.net/pdf?id=v0O9FrVTt1", "keywords": "Diffusion Model, Knowledge Informed Machine Learning, Source Localization, Complex Network", "abstract": "Network propagation issues like the spread of misinformation, cyber threats, or infrastructure breakdowns are prevalent and have significant societal impacts. Identifying the source of such propagation by analyzing snapshots of affected networks is crucial for managing crises like disease outbreaks and enhancing network security. Traditional methods rely on metrics derived from network topology and are limited to specific propagation models, while deep learning models face the challenge of data scarcity. We propose \\textbf{ASLDiff}~(\\textbf{A}daptive \\textbf{S}ource \\textbf{L}ocalization \\textbf{Diff}sion Model), a novel adaptive source localization diffusion model to achieve accurate and robust source localization across different network topologies and propagation modes by fusing the principles of information propagation and restructuring the label propagation process within the conditioning module. Our approach not only adapts to real-world patterns easily without abundant fine-tuning data but can also generalize to different network topologies easily. Evaluations of various datasets demonstrate ASLDiff's superior effectiveness, accuracy, and adaptability in real-world applications, showcasing its robust performance across different localization scenarios. The code can be found athttps://anonymous.4open.science/r/ASLDiff-4FE0.", "title_embedding_index": 10565, "title_abs_embedding_index": 10590}, {"title": "HumanoidOlympics: Sports Environments for Physically Simulated Humanoids", "link_suffix": "/forum?id=pblB72EmrM", "link": "https://openreview.net/forum?id=pblB72EmrM", "pdf_link": "https://openreview.net/pdf?id=pblB72EmrM", "keywords": "Physics Simulation, Embodied AI, Benchmark, Sports", "abstract": "We present HumanoidOlympics, a collection of physically simulated sports environments designed for the animation and robotics communities to develop humanoid behaviors.  Our suite includes individual sports such as golf, javelin throw, high jump, long jump, and hurdling, as well as competitive games like table tennis, tennis, fencing, boxing, soccer, and basketball. By simulating a wide range of Olympic sports, HumanoidOlympics offers a rich and standardized testing ground to evaluate and develop learning algorithms due to the diversity and physically demanding nature of athletic activities. Our suite supports simulating both graphics-focused (SMPL and SMPL-X) and real-world humanoid robots. For each sport, we benchmark popular humanoid control methods and provide expert-designed rewards that lead to surprising simulation results. Our analysis shows that leveraging human demonstrations can significantly enhance the resulting policies' human likeness and task performance. By providing a unified and competitive sports benchmark, HumanoidOlympics can help the animation and robotics communities develop human-like and performant controllers.", "title_embedding_index": 10566, "title_abs_embedding_index": 10591}, {"title": "HiDF: A Human-Indistinguishable Deepfake Dataset", "link_suffix": "/forum?id=XhyCPEnlCa", "link": "https://openreview.net/forum?id=XhyCPEnlCa", "pdf_link": "https://openreview.net/pdf?id=XhyCPEnlCa", "keywords": "Deepfake, Human-Indistinguishable, AI, Multimodal", "abstract": "The rapid development and prevalence of generative AI has made it easy for people to create high-quality deepfake images and videos, but their abuses also have been exponentially increased. To mitigate potential social disruption, it is crucial to quickly detect authenticity of each deepfake content hidden in a sea of information. While researchers have worked on developing deep learning-based methods, the deepfake datasets utilized in these studies are far from the real world in terms of their qualities; most of the popular deepfake datasets are human distinguishable. To address this problem, we present a novel deepfake dataset, HiDF, a high-quality and human-indistinguishable deepfake dataset consisting of 30 K images and 4 K videos. HiDF is a meticulously curated dataset that includes diverse subjects, which has been undergone rigorous quality checks. Comparison on the quality between HiDF and existing deepfake datasets demonstrates that HiDF is human-indistinguishable, hence it can be used as a valuable benchmark dataset for deepfake detection tasks. Data and code (https://github.\bwill.be.provided) are publicly available for future deepfake detection research.", "title_embedding_index": 10567, "title_abs_embedding_index": 10592}, {"title": "VideoPanda: Video Panoramic Diffusion With Multi-view Attention", "link_suffix": "/forum?id=CMj18BQQDK", "link": "https://openreview.net/forum?id=CMj18BQQDK", "pdf_link": "https://openreview.net/pdf?id=CMj18BQQDK", "keywords": "video generation, diffusion model, panorama", "abstract": "High resolution panoramic video content is paramount for immersive experiences in Virtual Reality, but is non-trivial to collect as it requires specialized equipment and intricate camera setups. \nIn this work, we introduce \\ourmodel, a novel approach for synthesizing $360^\\circ$ videos conditioned on text or single-view video data. \\ourmodel leverages multi-view attention layers to augment a video diffusion model, enabling it to generate consistent multi-view videos that can be combined into immersive panoramic content. \\ourmodel is trained jointly using two conditions: text-only and single-view video, and supports autoregressive generation of long-videos. \nTo overcome the computational burden of multi-view video generation, we randomly subsample the duration and camera views used during training and show that the model is able to gracefully generalize  to generating more frames during inference.\nExtensive evaluations on both real-world and synthetic video datasets demonstrate that \\ourmodel generates more realistic and coherent $360^\\circ$ panoramas across all input conditions compared to existing methods.\nVisit the project website athttps://mvpanovideo.github.io/VideoPanda/for results.", "title_embedding_index": 10568, "title_abs_embedding_index": 10593}, {"title": "Diverse and Effective Red Teaming with Auto-generated Rewards and Multi-step Reinforcement Learning", "link_suffix": "/forum?id=FDmKe5EBuy", "link": "https://openreview.net/forum?id=FDmKe5EBuy", "pdf_link": "https://openreview.net/pdf?id=FDmKe5EBuy", "keywords": "red teaming, safety, reinforcement learning", "abstract": "Automated red teaming can discover rare model failures and generate challenging examples that can be used for training or evaluation.  However, a core challenge in automated red teaming is ensuring that the attacks are both diverse and effective.  Prior methods typically succeed in optimizing either for diversity or for effectiveness, but rarely both.  In this paper, we provide methods that enable automated red teaming to generate a large number of diverse and successful attacks.Our approach decomposes the task into two steps: (1) automated methods for generating diverse attack goals and (2) generating effective attacks for those goals.  While we provide multiple straightforward methods for generating diverse goals, our key contributions are to train an RL attacker that both follows those goals and generates diverse attacks for those goals.  First, we demonstrate that it is easy to use a large language model (LLM) to generate diverse attacker goals with per-goal prompts and rewards, including rule-based rewards (RBRs) to grade whether the attacks are successful for the particular goal.  Second, we demonstrate how training the attacker model with multi-step RL, where the model is rewarded for generating attacks that are different from past attempts further increases diversity while remaining effective.  We use our approach to generate both prompt injection attacks and prompts that elicit unsafe responses.  In both cases, we find that our approach is able to generate highly-effective and considerably more diverse attacks than past general red-teaming approaches.", "title_embedding_index": 10569, "title_abs_embedding_index": 10594}, {"title": "Targeted Attack Improves Protection against Unauthorized Diffusion Customization", "link_suffix": "/forum?id=agHddsQhsL", "link": "https://openreview.net/forum?id=agHddsQhsL", "pdf_link": "https://openreview.net/pdf?id=agHddsQhsL", "keywords": "Protection, Unauthorized Diffusion Customization, Adversarial Attack, Diffusion Model, Privacy", "abstract": "Diffusion models build a new milestone for image generation yet raising public concerns, for they can be fine-tuned on unauthorized images for customization. Protection based on adversarial attacks rises to encounter this unauthorized diffusion customization, by adding protective watermarks to images and poisoning diffusion models. However, current protection, leveraging untargeted attacks, does not appear to be effective enough. In this paper, we propose a simple yet effective improvement for the protection against unauthorized diffusion customization by introducing targeted attacks. We show that by carefully selecting the target, targeted attacks significantly outperform untargeted attacks in poisoning diffusion models and degrading the customization image quality. Extensive experiments validate the superiority of our method on two mainstream customization methods of diffusion models, compared to existing protections. To explain the surprising success of targeted attacks, we delve into the mechanism of attack-based protections and propose a hypothesis based on our observation, which enhances the comprehension of attack-based protections. To the best of our knowledge, we are the first to both reveal the vulnerability of diffusion models to targeted attacks and leverage targeted attacks to enhance protection against unauthorized diffusion customization.", "title_embedding_index": 10570, "title_abs_embedding_index": 10595}, {"title": "OCEAN: Online Multi-modal Root Cause Analysis for Microservice Systems", "link_suffix": "/forum?id=7BiXovdUFX", "link": "https://openreview.net/forum?id=7BiXovdUFX", "pdf_link": "https://openreview.net/pdf?id=7BiXovdUFX", "keywords": "Root Cause Analysis, Online Learning, Multi-modal Learning", "abstract": "Root Cause Analysis (RCA) is essential for pinpointing the root causes of failures in microservice systems. Traditional data-driven RCA methods are typically limited to offline applications due to high computational demands, and existing online RCA methods handle only single-modal data, overlooking complex interactions in multi-modal systems. In this paper, we introduce OCEAN, a novel online multi-modal causal structure learning method for root cause localization. OCEAN employs a dilated convolutional neural network to capture long-term temporal dependencies and graph neural networks to learn causal relationships among system entities and key performance indicators. We further design a multi-factor attention mechanism to analyze and reassess the relationships among different metrics and log indicators/attributes for enhanced online causal graph learning. Additionally, a contrastive mutual information maximization-based graph fusion module is developed to effectively model the relationships across various modalities. Extensive experiments on three real-world datasets demonstrate the effectiveness and efficiency of our proposed method.", "title_embedding_index": 10571, "title_abs_embedding_index": 10596}, {"title": "Diffusion & Adversarial Schr\u00f6dinger Bridges via Iterative Proportional Markovian Fitting", "link_suffix": "/forum?id=LikKyNlzgP", "link": "https://openreview.net/forum?id=LikKyNlzgP", "pdf_link": "https://openreview.net/pdf?id=LikKyNlzgP", "keywords": "Schr\u00f6dinger Bridge, Optimal Transport, Entropic Optimal Transport, Unpaired Learning", "abstract": "The Iterative Markovian Fitting (IMF) procedure based on iterative reciprocal and Markovian projections has recently been proposed as a powerful method for solving the Schr\u00f6dinger Bridge problem. However, it has been observed that for the practical implementation of this procedure, it is crucial to alternate between fitting a forward and backward time diffusion at each iteration. Such implementation is thought to be a practical heuristic, which is required to stabilize training and obtain good results in applications such as unpaired domain translation. In our work, we show that this heuristic closely connects with the pioneer approaches for the Schr\u00f6dinger Bridge based on the Iterative Proportional Fitting (IPF) procedure. Namely, we find that the practical implementation of IMF is, in fact, a combination of IMF and IPF procedures, and we call this combination the Iterative Proportional Markovian Fitting (IPMF) procedure. We show both theoretically and practically that this combined IPMF procedure can converge under more general settings, thus, showing that the IPMF procedure opens a door towards developing a unified framework for solving Schr\u00f6dinger Bridge problems.", "title_embedding_index": 10572, "title_abs_embedding_index": 10597}, {"title": "Unifying All Species: LLM-based Hyper-Heuristics for Multi-objective Optimization", "link_suffix": "/forum?id=sUywd7UhFT", "link": "https://openreview.net/forum?id=sUywd7UhFT", "pdf_link": "https://openreview.net/pdf?id=sUywd7UhFT", "keywords": "Multi-Objective Optimization, Hierarchical Reflective Evolution, Ant Colony Optimization, Metaheuristic Algorithms, Combinatorial Optimization", "abstract": "Optimization problems are fundamental across various fields, including logistics, machine learning, and bioinformatics, where challenges are often characterized by complexity, high dimensionality. Modeling the interplay among multiple objectives is beneficial for optimization. However, existing Neural Combinatorial Optimization (NCO) methods and Large Language Model (LLM)-based approaches show limitations in adaptability and computational efficiency, primarily focusing on single-objective optimization. In this paper, we propose a novel framework, Multi-Objective Hierarchical Reflective Evolution (MHRE), for optimizing and generating heuristics algorithms for a broad range of optimization problems. Specifically, we extend the optimization space of the conventional hyper-heuristic methodologies, which allows us to unify similarity algorithms. We successfully construct Generalized Evolutionary Metaheuristic Algorithm (GEMA) for unifying metaheuristic algorithms. Yielding improved performance in experimental results. To show the performance of our method, we further applied the MHRE framework to optimize the Ant Colony Optimization (ACO) algorithm, achieving state-of-the-art results on random TSP problems and the TSPLib benchmark datasets. Our findings illustrate that the MLHH framework offers a robust and innovative solution for tackling complex optimization challenges, paving the way for future research in this area.\nFor better reproducibility, we open source the code at \\url{https://anonymous.4open.science/r/MHRE-BB53}.", "title_embedding_index": 10573, "title_abs_embedding_index": 10598}, {"title": "Incrementally Adapting Generative Vision-Language Models with Task Codebook", "link_suffix": "/forum?id=EKfcngSxwD", "link": "https://openreview.net/forum?id=EKfcngSxwD", "pdf_link": "https://openreview.net/pdf?id=EKfcngSxwD", "keywords": "Generative Vision-Language Models, Incremental Learning", "abstract": "With the help of large-scale pre-training, generative Vision-Language Models (VLMs) have acquired general-purpose capabilities.\nAs downstream applications diversify, it is imperative for VLMs to learn and adapt continuously without experiencing catastrophic forgetting or necessitating complete retraining.\nIn this work, we analyze the forgetting behavior of VLMs and propose a solution to enhance their incremental learning abilities.\nWe introduce a Task Codebook within VLMs, enabling efficient retrieval of task-specific parameters for model adaptation. \nOur evaluation encompasses a diverse set of tasks spanning a wide range of visual domains and textual instructions. \nExperiments demonstrate that our approach effectively mitigates forgetting, even under highly demanding task sequences.", "title_embedding_index": 10574, "title_abs_embedding_index": 10599}]
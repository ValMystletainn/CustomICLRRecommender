[{"title": "Domain Guidance: A Simple Transfer Approach for a Pre-trained Diffusion Model", "link_suffix": "/forum?id=PplM2kDrl3", "link": "https://openreview.net/forum?id=PplM2kDrl3", "pdf_link": "https://openreview.net/pdf?id=PplM2kDrl3", "keywords": "transfer learning, diffusion models, fine-tuning, guidance", "abstract": "Recent advancements in diffusion models have revolutionized generative modeling. However, the impressive and vivid outputs they produce often come at the cost of significant model scaling and increased computational demands. Consequently, building personalized diffusion models based on off-the-shelf models has emerged as an appealing alternative. In this paper, we introduce a novel perspective on conditional generation for transferring a pre-trained model. From this viewpoint, we propose \\textit{Domain Guidance}, a straightforward transfer approach that leverages pre-trained knowledge to guide the sampling process toward the target domain. Domain Guidance shares a formulation similar to advanced classifier-free guidance, facilitating better domain alignment and higher-quality generations. We provide both empirical and theoretical analyses of the mechanisms behind Domain Guidance. Our experimental results demonstrate its substantial effectiveness across various transfer benchmarks, achieving over a 19.6% improvement in FID and a 20.6% improvement in FD$_\\text{DINOv2}$ compared to standard fine-tuning. Notably, existing fine-tuned models can seamlessly integrate Domain Guidance to leverage these benefits, without additional training.", "title_embedding_index": 21600, "title_abs_embedding_index": 21625}, {"title": "Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Models", "link_suffix": "/forum?id=uAFHCZRmXk", "link": "https://openreview.net/forum?id=uAFHCZRmXk", "pdf_link": "https://openreview.net/pdf?id=uAFHCZRmXk", "keywords": "CLIP, modality gap, object bias, contrastive loss, data-centric, vision language models, VLM", "abstract": "Contrastive vision-language models (VLMs), like CLIP, have gained popularity for their versatile applicability to various downstream tasks. Despite their successes in some tasks, like zero-shot object recognition, they perform surprisingly poor on other tasks, like attribute recognition. Previous work has attributed these challenges to the modality gap, a separation of image and text in the shared representation space, and to a bias towards objects over other factors, such as attributes. In this analysis paper, we investigate both phenomena thoroughly. We evaluated off-the-shelf VLMs and find that while the gap's influence on performance is typically overshadowed by other factors, we find indications that closing the gap indeed leads to improvements. Moreover, we find that, contrary to intuition, only few embedding dimensions drive the gap and that the embedding spaces are differently organized. To allow for a clean study of object bias, we introduce a definition and a corresponding measure of it. Equipped with this tool, we find that object bias does not lead to worse performance on other concepts, such as attributes per se. However, why do both phenomena, modality gap and object bias, emerge in the first place? To answer this fundamental question and uncover some of the inner workings of contrastive VLMs, we conducted experiments that allowed us to control the amount of shared information between the modalities. These experiments revealed that the driving factor behind both the modality gap and the object bias, is an information imbalance between images and captions, and unveiled an intriguing connection between the modality gap and entropy of the logits.", "title_embedding_index": 21601, "title_abs_embedding_index": 21626}, {"title": "PTNQ: Post-Training Non-Linear Quantization", "link_suffix": "/forum?id=AEvu2ifH1r", "link": "https://openreview.net/forum?id=AEvu2ifH1r", "pdf_link": "https://openreview.net/pdf?id=AEvu2ifH1r", "keywords": "quantization", "abstract": "Quantization is one of the leading techniques to reduce the memory usage of machine learning models.\nIt works by approximating the weights of a model by some function with a smaller domain (e.g., replace 32-bit floats with 8-bit integers that are coefficients in some function that maps back to 32-bit floats).Although most quantization methods approximate weights with a linear or affine function, the weights of current machine learning models often exhibit non-linear behavior at the extremities.\nMoreover, some studies suggest that the extremities are important for the end-to-end accuracy.In this paper, we introduce PTNQ, a novel post-training quantization technique that approximates weights by searching through a pool of non-linear functions.\nWe show that PTNQ provides significant advantages over affine functions, achieving similar accuracy while requiring 2 to 4 fewer bits per coefficient.", "title_embedding_index": 21602, "title_abs_embedding_index": 21627}, {"title": "Conditional Diffusion on Web-Scale Image Pairs leads to Diverse Image Variations", "link_suffix": "/forum?id=s7vwXDsVYa", "link": "https://openreview.net/forum?id=s7vwXDsVYa", "pdf_link": "https://openreview.net/pdf?id=s7vwXDsVYa", "keywords": "diffusion, image variations, generative models", "abstract": "Generating image variations, where a model produces variations of an input image while preserving the semantic context has gained increasing attention. Current image variation techniques involve adapting a text-to-image model to reconstruct an input image conditioned on the same image. We first demonstrate that a diffusion model trained to reconstruct an input image from frozen embeddings can reconstruct the image with minor variations. Second, inspired by how text-to-image models learn from web-scale text-image pairs, we explore a new pretraining strategy to generate image variations using a large collection of image pairs. Our diffusion model \\textit{Semantica} receives a random (encoded) image from a webpage as conditional input and denoises another noisy random image from the same webpage. We carefully examine various design choices for the image encoder, given its crucial role in extracting relevant context from the input image. Once trained, \\textit{Semantica} can adaptively generate new images from a dataset by simply using images from that dataset as input. Finally, we identify limitations in standard image consistency metrics for evaluating image variations and propose alternative metrics based on few-shot generation.", "title_embedding_index": 21603, "title_abs_embedding_index": 21628}, {"title": "MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation", "link_suffix": "/forum?id=4z3IguA4Zg", "link": "https://openreview.net/forum?id=4z3IguA4Zg", "pdf_link": "https://openreview.net/pdf?id=4z3IguA4Zg", "keywords": "Hallucination Mitigation, Multimodal Large Language Models, Decoding Strategy", "abstract": "Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood. In this paper, we present an empirical analysis and find that, although MLLMs incorrectly generate the targets in the final output, they are actually able to recognize visual objects in the preceding layers. We speculate that this may be due to the strong knowledge priors of the language model suppressing the visual information, leading to hallucinations. Motivated by this, we propose a novel dynamic correction decoding method for MLLMs (Deco), which adaptively selects the appropriate preceding layers and proportionally integrates knowledge into the final layer to adjust the output logits. Note that Deco is model agnostic and can be seamlessly incorporated with various classic decoding strategies and applied to different MLLMs. We evaluate Deco on widely-used benchmarks, demonstrating that it can reduce hallucination rates by a large margin compared to baselines, highlighting its potential to mitigate hallucinations.", "title_embedding_index": 21604, "title_abs_embedding_index": 21629}, {"title": "SpacetimeE(n)-Transformer: Equivariant Attention for Spatio-temporal Graphs", "link_suffix": "/forum?id=VZ8kwfspAi", "link": "https://openreview.net/forum?id=VZ8kwfspAi", "pdf_link": "https://openreview.net/pdf?id=VZ8kwfspAi", "keywords": "graph neural networks, graph representation learning", "abstract": "We introduce an $E(n)$-equivariant Transformer architecture for spatio-temporal graph data. By imposing rotation, translation, and permutation equivariance inductive biases in both space and time, we show that the Spacetime $E(n)$-Transformer (SET) outperforms purely spatial and temporal models without symmetry-preserving properties. We benchmark SET against said models on the $N$-body problem, a simple physical system with complex dynamics. While existing spatio-temporal graph neural networks focus on sequential modeling, we empirically demonstrate that leveraging underlying domain symmetries yields considerable improvements for modeling dynamical systems on graphs.", "title_embedding_index": 21605, "title_abs_embedding_index": 21630}, {"title": "GDrag:Towards General-Purpose Interactive Editing with Anti-ambiguity Point Diffusion", "link_suffix": "/forum?id=8G3FyfHIko", "link": "https://openreview.net/forum?id=8G3FyfHIko", "pdf_link": "https://openreview.net/pdf?id=8G3FyfHIko", "keywords": "Interactive editing, dragging-based image manipulation, diffusion models", "abstract": "Recent interactive point-based image manipulation methods have gained considerable attention for being user-friendly. However, these methods still face two types of ambiguity issues that can lead to unsatisfactory outcomes, namely, intention ambiguity which misinterprets the purposes of users, and content ambiguity where target image areas are distorted by distracting elements. To address these issues and achieve general-purpose manipulations, we propose a novel task-aware, training-free framework called GDrag. Specifically, GDrag defines a taxonomy of atomic manipulations, which can be parameterized and combined unitedly to represent complex manipulations, thereby reducing intention ambiguity. Furthermore, GDrag introduces two strategies to mitigate content ambiguity, including an anti-ambiguity dense trajectory calculation method (ADT) and a self-adaptive motion supervision method (SMS). Given an atomic manipulation, ADT converts the sparse user-defined handle points into a dense point set by selecting their semantic and geometric neighbors, and calculates the trajectory of the point set. Unlike previous motion supervision methods relying on a single global scale for low-rank adaption, SMS jointly optimizes point-wise adaption scales and latent feature biases. These two methods allow us to model fine-grained target contexts and generate precise trajectories. As a result, GDrag consistently produces precise and appealing results in different editing tasks. Extensive experiments on the challenging DragBench dataset demonstrate that GDrag outperforms state-of-the-art methods significantly. The code of GDrag will be released upon acceptance.", "title_embedding_index": 21606, "title_abs_embedding_index": 21631}, {"title": "InterDance: Reactive 3D Dance Generation with Realistic Duet Interactions", "link_suffix": "/forum?id=KfkmwYQXWh", "link": "https://openreview.net/forum?id=KfkmwYQXWh", "pdf_link": "https://openreview.net/pdf?id=KfkmwYQXWh", "keywords": "Motion Synthesis, Human Interaction", "abstract": "Humans can perform a variety of interactive motions, among which two-person dance is one of the most challenging interactions. However, in terms of computer motion generation, current work is still unable to generate high-quality interactive motion, especially in the field of duet dance. On the one hand, this is caused by the lack of large-scale high-quality datasets. On the other hand, it arises from the incomplete representation of interactive motion and the lack of fine-grained optimization of interactions. To address these challenges, we propose a duet dance dataset that significantly enhances motion quality, data scale, and the variety of dance genres. Based on this dataset, we propose a new motion representation that can accurately and comprehensively describe interactive motion. We further introduce a diffusion-based algorithm with an interaction refine guidance strategy to optimize the realism of interactions progressively. Experiments demonstrate the effectiveness of our dataset and algorithm. Our project page ishttps://inter-dance.github.io/.", "title_embedding_index": 21607, "title_abs_embedding_index": 21632}, {"title": "AvatarGO: Zero-shot 4D Human-Object Interaction Generation and Animation", "link_suffix": "/forum?id=Trf0R8eoGF", "link": "https://openreview.net/forum?id=Trf0R8eoGF", "pdf_link": "https://openreview.net/pdf?id=Trf0R8eoGF", "keywords": "4D human avatar generation, compositional generation, human-object interaction", "abstract": "Recent advancements in diffusion models have led to significant improvements in the generation and animation of 4D full-body human-object interactions (HOI). Nevertheless, existing methods primarily focus on SMPL-based motion generation, which is limited by the scarcity of realistic large-scale interaction data. This constraint affects their ability to create everyday HOI scenes. This paper addresses this challenge using a zero-shot approach with a pre-trained diffusion model. Despite this potential, achieving our goals is difficult due to the diffusion model's lack of understanding of ''where'' and ''how'' objects interact with the human body. To tackle these issues, we introduceAvatarGO, a novel framework designed to generate animatable 4D HOI scenes directly from textual inputs. Specifically,1)for the ''where'' challenge, we proposeLLM-guided contact retargeting, which employs Lang-SAM to identify the contact body part from text prompts, ensuring precise representation of human-object spatial relations.2)For the ''how'' challenge, we introducecorrespondence-aware motion optimizationthat constructs motion fields for both human and object models using the linear blend skinning function from SMPL-X.  Our framework not only generates coherent compositional motions, but also exhibits greater robustness in handling penetration issues. Extensive experiments with existing methods validate AvatarGO's superior generation and animation capabilities on a variety of human-object pairs and diverse poses. As the first attempt to synthesize 4D avatars with object interactions, we hope AvatarGO could open new doors for human-centric 4D content creation.", "title_embedding_index": 21608, "title_abs_embedding_index": 21633}, {"title": "Enhancing Certified Robustness via Block Reflector Orthogonal Layers", "link_suffix": "/forum?id=yi3QcCGfP1", "link": "https://openreview.net/forum?id=yi3QcCGfP1", "pdf_link": "https://openreview.net/pdf?id=yi3QcCGfP1", "keywords": "Certified robustness, Adversarial", "abstract": "Lipschitz neural networks are well-known for providing certified robustness in deep learning. In this paper, we present a novel efficient Block Reflector Orthogonal layer that enables the construction of simple yet effective Lipschitz neural networks. \nIn addition, by theoretically analyzing the nature of Lipschitz neural networks, we introduce a new loss function that employs an annealing mechanism to improve margin for most data points.\nThis enables Lipschitz models to provide better certified robustness.\nBy employing our BRO layer and loss function, we design BRONet, which provides state-of-the-art certified robustness.\t\nExtensive experiments and empirical analysis on CIFAR-10, CIFAR-100, and Tiny-ImageNet validate that our method outperforms existing baselines.", "title_embedding_index": 21609, "title_abs_embedding_index": 21634}, {"title": "DSConv: Dynamic Convolution On Serialized Point Cloud", "link_suffix": "/forum?id=XfWJT3BUmX", "link": "https://openreview.net/forum?id=XfWJT3BUmX", "pdf_link": "https://openreview.net/pdf?id=XfWJT3BUmX", "keywords": "Point cloud serialization; Point cloud analysis; 3D object classification; 3D semantic segmentation; Deep learning architectures", "abstract": "In recent years, research on point-based architectures has advanced rapidly, showcasing their competitive performance. However, the unstructured nature of point clouds limits the application of effective operators such as convolutions in feature extraction. Although many works have attempted to address the issues of unstructured data and introduce convolutions or transformers, the complex spatial mappings of point clouds and cumbersome convolution implementations in these methods limit real-time performance of the model. Furthermore, excessive structural mapping ignores the independence of point cloud position representation and fails to capture finer-grained features. To tackle these challenges, we serialize point clouds to provide them with structure and introduce AdaConv to directly utilize 2D convolutions, which simplifies the process and better preserves the relative positional relationship. Additionally, we propose a novel dynamic refinement approach for point cloud positions, continuously modifying the coordinates of points within the convolutional neighborhood to enhance the flexibility and adaptability. We also integrate local and global features to compensate for the loss of point cloud features during downsampling. Finally, we propose DSConv based on PointNeXt, maintaining scalability and inference speed. By combining DSConv with new architectural designs, we outperform the current state-of-the-art methods on ScanObjectNN, Scannet V2, and S3DIS datasets.", "title_embedding_index": 21610, "title_abs_embedding_index": 21635}, {"title": "Calibrating LLMs with Information-Theoretic Evidential Deep Learning", "link_suffix": "/forum?id=YcML3rJl0N", "link": "https://openreview.net/forum?id=YcML3rJl0N", "pdf_link": "https://openreview.net/pdf?id=YcML3rJl0N", "keywords": "evidential deep learning; information bottleneck; calibration; large language models", "abstract": "Fine-tuned large language models (LLMs) often exhibit overconfidence, particularly when trained on small datasets, resulting in poor calibration and inaccurate uncertainty estimates. \nEvidential Deep Learning (EDL), an uncertainty-aware approach, enables uncertainty estimation in a single forward pass, making it a promising method for calibrating fine-tuned LLMs. However, despite its computational efficiency, EDL is prone to overfitting, as its training objective can result in overly concentrated probability distributions. \nTo mitigate this, we propose regularizing EDL by incorporating an information bottleneck (IB). Our approach IB-EDL suppresses spurious information in the evidence generated by the model and encourages truly predictive information to influence both the predictions and uncertainty estimates. Extensive experiments across various fine-tuned LLMs and tasks demonstrate that IB-EDL outperforms both existing EDL and non-EDL approaches. \nBy improving the trustworthiness of LLMs, IB-EDL facilitates their broader adoption in domains requiring high levels of confidence calibration.", "title_embedding_index": 21611, "title_abs_embedding_index": 21636}, {"title": "CodeDPO: Aligning Code Models with Self Generated and Verified Source Code", "link_suffix": "/forum?id=U5TebOVpfd", "link": "https://openreview.net/forum?id=U5TebOVpfd", "pdf_link": "https://openreview.net/pdf?id=U5TebOVpfd", "keywords": "Code Generation, Preference Optimization", "abstract": "Code generation models have shown significant potential for programming tasks. \nHowever, existing training methods like supervised fine-tuning face key limitations: they do not effectively teach models to prioritize correct over incorrect solutions in ambiguous situations, nor do they effectively optimize the runtime efficiency of the generated code. \nTo address these challenges, we propose CodeDPO, a framework that integrates preference learning into code generation to improve two key code preference factors: code correctness and efficiency.\nCodeDPO employs a novel dataset construction method, utilizing a self-generation-and-validation mechanism that simultaneously generates and evaluates code and test cases. \nThe underlying assumption is that test cases executable by multiple code snippets provide more reliable validation, and code that passes more tests is more likely to be correct. \nThrough this self-validation process, our PageRank-inspired algorithm iteratively updates the ranking score of each code snippet, ultimately creating a code preference optimization dataset based on correctness and efficiency.\nCodeDPO is flexible and scalable, generating diverse preference optimization data without depending on external resources. \nThrough comprehensive evaluations of five widely used benchmarks, CodeDPO demonstrates significant improvements in correctness and efficiency compared to existing methods. \nOur experiments prove that CodeDPO enhances the capabilities of LLMs in code generation and provides a robust foundation for conducting code preference optimization in more complex and challenging real-world scenarios.\nCode and additional details are available:https://anonymous.4open.science/r/CodeDPO.", "title_embedding_index": 21612, "title_abs_embedding_index": 21637}, {"title": "TIGeR: Unifying Text-to-Image Generation and Retrieval with Large Multimodal Models", "link_suffix": "/forum?id=mr2icR6dpD", "link": "https://openreview.net/forum?id=mr2icR6dpD", "pdf_link": "https://openreview.net/pdf?id=mr2icR6dpD", "keywords": "Multimodal Large Language Models, Text-to-Image Generation, Cross-Modal Retrieval", "abstract": "How humans can effectively and efficiently acquire images has always been a perennial question. A classic solution istext-to-image retrievalfrom an existing database; however, the limited database typically lacks creativity. By contrast, recent breakthroughs intext-to-image generationhave made it possible to produce attractive and counterfactual visual content, but it faces challenges in synthesizing knowledge-intensive images. In this work, we rethink the relationship between text-to-image generation and retrieval, proposing aunifiedframework for both tasks with one single Large Multimodal Model (LMM). Specifically, we first explore the intrinsic discriminative abilities of LMMs and introduce an efficient generative retrieval method for text-to-image retrieval in a training-free manner. Subsequently, we unify generation and retrieval autoregressively and propose an autonomous decision mechanism to choose the best-matched one between generated and retrieved images as the response to the text prompt. To standardize the evaluation of unified text-to-image generation and retrieval, we construct TIGeR-Bench, a benchmark spanning both creative and knowledge-intensive domains. Extensive experiments on TIGeR-Bench and two retrieval benchmarks,i.e., Flickr30K and MS-COCO, demonstrate the superiority of our proposed framework.", "title_embedding_index": 21613, "title_abs_embedding_index": 21638}, {"title": "Cross-Embodiment Dexterous Grasping with Reinforcement Learning", "link_suffix": "/forum?id=twIPSx9qHn", "link": "https://openreview.net/forum?id=twIPSx9qHn", "pdf_link": "https://openreview.net/pdf?id=twIPSx9qHn", "keywords": "dexterous grasping, cross-embodiment learning, reinforcement learning", "abstract": "Dexterous hands exhibit significant potential for complex real-world grasping tasks. While recent studies have primarily focused on learning policies for specific robotic hands, the development of a universal policy that controls diverse dexterous hands remains largely unexplored.\nIn this work, we study the learning of cross-embodiment dexterous grasping policies using reinforcement learning (RL). Inspired by the capability of human hands to control various dexterous hands through teleoperation, we propose a universal action space based on the human hand's eigengrasps. The policy outputs eigengrasp actions that are then converted into specific joint actions for each robot hand through a retargeting mapping. We simplify the robot hand's proprioception to include only the positions of fingertips and the palm, offering a unified observation space across different robot hands. Our approach demonstrates an 80% success rate in grasping objects from the YCB dataset across four distinct embodiments using a single vision-based policy. Additionally, our policy exhibits zero-shot generalization to two previously unseen embodiments and significant improvement in efficient finetuning. For further details and videos, visit our project page.", "title_embedding_index": 21614, "title_abs_embedding_index": 21639}, {"title": "Learning Visual Prompts for Guiding the Attention of Vision Transformers", "link_suffix": "/forum?id=hDPwaYVxBx", "link": "https://openreview.net/forum?id=hDPwaYVxBx", "pdf_link": "https://openreview.net/pdf?id=hDPwaYVxBx", "keywords": "vision transformers, attention, visual prompting, universal adversarial patch, universal adversarial transferability", "abstract": "to be completed laterVisual prompting infuses visual information into the input image to adapt models toward specific predictions and tasks. Recently, manually crafted markers such as red circles are shown to guide the model to attend to a target region on the image. However, these markers only work on models trained with data containing those markers. Moreover, finding these prompts requires guesswork or prior knowledge of the domain on which the model is trained. This work circumvents manual design constraints by proposing to learn the visual prompts for guiding the attention of vision transformers. The learned visual prompt, added to any input image would redirect the attention of the pre-trained vision transformer to its spatial location on the image. Specifically, the prompt is learned in a self-supervised manner without requiring annotations and without fine-tuning the vision transformer. Our experiments demonstrate the effectiveness of the proposed optimization-based visual prompting strategy across various pre-trained vision encoders.", "title_embedding_index": 21615, "title_abs_embedding_index": 21640}, {"title": "BiDoRA: Bi-level Optimization-based Weight-Decomposed Low-Rank Adaptation", "link_suffix": "/forum?id=WzUPae4WnA", "link": "https://openreview.net/forum?id=WzUPae4WnA", "pdf_link": "https://openreview.net/pdf?id=WzUPae4WnA", "keywords": "Parameter-Efficient Fine-Tuning, Bi-level Optimization, Large Language Model", "abstract": "Parameter-efficient fine-tuning (PEFT) of large language models (LLMs) has gained considerable attention as a flexible and efficient way of adapting LLMs to downstream tasks.\nAmong these methods, weighted decomposed low-rank adaptation (DoRA) has emerged as a promising approach.\nDoRA bridges the gap between low-rank adaptation (LoRA) and full fine-tuning (FT) by decomposing the weight matrices into magnitude and direction components, thereby maintaining learning behavior similar to FT.\nAlthough DoRA shows encouraging performance, it introduces additional parameters compared to LoRA, which potentially increases the risk of overfitting.\nMoreover, optimizing magnitude and direction simultaneously leads to a coupled gradient updating pattern for both components, limiting its learning capacity.\nTo overcome these limitations, we propose BiDoRA, a bi-level optimization-based PEFT method.\nIn BiDoRA, the direction and magnitude components are optimized on two distinct datasets at different optimization levels, mitigating the risk of overfitting.\nAdditionally, the asynchronous optimization of the two components promotes their decoupling, allowing for more flexible gradient updates suitable for various downstream tasks.\nEvaluation of BiDoRA on fourteen datasets spanning natural language understanding, natural language generation, and token classification reveals that it significantly outperforms DoRA and other PEFT methods.\nThe superior performance of BiDoRA underscores its effectiveness.\nThe code for BiDoRA is available athttps://anonymous.4open.science/r/BiDoRA-5D31.", "title_embedding_index": 21616, "title_abs_embedding_index": 21641}, {"title": "Honey: Harmonizing Progressive Federated Learning via Elastic Synergy across Different Training Blocks", "link_suffix": "/forum?id=JfgBhEqk6F", "link": "https://openreview.net/forum?id=JfgBhEqk6F", "pdf_link": "https://openreview.net/pdf?id=JfgBhEqk6F", "keywords": "Memory-Heterogeneous Federated Learning, Progressive Training, On-Device Training", "abstract": "Memory limitation is becoming the prevailing challenge that hinders the deployment of Federated Learning on mobile/IoT devices in real-world cases. Progressive training offers a promising alternative to surpass memory constraints. Instead of updating the full model in each training round, progressive training divides the model into multiple blocks and iteratively updates each block until the full model is converged. However, existing progressive training approaches suffer from prominent accuracy degradation as training each block in isolation drives it to prioritize features that are only beneficial to its specific needs, neglecting the overall learning objective. To address this issue, we present $\\texttt{\\textbf{Honey}}$, a synergistic progressive training approach that integrates the holistic view and block-wise feedback to facilitate the training of each block. Specifically, the holistic view broadens the learning scope of each block, ensuring that it operates in harmony with the global objective and benefits the training of the whole model. Simultaneously, block-wise feedback heightens each block's awareness of its role and position within the full model, empowering it to make real-time adjustments based on insights from downstream blocks and facilitating a smooth and consistent information flow. Furthermore, to fully harness the heterogeneous memory resources of participating devices, we develop an elastic resource harmonization protocol. \nThis protocol authorizes each device to adaptively train specific layers according to their memory capacity, optimizing resource utilization, sparking cross-block communication, and accelerating model convergence. Comprehensive experiments on benchmark datasets and models demonstrate that $\\texttt{\\textbf{Honey}}$ outperforms state-of-the-art approaches, delivering an exceptional average accuracy improvement of up to 43.9%. Moreover,  $\\texttt{\\textbf{Honey}}$ achieves comparable performance even with a reduction in peak memory usage of up to 49%.", "title_embedding_index": 21617, "title_abs_embedding_index": 21642}, {"title": "VEDIT: Latent Prediction Architecture For Procedural Video Representation Learning", "link_suffix": "/forum?id=LDAj4UJ4aL", "link": "https://openreview.net/forum?id=LDAj4UJ4aL", "pdf_link": "https://openreview.net/pdf?id=LDAj4UJ4aL", "keywords": "Procedural Learning from Videos, Representation Learning, Diffusion Transformer", "abstract": "Procedural video representation learning is an active research area where the objective is to learn an agent which can anticipate and forecast the future given the present video input, typically in conjunction with textual annotations. Prior works often rely on large-scale pretraining of visual encoders and prediction models with language supervision. However, the necessity and effectiveness of extending compute intensive pretraining to learn video clip sequences with noisy text supervision have not yet been fully validated by previous works. In this work, we show that a strong off-the-shelf frozen pretrained visual encoder, along with a well designed prediction model, can achieve state-of-the-art (SoTA) performance in forecasting and procedural planning without the need for pretraining the prediction model, nor requiring additional supervision from language or ASR. Instead of learning representations from pixel space, our method utilizes the latent embedding space of publicly available vision encoders. By conditioning on frozen clip-level embeddings from observed steps to predict the actions of unseen steps, our prediction model is able to learn robust representations for forecasting through iterative denoising \u2014leveraging the recent advances in diffusion transformers (Peebles & Xie, 2023). Empirical studies over a total of five procedural learning tasks across four datasets (NIV, CrossTask, COIN and Ego4D-v2) show that our model advances the strong baselines in long-horizon action anticipation (+2.6% in Verb ED@20, +3.1% in Noun ED@20), and significantly improves the SoTA in step forecasting (+5.0%), task classification (+3.8%), and procedure planning tasks (up to +2.28% in success rate, +3.39% in mAcc, and +0.90% in mIoU).", "title_embedding_index": 21618, "title_abs_embedding_index": 21643}, {"title": "Make Interval Bound Propagation great again", "link_suffix": "/forum?id=U7kzrhRxHn", "link": "https://openreview.net/forum?id=U7kzrhRxHn", "pdf_link": "https://openreview.net/pdf?id=U7kzrhRxHn", "keywords": "interval arthmetic, IBP", "abstract": "In various scenarios motivated by real life, such as medical data analysis, autonomous driving, and adversarial training, we are interested in robust deep networks. A network is robust when a relatively small perturbation of the input cannot lead to drastic changes in output (like change of class, etc.). This falls under the broader scope field of Neural Network Certification (NNC).\nTwo crucial problems in NNC are of profound interest to the scientific community: how to calculate the robustness of a given pre-trained network and how to construct robust networks. The common approach to constructing robust networks is Interval Bound Propagation (IBP). \nThis paper demonstrates that IBP is sub-optimal in the first case due to its susceptibility to the wrapping effect. Even for linear activation, IBP gives strongly sub-optimal bounds. Consequently, one should use strategies immune to the wrapping effect to obtain bounds close to optimal ones. We adapt two classical approaches dedicated to strict computations -- Dubleton Arithmetic and Affine Arithmetic -- to mitigate the wrapping effect in neural networks. These techniques yield precise results for networks with linear activation functions, thus resisting the wrapping effect. As a result, we achieve bounds significantly closer to the optimal level than IBPs.", "title_embedding_index": 21619, "title_abs_embedding_index": 21644}, {"title": "Roll the dice: Monte Carlo Downsampling as a low-cost Adversarial Defence", "link_suffix": "/forum?id=KoQkr9eIUG", "link": "https://openreview.net/forum?id=KoQkr9eIUG", "pdf_link": "https://openreview.net/pdf?id=KoQkr9eIUG", "keywords": "adversarial attacks, adversarial defense, stochasticity", "abstract": "The well-known vulnerability of Neural Networks to adversarial attacks is concerning, more so with the increasing reliance on them for real-world applications like autonomous driving, medical imaging, and others.\nMultiple previous works have proposed defense methods against adversarial attacks, including adversarial training, adding random noise to images, frequency pooling, and others.\nWe observe from several such works, that there are two main paradigms for mitigating adversarial attacks.\nFirst, effective downsampling leads to learning better feature representations during training, thus improving the performance on attacked and non-attacked samples. \nHowever, these methods are expensive.\nSecond, perturbing samples with for example random noise helps in mitigating adversarial attacks as they stymie the flow of gradients to optimize the attacks. \nHowever, these methods lower the network's performance on non-attacked samples.\nThus, in this work, we combine the best of both strategies to propose a novel Monte-Carlo sampling-based approach for downsampling called Stochastic Downsampling.\nWe combine bi-linear interpolation with Monte Carlo integration for performing downsampling.\nThis helps us mitigate adversarial attacks while preserving the performance of non-attacked samples, thus increasing reliability.\nOur proposed Stochastic Downsampling operator can easily be integrated into any existing architecture, including adversarially pre-trained networks, with some finetuning.\nWe show the effectiveness of Stochastic Dowsampling over multiple image classification datasets using different network architectures with different training strategies.\nWe provide the code for performing Stochastic Downsampling here: Anonymous GitHub Repository (https://anonymous.4open.science/r/stochastic-downsampling/).", "title_embedding_index": 21620, "title_abs_embedding_index": 21645}, {"title": "What Matters in Hierarchical Search for Combinatorial Reasoning Problems?", "link_suffix": "/forum?id=eqVu9eaVAB", "link": "https://openreview.net/forum?id=eqVu9eaVAB", "pdf_link": "https://openreview.net/pdf?id=eqVu9eaVAB", "keywords": "deep learning, search, subgoals, hierarchical reinforcement learning, imitation learning", "abstract": "Combinatorial reasoning problems, particularly the notorious NP-hard tasks, remain a significant challenge for AI research. A common approach to addressing them combines search with learned heuristics. Recent methods in this domain utilize hierarchical planning, executing strategies based on subgoals. Our goal is to advance research in this area and establish a solid conceptual and empirical foundation. Specifically, we identify the following key obstacles, whose presence favors the choice of hierarchical search methods:hard-to-learn value functions,complex action spaces,presence of dead ends in the environment, ordata collected from diverse sources. Through in-depth empirical analysis, we establish that hierarchical search methods consistently outperform standard search methods across these dimensions, and we formulate insights for future research. On the practical side, we also propose a consistent evaluation methodology to enable meaningful comparisons between methods and to reassess the state-of-the-art algorithms.", "title_embedding_index": 21621, "title_abs_embedding_index": 21646}, {"title": "General Compression Framework for Efficient Transformer Object Tracking", "link_suffix": "/forum?id=lXv9DTw650", "link": "https://openreview.net/forum?id=lXv9DTw650", "pdf_link": "https://openreview.net/pdf?id=lXv9DTw650", "keywords": "Object Tracking, Efficient Tracking, Lightweight Model, Knowledge Distillation", "abstract": "Transformer-based trackers have established a dominant role in the field of visual object tracking. While these trackers exhibit promising performance, their deployment on resource-constrained devices remains challenging due to inefficiencies. To improve the inference efficiency and reduce the computation cost, prior approaches have aimed to either design lightweight trackers or distill knowledge from larger teacher models into more compact student trackers. However, these solutions often sacrifice accuracy for speed. Thus, we propose a general model compression framework for efficient transformer object tracking, named CompressTracker, to reduce the size of a pre-trained tracking model into a lightweight tracker with minimal performance degradation. Our approach features a novel stage division strategy that segments the transformer layers of the teacher model into distinct stages, enabling the student model to emulate each corresponding teacher stage more effectively. Additionally, we also design a unique replacement training technique that involves randomly substituting specific stages in the student model with those from the teacher model, as opposed to training the student model in isolation. Replacement training enhances the student model's ability to replicate the teacher model's behavior. To further forcing student model to emulate teacher model, we incorporate prediction guidance and stage-wise feature mimicking to provide additional supervision during the teacher model's compression process. Our framework CompressTracker is structurally agnostic, making it compatible with any transformer architecture. We conduct a series of experiment to verify the effectiveness and generalizability of CompressTracker. Our CompressTracker-4 with 4 transformer layers, which is compressed from OSTrack, retains about $\\mathbf{96%}$ performance on LaSOT ($\\mathbf{66.1%}$ AUC) while achieves $\\mathbf{2.17\\times}$ speed up.", "title_embedding_index": 21622, "title_abs_embedding_index": 21647}, {"title": "FlowBench: A Robustness Benchmark for Optical Flow Estimation", "link_suffix": "/forum?id=S4jzvOBs9m", "link": "https://openreview.net/forum?id=S4jzvOBs9m", "pdf_link": "https://openreview.net/pdf?id=S4jzvOBs9m", "keywords": "Adversarial attacks, optical flow estimation, benchmarking tool, benchmark, robustness", "abstract": "Optical flow estimation is a crucial computer vision task often applied to safety-critical real-world scenarios like autonomous driving and medical imaging.\nWhile optical flow estimation accuracy has greatly benefited from the emergence of deep learning, learning-based methods are also known for their lack of generalization and reliability.\nHowever, reliability is paramount when optical flow methods are employed in the real world, where safety is essential.\nFurthermore, a deeper understanding of the robustness and reliability of learning-based optical flow estimation methods is still lacking, hindering the research community from building methods safe for real-world deployment.\nThus we proposeFlowBench, a robustness benchmark and evaluation tool for learning-based optical flow methods.FlowBenchfacilitates streamlined research into the reliability of optical flow methods by benchmarking their robustness to adversarial attacks and out-of-distribution samples.\nWithFlowBench, we benchmark 89 methods across 3 different datasets under 7 diverse adversarial attacks and 23 established common corruptions, making it the most comprehensive robustness analysis of optical flow methods to date.\nAcross this wide range of methods, we consistently find that methods with state-of-the-art performance on established standard benchmarks lack reliability and generalization ability.\nMoreover, we find interesting correlations between performance, reliability, and generalization ability of optical flow estimation methods, under various lenses such as point matching method used, number of parameters, etc.\nAfter acceptance,FlowBenchwill be open-source and publicly available, including the weights of all tested models.", "title_embedding_index": 21623, "title_abs_embedding_index": 21648}, {"title": "Toward Trustworthy: A Method for Detecting Fine-Tuning Origins in LLMs", "link_suffix": "/forum?id=bowetgeOMw", "link": "https://openreview.net/forum?id=bowetgeOMw", "pdf_link": "https://openreview.net/pdf?id=bowetgeOMw", "keywords": "Fine-Tuning Origins Detection, LoRA, LLM", "abstract": "As large language models (LLMs) continue to advance, their deployment often involves fine-tuning to enhance performance on specific downstream tasks. However, this customization is sometimes accompanied by misleading claims about the origins, raising significant concerns about transparency and trust within the open-source community. Existing model verification techniques typically assess functional, representational, and weight similarities. However, these approaches often struggle against obfuscation techniques, such as permutations and scaling transformations, that obscure a model's lineage. To address this limitation, we propose a novel detection method that rigorously determines whether a model has been fine-tuned from a specified base model. This method includes the ability to extract the LoRA rank utilized during the fine-tuning process, providing a more robust verification framework. This framework is the first to provide a formalized approach specifically aimed at pinpointing the sources of model fine-tuning. We empirically validated our method on twenty-nine diverse open-source models under conditions that simulate real-world obfuscation scenarios. We empirically analyze the effectiveness of our framework and finally, discuss its limitations. The results demonstrate the effectiveness of our approach and indicate its potential to establish new benchmarks for model verification.", "title_embedding_index": 21624, "title_abs_embedding_index": 21649}]
[
    {
        "title": "AltDev: Achieving Real-Time Alignment in Multi-Agent Software Development",
        "link_suffix": "/forum?id=lVUuQhjbRd",
        "link": "https://openreview.net/forum?id=lVUuQhjbRd",
        "pdf_link": "https://openreview.net/pdf?id=lVUuQhjbRd",
        "keywords": "Multi-Agent; Large Language Model; Software Development;",
        "abstract": "Large Language Models (LLMs) have shown remarkable capability in code generation tasks. However, they still struggle with complex software development tasks where agents of different roles need to work collaboratively. Existing works have proposed some LLM-based multi-agent software development frameworks following linear models such as the Waterfall model. However, linear models suffer from erroneous outputs of LLMs due to the lack of a self-correction mechanism. Inspired by human teams where people can freely start meetings for reaching agreement, we propose a novel and flexible multi-agent framework AltDev, which enables agents to correct their deliverables and align with other agents in a real-time manner. AltDev integrates a compulsory alignment checking and a conditional multi-agent discussion at the end of each development phase, in order to identify and reduce errors at early stages in the software development lifecycle. Our experiments on various software development tasks show that AltDev significantly improves the quality of generated software code in terms of executability, structural and functional completeness."
    },
    {
        "title": "Bridging the Reality Gap: A Benchmark for Physical Reasoning in General World Models with Various Physical Phenomena beyond Mechanics",
        "link_suffix": "/forum?id=vsYt8UHGzI",
        "link": "https://openreview.net/forum?id=vsYt8UHGzI",
        "pdf_link": "https://openreview.net/pdf?id=vsYt8UHGzI",
        "keywords": "Physical Reasoning, General World Models, Zero-shot Inference",
        "abstract": "While general world models have demonstrated excellent capability in modeling and simulating the world through video understanding and generation, their ability to reason about physical phenomena beyond mechanics remains underexplored. This includes crucial aspects like thermodynamics, electromagnetism, and optics, all of which are fundamental for simulating and predicting real-world dynamics. Existing benchmarks for evaluating physical reasoning in models often rely on datasets consisting solely of simulator-generated, virtual videos, limiting their generalizability to real-world scenarios.  This limitation hinders the comprehensive evaluation of general world models' physical reasoning in real-world scenarios. To bridge this gap, we introduce the Physics-RW benchmark, a physical reasoning dataset constructed from real-world videos. Encompassing a broad spectrum of real-world phenomena\u2014mechanics, thermodynamics, electromagnetism, and optics\u2014Physics-RW offers a comprehensive evaluation platform. We conducted extensive experiments on the Physics-RW benchmark, and the results indicate that there is still significant room for improvement in the physical reasoning abilities of general world models. We further analyzed the experimental results and explored several avenues for improvement. Virtual environment finetuning and physical knowledge injection via prompts demonstrate the potential for enhancing zero-shot physical reasoning ability."
    },
    {
        "title": "Shedding Light on Time Series Classification using Interpretability Gated Networks",
        "link_suffix": "/forum?id=n34taxF0TC",
        "link": "https://openreview.net/forum?id=n34taxF0TC",
        "pdf_link": "https://openreview.net/pdf?id=n34taxF0TC",
        "keywords": "Interpretability, Time-series, Shapelet",
        "abstract": "In time-series classification, interpretable models can bring additional insights but be outperformed by deep models since human-understandable features have limited expressivity and flexibility. In this work, we present InterpGN, a framework that integrates an interpretable model and a deep neural network. Within this framework, we introduce a novel gating function design based on the confidence of the interpretable expert, preserving interpretability for samples where interpretable features are significant while also identifying samples that require additional expertise. For the interpretable expert, we incorporate shapelets to effectively model shape-level features for time-series data. We introduce a variant of Shapelet Transforms to build logical predicates using shapelets. Our proposed model achieves comparable performance with state-of-the-art deep learning models while additionally providing interpretable classifiers for various benchmark datasets. We further show that our models improve on quantitative shapelet quality and interpretability metrics over existing shapelet-learning formulations. Finally, we demonstrate the capability of our models to provide interpretability in a real-world application using the MIMIC-III dataset."
    },
    {
        "title": "Towards Neural Scaling Laws for Time Series Foundation Models",
        "link_suffix": "/forum?id=uCqxDfLYrB",
        "link": "https://openreview.net/forum?id=uCqxDfLYrB",
        "pdf_link": "https://openreview.net/pdf?id=uCqxDfLYrB",
        "keywords": "Time series, scaling law, foundation model, transformer, forecasting",
        "abstract": "Scaling laws offer valuable insights into the design of time series foundation models (TSFMs). However, previous research has largely focused on the scaling laws of TSFMs for in-distribution (ID) data, leaving their out-of-distribution (OOD) scaling behavior and the influence of model architectures less explored. In this work, we examine two common TSFM architectures\u2014encoder-only and decoder-only Transformers\u2014and investigate their scaling behavior on both ID and OOD data. These models are trained and evaluated across varying parameter counts, compute budgets, and dataset sizes. Our experiments reveal that the log-likelihood loss of TSFMs exhibits similar scaling behavior in both OOD and ID settings. We further compare the scaling properties across different architectures, incorporating two state-of-the-art TSFMs as case studies, showing that model architecture plays a significant role in scaling. The encoder-only Transformers demonstrate better scalability than the decoder-only Transformers, while the architectural enhancements in the two advanced TSFMs primarily improve ID performance but reduce OOD scalability. While scaling up TSFMs is expected to drive performance breakthroughs, the lack of a comprehensive understanding of TSFM scaling laws has hindered the development of a robust framework to guide model scaling. We fill this gap in this work by synthesizing our findings and providing practical guidelines for designing and scaling larger TSFMs with enhanced model capabilities."
    },
    {
        "title": "Leveraging Variable Sparsity to Refine Pareto Stationarity in Multi-Objective Optimization",
        "link_suffix": "/forum?id=Bl3e8HV9xW",
        "link": "https://openreview.net/forum?id=Bl3e8HV9xW",
        "pdf_link": "https://openreview.net/pdf?id=Bl3e8HV9xW",
        "keywords": "Multi-Objective Optimization, Machine Learning, Deep Learning, Multi-task Learning, Gradient-Based Optimization",
        "abstract": "Gradient-based multi-objective optimization (MOO) is essential in modern machine learning, with applications in e.g., multi-task learning, federated learning,  algorithmic fairness and reinforcement learning. In this work, we first reveal some limitations of Pareto stationarity, a widely accepted first-order condition for Pareto optimality, in the presence of sparse function-variable structures. Next, to account for such sparsity, we propose a novel solution concept termed Refined Pareto Stationarity (RPS), which we prove is always sandwiched between Pareto optimality and Pareto stationarity. We give an efficient partitioning algorithm to automatically mine the function-variable dependency and substantially trim non-optimal Pareto stationary solutions. Then, we show that gradient-based descent algorithms in MOO can be enhanced with our refined partitioning. In particular, we propose Multiple Gradient Descent Algorithm with Refined Partition (RP-MGDA) as an example method that converges to RPS, while still enjoying a similar per-step complexity and convergence rate. Lastly, we validate our approach through experiments on both synthetic examples and realistic application scenarios where distinct function-variable dependency structures appear. Our results highlight the importance of exploiting function-variable structure in gradient-based MOO, and provide a seamless enhancement to existing approaches."
    },
    {
        "title": "RED QUEEN: SAFEGUARDING LARGE LANGUAGE MODELS AGAINST CONCEALED MULTI-TURN ATTACK",
        "link_suffix": "/forum?id=nttFj0wKfD",
        "link": "https://openreview.net/forum?id=nttFj0wKfD",
        "pdf_link": "https://openreview.net/pdf?id=nttFj0wKfD",
        "keywords": "Jailbreaking, Large Language Models, Safety Alignment",
        "abstract": "The rapid progress of large language models (LLMs) has opened up new opportunities across various domains and applications; yet it also presents challenges related to potential misuse. To mitigate such risks, red teaming, a strategy where developers adopt the role of potential attackers has been employed to probe language models and preemptively guard against such harms. Jailbreak attacks are a commonly used red teaming strategy that uses crafted prompts to bypass safety guardrails. However, current jailbreak attack approaches are single-turn, with explicit malicious queries that do not fully capture the complexity of real-world interactions. In reality, users can engage in multi-turn interactions with LLM-based chat assistants, allowing them to conceal their true intentions in a more covert manner. Research on the Theory of Mind (ToM) reveals that LLMs struggle to infer latent intent, making it crucial to investigate how LLMs handle concealed malicious intent within multi-turn scenarios. To bridge this gap, we propose a new jailbreak approach, RED QUEEN ATTACK. This method constructs a multi-turn scenario, concealing the malicious intent under the guise of preventing harm. Next, we craft 40 scenarios that vary in turns and select 14 harmful categories to generate 56k multi-turn attack data points. We conduct comprehensive experiments on the RED QUEEN ATTACK with four representative LLM families of different sizes. Our experiments reveal that all LLMs are vulnerable to RED QUEEN ATTACK, reaching 87.6% attack success rate on GPT-4o and 77.1% on Llama3-70B. Further analysis\nreveals that larger models are more susceptible to the RED QUEEN ATTACK, with multi-turn structures and concealment strategies contributing to its success. To prioritize safety, we introduce a straightforward mitigation strategy called RED QUEEN GUARD, which aligns LLMs to effectively counter adversarial attacks. This approach reduces the attack success rate to below 1% while maintaining the model\u2019s performance across standard benchmarks. We release our code and data to support future research."
    },
    {
        "title": "Mockingbird: Platform for Adapting LLMs to General Machine Learning Tasks",
        "link_suffix": "/forum?id=cLTM1gc6Qm",
        "link": "https://openreview.net/forum?id=cLTM1gc6Qm",
        "pdf_link": "https://openreview.net/pdf?id=cLTM1gc6Qm",
        "keywords": "Paradigm for AI Systems, LLM, In-Context Learning, Mocking",
        "abstract": "Large language models (LLMs) are now being used with increasing frequency as chat bots, tasked with the summarizing information or generating text and code in accordance with user instructions.\nThe rapid increase in reasoning capabilities and inference speed of LLMs has revealed their remarkable potential for applications extending beyond the domain of chat bots.\nHowever, there is a paucity of research exploring the integration of LLMs into a broader range of intelligent software systems.\nIn this research, we propose a paradigm for leveraging LLMs as mock functions to adapt LLMs to general machine learning tasks.\nFurthermore, we present an implementation of this paradigm, entitled the Mockingbird platform.\nIn this paradigm, users define mock functions which are defined solely by method signature and documentation. Unlike LLM-based code completion tools, this platform does not generate code at compile time; instead, it instructs the LLM to role-play these mock functions at runtime.\nBased on the feedback from users or error from software systems, this platform will instruct the LLM to conduct chains of thoughts to reflect on its previous output, thereby enabling it to perform reinforcement learning.\nThis paradigm fully exploits the intrinsic knowledge and in-context learning ability of LLMs.\nIn comparison to conventional machine learning methods, following distinctive advantages are offered: \n(a) Its intrinsic knowledge enables it to perform well in a wide range of zero-shot scenarios. \n(b) Its flexibility allows it to adapt to random increases or decreases of data fields.\n(c) It can utilize tools and extract information from sources that are inaccessible to conventional machine learning methods, such as the Internet.\nFinally, we evaluated its performance and demonstrated the previously mentioned benefits using several datasets from Kaggle. Our results indicate that this paradigm is highly competitive."
    },
    {
        "title": "Crafting Heavy-Tails in Weight Matrix Spectrum without Gradient Noise",
        "link_suffix": "/forum?id=WL4BmXG7Pl",
        "link": "https://openreview.net/forum?id=WL4BmXG7Pl",
        "pdf_link": "https://openreview.net/pdf?id=WL4BmXG7Pl",
        "keywords": "Heavy Tails, Spectral Analysis, Generalization",
        "abstract": "Training strategies for modern deep neural networks (NNs) tend to induce a heavy-\ntailed (HT) empirical spectral density (ESD) in the layer weights. While previous\nefforts have shown that the HT phenomenon correlates with good generalization\nin large NNs, a theoretical explanation of its occurrence is still lacking. Especially,\nunderstanding the conditions which lead to this phenomenon can shed light on the\ninterplay between generalization and weight spectra. Our work aims to bridge this\ngap by presenting a simple, rich setting to model the emergence of HT ESD. In\nparticular, we present a theory-informed analysis for 'crafting' heavy tails in the\nESD of two-layer NNs without any gradient noise. This is the first work to analyze a noise-free setting and incorporate optimizer (GD/Adam) dependent (large)\nlearning rates into the HT ESD analysis. Our results highlight the role of learning\nrates on the Bulk+Spike and HT shape of the ESDs in the early phase of training,\nwhich can facilitate generalization in the two-layer NN. These observations shed\nlight on the behavior of large-scale NNs, albeit in a much simpler setting. Last\nbut not least, we present a novel perspective on the ESD evolution dynamics by\nanalyzing the singular vectors of weight matrices and optimizer updates"
    },
    {
        "title": "Reflect-then-Plan: Offline Model-Based Planning through a Doubly Bayesian Lens",
        "link_suffix": "/forum?id=6jr94SCjH6",
        "link": "https://openreview.net/forum?id=6jr94SCjH6",
        "pdf_link": "https://openreview.net/pdf?id=6jr94SCjH6",
        "keywords": "Offline reinforcement learning, Model-based planning, Bayesian inference, Bayesian reinforcement learning",
        "abstract": "Offline reinforcement learning (RL) is essential when online exploration is costly or unsafe, but it often struggles with high epistemic uncertainty due to limited data. Existing methods learn fixed conservative policies, which limit adaptivity and generalization. To tackle these challenges, we proposeReflect-then-Plan (RefPlan), a noveldoubly Bayesianapproach for offline model-based (MB) planning that enhances offline-learned policies for improved adaptivity and generalization. RefPlan integrates uncertainty modeling and MB planning in a unified probabilistic framework, recasting planning as Bayesian posterior estimation. During deployment, it updates a belief distribution over environment dynamics based on real-time observations. By incorporating this uncertainty into MB planning via marginalization, RefPlan derives plans that account for unknowns beyond the agent's limited knowledge. Empirical results on standard benchmarks show that RefPlan significantly improves the performance of conservative offline RL policies. In particular, RefPlan maintains robust performance under high epistemic uncertainty and limited data, while demonstrating resilience to changing environment dynamics, improving the flexibility, generalizability, and robustness of offline-learned policies."
    },
    {
        "title": "OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling",
        "link_suffix": "/forum?id=fsDZwS49uY",
        "link": "https://openreview.net/forum?id=fsDZwS49uY",
        "pdf_link": "https://openreview.net/pdf?id=fsDZwS49uY",
        "keywords": "large language models; optimization problem; data synthesis",
        "abstract": "Large language models (LLMs) have exhibited their problem-solving abilities in mathematical reasoning. Solving realistic optimization (OPT) problems in application scenarios requires advanced and applied mathematics ability. However, current OPT benchmarks that merely solve linear programming are far from complex realistic situations. In this work, we proposeOptiBench, a benchmark forEnd-to-endoptimization problem-solving with human-readable inputs and outputs.OptiBenchcontains rich optimization problems, including linear and nonlinear programming with or without tabular data, which can comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are required to call a code solver to provide precise numerical answers.\nFurthermore, to alleviate the data scarcity for optimization problems, and to bridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a data synthesis method namelyReSocratic. Unlike general data synthesis methods that proceed from questions to answers, \\ReSocratic first incrementally synthesizes formatted optimization demonstration with mathematical formulations step by step and then back-translates the generated demonstrations into questions. Based on this, we synthesize theReSocratic-29kdataset. We further conduct supervised fine-tuning withReSocratic-29kon multiple open-source models. Experimental results show thatReSocratic-29ksignificantly improves the performance of open-source models."
    },
    {
        "title": "Consistency Verification for Detecting AI-Generated Images",
        "link_suffix": "/forum?id=PSQuy9sjQ8",
        "link": "https://openreview.net/forum?id=PSQuy9sjQ8",
        "pdf_link": "https://openreview.net/pdf?id=PSQuy9sjQ8",
        "keywords": "AI-generated image detection, Generative models, Diffusion models, GAN",
        "abstract": "With the rapid development of generative models, AI-generated images have sparked significant concerns regarding their potential misuse for malicious purposes, highlighting the urgent need for AI-generated image detection. Current methods primarily focus on training a binary classifier to detect generated images. However, the efficacy of these methods is critically dependent on the quantity and quality of the collected AI-generated images. More importantly, they suffer from a generalization challenge: \\emph{the literature lacks sufficient exploration of whether a binary classifier trained on images from a specific diffusion model can effectively generalize to images generated by other models.} In this work, we propose a novel framework termed \\textbf{con}sistency \\textbf{v}erification (ConV) for AI-generated image detection, providing a new approach that detects without requiring AI-generated images. In particular, we introduce two functions and establish a principle for designing them so that their outputs remain consistent for natural images but exhibit signi\ufb01cant inconsistency for AI-generated images. Our principle shows that gradients of these two functions need to lie within two mutually orthogonal subspaces. This enables a training-free detection approach: an image is identified as AI-generated if transformation along its data manifold results in a substantial change in the loss value of a self-supervised model pre-trained on natural images. This detection framework leads to the unique advantage of ConV over existing methods: \\emph{ConV identifies AI-generated images by fitting the distribution of natural images rather than that of AI-generated images.} Extensive experiments across various benchmarks validate the effectiveness of the proposed ConV."
    },
    {
        "title": "What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices",
        "link_suffix": "/forum?id=hgagmZSAb9",
        "link": "https://openreview.net/forum?id=hgagmZSAb9",
        "pdf_link": "https://openreview.net/pdf?id=hgagmZSAb9",
        "keywords": "Long context learning, data synthesis, multi-hop QA, large language model",
        "abstract": "Recent advancements in large language models (LLMs) with extended context windows have significantly improved tasks such as information extraction, question answering, and complex planning scenarios. In order to achieve success in long-context tasks, a large amount of work has been done to enhance the long-context capabilities of the model through synthetic data. Existing methods typically utilize the Self-Instruct framework to generate instruction-tuning data for better long-context capability improvement. However, our preliminary experiments indicate that less than 35% of samples generated by Qwen-2$_{72B}$ are multi-hop, and more than 40% exhibit poor quality, limiting comprehensive understanding and further research.\n   To improve the quality of synthetic data, we propose the Multi-agent Interactive Multi-hop Generation (MIMG) framework, incorporating a Quality Verification Agent, a Single-hop Question Generation Agent, a Multiple Question Sampling Strategy, and a Multi-hop Question Merger Agent. This framework improves the data quality, with the proportion of high-quality, multi-hop, and diverse data exceeding 85%. Furthermore, we systematically investigate strategies for document selection, question merging, and validation techniques through extensive experiments across various models. Our findings show that our synthetic high-quality long-context instruction data significantly enhances model performance, even surpassing models trained on larger amounts of human-annotated data."
    },
    {
        "title": "Provable Causal State Representation under Asynchronous Diffusion Model for POMDPs",
        "link_suffix": "/forum?id=FNiqaC382D",
        "link": "https://openreview.net/forum?id=FNiqaC382D",
        "pdf_link": "https://openreview.net/pdf?id=FNiqaC382D",
        "keywords": "diffusion model, causal state representation, model uncertainty, bisimulaion, POMDP",
        "abstract": "A major challenge in applying reinforcement learning (RL) to real-world scenarios is managing high-dimensional, noisy perception input signals. Identifying and utilizing representations that contain sufficient and essential information for decision-making tasks is key to computational efficiency and generalization of RL by reducing bias in decision-making processes. In this paper, we present a new RL framework, namedCausal State Representation under Asynchronous Diffusion Model (CSR-ADM), which accommodates and enhances any RL algorithm for partially observable Markov decision processes (POMDPs) with perturbed inputs. A new asynchronous diffusion model is proposed to denoise both reward and observation spaces, and integrated with the bisimulation technology to capture causal state representations in POMDPs. Notably, the causal state is the coarsest partition of the denoised observations. We link the causal state to a causal feature set and provide theoretical guarantees by deriving the upper bound on value function approximation between the noisy observation space and the causal state space, demonstrating equivalence to bisimulation under the Lipschitz assumption. To the best of our knowledge, CSR-ADM is the first framework to approximate causal states with diffusion models, substantiated by a comprehensive theoretical foundation. Extensive experiments on Roboschool tasks show that CSR-ADM outperforms state-of-the-art methods, significantly improving the robustness of existing RL algorithms under varying scales of random noise."
    },
    {
        "title": "Test-time Adaptation for Regression by Subspace Alignment",
        "link_suffix": "/forum?id=SXtl7NRyE5",
        "link": "https://openreview.net/forum?id=SXtl7NRyE5",
        "pdf_link": "https://openreview.net/pdf?id=SXtl7NRyE5",
        "keywords": "Test-time adaptation, regression, distribution shift, deep learning",
        "abstract": "This paper investigates test-time adaptation (TTA) for regression, where a regression model pre-trained in a source domain is adapted to an unknown target distribution with unlabeled target data.\nAlthough regression is one of the fundamental tasks in machine learning, most of the existing TTA methods have classification-specific designs, which assume that models output class-categorical predictions, whereas regression models typically output only single scalar values.\nTo enable TTA for regression, we adopt a feature alignment approach, which aligns the feature distributions between the source and target domains to mitigate the domain gap.\nHowever, we found that naive feature alignment employed in existing TTA methods for classification is ineffective or even worse for regression because the features are distributed in a small subspace and many of the raw feature dimensions have little significance to the output.\nFor an effective feature alignment in TTA for regression, we propose Significant-subspace Alignment (SSA).\nSSA consists of two components: subspace detection and dimension weighting.\nSubspace detection finds the feature subspace that is representative and significant to the output.\nThen, the feature alignment is performed in the subspace during TTA.\nMeanwhile, dimension weighting raises the importance of the dimensions of the feature subspace that have greater significance to the output.\nWe experimentally show that SSA outperforms various baselines on real-world datasets."
    },
    {
        "title": "AlignAb: Pareto-Optimal Energy Alignment for Designing Nature-Like Antibodies",
        "link_suffix": "/forum?id=esjkcic7Oh",
        "link": "https://openreview.net/forum?id=esjkcic7Oh",
        "pdf_link": "https://openreview.net/pdf?id=esjkcic7Oh",
        "keywords": "Antibody Design, Diffusion Models, Multi-Objective Optimization",
        "abstract": "We present a three-stage framework for training deep learning models specializing in antibody sequence-structure co-design.\nWe first pre-train a language model based on millions of antibody sequence data.\nThen, we employ the learned representations to guide the training of a diffusion model for joint optimization over both sequence and structure of antibodies. \nDuring the final alignment stage, we optimize the model to favor antibodies with low repulsion and high attraction to the antigen binding site, enhancing the rationality and functionality of the design.\nTo mitigate conflicting energy preferences, we extend AbDPO (Antibody Direct Preference Optimization) to guide the model towards Pareto optimality under multiple energy-based alignment objectives. \nFurthermore, we adopt an iterative learning paradigm with temperature scaling, enabling the model to benefit from diverse online datasets without requiring additional data.\nIn practice, our proposed methods achieve high stability and efficiency in producing a better Pareto front of antibody designs compared to top samples generated by baselines and previous alignment techniques.\nThrough extensive experiments, we showcase the superior performance of our methods in generating nature-like antibodies with high binding affinity consistently."
    },
    {
        "title": "TF-HOT: Training-Free Hand-Object Pose Tracking and Optimization for Dexterous Manipulation",
        "link_suffix": "/forum?id=gVWEq7LITG",
        "link": "https://openreview.net/forum?id=gVWEq7LITG",
        "pdf_link": "https://openreview.net/pdf?id=gVWEq7LITG",
        "keywords": "Pose estimation, Robotics manipulation",
        "abstract": "Robotic manipulation with dexterous hands is inherently challenging due to their high-dimensional action spaces and the lack of large-scale, high-quality demonstrations. While there are many videos involving interactions between human hands and objects, the frequent, dynamic occlusions between human hands and objects complicate the accurate and robust tracking of hand and object poses, making it challenging to convert these interactions into high-quality dexterous robotic demonstrations.\nTo address these challenges, we introduce a novel Training-Free Hand-Object pose tracking pipeline (TF-HOT) that leverages differentiable rendering and rich priors from pre-trained 2D foundation perception models to perform optimization of human hand and object pose trajectories from input videos. Our method is efficient, allowing us to convert an in-the-wild video to pose trajectories in 1 minute, and we demonstrate state-of-the-art performance of our method over in-the-wild videos. Finally, we illustrate an application of our method in imitation learning by training policies to follow the pose trajectories extracted from TF-HOT, allowing us to learn dexterous manipulation policies that significantly outperform reinforcement learning and imitation learning methods that do not utilize hand-object pose trajectory following."
    },
    {
        "title": "HoLoRA: Combining Orthogonal Fine-Tuning and LoRA with Householder Reflectors",
        "link_suffix": "/forum?id=igGeaxOiFM",
        "link": "https://openreview.net/forum?id=igGeaxOiFM",
        "pdf_link": "https://openreview.net/pdf?id=igGeaxOiFM",
        "keywords": "Transfer learning, Low Rank Adaptation, Fine tuning, Householder reflector, Orthogonal fine-tuning",
        "abstract": "The need for parameter-efficient fine-tuning (PEFT) has emerged as large pre-trained models are increasingly employed in specialized downstream tasks. Among PEFT methods, Low-Rank Adaptation (LoRA) is widely adopted due to its ability to fine-tune models with minimal additional parameters. However, LoRA\u2019s down-projection mechanism can lead to significant feature loss, particularly for tasks involving complex features and reasoning. This limitation poses a challenge in maintaining model performance in scenarios requiring high-dimensional representations.To address this issue, we introduce Householder Orthogonal LoRA (HoLoRA), which reparametrizes the down-projection matrix as a semi-orthogonal matrix, thereby mitigating feature loss. Our approach ensures strict orthogonality without increasing computational costs or modifying LoRA\u2019s core components. Experimental results on the GLUE benchmark show that HoLoRA consistently outperforms standard LoRA across various tasks, particularly in low-rank settings. By preserving essential features and improving fine-tuning efficiency, HoLoRA provides a robust solution to the limitations of existing PEFT methods. This advancement enhances LoRA's applicability in complex learning environments, promoting better performance in both low-budget and high-complexity scenarios."
    },
    {
        "title": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data",
        "link_suffix": "/forum?id=Zk8PNvzWQY",
        "link": "https://openreview.net/forum?id=Zk8PNvzWQY",
        "pdf_link": "https://openreview.net/pdf?id=Zk8PNvzWQY",
        "keywords": "Offline-to-Online Reinforcement Learning, Offline Reinforcement Learning, Penalizing Infeasible Actions, Layer Normalization, Reward Scaling\u200b",
        "abstract": "Reinforcement learning with offline data often suffers from Q-value extrapolation errors due to limited data, which poses significant challenges and limits overall performance. Existing methods such as layer normalization and reward relabeling have shown promise in addressing these errors and achieving empirical improvements. In this paper, we extend these approaches by introducing reward scaling with layer normalization (RS-LN) to further mitigate extrapolation errors and enhance performance. Furthermore, based on the insight that Q-values should be lower for infeasible action spaces\u2014where neural networks might otherwise extrapolate into undesirable regions\u2014we propose a penalization mechanism for infeasible actions (PA). By combining RS-LN and PA, we develop a new algorithm called PARS. We evaluate PARS on a range of tasks, demonstrating superior performance compared to state-of-the-art algorithms in both offline training and online fine-tuning across the D4RL benchmark, with notable success in the challenging AntMaze Ultra task."
    },
    {
        "title": "SynPlay: Importing Real-world Diversity for a Synthetic Human Dataset",
        "link_suffix": "/forum?id=CyxoD9pa5r",
        "link": "https://openreview.net/forum?id=CyxoD9pa5r",
        "pdf_link": "https://openreview.net/pdf?id=CyxoD9pa5r",
        "keywords": "Synthetic human dataset, Natural human pose and motion, Squid game",
        "abstract": "We introduce Synthetic Playground (SynPlay), a new synthetic human dataset that aims to bring out the diversity of human appearance in the real world. We focus on two factors to achieve a level of diversity that has not yet been seen in previous works: i) realistic human motions and poses and ii) multiple camera viewpoints towards human instances. We first use a game engine and its library-provided elementary motions to create games where virtual players can take less-constrained and natural movements while following the game rules (i.e., rule-guided motion design as opposed to detail-guided design). We then augment the elementary motions with real human motions captured with a motion capture device. To render various human appearances in the games from multiple viewpoints, we use seven virtual cameras encompassing the ground and aerial views, capturing abundant aerial-vs-ground and dynamic-vs-static attributes of the scene. Through extensive and carefully-designed experiments, we show that using SynPlay in model training leads to enhanced accuracy over existing synthetic datasets for human detection and segmentation. The benefit of SynPlay becomes even greater for tasks in the data-scarce regime, such as few-shot and cross-domain learning tasks. These results clearly demonstrate that SynPlay can be used as an essential dataset with rich attributes of complex human appearances and poses suitable for model pretraining. SynPlay dataset comprising over 73k images and 6.5M human instances, will be publicly released upon acceptance of this paper."
    },
    {
        "title": "MEENT: DIFFERENTIABLE ELECTROMAGNETIC SIMULATOR FOR MACHINE LEARNING",
        "link_suffix": "/forum?id=VWj9rTfZzQ",
        "link": "https://openreview.net/forum?id=VWj9rTfZzQ",
        "pdf_link": "https://openreview.net/pdf?id=VWj9rTfZzQ",
        "keywords": "computational physics, optics, electromagnetic simulation, reinforcement learning, neural operator, automatic differentiation, metasurface optimization, semiconductor metrology",
        "abstract": "Electromagnetic (EM) simulation plays a crucial role in analyzing and designing devices with sub-wavelength scale structures such as semiconductor devices and future displays. \nSpecifically, optics problems such as estimating semiconductor device structures and designing nanophotonic devices provide intriguing research topics with far-reaching real world impact. \nTraditional algorithms for such tasks require iteratively refining parameters through simulations, which often yield sub-optimal results due to the high computational cost of both the algorithms and EM simulations. \nMachine learning (ML) emerged as a promising candidate to mitigate these challenges, and optics research community has increasingly adopted ML algorithms to obtain results surpassing classical methods across various tasks.\nTo foster a synergistic collaboration between the optics and ML communities, it is essential to have an EM simulation software that is user-friendly for both research communities.\nTo this end, we present meent, an EM simulation software that employs rigorous coupled-wave analysis (RCWA). Developed in Python and equipped with automatic differentiation (AD) capabilities, meent serves as a versatile platform for integrating ML into optics research and vice versa.\nTo demonstrate its utility as a research platform, we present three applications of meent: 1) generating a dataset for training neural operator, 2) serving as an environment for the reinforcement learning of nanophotonic device optimization, and 3) providing a solution for inverse problems with gradient-based optimizers.\nThese applications highlight meent's potential to advance both EM simulation and ML methodologies. \nThe code is available on our Github repository with the MIT license to promote the cross-polinations of ideas among academic researchers and industry practitioners."
    },
    {
        "title": "Prediction Risk and Estimation Risk of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors",
        "link_suffix": "/forum?id=AsAy7CROLs",
        "link": "https://openreview.net/forum?id=AsAy7CROLs",
        "pdf_link": "https://openreview.net/pdf?id=AsAy7CROLs",
        "keywords": "minimum norm solution, ridgeless estimator, benign overfitting, double descent, overparameterization",
        "abstract": "In recent years, there has been a significant growth in research focusing on minimum $\\ell_2$ norm (ridgeless) interpolation least squares estimators. However, the majority of these analyses have been limited to an unrealistic regression error structure, assuming independent and identically distributed errors with zero mean and common variance. In this paper, we explore prediction risk as well as estimation risk under more general regression error assumptions, highlighting the benefits of overparameterization in a more realistic setting that allows for clustered or serial dependence. Notably, we establish that the estimation difficulties associated with the variance components of both risks can be summarized through the trace of the variance-covariance matrix of the regression errors. Our findings suggest that the benefits of overparameterization can extend to time series, panel and grouped data."
    },
    {
        "title": "Node-wise Filtering in Graph Neural Networks: A Mixture of Experts Approach",
        "link_suffix": "/forum?id=tj40W2HAKN",
        "link": "https://openreview.net/forum?id=tj40W2HAKN",
        "pdf_link": "https://openreview.net/pdf?id=tj40W2HAKN",
        "keywords": "Graph Neural Networks, Node-wise Filters, Node Classification, Homophilic and Heterophilic graphs",
        "abstract": "Graph Neural Networks (GNNs) have proven to be highly effective for node classification tasks across diverse graph structural patterns. Traditionally, GNNs employ a uniform global filter\u2014typically a low-pass filter for homophilic graphs and a high-pass filter for heterophilic graphs. However, real-world graphs often exhibit a complex mix of homophilic and heterophilic patterns, rendering a single filter approach suboptimal. In this work, we theoretically demonstrate that a global filter optimized for one pattern can adversely affect performance on nodes with differing patterns. To address this, we introduce a novel GNN framework Node-MoE that utilizes a mixture of experts to adaptively select the appropriate filters for different nodes. Extensive experiments demonstrate the effectiveness of the proposed Node-MoE on both homophilic and heterophilic graphs."
    },
    {
        "title": "Understanding Synthetic Context Extension via Retrieval Heads",
        "link_suffix": "/forum?id=hUD9ugK2OH",
        "link": "https://openreview.net/forum?id=hUD9ugK2OH",
        "pdf_link": "https://openreview.net/pdf?id=hUD9ugK2OH",
        "keywords": "Large Language Models, Synthetic Data, Long Context",
        "abstract": "Long-context LLMs are increasingly desired for a broad set of applications such as retrieval-augmented generation. The high cost for pretraining LLMs over long contexts has led to exploration of fine-tuning LLMs with synthetically generated data in a post-training stage. However, it remains unclear how and why fine-tuning on synthetic data transfers to long-context performance on realistic tasks. In this paper, we investigate fine-tuning on synthetic data for three long-context tasks that require retrieval and reasoning. We explore synthetic data variants from the literature by varying the realism of the concept expression and context diversity of the data. We find that models trained on synthetic data fall short of the real data, but surprisingly, the mismatch can be interpreted and even predicted in terms of a special set of attention heads that are responsible for retrieval over long context, retrieval heads (Wu et al., 2024). The retrieval heads learned on synthetic data are mostly subsets of the retrieval heads learned on real data, and there is a strong correlation between the recall of heads learned and the downstream performance of a model. Furthermore, with attention knockout and activation patching, we mechanistically show that retrieval heads are not only necessary, but also provide fine-grained explanations for the performance gap between fine-tuning on synthetic and real data. Our results shed light on how to interpret the success and failure of synthetic data fine-tuning and how to create better synthetic data that can be transferred to realistic capabilities over long context."
    },
    {
        "title": "Advancing LLM Reasoning Generalists with Preference Trees",
        "link_suffix": "/forum?id=2ea5TNVR0c",
        "link": "https://openreview.net/forum?id=2ea5TNVR0c",
        "pdf_link": "https://openreview.net/pdf?id=2ea5TNVR0c",
        "keywords": "Reasoning, Alignment, Data",
        "abstract": "We introduce EURUS, a suite of large language models (LLMs) optimized for reasoning. Finetuned from Mistral-7B, Llama-3-8B, and Mixtral-8x22B, EURUS models achieve state-of-the-art results among open-source models on a diverse set of benchmarks covering mathematics, code generation, and logical reasoning problems. Notably, EURUX-8X22B outperforms GPT-3.5 Turbo in reasoning through a comprehensive benchmarking across 12 test sets covering five tasks. The strong performance of EURUS can be primarily attributed to ULTRAINTERACT, our newly-curated large-scale, high-quality training data dataset specifically designed for complex reasoning tasks. ULTRAINTERACT can be used in both supervised fine-tuning, preference learning, and reward modeling. It pairs each instruction with a preference tree consisting of (1) reasoning chains with diverse planning strategies in a unified format, (2) multi-turn interaction trajectories with the environment and the critique, and (3) pairwise positive and negative responses to facilitate preference learning. ULTRAINTERACT allows us to conduct an in-depth exploration of preference learning for reasoning tasks. Our investigation reveals that some well-established preference learning algorithms may be less suitable for reasoning tasks compared to their effectiveness in general conversations. The hypothesis is that in reasoning tasks, the space of correct answers is much smaller than that of incorrect ones, so it is necessary to explicitly increase the reward of chosen data. Therefore, in addition to increasing the reward margin as many preference learning algorithms do, the absolute values of positive responses\u2019 rewards should be positive and may serve as a proxy for performance. Inspired by this, we derive a novel reward modeling objective and empirically that it leads to a stable reward modeling curve and better performance. Together with ULTRAINTERACT, we obtain a strong reward model."
    },
    {
        "title": "Debiased Contrastive Learning with multi-resolution Kolmogorov-Arnold Network for Gravitational Wave Glitch Detection",
        "link_suffix": "/forum?id=aGBA8wz9qA",
        "link": "https://openreview.net/forum?id=aGBA8wz9qA",
        "pdf_link": "https://openreview.net/pdf?id=aGBA8wz9qA",
        "keywords": "self-supervised learning, Debiased Contrastive Learning, Gravitational Wave, Glitch detection, deep learning",
        "abstract": "Time-series gravitational wave glitch detection presents significant challenges for machine learning due to the complexity of the data, limited labeled examples, and data imbalance. To address these issues, we introduce Debiased Contrastive Learning with Multi-Resolution Kolmogorov-Arnold Network(dcMltR-KAN), a novel self-supervised learning (SSL) approach that enhances glitch detection, robustness, explainability, and generalization. dcMltR-KAN consists of three key novel components: Wasserstein Debiased Contrastive Learning (wDCL), a CNN-based encoder, and a Multi-Resolution KAN (MltR-KAN). The wDCL improves the model\u2019s sensitivity to data imbalance and geometric structure. The CNN-based encoder eliminates false negatives during training, refines feature representations through similarity-based weighting (SBW), and reduces data complexity within the embedding. Additionally, MltR-KAN enhances explainability, generalization, and efficiency by adaptively learning parameters. Our model outperforms widely-used fully supervised baselines on the O1, O2, and O3 data from LIGO/Virgo observations, demonstrating its effectiveness. We also extend dcMltR-KAN to benchmark audio data, further showcasing its novelty and efficiency. To our knowledge, this is the first model of its kind for this application and will inspire future research in this field and SSL."
    }
]
[{"title": "Last Iterate Convergence in Monotone Mean Field Games", "link_suffix": "/forum?id=cUnqwFu5OO", "link": "https://openreview.net/forum?id=cUnqwFu5OO", "pdf_link": "https://openreview.net/pdf?id=cUnqwFu5OO", "keywords": "mean field game, learning in games", "abstract": "Mean Field Game (MFG) is a framework utilized to model and approximate the behavior of a large number of agents, and the computation of equilibria in MFG has been a subject of interest. Despite the proposal of methods to approximate the equilibria, algorithms that can achieve equilibrium with the most recent policy of the algorithm, namely the last-iterate policy, have been limited. \nWe propose the use of a simple, proximal-point-type algorithm to compute strategies for MFGs. Subsequently, we provide the first last-iterate convergence guarantee under the Lasry--Lions-type monotonicity condition. \nWe further employ the Mirror Descent algorithm for the regularized MFG to efficiently approximate the update rules of the proximal point method for MFGs. \nWe demonstrate that the last-iterate strategy of Mirror Descent converges exponentially fast: we provide the guarantee of computing the $\\varepsilon$ approximation in $O(\\log(1/\\varepsilon))$ iterations. This research offers a tractable approach for large-scale and large-population games.", "title_embedding_index": 16300, "title_abs_embedding_index": 16325}, {"title": "Non-parametric Kernel Relative Test for Machine-generated Text Detection", "link_suffix": "/forum?id=z9j7wctoGV", "link": "https://openreview.net/forum?id=z9j7wctoGV", "pdf_link": "https://openreview.net/pdf?id=z9j7wctoGV", "keywords": "Large language models, Machine-generated text detection, Relative test", "abstract": "Recent studies demonstrate that two-sample test can effectively detect machine-generated texts (MGTs) with excellent adaptation ability to texts generated by newer LLMs. \nHowever, the two-sample test-based detection relies on the assumption that human-written texts (HWTs) must follow the distribution of seen HWTs. As a result, it tends to make mistakes in identifying HWTs that deviate from the \\textit{seen HWT} distribution, limiting their use in sensitive areas like academic integrity verification.\nTo address this issue, we propose to employ \\textit{non-parametric kernel relative test} to detect MGTs by testing whether it is statistically significant that the distribution of \\textit{a text to be tested} is closer to the distribution of HWTs than to the distribution of MGTs. \nWe further develop a \\textit{kernel optimisation} algorithm in relative test to select the best kernel that can enhance the testing capability for MGT detection.\nAs relative test does not assume that a text to be tested must belong exclusively to either MGTs or HWTs, it can largely \\textit{reduce the false positive error} compared to two-sample test, offering significant advantages in practical use. \nExtensive experiments demonstrate the superior detection performance of our method, compared to state-of-the-art non-parametric and parametric detectors.", "title_embedding_index": 16301, "title_abs_embedding_index": 16326}, {"title": "LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics", "link_suffix": "/forum?id=Zkp1GuHerF", "link": "https://openreview.net/forum?id=Zkp1GuHerF", "pdf_link": "https://openreview.net/pdf?id=Zkp1GuHerF", "keywords": "adaptive optimization, memory efficiency, low-rank learning, low-rank compression, convergence rates", "abstract": "We introduce LDAdam, a memory-efficient optimizer for training large models, that performs adaptive optimization steps within lower dimensional subspaces, while consistently exploring the full parameter space during training. This strategy keeps the optimizer's memory footprint to a fraction of the model size. LDAdam relies on a new projection-aware update rule for the optimizer states that allows for transitioning between subspaces, i.e., estimation of the statistics of the projected gradients. To mitigate the errors due to low-rank projection, LDAdam integrates a new generalized error feedback mechanism, which explicitly accounts for both gradient and optimizer state compression. We prove the convergence of LDAdam under standard assumptions, and provide empirical evidence that LDAdam allows for efficient fine-tuning and pre-training of language models.", "title_embedding_index": 16302, "title_abs_embedding_index": 16327}, {"title": "Layerwise Recurrent Router for  Mixture-of-Experts", "link_suffix": "/forum?id=eWNEqdH0vk", "link": "https://openreview.net/forum?id=eWNEqdH0vk", "pdf_link": "https://openreview.net/pdf?id=eWNEqdH0vk", "keywords": "Mixture of Expert, Router, LLMs", "abstract": "The scaling of large language models (LLMs) has revolutionized their capabilities in various tasks, yet this growth must be matched with efficient computational strategies. \nThe Mixture-of-Experts (MoE) architecture stands out for its ability to scale model size without significantly increasing training costs. \nDespite their advantages, current MoE models often display parameter inefficiency. \nFor instance, a pre-trained MoE-based LLM with 52 billion parameters might perform comparably to a standard model with 6.7 billion. \nBeing a crucial part of MoE, \ncurrent routers in different layers independently assign tokens without leveraging historical routing information, potentially leading to suboptimal token-expert combinations and the parameter inefficiency problem.\nTo alleviate this issue, we introduce the Layerwise Recurrent Router for Mixture-of-Experts (RMoE). \nRMoE leverages a Gated Recurrent Unit (GRU) to establish dependencies between routing decisions across consecutive layers.\nSuch layerwise recurrence can be efficiently parallelly computed for input tokens and introduces negotiable costs.\nOur extensive empirical evaluations demonstrate that RMoE-based language models consistently outperform a spectrum of baseline models. \nFurthermore, RMoE integrates a novel computation stage orthogonal to existing methods, allowing seamless compatibility with other MoE architectures. \nOur analyses attribute RMoE's gains to its effective cross-layer information sharing, which also improves expert selection and diversity.", "title_embedding_index": 16303, "title_abs_embedding_index": 16328}, {"title": "AutoUAD: Hyper-parameter Optimization for Unsupervised Anomaly Detection", "link_suffix": "/forum?id=ErQPdaD5wJ", "link": "https://openreview.net/forum?id=ErQPdaD5wJ", "pdf_link": "https://openreview.net/pdf?id=ErQPdaD5wJ", "keywords": "anomaly detection, hyper-parameter optimization", "abstract": "Unsupervised anomaly detection (UAD) has important applications in diverse fields such as manufacturing industry and medical diagnosis. In the past decades, although numerous insightful and effective UAD methods have been proposed, it remains a huge challenge to tune the hyper-parameters of each method and select the most appropriate method among many candidates for a specific dataset, due to the absence of labeled anomalies in the training phase of UAD methods and the high diversity of real datasets. In this work, we aim to address this challenge, so as to make UAD more practical and reliable. We propose two internal evaluation metrics, \\textit{relative-top-median} and \\textit{expected-anomaly-gap}, and one semi-internal evaluation metric, \\textit{normalized pseudo discrepancy} (NPD), as surrogate functions of the expected model performance on unseen test data. For instance, NPD measures the discrepancy between the anomaly scores of a validation set drawn from the training data and a validation set drawn from an isotropic Gaussian. NPD is simple and hyper-parameter-free and is able to compare different UAD methods, and its effectiveness is theoretically analyzed. We integrate the three metrics with Bayesian optimization to effectively optimize the hyper-parameters of UAD models. Extensive experiments on 38 datasets show the effectiveness of our methods.", "title_embedding_index": 16304, "title_abs_embedding_index": 16329}, {"title": "From Forgery to Authenticity: Image Anti-Forensics via Reconstruction and Artefact Elimination", "link_suffix": "/forum?id=hYEV8QmaOt", "link": "https://openreview.net/forum?id=hYEV8QmaOt", "pdf_link": "https://openreview.net/pdf?id=hYEV8QmaOt", "keywords": "Image anti-forensics, computer vision", "abstract": "In recent years, the development of large-scale vision-language models has resulted in significant advancements in image generation and editing, producing results that can often deceive the naked eye. \nHowever, despite their convincing appearance, these generated images remain susceptible to detection by forgery detectors due to various artefacts.\nThe goal of image anti-forensics is to eliminate such artefacts, ensuring that manipulated images successfully evade detection and enhance their overall quality. Existing image anti-forensics methods primarily focus on rectifying artefacts at the feature level, often overlooking the authenticity of the manipulated regions.\nTo address this limitation, we propose a two-phase approach. In the first phase, we introduce GUIded Diffusive rEfinement (GUIDE), a zero-shot learning-based image refinement module aimed at reconstructing details from unaltered regions.\nIn the second phase, we introduce an artefact removal algorithm to eliminate artefacts from the reconstructed ''forged regions''. We validate the effectiveness of our proposed method across multiple image forgery datasets, and comprehensive ablation studies further affirm the efficacy of each component of our approach. The code will be made available upon acceptance.", "title_embedding_index": 16305, "title_abs_embedding_index": 16330}, {"title": "Dataset Condensation with Sharpness-Aware Trajectory Matching", "link_suffix": "/forum?id=ewBe3QpCyY", "link": "https://openreview.net/forum?id=ewBe3QpCyY", "pdf_link": "https://openreview.net/pdf?id=ewBe3QpCyY", "keywords": "dataset condensation, meta-learning", "abstract": "Dataset condensation aims to synthesise datasets with a few representative samples that can effectively represent the original datasets. This enables efficient training and produces models with performance close to those trained on the original sets. Most existing dataset condensation methods conduct dataset learning under the bilevel (inner and outer loop) based optimisation. However, due to its notoriously complicated loss landscape and expensive time-space complexity, the preceding methods either develop advanced training protocols so that the learned datasets generalise to unseen tasks or reduce the inner loop learning cost increasing proportionally to the unrolling steps. This phenomenon deteriorates when the datasets are learned via matching the trajectories of networks trained on the real and synthetic datasets with a long horizon inner loop. To address these issues, we introduce Sharpness-Aware Trajectory Matching (SATM), which enhances the generalisation capability of learned synthetic datasets by minimising sharpness in the outer loop of bilevel optimisation. Moreover, our approach is coupled with an efficient hypergradient approximation that is mathematically well-supported and straightforward to implement along with controllable computational overhead. Empirical evaluations of SATM demonstrate its effectiveness across various applications, including standard in-domain benchmarks and out-of-domain settings. Moreover, its easy-to-implement properties afford flexibility, allowing it to integrate with other advanced sharpness-aware minimisers. We will release our code on GitHub.", "title_embedding_index": 16306, "title_abs_embedding_index": 16331}, {"title": "Advancing Mathematical Reasoning in Language Models: The Impact of Problem-Solving Data, Data Synthesis Methods, and Training Stages", "link_suffix": "/forum?id=GtpubstM1D", "link": "https://openreview.net/forum?id=GtpubstM1D", "pdf_link": "https://openreview.net/pdf?id=GtpubstM1D", "keywords": "LLM continue pretrain;math problem solving;data synthesis", "abstract": "Advancements in large language models (LLMs) have significantly expanded their capabilities across various domains. However, mathematical reasoning remains a challenging area, prompting the development of math-specific LLMs such as LLEMMA, DeepSeekMath, and Qwen2-Math, among others. These models typically follow a two-stage training paradigm: pre-training with math-related corpora and post-training with problem datasets for supervised fine-tuning (SFT). Despite these efforts, the improvements in mathematical reasoning achieved through continued pre-training (CPT) are often less significant compared to those obtained via SFT. This study addresses this discrepancy by exploring alternative strategies during the pre-training phase, focusing on the use of problem-solving data over general mathematical corpora.\nWe investigate three primary research questions: (1) Can problem-solving data enhance the model's mathematical reasoning capabilities more effectively than general mathematical corpora during CPT? (2) Are synthetic data from the same source equally effective, and which synthesis methods are most efficient? (3) How do the capabilities developed from the same problem-solving data differ between the CPT and SFT stages, and what factors contribute to these differences?\nOur findings indicate that problem-solving data significantly enhances the model's mathematical capabilities compared to general mathematical corpora. We also identify effective data synthesis methods, demonstrating that the tutorship amplification synthesis method achieves the best performance. Furthermore, while SFT facilitates instruction-following abilities, it underperforms compared to CPT with the same data, which can be partially attributed to its poor learning capacity for hard multi-step problem-solving data. These insights provide valuable guidance for optimizing the mathematical reasoning capabilities of LLMs, culminating in our development of a powerful mathematical base model called JiuZhang-8B.", "title_embedding_index": 16307, "title_abs_embedding_index": 16332}, {"title": "AlphaMol: rigid neighborhood representation for small molecule structure prediction", "link_suffix": "/forum?id=DBitNcZa6T", "link": "https://openreview.net/forum?id=DBitNcZa6T", "pdf_link": "https://openreview.net/pdf?id=DBitNcZa6T", "keywords": "molecule, deep learning, structure prediction, chemistry, biology, biomolecules, bioinformatics", "abstract": "Recent success of the deep learning-based approach AlphaFold2 revolutionized the field of protein structure prediction. Since AlphaFold2 development, a lot of efforts were made to shape its limitations as well as to improve it further with respect to difficult protein classes. However, structure prediction of non-protein type of molecules, such as small organic molecules, non-standard amino acids, nucleic acids, and others, is still an open problem. Inspired by the powerful AlphaFold2 neural network architecture, we developed a general framework for prediction of molecular structures of arbitrary type. Specifically, we developed novel representation of molecular structures as a collection of rigid-body neighborhoods with encoded bonds between the neighborhoods fed into neural network comprising developed Evoformer-like blocks. We tested our approach on small organic molecules, that possess much higher variability in terms of atomic composition and structural patterns compared to proteins. Namely, we applied the developed method, named AlphaMol, to the ground-state structure prediction problem of small molecules and observed superior performance metrics on the PubChemQC benchmark, compared to the existing approaches. Our results demonstrate possibility to create multi-modal molecular structure prediction methods, that operate across different molecular types. The AlphaMol source code is available in the repository:https://anonymous.4open.science/r/AlphaMol-2EA7.", "title_embedding_index": 16308, "title_abs_embedding_index": 16333}, {"title": "DocMIA: Document-Level Membership Inference Attacks against DocVQA Models", "link_suffix": "/forum?id=gNxvs5pUdu", "link": "https://openreview.net/forum?id=gNxvs5pUdu", "pdf_link": "https://openreview.net/pdf?id=gNxvs5pUdu", "keywords": "Membership Inference Attacks, Document-based VQA, Multi-modal Models, Privacy", "abstract": "Document Visual Question Answering (DocVQA) has introduced a new paradigm for end-to-end document understanding, and quickly became one of the standard benchmarks for multimodal LLMs. Automating document processing workflows, driven by DocVQA models, presents significant potential for many business sectors. However, documents tend to contain highly sensitive information, raising concerns about privacy risks associated with training such DocVQA models. One significant privacy vulnerability, exploited by the membership inference attack, is the possibility for an adversary to determine if a particular record was part of the model's training data. In this paper, we introduce two novel membership inference attacks tailored specifically to DocVQA models. These attacks are designed for two different adversarial scenarios: a white-box setting, where the attacker has full access to the model architecture and parameters, and a black-box setting, where only the model's outputs are available. Notably, our attacks assume the adversary lacks access to auxiliary datasets, which is more realistic in practice but also more challenging. Our unsupervised methods outperform existing state-of-the-art membership inference attacks across a variety of DocVQA models and datasets, demonstrating their effectiveness and highlighting the privacy risks in this domain.", "title_embedding_index": 16309, "title_abs_embedding_index": 16334}, {"title": "Transformer2: Self-adaptive LLMs", "link_suffix": "/forum?id=dh4t9qmcvK", "link": "https://openreview.net/forum?id=dh4t9qmcvK", "pdf_link": "https://openreview.net/pdf?id=dh4t9qmcvK", "keywords": "Transformers, Self-Adaptation, Fine-tuning, Dynamic System, LLMs", "abstract": "Self-adaptive large language models (LLMs) aim to solve the challenges posed by traditional fine-tuning methods, which are often computationally intensive and static in their ability to handle diverse tasks. We introduce $\\text{Transformer}^2$, a novel self-adaptation framework that adapts LLMs for unseen tasks in real-time by selectively adjusting only the singular components of their weight matrices. During inference, $\\text{Transformer}^2$ employs a two-pass mechanism: first, a dispatch system identifies the task properties, and then task-specific \"expert\" vectors, trained using reinforcement learning, are dynamically mixed to obtain targeted behavior for the incoming prompt. Our method consistently outperforms ubiquitous approaches such as LoRA, with fewer parameters and greater efficiency. Furthermore, $\\text{Transformer}^2$ demonstrates versatility across different LLM architectures and modalities, including vision-language tasks. $\\text{Transformer}^2$ represents a significant leap forward, offering a scalable, efficient solution for enhancing the adaptability and task-specific performance of LLMs, paving the way for truly dynamic, self-organizing AI systems. We provide our full source code with the submission.", "title_embedding_index": 16310, "title_abs_embedding_index": 16335}, {"title": "EmpathyRobot: A Dataset and Benchmark for Empathetic Task Planning of Robotic Agent", "link_suffix": "/forum?id=F6h0v1CTpC", "link": "https://openreview.net/forum?id=F6h0v1CTpC", "pdf_link": "https://openreview.net/pdf?id=F6h0v1CTpC", "keywords": "empathy, robot planning, large language models", "abstract": "Empathy is a fundamental instinct and essential need for humans, as they both demonstrate empathetic actions toward others and receive empathetic support. As robots become increasingly integrated into daily life, it is essential to explore whether they can provide human-like empathetic support. Although existing emotion agents have explored how to understand humans' empathetic needs, they lack to further enable robots to generate empathy-oriented task planning, neglecting the evaluation of empathetic behaviors. To address this gap, we introduce \\textbf{EmpathyRobot}, the first dataset specifically designed to benchmark and enhance the empathetic actions of agents across diverse scenarios. This dataset contains 10,000 samples based on human feedback, encompassing information from various modalities and corresponding empathetic task planning sequences, including navigation and manipulation. Agents are required to perform actions based on their understanding of both the visual scene and human emotions. To systematically evaluate the performance of existing agents on the EmpathyRobot dataset, we conduct comprehensive experiments to test the most capable models. Our findings reveal that generating accurate empathetic actions remains a significant challenge. Meanwhile, we finetune an \\ac{llm} on our benchmark, demonstrating that it can effectively be used to enhance the empathetic behavior of robot agents. By establishing a standard benchmark for evaluating empathetic actions, we aim to drive advancements in the study and pursue of empathetic behaviors in robot agents. We will release our code and dataset.", "title_embedding_index": 16311, "title_abs_embedding_index": 16336}, {"title": "Maintaining Structural Integrity in Parameter Spaces for Parameter Efficient Fine-tuning", "link_suffix": "/forum?id=OALIb8oNfl", "link": "https://openreview.net/forum?id=OALIb8oNfl", "pdf_link": "https://openreview.net/pdf?id=OALIb8oNfl", "keywords": "parameter efficient fine-tuning", "abstract": "Adapting pre-trained foundation models for various downstream tasks has been prevalent in artificial intelligence. Due to the vast number of tasks and high costs, adjusting all parameters becomes unfeasible. To mitigate this, several fine-tuning techniques have been developed to update the pre-trained model weights in a more resource-efficient manner, such as through low-rank adjustments. Yet, almost all of these methods focus on linear weights, neglecting the intricacies of parameter spaces in higher dimensions like 4D. \nAlternatively, some methods can be adapted for high-dimensional parameter space by compressing changes in the original space into two dimensions and then employing low-rank matrix adaptations. However, these approaches destructs the structural integrity of the involved high-dimensional spaces. To tackle the diversity of dimensional spaces across different foundation models and provide a more precise representation of the changes within these spaces, this paper introduces a generalized parameter-efficient fine-tuning framework, designed for various dimensional parameter space. Specifically, our method asserts that changes in each dimensional parameter space are based on a low-rank core space which maintains the consistent topological structure with the original space. It then models the changes through this core space alongside corresponding weights to reconstruct alterations in the original space. It effectively preserves the structural integrity of the change of original N-dimensional parameter space, meanwhile models it via low-rank tensor adaptation. Extensive experiments on computer vision, natural language processing and multi-modal tasks validate the effectiveness of our method.", "title_embedding_index": 16312, "title_abs_embedding_index": 16337}, {"title": "Mechanistic Permutability: Match Features Across Layers", "link_suffix": "/forum?id=MDvecs7EvO", "link": "https://openreview.net/forum?id=MDvecs7EvO", "pdf_link": "https://openreview.net/pdf?id=MDvecs7EvO", "keywords": "Interpretability, LLM features, SAE", "abstract": "Understanding how features evolve across layers in deep neural networks is a fundamental challenge in mechanistic interpretability, particularly due to polysemanticity and feature superposition. While Sparse Autoencoders (SAEs) have been used to extract interpretable features from individual layers, aligning these features across layers has remained an open problem. In this paper, we introduce SAE Match, a novel, data-free method for aligning SAE features across different layers of a neural network. Our approach involves matching features by minimizing the mean squared error between the folded parameters of SAEs, a technique that incorporates activation thresholds into the encoder and decoder weights to account for differences in feature scales. Through extensive experiments on the Gemma 2 language model, we demonstrate that our method effectively captures feature evolution across layers, improving feature matching quality. We also show that features persist over several layers and that our approach can approximate hidden states across layers. Our work advances the understanding of feature dynamics in neural networks and provides a new tool for mechanistic interpretability studies.", "title_embedding_index": 16313, "title_abs_embedding_index": 16338}, {"title": "HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis", "link_suffix": "/forum?id=868masI331", "link": "https://openreview.net/forum?id=868masI331", "pdf_link": "https://openreview.net/pdf?id=868masI331", "keywords": "Text-to-speech synthesis, LLM-based TTS, neural audio codec, long-form generation", "abstract": "Recently, Text-to-speech (TTS) models based on large language models (LLMs) that translate natural language text into sequences of discrete audio tokens have gained great research attention, with advances in neural audio codec (NAC) models using residual vector quantization (RVQ).\nHowever, long-form speech synthesis remains a significant challenge due to the high frame rate, which increases the length of audio tokens and makes it difficult for autoregressive language models to generate audio tokens for even a minute of speech.\nTo address this challenge, this paper introduces two novel post-training approaches: 1) Multi-Resolution Requantization (MReQ) and 2) HALL-E.\nMReQ is a framework to reduce the frame rate of pre-trained NAC models.\nSpecifically, it incorporates multi-resolution residual vector quantization (MRVQ) module that hierarchically reorganizes discrete audio tokens through teacher-student distillation.\nHALL-E is an LLM-based TTS model designed to predict hierarchical tokens of MReQ.\nSpecifically, it incorporates the technique of using MRVQ sub-modules and continues training from a pre-trained LLM-based TTS model.\nFurthermore, to promote TTS research, we create MinutesSpeech, a new benchmark dataset consisting of 40k hours of filtered speech data for training and evaluating speech synthesis ranging from 3s up to 180s.\nIn experiments, we demonstrated the effectiveness of our approaches by applying our post-training framework to VALL-E.\nWe achieved the frame rate down to as low as 8 Hz, enabling the stable minitue-long speech synthesis in a single inference step.\nAudio samples, dataset, codes and pre-trained models are available athttps://anonymous.4open.science/w/halle_demo.", "title_embedding_index": 16314, "title_abs_embedding_index": 16339}, {"title": "Teaching Code Execution to Tiny Language Models", "link_suffix": "/forum?id=JVJE5yZRxm", "link": "https://openreview.net/forum?id=JVJE5yZRxm", "pdf_link": "https://openreview.net/pdf?id=JVJE5yZRxm", "keywords": "Code Language Models, Tiny Language Models, Code Execution", "abstract": "Recent advancements in large language models have demonstrated their effectiveness in various tasks. However, the question of these models' limitations remains open though. For instance, can a language model learn to perform code execution (i.e., predicting the output of code)? Current research indicates that the performance of state-of-the-art large language models in code execution is still limited. The reasons for this limitations are unclear though. Is it due to fundamental constraints or other factors such as training data and computational resources? Is the next-token prediction objective sufficient for learning code execution? How small can a language model be while still capable of learning code execution? In this paper, we investigate these questions. More specifically, we investigate whether tiny language models, trained from scratch using the next-token prediction objective, can effectively learn to execute code. Our experiments show that, given appropriate data, model size, and computational resources, tiny language models can indeed learn to perform code execution with a 99.13% accuracy for a tiny Turing-complete programming language. We begin by defining a tiny programming language called TinyPy. Millions of randomly generated codes in this language, along with their outputs, are used to train our tiny language models using the next-token prediction task. We then conduct a series of experiments to determine the smallest model size, data amount, and computational resources necessary to train our language model to achieve near-perfect accuracy in code execution. Our findings reveal that TEX, our proposed tiny language model with 15M parameters, can successfully learn code execution. This suggests that a task as complex as predicting code output is within the reach of language models.", "title_embedding_index": 16315, "title_abs_embedding_index": 16340}, {"title": "First-Step Advantage: Importance of Starting Right in Multi-Step Math Reasoning", "link_suffix": "/forum?id=MbK0Vs5lFI", "link": "https://openreview.net/forum?id=MbK0Vs5lFI", "pdf_link": "https://openreview.net/pdf?id=MbK0Vs5lFI", "keywords": "Reasoning, Planning, Refinement", "abstract": "Language models can solve complex reasoning tasks better by learning to generate rationales for their predictions. Often these models know how to solve a task but their auto-regressive decoding nature leads to incorrect results if they start incorrectly. \nWe observe that smaller models in particular, when corrected, can solve a task that they would have otherwise struggled with. We demonstrate this phenomenon by using a larger model to guide smaller models, which leads to significantly improved performance (up to+24points on the GSM8K dataset by 7B models). To assist smaller models in initiating the starting step, we propose QuestCoT, where a smaller model firstasks itself how to start, before proceeding with a chain of reasoning.\nOn various multistep mathematical reasoning datasets over multiple smaller models, we show that getting the right start can lead to significant performance gains across all models (gains of up to+6points on GSM8K,+9on SVAMP,+5on ASDiv, and+7on MultiArith).", "title_embedding_index": 16316, "title_abs_embedding_index": 16341}, {"title": "A General Aggregation Federated Learning Intervention Algorithm based ondo-Calculus", "link_suffix": "/forum?id=JNZdhbDBUH", "link": "https://openreview.net/forum?id=JNZdhbDBUH", "pdf_link": "https://openreview.net/pdf?id=JNZdhbDBUH", "keywords": "Federated Learning, do-Calculus, causal", "abstract": "This article explores federated long-tail learning (Fed-LT) tasks, which involve clients with private and heterogeneous data that exhibit a long-tail distribution. We propose two methods: (a) Client Re-weighted Prior Analyzer (CRePA), which balances the global model's performance on tail and non-tail categories and enhances performance on tail categories while maintaining it on non-tail categories. (b) Federated Long-Tail Causal Intervention Model (FedLT-CI) computes clients' causal effects on the global model's performance in the tail and enhances the interpretability of Fed-LT. CRePA achieves state-of-the-art performance, and FedLT-CI improves tail performance significantly without affecting non-tail performance. Extensive experiments indicate that CRePA achieved SOTA performance compared to other baselines on CIFAR-10-LT and CIFAR-100-LT. Applying the FedLT-CI to all baselines significantly improved tail performance without affecting non-tail performance.", "title_embedding_index": 16317, "title_abs_embedding_index": 16342}, {"title": "Zeroth-Order Policy Gradient for Reinforcement Learning from Human Feedback without Reward Inference", "link_suffix": "/forum?id=cmYScmfu4Q", "link": "https://openreview.net/forum?id=cmYScmfu4Q", "pdf_link": "https://openreview.net/pdf?id=cmYScmfu4Q", "keywords": "reinforcement learning theory, human feedback, zeroth-order optimization", "abstract": "Reward inference (learning a reward model from human preferences) is a critical intermediate step in Reinforcement Learning from Human Feedback (RLHF) for fine-tuning Large Language Models (LLMs) such as ChatGPT. In practice, reward inference faces several fundamental challenges, including double problem misspecification, reward model evaluation without ground truth, distribution shift, and overfitting in joint reward model and policy training. \nAn alternative approach that avoids these pitfalls is direct policy optimization without reward inference, such as Direct Preference Optimization (DPO), which provides a much simpler pipeline and has shown empirical success in LLMs. However, DPO utilizes the closed-form expression between the optimal policy and the reward function, which only works under the bandit setting or deterministic MDPs. This paper develops two RLHF algorithms without reward inference, which work for general RL problems beyond bandits and deterministic MDPs, and general preference models beyond the Bradely-Terry model. The key idea is to estimate the local value function difference from human preferences and then approximate the policy gradient with a zeroth-order gradient approximator. For both algorithms, we establish rates of convergence in terms of the number of policy gradient iterations, as well as the number of trajectory samples and human preference queries per iteration. Our results show there exist provably efficient methods to solve general RLHF problems without reward inference.", "title_embedding_index": 16318, "title_abs_embedding_index": 16343}, {"title": "SIKeD: Self-guided Iterative Knowledge Distillation for Mathematical Reasoning", "link_suffix": "/forum?id=ozTREVBARB", "link": "https://openreview.net/forum?id=ozTREVBARB", "pdf_link": "https://openreview.net/pdf?id=ozTREVBARB", "keywords": "Reasoning, Knowledge Distillation, LLM, SLM", "abstract": "Large Language Models (LLMs) can transfer their reasoning skills to smaller models by teaching them to generate the intermediate reasoning process required to solve multistep reasoning tasks.  While LLMs can accurately solve reasoning tasks through a variety of strategies, even without fine-tuning, smaller models are not expressive enough to fit the LLMs distribution on all strategies when distilled and tend to prioritize one strategy over the others.\nThis reliance on one strategy poses a challenge for smaller models when attempting to solve reasoning tasks that may be difficult with their preferred strategy.\nTo address this, we propose a distillation methodSIKeD:Self-guidedIterativeKnowledgeDistillation, where the LLM teaches the smaller model to approach a task using different strategies and the smaller model uses its self-generated on-policy outputs to choose the most suitable strategy for the given task. The training continues in aself-guidediterative manner, where for each training iteration, a decision is made on how to combine the LLM data with the self-generated outputs. Unlike traditional distillation methods,SIKeDallows the smaller model to learnwhichstrategy is suitable for a given task while continuously learning to solve a task using different strategies.\nOur experiments on various mathematical reasoning datasets show thatSIKeDsignificantly outperforms traditional distillation techniques across smaller models of different sizes.", "title_embedding_index": 16319, "title_abs_embedding_index": 16344}, {"title": "Zigzag Diffusion Sampling: The Path to Success ls Zigzag", "link_suffix": "/forum?id=MKvQH1ekeY", "link": "https://openreview.net/forum?id=MKvQH1ekeY", "pdf_link": "https://openreview.net/pdf?id=MKvQH1ekeY", "keywords": "Diffusion model, Semantic Information, Classifier Guidance Gap", "abstract": "Diffusion models, the most popular generative paradigm so far, can inject conditional information into the generation path to guide the latent towards desired directions. However, existing text-to-image diffusion models often fail to maintain high image quality and high prompt-image alignment for those challenging prompts. To mitigate this issue and enhance existing pretrained diffusion models, we mainly made three contributions in this paper. First, we theoretically and empirically demonstrate that the conditional guidance gap between the denoising and inversion processes captures prompt-related semantic information. Second, motivated by theoretical analysis, we derive Zigzag Diffusion Sampling (Z-Sampling), a novel sampling method that leverages the guidance gap to accumulate semantic information step-by-step throughout the entire generation process, leading to improved sampling results. Moreover, as a plug-and-play method, Z-Sampling can be generally applied to various diffusion models (e.g., accelerated ones and Transformer-based ones) with very limited coding costs. Third, extensive experiments demonstrate that Z-Sampling can generally and significantly enhance generation quality across various benchmark datasets, diffusion models, and performance evaluation metrics. Particularly, Z-Sampling is good at handling those challenging fine-grained prompts, such as style, position, counting, and multiple objects, due to its guidance-gap-based information gain. Moreover, Z-Sampling can even further enhance existing diffusion models combined with other orthogonal methods, including Diffusion-DPO.", "title_embedding_index": 16320, "title_abs_embedding_index": 16345}, {"title": "A Single Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces", "link_suffix": "/forum?id=fJ1hON2r2u", "link": "https://openreview.net/forum?id=fJ1hON2r2u", "pdf_link": "https://openreview.net/pdf?id=fJ1hON2r2u", "keywords": "Embedding Space Understanding, Semantic Field, Semantic Field Subspace, Hierarchical Clustering", "abstract": "Embedding spaces encapsulate rich information from deep learning models, with vector distances reflecting the semantic similarity between textual elements. However, their abstract nature and the computational complexity of analyzing them remain significant challenges. To address these, we introduce the concept of Semantic Field Subspace, a novel mapping that links embedding spaces with the underlying semantics. We propose \\textsf{SAFARI}, a novel algorithm for \\textsf{S}em\\textsf{A}ntic \\textsf{F}ield subsp\\textsf{A}ce dete\\textsf{R}m\\textsf{I}nation, which leverages hierarchical clustering to discover hierarchical semantic structures, using Semantic Shifts to capture semantic changes as clusters merge, allowing for the identification of meaningful subspaces. To improve scalability, we extend Weyl's Theorem, enabling an efficient approximation of Semantic Shifts that significantly reduces computational costs. Extensive evaluations on five real-world datasets demonstrate the effectiveness of \\textsf{SAFARI} in uncovering interpretable and hierarchical semantic structures. Additionally, our approximation method achieves a 15$\\sim$30$\\times$ speedup while maintaining minimal errors (less than 0.01), making it practical for large-scale applications. The source code is available at \\url{https://anonymous.4open.science/r/Safari-C803/}.", "title_embedding_index": 16321, "title_abs_embedding_index": 16346}, {"title": "Discrete Latent Plans via Semantic Skill Abstractions", "link_suffix": "/forum?id=L66G39JrM4", "link": "https://openreview.net/forum?id=L66G39JrM4", "pdf_link": "https://openreview.net/pdf?id=L66G39JrM4", "keywords": "Hierarchical Learning, Skill Learning, Imitation Learning", "abstract": "Skill learning from language instructions is a critical challenge in developing intelligent agents that can generalize across diverse tasks and follow complex human instructions. Hierarchical methods address this by decomposing the learning problem into multiple levels, where the high-level and low-level policies are mediated through a latent plan space. Effective modeling and learning of this latent plan space are key to enabling robust and interpretable skill learning. In this paper, we introduce LADS, a hierarchical approach that learns language-conditioned discrete latent plans through semantic skill abstractions. Our method decouples the learning of the latent plan space from the language-conditioned high-level policy to improve training stability. First, we incorporate a trajectory encoder to learn a discrete latent space with the low-level policy, regularized by language instructions. Next, we model the high-level policy as a categorical distribution over these discrete latent plans to capture the multi-modality of the dataset. Through experiments in simulated control environments, we demonstrate that LADS outperforms state-of-the-art methods in both skill learning and compositional generalization.", "title_embedding_index": 16322, "title_abs_embedding_index": 16347}, {"title": "Improving Visual Grounding with Pixel-Word Correlation and Cross-layer Regularization", "link_suffix": "/forum?id=kIOAMYeOcv", "link": "https://openreview.net/forum?id=kIOAMYeOcv", "pdf_link": "https://openreview.net/pdf?id=kIOAMYeOcv", "keywords": "Visual grounding, Vision and Language, Multi-modal fusion", "abstract": "Visual grounding aims to localize the target object in an input image according to a language expression. To achieve this purpose, existing methods either extract the visual and linguistic features independently or utilize language information to guide visual feature extraction. However, the former strategy generates identical, general-purpose visual representations for different text queries, which are redundant and sub-optimal for visual grounding tasks. Other methods that adopt the latter scheme typically construct sophisticated modules based on linguistic features, implicitly guiding the visual feature extraction through end-to-end training. But they often overlook fine-grained visual-linguistic alignment information, resulting in less discriminative visual features, and thus limiting overall model performance. In this paper, we propose a simple-yet-effective module named Highlighter, which explicitly calculates pixel-word correlations between visual and linguistic features, and then uses this correlation information to calibrate and enhance the visual representations. Based on the proposed module, we further introduce a cross-layer regularization loss, designed to maintain the consistency of fine-grained alignment information across different layers and to facilitate the transmission of supervision signals to shallow layers of the visual encoder. Extensive experiments demonstrate that our method achieves state-of-the-art performance on five widely used visual grounding datasets. And ablation studies also verify the effectiveness and efficiency of our method.", "title_embedding_index": 16323, "title_abs_embedding_index": 16348}, {"title": "Neuralized Markov Random Field for Interaction-Aware Stochastic Human Trajectory Prediction", "link_suffix": "/forum?id=r3cEOVj7Ze", "link": "https://openreview.net/forum?id=r3cEOVj7Ze", "pdf_link": "https://openreview.net/pdf?id=r3cEOVj7Ze", "keywords": "human trajectory prediction, interaction modeling", "abstract": "Interactive human motions and the continuously changing nature of intentions pose significant challenges for human trajectory prediction. In this paper, we present a neuralized Markov random field (MRF)-based motion evolution method for probabilistic interaction-aware human trajectory prediction. We use MRF to model each agent's motion and the resulting crowd interactions over time, hence is robust against noisy observations and enables group reasoning. We approximate the modeled distribution using two conditional variational autoencoders (CVAEs) for efficient learning and inference. Our proposed method achieves state-of-the-art performance on ADE/FDE metrics across two dataset categories: overhead datasets ETH/UCY, SDD, and NBA, and ego-centric JRDB. Furthermore, our approach allows for real-time stochastic inference in bustling environments, making it well-suited for a 30FPS video setting. We will open-source our codes upon paper acceptance.", "title_embedding_index": 16324, "title_abs_embedding_index": 16349}]
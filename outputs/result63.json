[
    {
        "title": "Optimal Transport-Based Domain Alignment as a Preprocessing Step for Federated Learning",
        "link_suffix": "/forum?id=KISgRiGCKS",
        "link": "https://openreview.net/forum?id=KISgRiGCKS",
        "pdf_link": "https://openreview.net/pdf?id=KISgRiGCKS",
        "keywords": "Federated Learning, Optimal Transport, Domain Alignment, Data Preprocessing",
        "abstract": "Federated learning is a subfield of machine learning that avoids sharing local data with a central server, which can enhance privacy and scalability. The inability to consolidate data in a central server leads to a unique problem called dataset imbalance, which can be challenging because learning typically requires iid datasets. In FL, fusing locally-trained models that are trained using non-iid datasets may deteriorate the performance of global model aggregation; this further reduces the quality of updated local models and the accuracy of the distributed agents' decisions. In this work, we introduce an Optimal Transport-based preprocessing algorithm that aligns the datasets in a privacy-preserving manner, in turn minimizing the distributional discrepancy of data along the edge devices. We accomplish this by leveraging Wasserstein barycenters when computing channel-wise averages. These barycenters are collected in a trusted central server where they collectively generate a target RGB space. By projecting our dataset towards this target space, we minimize the distributional discrepancy on a global level, which facilitates the learning process due to a minimization of variance across the samples in the analyzed network. We demonstrate the capabilities of the proposed approach over the CIFAR-10 dataset, where we show its capability of reaching higher degrees of generalization in fewer communication rounds."
    },
    {
        "title": "HiReview: Hierarchical Taxonomy-Driven Automatic Literature Review Generation",
        "link_suffix": "/forum?id=Ncx0X8lcN1",
        "link": "https://openreview.net/forum?id=Ncx0X8lcN1",
        "pdf_link": "https://openreview.net/pdf?id=Ncx0X8lcN1",
        "keywords": "Literature review generation, retrieval-augmented generation, hierarchical graph clustering",
        "abstract": "In this work, we present HiReview, a novel framework for hierarchical taxonomy-driven automatic literature review generation. With the exponential growth of academic documents, manual literature reviews have become increasingly labor-intensive and time-consuming, while traditional summarization models struggle to generate comprehensive document reviews effectively. Large language models (LLMs), with their powerful text processing capabilities, offer a potential solution; however, research on incorporating LLMs for automatic document generation remains limited. To address key challenges in large-scale automatic literature review generation (LRG), we propose a two-stage taxonomy-then-generation approach that combines graph-based hierarchical clustering with retrieval-augmented LLMs. First, we retrieve the most relevant sub-community within the citation network, then generate a hierarchical taxonomy tree by clustering papers based on both textual content and citation relationships. In the second stage, an LLM generates coherent and contextually accurate summaries for clusters or topics at each hierarchical level, ensuring comprehensive coverage and logical organization of the literature. Extensive experiments demonstrate that HiReview significantly outperforms state-of-the-art methods, achieving superior hierarchical organization, content relevance, and factual accuracy in automatic literature review generation tasks. The code and dataset are available athttps://anonymous.4open.science/r/HiReivew-767D."
    },
    {
        "title": "Comparing Protein Language Models Using Remote Homology Detection for Phages",
        "link_suffix": "/forum?id=IEZjjDX0iC",
        "link": "https://openreview.net/forum?id=IEZjjDX0iC",
        "pdf_link": "https://openreview.net/pdf?id=IEZjjDX0iC",
        "keywords": "Protein Language Model, Machine Learning, Classification, Virus",
        "abstract": "Background. Protein language models (pLMs) are machine learning models that\nlearn high-dimensional representations of protein sequences. These models have\nutility in biological settings, for instance pLMs can convert between protein sequence and structure (Heinzinger et al., 2023), determine evolutionary relationships between organisms (Bordin et al., 2023), and design protein sequences with\ndesired functions (Madani et al., 2023). Transfer learning with previously trained\npLMs offers a powerful, minimal resource strategy for performing diverse largescale classification and prediction tasks. However, as pLMs proliferate in the\nresearch community with differences in training objectives, model structure(s)\nand training datasets, it is daunting for a less-experienced end user to decide\nwhich pLM to use for biological experiments and discovery. Consequently, it\nis essential to compare pLMs to determine their strengths and limitations. In\nparticular, such explorations are necessary in use-cases relevant to biological researchers. Therefore, we present a comparison of pre-trained pLMs in a difficult remote homology detection task for phage proteins described previously in\nFlamholz et al. (2024), Large language models improve annotation of prokaryotic\nviral proteins. We also make available our code and notebooks to facilitate other\nresearch scientists to use such models. Results. Variations in model training resulted in\nsignificantly different performance in our biological task. We present an analysis that compares five recently published pLMs : (1) ProtT5, (2) ProstT5, (3)\nTMVec, (4) ESM2, and (5) CARP. We observed that all models were able to capture meaningful structural information in viral proteins. We also determined that\ntheir embeddings could be used to train functional classifiers that, when tested\nusing the PHROG and EFAM databases of phage proteins, captured meaningful\nbiological information. However, the performances across the different models\nwere noticeably different. Models trained on larger, more diverse databases of\ngenomic sequences such as Big Fantastic Database (BFD) performed better overall. Models with the Transformer architecture performed better than those with\nthe convolutional neural network (CNN) architectures. Conclusion. The utility\nof pLMs in areas of biological research is clear as we demonstrate such models\nare useful for remote homology detection in phage genomes, an area of active\ninterest in metagenomics and environmental biology. Our study highlights how\nbiological scientists can choose pLMs to incorporate into their experiments and\nanalyses. Overall, while some models clearly performed better, on the whole, all\npLMs achieved high scores for prediction. For end-users, the implication is that\nmany pLM models are useful, but testing and domain knowledge may improve\nresults when addressing specific biological questions and developing specialized\nmodel training paradigms."
    },
    {
        "title": "Learning with Real-time Improving Predictions in Online MDPs",
        "link_suffix": "/forum?id=6HfNB34x9I",
        "link": "https://openreview.net/forum?id=6HfNB34x9I",
        "pdf_link": "https://openreview.net/pdf?id=6HfNB34x9I",
        "keywords": "Online learning, Markov decision process, regret analysis, predictions",
        "abstract": "In this paper, we introduce the Decoupling Optimistic Online Mirror Descent (DOOMD) algorithm, a novel online learning approach designed for episodic Markov Decision Processes with real-time improving predictions. Unlike conventional methods that employ a fixed policy throughout each episode, our approach allows for continuous updates of both predictions and policies within an episode. To achieve this, the DOOMD algorithm decomposes decision-making across states, enabling each state to execute an individual sub-algorithm that considers both immediate and long-term effects on future decisions. We theoretically establish a sub-linear regret bound for the algorithm, providing a guarantee on the worst-case performance."
    },
    {
        "title": "Learning to localize leakage of cryptographic keys through power consumption",
        "link_suffix": "/forum?id=WmTYaKWHVW",
        "link": "https://openreview.net/forum?id=WmTYaKWHVW",
        "pdf_link": "https://openreview.net/pdf?id=WmTYaKWHVW",
        "keywords": "deep learning, adversarial, mutual information, side channel attack, cryptography",
        "abstract": "While cryptographic algorithms such as the ubiquitous Advanced Encryption Standard (AES) are secure,physical implementationsof these algorithms in hardware inevitably 'leak' sensitive information such as cryptographic keys. A particularly insidious form of leakage arises from the fact that hardware's power consumption over time is statistically associated with the data it processes and the instructions it executes. Supervised deep learning has emerged as a state-of-the-art tool for carrying outpower side-channel attacks, which exploit this leakage to break cryptographic implementations by learning to map power consumption measurements recorded during encryption to the secret key used for that encryption. In this work, we seek instead to develop a principled deep learning framework fordefenseagainst such attacks by understanding the relative leakage due to power measurements recorded at different points in time. This information is invaluable to cryptographic hardware designers for understandingwhytheir hardware leaks and how they can mitigate the leakage (e.g. by indicating that a particular section of code or electronic component is responsible for leakage and should be revised). Towards this end, we propose a novel deep learning algorithm by formulating an adversarial game played between a classifier trained to estimate the conditional distribution of a key given power measurements, and an 'obfuscator' which probabilistically erases individual power measurements and is trained to minimize the classifier-estimated log-likelihood of the correct key, subject to a penalty on erasure probability. We theoretically characterize the ideal output of our algorithm in terms of conditional mutual information quantities involving the key and individual power measurements. We then demonstrate the efficacy of our algorithm on real and synthetic datasets of power measurements from implementations of the AES cryptographic standard. Our code can be found (redacted)."
    },
    {
        "title": "Mitigating Goal Misgeneralization via Minimax Regret",
        "link_suffix": "/forum?id=po67tkP0Jx",
        "link": "https://openreview.net/forum?id=po67tkP0Jx",
        "pdf_link": "https://openreview.net/pdf?id=po67tkP0Jx",
        "keywords": "Goal Misgeneralization, Unsupervised Environment Design, Reinforcement Learning, AI Safety, Alignment, Autocurricula",
        "abstract": "Robustness research in reinforcement learning often focuses on ensuring that the policy consistently exhibits capable, goal-driven behavior. However, not every capable behavior is the intended behavior.Goal misgeneralizationcan occur when the policy generalizes capably with respect to a 'proxy goal' whose optimal behavior correlates with the intended goal on the training distribution, but not out of distribution. Though the intended goal would be ambiguous if they were perfectly correlated in training, we show progress can be made if the goals are onlynearly ambiguous, with the training distribution containing a small proportion ofdisambiguatinglevels. We observe that the training signal from disambiguating levels could be amplified by regret-based prioritization. We formally show that approximately optimal policies on maximal-regret levels avoid the harmful effects of goal misgeneralization, which may exist without this prioritization. Empirically, we find that current regret-based Unsupervised Environment Design (UED) methods can mitigate the effects of goal misgeneralization, though do not always entirely eliminate it. Our theoretical and empirical results show that as UED methods improve they could further mitigate goal misgeneralization in practice."
    },
    {
        "title": "LoRA-Contextualizing Adaptation of Large Multimodal Models for Multi-page Document Understanding",
        "link_suffix": "/forum?id=FDaHjwInXO",
        "link": "https://openreview.net/forum?id=FDaHjwInXO",
        "pdf_link": "https://openreview.net/pdf?id=FDaHjwInXO",
        "keywords": "Large Multimodal Models",
        "abstract": "Large multimodal models (LMMs) have recently shown great progress in text-rich image understanding, yet they still struggle with complex, multi-page visually-rich documents. Traditional methods using document parsers for retrieval-augmented generation suffer from performance and efficiency limitations, while directly presenting all pages to LMMs leads to inefficiencies, especially with lengthy ones.  In this work, we present a novel framework namedLoRA-ContextualizingAdaptation ofLarge multimodal models (LoCAL) to broaden the horizons of any LMM for multi-page document understanding. We demonstrate that LMMs themselves can be an effective multimodal retriever to fetch relevant pages and then answer user questions based on these pages. LoCAL is implemented with two specific LMM adapters: one for evidence page retrieval and the other for question answering. Empirical results show state-of-the-art performance on public benchmarks, demonstrating the effectiveness of LoCAL."
    },
    {
        "title": "Accelerating Multi-Block Constrained Optimization Through Learning to Optimize",
        "link_suffix": "/forum?id=R1WF5b5faF",
        "link": "https://openreview.net/forum?id=R1WF5b5faF",
        "pdf_link": "https://openreview.net/pdf?id=R1WF5b5faF",
        "keywords": "Learning to Optimize, Multi-Block Constrained Optimzation, Alternating Direction Method of Multipliers, Proximal Augmented Lagrangian Methods",
        "abstract": "Learning to Optimize (L2O) approaches, including algorithm unrolling, plug-and-play methods, and hyperparameter learning, have garnered significant attention and have been successfully applied to the Alternating Direction Method of Multipliers (ADMM) and its variants. However, the natural extension of L2O to multi-block ADMM-type methods remains largely unexplored. Such an extension is critical, as multi-block methods leverage the separable structure of optimization problems, offering substantial reductions in per-iteration complexity. Given that classical multi-block ADMM does not guarantee convergence, the Majorized Proximal Augmented Lagrangian Method (MPALM), which shares a similar form with multi-block ADMM and ensures convergence, is more suitable in this setting. Despite its theoretical advantages, MPALM’s performance is highly sensitive to the choice of penalty parameters. To address this limitation, we propose a novel L2O approach that adaptively selects this hyperparameter using supervised learning. We demonstrate the versatility and effectiveness of our method by applying it to the Lasso problem and the optimal transport problem. Our numerical results show that the proposed framework outperforms popular alternatives. Given its applicability to generic linearly constrained composite optimization problems, this work opens the door to a wide range of potential real-world applications."
    },
    {
        "title": "ToolComp: A Multi-Tool Reasoning & Process Supervision Benchmark",
        "link_suffix": "/forum?id=qHpfxfnIq3",
        "link": "https://openreview.net/forum?id=qHpfxfnIq3",
        "pdf_link": "https://openreview.net/pdf?id=qHpfxfnIq3",
        "keywords": "tool-augmented LLMs, process supervision, reward models, tool-use, react, benchmark, prm",
        "abstract": "Despite recent advances in AI, the development of systems capable of executing complex, multi-step reasoning tasks involving multiple tools remains a significant challenge. Current benchmarks fall short in capturing the real-world complexity of tool-use reasoning, where verifying the correctness of not only the final answer but also the intermediate steps is important for evaluation, development, and identifying failures during inference time. To bridge this gap, we introduce ToolComp, a comprehensive benchmark designed to evaluate multi-step tool-use reasoning. ToolComp is developed through a collaboration between models and human annotators, featuring human-edited/verified prompts, final answers, and process supervision labels, allowing for the evaluation of both final outcomes and intermediate reasoning. Evaluation across six different model families demonstrates the challenging nature of our dataset, with the majority of models achieving less than 50% accuracy. Additionally, we compare the performance of outcome-supervised reward models (ORMs) with process-supervised reward models (PRMs) on Tool-Comp to assess their ability to improve complex tool-use reasoning. Our results\nshow that PRMs generalize significantly better than ORMs, achieving a 19% and 11% improvement in rank@1 accuracy for ranking base and fine-tuned model trajectories, respectively. These findings highlight the critical role of process supervision in both the evaluation and training of AI models, paving the way for more robust and capable systems in complex, multi-step tool-use tasks."
    },
    {
        "title": "Intelligence at the Edge of Chaos",
        "link_suffix": "/forum?id=IeRcpsdY7P",
        "link": "https://openreview.net/forum?id=IeRcpsdY7P",
        "pdf_link": "https://openreview.net/pdf?id=IeRcpsdY7P",
        "keywords": "Large Language Models (LLMs), Elementary Cellular Automata (ECA), Emergent Intelligence, Complex Systems, Complexity Theory",
        "abstract": "We explore the emergence of intelligent behavior in artificial systems by investigating how the complexity of rule-based systems influences the capabilities of models trained to predict these rules. Our study focuses on elementary cellular automata (ECA), simple yet powerful one-dimensional systems that generate behaviors ranging from trivial to highly complex. By training distinct Large Language Models (LLMs) on different ECAs, we evaluated the relationship between the complexity of the rules' behavior and the intelligence exhibited by the LLMs, as reflected in their performance on downstream tasks. Our findings reveal that rules with higher complexity lead to models exhibiting greater intelligence, as demonstrated by their performance on reasoning and chess move prediction tasks. Both uniform and periodic systems, and often also highly chaotic systems, resulted in poorer downstream performance, highlighting a sweet spot of complexity conducive to intelligence. We conjecture that intelligence arises from the ability to predict complexity and that creating intelligence may require only exposure to complexity."
    },
    {
        "title": "Towards a  learning theory of representation alignment",
        "link_suffix": "/forum?id=DShqJA1Z64",
        "link": "https://openreview.net/forum?id=DShqJA1Z64",
        "pdf_link": "https://openreview.net/pdf?id=DShqJA1Z64",
        "keywords": "learning theory, representation learning, model stitching, representation alignment",
        "abstract": "It has recently been argued that AI models' representations are becoming aligned as their scale and performance increase. Empirical analyses have been designed to support this idea and conjecture the possible alignment of different representations toward a shared statistical model of reality. In this paper, we propose a learning-theoretic perspective to representation alignment. First, we review and connect different notions of alignment based on metric, probabilistic, and spectral ideas. Then, we focus on stitching, a particular approach to understanding the interplay between different representations in the context of a task. Our main contribution here is relating properties of stitching to the kernel alignment of the underlying representation. Our results can be seen as a first step toward casting representation alignment as a learning-theoretic problem."
    },
    {
        "title": "Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering and Modulating Individual Human Percepts",
        "link_suffix": "/forum?id=APWIZgehDT",
        "link": "https://openreview.net/forum?id=APWIZgehDT",
        "pdf_link": "https://openreview.net/pdf?id=APWIZgehDT",
        "keywords": "Perceptual variability, Diffusion model, Object Recognition, Behavior Modulation, Behavioral Alignment",
        "abstract": "Human decision-making in cognitive tasks and daily life often exhibits significant variability influenced by various factors such as task difficulty, individual preferences, and cultural differences. Understanding individual variability helps enhance our comprehension of the perceptual and decision-making mechanisms when humans confront uncertainty and ambiguous information. Here we present a counterfactual-based approach to investigate the subject-level decision-making behaviors and the underlying perceptual mechanisms using synthetic visual stimuli. We develop an efficient generative model that samples along the artificial neural network (ANN)’s perceptual boundary to create image samples capable of inducing high variability in human perception. These generated samples, combined with behavioral measurements collected from 346 participants with 242,900 trials, form the varMNIST dataset. By aligning the perceptual variability between humans and ANNs, we successfully predict human decision-making behaviors on varMNIST. Furthermore, we are able to selectively modulate individual behaviors by generating tailored controversial stimuli. These stimuli reveal large individual differences, indicating the inter-subject perceptual variability. Together, our study uncovers specific distinctions between humans and machines in the variability of their perceptual experiences and opens a new avenue for modulating individual decision-making behaviors, providing new perspectives for developing artificial intelligence models with personalized perception."
    },
    {
        "title": "Finding Equilibria in Bilinear Zero-sum Games via a Convexity-based Approach",
        "link_suffix": "/forum?id=CrMyHiUttz",
        "link": "https://openreview.net/forum?id=CrMyHiUttz",
        "pdf_link": "https://openreview.net/pdf?id=CrMyHiUttz",
        "keywords": "Zero-sum games, Directional derivative, gradient descent, duality gap",
        "abstract": "We focus on the design of algorithms for finding equilibria in 2-player zero-sum games. Although it is well known that such problems can be solved by a single linear program, there has been a surge of interest in recent years, for simpler algorithms, motivated in part by applications in machine learning. Our work proposes such a method, inspired by the observation that the duality gap (a standard metric for evaluating convergence in general min-max optimization problems) is a convex function for the case of bilinear zero-sum games. To this end, we analyze a descent-based approach, variants of which have also been used as a subroutine in a series of algorithms for approximating Nash equilibria in general non-zero-sum games.In particular, we analyze a steepest descent approach, by finding the direction that minimises the directional derivative of the duality gap function and move towards that. Our main theoretical result is that the derived algorithms achieve a geometric decrease in the duality gap and improved complexity bounds until we reach an approximate equilibrium. Finally, we complement this with an experimental evaluation. Our findings reveal that for some classes of zero-sum games, the running time of our method is comparable with standard LP solvers, even with thousands of available strategies per player."
    },
    {
        "title": "Physics-Informed Interpolator Generalizes Well in Fixed Dimension: Inductive Bias and Benign Overfitting",
        "link_suffix": "/forum?id=lNuGCXxvkn",
        "link": "https://openreview.net/forum?id=lNuGCXxvkn",
        "pdf_link": "https://openreview.net/pdf?id=lNuGCXxvkn",
        "keywords": "Kernel",
        "abstract": "Recent advances in machine learning have inspired a surge of research into reconstructing specific quantities of interest from measurements that comply with certain physical laws. These efforts focus on inverse problems that are governed by partial differential equations (PDEs). In this work, we develop an asymptotic Sobolev norm learning curve  for kernel ridge(less) regression when addressing (elliptical) linear inverse problems. Our results show that the PDE operators in the inverse problem can stabilize the variance and even behave benign overfitting for fixed-dimensional problems, exhibiting different behaviors from regression problems. Besides, our investigation also demonstrates the impact of various inductive biases introduced by minimizing different Sobolev norms as a form of implicit regularization. For the regularized least squares estimator, we find that all considered inductive biases can achieve the optimal convergence rate, provided the regularization parameter is appropriately chosen. The convergence rate is actually independent to the choice of (smooth enough) inductive bias for both ridge and ridgeless regression. Surprisingly, our smoothness requirement recovered the condition found in Bayesian setting and extend the conclusion to the minimum norm interpolation estimators."
    },
    {
        "title": "Grassmannian Geometry Meets Dynamic Mode Decomposition in DMD-GEN: A New Metric for Mode Collapse in Time Series Generative Models",
        "link_suffix": "/forum?id=psG83N6GZi",
        "link": "https://openreview.net/forum?id=psG83N6GZi",
        "pdf_link": "https://openreview.net/pdf?id=psG83N6GZi",
        "keywords": "Time series, Generative models, Mode Collapse",
        "abstract": "Generative models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) often fail to capture the full diversity of their training data, leading to mode collapse. While this issue is well-explored in image generation, it remains underinvestigated for time series data. We introduce a new definition of mode collapse specific to time series and propose a novel metric, DMD-GEN, to quantify its severity. Our metric utilizes Dynamic Mode Decomposition (DMD), a data-driven technique for identifying coherent spatiotemporal patterns, and employs Optimal Transport between DMD eigenvectors to assess discrepancies between the underlying dynamics of the original and generated data. This approach not only quantifies the preservation of essential dynamic characteristics but also provides interpretability by pinpointing which modes have collapsed. We validate DMD-GEN on both synthetic and real-world datasets using various generative models, including TimeGAN, TimeVAE, and DiffusionTS. The results demonstrate that DMD-GEN correlates well with traditional evaluation metrics for static data while offering the advantage of applicability to dynamic data. This work offers for the first time a definition of mode collapse for time series, improving understanding, and forming the basis of our tool for assessing and improving generative models in the time series domain."
    },
    {
        "title": "Running Huge Context Windows On Tiny GPUs",
        "link_suffix": "/forum?id=pG820nmDvy",
        "link": "https://openreview.net/forum?id=pG820nmDvy",
        "pdf_link": "https://openreview.net/pdf?id=pG820nmDvy",
        "keywords": "attention, transformers, large language models, long context",
        "abstract": "There is growing demand for large language models that can process hundreds of thousands or even millions of input tokens. Inference at this extreme scale demands significant computational resources and costs. To address the inference time costs associated with running self-attention based transformer language models on long contexts, we propose a tunable mechanism that reduces the cost of the forward pass by attending to only the most relevant tokens at every generation step using a top-k selection mechanism. We showcase the efficiency gains afforded by our method by performing inference on context windows up to 1M tokens using approximately 16GB of GPU RAM. Our experiments reveal that models are capable of handling the sparsity induced by the reduced number of keys and values. \nBy attending to less than 1% of input tokens, we achieve over 95% of model performance on common long context benchmarks (LM-Eval, AlpacaEval, and RULER)."
    },
    {
        "title": "Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders",
        "link_suffix": "/forum?id=Ch8s4FdUXS",
        "link": "https://openreview.net/forum?id=Ch8s4FdUXS",
        "pdf_link": "https://openreview.net/pdf?id=Ch8s4FdUXS",
        "keywords": "SDXL Turbo, sparse autoencoders, interpretability, steering",
        "abstract": "Sparse autoencoders (SAEs) have become a core ingredient in the reverse engineering of large-language models (LLMs). For LLMs, they have been shown to decompose intermediate representations that often are not interpretable directly into sparse sums of interpretable features, facilitating better control and subsequent analysis. However, similar analyses and approaches were lacking for text-to-image models. We investigated the possibility of using SAEs to learn interpretable features for a few-step text-to-image diffusion models, such as SDXL Turbo. To this end, we train SAEs on the updates performed by transformer blocks within SDXL Turbo's denoising U-net. We find that their learned features are interpretable, causally influence the generation process, and reveal specialization among the blocks. In particular, we find one block mainly dealing with image composition, mainly responsible for adding local details, and, one for color, illumination, and style. Therefore, our work is an important first step towards better understanding the internals of generative text-to-image models like SDXL Turbo and showcases the potential of features learned by SAEs for the visual domain."
    },
    {
        "title": "Understanding Benefit of Personalization: Beyond Classification",
        "link_suffix": "/forum?id=wF8eG12wtw",
        "link": "https://openreview.net/forum?id=wF8eG12wtw",
        "pdf_link": "https://openreview.net/pdf?id=wF8eG12wtw",
        "keywords": "Explainability, Fairness, Personalization",
        "abstract": "In many applications spanning healthcare, finance, and admissions, it is beneficial to have personalized machine learning models that make predictions tailored to subgroups. This can be achieved by encoding personalized characteristics (such as age and sex) as model inputs. In domains where model trust and accuracy are paramount, it is critical to evaluate the effect of personalizing models not only on prediction accuracy but also on the quality of post-hoc model explanations. This paper introduces a unifying framework to quantify and validate personalization benefits in terms of both prediction accuracy and explanation quality across different groups, extending this concept to regression settings for the first time --broadening its scope and applicability. For both regression and classification, we derive novel bounds for the number of personalized attributes that can be used to reliably validate these gains. Additionally, through our theoretical analysis we demonstrate that improvements in prediction accuracy due to personalization do not necessarily translate to enhanced explainability, underpinning the importance to evaluate both metrics when applying machine learning models to safety-critical settings such as healthcare. Finally, we evaluate our proposed framework and validation techniques on a real-world dataset, exemplifying the analysis possibilities that they offer. This research contributes to ongoing efforts in understanding personalization benefits, offering a robust and versatile framework for practitioners to holistically evaluate their models."
    },
    {
        "title": "First-Step Inference in Diffusion Models Learns Image De-whitening",
        "link_suffix": "/forum?id=2xljvcYOLm",
        "link": "https://openreview.net/forum?id=2xljvcYOLm",
        "pdf_link": "https://openreview.net/pdf?id=2xljvcYOLm",
        "keywords": "Diffusion models, ZCA Whitening",
        "abstract": "Diffusion models have emerged as powerful generative models for image synthesis, yet the intricate relationship between input noise and generated images remains not fully understood. In this paper, we investigate the correlation between noise and images generated through deterministic DDIM sampling, uncovering fundamental elements that are present across different diffusion models. More specifically, we demonstrate that a one-step approximation of the mapping learned by these models closely relates to Zero-phase Component Analysis (ZCA) inverse whitening transform, which maximizes the correlation between source and target distributions. We leverage this insight to develop a simple and yet effective model-agnostic method for sampling correlated noises and showcase applications for image variation generation and editing."
    },
    {
        "title": "PLS-based approach for Fair Representation Learning",
        "link_suffix": "/forum?id=EUBMPmcCWQ",
        "link": "https://openreview.net/forum?id=EUBMPmcCWQ",
        "pdf_link": "https://openreview.net/pdf?id=EUBMPmcCWQ",
        "keywords": "Fair Representation Learning, PLS, Supervised Learning, Dimension Reduction, Fairness",
        "abstract": "We revisit the problem of fair representation learning by proposing Fair Partial Least Squares (PLS) components. PLS is widely used in statistics to efficiently reduce the dimension of the data by providing representation tailored for the prediction. We propose a novel method to incorporate fairness constraints in the construction of PLS components. This new algorithm provides a feasible way to construct such features both in the linear and the non linear case using kernel embeddings. The efficiency of our method is evaluated on different datasets, and we prove its superiority with respect to standard fair PCA method."
    },
    {
        "title": "Identifying Sub-networks in Neural Networks via Functionally Similar Representations",
        "link_suffix": "/forum?id=sp9irsV1yq",
        "link": "https://openreview.net/forum?id=sp9irsV1yq",
        "pdf_link": "https://openreview.net/pdf?id=sp9irsV1yq",
        "keywords": "mechanistic interpretability, subnetworks",
        "abstract": "Mechanistic interpretability aims to provide human-understandable insights into the inner workings of neural network models by examining their internals. Existing approaches typically require significant manual effort and prior knowledge, with strategies tailored to specific tasks. In this work, we take a step toward automating the understanding of the network by investigating the existence of distinct  sub-networks. Specifically, we explore a novel automated and task-agnostic approach based on the notion of functionally similar representations within neural networks, reducing the need for human intervention. \nOur method identifies similar and dissimilar layers in the network, revealing potential sub-components. We achieve this by proposing, for the first time to our knowledge, the use of Gromov-Wasserstein distance, which overcomes challenges posed by varying distributions and dimensionalities across intermediate representations—issues that complicate direct layer-to-layer comparisons.\nThrough experiments on algebraic and language tasks, we observe the emergence of sub-groups within neural network layers corresponding to functional abstractions. Additionally, we find that different training strategies influence the positioning of these sub-groups. Our approach offers meaningful insights into the behavior of neural networks with minimal human and computational cost."
    },
    {
        "title": "A Unified Framework for Forward and Inverse Problems in Subsurface Imaging using Latent Space Translations",
        "link_suffix": "/forum?id=yIlyHJdYV3",
        "link": "https://openreview.net/forum?id=yIlyHJdYV3",
        "pdf_link": "https://openreview.net/pdf?id=yIlyHJdYV3",
        "keywords": "Machine Learning, Inverse Problems, Full-Waveform Inversion, Seismic Imaging, ML4Science",
        "abstract": "In subsurface imaging, learning the mapping from velocity maps to seismic waveforms (forward problem) and waveforms to velocity (inverse problem) is important for several applications. While traditional techniques for solving forward and inverse problems are computationally prohibitive, there is a growing interest to leverage recent advances in deep learning to learn the mapping between velocity maps and seismic waveform images directly from data. Despite the variety of architectures explored in previous works, several open questions still remain unanswered such as the effect of latent space sizes, the importance of manifold learning, the complexity of translation models, and the value of jointly solving forward and inverse problems. We propose a unified framework to systematically characterize prior research in this area termed the Generalized Forward-Inverse (GFI) framework, building on the assumption of manifolds and latent space translations. We show that GFI encompasses previous works in deep learning for subsurface imaging, which can be viewed as specific instantiations of GFI. We also propose two new model architectures within the framework of GFI: Latent U-Net and Invertible X-Net, leveraging the power of U-Nets for domain translation and the ability of IU-Nets to simultaneously learn forward and inverse translations, respectively. We show that our proposed models achieve state-of-the-art (SOTA) performance for forward and inverse problems on a wide range of synthetic datasets, and also investigate their zero-shot effectiveness on two real-world-like datasets."
    },
    {
        "title": "Decomposing heterogeneous dynamical systems with graph neural networks",
        "link_suffix": "/forum?id=7FQDHv9fD4",
        "link": "https://openreview.net/forum?id=7FQDHv9fD4",
        "pdf_link": "https://openreview.net/pdf?id=7FQDHv9fD4",
        "keywords": "graph neural networks, gnn, dynamic system, latent parameter discovery",
        "abstract": "Natural physical, chemical, and biological dynamical systems are often complex, with heterogeneous components interacting in diverse ways. We show that graph neural networks can be designed to jointly learn the interaction rules and the structure of the heterogeneity from data alone. The learned latent structure and dynamics can be used to virtually decompose the complex system which is necessary to infer and parameterize the underlying governing equations. We tested the approach with simulation experiments of moving particles and vector fields that interact with each other. While our current aim is to better understand and validate the approach with simulated data, we anticipate it to become a generally applicable tool to uncover the governing rules underlying complex dynamics observed in nature."
    },
    {
        "title": "Forecasting Needles in a Time Series Haystack",
        "link_suffix": "/forum?id=PTjKXwrVCT",
        "link": "https://openreview.net/forum?id=PTjKXwrVCT",
        "pdf_link": "https://openreview.net/pdf?id=PTjKXwrVCT",
        "keywords": "Time Series Forecasting, Zero-Shot Forecasting, Time Series Benchmark",
        "abstract": "Shocks and sudden spikes are common characteristics of real-world time series data. For example, demand surges or electricity outages often occur in time series data, manifesting as spikes (“Needles”) added to the regular time series (“Haystack”). Despite their importance, it is surprising to find their absence in the benchmarking protocol at the frontier of time series research—Time Series Foundation Models (TSFMs). To address this gap, we present the Needle-in-a-Time-Series-Haystack (NiTH) Benchmark, which includes both synthetic and real-world spiky time series data from diverse domains like traffic, energy, and biomedical systems. For synthetic data, we develop a flexible framework using Poisson-based modeling to generate spiky time series, allowing us to evaluate forecast models under various conditions. To accurately assess model performance, we introduce a new metric based on Dynamic Time Warping, specifically designed for spiky data. We evaluate the zero-shot forecasting capabilities of 6 popular TSFMs over 64 million observations, identifying their limitations related to architecture, tokenization, and loss functions. Furthermore, we demonstrate that the incorporation of the proposed NiTH dataset, due to its diversity compared to the common pre-training corpus of TSFMs, results in improved performance."
    },
    {
        "title": "Bias Analysis in Unconditional Image Generative Models",
        "link_suffix": "/forum?id=57xboRTbwI",
        "link": "https://openreview.net/forum?id=57xboRTbwI",
        "pdf_link": "https://openreview.net/pdf?id=57xboRTbwI",
        "keywords": "image generative models, bias analysis, distribution shift",
        "abstract": "The widespread usage of generative AI models raises concerns regarding fairness and potential discriminatory outcomes. In this work, we define the bias of an attribute (e.g., gender or race) as the difference between the probability of its presence in the observed distribution and its expected proportion in an ideal reference distribution. Despite efforts to study social biases in these models, the origin of biases in generation remains unclear. Many components in generative AI models may contribute to biases. This study focuses on the inductive bias of unconditional generative models, one of the core components, in image generation tasks. We propose a standardized bias evaluation framework to study bias shift between training and generated data distributions. We train unconditional image generative models on the training set and generate images unconditionally. To obtain attribute labels for generated images, we train a classifier using ground truth labels. We compare the bias of given attributes between generation and data distribution using classifier-predicted labels. This absolute difference is named bias shift. Our experiments reveal that biases are indeed shifted in image generative models. Different attributes exhibit varying bias shifts' sensitivity towards distribution shifts. We propose a taxonomy categorizing attributes as $\\textit{subjective}$ (high sensitivity) or $\\textit{non-subjective}$ (low sensitivity), based on whether the classifier's decision boundary falls within a high-density region. We demonstrate an inconsistency between conventional image generation metrics and observed bias shifts. Finally, we compare diffusion models of different sizes with Generative Adversarial Networks (GANs), highlighting the superiority of diffusion models in terms of reduced bias shifts."
    }
]
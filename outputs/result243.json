[
    {
        "title": "ErrorRadar: Benchmarking Complex Mathematical Reasoning of Multimodal Large Language Models Via Error Detection",
        "link_suffix": "/forum?id=GeTBk67mK6",
        "link": "https://openreview.net/forum?id=GeTBk67mK6",
        "pdf_link": "https://openreview.net/pdf?id=GeTBk67mK6",
        "keywords": "Multimodal Large Language Model, Complex Reasoning, Error Detection",
        "abstract": "As the field of Multimodal Large Language Models (MLLMs) continues to evolve, their potential to revolutionize artificial intelligence is particularly promising, especially in addressing mathematical reasoning tasks. Current mathematical benchmarks predominantly focus on evaluating MLLMs' problem-solving ability, yet there is a crucial gap in addressing more complex scenarios such as error detection, for enhancing reasoning capability in complicated settings. To fill this gap, we formally formulate the new task \u2014 \\textbf{multimodal error detection}, and introduce ErrorRadar, the first benchmark designed to assess MLLMs' capabilities in such a task. ErrorRadar evaluates two sub-tasks: \\textit{error step identification} and \\textit{error categorization}, providing a comprehensive framework for evaluating MLLMs' complex mathematical reasoning ability. It consists of 2,500 high-quality multimodal K-12 mathematical problems, collected from real-world student interactions in an educational organization, with rigorous annotation and rich metadata such as problem type and error category. Through extensive experiments, we evaluated both open-source and closed-source representative MLLMs, benchmarking their performance against educational expert evaluators. Results indicate significant challenges still remain, as GPT-4o with best performance is still around 10% behind human evaluation. The dataset is available athttps://anonymous.4open.science/r/Error-Radar."
    },
    {
        "title": "Revisiting Referring Expression Comprehension Evaluation in the Era of Large Multimodal Models",
        "link_suffix": "/forum?id=fqtaADSGEe",
        "link": "https://openreview.net/forum?id=fqtaADSGEe",
        "pdf_link": "https://openreview.net/pdf?id=fqtaADSGEe",
        "keywords": "Referring Expression Comprehension, Benchmark, Dataset, Evaluation, Large Multimodal Models",
        "abstract": "Referring expression comprehension (REC) involves localizing a target instance based on a textual description. Recent advancements in REC have been driven by large multimodal models (LMMs) like CogVLM, which achieved 92.44% accuracy on RefCOCO. However, this study questions whether existing benchmarks such as RefCOCO, RefCOCO+, and RefCOCOg, capture LMMs' comprehensive capabilities. We begin with a manual examination of these benchmarks, revealing high labeling error rates: 14% in RefCOCO, 24% in RefCOCO+, and 5% in RefCOCOg, which undermines the authenticity of evaluations. We address this by excluding problematic instances and reevaluating several LMMs capable of handling the REC task, showing significant accuracy improvements, thus highlighting the impact of benchmark noise. In response, we introduce Ref-L4, a comprehensive REC benchmark, specifically designed to evaluate modern REC models. Ref-L4 is distinguished by four key features: 1) a substantial sample size with 45,341 annotations; 2) a diverse range of object categories with 365 distinct types and varying instance scales from 30 to 3,767; 3) lengthy referring expressions averaging 24.2 words; and 4) an extensive vocabulary comprising 22,813 unique words. We evaluate a total of 24 large models on Ref-L4 and provide valuable insights. The cleaned versions of RefCOCO, RefCOCO+, and RefCOCOg, as well as our Ref-L4 benchmark and evaluation code will be made available to the community."
    },
    {
        "title": "Multimodal Context-Aware Transformer with Visual Guidance for Automated 3D Annotation",
        "link_suffix": "/forum?id=Dkz8npDqAv",
        "link": "https://openreview.net/forum?id=Dkz8npDqAv",
        "pdf_link": "https://openreview.net/pdf?id=Dkz8npDqAv",
        "keywords": "3D point cloud, multimodal architecture, automatic annotation, LiDar",
        "abstract": "The laborious nature of manual point cloud labeling drives the growing interest in 3D auto-annotation. The challenge is amplified by the sparse and irregular distribution of point clouds. This leads to the under-performance of current autolabelers, particularly with hard-to-detect samples characterized by truncation, occlusion, or distance.\n  In response, we propose a multimodal context-aware transformer (MMCAT) that integrates 3D point cloud geometry with image-based semantic insights to improve 3D bounding box annotations through 2D visual guidance. Our approach utilizes visual hints from three perspectives to integrate the 2D and 3D dimensions.\n  Initially, we develop point and image encoders to align LiDAR and image data, establishing a unified semantic bridge between image visuals and point cloud geometry. Subsequently, our box encoder processes 2D box coordinates to improve accuracy in determining object positions and dimensions within 3D space. Finally, our multimodal encoders enhance feature interactions, improving point cloud interpretation and annotation accuracy, especially for challenging samples.\n  MMCAT lies in its strategic use of 2D visual prompts to bolster 3D representation and annotation processes. We validate MMCAT's efficacy through extensive experiments on the widely recognized KITTI and Waymo Open datasets, particularly highlighting its superior performance with hard samples."
    },
    {
        "title": "GenVidBench: A Challenging Benchmark for Detecting AI-Generated Video",
        "link_suffix": "/forum?id=I7UpqPmLN5",
        "link": "https://openreview.net/forum?id=I7UpqPmLN5",
        "pdf_link": "https://openreview.net/pdf?id=I7UpqPmLN5",
        "keywords": "AI-Generated Video Detection;  Dataset; Benchmark",
        "abstract": "The rapid advancement of video generation models has made it increasingly challenging to distinguish AI-generated videos from real ones. This issue underscores the urgent need for effective AI-generated video detectors to prevent the dissemination of false information through such videos. However, the development of high-performance generative video detectors is currently impeded by the lack of large-scale, high-quality datasets specifically designed for generative video detection. To this end, we introduce GenVidBench, a challenging AI-generated video detection dataset with several key advantages: 1) Cross Source and Cross Generator: The cross-generation source mitigates the interference of video content on the detection. The cross-generator ensures diversity in video attributes between the training and test sets, preventing them from being overly similar. 2) State-of-the-Art Video Generators: The dataset includes videos from 8 state-of-the-art AI video generators, ensuring that it covers the latest advancements in the field of video generation. 3) Rich Semantics: The videos in GenVidBench are analyzed from multiple dimensions and classified into various semantic categories based on their content. This classification ensures that the dataset is not only large but also diverse, aiding in the development of more generalized and effective detection models. We conduct a comprehensive evaluation of different advanced video generators and present a challenging setting. Additionally, we present rich experimental results including advanced video classification models as baselines. With the GenVidBench, researchers can efficiently develop and evaluate AI-generated video detection models."
    },
    {
        "title": "PaRa: Personalizing Text-to-Image Diffusion via Parameter Rank Reduction",
        "link_suffix": "/forum?id=KZgo2YQbhc",
        "link": "https://openreview.net/forum?id=KZgo2YQbhc",
        "pdf_link": "https://openreview.net/pdf?id=KZgo2YQbhc",
        "keywords": "Text-to-Image diffusion model, Diffusion model fine-tuning",
        "abstract": "Personalizing a large-scale pretrained Text-to-Image (T2I) diffusion model is chal-\nlenging as it typically struggles to make an appropriate trade-off between its training\ndata distribution and the target distribution, i.e., learning a novel concept with only a\nfew target images to achieve personalization (aligning with the personalized target)\nwhile preserving text editability (aligning with diverse text prompts). In this paper,\nwe propose PaRa, an effective and efficient Parameter Rank Reduction approach\nfor T2I model personalization by explicitly controlling the rank of the diffusion\nmodel parameters to restrict its initial diverse generation space into a small and\nwell-balanced target space. Our design is motivated by the fact that taming a T2I\nmodel toward a novel concept such as a specific art style implies a small generation\nspace. To this end, by reducing the rank of model parameters during finetuning, we\ncan effectively constrain the space of the denoising sampling trajectories towards\nthe target. With comprehensive experiments, we show that PaRa achieves great\nadvantages over existing finetuning approaches on single/multi-subject generation\nas well as single-image editing. Notably, compared to the prevailing fine-tuning\ntechnique LoRA, PaRa achieves better parameter efficiency (2\u00d7 fewer learnable\nparameters) and much better target image alignment."
    },
    {
        "title": "LiveXiv - A Multi-Modal live benchmark based on Arxiv papers content",
        "link_suffix": "/forum?id=SulRfnEVK4",
        "link": "https://openreview.net/forum?id=SulRfnEVK4",
        "pdf_link": "https://openreview.net/pdf?id=SulRfnEVK4",
        "keywords": "Multi-Modal Dataset, Visual Question-Answering, Efficient Evaluation",
        "abstract": "The large-scale training of multi-modal models on data scraped from the web has shown outstanding utility in infusing these models with the required world knowledge to perform effectively on multiple downstream tasks. However, one downside of scraping data from the web can be the potential sacrifice of the benchmarks on which the abilities of these models are often evaluated. To safeguard against test data contamination and to truly test the abilities of these foundation models we propose LiveXiv: A scalable evolving live benchmark based on scientific ArXiv papers. LiveXiv accesses domain-specific manuscripts at any given timestamp and proposes to automatically generate visual question-answer pairs (VQA). This is done without any human-in-the-loop, using the multi-modal content in the manuscripts, like graphs, charts, and tables. Moreover, we introduce an efficient evaluation approach that estimates the performance of all models on the evolving benchmark using evaluations of only a subset of models. This significantly reduces the overall evaluation cost. We benchmark multiple open and proprietary Large Multi-modal Models (LMMs) on the first version of our benchmark, showing its challenging nature and exposing the models\u2019 true abilities, avoiding contamination. Lastly, in our commitment to high quality, we\nhave collected and evaluated a manually verified subset. By comparing its overall results to our automatic annotations, we have found that the performance variance is indeed minimal (<2.5%). Our dataset is available online anonymously on HuggingFace."
    },
    {
        "title": "Adversarial Inverse Reward-Constraint Learning with Reward-Feasibility Contrast Prior Inspired by Animal Behaviour",
        "link_suffix": "/forum?id=eszQcR5F1e",
        "link": "https://openreview.net/forum?id=eszQcR5F1e",
        "pdf_link": "https://openreview.net/pdf?id=eszQcR5F1e",
        "keywords": "inverse reinforcement learning, inverse constraint inference, simultaneous reward-constraint inference, animal behaviour",
        "abstract": "The behaviour of natural and artificial agents is shaped by underlying reward systems, which signal rewards based on internal and external factors, driving reward-oriented actions. However, real-world scenarios often impose constraints that reward alone cannot capture. While existing inverse (constrained) reinforcement learning methods can recover either rewards or constraints from demonstrations, the simultaneous inference of both remains unexplored due to the complexity of inference and the lack of knowledge of their relationship. To address this gap, we propose a novel algorithm that simultaneously infers both rewards and constraints within an adversarial learning framework, where both are updated through a policy optimisation process guided by expert demonstrations. Crucial to this framework is the introduction of the \u201creward-feasibility contrast prior,\u201d a hypothesis that correlates rewards and constraints. It is inspired by patterns observed in animal behaviour (particularly meerkats), positing that states with high rewards nearby are more likely to be associated with weaker feasibility (stronger constraints).\nOur experiments on virtual robot control tasks with safety constraints and real-world animal behaviour data with spatio-temporal causal constraints validate our proposed framework's effectiveness and the reward-feasibility contrast prior hypothesis. The results show accurate recovery of rewards and constraints, reflected by strong alignment with expert demonstrations and a low rate of constraint violations. Additionally, the performance improvement by embedding this prior into other inverse constraint inference methods further confirms its general effectiveness."
    },
    {
        "title": "QCircuitNet: A Large-Scale Hierarchical Dataset for Quantum Algorithm Design",
        "link_suffix": "/forum?id=pz0EK4g6AN",
        "link": "https://openreview.net/forum?id=pz0EK4g6AN",
        "pdf_link": "https://openreview.net/pdf?id=pz0EK4g6AN",
        "keywords": "AI for science, quantum computing, quantum oracle construction, quantum algorithm design",
        "abstract": "Quantum computing is an emerging field recognized for the significant speedup it offers over classical computing through quantum algorithms. However, designing and implementing quantum algorithms pose challenges due to the complex nature of quantum mechanics and the necessity for precise control over quantum states. \nDespite the significant advancements in AI, there has been a lack of datasets specifically tailored for this purpose. \nIn this work, we introduce QCircuitNet, the first benchmark and test dataset designed to evaluate AI's capability in designing and implementing quantum algorithms in the form of quantum circuit codes. Unlike using AI for writing traditional codes, this task is fundamentally different and significantly more complicated due to highly flexible design space and intricate manipulation of qubits. \nOur key contributions include:A general framework which formulates the key features of quantum algorithm design task for Large Language Models.Implementation for a wide range of quantum algorithms from basic primitives to advanced applications, with easy extension to more quantum algorithms.Automatic validation and verification functions, allowing for iterative evaluation and interactive reasoning without human inspection.Promising potential as a training dataset through primitive fine-tuning results.We observed several interesting experimental phenomena: fine-tuning does not always outperform few-shot learning, and LLMs tend to exhibit consistent error patterns. QCircuitNet provides a comprehensive benchmark for AI-driven quantum algorithm design, offering advantages in model evaluation and improvement, while also revealing some limitations of LLMs in this domain."
    },
    {
        "title": "Concepts' Information Bottleneck Models",
        "link_suffix": "/forum?id=2xRTdzmQ6C",
        "link": "https://openreview.net/forum?id=2xRTdzmQ6C",
        "pdf_link": "https://openreview.net/pdf?id=2xRTdzmQ6C",
        "keywords": "Concept bottleneck models, Information bottleneck",
        "abstract": "Concept Bottleneck Models (CBMs) offer a self-explainable AI framework by predicting targets based on human-understandable concepts, but they often fail to achieve optimal performance and interpretability due to leakage of irrelevant information into the concept activations. This paper presents an information-theoretic enhancement of CBMs through the integration of the Information Bottleneck (IB) framework, aimed at addressing their issues of concept leakage and reduced performance. Our approach reshapes the way CBMs process and utilize concepts by constraining mutual information between input data and concepts, ensuring that only the most relevant information is preserved for decision-making. This introduces a new paradigm for CBMs that not only enhances performance but also enforces a tighter connection between latent representations and human-understandable concepts, ensuring a more robust and interpretable model. Our experiments on datasets such as CUB, AwA2, and aPY demonstrate that IB-augmented CBMs improve both concept and target prediction accuracy, while also increasing intervenability. Additionally, we propose a novel metric to assess the quality of concept sets based on intervention performance. Unlike traditional task performance metrics, which may obscure the effects of concept leakage, the new metric offers a direct, interpretable evaluation of concept set goodness."
    },
    {
        "title": "Chronicling Germany: An Annotated Historical Newspaper Dataset",
        "link_suffix": "/forum?id=wh6pilyz2L",
        "link": "https://openreview.net/forum?id=wh6pilyz2L",
        "pdf_link": "https://openreview.net/pdf?id=wh6pilyz2L",
        "keywords": "historic newspaper processing, digital history, computer vision",
        "abstract": "The correct detection of dense article layout and the recognition of characters in historical newspaper pages remains a challenging requirement for Natural Language Processing (NLP) and machine learning applications on historical newspapers in the field of digital history. Digital newspaper portals for historic Germany typically provide Optical Character Recognition (OCR) text, albeit of varying quality. Unfortunately, layout information is often missing, limiting this rich source\u2019s scope. Our dataset is designed to enable the training of layout and OCR modells for historic German-language newspapers. The Chronicling Germany dataset contains 693 annotated historical newspaper pages from the time period between 1852 and 1924. The paper presents a processing pipeline and establishes baseline results on in- and out-of-domain test data using this pipeline. Both our dataset and the corresponding baseline code are freely available online. This work creates a starting point for future research in the field of digital history and historic German language newspaper processing. Furthermore, it provides the opportunity to study a low-resource task in computer vision."
    },
    {
        "title": "Weighted-Rank Contrastive Regression for Robust Learning on Imbalance Social Media Popularity Prediction",
        "link_suffix": "/forum?id=adrPcTD2cz",
        "link": "https://openreview.net/forum?id=adrPcTD2cz",
        "pdf_link": "https://openreview.net/pdf?id=adrPcTD2cz",
        "keywords": "Social Media Popularity Prediction, Contrastive Learning, Imbalance Regression, Rank-N-Contrast, Social Media Prediction Dataset",
        "abstract": "Social Media Popularity Prediction (SMPP) is the task of forecasting the level of engagement a social media post will receive. It is crucial\nfor understanding audience engagement and enabling targeted marketing strategies. However, the inherent imbalance in real-world\nsocial media data, where certain popularity levels are underrepresented, poses a significant challenge. In this study, we leveraged the\nrecent success of contrastive learning and its growing integration into regression tasks by introducing a Weighted-Rank CR loss to\naddress the data imbalance challenges. Experiments on the Social Media Prediction Dataset demonstrated that our method outperformed\nthe vanilla approach and the current state-of-the-art contrastive regression approach Rank-N-Contrast."
    },
    {
        "title": "Graph Supervised Contrastive Learning for Geodemographics",
        "link_suffix": "/forum?id=OFWD0jgJ17",
        "link": "https://openreview.net/forum?id=OFWD0jgJ17",
        "pdf_link": "https://openreview.net/pdf?id=OFWD0jgJ17",
        "keywords": "Graph Neural Network, Geodemographics",
        "abstract": "Geodemographic analysis is essential for understanding population characteristics and addressing socio-economic disparities across regions. However, limited research has been conducted on modelling changes in demographic data over time using Graph Neural Networks (GNNs). In this study, we address this gap by leveraging GNNs to model correlations between the 2011 census data (England & Wales), observing changes over time, and the Output Area Classification 2021, which reflects socio-economic differences between Output Areas. We propose a novel framework that utilises Supervised Contrastive Learning on graphs to obtain robust OA embeddings, with a particular focus on improving the model\u2019s performance for minority classes. To evaluate the effectiveness of our framework, we conducted two downstream tasks based on the 2021 OA embeddings. Our results demonstrate that the proposed approach provides valuable insights for geodemographic analysis and offers policymakers a useful tool for assessing socio-economic transitions over time, and planning ahead on the basis of it."
    },
    {
        "title": "Variational Bayes Gaussian Splatting",
        "link_suffix": "/forum?id=pjfrGVekwK",
        "link": "https://openreview.net/forum?id=pjfrGVekwK",
        "pdf_link": "https://openreview.net/pdf?id=pjfrGVekwK",
        "keywords": "Variational Bayes, Gaussian Splatting, Continual Learning",
        "abstract": "Recently, 3D Gaussian Splatting has emerged as a promising approach for modeling 3D scenes using mixtures of Gaussians. The predominant optimization method for these models relies on backpropagating gradients through a differentiable rendering pipeline, which struggles with catastrophic forgetting when dealing with continuous streams of data. To address this limitation, we propose Variational Bayes Gaussian Splatting (VBGS), a novel approach that frames training a Gaussian splat as variational inference over model parameters. By leveraging the conjugacy properties of multivariate Gaussians, we derive a closed-form variational update rule, allowing efficient updates from partial, sequential observations without the need for replay buffers. Our experiments show that VBGS not only matches state-of-the-art performance on static datasets, but also enables continual learning from sequentially streamed 2D and 3D data, drastically improving performance in this setting."
    },
    {
        "title": "CTNet: A CNN-Transformer Hybrid Network for 6D Object Pose Estimation",
        "link_suffix": "/forum?id=JHoC430Nxi",
        "link": "https://openreview.net/forum?id=JHoC430Nxi",
        "pdf_link": "https://openreview.net/pdf?id=JHoC430Nxi",
        "keywords": "neural networks, 6D pose estimation, RGB-D image",
        "abstract": "Recent advances in 6D pose estimation primarily rely on CNNs, but they struggle to grasp long-range dependencies and the global context, which are essential for precise pose determination. Although deeper or expanded networks are commonly used to tackle this, they lead to significant computational burdens without fully addressing these constraints. To overcome these challenges, we present CTNet, a hybrid network that fuses the strengths of CNN and Transformer, aiming for accurate 6D pose estimation from a solitary RGB-D image. CTNet employs Transformer to capture elusive long-range dependencies and the global context, while lightweight CNNs adeptly extract detailed local features. This complementary approach offers a comprehensive feature representation, eliminating the necessity for excessively deep networks. To further bolster the CNNs' efficiency, we introduce the Hierarchical Feature Extractor (HFE), which enhances the C2f and ELAN modules for optimal feature extraction. Additionally, we integrate a CNN-based PointNet module, designed to extract vital spatial data from the point cloud. The Transformer element captures global contextual insights, which are then seamlessly integrated with the local and spatial features extracted by the CNNs to ensure precise 6D pose estimation. Experiments demonstrate that CTNet achieves high accuracy with nearly half the FLOPs of current methods on the LineMOD and YCB-Video datasets. Furthermore, the HFE is highly adaptable, showing excellent transferability across other 6D pose estimation architectures."
    },
    {
        "title": "Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency",
        "link_suffix": "/forum?id=i8dYPGdB1C",
        "link": "https://openreview.net/forum?id=i8dYPGdB1C",
        "pdf_link": "https://openreview.net/pdf?id=i8dYPGdB1C",
        "keywords": "Online Learning, Submodular Maximization, Surrogate Gradient, Multi-Agent",
        "abstract": "Coordinating multiple agents to collaboratively maximize submodular functions in unpredictable environments is a critical task with numerous applications in machine learning, robot planning and control. The existing approaches, such as the OSG algorithm,  are often hindered by their poor approximation guarantees and the rigid requirement for a fully connected communication graph. To address these challenges, we firstly present a $\\textbf{MA-OSMA}$ algorithm, which employs the multi-linear extension to transfer the discrete submodular maximization problem into a continuous optimization, thereby allowing us to reduce the strict dependence on a complete graph through consensus techniques. Moreover, $\\textbf{MA-OSMA}$ leverages a novel surrogate gradient to avoid sub-optimal stationary points. To eliminate the computationally intensive projection operations in $\\textbf{MA-OSMA}$, we also introduce a projection-free $\\textbf{MA-OSEA}$ algorithm skillfully harnessing the KL divergence by mixing a uniform distribution. Theoretically, we confirm that both algorithms achieve a regret bound of $\\widetilde{O}(\\sqrt{\\frac{C_{T}T}{1-\\beta}})$ against a\u00a0 $(\\frac{1-e^{-c}}{c})$-approximation to the best comparator in hindsight, where $C_{T}$ is the deviation of maximizer sequence, $\\beta$ is the spectral gap of the network and $c$ is the joint curvature of submodular objectives. This result significantly improves the $(\\frac{1}{1+c})$-approximation provided by the state-of-the-art OSG algorithm. Finally, we demonstrate the effectiveness of our proposed algorithms through simulation-based multi-target tracking."
    },
    {
        "title": "EfficientSkip: Efficiently Transforming Dense LLMs into Sparse Variants",
        "link_suffix": "/forum?id=7DY2DFDT0T",
        "link": "https://openreview.net/forum?id=7DY2DFDT0T",
        "pdf_link": "https://openreview.net/pdf?id=7DY2DFDT0T",
        "keywords": "efficient LLM, skip token, conditional computation",
        "abstract": "Transformer-based LLMs achieve great success on a variety of NLP tasks, including machine translation, text summarization, and text generation.\nHowever, it requires huge amount of computation and data to train such a powerful LLM.\nResearchers have proposed transformer-based conditional computation algorithms that significantly reduce redundant computations on certain tokens.\nBy skipping dense attention and feed forward computations, these approaches yield sparse LLMs.\nHowever, these sparse LLMs are trained from scratch, requiring substantial computation and data.\nTherefore in this paper, we proposed a training paradigm that can effectively transform a dense transformer-based LLM to its sparse variant with very limited computation resources and merely millions of tokens.\nWe conducted thorough investigations into the key factors that may influence the dense-to-sparse transformation through numerous empirical experiments.\nIn addition, we conducted a case study on the how the tokens skip layers and analyzed their Part-of-Speech tags, gaining valuable insights."
    },
    {
        "title": "Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models",
        "link_suffix": "/forum?id=VarjSNbij7",
        "link": "https://openreview.net/forum?id=VarjSNbij7",
        "pdf_link": "https://openreview.net/pdf?id=VarjSNbij7",
        "keywords": "Large Language Models, Quantization, Safety Alignment",
        "abstract": "Quantized large language models (LLMs) have garnered surging demand for broadening the deployment scenarios of LLMs, particularly on resource-constrained applications, which would otherwise be infeasible due to the substantial resource overhead incurred by astronomical model sizes. Propelled by this vast application potential, various quantization techniques have been developed to convert high-precision LLMs into low-precision quantized counterparts, aiming to preserve strong capabilities with reduced bit-widths. Despite achieving promising utility preservation after quantization, current efforts have largely neglected the safety aspect of quantized LLMs, leaving them at risk of engaging in harmful behaviors. Unfortunately, safety is fragile to preserve, as evidenced by recent safety studies on high-precision LLMs, further aggravating concerns about the safety of quantized LLMs. Assessing and restoring the safety capabilities of quantized LLMs has thus become a pressing need.In this paper, we conduct the first systematic assessment of safety risks in quantized LLMs, scrutinizing four mainstream categories of quantization techniques across diverse settings, including varying quantization bit-widths and different quantization-assisting datasets, through well-established safety measurements. Our empirical evaluation reveals concerning safety degradation across all quantization methods and settings. We therefore propose the first quantization-aware safety patching framework,  Q-resafe, to efficiently restore the safety capabilities of quantized LLMs while avoiding any adverse impact on the utility. Extensive experiments demonstrate that  Q-resafe effectively restores the safety of quantized LLMs obtained from diverse quantization processes, matching the pre-quantization LLMs, even with harmful datasets. We will make our implementation publicly availablehttps://anonymous.4open.science/r/Qresafe-D085/."
    },
    {
        "title": "DRAG: Data Reconstruction Attack using Guided Diffusion",
        "link_suffix": "/forum?id=jvmMqD57ZR",
        "link": "https://openreview.net/forum?id=jvmMqD57ZR",
        "pdf_link": "https://openreview.net/pdf?id=jvmMqD57ZR",
        "keywords": "Data Reconstruction Attack, Privacy, Diffusion Model",
        "abstract": "With the rise of large foundation models, split inference (SI) has emerged as a popular computational paradigm for deploying models across lightweight edge devices and cloud servers, addressing both data privacy and computational cost concerns. However, most existing data reconstruction attacks have focused on smaller classification models like ResNet, leaving the privacy risks of foundation models in SI settings largely unexplored. To address this gap, we propose a novel data reconstruction attack based on guided diffusion, which leverages the rich prior knowledge embedded in a latent diffusion model (LDM) pretrained on a large-scale dataset. Our method performs iterative reconstruction on the LDM\u2019s learned image manifold, effectively generating high-fidelity images closely resembling the original data from their intermediate representations (IR). Extensive experiments demonstrate that our approach significantly outperforms state-of-the-art methods, both qualitatively and quantitatively, in reconstructing data from deep-layer IRs of the vision foundation model. The results highlight the urgent need for more robust privacy protection mechanisms for large models in SI scenarios."
    },
    {
        "title": "CasualHDR: Robust High Dynamic Range 3D Gaussian Splatting from Casually Captured Videos",
        "link_suffix": "/forum?id=ZNKLD0fX59",
        "link": "https://openreview.net/forum?id=ZNKLD0fX59",
        "pdf_link": "https://openreview.net/pdf?id=ZNKLD0fX59",
        "keywords": "High Dynamic Range, 3D Reconstruction, Continous-time Trajectory, Radiance Field, Motion Blur",
        "abstract": "In recent years, thanks to innovations in 3D scene representation, novel view synthesis and photo-realistic dense 3D reconstruction from multi-view images, such as neural radiance field (NeRF) and 3D Gaussian Splatting (3DGS), have garnered widespread attention due to their superior performance. However, most works rely on low dynamic range (LDR) images and representations of scenes, which limits the capturing of richer scene details. Prior works have focused on high dynamic range (HDR) scene recovery, typically require repeatedly capturing of multiple sharp images with different exposure times at fixed camera positions, which is time-consuming and challenging in practice.For a more flexible data acquisition, we propose a one-stage method: \\textbf{CasualHDR} to easily and robustly recover the 3D HDR scene from casual videos with auto-exposure (AE) enabled, even in the presence of severe motion blur and varying exposure time. CasualHDR contains a unified differentiable physical imaging model which jointly optimize (i.e. bundle adjust) exposure time, camera response function (CRF), continuous-time camera motion trajectory on $\\mathbb{SE}(3)$, and the 3DGS-based HDR scene. Extensive experiments demonstrate that our approach outperforms existing reconstruction methods in terms of robustness and rendering quality. Three applications can be achieved after the 3DGS HDR scene reconstruction: novel-view synthesis, image deblurring (deblur input images) and HDR editing (adjust the exposure time thus brightness of the input images)."
    },
    {
        "title": "GRAMA: Adaptive Graph Autoregressive Moving Average Models",
        "link_suffix": "/forum?id=ZuOXuS7yDw",
        "link": "https://openreview.net/forum?id=ZuOXuS7yDw",
        "pdf_link": "https://openreview.net/pdf?id=ZuOXuS7yDw",
        "keywords": "Graph Neural Networks, Auto-regressive Moving Average, State Space Models",
        "abstract": "Graph State Space Models (SSMs) have recently been introduced to enhance Graph Neural Networks (GNNs) in modeling long-range interactions. Despite their success, existing methods either compromise on permutation equivariance or limit their focus to pairwise interactions rather than sequences. Building on the connection between Autoregressive Moving Average (ARMA)  and SSM, in this paper, we introduce GRAMA, a Graph Adaptive method based on a learnable Autoregressive Moving Average (ARMA) framework that addresses these limitations. By transforming from static to sequential graph data, GRAMA leverages the strengths of the ARMA framework, while preserving permutation equivariance. Moreover, GRAMA incorporates a selective attention mechanism for dynamic learning of ARMA coefficients, enabling efficient and flexible long-range information propagation. We also establish theoretical connections between GRAMA and Selective SSMs, providing insights into its ability to capture long-range dependencies. Extensive experiments on 14 synthetic and real-world datasets demonstrate that GRAMA consistently outperforms backbone models and performs competitively with state-of-the-art methods."
    },
    {
        "title": "Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer",
        "link_suffix": "/forum?id=emns7tgDOq",
        "link": "https://openreview.net/forum?id=emns7tgDOq",
        "pdf_link": "https://openreview.net/pdf?id=emns7tgDOq",
        "keywords": "reinforcement learning, decision transformer, causality",
        "abstract": "Decision Transformer (DT) plays a crucial role in modern reinforcement learning, leveraging offline datasets to achieve impressive results across various domains. However, DT requires high-quality, comprehensive data to perform optimally. In real-world applications, such ideal data is often lacking, with the underrepresentation of optimal behaviours posing a significant challenge. This limitation highlights the difficulty of relying on offline datasets for training, as suboptimal data can hinder performance. To address this, we propose the Counterfactual Reasoning Decision Transformer (CRDT), a novel framework inspired by counterfactual reasoning. CRDT enhances DT\u2019s ability to reason beyond known data by generating and utilizing counterfactual experiences, enabling improved decision-making in out-of-distribution scenarios. Extensive experiments across continuous and discrete action spaces, including environments with limited data, demonstrate that CRDT consistently outperforms conventional DT approaches. Additionally, reasoning counterfactually allows the DT agent to obtain stitching ability, allowing it to combine suboptimal trajectories. These results highlight the potential of counterfactual reasoning to enhance RL agents' performance and generalization capabilities."
    },
    {
        "title": "BALCONI: BALancing CONtext  and Internal Knowledge For Training Flexible LLMs",
        "link_suffix": "/forum?id=hPk92D2GJV",
        "link": "https://openreview.net/forum?id=hPk92D2GJV",
        "pdf_link": "https://openreview.net/pdf?id=hPk92D2GJV",
        "keywords": "Large Language Model, Faithfulness, Internal knowledge",
        "abstract": "The faithfulness to the context is significant for large language models (LLMs)  in tasks such as Retrieval-Augmented Generation (RAG) or Information Extraction. However, LLMs can exhibit a \"stubborn\" reliance on their internal knowledge, which leads to failure in maintaining faithfulness to the context. Ideally, a model should leverage the given context if the user instruction requires to, yet remain correctness based on internal knowledge when the instruction does not provide the context. Considering such scenarios, we propose a balanced benchmark, FaithfulBench, to evaluate the faithfulness of LLMs, together with internal knowledge correctness in LLMs and evaluate whether the improvement in faithfulness would affect internal knowledge. Extensive experiments show that LLMs  can be unfaithful to the context to some extent and in the Multi-choice QA, we observe an obvious negative correlation between faithfulness and internal knowledge correctness across different LLMs. Then based on the analysis of faithfulness enhancement methods, we find that instruction tuning using counterfactual data can significantly improve the model's context faithfulness, but compromise the model's internal knowledge. To address such a issue, we propose a straightforward yet effective approach BALCONI training  by training with mixup data of factual requests, context requests, and NoAns (I cannot tell the answer from the context) requests. Experiments on our benchmark and a context-based machine translation task demonstrate that BALCONI can achieve a well-balanced effect in improving the balanced faithfulness and internal knowledge."
    },
    {
        "title": "SEPARATE: A Simple Low-rank Projection for Gradient Compression in Modern Large-scale Model Training Process",
        "link_suffix": "/forum?id=8HuLgtjqOD",
        "link": "https://openreview.net/forum?id=8HuLgtjqOD",
        "pdf_link": "https://openreview.net/pdf?id=8HuLgtjqOD",
        "keywords": "efficient training, gradient compression",
        "abstract": "Training Large Language Models (LLMs) presents a significant communication bottleneck, predominantly due to the growing scale of the gradient to communicate across multi-device clusters. However, how to mitigate communication overhead in practice remains a formidable challenge due to the weakness of the methodology of the existing compression methods, especially the neglect of the characteristics of the gradient. In this paper, we consider and demonstrate the low-rank properties of gradient and Hessian observed in LLMs training dynamic, and take advantage of such natural properties to design SEPARATE, a simple low-rank projection for gradient compression in modern large-scale model training processes. SEPARATE realizes dimensional reduction by common random Gaussian variables and an improved moving average error-feedback technique. We theoretically demonstrate that SEPARATE-based optimizers maintain the original convergence rate for SGD and Adam-Type optimizers for general non-convex objectives. Experimental results show that SEPARATE accelerates training speed by up to 2\u00d7 for GPT-2-Medium pre-training, and improves performance on various benchmarks for LLAMA2-7B fine-tuning."
    },
    {
        "title": "RAQ-VAE: Rate-Adaptive Vector-Quantized Variational Autoencoder",
        "link_suffix": "/forum?id=iqqpx8hgSQ",
        "link": "https://openreview.net/forum?id=iqqpx8hgSQ",
        "pdf_link": "https://openreview.net/pdf?id=iqqpx8hgSQ",
        "keywords": "Discrete representation learning, Vector-quantized variational autoencoder, Generative model, Sequence-to-sequence",
        "abstract": "Vector Quantized Variational AutoEncoder (VQ-VAE) is an established technique in machine learning for learning discrete representations across various modalities. However, its scalability and applicability are limited by the need to retrain the model to adjust the codebook for different rate requirements or encoding efficiency. We introduce the Rate-Adaptive VQ-VAE ($\\textbf{RAQ-VAE}$) framework, which addresses this challenge with two novel discrete (codebook) representation methods: a model-based approach using a clustering technique for existing pre-trained VQ-VAE models, and a data-driven approach utilizing a sequence-to-sequence (Seq2Seq) model for variable-rate codebook generation. Our experiments demonstrate that RAQ-VAE achieves effective reconstruction performance across multiple rates, often outperforming conventional fixed-rate VQ-VAE models. This work enhances the adaptability and performance of VQ-VAEs, with broad applications in data reconstruction, generation, and computer vision tasks."
    },
    {
        "title": "Object-Based Sub-Environment Recognition",
        "link_suffix": "/forum?id=BUEQlOwGMY",
        "link": "https://openreview.net/forum?id=BUEQlOwGMY",
        "pdf_link": "https://openreview.net/pdf?id=BUEQlOwGMY",
        "keywords": "metric learning, environment recognition, bayesian inference, self-supervised learning",
        "abstract": "Real-world agents, such as robots, are advancing beyond laboratory settings into the open-world environments driven by developments in AI technologies. Since these environments are complex and dynamic, empirical recognition of sub-environments that form the entire environment is essential. Through sub-environment recognition, the agent can 1) retrieve relevant sub-environments for a query, 2) track changes in its circumstances over time and space, and 3) identify similarities between different sub-environments while solving its tasks. To this end, we propose the Object-Based Sub-Environment Recognition (OBSER) framework, a novel Bayesian framework for measuring object-environment and environment-environment relationships using a feature extractor trained with metric learning. We first design the ($\\epsilon,\\delta$) Statistically Separable (EDS) function which indicates the robustness of trained representations and shows both theoretically and empirically that the optimized feature extractor can guarantee the accuracy of the proposed measures. We validate the efficacy of the OBSER framework in various environments, such as a Minecraft environment and an artificial environment with the ImageNet dataset. The result highlights the framework's strong generalization and accurate inference to recognize real-world environments."
    }
]
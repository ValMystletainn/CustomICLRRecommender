[
    {
        "title": "Quantifying Emergence in Neural Networks: Insights from Pruning and Training Dynamics",
        "link_suffix": "/forum?id=gInIbukM0R",
        "link": "https://openreview.net/forum?id=gInIbukM0R",
        "pdf_link": "https://openreview.net/pdf?id=gInIbukM0R",
        "keywords": "Emergence, training dynamics, pruning, landscape",
        "abstract": "Emergence, where complex behaviors develop from the interactions of simpler components within a network, plays a crucial role in enhancing neural network capabilities. We introduce a quantitative framework to measure emergence as structural nonlinearity, study the dynamics of this measure during the training process, and examine its impact on network performance, particularly in relation to pruning and training dynamics. Our hypothesis posits that the degree of emergence\u2014evaluated from the distribution and connectivity of active nodes\u2014can predict the development of emergent behaviors in the network. We demonstrate that higher emergence correlates with improved trianing performance. We further explore the relationship between network complexity and the loss landscape, suggesting that higher emergence indicates a greater concentration of local minima and a more rugged loss landscape. We show that this framework can be applied to explain the impact of pruning on the training dynamics. These findings provide new insights into the interplay between emergence, complexity, and performance in neural networks, offering implications for designing and optimizing architectures."
    },
    {
        "title": "RDHNet: Addressing Rotational and Permutational Symmetries in Continuous Multi-Agent Systems",
        "link_suffix": "/forum?id=vszlHtUvSR",
        "link": "https://openreview.net/forum?id=vszlHtUvSR",
        "pdf_link": "https://openreview.net/pdf?id=vszlHtUvSR",
        "keywords": "Multi-agent, Reinforcement Learning, Symmetry",
        "abstract": "Symmetry is prevalent in multi-agent systems. The presence of symmetry, coupled with the misuse of absolute coordinate systems, often leads to a large amount of redundant representation space, significantly increasing the search space for learning policies and reducing learning efficiency. Effectively utilizing symmetry and extracting symmetry-invariant representations can significantly enhance multi-agent systems' learning efficiency and overall performance by compressing the model's hypothesis space and improving sample efficiency. The issue of rotational symmetry in multi-agent reinforcement learning has received little attention in previous research and is the primary focus of this paper. To address this issue, we propose a rotation-invariant network architecture for continuous action space tasks. This architecture utilizes relative coordinates between agents, eliminating dependence on absolute coordinate systems, and employs a hypernetwork to enhance the model's fitting capability, enabling it to model MDPs with more complex dynamics. It can be used for both predicting actions and evaluating action values/utilities. In benchmark tasks, experimental results validate the impact of rotational symmetry on multi-agent decision systems and demonstrate the effectiveness of our method."
    },
    {
        "title": "GeNIe: Generative Hard Negative Images Through Diffusion",
        "link_suffix": "/forum?id=dd0rUW29tQ",
        "link": "https://openreview.net/forum?id=dd0rUW29tQ",
        "pdf_link": "https://openreview.net/pdf?id=dd0rUW29tQ",
        "keywords": "Data Augmentation;Diffusion Models; Computer Vision; Few-shot Learning; Long-tail Classification;",
        "abstract": "Data augmentation is crucial in training deep models, preventing them from overfitting to limited data. Recent advances in generative AI, e.g., diffusion models, have enabled more sophisticated augmentation techniques that produce data resembling natural images. We introduce GeNIe a novel augmentation method which leverages a latent diffusion model conditioned on a text prompt to combine two contrasting data points (an image from the source category and a text prompt from the target category) to generate challenging augmentations. To achieve this, we adjust the noise level (equivalently, number of diffusion iterations) to ensure the generated image retains low-level and background features from the source image while representing the target category, resulting in a hard negative sample for the source category. We further automate and enhance GeNIe by adaptively adjusting the noise level selection on a per image basis (coined as GeNIe-Ada), leading to further performance improvements. Our extensive experiments, in both few-shot and long-tail distribution settings, demonstrate the effectiveness of our novel augmentation method and its superior performance over the prior art."
    },
    {
        "title": "UniCoTT: A Unified Framework for Structural Chain-of-Thought Distillation",
        "link_suffix": "/forum?id=3baOKeI2EU",
        "link": "https://openreview.net/forum?id=3baOKeI2EU",
        "pdf_link": "https://openreview.net/pdf?id=3baOKeI2EU",
        "keywords": "Chain-of-Thought; Structural Thought; Distillation; Unified Framework",
        "abstract": "Chains of thought (CoTs) have achieved success in enhancing the reasoning capabilities of large language models (LLMs), while their effectiveness is predominantly observed in LLMs. \n    Existing solutions methods adopt distillation to inject chain-of-thought capabilities into small models (SLMs).\n    However, they: \n    (1) can not guarantee the rationality of the generated explanation due to hallucinations; \n    (2) ignore diverse structures of CoT during knowledge transfer.\n    In this paper, we propose a unified CoT distillation framework termed UniCoTT for considering diverse structural CoTs (\\emph{i.e.}, chain, tree, and graph).\n    UniCoTT contains two core strategies: iterative construction for structured CoTs and the structural constraint strategy.\n    Specifically, UniCoTT prompts LLMs to iteratively produce accurate explanations with answers and unifies structured explanations as UniCoT which is seen as a bridge for knowledge transfer.\n    Furthermore, UniCoTT utilizes the proposed unified supervised learning and structural consistency learning strategies to transfer knowledge of structured CoT to SLMs. \n    Experimental results show that UniCoTT can significantly improve the performance of SLMs on multiple datasets across different NLP tasks.Our code is available in our supplementary materials."
    },
    {
        "title": "Towards Stable Learning in Predictive Coding Networks",
        "link_suffix": "/forum?id=FwdN0KovFp",
        "link": "https://openreview.net/forum?id=FwdN0KovFp",
        "pdf_link": "https://openreview.net/pdf?id=FwdN0KovFp",
        "keywords": "Neuroscience, Predictive Coding, Predictive Coding Networks, Neural Networks",
        "abstract": "Predictive coding (PC) offers a biologically plausible model of cortical functions, encompassing processes such as learning, prediction, encoding, and memory. However, predictive coding networks (PCNs) face significant challenges in stability and scalability, which constrain our capacity to elucidate cortical computation. Our study identifies instability in PCNs as a fundamental issue, focusing on the exponential growth of latent state norms and prediction errors after inference. These dynamics lead to exploding and vanishing gradients in PCNs. Moreover, the concentration of prediction errors near the input and output layer impedes effective learning, exacerbating performance degradation as network depth increases. To address these limitations, we propose stabilizing techniques for PCNs, including length regularization and sequential training with skip connection modules. This approach counteracts the exponential growth of latent states and makes the distribution of prediction errors more uniform across layers. Empirical evaluations demonstrate that our approach enhances stability and generalization, enabling the training of deeper networks more efficiently. This study deepens our understanding of complex dynamics in cortical networks, thereby advancing the practical application of predictive coding theory to its full potential."
    },
    {
        "title": "Neural Fluid Simulation on Geometric Surfaces",
        "link_suffix": "/forum?id=58lbAsXCoZ",
        "link": "https://openreview.net/forum?id=58lbAsXCoZ",
        "pdf_link": "https://openreview.net/pdf?id=58lbAsXCoZ",
        "keywords": "Fluid simulation, Implicit Neural Representation, Exterior Calculus",
        "abstract": "Incompressible Euler fluid on the surface is an interesting research area in the fluid simulation, which is the fundamental building block in visual effects, design of liquid crystal films, scientific analyses of atmospheric and oceanic phenomena, etc. The task brings two key challenges: the extension of the physical laws on 3D surfaces and the preservation of the energy and volume. Traditional methods rely on grids or meshes for spatial discretization, which leads to high memory consumption and a lack of robustness and adaptivity for various mesh qualities and representations. Many implicit representations based simulators like INSR are proposed for the storage efficiency and continuity, but they face challenges in the surface simulation and the energy dissipation. We contribute a neural physical simulation framework on the surface with the implicit neural representation. Our method constructs a parameterized vector field with the exterior calculus and Closest Point Method on the surfaces, which guarantees the divergence-free property and enables the simulation on different surface representations (e.g. implicit neural represented surfaces). We further adopt a corresponding covariant derivative based advection process for surface flow dynamics and energy preservation. Our method shows higher accuracy, flexibility and memory-efficiency in the simulations of various surfaces with low energy dissipation. Numerical studies also highlight the potential of our framework across different practical applications such as vorticity shape generation and vector field Helmholtz decomposition."
    },
    {
        "title": "RandLoRA: Full rank parameter-efficient fine-tuning of large models",
        "link_suffix": "/forum?id=Hn5eoTunHN",
        "link": "https://openreview.net/forum?id=Hn5eoTunHN",
        "pdf_link": "https://openreview.net/pdf?id=Hn5eoTunHN",
        "keywords": "parameter-efficient; finetuning; CLIP; vision-language; full rank;",
        "abstract": "Low-Rank Adaptation (LoRA) and its variants have shown impressive results in reducing the number of trainable parameters and memory requirements of large transformer networks while maintaining fine-tuning performance. \nHowever, the low-rank nature of the weight update inherently limits the representation power of the fine-tuned model, potentially compromising performance on complex tasks.\nThis raises a critical question: when a performance gap between LoRA and standard fine-tuning is observed, is it due to the reduced number of trainable parameters or the rank deficiency?\nThis paper aims to answer this question by introducing RandLoRA, a parameter-efficient method that performs full-rank updates using a learned linear combinations of low-rank, non-trainable random matrices. Our method limits the number of trainable parameters by restricting optimization to diagonal scaling matrices applied to the fixed random matrices. This allows us to effectively overcome low-rank limitations while maintaining low parameter count and memory usage during training.\nThrough extensive experimentation across vision, language, and vision-language benchmarks, we systematically evaluate the limitations of LoRA and existing random basis methods.\nOur findings reveal that full-rank updates are beneficial across vision and language tasks separately, but especially so for vision-language tasks, where RandLoRA significantly reduces---and sometimes eliminates---the performance gap between standard fine-tuning and LoRA, demonstrating its efficacy."
    },
    {
        "title": "Defensive Prompt Patch: A Robust and Generalizable Defense of Large Language Models against Jailbreak Attacks",
        "link_suffix": "/forum?id=wetJo6xXb1",
        "link": "https://openreview.net/forum?id=wetJo6xXb1",
        "pdf_link": "https://openreview.net/pdf?id=wetJo6xXb1",
        "keywords": "NLP, AI Safety, Adversarial Jailbreaking, Jailbreak Defense",
        "abstract": "Safety, security, and compliance are essential requirements when aligning large language models (LLMs). However, many seemingly aligned LLMs are soon shown to be susceptible to jailbreak attacks. These attacks aim to circumvent the models' safety guardrails and security mechanisms by introducing jailbreak prompts into malicious queries. In response to these challenges, this paper introduces \\textbf{Defensive Prompt Patch} (DPP), a novel prompt-based defense mechanism specifically designed to protect LLMs against such sophisticated jailbreak strategies. Unlike previous approaches, which have often compromised the utility of the model for the sake of safety, DPP is designed to achieve a minimal Attack Success Rate (ASR) while preserving the high utility of LLMs. Our method uses strategically designed suffix prompts that effectively thwart a wide range of standard and adaptive jailbreak techniques. Empirical results conducted on Llama-2-7B-Chat and Mistral-7B-Instruct-v0.2  demonstrate the robustness and adaptability of DPP, showing significant reductions in ASR with negligible impact on utility. Our approach not only outperforms existing defense strategies in balancing safety and functionality, but also provides a scalable and robust solution to various LLM platforms."
    },
    {
        "title": "Data Interpreter: An LLM Agent For Data Science",
        "link_suffix": "/forum?id=aYwHiDkAdI",
        "link": "https://openreview.net/forum?id=aYwHiDkAdI",
        "pdf_link": "https://openreview.net/pdf?id=aYwHiDkAdI",
        "keywords": "Interactive Agent, Large Language Models, Dynamic Planning, AI for Data Science",
        "abstract": "Large Language Model (LLM)-based agents have shown effectiveness across many\napplications. However, their use in data science scenarios requiring solving long-\nterm interconnected tasks, dynamic data adjustments and domain expertise remains\nchallenging. Previous approaches primarily focus on individual tasks, making it\ndifficult to assess the complete data science workflow. Moreover, they struggle\nto handle real-time changes in intermediate data and fail to adapt dynamically\nto evolving task dependencies inherent to data science problems. In this paper,\nwe present Data Interpreter, an LLM-based agent designed to automatically\nsolve various data science problems end-to-end. Our Data Interpreter incorporates\ntwo key modules: 1) Hierarchical Graph Modeling, which breaks down complex\nproblems into manageable subproblems, enabling dynamic node generation and\ngraph optimization; and 2) Programmable Node Generation, a technique that\nrefines and verifies each subproblem to iteratively improve code generation results\nand robustness. Extensive experiments consistently demonstrate the superiority of\nData Interpreter. On InfiAgent-DABench, it achieves a 25% performance boost,\nraising accuracy from 75.9% to 94.9%. For machine learning and open-ended tasks,\nit improves performance from 88% to 95%, and from 60% to 97%, respectively.\nMoreover, on the MATH dataset, Data Interpreter achieves remarkable performance\nwith a 26% improvement compared to state-of-the-art baselines. Code will be open-\nsourced upon publication"
    },
    {
        "title": "Voila: Evaluation of MLLMs For Perceptual Understanding and Analogical Reasoning",
        "link_suffix": "/forum?id=q5MUMlHxpd",
        "link": "https://openreview.net/forum?id=q5MUMlHxpd",
        "pdf_link": "https://openreview.net/pdf?id=q5MUMlHxpd",
        "keywords": "abstract reasoning, relational reasoning, perceptual understanding, MLLMs, visual analogy",
        "abstract": "Multimodal Large Language Models (MLLMs) have become a powerful tool for\nintegrating visual and textual information. Despite their exceptional performance\non visual understanding benchmarks, measuring their ability to reason abstractly\nacross multiple images remains a significant challenge. To address this, we introduce VOILA , a large-scale, open-ended, dynamic benchmark designed to evaluate MLLMs\u2019 perceptual understanding and abstract relational reasoning. VOILA\nemploys an analogical mapping approach in the visual domain, requiring models\nto generate an image that completes an analogy between two given image pairs,\nreference and application, without relying on predefined choices. Our experiments demonstrate that VOILA presents MLLMs with demanding relational reasoning tasks. Through multi-step analysis, we reveal that current MLLMs struggle\nto comprehend inter-image relationships and exhibit limited capabilities in highlevel relational reasoning. Notably, we observe that performance improves when\nusing least-to-most prompting strategies. Comprehensive evaluations on opensource models and GPT-4o show that while the MolmoE-8B model achieves a\nstate-of-the-art performance of 34% and 19% at finding the text-based answer to\nthe questions on easy and hard scenarios, human performance consistently remains significantly higher at 70% on both difficulty scenarios."
    },
    {
        "title": "Learning local equivariant representations for quantum operators",
        "link_suffix": "/forum?id=kpq3IIjUD3",
        "link": "https://openreview.net/forum?id=kpq3IIjUD3",
        "pdf_link": "https://openreview.net/pdf?id=kpq3IIjUD3",
        "keywords": "Density Functional Theory, Local Graph Neural Network, Equivariant Neural Network",
        "abstract": "Predicting quantum operator matrices such as Hamiltonian, overlap, and density matrices in the density functional theory (DFT) framework is crucial for understanding material properties. Current methods often focus on individual operators and struggle with efficiency and scalability for large systems. Here we introduce a novel deep learning model, SLEM (strictly localized equivariant message-passing) for predicting multiple quantum operators, that achieves state-of-the-art accuracy while dramatically improving computational efficiency. SLEM's key innovation is its strict locality-based design, constructing local, equivariant representations for quantum tensors while preserving physical symmetries. This enables complex many-body dependence without expanding the effective receptive field, leading to superior data efficiency and transferability. Using an innovative SO(2) convolution technique, SLEM reduces the computational complexity of high-order tensor products and is therefore capable of handling systems requiring the $f$ and $g$ orbitals in their basis sets. We demonstrate SLEM's capabilities across diverse 2D and 3D materials, achieving high accuracy even with limited training data. SLEM's design facilitates efficient parallelization, potentially extending DFT simulations to systems with device-level sizes, opening new possibilities for large-scale quantum simulations and high-throughput materials discovery."
    },
    {
        "title": "Continual Task Learning through Adaptive Policy Self-Composition",
        "link_suffix": "/forum?id=upV91V0Big",
        "link": "https://openreview.net/forum?id=upV91V0Big",
        "pdf_link": "https://openreview.net/pdf?id=upV91V0Big",
        "keywords": "continual learning, offline reinforcement learning",
        "abstract": "Training a generalizable agent to continually learn a sequence of tasks from offline trajectories is a natural requirement for long-lived agents, yet remains a significant challenge for current offline reinforcement learning (RL) algorithms. Specifically, an agent must be able to rapidly adapt to new tasks using newly collected trajectories (plasticity), while retaining knowledge from previously learned tasks (stability). \nHowever, systematic analyses of this setting are scarce, and it remains unclear whether conventional continual learning (CL) methods are effective in continual offline RL (CORL) scenarios. In this study, we develop the Offline Continual World benchmark and demonstrate that traditional CL methods struggle with catastrophic forgetting, primarily due to the unique distribution shifts inherent to CORL scenarios.\nTo address this challenge, we introduce CompoFormer, a structure-based continual transformer model that adaptively composes previous policies via a meta-policy network. Upon encountering a new task, CompoFormer leverages semantic correlations to selectively integrate relevant prior policies alongside newly trained parameters, thereby enhancing knowledge sharing and accelerating the learning process.\nOur experiments reveal that CompoFormer outperforms conventional CL methods, particularly in longer task sequences, showcasing a promising balance between plasticity and stability."
    },
    {
        "title": "Hiding Images in Diffusion Models by Editing Learned Score Functions",
        "link_suffix": "/forum?id=kRJNV8RCE3",
        "link": "https://openreview.net/forum?id=kRJNV8RCE3",
        "pdf_link": "https://openreview.net/pdf?id=kRJNV8RCE3",
        "keywords": "data hiding, steganography, diffusion models",
        "abstract": "Hiding data in deep neural networks (DNNs) has achieved remarkable successes, including both discriminative and generative models. Yet, the potential for hiding images in diffusion models remains underdeveloped. Existing approaches fall short in extracting fidelity, secrecy, and efficiency. In particular, the intensive computational demands of the hiding process, coupled with the slow extraction due to multiple denoising stages, make these methods impractical for resource-limited environments.\nTo address these challenges, we propose hiding images at a specific denoising stage in diffusion models by modifying the learned score functions. We also introduce a parameter-efficient fine-tuning (PEFT) approach that combines parameter selection with a variant of low-rank adaptation (LoRA)  to boost secrecy and hiding efficiency.\nComprehensive experiments demonstrate the effectiveness of our proposed method."
    },
    {
        "title": "One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments",
        "link_suffix": "/forum?id=RdG7LVGnQi",
        "link": "https://openreview.net/forum?id=RdG7LVGnQi",
        "pdf_link": "https://openreview.net/pdf?id=RdG7LVGnQi",
        "keywords": "Large Language Models, Quantization, LoRA, Instruct Fine-tuning, One-Shot Training",
        "abstract": "Large Language Models (LLMs) have advanced rapidly but face significant memory demands. While quantization has shown promise for LLMs, current methods typically require lengthy training to alleviate the performance degradation from quantization loss. However, deploying LLMs across diverse scenarios with different resource constraints, e.g., servers and personal computers, requires repeated training per application, which amplifies the lengthy training problem. Given that, it is advantageous to train a once-for-all (OFA) supernet capable of yielding diverse optimal subnets for downstream applications through one-shot training. Nonetheless, the scale of current language models impedes efficiency and amplifies interference from weight sharing between subnets. We make an initial attempt to extend the once-for-all framework to large language models. Specifically, we decouple shared weights to eliminate the interference and incorporate Low-Rank adapters for training efficiency.\nFurthermore, we observe the imbalance allocation of training resources from the traditional uniform sampling. A non-parametric scheduler is introduced to adjust the sampling rate for each quantization configuration, achieving a more balanced allocation among subnets with varying demands. We validate the approach on LLaMA2 families and Mistral on downstream evaluation, demonstrating high performance while significantly reducing deployment time faced with multiple scenarios."
    },
    {
        "title": "Out-of-Distribution Detection in Class Incremental Learning",
        "link_suffix": "/forum?id=aUH0XrFhiX",
        "link": "https://openreview.net/forum?id=aUH0XrFhiX",
        "pdf_link": "https://openreview.net/pdf?id=aUH0XrFhiX",
        "keywords": "Out-of-Distribution Detection, Class Incremental Learning",
        "abstract": "Class incremental learning (CIL) aims to learn a model that can not only incrementally accommodate new classes, but also maintain the learned knowledge of old classes. Out-of-distribution (OOD) detection in CIL is to retain this incremental learning ability, while being able to reject unknown samples that are drawn from different distributions of the learned classes. This capability is crucial to the safety of deploying CIL models in open worlds.However, despite remarkable advancements in the respective CIL and OOD detection, there lacks a systematic and large-scale benchmark to assess the capability of advanced CIL models in detecting OOD samples. To fill this gap, in this study we design a comprehensive empirical study to establish such a benchmark, namedOpenCIL, offering a unified protocol for enabling CIL models with different OOD detectors using two principled OOD detection frameworks. One key observation we find through our comprehensive evaluation is that the CIL models can be severely biased towards the OOD samples and newly added classes when they are exposed to open environments. Motivated by this, we further propose a novel approach for OOD detection in CIL, namely Bi-directional Energy Regularization (BER), which is specially designed to mitigate these two biases in different CIL models by having energy regularization on both old and new classes. Extensive experiments show that BER can substantially improve the OOD detection capability across a range of CIL models, achieving state-of-the-art performance on the OpenCIL benchmark."
    },
    {
        "title": "MamBEV: Enabling State Space Models to Learn Birds-Eye-View Representations",
        "link_suffix": "/forum?id=MvEkN2ejZ1",
        "link": "https://openreview.net/forum?id=MvEkN2ejZ1",
        "pdf_link": "https://openreview.net/pdf?id=MvEkN2ejZ1",
        "keywords": "BEV, Bird\u2019s Eye View, State space model, causal attention, 3d computer vision",
        "abstract": "3D visual perception tasks, such as 3D detection from multi-camera images, are essential components of autonomous driving and assistance systems. However, designing computationally efficient methods remains a significant challenge. In this paper, we propose a Mamba-based framework called MamBEV, which learns unified Bird's Eye View (BEV) representations using linear spatio-temporal SSM-based attention. This approach supports multiple 3D perception tasks with significantly improved computational and memory efficiency. Furthermore, we introduce SSM based cross-attention, analogous to standard cross attention, where BEV query representations can interact with relevant image features. Extensive experiments demonstrate MamBEV's promising performance across diverse visual perception metrics, highlighting its advantages in input scaling efficiency compared to existing benchmark models."
    },
    {
        "title": "On the Inflation of KNN-Shapley Value",
        "link_suffix": "/forum?id=EXXvBdFJ6I",
        "link": "https://openreview.net/forum?id=EXXvBdFJ6I",
        "pdf_link": "https://openreview.net/pdf?id=EXXvBdFJ6I",
        "keywords": "Shapley Value, Data Valuation, KNN",
        "abstract": "Shapley value-based data valuation methods, originating from cooperative game theory, quantify the usefulness of each individual sample by considering its contribution to all possible training subsets. Despite their extensive applications, we observe these methods encounter value inflation\u2014while samples with negative Shapley values are detrimental, some with positive values can also be harmful. This challenge prompts two fundamental questions: the suitability of zero as a threshold for distinguishing detrimental from beneficial samples and the determination of an appropriate threshold. To address these questions, we focus on KNN-Shapley and propose Calibrated KNN-Shapley (CKNN-Shapley), a semi-value method that calibrates zero as the threshold to distinguish detrimental samples from beneficial ones by mitigating the negative effects of small-sized training subsets. Through extensive experiments, we demonstrate the effectiveness of CKNN-Shapley in alleviating data valuation inflation, detecting detrimental samples, and assessing data quality. We also extend our approach beyond conventional classification settings, applying it to diverse and practical scenarios such as learning with mislabeled data, online learning with stream data, and active learning for label annotation."
    },
    {
        "title": "RainbowPO: A Unified Framework for Combining Improvements in Preference Optimization",
        "link_suffix": "/forum?id=trKee5pIFv",
        "link": "https://openreview.net/forum?id=trKee5pIFv",
        "pdf_link": "https://openreview.net/pdf?id=trKee5pIFv",
        "keywords": "Alignment, Preference Optimization, Reinforcement Learning from Human Feedback",
        "abstract": "Recently, numerous preference optimization algorithms have been introduced as extensions to the Direct Preference Optimization (DPO) family. While these methods have successfully aligned models with human preferences, there is a lack of understanding regarding the contributions of their additional components. Moreover, fair and consistent comparisons are scarce, making it difficult to discern which components genuinely enhance downstream performance. In this work, we propose RainbowPO, a unified framework that demystifies the effectiveness of existing DPO methods by categorizing their key components into seven broad directions. We integrate these components into a single cohesive objective, enhancing the performance of each individual element. Through extensive experiments, we demonstrate that RainbowPO outperforms existing DPO variants. Additionally, we provide insights to guide researchers in developing new DPO methods and assist practitioners in their implementations."
    },
    {
        "title": "Binary Hypothesis Testing for Softmax Models and Leverage Score Models",
        "link_suffix": "/forum?id=pq3RANvCZC",
        "link": "https://openreview.net/forum?id=pq3RANvCZC",
        "pdf_link": "https://openreview.net/pdf?id=pq3RANvCZC",
        "keywords": "Binary hypothesis testing, softmax distributions, large language models, attention",
        "abstract": "Softmax distributions are widely used in machine learning, including Large Language Models (LLMs) where the attention unit uses softmax distributions. We abstract the attention unit as the softmax model, where given a vector input, the model produces an output drawn from the softmax distribution (which depends on the vector input). We consider the fundamental problem of binary hypothesis testing in the setting of softmax models. That is, given an unknown softmax model, which is known to be one of the two given softmax models, how many queries are needed to determine which one is the truth? We show that the sample complexity is asymptotically $O(\\epsilon^{-2})$ where $\\epsilon$ is a certain distance between the parameters of the models.Furthermore, we draw analogy between the softmax model and the leverage score model, an important tool for algorithm design in linear algebra and graph theory. The leverage score model, on a high level, is a model which, given vector input, produces an output drawn from a distribution dependent on the input. We obtain similar results for the binary hypothesis testing problem for leverage score models."
    },
    {
        "title": "Enhancing Deep Symbolic Regression via Reasoning Equivalent Expressions",
        "link_suffix": "/forum?id=2CQa1VgO52",
        "link": "https://openreview.net/forum?id=2CQa1VgO52",
        "pdf_link": "https://openreview.net/pdf?id=2CQa1VgO52",
        "keywords": "symbolic regression, deep reinforcement learning, symbolic reasoning",
        "abstract": "Symbolic regression seeks to uncover physical knowledge from experimental data. Recently a line of work on deep reinforcement learning (DRL) formulated the search for optimal expressions as a sequential decision-making problem. However, training these models is challenging due to the inherent instability of the policy gradient estimator.\nWe observe that many numerically equivalent yet symbolically distinct expressions exist, such as $\\log(x_1^2 x_2^3)$ and $2\\log(x_1) + 3\\log(x_2)$. \nBuilding on this, we propose Deep Symbolic Regression via Reasoning Equivalent eXpressions (DSR-Rex). The high-level idea is to enhance policy gradient estimation by leveraging both expressions sampled from the DRL and their numerically identical counterparts generated via an expression reasoning module. \nOur DSR-Rex (1) embeds mathematical laws and equalities into the deep model, (2) reduces gradient estimator variance with theoretical justification and (3) encourages RL exploration of different symbolic forms in the search space of all expressions.\nIn our experiments, DSR-Rex is evaluated on several challenging scientific datasets, demonstrating superior performance in discovering equations with lower Normalized MSE scores. Additionally, DSR-Rex computes gradients with smaller empirical standard deviation, compared to the previous DSR method."
    },
    {
        "title": "Generalizable Dynamic Radiance Field in Egocentric View",
        "link_suffix": "/forum?id=oegbNuUrXV",
        "link": "https://openreview.net/forum?id=oegbNuUrXV",
        "pdf_link": "https://openreview.net/pdf?id=oegbNuUrXV",
        "keywords": "generalized dynamic view synthesis, NeRF, computer vision",
        "abstract": "We present a novel framework for generalizable dynamic radiance field in first-person view. Our approach can predict the neural representation of physical world conditioned on a sequence of egocentric observations without test-time training. To this end, we propose a data-driven algorithm that updates an explicit 3D representation by aggregating features from given videos and the 3D representation itself in an implicit 4D-aware mechanism. Specifically, we use a contracted triplane as the 3D representation, propose a 4D-aware transformer module to aggregate features and introduce a temporal-based 3D constraint to achieve better multiview consistency. We train the proposed model with large-scale diverse videos in self-supervised manner. We demonstrate the effectiveness of our approach by showing top results in novel view synthesis on dynamic scene datasets. Besides, we also validate the cross-scene ability of our method on various datasets. Furthermore, we observe that our approach emerges capabilities for geometry and semantic learning. We hope our approach can provide preliminary understanding of the physical world in first-person view and help ease future research in computer vision, computer graphics and robotics."
    },
    {
        "title": "Hybrid Fourier Score Distillation for Efficient One Image to 3D Object Generation",
        "link_suffix": "/forum?id=v5JrYUdMxc",
        "link": "https://openreview.net/forum?id=v5JrYUdMxc",
        "pdf_link": "https://openreview.net/pdf?id=v5JrYUdMxc",
        "keywords": "3D Generation, One Image to 3D Generation",
        "abstract": "Single image-to-3D generation is pivotal for crafting controllable 3D assets. Given its under-constrained nature, we attempt to leverage 3D geometric priors from a novel view diffusion model and 2D appearance priors from an image generation model to guide the optimization process. We note that there is a disparity between the generation priors of these two diffusion models, leading to their different appearance outputs. Specifically, image generation models tend to deliver more detailed visuals, whereas novel view models produce consistent yet over-smooth results across different views. Directly combining them leads to suboptimal effects due to their appearance conflicts. Hence, we propose a 2D-3DhybridFourierScoreDistillation objective function,hy-FSD. It optimizes 3D Gaussians using 3D priors in spatial domain to ensure geometric consistency, while exploiting 2D priors in the frequency domain through Fourier transform for better visual quality. hy-FSD can be integrated into existing 3D generation methods and produce significant performance gains. With this technique, we further develop an image-to-3D generation pipeline to create high-quality 3D objects within one minute, namedFourier123. Extensive experiments demonstrate that Fourier123 excels in efficient generation with rapid convergence speed and visually-friendly generation results."
    },
    {
        "title": "Learning Pattern-Specific Experts for Time Series Forecasting Under Patch-level Distribution Shift",
        "link_suffix": "/forum?id=qVyjN01x4P",
        "link": "https://openreview.net/forum?id=qVyjN01x4P",
        "pdf_link": "https://openreview.net/pdf?id=qVyjN01x4P",
        "keywords": "Time Series Forecasting, Distribution Shift, Deep Learning",
        "abstract": "Time series forecasting, which aims to predict future values based on historical data, has garnered significant attention due to its broad range of applications.  However, real-world time series often exhibit complex non-uniform distribution with varying patterns across segments, such as season, operating condition, or semantic meaning, making accurate forecasting challenging. Existing approaches, which typically train a single model to capture all these diverse patterns, often struggle with the pattern drifts between patches and may lead to poor generalization. To address these challenges, we propose TFPS, a novel architecture that leverages pattern-specific experts for more accurate and adaptable time series forecasting. TFPS employs a dual-domain encoder to capture both time-domain and frequency-domain features, enabling a more comprehensive understanding of temporal dynamics. It then uses subspace clustering to dynamically identify distinct patterns across data patches. Finally, pattern-specific experts model these unique patterns, delivering tailored predictions for each patch. By explicitly learning and adapting to evolving patterns, TFPS achieves significantly improved forecasting accuracy. Extensive experiments on real-world datasets demonstrate that TFPS outperforms state-of-the-art methods, particularly in long-term forecasting, through its dynamic and pattern-aware learning approach. The data and codes are available:https://anonymous.4open.science/r/TFPS-D001."
    },
    {
        "title": "Maximum Next-State Entropy for Efficient Reinforcement Learning",
        "link_suffix": "/forum?id=0G6rRLYcxm",
        "link": "https://openreview.net/forum?id=0G6rRLYcxm",
        "pdf_link": "https://openreview.net/pdf?id=0G6rRLYcxm",
        "keywords": "Deep Reinforcement Learning; Maximum Entropy Reinforcement Learning",
        "abstract": "Maximum entropy algorithms have demonstrated significant progress in Reinforcement Learning~(RL), which offers an additional guidance in the form of entropy, particularly beneficial in tasks with sparse rewards. Nevertheless, current approaches grounded in policy entropy encourage the agent to explore diverse actions, yet they do not directly help agent explore diverse states. In this study, we theoretically reveal the challenge for optimizing the next-state entropy of agent. To address this limitation, we introduce Maximum Next-State Entropy (MNSE), a novel method which maximizes next-state entropy through an action mapping layer following the inner policy. We provide a theoretical analysis demonstrating that MNSE can maximize next-state entropy by optimizing the action entropy of the inner policy. We conduct extensive experiments on various continuous control tasks and show that MNSE can significantly improve the exploration capability of RL algorithms."
    },
    {
        "title": "Integral Performance Approximation for Continuous-Time Reinforcement Learning Control",
        "link_suffix": "/forum?id=z21DkDDdgq",
        "link": "https://openreview.net/forum?id=z21DkDDdgq",
        "pdf_link": "https://openreview.net/pdf?id=z21DkDDdgq",
        "keywords": "Continuous-Time Reinforcement Learning (CT-RL), Optimal Control, Integral Performance Approximation (IPA), Adaptive/Approximate Dynamic Programming (ADP), Flight Control, Hypersonic Vehicles (HSVs)",
        "abstract": "We introduce integral performance approximation (IPA), a new continuous-time reinforcement learning (CT-RL) control method. It leverages an affine nonlinear dynamic model, which partially captures the dynamics of the physical environment, alongside state-action trajectory data to enable optimal control with great data efficiency and robust control performance. Utilizing Kleinman algorithm structures allows IPA to provide theoretical guarantees of learning convergence, solution optimality, and closed-loop stability. Furthermore, we demonstrate the effectiveness of IPA on three CT-RL environments including hypersonic vehicle (HSV) control, which has additional challenges caused by unstable and nonminimum phase dynamics. As a result, we demonstrate that the IPA method leads to new, SOTA control design and performance in CT-RL."
    }
]
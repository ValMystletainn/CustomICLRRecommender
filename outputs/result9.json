[
    {
        "title": "JOOCI: A FRAMEWORK FOR LEARNING COMPREHENSIVE SPEECH REPRESENTATIONS",
        "link_suffix": "/forum?id=DnfPX10Etk",
        "link": "https://openreview.net/forum?id=DnfPX10Etk",
        "pdf_link": "https://openreview.net/pdf?id=DnfPX10Etk",
        "keywords": "SSL, Speech Representation Learning, Joint Optimization",
        "abstract": "Information in speech can be divided into two categories: \u201cwhat is being said\u201d (content) and \u201chow it is expressed\u201d (other). Current state-of-the-art (SOTA) techniques model speech at a fixed segment, usually 10-25 ms, using a single embedding. Given the orthogonal nature of other and content information, attempting to optimize both within a single embedding results in a sub-optimal solution. This approach divides the model\u2019s capacity, limiting its ability to build complex hierarchical features effectively. In this work, we present an end-to-end speech representation learning framework designed to jointly optimize the \u201cother\u201d and \u201ccontent\u201d information (JOOCI) in speech. By using separate learnable parameters, JOOCI addresses the optimization problem by modeling other and content information independently. Our results show that JOOCI consistently outperforms other SOTA models of similar size (100 million parameters) and pre-training data\nused (960 hours) by a significant margin when evaluated on a range of speech downstream tasks in the SUPERB benchmark as shown in Table 1."
    },
    {
        "title": "Learning-Augmented Streaming Algorithms for Correlation Clustering",
        "link_suffix": "/forum?id=QSTv4os59f",
        "link": "https://openreview.net/forum?id=QSTv4os59f",
        "pdf_link": "https://openreview.net/pdf?id=QSTv4os59f",
        "keywords": "Correlation Clustering, graph streaming algorithms, learning-augmented algorithms",
        "abstract": "We study streaming algorithms for Correlation Clustering. Given a complete graph as an arbitrary-order stream of edges, with each edge labelled as positive or negative, the goal is to partition the vertices into disjoint clusters, such that the number of disagreements is minimized. In this paper, we introduce the first learning-augmented streaming algorithms for the problem, achieving the first better-than-$3$-approximation in dynamic streams. Our algorithms draw inspiration from recent works of Cambus et al. (SODA'24), and Chakrabarty and Makarychev (NeurIPS'23). Our algorithms use the predictions of pairwise dissimilarities between vertices provided by a predictor and achieve an approximation ratio that is close to $2.06$ under good prediction quality. Even if the prediction quality is poor, our algorithms cannot perform worse than the well known Pivot algorithm, which achieves a $3$-approximation. Our algorithms are much simpler than the recent $1.847$-approximation streaming algorithm by Cohen-Addad et al. (STOC'24) which appears to be challenging to implement and is restricted to insertion-only streams. Experimental results on synthetic and real-world datasets demonstrate the superiority of our proposed algorithms over their non-learning counterparts."
    },
    {
        "title": "MMAR: Towards Lossless Multi-Modal Auto-Regressive Prababilistic Modeling",
        "link_suffix": "/forum?id=UE3okxYTUR",
        "link": "https://openreview.net/forum?id=UE3okxYTUR",
        "pdf_link": "https://openreview.net/pdf?id=UE3okxYTUR",
        "keywords": "Multimodal Large Language Model, Vision Language Model",
        "abstract": "Recent advancements in multimodal large language models have propelled the development of joint probabilistic models for image understanding and generation. Existing methods that discretize image spaces cause information loss and reduced model capacity. Recent work attempts to integrate diffusion transformers and text autoregression show promise, but it faces challenges in incomplete image\ninformation utilization for understanding tasks \u2014 diffusion transformers encode image information within various noise levels, but image understanding tasks take only clean image as input. In this paper, we develop a novel MultiModal AutoregRessive (MMAR) probabilistic modeling framework based on continuous image representations. Unlike previous methods, MMAR avoids the information loss associated with discretization and the drawback of combining diffusion transformers with AR models. It employs a standalone diffusion-based continuous probabilistic sampler at the image token level on top of LLMs to theoretically ensure lossless image-text joint probabilistic modeling. In practice, to address the substantial optimization difficulties encountered in low-precision training regime common\nfor LLMs, we theoretically derive an optimal diffusion model parameterization that minimizes numerical error. To balance visual understanding and generalization capabilities, we introduce a two-stage training strategy and an extremely large CFG scale for inference. The proposed MMAR significantly demonstrates scaling-up laws with more data and larger model size. Extensive evaluations are\nconducted on 18 image understanding benchmarks. It reveals that MMAR is the first joint image-text modeling framework that approaches comparable performance with traditional MLLMs that employ pretrained CLIP vision encoder, marking a significant step toward lossless joint probabilistic modeling of images and text."
    },
    {
        "title": "Reliable and Diverse Evaluation of LLM Medical Knowledge Mastery",
        "link_suffix": "/forum?id=TXfzH933qV",
        "link": "https://openreview.net/forum?id=TXfzH933qV",
        "pdf_link": "https://openreview.net/pdf?id=TXfzH933qV",
        "keywords": "LLM Evaluation, Medical Evaluation, Large Language Model",
        "abstract": "Mastering medical knowledge is crucial for medical-specific LLMs. However, despite the existence of medical benchmarks like MedQA, a unified framework that fully leverages existing knowledge bases to evaluate LLMs' mastery of medical knowledge is still lacking. In the study, we propose a novel framework PretexEval that dynamically generates reliable and diverse test samples to evaluate LLMs for any given medical knowledge base. We notice that test samples produced directly from knowledge bases by templates or LLMs may introduce factual errors and also lack diversity. To address these issues, we introduce a novel schema into our proposed evaluation framework that employs predicate equivalence transformations to produce a series of variants for any given medical knowledge point. Finally, these produced predicate variants are converted into textual language, resulting in a series of reliable and diverse test samples to evaluate whether LLMs fully master the given medical factual knowledge point. Here, we use our proposed framework to systematically investigate the mastery of medical factual knowledge of 12 well-known LLMs, based on two knowledge bases that are crucial for clinical diagnosis and treatment. The evaluation results illustrate that current LLMs still exhibit significant deficiencies in fully mastering medical knowledge, despite achieving considerable success on some famous public benchmarks. These new findings provide valuable insights for developing medical-specific LLMs, highlighting that current LLMs urgently need to strengthen their comprehensive and in-depth mastery of medical knowledge before being applied to real-world medical scenarios."
    },
    {
        "title": "Personalized Federated Learning via Tailored Lorentz Space",
        "link_suffix": "/forum?id=5YRw1m6GSz",
        "link": "https://openreview.net/forum?id=5YRw1m6GSz",
        "pdf_link": "https://openreview.net/pdf?id=5YRw1m6GSz",
        "keywords": "Personalized Federated Learning, Hyperbolic Geometry",
        "abstract": "Personalized Federated Learning (PFL) has gained attention for privacy-preserving training on heterogeneous data. However, existing methods fail to capture the unique inherent geometric properties across diverse datasets by assuming a unified Euclidean space for all data distributions. Drawing on hyperbolic geometry's ability to fit complex data properties, we present FlatLand, a novel personalized federated learning method that embeds different clients' data in tailored Lorentz space. FlatLand can directly tackle the challenge of heterogeneity through the personalized curvatures of their respective Lorentz model of hyperbolic geometry, which is manifested by the time-like dimension. Leveraging the Lorentz model properties, we further design a parameter decoupling strategy that enables direct server aggregation of common client information, with reduced heterogeneity interference and without the need for client-wise similarity estimation. To the best of our knowledge, this is the first attempt to incorporate Lorentz geometry into personalized federated learning. Empirical results on various federated graph learning tasks demonstrate that FlatLand achieves superior performance, particularly in low-dimensional settings."
    },
    {
        "title": "Degree-aware Spiking Graph Domain Adaptation for Classification",
        "link_suffix": "/forum?id=nVbbB3Jmyo",
        "link": "https://openreview.net/forum?id=nVbbB3Jmyo",
        "pdf_link": "https://openreview.net/pdf?id=nVbbB3Jmyo",
        "keywords": "spiking graph neural network; domain adaptation",
        "abstract": "Spiking Graph Networks (SGNs) have garnered significant interest from both researchers and industry due to their ability to address energy consumption challenges in graph classification. However, SGNs are typically inference under the same distribution of training dataset, which is difficult to satisfy in real applications. In this paper, we first propose the domain adaptation problem in SGNs, and introduce the novel framework named \\textbf{De}gree-aware \\textbf{S}piking \\textbf{G}raph \\textbf{D}omain \\textbf{A}daptation for Classification (\\method{}). To address this problem, we propose solutions in terms of three aspects: node distribution-aware personalized spiking representation, graph feature distribution alignment, and pseudo-label distillation. Firstly, we introduce the personalized spiking representation method that varies with node degrees. The difficulty of triggering a spike is determined by the node degree, allowing this personalized approach to capture more expressive information for classification. Then, we propose the graph feature distribution alignment module that is adversarially trained using membrane potential against a domain discriminator, efficiently maintaining high performance and low energy consumption in the case of inconsistent distribution. Additionally, we extract consistent predictions across two spaces to create reliable pseudo-labels, effectively leveraging unlabeled data to enhance graph classification performance. \nExtensive experiments on benchmark datasets validate the superiority of the proposed \\method{} compared with baselines."
    },
    {
        "title": "SynthFormer: Equivariant Pharmacophore-based Generation of Molecules for Ligand-Based Drug Design",
        "link_suffix": "/forum?id=UFBabPTgr2",
        "link": "https://openreview.net/forum?id=UFBabPTgr2",
        "pdf_link": "https://openreview.net/pdf?id=UFBabPTgr2",
        "keywords": "Generative Machine Learning, Drug Discovery, Chemical Space Exploration, 3D Equivariant Encoder, Pharmacophore Representation, Molecule Generation, Synthetic Trees, Synthesis Pathways, Docking Scores, Late-stage Optimization, In Silico to In Vitro Integration, Deep Learning in Chemistry, Structure-based Drug Design, 3D Molecular Embedding, Computational Chemistry, ML-driven Molecule Design",
        "abstract": "Drug discovery is a complex and resource-intensive process, with significant time and cost investments required to bring new medicines to patients. Recent advancements in generative machine learning (ML) methods offer promising avenues to accelerate early-stage drug discovery by efficiently exploring chemical space. This paper addresses the gap between in silico generative approaches and practical in vitro methodologies, highlighting the need for their integration to optimize molecule discovery. We introduce SynthFormer, a novel ML model that utilizes a 3D equivariant encoder for pharmacophores to generate fully synthesizable molecules, constructed as synthetic trees. Unlike previous methods, SynthFormer incorporates 3D information and provides synthetic paths, enhancing its ability to produce molecules with good docking scores across various proteins. Our contributions include a new methodology for efficient chemical space exploration using 3D information, a novel architecture called Synthformer for translating 3D pharmacophore representations into molecules, and a meaningful embedding space that organizes reagents for drug discovery optimization. Synthformer generates molecules that dock well and enables effective hit expansion and later-stage optimization restricted by synthesis paths."
    },
    {
        "title": "Revisiting the Relation Between Robustness and Universality",
        "link_suffix": "/forum?id=2z340YQdvJ",
        "link": "https://openreview.net/forum?id=2z340YQdvJ",
        "pdf_link": "https://openreview.net/pdf?id=2z340YQdvJ",
        "keywords": "similarity, representational similarity, functional similarity, adversarial robustness, universality",
        "abstract": "Themodified universality hypothesisproposed by Jones et al. (2022) suggests that adversarially robust models trained for a given task are highly similar. We revisit the hypothesis and test its generality. We find that predictive behavior does not converge with increasing robustness and thus is not universal. Further, with additional similarity measures, we uncover differences in the representations that were invisible with the measures used in prior work. While robust models tend to be more similar than standard models, robust models remain distinct in important aspects. Moreover, the importance of similarity measures when comparing representations is highlighted as the absolute level of similarity---and thus the assessment of universality---is heavily dependent on the measure used."
    },
    {
        "title": "SparsePO: Controlling Preference Alignment of LLMs via Sparse Token Masks",
        "link_suffix": "/forum?id=YOrN9vNrqo",
        "link": "https://openreview.net/forum?id=YOrN9vNrqo",
        "pdf_link": "https://openreview.net/pdf?id=YOrN9vNrqo",
        "keywords": "preference optimization, alignment with human preferences",
        "abstract": "Preference Optimization (PO) has proven an effective step for aligning language models to human-desired behaviors. Current variants, following the offline Direct Preference Optimization objective, have focused on a strict setting where all tokens are contributing signals of KL divergence and rewards to the loss function. However, human preference is not affected by each word in a sequence equally but is often dependent on specific words or phrases, e.g. existence of toxic terms leads to non-preferred responses. Based on this observation, we argue that not all tokens should be weighted equally during PO and propose a flexible objective termed SparsePO, that aims to automatically learn to weight the KL divergence and reward corresponding to each token during PO training. We propose two different variants of weight-masks that can either be derived from the reference model itself or learned on the fly. Notably, our method induces sparsity in the learned masks, allowing the model to learn how to best weight reward and KL divergence contributions at the token level, learning an optimal level of mask sparsity. Extensive experiments on multiple domains, including sentiment control, dialogue, text summarization and text-to-code generation, illustrate that our approach assigns meaningful weights to tokens according to the target task, generates more responses with the desired preference and improves reasoning tasks by up to 2 percentage points  compared to other token- and sentence-level PO methods."
    },
    {
        "title": "Dynamic Contrastive Learning for Time Series Representation",
        "link_suffix": "/forum?id=nphsoKxlFs",
        "link": "https://openreview.net/forum?id=nphsoKxlFs",
        "pdf_link": "https://openreview.net/pdf?id=nphsoKxlFs",
        "keywords": "contrastive learning, self-supervised learning, time series analysis, representation learning",
        "abstract": "Understanding events in time series is an important task in a variety of contexts. However, human analysis and labeling are expensive and time-consuming. Therefore, it is advantageous to learn embeddings for moments in time series in an unsupervised way, which allows for good performance in classification or detection tasks after later minimal human labeling. In this paper, we propose dynamic contrastive learning (DynaCL), an unsupervised representation learning framework for time series that uses temporal adjacent steps to define positive pairs. DynaCL adopts N-pair loss to dynamically treat all samples in a batch as positive or negative pairs, enabling efficient training and addressing the challenges of complicated sampling of positives. We demonstrate that DynaCL embeds instances from time series into well-defined, semantically meaningful clusters, which allows superior performance on downstream tasks on a variety of public time series datasets. Our findings also reveal that high scores on unsupervised clustering metrics do not guarantee that the representations are useful in downstream tasks."
    },
    {
        "title": "Meta-Learning for Dynamic Synaptic Plasticity in Spiking Neural Networks",
        "link_suffix": "/forum?id=KJ4hQAfqVa",
        "link": "https://openreview.net/forum?id=KJ4hQAfqVa",
        "pdf_link": "https://openreview.net/pdf?id=KJ4hQAfqVa",
        "keywords": "Spiking Neural Networks, Meta-learning, Synaptic Plasticity, Neuromorphic Computing, Adaptive Learning",
        "abstract": "Adaptive optimization algorithms, such as Adam Kingma & Ba (2015) and RM-SProp Tieleman & Hinton (2012), have become integral to training deep neu-ral networks, yet their stability properties and impact on generalization remain poorly understood Wilson et al. (2017). This paper extends linear stability anal-ysis to adaptive optimizers, providing a theoretical framework that explains their behavior in relation to loss surface geometry Wu et al. (2022); Jastrz\u02dbebski et al.(2019). We introduce a novel generalized coherence measure that quantifies the interaction between the adaptive preconditioner and the Hessian of the loss func-tion. This measure yields necessary and sufficient conditions for linear stability near stationary points, offering insights into why adaptive methods may converge to sharper minima with poorer generalization.\nOur analysis leads to practical guidelines for hyperparameter tuning, demon-strating how to improve the generalization performance of adaptive optimizers. Through extensive experiments on benchmark datasets and architectures, includ-ing ResNet He et al. (2016) and Vision Transformers Dosovitskiy et al. (2020), we validate our theoretical predictions, showing that aligning the adaptive precon-ditioner with the loss surface geometry through careful parameter selection can narrow the generalization gap between adaptive methods and SGD Loshchilov & Hutter (2018)."
    },
    {
        "title": "Invariant Spatiotemporal Representation Learning for Cross-patient Seizure Classification",
        "link_suffix": "/forum?id=TkbjqexD8w",
        "link": "https://openreview.net/forum?id=TkbjqexD8w",
        "pdf_link": "https://openreview.net/pdf?id=TkbjqexD8w",
        "keywords": "electroencephalogram data, spatiotemporal data, invariant representation learning",
        "abstract": "Automatic seizure type classification from electroencephalogram (EEG) data can help clinicians to better diagnose epilepsy. Although many previous studies have focused on the classification problem of seizure EEG data, most of these methods require that there is no distribution shift between training data and test data, which greatly limits the applicability in real-world scenarios. In this paper, we propose an invariant spatiotemporal representation learning method for cross-patient seizure classification. Specifically, we first split the spatiotemporal EEG data into different environments based on heterogeneous risk minimization to reflect the spurious correlations. We then learn invariant spatiotemporal representations and train the seizure classification model based on the learned representations to achieve accurate seizure-type classification across various environments. The experiments are conducted on the largest public EEG dataset, the Temple University Hospital Seizure Corpus (TUSZ) dataset, and the experimental results demonstrate the effectiveness of our method."
    },
    {
        "title": "Extending Stability Analysis to Adaptive Optimization Algorithms Using Loss Surface Geometry",
        "link_suffix": "/forum?id=9mOs2Bxd3Q",
        "link": "https://openreview.net/forum?id=9mOs2Bxd3Q",
        "pdf_link": "https://openreview.net/pdf?id=9mOs2Bxd3Q",
        "keywords": "Adaptive Optimization, Linear Stability Analysis, Generalization, Loss Surface Geometry, Deep Neural Networks",
        "abstract": "Adaptive optimization algorithms, such as Adam Kingma & Ba (2015) and RM-SProp Tieleman & Hinton (2012), have become integral to training deep neu-ral networks, yet their stability properties and impact on generalization remain poorly understood Wilson et al. (2017). This paper extends linear stability anal-ysis to adaptive optimizers, providing a theoretical framework that explains their behavior in relation to loss surface geometry Wu et al. (2022); Jastrz\u02dbebski et al.(2019). We introduce a novel generalized coherence measure that quantifies the interaction between the adaptive preconditioner and the Hessian of the loss func-tion. This measure yields necessary and sufficient conditions for linear stability near stationary points, offering insights into why adaptive methods may converge to sharper minima with poorer generalization.\nOur analysis leads to practical guidelines for hyperparameter tuning, demon-strating how to improve the generalization performance of adaptive optimizers. Through extensive experiments on benchmark datasets and architectures, includ-ing ResNet He et al. (2016) and Vision Transformers Dosovitskiy et al. (2020), we validate our theoretical predictions, showing that aligning the adaptive precon-ditioner with the loss surface geometry through careful parameter selection can narrow the generalization gap between adaptive methods and SGD Loshchilov & Hutter (2018)."
    },
    {
        "title": "Leveraging LLM Embeddings for Cross Dataset Label Alignment and Zero Shot Music Emotion Prediction",
        "link_suffix": "/forum?id=Gi3SwL98nL",
        "link": "https://openreview.net/forum?id=Gi3SwL98nL",
        "pdf_link": "https://openreview.net/pdf?id=Gi3SwL98nL",
        "keywords": "Music Emotion Prediction, Zero Shot Learning, Label Alignment",
        "abstract": "In this work, we present a novel method for music emotion recognition that leverages Large Language Model (LLM) embeddings for label alignment across multiple datasets and zero-shot prediction on novel categories. First, we compute LLM embeddings for emotion labels and apply non-parametric clustering to group similar labels, across multiple datasets containing disjoint labels. We use these cluster centers to map music features (MERT) to the LLM embedding space. To further enhance the model, we introduce an alignment regularization that enables dissociation of MERT embeddings from different clusters. This further enhances the model's ability to better adaptation to unseen datasets. We demonstrate the effectiveness of our approach by performing zero-shot inference on a new dataset, showcasing its ability to generalize to unseen labels without additional training."
    },
    {
        "title": "Interpretability of LLM Deception: Universal Motif",
        "link_suffix": "/forum?id=znL549Ymoi",
        "link": "https://openreview.net/forum?id=znL549Ymoi",
        "pdf_link": "https://openreview.net/pdf?id=znL549Ymoi",
        "keywords": "safety, honesty, deception, lie, interpretability, Large Language Model",
        "abstract": "Conversational large language models (LLMs) are trained to be helpful, honest and harmless (HHH) and yet they remain susceptible to hallucinations, misinformation and are capable of deception. A promising avenue for safeguarding against these behaviors is to gain a deeper understanding of their inner workings. Here we ask:  what could interpretability tell us about deception and can it help to control it?  First, we introduce a simple and yet general protocol to induce 20 large conversational models from different model families (Llama, Gemma, Yi and Qwen) of various sizes (from 1.5B to 70B) to knowingly lie. Second, we characterize three iterative refinement stages of deception from the latent space representation. Third, we demonstrate that these stages are \\textit{universal} across models from different families and sizes. We find that the third stage progression reliably predicts whether a certain model is capable of deception. Furthermore, our patching results reveal that a surprisingly sparse set of layers and attention heads are causally responsible for lying. Importantly, consistent across all models tested, this sparse set of layers and attention heads are part of the third iterative refinement process. When contrastive activation steering is applied to control model output, only steering these layers from the third stage could effectively reduce lying. Overall, these findings identify a universal motif across deceptive models and provide actionable insights for developing general and robust safeguards against deceptive AI. The code, dataset, visualizations, and an interactive demo notebook are available at \\url{https://github.com/safellm-2024/llm_deception}."
    },
    {
        "title": "Multi-Dimensional Insights: Benchmarking Real-World Personalization in Large Multimodal Models",
        "link_suffix": "/forum?id=CvunOaPA1W",
        "link": "https://openreview.net/forum?id=CvunOaPA1W",
        "pdf_link": "https://openreview.net/pdf?id=CvunOaPA1W",
        "keywords": "large multimodal models, benchmark, evaluation",
        "abstract": "The rapidly developing field of large multimodal models (LMMs) has led to the emergence of diverse models with remarkable capabilities. However, existing benchmarks fail to comprehensively, objectively and accurately evaluate whether LMMs align with the diverse needs of humans in real-world scenarios. To bridge this gap, we propose the Multi-Dimensional Insights (MDI) benchmark, which includes over 500 images covering six common scenarios of human life. Notably, the MDI-Benchmark offers two significant advantages over existing evaluations:\n(1) Each image is accompanied by two types of questions: simple questions to assess the model's understanding of the image, and complex questions to evaluate the model's ability to analyze and reason beyond basic content.\n(2) Recognizing that people of different age groups have varying needs and perspectives when faced with the same scenario, our benchmark stratifies questions into three age categories: young people, middle-aged people, and older people. This design allows for a detailed assessment of LMMs' capabilities in meeting the preferences and needs of different age groups. With MDI-Benchmark, the strong model like GPT-4o achieve 79% accuracy on age-related tasks, indicating that existing LMMs still have considerable room for improvement in addressing real-world applications. Looking ahead, we anticipate that the MDI-Benchmark will open new pathways for aligning real-world personalization in LMMs."
    },
    {
        "title": "How new data pollutes LLM knowledge and how to dilute it",
        "link_suffix": "/forum?id=NGKQoaqLpo",
        "link": "https://openreview.net/forum?id=NGKQoaqLpo",
        "pdf_link": "https://openreview.net/pdf?id=NGKQoaqLpo",
        "keywords": "fine-tuning, hallucinations, knowledge injection, memory, LLMs",
        "abstract": "Understanding how the learning of new texts alter the existing knowledge in a large language model is of great importance, because it is through these accumulated changes that the LLM was initially pre-trained, and is also through such changes that continual, new learning in LLMs can proceed. As a result, both desirable alterations (i.e. generalization) and undesirable alterations (i.e. hallucination) can occur. Here, we study the learning of new texts, one at a time, and ask: how does it impact the underlying LLM knowledge? \n  We show that learning new texts induce 'priming', an undesirable effect that pollutes existing knowledge where it should not.\nCentrally, we demonstrate that we can predict how much priming will happen after learning, using token probability before learning. This was empirically robust across models (PALM-2-xs/s, Gemma-2b, Llama-2-7b), of various sizes, and training stages. To show this, we created a new dataset, called \"Outlandish\" consisting of 1320 different samples with diverse textual characteristics. Finally, we propose two strategies to mitigate the spread of priming: first, a simple text augmentation technique which we call the \"stepping-stone'', and second, a novel update pruning technique (\"ignore-k\"). These decrease priming by a median of 50%-75% and 50%-95% respectively depending on the model architecture, and enhance the specificity of new learning in language models. The dataset and reproducible findings can be found [LINK omitted for double blind review]."
    },
    {
        "title": "Enhancing Software Agents with Monte Carlo Tree Search and Hindsight Feedback",
        "link_suffix": "/forum?id=G7sIFXugTX",
        "link": "https://openreview.net/forum?id=G7sIFXugTX",
        "pdf_link": "https://openreview.net/pdf?id=G7sIFXugTX",
        "keywords": "agents, LLM, SWE-agents, SWE-bench, search, planning, reasoning, self-improvement, open-ended",
        "abstract": "In complex and dynamic environments like software development, effective decision-making requires continuous adaptation, iterative learning, and strategic reconsideration. Current large language model (LLM)-based software agents often rely on rigid processes, limiting their ability to handle intricate, long-horizon tasks. These agents frequently fall into repetitive patterns, unable to assess the efficacy of their actions over time. To address these challenges, we propose SWE-search, a multi-agent framework that integrates Monte Carlo Tree Search (MCTS) with self-improvement mechanisms to enhance software agents' performance in dynamic, repository-level tasks. SWE-search extends traditional MCTS by incorporating a hybrid value function that leverages LLMs for both numerical value estimation and qualitative evaluation. This combination enables self-feedback loops where agents iteratively refine their strategies based on both quantitative outcomes and the qualitative assessment of the paths taken. The framework includes a SWE-Agent for adaptive exploration, a Value Agent for iterative feedback, and a Discriminator Agent that facilitates multi-agent debate for collaborative decision-making.\nApplied to the SWE-Bench benchmark, our approach demonstrates a 23% relative improvement in performance across five models compared to standard open-source agents without MCTS. Our analysis reveals how performance scales with increased search breadth and identifies key factors that facilitate effective self-evaluation in software agents. This work highlights the potential of self-evaluation driven search techniques to enhance agent reasoning and planning in complex, dynamic software engineering environments."
    },
    {
        "title": "Language Models are Advanced Anonymizers",
        "link_suffix": "/forum?id=82p8VHRsaK",
        "link": "https://openreview.net/forum?id=82p8VHRsaK",
        "pdf_link": "https://openreview.net/pdf?id=82p8VHRsaK",
        "keywords": "privacy, anonymization, large language models",
        "abstract": "Recent privacy research on large language models (LLMs) has shown that they achieve near-human-level performance at inferring personal data from online texts. With ever-increasing model capabilities, existing text anonymization methods are currently lacking behind regulatory requirements and adversarial threats. In this work, we take two steps to bridge this gap: First, we present a new setting for evaluating anonymization in the face of adversarial LLM inferences, allowing for a natural measurement of anonymization performance while remedying some of the shortcomings of previous metrics. Then, within this setting, we develop a novel LLM-based adversarial anonymization framework leveraging the strong inferential capabilities of LLMs to inform our anonymization procedure. We conduct a comprehensive experimental evaluation of adversarial anonymization across 13 LLMs on real-world and synthetic online texts, comparing it against multiple baselines and industry-grade anonymizers. Our evaluation shows that adversarial anonymization outperforms current commercial anonymizers both in terms of the resulting utility and privacy. We support our findings with a human study (n=50) highlighting a strong and consistent human preference for LLM-anonymized texts."
    },
    {
        "title": "Coresets fork-mean clustering of segments",
        "link_suffix": "/forum?id=oY2jw2NLiM",
        "link": "https://openreview.net/forum?id=oY2jw2NLiM",
        "pdf_link": "https://openreview.net/pdf?id=oY2jw2NLiM",
        "keywords": "Clustering; $k$-means; Segment clustering; Non-convex optimisation; Coresets",
        "abstract": "The $k$-means of a given set $\\mathcal{S}\\subseteq \\mathbb{R}^d$ of $n$ segments is a set $X\\subseteq \\mathbb{R}^d$ of $|X|=k$ centers which minimizes their sum of squared distances $D(\\mathcal{S},X):=\\sum_{S\\in \\mathcal{S}}\\min_{x\\in X}D(S,x)$.\nHere, the distance $D(S,x)$ between a segment $S$ and a point $x$ is the integral of its distances $\\int_{s\\in S}|p-x|$ over each point on the segment.\nMore generally, the farthest $m$ input points (outliers) may be ignored, other distance functions may be used, such as M-estimator or non-squared, and each distance may be multiplied by a function that depends on the size of its cluster, say, to obtain balanced clustering.\nFor a given $\\varepsilon>0$, an $\\varepsilon$-coreset $C\\subseteq S$ for all these problems is a weighted subset $C\\subset S$, that approximates $D(S,X)$ up to $1\\pm\\varepsilon$ multiplicative factor for every set $X\\subseteq\\mathbb{R}^d$ of (possibly weighted) $k$ centers. Such a coreset enables handling streaming, big, distributed input in parallel using existing techniques.\nWe suggest the first coreset construction that, with high probability, returns an $\\varepsilon$-coreset $C$ for \\emph{any} input set $\\mathcal{S}$ of segments.\nFor constant $k,\\varepsilon$, the size of the coreset is $|C|\\in O \\big(\\log^2(n)\\big)$ and is computed in time $O(nd)$.\nExperimental results and real-time video tracking application demonstrate the applicability of our algorithm, the latter demonstrates that our method supports vectorized segments."
    },
    {
        "title": "Hierarchical Self-Supervised Graph Contrastive Learning: Capturing Multi-Scale Structural Information",
        "link_suffix": "/forum?id=pL8ws91RW2",
        "link": "https://openreview.net/forum?id=pL8ws91RW2",
        "pdf_link": "https://openreview.net/pdf?id=pL8ws91RW2",
        "keywords": "Graph Neural Networks, Self-supervised Learning, Contrastive Learning, Hierarchical Representation, Node Classification",
        "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning rep-resentations from graph-structured data Kipf & Welling (2017); Veli\u02c7ckovic\u00b4 et al.(2018), but often rely heavily on labeled data for training. This paper introduces a novel hierarchical self-supervised graph contrastive learning framework that ef-fectively leverages unlabeled data to enhance node representations. Our method captures rich structural information at multiple scales by incorporating contrastive objectives at the node, subgraph, and graph levels, extending previous work on self-supervised learning for graphs Veli\u02c7ckovic\u00b4 et al. (2019); You et al. (2020). We employ an adaptive graph augmentation strategy to generate meaningful views of the graph while preserving essential properties. Through extensive experiments on benchmark datasets, including Cora, Citeseer, PubMed Sen & Dhillon (2008), and Reddit Hamilton et al. (2017), we demonstrate that our approach consistently outperforms both supervised and self-supervised baseline models in node clas-sification tasks. Our method shows particular strength in low-label regimes and exhibits strong generalization capabilities in both transductive and inductive set-tings. Ablation studies confirm the importance of each hierarchical component, while qualitative analyses illustrate the discriminative power of the learned em-beddings. This work opens new avenues for self-supervised learning on graphs and has broad implications for applications where labeled data is scarce or ex-pensive to obtain, such as in social networks Perozzi et al. (2014) and biological networks Zitnik et al. (2017)."
    },
    {
        "title": "ADAM: An Embodied Causal Agent in Open-World Environments",
        "link_suffix": "/forum?id=Ouu3HnIVBc",
        "link": "https://openreview.net/forum?id=Ouu3HnIVBc",
        "pdf_link": "https://openreview.net/pdf?id=Ouu3HnIVBc",
        "keywords": "embodied agent, causality, large language model, interpretability, vision language navigation, cross-modal application, cross-modal information extraction, multimodality",
        "abstract": "In open-world environments like Minecraft, existing agents face challenges in continuously learning structured knowledge, particularly causality. These challenges stem from the opacity inherent in black-box models and an excessive reliance on prior knowledge during training, which impair their interpretability and generalization capability. To this end, we introduce ADAM, An emboDied causal Agent in Minecraft, that can autonomously navigate the open world, perceive multimodal contexts, learn causal world knowledge, and tackle complex tasks through lifelong learning. ADAM is empowered by four key components: 1) an interaction module, enabling the agent to execute actions while documenting the interaction processes; 2) a causal model module, tasked with constructing an ever-growing causal graph from scratch, which enhances interpretability and diminishes reliance on prior knowledge; 3) a controller module, comprising a planner, an actor, and a memory pool, which uses the learned causal graph to accomplish tasks; 4) a perception module, powered by multimodal large language models, which enables ADAM to perceive like a human player. Extensive experiments show that ADAM constructs an almost perfect causal graph from scratch, enabling efficient task decomposition and execution with strong interpretability. Notably, in our modified Minecraft games where no prior knowledge is available, ADAM maintains its performance and shows remarkable robustness and generalization capability. ADAM pioneers a novel paradigm that integrates causal methods and embodied agents in a synergistic manner."
    },
    {
        "title": "Expected Return Symmetries",
        "link_suffix": "/forum?id=wFg0shwoRe",
        "link": "https://openreview.net/forum?id=wFg0shwoRe",
        "pdf_link": "https://openreview.net/pdf?id=wFg0shwoRe",
        "keywords": "multi-agent reinforcement learning, zero-shot coordination",
        "abstract": "Symmetry is an important inductive bias that can improve model robustness and generalization across many deep learning domains. In multi-agent settings, a priori known symmetries have been shown to address a fundamental coordination failure mode known as mutually incompatible symmetry breaking; e.g. in a game where two independent agents can choose to move \"left\" or \"right\", and where a reward of +1 or -1 is received when the agents choose the same action or different actions, respectively. However, the efficient and automatic discovery of environment symmetries, in particular for decentralized partially observable Markov decision processes, remains an open problem. Furthermore, environmental symmetry breaking constitutes only one type of coordination failure, which motivates the search for a more accessible and broader symmetry class. In this paper, we introduce such a broader group of previously unexplored symmetries, which we call expected return symmetries, which contains environment symmetries as a subgroup. We show that agents trained to be compatible under the group of expected return symmetries achieve better zero-shot coordination results than those using environment symmetries. As an additional benefit, our method makes minimal a priori assumptions about the structure of their environment and does not require access to ground truth symmetries."
    },
    {
        "title": "Younger: The First Dataset for Artificial Intelligence-Generated Neural Network Architecture",
        "link_suffix": "/forum?id=3LFR5N2uv8",
        "link": "https://openreview.net/forum?id=3LFR5N2uv8",
        "pdf_link": "https://openreview.net/pdf?id=3LFR5N2uv8",
        "keywords": "Artificial Intelligence-Generated Neural Network Architecture, Neural Architecture Design, Graph Neural Network, Benchmark, Dataset",
        "abstract": "Designing and optimizing neural network architectures typically require extensive expertise, starting from handcrafted designs followed by manual or automated refinement, which significantly hinders rapid innovation. To address these challenges, Younger is introduced as a comprehensive dataset derived from over 174K real-world models across more than 30 tasks from various public model hubs. After extensive processing and filtering, Younger includes 7,629 unique architectures, each represented as a directed acyclic graph with detailed operator-level information based on ONNX operator definitions, enabling compatibility across different deep learning frameworks. The dataset is designed to support the emerging research area of Artificial Intelligence-Generated Neural Network Architecture (AIGNNA), which aims to automate their generation and refinement. Comprehensive statistical analysis, including architecture component analyses, highlights the diversity and complexity of architectures in Younger, revealing the potential for future research in this domain. Initial experiments, including operator and dataflow predictions, demonstrate the dataset's utility for architecture exploration and evaluation, and highlight its potential as a benchmark for graph neural networks. Furthermore, an online platform ensures continuous maintenance and expansion of the dataset, supporting global researchers in their endeavors. The dataset and source code are publicly available to encourage further research and lower entry barriers in this challenging domain."
    },
    {
        "title": "Differentially Private One Permutation Hashing",
        "link_suffix": "/forum?id=ODzT43I5lJ",
        "link": "https://openreview.net/forum?id=ODzT43I5lJ",
        "pdf_link": "https://openreview.net/pdf?id=ODzT43I5lJ",
        "keywords": "hash, data compression, privacy",
        "abstract": "Minwise hashing (MinHash) is a standard hashing algorithm for large-scale search and learning with the binary Jaccard similarity. One permutation hashing (OPH) is an effective and efficient alternative of MinHash which splits the data into K bins and generates hash values within each bin. In this paper, to protect the privacy of the output sketches, we combine differential privacy (DP) with OPH, and propose DP-OPH framework with three variants: DP-OPH-fix, DP-OPH-re and DP-OPH-rand, depending on the densification strategy to deal with empty bins in OPH. Detailed algorithm design and privacy and utility analysis are provided. The proposed DP-OPH methods significantly improves the DP minwise hashing (DP-MH) alternative in the literature. Experiments on similarity search confirm the effectiveness of our proposed algorithms. We also provide an extension to real-value data, named DP-BCWS, in the appendix."
    }
]
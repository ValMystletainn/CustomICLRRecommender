[{"title": "Learning to Translate Noise for Robust Image Denoising", "link_suffix": "/forum?id=NCynHu1kVF", "link": "https://openreview.net/forum?id=NCynHu1kVF", "pdf_link": "https://openreview.net/pdf?id=NCynHu1kVF", "keywords": "denoising, generalization, robustness, noise translation", "abstract": "Image denoising techniques based on deep learning often struggle with poor generalization performance to out-of-distribution real-world noise. To tackle this challenge, we propose a novel noise translation framework that performs denoising on an image with translated noise rather than directly denoising an original noisy image. Speci\ufb01cally, our approach translates complex, unknown real-world noise into Gaussian noise, which is spatially uncorrelated and independent of image content, through a noise translation network. The translated noisy images are then processed by an image denoising network pretrained to effectively remove Gaussian noise, enabling robust and consistent denoising performance. We also design well-motivated loss functions and architectures for the noise translation network by leveraging the mathematical properties of Gaussian noise. Experimental results demonstrate that the proposed method substantially improves robustness and generalizability, outperforming state-of-the-art methods across diverse benchmarks.", "title_embedding_index": 20550, "title_abs_embedding_index": 20575}, {"title": "UIP2P: Unsupervised Instruction-Based Image Editing via Cycle Edit Consistency", "link_suffix": "/forum?id=PNiqWDAtPq", "link": "https://openreview.net/forum?id=PNiqWDAtPq", "pdf_link": "https://openreview.net/pdf?id=PNiqWDAtPq", "keywords": "Unsupervised learning, Diffusion models, Cycle edit consistency, Instruction-based image editing", "abstract": "We propose an unsupervised model for instruction-based image editing that eliminates the need for ground-truth edited images during training. Traditional supervised approaches depend on datasets containing triplets of input image, edited image, and edit instruction, often generated by either existing editing methods or human-annotations, which introduce biases and limit their generalization ability. Our model addresses these challenges by introducing a novel editing mechanism called Cycle Edit Consistency (CEC). We propose to apply a forward and backward edit in one training step and enforce consistency in both the image and attention space. This allows us to bypass the need for ground-truth edited images and unlock training on datasets comprising either real image-caption pairs or image-caption-edit triplets. We empirically show that our unsupervised method achieves better performance across a wider range of edits with high fidelity and precision. By eliminating the need for pre-existing datasets of triplets, reducing biases associated with supervised methods, and introducing CEC, our work represents a significant advancement in unblocking scaling of instruction-based image editing.", "title_embedding_index": 20551, "title_abs_embedding_index": 20576}, {"title": "What Makes a Good Time-series Forecasting Model? A Causal Perspective", "link_suffix": "/forum?id=HHISuWB0nX", "link": "https://openreview.net/forum?id=HHISuWB0nX", "pdf_link": "https://openreview.net/pdf?id=HHISuWB0nX", "keywords": "Time-series Forecasting, Causal discovery", "abstract": "Generalization is a long-standing challenge in multivariate time series forecasting (MTSF) tasks. Most existing forecasting methods use all available variables in historical series to predict all future variables, assuming that there may be correlations among all variables. From a causal perspective, this reliance on correlated variables can compromise the model\u2019s generalization. To address this, we aim to explore the role of causal relationships in enhancing the generalization of multivariate time series models. We examine how graphical causal models, through conditional independence constraints, can reduce the hypothesis space, thereby improving generalization. Building on this foundation, we introduce a novel causality-based MTSF algorithm CAusal Informed Transformer (CAIFormer). It first constructs a Directed Acyclic Graph (DAG) among variables using causal discovery techniques. Then we build the forecasting model by enforcing the causal constraints informed by the DAG. Empirical evaluations on benchmark datasets demonstrate that our method surpasses traditional approaches in predictive accuracy. Additionally, we present the structural causal models derived for these datasets, underscoring the practical applicability of our causality-driven framework in MTSF.", "title_embedding_index": 20552, "title_abs_embedding_index": 20577}, {"title": "ResidualViT for Efficient Zero-Shot Natural Language Temporal Video Grounding", "link_suffix": "/forum?id=QWDFOOoV3U", "link": "https://openreview.net/forum?id=QWDFOOoV3U", "pdf_link": "https://openreview.net/pdf?id=QWDFOOoV3U", "keywords": "Vision Transformers, Efficiency, Video Encoding, Natural Language Video Grounding", "abstract": "The goal of this work is to efficiently compute frame-level features from videos for the Zero-Shot Natural Language Temporal Video Grounding (NLTVG) task. The contributions of this work are three-fold. First, we introduce a novel vision transformer (ViT) architecture, dubbed ResidualViT, that capitalizes on the large temporal redundancies in video. Our architecture incorporates (i) learnable residual connections that ensure temporal consistency across consecutive frames and (ii) a token reduction module for enhancing processing speed by selectively discarding temporally redundant information. Second, we describe a lightweight distillation strategy that enables learning parameters of  ResidualViT from existing frame encoders without additional manual annotation. Finally, we validate the effectiveness of our approach across three diverse datasets, demonstrating significant reductions in computational cost (up to 60%) and improvements in inference speed (up to 2.5x faster), all while observing marginal accuracy reduction with respect to the teacher model.", "title_embedding_index": 20553, "title_abs_embedding_index": 20578}, {"title": "Tra-MoE: Scaling Trajectory Prediction Models for Adaptive Policy Conditioning", "link_suffix": "/forum?id=InUpEfpXQS", "link": "https://openreview.net/forum?id=InUpEfpXQS", "pdf_link": "https://openreview.net/pdf?id=InUpEfpXQS", "keywords": "Mixture-of-experts, Trajectory-guided policy, Policy Conditioning, Scaling, Robot manipulation, Embodied AI", "abstract": "Scale is a primary factor that influences the performance and generalization of a robot learning system. In this paper, we aim to scale up the trajectory prediction model by using broad out-of-domain data to improve its robustness and generalization ability. Trajectory model is designed to predict any-point trajectories in the current frame given an instruction and can provide detailed control guidance for robotic policy learning. To handle the diverse out-of-domain data distribution, we propose a sparsely-gated MoE (\\textbf{Top-1} gating strategy) architecture for trajectory model, coined as \\textbf{Tra-MoE}. The sparse activation design enables good balance between parameter cooperation and specialization, effectively benefiting from large-scale out-of-domain data while maintaining constant FLOPs per token. In addition, we further introduce an adaptive policy conditioning technique by learning 2D mask representations for predicted trajectories, which is explicitly aligned with image observations to guide policy prediction more flexibly. We perform experiments on both simulation and real-world scenarios to verify the effectiveness of our Tra-MoE and adaptive policy conditioning technique. We jointly train the Tra-MoE model on all 130 tasks in the LIBERO benchmark and conduct a comprehensive empirical analysis, demonstrating that our Tra-MoE consistently exhibits superior performance compared to the dense baseline model, even when the latter is scaled to match Tra-MoE's parameter count.", "title_embedding_index": 20554, "title_abs_embedding_index": 20579}, {"title": "PerPO: Perceptual Preference Optimization via Discriminative Rewarding", "link_suffix": "/forum?id=SrkDVzygXx", "link": "https://openreview.net/forum?id=SrkDVzygXx", "pdf_link": "https://openreview.net/pdf?id=SrkDVzygXx", "keywords": "MLLMs; RLHF; DPO", "abstract": "This paper presents Perceptual Preference Optimization (PerPO), a perception alignment method aimed at addressing the visual discrimination challenges in generative pre-trained multimodal large language models (MLLMs). PerPO employs discriminative rewarding and listwise preference optimization to align MLLMs with human visual perception processes. By utilizing the reward as a quantitative margin for ranking, our method effectively bridges generative preference optimization and discriminative empirical risk minimization. PerPO significantly enhances MLLMs\u2019 visual discrimination capabilities while maintaining their generative strengths, mitigates image-unconditional reward hacking, and ensures consistent performance across visual tasks. This work marks a crucial step towards more perceptually aligned and versatile MLLMs. We also anticipate that PerPO will inspire the community to reconsider MLLM alignment strategies.", "title_embedding_index": 20555, "title_abs_embedding_index": 20580}, {"title": "DSPFusion: Degradation and Semantic Prior Dual-guided Framework for Image Fusion", "link_suffix": "/forum?id=ittdt7tKND", "link": "https://openreview.net/forum?id=ittdt7tKND", "pdf_link": "https://openreview.net/pdf?id=ittdt7tKND", "keywords": "Image fusion, mluti-modal fusion, image restoration, infrared", "abstract": "Existing fusion methods are tailored for high-quality images but struggle with degraded images captured under harsh circumstances, thus limiting the practical potential of image fusion. In this work, we present a Degradation and Semantic Prior dual-guided framework for degraded image Fusion (DSPFusion), utilizing degradation priors and high-quality scene semantic priors restored via diffusion models to guide both information recovery and fusion in a unified model. In specific, it first individually extracts modality-specific degradation priors and jointly captures comprehensive low-quality semantic priors from cascaded source images. Subsequently, a diffusion model is developed to iteratively restore high-quality semantic priors in a compact latent space, enabling our method to be over $200 \\times$ faster than mainstream diffusion model-based image fusion schemes. Finally, the degradation priors and high-quality semantic priors are employed to guide information enhancement and aggregation via the dual-prior guidance and prior-guided fusion modules. Extensive experiments demonstrate that DSPFusion mitigates most typical degradations while integrating complementary context with minimal computational cost, greatly broadening the application scope of image fusion.", "title_embedding_index": 20556, "title_abs_embedding_index": 20581}, {"title": "CAR: Controllable Autoregressive Modeling for Visual Generation", "link_suffix": "/forum?id=sicB10feCQ", "link": "https://openreview.net/forum?id=sicB10feCQ", "pdf_link": "https://openreview.net/pdf?id=sicB10feCQ", "keywords": "controllable generation, autoregressive models, visual generative models", "abstract": "Controllable generation, which enables fine-grained control over generated outputs, has emerged as a critical focus in visual generative models. Currently, there are two primary technical approaches in visual generation: diffusion models and autoregressive models. Diffusion models, as exemplified by ControlNet and T2I-Adapter, offer advanced control mechanisms, whereas autoregressive models, despite showcasing impressive generative quality and scalability, remain underexplored in terms of controllability and flexibility. In this study, we introduce Controllable AutoRegressive Modeling (CAR), a novel, plug-and-play framework that integrates conditional control into multi-scale latent variable modeling, enabling efficient control generation within a pre-trained visual autoregressive model. CAR progressively refines and captures control representations, which are injected into each autoregressive step of the pre-trained model to guide the generation process. Our approach demonstrates excellent controllability across various types of conditions and delivers higher image quality compared to previous methods. Additionally, CAR achieves robust generalization with significantly fewer training resources compared to those required for pre-training the model. To the best of our knowledge, we are the first to propose a control framework for pre-trained autoregressive visual generation models.", "title_embedding_index": 20557, "title_abs_embedding_index": 20582}, {"title": "MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion", "link_suffix": "/forum?id=bW9fGYo44s", "link": "https://openreview.net/forum?id=bW9fGYo44s", "pdf_link": "https://openreview.net/pdf?id=bW9fGYo44s", "keywords": "text2video, VQ-Diffusion, video Inpainting, Large scale pretraining", "abstract": "The spatio-temporal complexity of video data presents significant challenges in tasks such as compression, generation, and inpainting. We present four key contributions to address the challenges of spatiotemporal video processing. First, we introduce the 3D Mobile Inverted Vector-Quantization Variational Autoencoder (3D-MBQ-VAE), which combines Variational Autoencoders (VAEs) with masked modeling to enhance spatiotemporal video compression. The model achieves superior temporal consistency and state-of-the-art (SOTA) reconstruction quality by employing a novel training strategy with full frame masking. Second, we present MotionAura, a text-to-video generation framework that utilizes vector-quantized diffusion models to discretize the latent space and capture complex motion dynamics, producing temporally coherent videos aligned with text prompts. Third, we propose a spectral transformer-based denoising network that processes video data in the frequency domain using the Fourier Transform. This method effectively captures global context and long-range dependencies for high-quality video generation and denoising. Lastly, we introduce a downstream task of Sketch Guided Video Inpainting. This task leverages Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. Our models achieve SOTA performance on a range of benchmarks.  Our work offers robust frameworks for spatiotemporal modeling and user-driven video content manipulation. We will release the code, dataset, and models in open-source.", "title_embedding_index": 20558, "title_abs_embedding_index": 20583}, {"title": "L-PINN: A Langevin Dynamics Approach with Balanced Sampling to Improve Learning Stability in Physics-Informed Neural Networks", "link_suffix": "/forum?id=EP09OGPRzk", "link": "https://openreview.net/forum?id=EP09OGPRzk", "pdf_link": "https://openreview.net/pdf?id=EP09OGPRzk", "keywords": "Physics-informed neural network, Langevin dynamics, Adaptive sampling method", "abstract": "Physics-informed neural networks (PINNs) have emerged as a promising technique solving partial differential equations (PDEs). However, PINNs face challenges in resource efficiency (e.g., repeatedly sampling of collocation points) and achieving fast convergence to accurate solutions. To address these issues, adaptive sampling methods that focus on collocation points with high residual values have been proposed, enhancing both resource efficiency and solution accuracy. While these high residual-based sampling methods have demonstrated exceptional performance in solving certain stiff PDEs, their potential drawbacks, particularly the relative neglect of points with medium and low residuals, remain under-explored. In this paper, we investigate the limitations of high residual-based methods concerning learning stability as model complexity increases. We provide a theoretical analysis demonstrating that high residual-based methods require tighter upper bound on the learning rate to maintain stability. To overcome this limitation, we present a novel Langevin dynamics-based PINN (L-PINN) framework for adaptive sampling of collocation points, which is designed to improve learning stability and convergence speed. To validate the effectiveness, we evaluated the L-PINN framework against existing adaptive sampling approaches for PINNs. Our results indicate that the L-PINN framework achieves superior relative $L^{2}$ error performance in solutions while demonstrating faster or comparable convergence stability. Furthermore, we showed that our framework maintains robust performance across varying model complexities, suggesting its potential for compatibility with larger, more complex neural network architectures.", "title_embedding_index": 20559, "title_abs_embedding_index": 20584}, {"title": "Fine-grained Attention I/O Complexity: Comprehensive  Analysis for Backward Passes", "link_suffix": "/forum?id=Zs8Z3sgnAA", "link": "https://openreview.net/forum?id=Zs8Z3sgnAA", "pdf_link": "https://openreview.net/pdf?id=Zs8Z3sgnAA", "keywords": "Attention, I/O Complexity, FlashAttention, Gradient, Backward Pass", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in processing long-context information. However, the quadratic complexity of attention computation with respect to sequence length poses significant computational challenges, and I/O aware algorithms have been proposed.This paper presents a comprehensive analysis of the I/O complexity for attention mechanisms, focusing on backward passes by categorizing into small and large cache scenarios. \nUsing the red-blue pebble game framework, we establish tight bounds on I/O complexity across all cache sizes. We confirm that the de facto standard I/O aware algorithm FlashAttention is optimal for both forward and backward passes for the large cache size scenario. For small cache sizes, we provide an algorithm that improves over existing methods and achieves the tight bounds. \nAdditionally, we extend our analysis to sparse attention, a mainstream speeding-up approach, deriving fine-grained lower bounds for both forward and backward passes and both small and large caches. \nOur findings complete the theoretical foundation for I/O complexity in attention mechanisms, offering insights for designing efficient algorithms of LLM training and inference.", "title_embedding_index": 20560, "title_abs_embedding_index": 20585}, {"title": "Mirror Descent Actor Critic via Bounded Advantage Learning", "link_suffix": "/forum?id=wXIncJRlK0", "link": "https://openreview.net/forum?id=wXIncJRlK0", "pdf_link": "https://openreview.net/pdf?id=wXIncJRlK0", "keywords": "reinforcement learning, regularization, KL divergence, entropy, actor critic", "abstract": "Regularization is a core component of recent Reinforcement Learning (RL) algorithms. Mirror Descent Value Iteration (MDVI) uses both Kullback-Leibler divergence and entropy as regularizers in its value and policy updates. Despite its empirical success in discrete action domains and strong theoretical garantees, the performance improvement of a MDVI-based method over the entropy-only-regularized RL is limited in continuous action domains. In this study, we propose Mirror Descent Actor Critic (MDAC) as an actor-critic style instantiation of MDVI for continuous action domains, and show that its empirical performance is significantly boosted by bounding the values of actor's log-density terms in the critic's loss function. Further, we relate MDAC to Advantage Learning by recalling that the actor's log-probability is equal to the regularized advantage function in tabular cases, and theoretically show that the error of optimal policy misspecification is decreased by bounding the advantage terms.", "title_embedding_index": 20561, "title_abs_embedding_index": 20586}, {"title": "Differential Privacy of Cross-Attention with Provable Guarantee", "link_suffix": "/forum?id=ZC9KpPXgDI", "link": "https://openreview.net/forum?id=ZC9KpPXgDI", "pdf_link": "https://openreview.net/pdf?id=ZC9KpPXgDI", "keywords": "Differential Privacy, Cross-Attention, Provable Guarantee", "abstract": "Cross-attention has become a fundamental module nowadays in many important artificial intelligence applications, e.g.,\nretrieval-augmented generation (RAG), system prompt, guided stable diffusion, and many more. \nEnsuring cross-attention privacy is crucial and urgently needed because its key and value matrices may contain sensitive information about model providers and their users.\nIn this work, we design a novel differential privacy (DP) data structure to address the privacy security of cross-attention with a theoretical guarantee.\nIn detail, let $n$ be the input token length of system prompt/RAG data, $d$ be the feature dimension, $0 < \\alpha \\le 1$ be the relative error parameter, $R$ be the maximum value of the query and key matrices, $R_w$ be the maximum value of the value matrix, and $r,s,\\epsilon_s$ be parameters of polynomial kernel methods. \nThen, our data structure requires $\\widetilde{O}(ndr^2)$ memory consumption with $\\widetilde{O}(nr^2)$ initialization time complexity and $\\widetilde{O}(\\alpha^{-1} r^2)$ query time complexity for a single token query.\nIn addition, our data structure can guarantee that the process of answering user query satisfies $(\\epsilon, \\delta)$-DP with $\\widetilde{O}(n^{-1} \\epsilon^{-1} \\alpha^{-1/2} R^{2s} R_w r^2)$ additive error and $n^{-1} (\\alpha + \\epsilon_s)$ relative error between our output and the true answer.\nFurthermore, our result is robust to adaptive queries in which users can intentionally attack the cross-attention system. \nTo our knowledge, this is the first work to provide DP for cross-attention and is promising to inspire more privacy algorithm design in large generative models (LGMs).", "title_embedding_index": 20562, "title_abs_embedding_index": 20587}, {"title": "Multi-Layer Transformers Gradient Can be Approximated in Almost Linear Time", "link_suffix": "/forum?id=JgSbMcgd8q", "link": "https://openreview.net/forum?id=JgSbMcgd8q", "pdf_link": "https://openreview.net/pdf?id=JgSbMcgd8q", "keywords": "Multi-Layer Transformers, Attention Acceleration, Gradient Computation", "abstract": "The computational complexity of the self-attention mechanism in popular transformer architectures poses significant challenges for training and inference, and becomes the bottleneck for long inputs. Is it possible to significantly reduce the quadratic time complexity of computing the gradients in multi-layer transformer models? This paper proves that a novel fast approximation method can calculate the gradients in almost linear time $n^{1+o(1)}$ where $n$ is the input sequence length, while it maintains a polynomially small approximation error $1 / \\mathrm{poly}(n)$ across the entire model. \nOur theory holds for general loss functions and when the multi-layer transformer model contains many practical sub-modules, such as residual connection, casual mask, and multi-head attention. \nBy improving the efficiency of gradient computation, we hope that this work will facilitate more effective training and deployment of long-context language models based on our theoretical results.", "title_embedding_index": 20563, "title_abs_embedding_index": 20588}, {"title": "Episodic Novelty Through Temporal Distance", "link_suffix": "/forum?id=I7DeajDEx7", "link": "https://openreview.net/forum?id=I7DeajDEx7", "pdf_link": "https://openreview.net/pdf?id=I7DeajDEx7", "keywords": "Reinforcement Learning", "abstract": "Exploration in sparse reward environments remains a significant challenge in reinforcement learning, particularly in Contextual Markov Decision Processes (CMDPs), where environments differ across episodes. Existing episodic intrinsic motivation methods for CMDPs primarily rely on count-based approaches, which are ineffective in large state spaces, or on similarity-based methods that lack appropriate metrics for state comparison. To address these shortcomings, we propose Episodic Novelty Through Temporal Distance (ETD), a novel approach that introduces temporal distance as a robust metric for state similarity and intrinsic reward computation. By employing contrastive learning, ETD accurately estimates temporal distances and derives intrinsic rewards based on the novelty of states within the current episode. Extensive experiments on various benchmark tasks demonstrate that ETD significantly outperforms state-of-the-art methods, highlighting its effectiveness in enhancing exploration in sparse reward CMDPs.", "title_embedding_index": 20564, "title_abs_embedding_index": 20589}, {"title": "SparseLGS: Fast Language Gaussian Splatting from Sparse Multi-View Images", "link_suffix": "/forum?id=Ts1waOOQjF", "link": "https://openreview.net/forum?id=Ts1waOOQjF", "pdf_link": "https://openreview.net/pdf?id=Ts1waOOQjF", "keywords": "3D Gaussian Splatting; 3D open-vocabulary query; 3D segmentation; sparse view reconstruction;", "abstract": "3D semantic field learning is crucial for applications like autonomous navigation, AR/VR, and robotics, where accurate comprehension of 3D scenes from limited viewpoints is essential. Existing methods struggle under sparse view conditions, relying on inefficient per-scene multi-view optimizations, which are impractical for many real-world tasks. To address this, we propose SparseLGS, a feed-forward method for constructing 3D semantic fields from sparse viewpoints, allowing direct inference of 3DGS-based scenes. By ensuring consistent SAM segmentations through video tracking and using low-dimensional indexing for high-dimensional CLIP features, SparseLGS efficiently embeds language information in 3D space, offering a robust solution for accurate 3D scene understanding under sparse view conditions. In experiments on two-view sparse 3D object querying and segmentation in the LERF and 3D-OVS datasets, SparseLGS outperforms existing methods in chosen IoU, Localization Accuracy, and mIoU. Moreover, our model achieves scene inference in under 30 seconds and open-vocabulary querying in just 0.011 seconds per query.", "title_embedding_index": 20565, "title_abs_embedding_index": 20590}, {"title": "Prompt-guided Visual Perception for Efficient Training-free Video LLM", "link_suffix": "/forum?id=NmmRPUCWIA", "link": "https://openreview.net/forum?id=NmmRPUCWIA", "pdf_link": "https://openreview.net/pdf?id=NmmRPUCWIA", "keywords": "LLM, Multi-modality, VLM, Video", "abstract": "Vision-language large models have achieved remarkable success in various multi-modal tasks, yet applying them to video understanding remains challenging due to the inherent complexity and computational demands of video data. While training-based video-LLMs deliver high performance, they often require substantial resources for training and inference. Conversely, training-free approaches offer a more efficient alternative by adapting pre-trained image-LLMs models for video tasks without additional training, but they face inference efficiency bottlenecks due to the large number of visual tokens generated from video frames. In this work, we present a novel prompt-guided visual perception framework (abbreviated as \\emph{Free Video-LLM}) for efficient inference of training-free video LLMs. The proposed framework decouples spatial-temporal dimension and performs temporal frame sampling and spatial RoI cropping respectively based on task-specific prompts. Our method effectively reduces the number of visual tokens while maintaining high performance across multiple video question-answering benchmarks. Extensive experiments demonstrate that our approach achieves competitive results with significantly fewer tokens, offering an optimal trade-off between accuracy and computational efficiency compared to state-of-the-art video LLMs.", "title_embedding_index": 20566, "title_abs_embedding_index": 20591}, {"title": "Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation", "link_suffix": "/forum?id=yYQLvofQ1k", "link": "https://openreview.net/forum?id=yYQLvofQ1k", "pdf_link": "https://openreview.net/pdf?id=yYQLvofQ1k", "keywords": "Large Language Model, Multi-agent System, Collaboration Strategy, Automatic Scientific Discovery, Science of Science", "abstract": "The rapid advancement of scientific progress requires innovative tools that can accelerate discovery. While recent AI methods, particularly large language models (LLMs), have shown promise in tasks such as hypothesis generation and experimental design, they fall short in replicating the collaborative nature of real-world scientific practices, where diverse teams of experts work together to tackle complex problems. To address the limitation, we propose an LLM-based multi-agent system, i.e., Virtual Scientists (VirSci), designed to mimic the teamwork inherent in scientific research. VirSci organizes a team of agents to collaboratively generate, evaluate, and refine research ideas. Through comprehensive experiments, we demonstrate that this multi-agent approach outperforms the state-of-the-art method in producing novel and impactful scientific ideas, showing potential in aligning with key insights in the Science of Science field. Our findings suggest that integrating collaborative agents can lead to more innovative scientific outputs, offering a robust system for autonomous scientific discovery.", "title_embedding_index": 20567, "title_abs_embedding_index": 20592}, {"title": "ViDiT-Q: Efficient and Accurate Quantization of Diffusion Transformers for Image and Video Generation", "link_suffix": "/forum?id=E1N1oxd63b", "link": "https://openreview.net/forum?id=E1N1oxd63b", "pdf_link": "https://openreview.net/pdf?id=E1N1oxd63b", "keywords": "video generation, low-bit quantization, diffusion model", "abstract": "Diffusion transformers have demonstrated remarkable performance in visual generation tasks, such as generating realistic images or videos based on textual instructions. However, larger model sizes and multi-frame processing for video generation lead to increased computational and memory costs, posing challenges for practical deployment on edge devices. Post-Training Quantization (PTQ) is an effective method for reducing memory costs and computational complexity.\nWhen quantizing diffusion transformers, we find that existing quantization methods face challenges when applied to text-to-image and video tasks. To address these challenges, we begin by systematically analyzing the source of quantization error and conclude with the unique challenges posed by DiT quantization. Accordingly, we design an improved quantization scheme: ViDiT-Q (Video &ImageDiffusionTransformerQuantization), tailored specifically for DiT models. We validate the effectiveness of ViDiT-Q across a variety of text-to-image and video models, achieving W8A8 and W4A8 with negligible degradation in visual quality and metrics. Additionally, we implement efficient GPU kernels to achieve practical 2-2.5x memory optimization and a 1.4-1.7x end-to-end latency speedup.", "title_embedding_index": 20568, "title_abs_embedding_index": 20593}, {"title": "ConLUX: Concept-Based Local Unified Explanations", "link_suffix": "/forum?id=0qrTH5AZVt", "link": "https://openreview.net/forum?id=0qrTH5AZVt", "pdf_link": "https://openreview.net/pdf?id=0qrTH5AZVt", "keywords": "local model-agnostic explanations, post-hoc XAI, concept-based XAI", "abstract": "With the rapid advancements of various machine learning models, there is a significant demand for model-agnostic explanation techniques, which can explain these models across different architectures.\nMainstream model-agnostic explanation techniques generate local explanations based on basic features (e.g., words for text models and (super-)pixels for image models). However, these explanations often do not align with the decision-making processes of the target models and end-users, resulting in explanations that are unfaithful and difficult for users to understand.\nOn the other hand, concept-based techniques provide explanations based on high-level features (e.g., topics for text models and objects for image models), but most are model-specific or require additional pre-defined external concept knowledge. \nTo address this limitation, we propose ConLUX, a general framework to provide concept-based local explanations for any machine learning models. \nOur key insight is that we can automatically extract high-level concepts from large pre-trained models, and uniformly extend existing local model-agnostic techniques to provide unified concept-based explanations.\nWe have instantiated ConLUX on four different types of explanation techniques: LIME, Kernel SHAP, Anchor, and LORE, and applied these techniques to text and image models.\nOur evaluation results demonstrate that 1) compared to the vanilla versions, ConLUX offers more faithful explanations and makes them more understandable to users, and 2) by offering multiple forms of explanations, ConLUX outperforms state-of-the-art concept-based explanation techniques specifically designed for text and image models, respectively.", "title_embedding_index": 20569, "title_abs_embedding_index": 20594}, {"title": "Foundation of Scalable Constraint Learning from Human Feedback", "link_suffix": "/forum?id=zBrjRswpkg", "link": "https://openreview.net/forum?id=zBrjRswpkg", "pdf_link": "https://openreview.net/pdf?id=zBrjRswpkg", "keywords": "RLHF, RL, Constraint Learning, Theoretical Analysis", "abstract": "Constraint learning from human feedback (CLHF) has garnered significant interest in the domain of safe reinforcement learning (RL) due to the challenges associated with designing constraints that elicit desired behaviors. However, a comprehensive theoretical analysis of CLHF is still missing. This paper addresses this gap by establishing a theoretical foundation. Concretely, trajectory-wise feedback, which is the most natural form of feedback, is shown to be helpful only for learning chance constraints. Building on this insight, we propose and theoretically analyze algorithms for CLHF and for solving chance constrained RL problems. Our algorithm is empirically shown to outperform an existing algorithm.", "title_embedding_index": 20570, "title_abs_embedding_index": 20595}, {"title": "Clipping Improves Adam and AdaGrad when the Noise Is Heavy-Tailed", "link_suffix": "/forum?id=8QqQk1c0Dg", "link": "https://openreview.net/forum?id=8QqQk1c0Dg", "pdf_link": "https://openreview.net/pdf?id=8QqQk1c0Dg", "keywords": "stochastic optimization, heavy-tailed noise, adaptive methods, gradient clipping, high-probability convergence bounds", "abstract": "Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for training modern Deep Learning models, especially Large Language Models. Typically, the noise in the stochastic gradients is heavy-tailed for the later ones. Gradient clipping provably helps to achieve good high-probability convergence for such noises. However, despite the similarity between AdaGrad/Adam and Clip-SGD, the current understanding of the high-probability convergence of AdaGrad/Adam-type methods is limited in this case. In this work, we prove that AdaGrad/Adam (and their delayed version) can have provably bad high-probability convergence if the noise is heavy-tailed. We also show that gradient clipping fixes this issue, i.e., we derive new high-probability convergence bounds with polylogarithmic dependence on the confidence level for AdaGrad and Adam with clipping and with/without delay for smooth convex/non-convex stochastic optimization with heavy-tailed noise. Our empirical evaluations highlight the superiority of clipped versions of AdaGrad/Adam in handling the heavy-tailed noise.", "title_embedding_index": 20571, "title_abs_embedding_index": 20596}, {"title": "Do You Keep an Eye on What I Ask? Mitigating Multimodal Hallucination via Attention-Guided Ensemble Decoding", "link_suffix": "/forum?id=ziw5bzg2NO", "link": "https://openreview.net/forum?id=ziw5bzg2NO", "pdf_link": "https://openreview.net/pdf?id=ziw5bzg2NO", "keywords": "Hallucination, Multimodal Hallucination, Large Vision-Language Model", "abstract": "Recent advancements in Large Vision-Language Models (LVLMs) have significantly expanded their utility in tasks like image captioning and visual question answering. However, they still struggle with object hallucination, where models generate descriptions that inaccurately reflect the visual content by including nonexistent objects or misrepresenting existing ones. While previous methods, such as data augmentation and training-free approaches, strive to tackle this issue, they still encounter scalability challenges and often depend on additional external modules. In this work, we propose Ensemble Decoding (ED), a novel strategy that splits the input image into sub-images and combines logit distributions by assigning weights through the attention map. Furthermore, we introduce ED adaptive plausibility constraint to calibrate logit distribution and FastED, a variant designed for speed-critical applications. Extensive experiments across hallucination benchmarks demonstrate that our proposed method achieves state-of-the-art performance, validating the effectiveness of our approach.", "title_embedding_index": 20572, "title_abs_embedding_index": 20597}, {"title": "Decouple-Then-Merge: Towards Better Training for Diffusion Models", "link_suffix": "/forum?id=Y0P6cOZzNm", "link": "https://openreview.net/forum?id=Y0P6cOZzNm", "pdf_link": "https://openreview.net/pdf?id=Y0P6cOZzNm", "keywords": "Diffusion Model, Image Synthesis", "abstract": "Diffusion models are trained by learning a sequence of models that reverse each step of noise corruption. Typically, the model parameters are fully shared across multiple timesteps to enhance training efficiency. However, since the denoising tasks differ at each timestep, the gradients computed at different timesteps may conflict, potentially degrading the overall performance of image generation. To solve this issue, this work proposes a $\\textbf{De}$couple-then-$\\textbf{Me}$rge ($\\textbf{DeMe}$) framework, which begins with a pretrained model and finetunes separate models tailored to specific timesteps. We introduce several improved techniques during the finetuning stage to promote effective knowledge sharing while minimizing training interference across timesteps. Finally, after finetuning, these separate models can be merged into a single model in the parameter space, ensuring efficient and practical inference. Experimental results show significant generation quality improvements upon 6 benchmarks including Stable Diffusion on COCO30K, ImageNet1K, PartiPrompts, and DDPM on LSUN Church, LSUN Bedroom, and CIFAR10. Code is included in the supplementary material and will be released on Github.", "title_embedding_index": 20573, "title_abs_embedding_index": 20598}, {"title": "Enhancing Graph Self-Supervised Learning with Graph Interplay", "link_suffix": "/forum?id=YWTpBisnwd", "link": "https://openreview.net/forum?id=YWTpBisnwd", "pdf_link": "https://openreview.net/pdf?id=YWTpBisnwd", "keywords": "Graph Self-Supervised Learning, Graph Neural Networks", "abstract": "Graph self-supervised learning (GSSL) has emerged as a compelling framework for extracting informative representations from graph-structured data without extensive reliance on labeled inputs.  In this study, we introduce Graph Interplay (GIP), an innovative and versatile approach that significantly enhances the performance equipped with various existing GSSL methods. To this end, GIP advocates direct graph-level communications by introducing random inter-graph edges within standard batches.  Against GIP's simplicity, we further theoretically show that GIP essentially performs a principled manifold separation via combining inter-graph message passing and GSSL, bringing about more structured embedding manifolds and thus benefits a series of downstream tasks. Our empirical study demonstrates that GIP surpasses the performance of prevailing GSSL methods across multiple benchmarks by significant margins, highlighting its potential as a breakthrough approach.  Besides, GIP can be readily integrated into a series of GSSL methods and consistently offers additional performance gain. This advancement not only amplifies the capability of GSSL but also potentially sets the stage for a novel graph learning paradigm in a broader sense.", "title_embedding_index": 20574, "title_abs_embedding_index": 20599}]
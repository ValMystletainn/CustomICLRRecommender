[
    {
        "title": "Chain of Ideas: Revolutionizing Research in Idea Development with LLM Agents",
        "link_suffix": "/forum?id=GHJzxPgFa6",
        "link": "https://openreview.net/forum?id=GHJzxPgFa6",
        "pdf_link": "https://openreview.net/pdf?id=GHJzxPgFa6",
        "keywords": "Large Language Model, Agent, Idea Generation",
        "abstract": "Effective research ideation is a critical step for scientific research. However, the exponential increase in scientific literature makes it challenging for researchers to stay current with recent advances and identify meaningful research directions. Recent developments in large language models~(LLMs) suggest a promising avenue for automating the generation of novel research ideas. However, existing methods for idea generation either trivially prompt LLMs or directly expose LLMs to extensive literature without indicating useful information.  Inspired by the research process of human researchers, we propose a Chain-of-Ideas (CoI) agent, an LLM-based agent that organizes relevant literature in a chain structure to effectively mirror the progressive development in a research domain. This organization facilitates LLMs to capture the current advancements in research, thereby enhancing their ideation capabilities. Furthermore, we propose Idea Arena, an evaluation protocol that can comprehensively evaluate idea generation methods from different perspectives, aligning closely with the preferences of human researchers. Experimental results indicate that the CoI agent consistently outperforms other methods and shows comparable quality as humans in research idea generation. Moreover, our CoI agent is budget-friendly, with a minimum cost of $0.50 to generate a candidate idea and its corresponding experimental design."
    },
    {
        "title": "PERSONALIZED FEDERATED PARTIAL LABEL LEARNING",
        "link_suffix": "/forum?id=ehlZFDxwJo",
        "link": "https://openreview.net/forum?id=ehlZFDxwJo",
        "pdf_link": "https://openreview.net/pdf?id=ehlZFDxwJo",
        "keywords": "Federated learning, Partial label learning, Weakly supervised learning",
        "abstract": "Partial Label Learning (PLL) is known as a valuable learning technique that trains Machine Learning (ML) models on partial label datasets, where the ground truth label is concealed within the candidate label set of each data instance. It learns label correlation based on a single centralized dataset to predict the latent true label. When data is non-independent and identically distributed (non-i.i.d.) among workers in Federated Learning (FL), the label correlation interference problem occurs. To address the issue, in this paper, we propose pFedPLL, a personalized federated partial label learning algorithm with two new designs. In Label Correlation Isolation (LCI), we first develop a twin-module architecture, where a feature-level correlation matrix layer for each worker is isolated locally to prevent it from being interfered with by others. In Label Correlation Personalization (LCP), we then propose a bi-directional calibration loss to identify a more accurate learning direction, where the positive calibration aligns the prediction result with the latent true label, and the negative calibration pushes away the prediction result that falls into the non-candidate label set. We provide a convergence analysis of pFedPLL with a rate of $O\\left(\\sqrt{\\frac{1}{T}}\\right)$ for smooth non-convex problems. Experiment results demonstrate that pFedPLL outperforms SOTA federated PLL algorithms and the federated version of centralized PLL algorithms across nine datasets."
    },
    {
        "title": "On the Sample Complexity of a Policy Gradient Algorithm with Occupancy Approximation for General Utility Reinforcement Learning",
        "link_suffix": "/forum?id=Gi5aWK8tOx",
        "link": "https://openreview.net/forum?id=Gi5aWK8tOx",
        "pdf_link": "https://openreview.net/pdf?id=Gi5aWK8tOx",
        "keywords": "reinforcement learning with general utilities, policy gradient algorithm",
        "abstract": "Reinforcement learning with general utilities has recently gained attention thanks to its ability to unify several problems, including imitation learning, pure exploration, and safe RL. However, prior work for solving this general problem in a unified way has only focused on the tabular setting. This is restrictive when considering larger state-action spaces because of the need to estimate occupancy measures during policy optimization. In this work, we address this issue and propose to approximate occupancy measures within a function approximation class using maximum likelihood estimation (MLE). We propose a simple policy gradient algorithm (PG-OMA) where an actor updates the policy parameters to maximize the general utility objective whereas a critic approximates the occupancy measure using MLE. We provide a statistical complexity analysis of PG-OMA  showing that our occupancy measure estimation error only scales with the dimension of our function approximation class rather than the size of the state action space. Under suitable assumptions, we establish first order stationarity and global optimality performance bounds for the proposed PG-OMA algorithm for nonconcave and concave general utilities respectively. We complement our methodological and theoretical findings with promising empirical results showing the scalability potential of our approach compared to existing tabular count-based approaches."
    },
    {
        "title": "An Empirical Study on Reconstructing Scientific History to Forecast Future Trends",
        "link_suffix": "/forum?id=lxMlenl3XU",
        "link": "https://openreview.net/forum?id=lxMlenl3XU",
        "pdf_link": "https://openreview.net/pdf?id=lxMlenl3XU",
        "keywords": "LLM, TKG, Research-Assistant AI, Academic History Tracing, Research Future Prediction",
        "abstract": "The advancement of scientific knowledge relies on synthesizing prior research to forecast future developments, a task that has become increasingly intricate. The emergence of large language models (LLMs) offers a transformative opportunity to automate and streamline this process, enabling faster and more accurate academic discovery. However, recent attempts either limit to producing surveys or focus overly on downstream tasks. To this end, we introduce a novel task that bridges two key challenges: the comprehensive synopsis of past research and the accurate prediction of emerging trends, dubbed $\\textit{Dual Temporal Research Analysis}$. This dual approach requires not only an understanding of historical knowledge but also the ability to predict future developments based on detected patterns. To evaluate, we present an evaluation benchmark encompassing 20 research topics and 210 key AI papers, based on the completeness of historical coverage and predictive reliability. We further draw inspirations from dual-system theory and propose a framework $\\textit{HorizonAI}$ which utilizes a specialized temporal knowledge graph for papers, to capture and organize past research patterns (System 1), while leveraging LLMs for deeper analytical reasoning (System 2) to enhance both summarization and prediction. Our framework demonstrates a robust capacity to accurately summarize historical research trends and predict future developments, achieving significant improvements in both areas. For summarizing historical research, we achieve a 18.99% increase over AutoSurvey; for predicting future developments, we achieve a 10.37% increase over GPT-4o."
    },
    {
        "title": "u-\u03bcP: The Unit-Scaled Maximal Update Parametrization",
        "link_suffix": "/forum?id=P7KRIiLM8T",
        "link": "https://openreview.net/forum?id=P7KRIiLM8T",
        "pdf_link": "https://openreview.net/pdf?id=P7KRIiLM8T",
        "keywords": "maximal update parametrization, learning dynamics, hyperparameter transfer, efficiency, training, stability, scaling, numerics, fp8, low precision",
        "abstract": "The Maximal Update Parametrization ($\\mu$P) aims to make the optimal hyperparameters (HPs) of a model independent of its size, allowing them to be swept using a cheap proxy model rather than the full-size target model. We present a new scheme, u-$\\mu$P, which improves upon $\\mu$P by combining it with Unit Scaling, a method for designing models that makes them easy to train in low-precision. The two techniques have a natural affinity: $\\mu$P ensures that the scale of activations is independent of model size, and Unit Scaling ensures that activations, weights and gradients begin training with a scale of one. This synthesis opens the door to a simpler scheme, whose default values are near-optimal. This in turn facilitates a more efficient sweeping strategy, with u-$\\mu$P models reaching a lower loss than comparable $\\mu$P models and working out-of-the-box in FP8."
    },
    {
        "title": "Measurement Manipulation of the Matrix Sensing Problem to Improve Optimization Landscape",
        "link_suffix": "/forum?id=Jyrwd2wja9",
        "link": "https://openreview.net/forum?id=Jyrwd2wja9",
        "pdf_link": "https://openreview.net/pdf?id=Jyrwd2wja9",
        "keywords": "non-convex optimization, low-rank matrix optimization, matrix sensing, preconditioning algorithm",
        "abstract": "This work studies the matrix sensing (MS) problem through the lens of the Restricted Isometry Property (RIP). It has been shown in several recent papers that two different techniques of convex relaxations and local search methods for the MS problem both require the RIP constant to be less than 0.5 while most real-world problems have their RIPs close to 1. The existing literature guarantees a small RIP constant only for sensing operators having an i.i.d. Gaussian distribution, and it is well-known that the MS problem could have a complicated landscape when the RIP is greater than 0.5. In this work, we address this issue and improve the optimization landscape by developing two results. First, we show that any sensing operator with a model not too distant from i.i.d. Gaussian has a slightly higher RIP than i.i.d. Gaussian, and that its RIP constant can be reduced to match the RIP constant of an i.i.d. Gaussian via slightly increasing the number of measurements. Second, we show that if the sensing operator has an arbitrary distribution, it can be modified in such a way that the resulting operator will act as a perturbed Gaussian with a lower RIP constant. Our approach is a preconditioning technique that replaces each sensing matrix with a weighted sum of all sensing matrices. We numerically demonstrate that the RIP constants for different distributions can be reduced from almost 1 to less than 0.5 via the preconditioning of the sensing operator."
    },
    {
        "title": "Towards Synergistic Path-based Explanations for Knowledge Graph Completion: Exploration and Evaluation",
        "link_suffix": "/forum?id=WQvkqarwXi",
        "link": "https://openreview.net/forum?id=WQvkqarwXi",
        "pdf_link": "https://openreview.net/pdf?id=WQvkqarwXi",
        "keywords": "Knowledge Graph Completion, Model Explainability, Knowledge Graph Embedding, Link Prediction",
        "abstract": "Knowledge graph completion (KGC) aims to alleviate the inherent incompleteness of knowledge graphs (KGs), a crucial task for numerous applications such as recommendation systems and drug repurposing. The success of knowledge graph embedding (KGE) models provokes the question about the explainability: ``\\textit{Which the patterns of the input KG are most determinant to the prediction}?'' Particularly, path-based explainers prevail in existing methods because of their strong capability for human understanding. In this paper, based on the observation that a fact is usually determined by the synergy of multiple reasoning chains, we propose a novel explainable framework, dubbed KGExplainer, to explore synergistic pathways. KGExplainer is a model-agnostic approach that employs a perturbation-based greedy search algorithm to identify the most crucial synergistic paths as explanations within the local structure of target predictions. To evaluate the quality of these explanations, KGExplainer distills an evaluator from the target KGE model, allowing for the examination of their fidelity. We experimentally demonstrate that the distilled evaluator has comparable predictive performance to the target KGE. Experimental results on benchmark datasets demonstrate the effectiveness of KGExplainer, achieving a human evaluation accuracy of 83.3% and showing promising improvements in explainability. Code is available at \\url{https://anonymous.4open.science/r/KGExplainer-33A0}"
    },
    {
        "title": "BrightDreamer: Generic 3D Gaussian Generative Framework for Fast Text-to-3D Synthesis",
        "link_suffix": "/forum?id=BqbeJzN9Ie",
        "link": "https://openreview.net/forum?id=BqbeJzN9Ie",
        "pdf_link": "https://openreview.net/pdf?id=BqbeJzN9Ie",
        "keywords": "Text-to-3D Generation",
        "abstract": "Text-to-3D synthesis has recently seen intriguing advances by combining the text-to-image models with 3D representation methods, e.g., Gaussian Splatting (GS), via Score Distillation Sampling (SDS). However, a hurdle of existing methods is the low efficiency, per-prompt optimization for a single 3D object. Therefore, it is imperative for a paradigm shift from per-prompt optimization to one-stage generation for any unseen text prompts, which yet remains challenging. A hurdle is how to directly generate a set of millions of 3D Gaussians to represent a 3D object. This paper presents BrightDreamer, an end-to-end single-stage approach that can achieve generalizable and fast (77 ms) text-to-3D generation. Our key idea is to formulate the generation process as estimating the 3D deformation from an anchor shape with predefined positions. For this, we first propose a Text-guided Shape Deformation (TSD) network to predict the deformed shape and its new positions, used as the centers (one attribute) of 3D Gaussians. To estimate the other four attributes (i.e., scaling, rotation, opacity, and SH coefficient), we then design a novel Text-guided Triplane Generator (TTG) to generate a triplane representation for a 3D object. The center of each Gaussian enables us to transform the triplane feature into the four attributes. The generated 3D Gaussians can be finally rendered at 705 frames per second. Extensive experiments demonstrate the superiority of our method over existing methods. Also, BrightDreamer possesses a strong semantic understanding capability even for complex text prompts."
    },
    {
        "title": "Priority on High-Quality: Instruction Data Selection for Optimized Instruction Tuning",
        "link_suffix": "/forum?id=7qMrDf9zFU",
        "link": "https://openreview.net/forum?id=7qMrDf9zFU",
        "pdf_link": "https://openreview.net/pdf?id=7qMrDf9zFU",
        "keywords": "Instruction Data Selection, Instruction Tuning, Large Language Models, High-quality",
        "abstract": "Large Language Models (LLMs) have demonstrated a remarkable understanding of language nuances through instruction tuning, enabling them to effectively tackle various natural language processing tasks. Previous research on instruction tuning mainly focused on the quantity of instruction data. Recent studies indicate that the quality of instruction data is more significant than the quantity of data. Even selecting a small amount of high-quality data can achieve optimal fine-tuning effects. However, existing selection methods have severe limitations in defining the quality of each instruction data and considering the balance between data quality and data diversity. To address these challenges, we propose a strategy that utilizes noise injection to identify the quality of instruction data. We also implement the strategy of combining inter-class diversity and intra-class diversity to improve model performance. Experimental results demonstrate that our method significantly outperforms the model trained on the full dataset when utilizing only 12% of the entire dataset. Our study provides a new perspective on noise injection in the field of instruction tuning, and also illustrates that a high-quality instruction dataset should possess both quality and diversity. Additionally, we have published our selected high-quality instruction data."
    },
    {
        "title": "Physics-Informed Weakly Supervised Learning for Interatomic Potentials",
        "link_suffix": "/forum?id=qfU5S4cddQ",
        "link": "https://openreview.net/forum?id=qfU5S4cddQ",
        "pdf_link": "https://openreview.net/pdf?id=qfU5S4cddQ",
        "keywords": "machine learning interatomic potential, weakly supervised learning, machine learning for science",
        "abstract": "Machine learning plays an increasingly important role in computational chemistry and materials science, complementing computationally intensive ab initio and first-principles methods. Despite their utility, machine-learning models often lack generalization capability and robustness during atomistic simulations, yielding unphysical energy and force predictions that hinder their real-world applications. We address this challenge by introducing a physics-informed, weakly supervised approach for training machine-learned interatomic potentials (MLIPs). We introduce two novel loss functions, extrapolating the potential energy via a Taylor expansion and using the concept of conservative forces. Our approach improves the accuracy of MLIPs applied to training tasks with sparse training data sets and reduces the need for pre-training computationally demanding models with large data sets. Particularly, we perform extensive experiments demonstrating reduced energy and force errors---often lower by a factor of two---for various baseline models and benchmark data sets. Moreover, we demonstrate improved robustness during MD simulations of the MLIP models trained with the proposed weakly supervised loss.\n    Finally, we show that our approach facilitates MLIPs' training in a setting where the computation of forces is infeasible at the reference level, such as those employing complete-basis-set extrapolation. An implementation of our method and scripts for executing experiments are available at \\url{https://anonymous.4open.science/r/PICPS-ML4Sci-1E8F}."
    },
    {
        "title": "SCALE: Augmenting Content Analysis via LLM Agents and AI-Human Collaboration",
        "link_suffix": "/forum?id=2miMc8FR0j",
        "link": "https://openreview.net/forum?id=2miMc8FR0j",
        "pdf_link": "https://openreview.net/pdf?id=2miMc8FR0j",
        "keywords": "Content Analysis, Large Language Model, Multiagent, Simulation, Computational Social Science, AI for Science",
        "abstract": "Content analysis is a fundamental social science research method that breaks down complex, unstructured texts into theory-informed numerical categories. It has been widely applied across social science disciplines such as political science, media and communication, sociology, and psychology for over a century. This process often relies on multiple rounds of manual annotation and discussion. While rigorous,  content analysis is domain knowledge-dependent, labor-intensive, and time-consuming, posing challenges of subjectivity and scalability. In this paper, we introduce SCALE, a transformative multi-agent framework to $\\underline{\\textbf{S}}$imulate $\\underline{\\textbf{C}}$ontent $\\underline{\\textbf{A}}$nalysis via large language model ($\\underline{\\textbf{L}}$LM) ag$\\underline{\\textbf{E}}$nts. This framework automates key phases including text coding, inter-agent discussion, and dynamic codebook updating, capturing human researchers' reflective depth and adaptive discussions. It also incorporates human intervention, enabling different modes of AI-human expert collaboration to mitigate algorithmic bias and enhance contextual sensitivity. Extensive evaluations across real-world datasets demonstrate that SCALE exhibits versatility across diverse contexts and approximates human judgment in complex annotation tasks commonly required for content analysis. Our findings have the potential to transform social science and machine learning by demonstrating how an appropriately designed multi-agent system can automate complex, domain-expert-dependent interactions and generate large-scale, quality outputs invaluable for social scientists."
    },
    {
        "title": "Novel Kernel Models and Uniform Convergence Bounds for Neural Networks Beyond the Over-Parameterized Regime",
        "link_suffix": "/forum?id=kOtFuzoA93",
        "link": "https://openreview.net/forum?id=kOtFuzoA93",
        "pdf_link": "https://openreview.net/pdf?id=kOtFuzoA93",
        "keywords": "uniform convergence, reproducing kernel banach space, reproducing kernel hilbert space, relu, resnet",
        "abstract": "This paper presents two models - called global and local models - of neural-networks applicable to neural networks of arbitrary width, depth and topology, assuming only finite-energy neural activations.  The first model is exact (un-approximated) and global (applicable for arbitrary weights), casting the neural network in reproducing kernel Banach space (RKBS).  This leads to a width-independent (under usual scaling) bound on the Rademacher complexity of neural networks in terms of the spectral-norm of the weight matrices, which is depth-independent with mild assumptions.  For illustrative purposes we consider how this bound may be applied to untrained networks with LeCun, He and Glorot initialization, discuss their connect to width and depth dependence in the complexity bound, and suggest a modified He initialization that gives a depth-independent complexity bound whp.  The second model is exact and local, casting the change in neural network function resulting from a bounded change in weights and biases (ie. a training step) in reproducing kernel Hilbert space (RKHS) with a well-defined local-intrinsic neural kernel (LiNK).  The neural tangent kernel (NTK) is shown to be a first-order approximation of the LiNK, so the local model gives insight into how the NTK model may be generalized outside of the over-parameterized limit.  Analogous to the global model, a bound on the Rademacher complexity of network adaptation is obtained from the local model, providing insight into the benefits of network adaptation algorithms such as LoRA.  Throughout the paper (a) dense feed-forward ReLU networks and (b) residual networks (ResNet) are used as illustrative examples and to provide insight into their operation and properties."
    },
    {
        "title": "MULAN: Multimodal Protein Language Model for Sequence and Structure Encoding",
        "link_suffix": "/forum?id=uXLXq4ugAy",
        "link": "https://openreview.net/forum?id=uXLXq4ugAy",
        "pdf_link": "https://openreview.net/pdf?id=uXLXq4ugAy",
        "keywords": "Protein language model, protein structure, multimodal model, downstream tasks",
        "abstract": "Most protein language models (PLMs), which produce high-quality protein representations, use only protein sequences during training.\nHowever, the known protein structure is crucial in many protein property prediction tasks, so there is a growing interest in incorporating the knowledge about the protein structure into a PLM. Currently, structure-aware PLMs are trained from scratch or introduce a huge parameter overhead for the structure encoder. In this study, we propose MULAN, a MULtimodal PLM for both sequence and ANgle-based structure encoding. MULAN has a pre-trained sequence encoder and an introduced parameter-efficient Structure Adapter, which are then fused and trained together. According to the evaluation on 9 downstream tasks, MULAN models of various sizes show quality improvement compared to both sequence-only ESM2 and structure-aware SaProt as well as comparable performance to Ankh, ESM3, ProstT5, and other PLMs considered in the study. Importantly, unlike other models, MULAN offers a cheap increase in the structural awareness of the protein representations due to finetuning of existing PLMs instead of training from scratch. We perform a detailed analysis of the proposed model and demonstrate its awareness of the protein structure."
    },
    {
        "title": "Simple Yet Efficient Locality Sensitive Hashing with Theoretical Guarantee",
        "link_suffix": "/forum?id=BvQkjCnXXr",
        "link": "https://openreview.net/forum?id=BvQkjCnXXr",
        "pdf_link": "https://openreview.net/pdf?id=BvQkjCnXXr",
        "keywords": "Locality-sensitive hashing, random sampling, machine learning",
        "abstract": "Locality-sensitive hashing (LSH) is an effective randomized technique widely used in many machine learning tasks such as outlier detection, neural network training and nearest neighbor search. The cost of hashing is the main performance bottleneck of these applications because the index construction functionality, a core component dominating the end-to-end latency, involves the evaluation of a large number of hash functions. Surprisingly, however, little work has been done to improve the efficiency of LSH computation. In this paper, we design a simple yet efficient LSH scheme, named FastLSH, by combining random sampling and random projection. FastLSH reduces the hashing complexity from $O(n)$ to $O(m)$ ($m<n$), where $n$ is the data dimensionality and $m$ is the number of sampled dimensions. More importantly, FastLSH has provable LSH property, which distinguishes it from the non-LSH fast sketches. To demonstrate its broad applicability, we conduct comprehensive experiments over three machine learning tasks, i.e., outlier detection, neural network training and nearest neighbor search. Experimental results show that algorithms powered by FastLSH provides up to 6.1x, 1.7x and 20x end-to-end speedup in anomaly detection latency, training time and index construction, respectively. The source code is available athttps://anonymous.4open.science/r/FastLSHForMachineLearning-7CAC."
    },
    {
        "title": "InstaRevive: One-Step Image Enhancement via Dynamic Score Matching",
        "link_suffix": "/forum?id=G1CN7R5qwE",
        "link": "https://openreview.net/forum?id=G1CN7R5qwE",
        "pdf_link": "https://openreview.net/pdf?id=G1CN7R5qwE",
        "keywords": "Image Enhancement, Diffusion model, Score Distillation",
        "abstract": "Image enhancement finds wide-ranging applications in real-world scenarios due to complex environments and the inherent limitations of imaging devices. Recent diffusion-based methods yield promising outcomes but necessitate prolonged and computationally intensive iterative sampling. In response, we propose InstaRevive, a straightforward yet powerful image enhancement framework that employs score-based diffusion distillation to harness potent generative capability and minimize the sampling steps. To fully exploit the potential of the pre-trained diffusion model, we devise a practical and effective diffusion distillation pipeline using dynamic noise control to address inaccuracies in updating direction during score matching. Our noise control strategy enables a dynamic diffusing scope, facilitating precise learning of denoising trajectories within the diffusion model and ensuring accurate distribution matching gradients during training. Additionally, to enrich guidance for the generative power, we incorporate textual prompts via image captioning as auxiliary conditions, fostering further exploration of the diffusion model. Extensive experiments substantiate the efficacy of our framework across a diverse array of challenging tasks and datasets, unveiling the compelling efficacy and efficiency of InstaRevive in delivering high-quality and visually appealing results."
    },
    {
        "title": "Online Pre-Training for Offline-to-Online Reinforcement Learning",
        "link_suffix": "/forum?id=sxus3NNiuf",
        "link": "https://openreview.net/forum?id=sxus3NNiuf",
        "pdf_link": "https://openreview.net/pdf?id=sxus3NNiuf",
        "keywords": "Reinforcement Learning, Offline-to-Online Reinforcement Learning, Online Pre-Training, Online Fine-Tuning",
        "abstract": "Reinforcement Learning (RL) has achieved notable success in tasks requiring complex decision making, with offline RL offering the ability to train agents using fixed datasets, thereby avoiding the risks and costs associated with online interactions. However, offline RL is inherently limited by the quality of the dataset, which can restrict an agent\u2019s performance. Offline-to-online RL aims to bridge the gap between the cost-efficiency of offline RL and the performance potential of online RL by pre-training an agent offline before fine-tuning it through online interactions. Despite its promise, recent studies show that offline pre-trained agents often underperform during online fine-tuning due to inaccurate value function, with random initialization proving more effective in certain cases. In this work, we propose a novel method, Online Pre-Training for Offline-to-Online RL (OPT), to address the issue of inaccurate value estimation in offline pre-trained agents. OPT introduces a new learning phase, Online Pre-Training, which allows the training of a new value function that enhances the subsequent fine-tuning process. Implementation of OPT on TD3 and SPOT demonstrates an average 30% improvement in performance across D4RL environments, such as MuJoCo, Antmaze, and Adroit."
    },
    {
        "title": "LLM Unlearning via Loss Adjustment with Only Forget Data",
        "link_suffix": "/forum?id=6ESRicalFE",
        "link": "https://openreview.net/forum?id=6ESRicalFE",
        "pdf_link": "https://openreview.net/pdf?id=6ESRicalFE",
        "keywords": "LLM Unlearning, Responsible AI",
        "abstract": "Unlearning in Large Language Models (LLMs) is essential for ensuring ethical and responsible AI use, especially in addressing privacy leak, bias, safety, and evolving regulations. Existing approaches to LLM unlearning often rely on retain data or a reference LLM, yet they struggle to adequately balance unlearning performance with overall model utility. This challenge arises because leveraging explicit retain data or implicit knowledge of retain data from a reference LLM to fine-tune the model tends to blur the boundaries between the forgotten and retain data, as different queries often elicit similar responses. In this work, we propose eliminating the need to retain data or the reference LLM for response calibration in LLM unlearning. Recognizing that directly applying gradient ascent on the forget data often leads to optimization instability and poor performance, our method guides the LLM on what not to respond to, and importantly, how to respond, based on the forget data. Hence, we introduce Forget data only Loss AjustmenT (FLAT), a \"flat\" loss adjustment approach which addresses these issues by maximizing $f$-divergence between the available template answer and the forget answer only w.r.t. the forget data. The variational form of the defined $f$-divergence theoretically provides a way of loss adjustment by assigning different importance weights for the learning w.r.t. template responses and the forgetting of responses subject to unlearning. Empirical results demonstrate that our approach not only achieves superior unlearning performance compared to existing methods but also minimizes the impact on the model\u2019s retained capabilities, ensuring high utility across diverse tasks, including copyrighted content unlearning on Harry Potter dataset and MUSE Benchmark, and entity unlearning on the TOFU dataset."
    },
    {
        "title": "AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization",
        "link_suffix": "/forum?id=nbngu7H3ko",
        "link": "https://openreview.net/forum?id=nbngu7H3ko",
        "pdf_link": "https://openreview.net/pdf?id=nbngu7H3ko",
        "keywords": "Adversarial defense, Adversarial attacks, Large Vision-Language Models, Preference optimization",
        "abstract": "Large Vision-Language Models (LVLMs), such as GPT-4 and LLaVA, have recently witnessed remarkable advancements and are increasingly being deployed in real-world applications. \nHowever, inheriting the sensitivity of visual neural networks, LVLMs remain vulnerable to adversarial attacks, which can result in erroneous or malicious outputs. \nWhile existing efforts utilize adversarial fine-tuning to enhance robustness, they often suffer from performance degradation on clean inputs. \nIn this paper, we proposes AdPO, a novel adversarial defense strategy for LVLMs based on preference optimization. \nPreference optimization methods, such as DPO and RLHF, have been widely used to align large language models (LLMs) with human values and preferences. \nFor the first time, we reframe adversarial training as a preference optimization problem, aiming to enhance the model\u2019s preference for generating normal outputs on clean inputs while rejecting the potential misleading outputs for adversarial examples.\nNotably, AdPO achieves this by solely modifying the image encoder, e.g., CLIP ViT, resulting in superior robustness across a range of downstream tasks (including LVLMs and zero-shot classification).\nOur comprehensive experimental validation confirms the efficacy of the proposed AdPO, which outperforms prior state-of-the-art methods."
    },
    {
        "title": "MetaDD: Boosting Dataset Distillation with Neural Network Architecture-Invariant Generalization",
        "link_suffix": "/forum?id=hKZfzVZ999",
        "link": "https://openreview.net/forum?id=hKZfzVZ999",
        "pdf_link": "https://openreview.net/pdf?id=hKZfzVZ999",
        "keywords": "Dataset Distillation, Class Active Map",
        "abstract": "Dataset distillation (DD) entails creating a refined, compact distilled dataset from a large-scale dataset to facilitate efficient training. A significant challenge in DD is the dependency between the distilled dataset and the neural network (NN) architecture used. Training a different NN architecture with a distilled dataset distilled using a specific architecture often results in diminished trainning performance for other architectures. This paper introduces MetaDD, designed to enhance the generalizability of DD across various NN architectures. Specifically, MetaDD partitions distilled data into meta features (i.e., the data's common characteristics that remain consistent across different NN architectures) and heterogeneous features (i.e., the data's unique feature to each NN architecture). Then, MetaDD employs an architecture-invariant loss function for multi-architecture feature alignment, which increases meta features and reduces heterogeneous features in distilled data. As a low-memory consumption component, MetaDD can be seamlessly integrated into any DD methodology. Experimental results demonstrate that MetaDD significantly improves performance across various DD methods. On the Distilled Tiny-Imagenet with Sre2L (50 IPC), MetaDD achieves cross-architecture NN accuracy of up to 30.1%, surpassing the second-best method (GLaD) by 1.7%."
    },
    {
        "title": "AI2TALE: An Innovative Information Theory-based Approach for Learning to Localize Phishing Attacks",
        "link_suffix": "/forum?id=3xpTXF5ALZ",
        "link": "https://openreview.net/forum?id=3xpTXF5ALZ",
        "pdf_link": "https://openreview.net/pdf?id=3xpTXF5ALZ",
        "keywords": "Phishing Attacks, Email Phishing Attack Localization, Interpretability and Explainable AI, Deep Learning",
        "abstract": "Phishing attacks remain a significant challenge for detection, explanation, and defense, despite over a decade of research on both technical and non-technical solutions. AI-based phishing detection methods are among the most effective approaches for defeating phishing attacks, providing predictions on the vulnerability label (i.e., phishing or benign) of data. However, they often lack intrinsic explainability, failing to identify the specific information that triggers the classification. To this end, we propose an innovative deep learning-based approach for email (the most common phishing way) phishing attack localization. Our method aims to not only predict the vulnerability label of the email data but also provide the capability to automatically learn and figure out the most important and phishing-relevant information (i.e., sentences) in the phishing email data, offering useful and concise explanations for the identified vulnerability.The extensive experiments on seven diverse real-world email datasets demonstrate the capability and effectiveness of our method in selecting crucial information, enabling accurate detection and offering useful and concise explanations (via the most important and phishing-relevant information triggering the classification) for the vulnerability of phishing emails. Notably, our approach outperforms state-of-the-art baselines by 1.5% to 3.5% on average in Label-Accuracy and Cognitive-True-Positive metrics under a weakly supervised setting, where only vulnerability labels are used without requiring ground truth phishing information."
    },
    {
        "title": "RETRIEVAL-AUGMENTED GENERATION WITH ESTIMATION OF SOURCE RELIABILITY",
        "link_suffix": "/forum?id=J3xRByRqOz",
        "link": "https://openreview.net/forum?id=J3xRByRqOz",
        "pdf_link": "https://openreview.net/pdf?id=J3xRByRqOz",
        "keywords": "Retrieval-augmented Generation (RAG), Trustworthy AI",
        "abstract": "Retrieval-augmented generation (RAG) addresses key limitations of large language models (LLMs), such as hallucinations and outdated knowledge, by incorporating external databases. These databases typically consult multiple sources to encompass up-to-date and various information. However, standard RAG methods often overlook the heterogeneous source reliability in the multi-source database and retrieve documents solely based on relevance, making them prone to propagating misinformation. To address this, we propose Reliability-Aware RAG (RA-RAG) which estimates the reliability of multiple sources and incorporates this information into both retrieval and aggregation processes. Specifically, it iteratively estimates source reliability and true answers for a set of queries with no labelling. Then, it selectively retrieves relevant documents from a few of reliable sources and aggregates them using weighted majority voting, where the selective retrieval ensures scalability while not compromising the performance. We also introduce a benchmark designed to reflect real-world scenarios with heterogeneous source reliability and demonstrate the effectiveness of RA-RAG compared to a set of baselines."
    },
    {
        "title": "A Distributional Approach to Uncertainty-Aware Preference Alignment Using Offline Demonstrations",
        "link_suffix": "/forum?id=RKOAU5ti1y",
        "link": "https://openreview.net/forum?id=RKOAU5ti1y",
        "pdf_link": "https://openreview.net/pdf?id=RKOAU5ti1y",
        "keywords": "Preference-based Reinforcement Learning, Distributional Reinforcement Learning, Uncertainty Awareness",
        "abstract": "Designing reward functions in Reinforcement Learning (RL) often demands significant task-specific expertise. Offline preference-based Reinforcement Learning (PbRL) provides an effective alternative to address the complexity of reward design by learning policies from offline datasets that contain human preferences between trajectory pairs. Existing offline PbRL studies typically model a reward function by maximizing its likelihood of generating the observed human preferences. However, due to the varying number of samples within the limited dataset, less frequently compared trajectories exhibit greater uncertainty, which potentially leads to unrelible behaviors during reward and policy updates. To solve this issue, in this work, we introduce Uncertainty-Aware PbRL (UA-PbRL) to learn a distributional reward model and a risk-sensitive policy from an offline preference dataset. Our approach employs a Maximum A Posteriori (MAP) objective to update trajectory rewards and incorporates an informative prior to account for the uncertainties. Building upon this reward update, we propose a generative reward model to capture the reward distribution, utilizing the offline distributional Bellman operator and the Conditional Value-at-Risk (CVaR) metric to train a risk-sensitive policy. Experimental results demonstrate that UA-PbRL effectively identifies and avoids states with high uncertainty, facilitating risk-averse behaviors across various tasks, including robot control and language model alignment."
    },
    {
        "title": "FCVL: Fourier Cross-View Learning for Generalizable 3D Object Detection in Bird\u2019s Eye View",
        "link_suffix": "/forum?id=8SaFvd4sj2",
        "link": "https://openreview.net/forum?id=8SaFvd4sj2",
        "pdf_link": "https://openreview.net/pdf?id=8SaFvd4sj2",
        "keywords": "Single Domain Generalization\uff0c3D Object Detection\uff0cBird\u2019s Eye View",
        "abstract": "Improving the generalization of Birds' Eye View (BEV) detection models is essential for safe driving in real world. In this paper, we consider a realistic yet more challenging scenario, which aims to improve the generalization with single source data for training, as collecting multiple source data is time-consuming and labor intensive in autonomous driving. To achieve this, we rethink the task from a frequency perspective and exploit the cross-view consistency between adjacent perspectives. We propose the Fourier Cross-View Learning (FCVL) framework including Fourier Hierarchical Augmentation (FHiAug), an augmentation strategy in frequency domain to boost domain diversity and Fourier Cross-View Semantic Consistency Loss to facilitate the model to learn more domain-invariant features. Furthermore, we provide theoretical guarantees via augmentation graph theory. To the best of our knowledge, this is the first study to explore generalizable 3D Object Detection in BEV with single source data, and extensive experiments on various testing domains have demonstrated that our approach achieves the best performance on various test domains with single source data."
    },
    {
        "title": "Balancing Gradient Frequencies Facilitates Inductive Inference in Algorithmic Reasoning",
        "link_suffix": "/forum?id=ZGyapLnDb7",
        "link": "https://openreview.net/forum?id=ZGyapLnDb7",
        "pdf_link": "https://openreview.net/pdf?id=ZGyapLnDb7",
        "keywords": "Algorithmic Reasoning, Inductive Inference, Spurious Correlation, Out-of-Distribution Generalization, Optimization",
        "abstract": "Inductive inference, or extrapolation of general rules from finite instances, is understood to be the foundation of human intelligence. Unfortunately, Deep Neural Networks (DNNs) struggle with inductive inference and thus fail to learn even the simplest algorithms in Algorithmic Reasoning (AR). Existing research efforts on AR with DNNs are limited to those on the architectural design for DNNs. In this study, we investigate the influence of optimization techniques on AR performance. Through toy experiments designed to understand an optimizer's susceptibility to shortcuts in AR, we reveal that Adam, the naive choice of optimization, is easily fooled by spurious correlations. To overcome this shortcoming of Adam, we propose a novel optimizer that avoids spurious correlations by balancing gradients of low- and high-frequencies (BGF). We present extensive experiments and analyses to demonstrate the broad and multifaceted advantages of BGF across various architectures and AR tasks. In particular, BGF expands the AR capability of all explored DNN models and even shows the potential to enable learning of tasks that they previously failed at. The observed success of BGF in climbing the Chomsky hierarchy underscores the importance of optimization for developing advanced artificial intelligence with DNNs."
    },
    {
        "title": "Curvature Enhanced Manifold Sampling",
        "link_suffix": "/forum?id=HYWdlCPtao",
        "link": "https://openreview.net/forum?id=HYWdlCPtao",
        "pdf_link": "https://openreview.net/pdf?id=HYWdlCPtao",
        "keywords": "Manifold learning, Data augmentation, Regression",
        "abstract": "Over-parameterized deep learning models, characterized by their large number of parameters, have demonstrated remarkable performance in various tasks. Despite the potential risk of overfitting, these models often generalize well to unseen data due to effective regularization techniques, with data augmentation being one of the most prominent methods. This strategy has proven effective in classification tasks, where label-preserving transformations are applicable. However, the application of data augmentation in regression problems remains underexplored. Recently, a newmanifold learningapproach for sampling synthetic data has been introduced, and it can be viewed as utilizing a first-order approximation of the data manifold. In this work, we propose to extend this direction by providing the fundamental theory and practical tools for approximating and sampling general data manifolds. Further, we introduce the curvature enhanced manifold sampling (CEMS) data augmentation method for regression. CEMS is based on a second-order encoding of the manifold, facilitating sampling and reconstruction of new points. Through extensive evaluations on multiple datasets and in comparison to several state-of-the-art approaches, we demonstrate that CEMS is superior in in-distribution and out-of-distribution tasks, while incurring only a mild computational overhead."
    }
]
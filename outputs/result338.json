[
    {
        "title": "PostEdit: Posterior Sampling for Efficient Zero-Shot Image Editing",
        "link_suffix": "/forum?id=J8YWCBPgx7",
        "link": "https://openreview.net/forum?id=J8YWCBPgx7",
        "pdf_link": "https://openreview.net/pdf?id=J8YWCBPgx7",
        "keywords": "Measurements, Posterior Sampling, Image Editing, Inversion-free, Trianing-free.",
        "abstract": "In the field of image editing, three core challenges persist: controllability, background preservation, and efficiency. Inversion-based methods rely on time-consuming optimization to preserve the features of the initial images, which results in low efficiency due to the requirement for extensive network inference. Conversely, inversion-free methods lack theoretical support for background similarity, as they circumvent the issue of maintaining initial features to achieve efficiency. As a consequence, none of these methods can achieve both high efficiency and background consistency. To tackle the challenges and the aforementioned disadvantages, we introduce PostEdit, a method that incorporates a posterior scheme to govern the diffusion sampling process. Specifically, a corresponding measurement term related to both the initial features and Langevin dynamics is introduced to optimize the estimated image generated by the given target prompt. Extensive experimental results indicate that the proposed PostEdit achieves state-of-the-art editing performance while accurately preserving unedited regions. Furthermore, the method is both inversion- and training-free, necessitating approximately 1.5 seconds and 18 GB of GPU memory to generate high-quality results."
    },
    {
        "title": "Robotic Programmer: Video Instructed Policy Code Generation for Robotic Manipulation",
        "link_suffix": "/forum?id=baQ0ICrnCR",
        "link": "https://openreview.net/forum?id=baQ0ICrnCR",
        "pdf_link": "https://openreview.net/pdf?id=baQ0ICrnCR",
        "keywords": "robotic manipulation, vision language models, code generation",
        "abstract": "Zero-shot generalization across various robots, tasks and environments remains a significant challenge in robotic manipulation. Policy code generation methods use executable code to connect high-level task descriptions and low-level action sequences, leveraging the generalization capabilities of large language models and atomic skill libraries. In this work, we propose Robotic Programmer (RoboPro), a robotic foundation model, enabling the capability of perceiving visual information and following free-form instructions to perform robotic manipulation with policy code in a zero-shot manner. To address low efficiency and high cost in collecting runtime code data for robotic tasks, we devise Video2Code to synthesize executable code from extensive videos in-the-wild with off-the-shelf vision-language model and code-domain large language model. Extensive experiments show that RoboPro achieves the state-of-the-art zero-shot performance on robotic manipulation in both simulators and real-world environments. Specifically, the zero-shot success rate of RoboPro on RLBench surpasses the state-of-the-art model GPT-4o by 11.6%, which is even comparable to a strong supervised training baseline. Furthermore, RoboPro is robust to different robotic configurations, and demonstrates broad visual understanding in general VQA tasks."
    },
    {
        "title": "Range-Null Latent Prior-guided Consistency Model for Low Light Image Enhancement",
        "link_suffix": "/forum?id=Y8i3rF4Umc",
        "link": "https://openreview.net/forum?id=Y8i3rF4Umc",
        "pdf_link": "https://openreview.net/pdf?id=Y8i3rF4Umc",
        "keywords": "Low light enhancement, Consistency model",
        "abstract": "Low light image enhancement (LLIE) is a challenging task, with most existing models often struggling to adapt to diverse dark environments due to insufficient training datasets. In this paper, we propose a novel unsupervised model called Range-null Latent Prior-guided Consistency Model (RLPCM), which integrates a latent consistency model (LCM) into low light enhancement using Retinex-based range-null space decomposition.RLPCM leverages an off-the-shelf LCM as a generative prior to improve both the latent consistency and realness of enhanced images. Meanwhile, fine-tuning a lighting decoder solely on normal-light images to ensure high fidelity in image space. A key contribution is a simple yet effective global illumination adjustment applied to the range-space component, along with a natural language guidance module to learn the null-space component. This allows for iterative generation to enhance both consistency and realness in just a few steps. Additionally, we present a new UAV low light dataset (UAV-LL) containing 300 image pairs from various UAV scenarios to support comprehensive evaluation. Extensive experiments demonstrate the superior adaptability and effectiveness of our framework across a wide range of low-light environments."
    },
    {
        "title": "The Benefit of Being Bayesian in Online Conformal Prediction",
        "link_suffix": "/forum?id=W6hzM9DMMU",
        "link": "https://openreview.net/forum?id=W6hzM9DMMU",
        "pdf_link": "https://openreview.net/pdf?id=W6hzM9DMMU",
        "keywords": "conformal prediction, online learning, adversarial Bayes",
        "abstract": "Based on the framework of Conformal Prediction (CP), we study the online construction of valid confidence sets given a black-box machine learning model. By converting the target confidence levels into quantile levels, the problem can be reduced to predicting the quantiles (in hindsight) of a sequentially revealed data sequence. Two very different approaches have been studied previously:Direct approach.Assuming the data sequence is iid or exchangeable, one could maintain the empirical distribution of the observed data as an algorithmic belief, and directly predict its quantiles.Indirect approach.As statistical assumptions often do not hold in practice, a recent trend is to consider the adversarial setting and apply first-order online optimization to moving quantile losses (Gibbs and Candes, 2021). It requires knowing the target quantile level beforehand, and suffers from certain validity issues on the obtained confidence sets, due to the associated loss linearization.This paper presents a novel Bayesian CP framework that combines their strengths. Without any statistical assumption, it is able to bothanswer multiple arbitrary confidence level queries online, with provably low regret; andovercome the validity issues suffered by first-order optimization baselines, due to being \"data-centric\" rather than \"iterate-centric\".From a technical perspective, our key idea is to regularize the algorithmic belief of the above direct approach by a Bayesian prior, which \"robustifies\" it by simulating a non-linearizedFollow the Regularized Leader(FTRL) algorithm on the output. For statisticians, this can be regarded as an online adversarial view of Bayesian inference. Importantly, the proposed belief update backbone is shared by prediction heads targeting different confidence levels, bringing practical benefits analogous to the recently proposed concept ofU-calibration(Kleinberg et al., 2023)."
    },
    {
        "title": "CLIP-LAD: Unleash the Potential of CLIP for Few-shot Logical Anomaly Detection",
        "link_suffix": "/forum?id=bESxQeXTlo",
        "link": "https://openreview.net/forum?id=bESxQeXTlo",
        "pdf_link": "https://openreview.net/pdf?id=bESxQeXTlo",
        "keywords": "logical anomaly detection, multi-modal transfer learning",
        "abstract": "Anomaly detection (AD) is crucial for visual inspections, and includes two main types: structural and logical anomalies. Despite growing interest in AD, most methods focus on structural anomalies, while few works address logical anomaly detection (LAD), which requires a global understanding of the context. Leading LAD methods often advocate segmentation algorithms to parse logical relations within images, necessitating extensive training images or elaborate labels, but they undergo significant performance degradation in low-data scenarios. This study explores a practical yet challenging scenario where only few-shot normal images are available. To the end, we introduce CLIP-LAD, a novel, training-free method for few-shot LAD. We propose a coarse-to-fine segmentation process, involving foreground extraction and fine-grained alignment, to progressively harness the CLIP's generalization abilities for LAD. Specifically, we first aggregate visual features into different regions with clear boundaries, benefited from the strong visual coherence in vision transformer (ViT), and leverage coarse prompts to help identify the foreground. Within the foreground, we further conduct per-pixel fine-grained classification with fine prompts to parse different parts of an object. The anomaly scoring is derived from the class histograms in the precise segmentation masks. For comprehensive evaluation, we build up a few-shot LAD benchmark based on the MvTec-LOCO dataset and include a series of comparison methods. Experiments on this benchmark demonstrates our superiority in low-data regime."
    },
    {
        "title": "Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models",
        "link_suffix": "/forum?id=45rvZkJbuX",
        "link": "https://openreview.net/forum?id=45rvZkJbuX",
        "pdf_link": "https://openreview.net/pdf?id=45rvZkJbuX",
        "keywords": "Vision-language alignment, Safety of LVLMs, Toxic Content",
        "abstract": "Vision-language alignment in Large Vision-Language Models (LVLMs) successfully enables LLMs to understand visual input. However, we find that existing vision-language alignment methods fail to transfer the existing safety mechanism for text in LLMs to vision, which leads to vulnerabilities in toxic image. To explore the cause of this problem, we give the insightful explanation of where and how the safety mechanism of LVLMs operates and conduct comparative analysis between text and vision. We find that the hidden states at the specific transformer layers play a crucial role in the successful activation of safety mechanism, while the vision-language alignment at hidden states level in current methods is insufficient. This results in a semantic shift for input images compared to text in hidden states, therefore misleads the safety mechanism. To address this, we propose a novel Text-Guided vision-language Alignment method (TGA) for LVLMs. TGA retrieves the texts related to input vision and uses them to guide the projection of vision into the hidden states space in LLMs. Experiments show that \\textbf{TGA} not only successfully transfers the safety mechanism for text in basic LLMs to vision in vision-language alignment for LVLMs without any safety fine-tuning on the visual modality but also maintains the general performance on various vision tasks (Safe and Good). Code is in supplemental material and will be released on GitHub after acceptance."
    },
    {
        "title": "Neuron-level Balance between Stability and Plasticity in Deep Reinforcement Learning",
        "link_suffix": "/forum?id=bKswCSYkKq",
        "link": "https://openreview.net/forum?id=bKswCSYkKq",
        "pdf_link": "https://openreview.net/pdf?id=bKswCSYkKq",
        "keywords": "reinforcement learning, stability-plasticity dilemma, skill neuron",
        "abstract": "In contrast to the inherent ability of humans to continuously acquire new knowledge, modern deep reinforcement learning (DRL) agents generally encounter a significant challenge: the stability-plasticity dilemma, which refers to the trade-off between retaining existing skills (stability) and learning new knowledge (plasticity). In this study, we propose Neuron-level Balance between Stability and Plasticity (NBSP) to tackle this challenge, by taking inspiration from the observation that both stability and plasticity are integrally linked to the expressive capabilities of networks, which are primarily determined by the behavior of individual neurons. To the best of our knowledge, this is the first work that addresses both stability and plasticity loss simultaneously in DRL at the level of neurons. Specifically, NBSP first (1) defines and identifies RL skill neurons that are crucial for knowledge retention through a goal-oriented method, and then (2) introduces a stability-plasticity balancing mechanism by employing gradient masking and experience replay techniques targeting these neurons to preserve the encoded memory related to existing skills while enhancing the learning capabilities of other neurons. Experimental results on the Meta-World and Atari benchmarks demonstrate that NBSP significantly outperforms existing approaches in balancing stability and plasticity. Furthermore, our findings underscore the pivotal role of the critic within this context, providing valuable insights for future research."
    },
    {
        "title": "RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code",
        "link_suffix": "/forum?id=NiNIthntx7",
        "link": "https://openreview.net/forum?id=NiNIthntx7",
        "pdf_link": "https://openreview.net/pdf?id=NiNIthntx7",
        "keywords": "Language Agents, Benchmarks, Code Generation, Reasoning, State-Awareness, Refactoring, Long-Horizon Tasks, Knowledge Representation",
        "abstract": "Recent advances in language model (LM) agents and function calling have enabled autonomous, feedback-driven systems to solve problems across various digital domains. To better understand the unique limitations of LM agents, we introduce RefactorBench, a benchmark consisting of 100 large handcrafted multi-file refactoring tasks in popular open-source repositories. Solving tasks within RefactorBench requires thorough exploration of dependencies across multiple files and strong adherence to relevant instructions. Every task is defined by 3 natural language instructions of varying specificity and is mutually exclusive, allowing for the chaining of longer pseudo-tasks on the same repository. Baselines on RefactorBench reveal that current LM agents struggle with simple compositional tasks, solving only 18% of tasks with base instructions, in contrast to a human developer with short time constraints solving 87%. Through trajectory analysis, we identify various unique failure modes of LM agents, and further explore the failure mode of tracking past actions. By adapting a baseline agent to condition on representations of state, we achieve a 40.4% improvement in solving RefactorBench tasks. We further extend our state-aware approach to encompass entire digital environments and outline potential directions for future research. RefactorBench aims to support the study of LM agents by providing a set of real-world, multi-hop tasks within the realm of code."
    },
    {
        "title": "Connecting Solutions and Boundary Conditions/Parameters Directly: Solving PDEs in Real Time with PINNs",
        "link_suffix": "/forum?id=Q9OGPWt0Rp",
        "link": "https://openreview.net/forum?id=Q9OGPWt0Rp",
        "pdf_link": "https://openreview.net/pdf?id=Q9OGPWt0Rp",
        "keywords": "Physics-Informed Neural Networks; Partial Differential Equations; PINNs; PDEs",
        "abstract": "Physics-Informed Neural Networks (PINNs) have proven to be important tools for solving both forward and inverse problems of partial differential equations (PDEs). However, PINNs face the retraining challenge in which neural networks need to be retrained once the parameters, or boundary/initial conditions change. To address this challenge, meta-learning PINNs train a meta-model across a range of PDE configurations, and the PINN models for new PDE configurations are then generated directly or fine-tuned from the meta-model. Meta-learning PINNs are confronted with either the issue of generalizing to significantly new PDE configurations or the time-consuming process of fine-tuning. By analyzing the mathematical structure of various PDEs, in this paper we establish the direct and mathematically sound connections between PDE solutions and boundary/initial conditions, sources and parameters. The learnable functions in these connections are trained offline in less than 1 hour in most cases. With these connections, the solutions for new PDE configurations can be obtained directly and vice versa, without retraining and fine-tuning at all. Our experimental results indicate that our methods are comparable to vanilla PINNs in terms of accuracy in forward problems, yet at least 400 times faster than them (even over 800 times faster for variable initial/source problems). In inverse problems, our methods are much more accurate than vanilla PINNs while being 80 times faster. Compared with meta-learning PINNs, our methods are much more accurate and about 20 times faster than fine-tuning. Our inference time is less than half a second in forward problems, and at most 3 seconds in inverse problems (less than half a second for variable initial/source problems of linear PDEs). Our code will be made publicly available upon acceptance."
    },
    {
        "title": "On Erroneous Agreements of CLIP Image Embeddings",
        "link_suffix": "/forum?id=5E6VOD7W0z",
        "link": "https://openreview.net/forum?id=5E6VOD7W0z",
        "pdf_link": "https://openreview.net/pdf?id=5E6VOD7W0z",
        "keywords": "Multimodal Learning, CLIP, LLaVA, cosine similarity, erroneous agreement",
        "abstract": "Recent research suggests that the failure of Vision-Language Models (VLMs) in visual reasoning could be attributed to the CLIP image encoder ambiguously encoding distinct images into embeddings with high cosine similarity, namelyerroneous agreements. In this paper, we show that they are not the sole issue, as multimodal large language models (MLLMs) may extract distinct information even from image embeddings with high cosine similarities. On Subset A of the What'sUp benchmark, where the Left/Right image pairs are embedded by CLIP with average cosine similarity greater than 0.99, CLIP's performance is near random guess. In contrast, LLaVA-1.5-7B, which uses the same image encoder as CLIP, achieves nearly 100% accuracy. This discrepancy is also observed between LLaVA-1.5-7B and CLIP-like models on similar benchmarks. To investigate this performance gap, we conduct controlled experiments to test the effect of varying evaluation methods, training data, and language processing choices. We find that the CLIP image embeddings contain more extractable information than previously suggested, but it is likely obscured by the inadequate vision-language alignment of the CLIP's paradigm. Motivated by this observation, we reconsider the LLaVA-1.5 model on the MMVP benchmark, for which prior work showed that it could not distinguish image pairs with high cosine similarity. We observe a performance gain brought about by an alternative decoding algorithm, which attends more to visual input. Further, we show that the accuracy significantly increases if the model can take both images as input to emphasize their nuanced differences. Both findings indicate that LLaVA-1.5 did not utilize extracted visual information sufficiently. In conclusion, our findings suggest that while improving image encoders could benefit VLMs, there is room to enhance the models with a fixed image encoder through better strategies for extracting and utilizing visual information."
    },
    {
        "title": "Neural Symbolic Regression of Complex Network Dynamics",
        "link_suffix": "/forum?id=RdFpj6z4nE",
        "link": "https://openreview.net/forum?id=RdFpj6z4nE",
        "pdf_link": "https://openreview.net/pdf?id=RdFpj6z4nE",
        "keywords": "network dynamics, symbolic regression, complex network",
        "abstract": "Complex networks describe important structures in nature and society, composed of nodes and the edges that connect them. The evolution of these networks is typically described by dynamics, which are labor-intensive and require expert knowledge to derive. However, because the complex network involves noisy observations from multiple trajectories of nodes, existing symbolic regression methods are either not applicable or ineffective on its dynamics. In this paper, we propose Physically Inspired Neural Dynamics Symbolic Regression (PI-NDSR), a method based on neural networks and genetic programming to automatically learn the symbolic expression of dynamics. Our method consists of two key components: a Physically Inspired Neural Dynamics (PIND) to augment and denoise trajectories through observed trajectory interpolation; and a coordinated genetic search algorithm to derive symbolic expressions. This algorithm leverages references of node dynamics and edge dynamics from neural dynamics to avoid overfitted expressions in symbolic space. We evaluate our method on synthetic datasets generated by various dynamics and real datasets on disease spreading. The results demonstrate that PI-NDSR outperforms the existing method in terms of both recovery probability and error."
    },
    {
        "title": "SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition",
        "link_suffix": "/forum?id=cDd7kg9mkP",
        "link": "https://openreview.net/forum?id=cDd7kg9mkP",
        "pdf_link": "https://openreview.net/pdf?id=cDd7kg9mkP",
        "keywords": "Large language models, Multi-modal, alignment, human activity recognition, sensor, time-series",
        "abstract": "In this work, we bridge the gap between wearable sensor technology and personalized AI assistants by enabling Large Language Models (LLMs) to understand time-series tasks like human activity recognition (HAR). Despite the strong reasoning and generalization capabilities of LLMs, leveraging them for sensor data tasks, such as human activity recognition (HAR), remains largely unexplored. This gap stems from challenges like the lack of semantic context in time-series data, computational limitations, and LLMs' difficulty processing numerical inputs. To address these issues, we introduce SensorLLM, a two-stage framework to unlock LLMs\u2019 potential for sensor data tasks. In the Sensor-Language Alignment Stage, we introduce special tokens for each sensor channel and automatically generate trend-descriptive text to align sensor data with textual inputs, enabling SensorLLM to capture numerical changes, channel-specific information, and sensor data of varying lengths\u2014capabilities that existing LLMs typically struggle with, all without the need for human annotations. Next, in Task-Aware Tuning Stage, we refine the model for HAR classification using the frozen LLM and alignment module, achieving performance on par with or surpassing state-of-the-art models. We further demonstrate that SensorLLM evolves into an effective sensor learner, reasoner, and classifier through Sensor-Language Alignment, enabling it to generalize across diverse datasets for HAR tasks. We strongly believe our work lays the stepstone for future time-series and text alignment research, offering a path toward foundation models for sensor data. Our codes are available athttps://anonymous.4open.science/r/sensorllm_code-E0FC."
    },
    {
        "title": "What can Mamba do for 3D Volumetric Medical Image Segmentation?",
        "link_suffix": "/forum?id=m3cKeqvC7z",
        "link": "https://openreview.net/forum?id=m3cKeqvC7z",
        "pdf_link": "https://openreview.net/pdf?id=m3cKeqvC7z",
        "keywords": "3D Volumetric Medical Image Segmentation, Mamba, Transformer",
        "abstract": "Mamba, with its State Space Model (SSM), offers a more computationally efficient solution than Transformers for long-range dependency modeling. However, there is still a debate about its effectiveness in \\textit{high-resolution 3D medical image} segmentation. \nIn this study, we present a comprehensive investigation into Mamba's capabilities in 3D medical image segmentation by tackling three pivotal questions: Can Mamba replace Transformers? Can it elevate multi-scale representation learning? Is complex scanning necessary to unlock its full potential? We evaluate Mamba\u2019s performance across three large public benchmarks\u2014AMOS, TotalSegmentator, and BraTS. Our findings reveal that UlikeMamba, a U-shape Mamba-based network, consistently surpasses UlikeTrans, a U-shape Transformer-based network, particularly when enhanced with custom-designed 3D depthwise convolutions, boosting accuracy and computational efficiency. Further, our proposed multi-scale Mamba block demonstrates superior performance in capturing both fine-grained details and global context, especially in complex segmentation tasks, surpassing Transformer-based counterparts. We also critically assess complex scanning strategies, finding that simpler methods often suffice, while our Tri-scan approach delivers notable advantages in the most challenging scenarios. By integrating these advancements, we introduce a new network for 3D medical image segmentation, positioning Mamba as a transformative force that outperforms leading models such as nnUNet, CoTr, and U-Mamba, offering competitive accuracy with superior computational efficiency. This study provides key insights into Mamba's unique advantages, paving the way for more efficient and accurate approaches to 3D medical imaging. All code used in the experiments will be made publicly available."
    },
    {
        "title": "Learning Semantic-Enhanced Dual Temporal Adjacent Maps for Video Moment Retrieval",
        "link_suffix": "/forum?id=l3CSCOnGPB",
        "link": "https://openreview.net/forum?id=l3CSCOnGPB",
        "pdf_link": "https://openreview.net/pdf?id=l3CSCOnGPB",
        "keywords": "Computer Vision, Muylti-modal Understanding, Video Grounding",
        "abstract": "Retrieving a specific moment from an untrimmed video via a text description is a central problem in vision-language learning. It is a challenging task due to the sophisticated temporal dependency among moments. Existing methods fail to deal with this issue well since they establish temporal relations of moments in a way that visual content and semantics are coupled. This paper studies temporal dependence schemes that decouple content and semantic information, establishing semantic-enhanced Dual Temporal Adjacent Maps for video moment retrieval, conferred as DTAM. Specifically, DTAM designs two branches to encode visual appearance and semantic knowledge from video clips respectively, where knowledge from the appearance branch is distilled into the semantic branch to help DTAM distinguish features with the same visual content but different semantics with a well-designed semantic-aware contrastive loss. Besides, we also develop a moment-aware mechanism to assist temporal adjacent maps' learning for better video grounding. Finally, extensive experimental results and analysis demonstrate the superiority of the proposed DTAM over existing state-of-the-art approaches on three challenging video moment retrieval benchmarks, i.e., TACoS, Charades-STA, and ActivityNet Captions."
    },
    {
        "title": "TUI: A Conformal Uncertainty Indicator for Continual Test-Time Adaptation",
        "link_suffix": "/forum?id=LGIhipNvCQ",
        "link": "https://openreview.net/forum?id=LGIhipNvCQ",
        "pdf_link": "https://openreview.net/pdf?id=LGIhipNvCQ",
        "keywords": "Continual Test-Time Adaptation, Domain Adaptation, Conformal Prediction",
        "abstract": "Continual Test-Time Adaptation (CTTA) addresses the challenge of adapting models to sequentially changing domains during the testing phase. Since no ground truth labels are provided, existing CTTA methods rely on pseudo-labels for self-adaptation. However, CTTA is prone to error accumulation, where incorrect pseudo-labels can negatively impact subsequent model updates. Critically, during testing, a CTTA method can not detect its mistakes, which may then propagate through further adaptations. In this paper, we propose a simple uncertainty indicator called TUI for the CTTA task based on Conformal Prediction (CP), which generates a set of possible labels for each test sample, ensuring that the true label is included within this set with a given coverage probability. Specifically, since domain shifts can undermine the coverage of predictions, making uncertainty estimation less dependable, we propose compensating for coverage by dynamically measuring the domain difference between the target and source domains in continuously changing environments. Moreover, after estimating uncertainty, we separate reliable test pseudo-labels and use them to discriminatively enhance the adaptation process. Empirical results demonstrate that our algorithm effectively estimates the uncertainty for CTTA under a specified coverage probability and improves adaptation performance across various existing CTTA methods."
    },
    {
        "title": "Not All LLM Reasoners Are Created Equal",
        "link_suffix": "/forum?id=T8PzwgYgmn",
        "link": "https://openreview.net/forum?id=T8PzwgYgmn",
        "pdf_link": "https://openreview.net/pdf?id=T8PzwgYgmn",
        "keywords": "LLM reasoning, Mathematical reasoning, Reasoning Gap, Reasoning Behavior, Evaluating Reasoning",
        "abstract": "We study the depth of grade-school math (GSM) problem-solving capabilities of LLMs. To this end, we evaluate their performance on pairs of existing math word problems together so that the answer to the second problem depends on correctly answering the first problem. Our findings reveal a significant reasoning gap in most LLMs, that is performance difference between solving the compositional pairs and solving each question independently. This gap is more pronounced in smaller, more cost-efficient, and math-specialized models. Moreover, instruction-tuning recipes and code generation have varying effects across LLM sizes, while finetuning on GSM can lead to task overfitting. Our analysis indicates that large reasoning gaps are not because of test-set leakage, but due to distraction from additional context and poor second-hop reasoning. Overall, LLMs exhibit systematic differences in their reasoning abilities, despite what their performance on standard benchmarks indicates."
    },
    {
        "title": "Pseudo-Labels are All You Need for Out-Of-Distribution Detection",
        "link_suffix": "/forum?id=jjjxp9Wgjp",
        "link": "https://openreview.net/forum?id=jjjxp9Wgjp",
        "pdf_link": "https://openreview.net/pdf?id=jjjxp9Wgjp",
        "keywords": "Pseudo-Labels, Unsupervised Out-of-Distribution Detection",
        "abstract": "Detecting out-of-distribution (OOD) samples is a significant challenge in real-world deep-learning applications, such as medical imaging and autonomous driving. Traditional machine learning models, primarily trained on in-distribution (ID) data, often struggle when encountering OOD instances, resulting in unreliable predictions. While supervised OOD detection methods generally outperform unsupervised approaches due to the availability of labeled data, our research uncovers a crucial insight: their success is not necessarily due to recognizing the actual object categories in the images; instead, these methods rely on a specific classification strategy that may not correspond to real-world understanding. Essentially, supervised methods detect OOD samples by identifying the difficulties in classifying unfamiliar data. This challenge is similar to what unsupervised OOD detection methods face, as they also depend on the failure to reconstruct OOD data due to the lack of prior exposure. In this study, we bridge the gap between supervised and unsupervised OOD detection by introducing a novel approach that trains models to classify data into pseudo-categories. We employ self-supervised learning (SSL) to convert raw data into representations, which are then clustered to generate pseudo-labels. These pseudo-labels are subsequently used to train a classifier, enabling its OOD detection capabilities. Experimental results show that our approach surpasses state-of-the-art techniques. Furthermore, by training models on different sets of pseudo-labels derived from the dataset, we enhance the robustness and reliability of our OOD detection method."
    },
    {
        "title": "Efficient Training of Neural Stochastic Differential Equations by Matching Finite Dimensional Distributions",
        "link_suffix": "/forum?id=d4qMoUSMLT",
        "link": "https://openreview.net/forum?id=d4qMoUSMLT",
        "pdf_link": "https://openreview.net/pdf?id=d4qMoUSMLT",
        "keywords": "neural stochastic differential equations, Markov process, scoring rule",
        "abstract": "Neural Stochastic Differential Equations (Neural SDEs) have emerged as powerful mesh-free generative models for continuous stochastic processes, with critical applications in fields such as finance, physics, and biology. Previous state-of-the-art methods have relied on adversarial training, such as GANs, or on minimizing distance measures between processes using signature kernels. However, GANs suffer from issues like instability, mode collapse, and the need for specialized training techniques, while signature kernel-based methods require solving linear PDEs and backpropagating gradients through the solver, whose computational complexity scales quadratically with the discretization steps. In this paper, we identify a novel class of strictly proper scoring rules for comparing continuous Markov processes. This theoretical finding naturally leads to a novel approach called Finite Dimensional Matching (FDM) for training Neural SDEs. Our method leverages the Markov property of SDEs to provide a computationally efficient training objective. This scoring rule allows us to bypass the computational overhead associated with signature kernels and reduces the training complexity from $O(D^2)$ to $O(D)$ per epoch, where $D$ represents the number of discretization steps of the process. We demonstrate that FDM achieves superior performance, consistently outperforming existing methods in terms of both computational efficiency and generative quality."
    },
    {
        "title": "Zero-shot Generalist Graph Anomaly Detection with Unified Neighborhood Prompts",
        "link_suffix": "/forum?id=ZslV4L5AhM",
        "link": "https://openreview.net/forum?id=ZslV4L5AhM",
        "pdf_link": "https://openreview.net/pdf?id=ZslV4L5AhM",
        "keywords": "graph anomaly detection, generalist model, prompt",
        "abstract": "Graph anomaly detection (GAD), which aims to identify nodes in a graph that significantly deviate from normal patterns, plays a crucial role in broad application domains. Existing GAD methods, whether supervised or unsupervised, are one-model-for-one-dataset approaches, i.e., training a separate model for each graph dataset. This limits their applicability in real-world scenarios where training on the target graph data is not possible due to issues like data privacy. To overcome this limitation, we propose a novel zero-shot generalist GAD approachUNPromptthat trains a one-for-all detection model, requiring the training of one GAD model on a single graph dataset and then effectively generalizing to detect anomalies in other graph datasets without any retraining or fine-tuning. The key insight in UNPrompt is that i) the predictability of latent node attributes can serve as a generalized anomaly measure and ii)  highly generalized normal and abnormal graph patterns can be learned via latent node attribute prediction in a properly normalized node attribute space. UNPrompt achieves generalist GAD through two main modules: one module aligns the dimensionality and semantics of node attributes across different graphs via coordinate-wise normalization in a projected space, while another module learns generalized neighborhood prompts that support the use of latent node attribute predictability as an anomaly score across different datasets. Extensive experiments on real-world GAD datasets show that UNPrompt significantly outperforms diverse competing methods under the generalist GAD setting, and it also has strong superiority under the one-model-for-one-dataset setting."
    },
    {
        "title": "Learning Diverse Attacks on Large Language Models for Robust Red-Teaming and Safety Tuning",
        "link_suffix": "/forum?id=1mXufFuv95",
        "link": "https://openreview.net/forum?id=1mXufFuv95",
        "pdf_link": "https://openreview.net/pdf?id=1mXufFuv95",
        "keywords": "red-teaming, LLM, diversity",
        "abstract": "Red-teaming, or identifying prompts that elicit harmful responses, is a critical step in ensuring the safe and responsible deployment of large language models (LLMs). Developing effective protection against many modes of attack prompts requires discovering diverse attacks. Automated red-teaming typically uses reinforcement learning to fine-tune an attacker language model to generate prompts that elicit undesirable responses from a target LLM, as measured, for example, by an auxiliary toxicity classifier. We show that even with explicit regularization to favor novelty and diversity, existing approaches suffer from mode collapse or fail to generate effective attacks. As a flexible and probabilistically principled alternative, we propose to use GFlowNet fine-tuning, followed by a secondary smoothing phase, to train the attacker model to generatediverseandeffectiveattack prompts. We find that the attacks generated by our method are effective against a wide range of target LLMs, both with and without safety tuning, and transfer well between target LLMs. Finally, we demonstrate that models safety-tuned using a dataset of red-teaming prompts generated by our method are robust to attacks from other RL-based red-teaming approaches."
    },
    {
        "title": "TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights",
        "link_suffix": "/forum?id=oF6e2WwxX0",
        "link": "https://openreview.net/forum?id=oF6e2WwxX0",
        "pdf_link": "https://openreview.net/pdf?id=oF6e2WwxX0",
        "keywords": "Large Language Models, Importance Sampling, Preference Learning",
        "abstract": "Direct Preference Optimization (DPO) has been widely adopted for preference alignment of Large Language Models (LLMs) due to its simplicity and effectiveness. \nHowever, DPO is derived as a bandit problem in which the whole response is treated as a single arm, ignoring the importance differences between tokens, which may affect optimization efficiency and make it difficult to achieve optimal results.\nIn this work, we propose that the optimal data for DPO has equal expected rewards for each token in winning and losing responses, as there is no difference in token importance. \nHowever, since the optimal dataset is unavailable in practice, we propose using the original dataset for importance sampling to achieve unbiased optimization. \nAccordingly, we propose a token-level importance sampling DPO objective named TIS-DPO that assigns importance weights to each token based on its reward.\nInspired by previous works, we estimate the token importance weights using the difference in prediction probabilities from a pair of contrastive LLMs. We explore three methods to construct these contrastive LLMs: (1) guiding the original LLM with contrastive prompts, (2) training two separate LLMs using winning and losing responses, and (3) performing forward and reverse DPO training with winning and losing responses.\nExperiments show that TIS-DPO significantly outperforms various baseline methods on harmlessness and helpfulness alignment and summarization tasks. We also visualize the estimated weights, demonstrating their ability to identify key token positions."
    },
    {
        "title": "Multi-objective Multi-agent Reinforcement Learning with Pareto-stationary Convergence",
        "link_suffix": "/forum?id=v9fQfQ85oG",
        "link": "https://openreview.net/forum?id=v9fQfQ85oG",
        "pdf_link": "https://openreview.net/pdf?id=v9fQfQ85oG",
        "keywords": "Multi-objective, multi-agent reinforcement learning, Pareto-stationary convergence",
        "abstract": "Multi-objective multi-agent reinforcement learning (MOMARL) problems frequently arise in real world applications (e.g., path planning for swarm robots) or have not been explored well. To find Pareto-optimum is NP-hard, and thus some multi-objective algorithms have emerged recently to provide Pareto-stationary solution centrally, managed by a single agent. Yet, they cannot deal with MOMARL problem, as the dimension of global state-action $(\\boldsymbol{s},\\boldsymbol{a})$ grows exponentially with the number of spatially distributed agents. To tackle this issue, we design a novel graph-truncated $Q$-function approximation method for each agent $i$, which does not require the global state-action $(\\boldsymbol{s},\\boldsymbol{a})$ but only the neighborhood state-action $(s_{\\mathcal{N}^{\\kappa}_{i}},a_{\\mathcal{N}^{\\kappa}_{i}})$ of its $\\kappa$-hop neighbors. To further reduce the dimension to state-action $(s_{\\mathcal{N}^{\\kappa}_{i}},a_{i})$ with only local action, we further develop a concept of action-averaged $Q$-function and establish the equivalence between using graph-truncated $Q$-function and action-averaged $Q$-function for policy gradient approximation. Accordingly, we develop a distributed scalable algorithm with linear function approximation and we prove that it successfully converges Pareto-stationary solution at rate $\\mathcal{O}(1/T)$ that is inversely proportional to time domain $T$. Finally, we run simulations in a robot path planning environment and show our algorithm converges to greater multi-objective values as compared to the latest MORL algorithm, and performs close to the central optimum with much shorter running time."
    },
    {
        "title": "GasketRAG: Systematic Alignment of Large Language Models with Retrievers",
        "link_suffix": "/forum?id=TqLY7QoELU",
        "link": "https://openreview.net/forum?id=TqLY7QoELU",
        "pdf_link": "https://openreview.net/pdf?id=TqLY7QoELU",
        "keywords": "Retrieval Augmented Generation, Large Language Models",
        "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful method for enhancing the output quality of large language models (LLMs). However, existing retrievers are not specifically optimized for LLMs, and retraining them requires substantial resources. Furthermore, current approaches are often constrained to either improving the relevancy of retrieved documents or refining the documents post-retrieval. Various stages within the typical RAG pipeline present challenges in aligning LLMs with retrievers. To address these issues, we propose GasketRAG, a novel approach that introduces a gasket between the retriever and the LLM to improve their collaborative performance. By employing innovative techniques, we gather high-quality preference data and use the gasket to optimize both retrieval ranking and document refinement simultaneously. Our approach circumvents the need for constructing complex training and inference pipelines. In a fair comparison against the latest RAG methods across multiple test datasets, GasketRAG demonstrated a clear advantage."
    },
    {
        "title": "Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning",
        "link_suffix": "/forum?id=YeErX16hMC",
        "link": "https://openreview.net/forum?id=YeErX16hMC",
        "pdf_link": "https://openreview.net/pdf?id=YeErX16hMC",
        "keywords": "Optimization Trade-off, Large Language Models (LLMs), Supervised Fine-tuning (SFT), Reinforcement Learning from Human Feedback (RLHF)",
        "abstract": "Post-training of pre-trained LLMs, which typically consists of the supervised fine-tuning (SFT) stage and the preference learning (RLHF or DPO) stage, is crucial to effective and safe LLM applications. The widely adopted approach in post-training popular open-source LLMs is to sequentially perform SFT and RLHF/DPO. However, sequential training is sub-optimal in terms of SFT and RLHF/DPO trade-off: the LLM gradually forgets about the first stage's training when undergoing the second stage's training. We theoretically prove the sub-optimality of sequential post-training. Furthermore, we propose a practical joint post-training framework that has theoretical convergence guarantees and empirically outperforms sequential post-training framework, while having similar computational cost."
    },
    {
        "title": "Looking beyond the surface with Contrastive LEarning with Anti-contrastive Regularization (CLEAR)",
        "link_suffix": "/forum?id=4ZeOIf2dtC",
        "link": "https://openreview.net/forum?id=4ZeOIf2dtC",
        "pdf_link": "https://openreview.net/pdf?id=4ZeOIf2dtC",
        "keywords": "Weakly Supervised Learning, Disentangled Representation Learning, Variational Autoencoder, Contrastive Learning",
        "abstract": "Learning representations that are robust to superficial sources of variability is important to ensure such variability does not impact downstream tasks. For instance, in healthcare applications, we might like to learn features that are useful for identifying pathology, yet have similar distributions across diverse demographic groups, leading to more accurate and equitable diagnoses regardless of background or surface characteristics. More broadly, this capability can improve the generalizability of our representations by mitigating unwanted effects of variability not seen during training. In this work, we suppose that data representations can be semantically separated into two components: $content$ and $style$. The $content$ consists of information needed for downstream tasks -- for example, it is predictive of the class label in a downstream classification problem -- whereas the $style$ consists of attributes that are superficial in the sense that they are irrelevant to downstream tasks, yet may compromise performance due to associations observed in training data that do not generalize. Here we propose a weakly supervised framework, Contrastive LEarning with Anti-contrastive Regularization (CLEAR), to effectively disentangle $content$ and $style$ in the latent space of a Variational Autoencoder (VAE). Our anti-contrastive penalty, which we call Pair Switching (PS), uses a novel label flipping approach to ensure content is recognized effectively and limited to the $content$ features. We perform experiments to quantitatively and qualitatively evaluate CLEAR-VAE across distinct data modalities. We then analyze the trade-off between disentanglement and ELBO, and the impact of various hyperparameters within our framework. Our results show that using disentangled representations from CLEAR-VAE, we can: (a) swap and interpolate $content$ and $style$ between any pair of samples, and (b) improve downstream classification performance in the presence of previously unseen combinations of $content$ and $style$."
    }
]
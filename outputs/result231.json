[{"title": "Stay Hungry, Keep Learning: Sustainable Plasticity for Deep Reinforcement Learning", "link_suffix": "/forum?id=QmXfEmtBie", "link": "https://openreview.net/forum?id=QmXfEmtBie", "pdf_link": "https://openreview.net/pdf?id=QmXfEmtBie", "keywords": "Deep reinforcement learning, Plasticity", "abstract": "The integration of Deep Neural Networks (DNNs) in Reinforcement Learning (RL) systems has led to remarkable progress in solving complex tasks but also introduced challenges like primacy bias and dead neurons. Primacy bias skews learning towards early experiences, while dead neurons diminish the network's capacity to acquire new knowledge. Traditional reset mechanisms aimed at addressing these issues often involve maintaining large replay buffers to train new networks or selectively resetting subsets of neurons. However, These approaches either incur substantial computational costs or fail to effectively reset the entire network, resulting in underutilization of network plasticity and reduced learning efficiency. In this work, we introduce the novel concept of neuron regeneration, which combines reset mechanisms with knowledge recovery techniques. We also propose a new framework called Sustainable Back Propagation (SBP) that effectively maintains plasticity in neural networks through this neuron regeneration process. The SBP framework achieves whole network neuron regeneration through two key procedures: cycle reset and inner distillation. Cycle reset involves a scheduled renewal of neurons, while inner distillation functions as a knowledge recovery mechanism at the neuron level. To validate our framework, we integrate Sustainable Brain Plasticity (SBP) with Proximal Policy Optimization (PPO) and propose a novel distillation function for inner distillation. This integration results in Plastic PPO (P3O), a new algorithm that enables efficient cyclic regeneration of all neurons in the actor network. This approach facilitates neuron regeneration while maintaining policy plasticity and sample efficiency. Extensive experiments demonstrate that, with proper neuron regeneration methods, the SBP framework can effectively maintain plasticity and improve sample efficiency in reinforcement learning tasks.", "title_embedding_index": 11500, "title_abs_embedding_index": 11525}, {"title": "ANALOGXPERT: AUTOMATING ANALOG TOPOLOGY SYNTHESIS BY INCORPORATING CIRCUIT DESIGN EXPERTISE INTO LARGE LANGUAGE MODELS", "link_suffix": "/forum?id=F0iBQktr5Z", "link": "https://openreview.net/forum?id=F0iBQktr5Z", "pdf_link": "https://openreview.net/pdf?id=F0iBQktr5Z", "keywords": "Analog circuit design, subcircuit library, proofreading, CoT, in-context learning", "abstract": "Analog circuits are crucial in modern electronic systems, and automating their design\nhas attracted significant research interest. One of major challenges is topology\nsynthesis, which determines circuit components and their connections. Recent\nstudies explore large language models (LLM) for topology synthesis. However,\nthe scenarios addressed by these studies do not align well with practical applications.\nSpecifically, existing work uses vague design requirements as input and outputs\nan ideal model, but detailed structural requirements and device-level models\nare more practical. Moreover, current approaches either formulate topology synthesis\nas graph generation or Python code generation, whereas practical topology\ndesign is a complex process that demands extensive design knowledge. In this\nwork, we propose AnalogXpert, a LLM-based agent aiming at solving practical\ntopology synthesis problem by incorporating circuit design expertise into LLMs.\nFirst, we represent analog topology as SPICE code and introduce a subcircuit library\nto reduce the design space, in the same manner as experienced designers.\nSecond, we decompose the problem into two sub-task (i.e., block selection and\nblock connection) through the use of CoT and in-context learning techniques, to\nmimic the practical design process. Third, we introduce a proofreading strategy\nthat allows LLMs to incrementally correct the errors in the initial design, akin to\nhuman designers who iteratively check and adjust the initial topology design to\nensure accuracy. Finally, we construct a high-quality benchmark containing both\nreal data (30) and synthetic data (2k). AnalogXpert achieves 40% and 23% success\nrates on the synthetic dataset and real dataset respectively, which is markedly\nbetter than those of GPT-4o (3% on both the synthetic dataset and the real dataset).", "title_embedding_index": 11501, "title_abs_embedding_index": 11526}, {"title": "Fr\u00e9chet Wavelet Distance: A Domain-Agnostic Metric for Image Generation", "link_suffix": "/forum?id=QinkNNKZ3b", "link": "https://openreview.net/forum?id=QinkNNKZ3b", "pdf_link": "https://openreview.net/pdf?id=QinkNNKZ3b", "keywords": "Frechet Distance, Wavelet Packet Transform, Frechet Inception Distance, Diffusion, GAN, ImageNet, Frechet Inception Distance, FD-DINOv2", "abstract": "Modern metrics for generative learning like Fr\u00e9chet Inception Distance (FID ) and DINOv2-Fr\u00e9chet Distance (FD-DINOv2 ) demonstrate impressive performance. However, they suffer from various shortcomings, like a bias towards specific generators and datasets. To address this problem, we propose the Fr\u00e9chet Wavelet Distance (FWD ) as a domain-agnostic metric based on the Wavelet Packet Transform ($\\mathcal{W}_p$). FWD provides a sight across a broad spectrum of frequencies in images with a high resolution, preserving both spatial and textural aspects. Specifically, we use $\\mathcal{W}_p$ to project generated and real images to the packet coefficient space. We then compute the Fr\u00e9chet distance with the resultant coefficients to evaluate the quality of a generator. This metric is general-purpose and dataset-domain agnostic, as it does not rely on any pre-trained network while being more interpretable due to its ability to compute Fr\u00e9chet distance per packet, enhancing transparency. We conclude with an extensive evaluation of a wide variety of generators across various datasets that the proposed FWD can generalize and improve robustness to domain shifts and various corruptions compared to other metrics.", "title_embedding_index": 11502, "title_abs_embedding_index": 11527}, {"title": "SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision Language Model", "link_suffix": "/forum?id=cp9LvuvAKW", "link": "https://openreview.net/forum?id=cp9LvuvAKW", "pdf_link": "https://openreview.net/pdf?id=cp9LvuvAKW", "keywords": "Alignment, VLM, LLM, Dataset", "abstract": "The emergence of Vision Language Models (VLMs) has brought unprecedented advances in understanding multimodal information. The combination of textual and visual semantics in VLMs is highly complex and diverse, making the safety alignment of these models challenging. Furthermore, due to the limited study on the safety alignment of VLMs, there is a lack of large-scale, high-quality datasets. To address these limitations, we propose a Safety Preference Alignment dataset for Vision Language Models named SPA-VL. In terms of breadth, SPA-VL covers 6 harmfulness domains, 13 categories, and 53 subcategories, and contains 100,788 samples of the quadruple (question, image, chosen response, rejected response). In terms of depth, the responses are collected from 12 open-source (e.g., QwenVL) and closed-source (e.g., Gemini) VLMs to ensure diversity. The construction of preference data is fully automated, and the experimental results indicate that models trained with alignment techniques on the SPA-VL dataset exhibit substantial improvements in harmlessness and helpfulness while maintaining core capabilities. SPA-VL, as a large-scale, high-quality, and diverse dataset, represents a significant milestone in ensuring that VLMs achieve both harmlessness and helpfulness.", "title_embedding_index": 11503, "title_abs_embedding_index": 11528}, {"title": "BONE: BLOCK AFFINE TRANSFORMATION AS PARAMETER EFFICIENT FINE-TUNING METHODS FOR LARGE LANGUAGE MODELS", "link_suffix": "/forum?id=RP0NPepy1m", "link": "https://openreview.net/forum?id=RP0NPepy1m", "pdf_link": "https://openreview.net/pdf?id=RP0NPepy1m", "keywords": "Block Affine, LLM, LoRA, PISSA, RWKV, Llama", "abstract": "Low-Rank Adaptation (LoRA) has achieved remarkable training results by freezing the original weights and training only low-rank matrices, establishing itself as the predominant fine-tuning method for LLMs. In pursuit of performance closer to full-parameter training, a series of LoRA variants have emerged, such as LoRA+, PISSA, Olora, and LoRA-GA. However, these improvements complicate the initial setup of model training and increase initialization time. More importantly, they overlook the internal interactions of the original weight information. To address these issues, we introduce a novel theory, ``Weight Guide'' aimed at continuously guiding trainable matrices through the original weights during training to enhance the utilization of weight information. Based on this theory, we designed a new PEFT technique called Bone (Block Affine), which not only enhances the utilization of original weight information but also emphasizes the internal connections between weights, leading to faster convergence and better data fitting. Experimental comparisons across two different LLM architectures (LLaMA2, RWKV6) and various parameter scales demonstrate that the Bone structure can achieve rapid convergence and superior data fitting without the need for complex initialization. For example, when fine-tuning LLaMA2-7B on the MetaMathQA dataset and validating on GSM8k and math benchmarks, Bone achieved fine-tuning scores of 49.36 and 8.8, respectively, outperforming PISSA by 5.84% and 1.96%.", "title_embedding_index": 11504, "title_abs_embedding_index": 11529}, {"title": "Text-promptable Propagation for Referring Medical Image Sequence Segmentation", "link_suffix": "/forum?id=8zCB9rTnmE", "link": "https://openreview.net/forum?id=8zCB9rTnmE", "pdf_link": "https://openreview.net/pdf?id=8zCB9rTnmE", "keywords": "Referring medical image sequence segmentation, Text-promptable propagation", "abstract": "Medical image sequences, generated by both 2D video-based examinations and 3D imaging techniques, consist of sequential frames or slices that capture the same anatomical entities (e.g., organs or lesions) from multiple perspectives. Existing segmentation studies typically process medical images using either 2D or 3D methods in isolation, often overlooking the inherent consistencies among these\nimages. Additionally, interactive segmentation, while highly beneficial in clinical scenarios, faces the challenge of integrating text prompts effectively across multimodalities. To address these issues, we introduce an innovative task, Referring Medical Image Sequence Segmentation for the first time, which aims to segment the referred anatomical entities corresponding to medical text prompts. We\ndevelop a strong baseline model, Text-Promptable Propagation (TPP), designed to exploit the intrinsic relationships among sequential images and their associated textual descriptions. TPP supports the segmentation of arbitrary objects of interest based on cross-modal prompt fusion. Carefully designed medical prompts are fused and employed as queries to guide image sequence segmentation through\ntriple-propagation. We curate a large and comprehensive benchmark covering 4 modalities and 20 different organs and lesions. Experimental results consistently demonstrate the superior performance of our approach compared to previous methods across these datasets. Code and data are available athttps://anonymous.4open.science/r/TPP/.", "title_embedding_index": 11505, "title_abs_embedding_index": 11530}, {"title": "Scaling Probabilistic Circuits via Data Partitioning", "link_suffix": "/forum?id=a1jpdqRED9", "link": "https://openreview.net/forum?id=a1jpdqRED9", "pdf_link": "https://openreview.net/pdf?id=a1jpdqRED9", "keywords": "probabilistic circuits, probabilistic models, federated learning", "abstract": "Probabilistic circuits (PCs) enable us to learn joint distributions over a set of random variables and to perform various probabilistic queries in a tractable fashion. Though the tractability property allows PCs to scale beyond non-tractable models such as Bayesian Networks, scaling training and inference of PCs to larger, real-world datasets remains challenging. To remedy the situation, we show how PCs can be learned across multiple machines by recursively partitioning a distributed dataset, thereby unveiling a deep connection between PCs and federated learning (FL). This leads to federated circuits (FCs)---a novel and flexible federated learning (FL) framework that (1) allows one to scale PCs on distributed learning environments (2) train PCs faster and (3) unifies for the first time horizontal, vertical, and hybrid FL in one framework by re-framing FL as a density estimation problem over distributed datasets. We demonstrate FC's capability to scale PCs on various large-scale datasets. Also, we show FC's versatility in handling horizontal, vertical, and hybrid FL within a unified framework on multiple classification tasks.", "title_embedding_index": 11506, "title_abs_embedding_index": 11531}, {"title": "Multimodal Sentiment Analysis Based on Causal Reasoning", "link_suffix": "/forum?id=exIN7Z0wDf", "link": "https://openreview.net/forum?id=exIN7Z0wDf", "pdf_link": "https://openreview.net/pdf?id=exIN7Z0wDf", "keywords": "Causal Reasoning; Multimodal Sentiment Analysis", "abstract": "With the rapid development of multimedia, the shift from unimodal textual sentiment analysis to multimodal image-text sentiment analysis has obtained academic and industrial attention in recent years. However, multimodal sentiment analysis is affected by unimodal data bias, e.g., text sentiment is misleading due to explicit sentiment semantic, leading to low accuracy in the final sentiment classification. In this paper, we propose a novel CounterFactual Multimodal Sentiment Analysis framework (CF-MSA) using causal counterfactual inference to construct multimodal sentiment causal inference. CF-MSA mitigates the direct effect from unimodal bias and ensures heterogeneity across modalities by differentiating the treatment variables between modalities. In addition, considering the information complementarity and bias differences between modalities, we propose a new optimisation objective to effectively integrate different modalities and reduce the inherent bias from each modality. Experimental results on two public datasets, MVSA-Single and MVSA-Multiple, demonstrate that the proposed CF-MSA has superior debiasing capability and achieves new state-of-the-art performances.  We will release the code and datasets to facilitate future research.", "title_embedding_index": 11507, "title_abs_embedding_index": 11532}, {"title": "T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback", "link_suffix": "/forum?id=H8QvefExFf", "link": "https://openreview.net/forum?id=H8QvefExFf", "pdf_link": "https://openreview.net/pdf?id=H8QvefExFf", "keywords": "text-to-audio generation; preference learning", "abstract": "Text-to-audio (T2A) generation has achieved remarkable progress in generating a variety of audio outputs from language prompts. However, current state-of-the-art T2A models still struggle to satisfy human preferences for prompt-following and acoustic quality when generating complex multi-event audio. To improve the performance of the model in these high-level applications, we propose to enhance the basic capabilities of the model with AI feedback learning. First, we introduce fine-grained AI audio scoring pipelines to: 1) verify whether each event in the text prompt is present in the audio (Event Occurrence Score), 2) detect deviations in event sequences from the language description (Event Sequence Score), and 3) assess the overall acoustic and harmonic quality of the generated audio (Acoustic & Harmonic Quality). We evaluate these three automatic scoring pipelines and find that they correlate significantly better with human preferences than other evaluation metrics. This highlights their value as both feedback signals and evaluation metrics. Utilizing our robust scoring pipelines, we construct a large audio preference dataset, T2A-FeedBack, which contains 41k prompts and 249k audios, each accompanied by detailed scores. Moreover, we introduce T2A-EpicBench, a benchmark that focuses on long captions, multi-events, and story-telling scenarios, aiming to evaluate the advanced capabilities of T2A models. Finally, we demonstrate how T2A-FeedBack can enhance current state-of-the-art audio model. With simple preference tuning, the audio generation model exhibits significant improvements in both simple (AudioCaps test set) and complex (T2A-EpicBench) scenarios. The project page is available at \\url{https://T2Afeedback.github.io}", "title_embedding_index": 11508, "title_abs_embedding_index": 11533}, {"title": "Adapting Communicating MLLMs on the Fly in Referring Expression Tasks", "link_suffix": "/forum?id=3fuPS85ekI", "link": "https://openreview.net/forum?id=3fuPS85ekI", "pdf_link": "https://openreview.net/pdf?id=3fuPS85ekI", "keywords": "Multimodal Large Language Models, Online Adaptation, Referring Expressions", "abstract": "Multimodal Large Language Models (MLLMs) exhibit varying comprehension levels in language and perception that complicate interacting with a diverse population of agents, similar to how miscommunication happens in humans, e.g., because intentions are not always known.\nIn this work, we investigate whether MLLMs can adapt to the perceptual weaknesses of the communication partners in an online manner, i.e. change the way they describe their environment in a way that is understandable to their partner while communicating with them, via reinforcement learning.\nWe experiment with two tasks: referring expression identification (REI) and referring expression segmentation (RES), where a speaker agent has to describe an object, and a listener has to identify it.\nTo be successful, the speaker agent must discern the comprehension level of the listener and adapt accordingly, especially when the listener suffers from perceptual weaknesses such as color blindness or blurred vision.\nUnlike traditional offline alignment methods for LLMs, we fine-tune a Multimodal LLM (MLLM) online to adapt to other agents' conceptual understanding. Our experiments with four MLLMs on four datasets show that online adaptation is feasible in both REI and RES settings.", "title_embedding_index": 11509, "title_abs_embedding_index": 11534}, {"title": "Standardizing the Measurement of Text Diversity: A Tool and Comparative Analysis", "link_suffix": "/forum?id=jvRCirB0Oq", "link": "https://openreview.net/forum?id=jvRCirB0Oq", "pdf_link": "https://openreview.net/pdf?id=jvRCirB0Oq", "keywords": "text diversity, summarization, generation", "abstract": "The diversity across outputs generated by LLMs shapes perception of their quality and utility. \nAchieving high textual diversity in datasets is often a desired quality, but there is no standard method to measure this aspect of model behaviour.\nIn this work we empirically investigate diversity scores on English texts and measure how much overlapping information is captured in these metrics. \nWe find that computationally efficient compression algorithms capture information similar to what is measured by slow-to-compute $n$-gram overlap homogeneity scores. \nFurther, a combination of measures---compression ratios, self-repetition of long $n$-grams and Self-BLEU and BERTScore---are sufficient to report, as they have low mutual correlation with each other. \nThe applicability of scores extends beyond analysis of generative models; for example, we highlight applications on instruction-tuning datasets and human-produced texts. \nWe release a diversity score package to facilitate research and invite consistency going forward.", "title_embedding_index": 11510, "title_abs_embedding_index": 11535}, {"title": "Learning Cooperative Mean Field Games on Sparse Chung-Lu Graphs", "link_suffix": "/forum?id=pNxD5dpu1M", "link": "https://openreview.net/forum?id=pNxD5dpu1M", "pdf_link": "https://openreview.net/pdf?id=pNxD5dpu1M", "keywords": "Cooperative Mean Field Games, Large Networks, Sparse Graphs, Multi Agent Reinforcement Learning", "abstract": "Large agent networks are abundant in applications and nature and pose difficult challenges in the field of multi-agent reinforcement learning (MARL) due to their computational and theoretical complexity. While graphon mean field games and their extensions provide efficient learning algorithms for dense and moderately sparse agent networks, the case of realistic sparser graphs remains largely unsolved. Thus, we propose a novel cooperative mean field game (MFG) model based on the large class of Chung-Lu graphs including power law networks with coefficients above two. Besides a theoretical analysis, we design scalable learning algorithms which especially apply to the challenging class of graph sequences with finite first moment and infinite second moment. We compare our model and algorithms for various examples on synthetic and real world networks with MFG algorithms based on Lp graphons and graphexes. As it turns out, our approach outperforms existing methods in many examples and on various networks due to the special design aiming at an important, but so far hard to solve class of MARL problems.", "title_embedding_index": 11511, "title_abs_embedding_index": 11536}, {"title": "RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction", "link_suffix": "/forum?id=gRmWtOnTLK", "link": "https://openreview.net/forum?id=gRmWtOnTLK", "pdf_link": "https://openreview.net/pdf?id=gRmWtOnTLK", "keywords": "Rectified Flow, Audio Waveform Reconstruction, Multi-band audio generation\uff0cReal-time diffusion  Vocoder", "abstract": "Recent advancements in generative modeling have significantly enhanced the reconstruction of audio waveforms from various representations. While diffusion models are adept at this task, they are hindered by latency issues due to their operation at the individual sample point level and the need for numerous sampling steps. In this study, we introduce RFWave, a cutting-edge multi-band Rectified Flow approach designed to reconstruct high-fidelity audio waveforms from Mel-spectrograms or discrete acoustic tokens. RFWave uniquely generates complex spectrograms and operates at the frame level, processing all subbands simultaneously to boost efficiency. Leveraging Rectified Flow, which targets a straight transport trajectory, RFWave achieves reconstruction with just 10 sampling steps. Our empirical evaluations show that RFWave not only provides outstanding reconstruction quality but also offers vastly superior computational efficiency, enabling audio generation at speeds up to 160 times faster than real-time on a GPU. An online demonstration is available at:https://rfwave-demo.github.io/rfwave/.", "title_embedding_index": 11512, "title_abs_embedding_index": 11537}, {"title": "SORRY-Bench: Systematically Evaluating Large Language Model Safety Refusal", "link_suffix": "/forum?id=YfKNaRktan", "link": "https://openreview.net/forum?id=YfKNaRktan", "pdf_link": "https://openreview.net/pdf?id=YfKNaRktan", "keywords": "LLM, safety, alignment, benchmark, refusal", "abstract": "Evaluating aligned large language models' (LLMs) ability to recognize and reject unsafe user requests is crucial for safe, policy-compliant deployments. Existing evaluation efforts, however, face three limitations that we address withSORRY-Bench, our proposed benchmark.First, existing methods often use coarse-grained taxonomies of unsafe topics, and are over-representing some fine-grained topics. For example, among the ten existing datasets that we evaluated, tests for refusals of self-harm instructions are over 3x less represented than tests for fraudulent activities. SORRY-Bench improves on this by using a fine-grained taxonomy of 44 potentially unsafe topics, and 440 class-balanced unsafe instructions, compiled through human-in-the-loop methods.Second, evaluations often overlook the linguistic formatting of prompts, like different languages, dialects, and more --- which are only implicitly considered in many evaluations. We supplement SORRY-bench with 20 diverse linguistic augmentations to systematically examine these effects.Third, existing evaluations rely on large LLMs (e.g., GPT-4) for evaluation, which can be computationally expensive. We investigate design choices for creating a fast, accurate automated safety evaluator. By collecting 7K+ human annotations and conducting a meta-evaluation of diverse LLM-as-a-judge designs, we show that fine-tuned 7B LLMs can achieve accuracy comparable to GPT-4 scale LLMs, with lower computational cost. Putting these together, we evaluate over 50 proprietary and open-weight LLMs on SORRY-Bench, analyzing their distinctive safety refusal behaviors. We hope our effort provides a building block for systematic evaluations of LLMs' safety refusal capabilities, in a balanced, granular, and efficient manner.", "title_embedding_index": 11513, "title_abs_embedding_index": 11538}, {"title": "Towards Auto-Regressive Next-Token Prediction: In-context Learning Emerges from Generalization", "link_suffix": "/forum?id=gK1rl98VRp", "link": "https://openreview.net/forum?id=gK1rl98VRp", "pdf_link": "https://openreview.net/pdf?id=gK1rl98VRp", "keywords": "In-context learning, Auto-regressive next-token prediction, Generalization performance, PAC-Bayesian", "abstract": "Large language models (LLMs) have demonstrated remarkable in-context learning (ICL) abilities. However, existing theoretical analysis of ICL primarily exhibits two limitations: \\textbf{(a) Limited \\textit{i.i.d.} Setting.} Most studies focus on supervised function learning tasks where prompts are constructed with \\textit{i.i.d.} input-label pairs. This \\textit{i.i.d.} assumption diverges significantly from real language learning scenarios where prompt tokens are interdependent. \\textbf{(b) Lack of Emergence Explanation.} Most literature answers \\textbf{\\textit{what}} ICL does from an implicit optimization perspective but falls short in elucidating \\textbf{\\textit{how}} ICL emerges and the impact of pre-training phase on ICL. In our paper, to extend (a), we adopt a more practical paradigm, \\textbf{\\textit{auto-regressive next-token prediction (AR-NTP)}}, which closely aligns with the actual training of language models. Specifically, within AR-NTP, we emphasize prompt token-dependency, which involves predicting each subsequent token based on the preceding sequence. To address (b), we formalize a systematic pre-training and ICL framework, highlighting the layer-wise structure of sequences and topics, alongside a two-level expectation. In conclusion, we present data-dependent, topic-dependent and optimization-dependent PAC-Bayesian generalization bounds for pre-trained LLMs, investigating that \\textbf{\\textit{ICL emerges from the generalization of sequences and topics}}. Our theory is supported by experiments on numerical linear dynamic systems, synthetic GINC and real-world language datasets.", "title_embedding_index": 11514, "title_abs_embedding_index": 11539}, {"title": "Low-Budget Simulation-Based Inference with Bayesian Neural Networks", "link_suffix": "/forum?id=cho9iE9POr", "link": "https://openreview.net/forum?id=cho9iE9POr", "pdf_link": "https://openreview.net/pdf?id=cho9iE9POr", "keywords": "simulation-based inference, approximate Bayesian inference", "abstract": "Simulation-based inference methods have been shown to be inaccurate in the data-poor regime, when training simulations are limited or expensive.\nUnder these circumstances, the inference network is particularly prone to overfitting, and using it without accounting for the computational uncertainty arising from the lack of identifiability of the network weights can lead to unreliable results.\nTo address this issue, we propose using Bayesian neural networks in low-budget simulation-based inference, thereby explicitly accounting for the computational uncertainty of the posterior approximation.\nWe design a family of Bayesian neural network priors that are tailored for inference and show that they lead to well-calibrated posteriors on tested benchmarks, even when as few as $O(10)$ simulations are available.\nThis opens up the possibility of performing reliable simulation-based inference using very expensive simulators, as we demonstrate on a problem from the field of cosmology where single simulations are computationally expensive. We show that Bayesian neural networks produce informative and well-calibrated posterior estimates with only a few hundred simulations.", "title_embedding_index": 11515, "title_abs_embedding_index": 11540}, {"title": "Information Subtraction: Learning Representations for Conditional Entropy", "link_suffix": "/forum?id=C2uViDZmNp", "link": "https://openreview.net/forum?id=C2uViDZmNp", "pdf_link": "https://openreview.net/pdf?id=C2uViDZmNp", "keywords": "conditional entropy, conditional representation learning, self-supervised learning", "abstract": "The representations of conditional entropy and conditional mutual information are significant in explaining the unique effects among variables. The previous works based on conditional contrastive sampling have successfully eliminated information about discrete sensitive variables, but have not yet addressed continuous cases. This paper introduces a framework of Information Subtraction capable of representing arbitrary information components between continuous variables. We implement a generative-based architecture that outputs such representations by simultaneously maximizing an information term and minimizing another. The results highlight the representations' ability to provide semantic features of conditional entropy. By subtracting sensitive and domain-specific information, our framework effectively enhances fair learning and domain generalization.", "title_embedding_index": 11516, "title_abs_embedding_index": 11541}, {"title": "SimPER: Simple Preference Fine-Tuning without Hyperparameters by Perplexity Optimization", "link_suffix": "/forum?id=jfwe9qNqRi", "link": "https://openreview.net/forum?id=jfwe9qNqRi", "pdf_link": "https://openreview.net/pdf?id=jfwe9qNqRi", "keywords": "Large Language Model", "abstract": "Preference optimization has made significant advances in aligning large language models with preference data. However, existing preference optimization objectives require additional hyperparameters that must be extensively manually adjusted to achieve optimal performance, increasing the complexity and time required for fine-tuning large language models. In this paper, we propose a simple\nhyperparameter-free preference optimization algorithm for alignment. We observe that we can achieve promising performance simply by optimizing inverse perplexity, which is computed as the inverse of the exponentiated average log-likelihood of the chosen and rejected responses in the preference dataset. The resulting simple learning objective, SimPER, is easy to implement and eliminates the need for expensive hyperparameter tuning and a reference model, making it both learning and memory efficient. We show theoretically that SimPER can avoid overestimation of rejected responses in preference data and is closely related to the total variation distance, encouraging promising mode-seeking behavior for alignment. Extensive experiments on widely used real-world benchmarks: MT-Bench, AlpacaEval 2, and 10 key benchmarks of the Open LLM Leadboard with 5 base models show that SimPER consistently and significantly outperforms existing approaches even without any hyperparameters and the reference model. For instance, despite its simplicity, SimPER outperforms state-of-the-art methods by up to 5.7 points on AlpacaEval 2 and achieves the highest average ranking across 10 benchmarks on the Open LLM Leaderboard. Code for SimPER is publicly available at this link.", "title_embedding_index": 11517, "title_abs_embedding_index": 11542}, {"title": "FreqKV: Frequency Domain Key-Value Compression for Efficient Context Window Extension", "link_suffix": "/forum?id=KscheKSYrh", "link": "https://openreview.net/forum?id=KscheKSYrh", "pdf_link": "https://openreview.net/pdf?id=KscheKSYrh", "keywords": "Large Language Models, KV Compression, Context Extension", "abstract": "Extending the context window in large language models (LLMs) is essential for applications involving long-form content generation. However, the quadratic complexity of self-attention and the linear increase in key-value (KV) cache memory requirements with respect to sequence length present significant challenges during fine-tuning and inference. Although LongLoRA achieves efficient fine-tuning by employing shifted sparse attention, inference remains inefficient due to the requirement for dense global attention.\nIn this work, we introduce a novel context extension method that optimizes both fine-tuning and inference efficiency. Our method exploits a key observation: in the frequency domain, the energy distribution of the KV cache is primarily concentrated in low-frequency components. By filtering out the high-frequency components, the KV cache can be effectively compressed with minimal information loss. Building on this insight, we propose an efficient compression technique, FreqKV, that iteratively reduces the increasing KV cache to a fixed size in the frequency domain, applicable to both fine-tuning and inference. With minimal fine-tuning, LLMs can learn to leverage the limited cache that is compressed in the frequency domain and extend the context window efficiently.\nFreqKV introduces no additional parameters or architectural modifications, ensuring compatibility with the original full attention post-training.\nExperiments on long context language modeling and understanding demonstrate the efficiency and efficacy of the proposed method.", "title_embedding_index": 11518, "title_abs_embedding_index": 11543}, {"title": "Periodical Moving Average Accelerates Gradient Accumulation for Post-Training", "link_suffix": "/forum?id=i0qnHlgxFm", "link": "https://openreview.net/forum?id=i0qnHlgxFm", "pdf_link": "https://openreview.net/pdf?id=i0qnHlgxFm", "keywords": "Optimization, Large Language Models, Efficient Machine Learning", "abstract": "High gradient variance challenges training Large Language Models (LLMs) on memory-limited devices. Existing practical approaches, such as small batch size or using Gradient Accumulation (GA), face the dilemma between low convergence rates due to high variance in parameter updates and long training times due to the serial GA process. In this paper, we identify that the exponential nature of the Exponential Moving Average (EMA) rapidly forgets historical gradients at an exponential rate in momentum updates, making it difficult to utilize the historical gradients to stabilize the update steps. To address this issue, we embed the idea of GA into the momentum update and propose the Periodical Moving Average (PMA) technique. PMA splits the training steps into periods and employs moving averages instead of EMA in each period. We apply PMA to AdamW and Lion, resulting in AdamW-PMA and Lion-PMA. Theoretical analysis demonstrates that AdamW-PMA achieves a comparable convergence rate with Adam. Extensive experiments showcase the superiority of PMA on post-training tasks, including Supervised Fine-Tuning and Direct Preference Optimization, that the PMA-based methods achieve approximately at least $2\\times$ speedup and higher scores on downstream tasks.", "title_embedding_index": 11519, "title_abs_embedding_index": 11544}, {"title": "An Adaptive Defense Against Adversarial Patch Attacks For Vision Transformers", "link_suffix": "/forum?id=vOSwtXGSA2", "link": "https://openreview.net/forum?id=vOSwtXGSA2", "pdf_link": "https://openreview.net/pdf?id=vOSwtXGSA2", "keywords": "vision transformer; adversarial patch attack;  adptive defense", "abstract": "Vision Transformers (ViTs) have become the prominent architecture for various computer vision tasks due to their superior ability to capture long-range dependencies through the self-attention mechanism. However, recent research indicates that ViTs are highly susceptible to carefully crafted adversarial patch attacks, presenting a significant challenge for practical deployment, particularly in security-critical applications. Existing approaches towards robust ViT frameworks often sacrifice clean accuracy and/or achieve suboptimal robustness, likely due to their uniform handling of diverse input samples. In this paper, we present NeighborViT, a novel adaptive defense framework specifically designed to counter adversarial patch attacks for ViTs. NeighborViT stands out by detecting and categorizing different types of attacks on inputs and applying adaptive, tailored defense mechanisms for each type of attack. To realize effective attack detection, categorization, and mitigation, NeighborViT explores the information in neighbor patches of the target patch and strategically employs them for defense. Our experimental results on the ImageNet dataset using various state-of-the-art ViT models demonstrate that NeighborViT significantly enhances robust accuracy without compromising clean accuracy. Our code is available athttps://anonymous.4open.science/r/NeighborViT-8255.", "title_embedding_index": 11520, "title_abs_embedding_index": 11545}, {"title": "MAGNet: Motif-Agnostic Generation of Molecules from Scaffolds", "link_suffix": "/forum?id=5FXKgOxmb2", "link": "https://openreview.net/forum?id=5FXKgOxmb2", "pdf_link": "https://openreview.net/pdf?id=5FXKgOxmb2", "keywords": "graph generative models, 2d molecules", "abstract": "Recent advances in machine learning for molecules exhibit great potential for facilitating drug discovery from in silico predictions.\nMost models for molecule generation rely on the decomposition of molecules into frequently occurring substructures (motifs), from which they generate novel compounds. \nWhile motif representations greatly aid in learning molecular distributions, such methods fail to represent substructures beyond their known motif set, posing a fundamental limitation for discovering novel compounds.\nTo address this limitation and enhance structural expressivity, we propose to separate structure from features by abstracting motifs to scaffolds and, subsequently, allocating atom and bond types. \nTo this end, we introduce a novel factorisation of the molecules' data distribution that considers the entire molecular context and facilitates learning adequate assignments of atoms and bonds to scaffolds. Complementary to this, we propose MAGNet, the first model to freely learn motifs. Importantly, we demonstrate that MAGNet's improved expressivity leads to molecules with more structural diversity and, at the same time, diverse atom and bond assignments.", "title_embedding_index": 11521, "title_abs_embedding_index": 11546}, {"title": "3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination", "link_suffix": "/forum?id=i7hXOqzUcK", "link": "https://openreview.net/forum?id=i7hXOqzUcK", "pdf_link": "https://openreview.net/pdf?id=i7hXOqzUcK", "keywords": "3D, LLM, Hallucination, Embodied AI, Multimodal, NLP", "abstract": "The integration of language and 3D perception is crucial for developing embodied agents and robots that comprehend and interact with the physical world. While large language models (LLMs) have demonstrated impressive language understanding and generation capabilities, their adaptation to 3D environments (3D-LLMs) remains in its early stages. A primary challenge is the absence of large-scale datasets that provide dense grounding between language and 3D scenes. In this paper, we introduce 3D-GRAND, a pioneering large-scale dataset comprising 40,087 household scenes paired with 6.2 million densely-grounded scene-language instructions. Our results show that instruction tuning with 3D-GRAND significantly enhances grounding capabilities and reduces hallucinations in 3D-LLMs. As part of our contributions, we propose a comprehensive benchmark 3D-POPE to systematically evaluate hallucination in 3D-LLMs, enabling fair comparisons among future models. Our experiments highlight a scaling effect between dataset size and 3D-LLM performance, emphasizing the critical role of large-scale 3D-text datasets in advancing embodied AI research. Notably, our results demonstrate early signals for effective sim-to-real transfer, indicating that models trained on large synthetic data can perform well on real-world 3D scans. Through 3D-GRAND and 3D-POPE, we aim to equip the embodied AI community with essential resources and insights, setting the stage for more reliable and better-grounded 3D-LLMs.", "title_embedding_index": 11522, "title_abs_embedding_index": 11547}, {"title": "XXLTraffic: Expanding and Extremely Long Traffic forecasting beyond test adaptation", "link_suffix": "/forum?id=GrHewano8m", "link": "https://openreview.net/forum?id=GrHewano8m", "pdf_link": "https://openreview.net/pdf?id=GrHewano8m", "keywords": "spatio-temporal, traffic forecasting, time-series", "abstract": "Traffic forecasting is crucial for smart cities and intelligent transportation initiatives, where deep learning has made significant progress in modeling complex spatio-temporal patterns in recent years. However, current public datasets have limitations in reflecting the distribution shift nature of real-world scenarios, characterized by continuously evolving infrastructures, varying temporal distributions, and long temporal gaps due to sensor downtimes or changes in traffic patterns. These limitations inevitably restrict the practical applicability of existing traffic forecasting datasets. To bridge this gap, we present XXLTraffic, the longest available public traffic dataset with the longest timespan collected from Los Angeles, USA, and New South Wales, Australia, curated to support research in extremely long forecasting beyond test adaptation. Our benchmark includes both typical time-series forecasting settings with hourly and daily aggregated data and novel configurations that introduce gaps and down-sample the training size to better simulate practical constraints. We anticipate the new XXLTraffic will provide a fresh perspective for the time-series and traffic forecasting communities. It would also offer a robust platform for developing and evaluating models designed to tackle the extremely long forecasting problems beyond test adaptation. Our dataset supplements existing spatio-temporal data resources and leads to new research directions in this domain.", "title_embedding_index": 11523, "title_abs_embedding_index": 11548}, {"title": "Zero-cost Proxy for Adversarial Robustness Evaluation", "link_suffix": "/forum?id=zHf7hOfeer", "link": "https://openreview.net/forum?id=zHf7hOfeer", "pdf_link": "https://openreview.net/pdf?id=zHf7hOfeer", "keywords": "Neural architecture search, adversarial robustness, zero-cost proxy", "abstract": "Deep neural networks (DNNs) easily cause security issues due to the lack of adversarial robustness. An emerging research topic for this problem is to design adversarially robust architectures via neural architecture search (NAS), i.e., robust NAS. However, robust NAS needs to train numerous DNNs for robustness estimation, making the search process prohibitively expensive. In this paper, we propose a zero-cost proxy to evaluate the adversarial robustness without training. Specifically, the proposed zero-cost proxy formulates the upper bound of adversarial loss, which can directly reflect the adversarial robustness. The formulation involves only the initialized weights of DNNs, thus the training process is no longer needed. Moreover, we theoretically justify the validity of the proposed proxy based on the theory of neural tangent kernel and input loss landscape. Experimental results show that the proposed zero-cost proxy can bring more than $20\\times$ speedup compared with the state-of-the-art robust NAS methods, while the searched architecture has superior robustness and transferability under white-box and black-box attacks. Furthermore, compared with the state-of-the-art zero-cost proxies, the calculation of the proposed method has the strongest correlation with adversarial robustness. Our source code is available athttps://anonymous.4open.science/r/ZCP-05B6.", "title_embedding_index": 11524, "title_abs_embedding_index": 11549}]
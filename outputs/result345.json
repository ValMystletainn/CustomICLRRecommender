[
    {
        "title": "Democratizing Evaluation with Infinity-Benchmarks: Sample-Level Heterogeneous Testing Over Arbitrary Capabilities",
        "link_suffix": "/forum?id=Dj1PVLU8fK",
        "link": "https://openreview.net/forum?id=Dj1PVLU8fK",
        "pdf_link": "https://openreview.net/pdf?id=Dj1PVLU8fK",
        "keywords": "foundation models, efficient evaluation, aggregation, lifelong benchmarking, heterogeneity",
        "abstract": "Traditional fixed test datasets fall short in quantifying the open-ended potential of foundation models. In this work, we propose \u221e-benchmarks, a new testing paradigm that combines individual evaluation datasets into a single, uniform, ever-expanding sample pool from which custom evaluations can be flexibly generated. An \u221e-benchmark allows users to dynamically select a collection of sample-level evaluations that correspond to their specific capabilities of interest. By aggregating and reusing samples across various test sets, it enables the assessment of diverse capabilities beyond those covered by the original test sets, while mitigating overfitting and dataset bias through real-world diversity. Most importantly, it frames model evaluation as a collective process of aggregation and selection of sample-level tests.The shift from multi-task benchmarks to \u221e-benchmarks introduces two key challenges: (1) heterogeneity and (2) incompleteness. Heterogeneity refers to aggregating diverse metrics, including binary, numeric, and ordinal data, while incompleteness describes comparing models evaluated on different subsets of testing data. To address these challenges, we explore algorithms inspired by social choice theory which aggregate sparse, unequal measurements into reliable model scores. Our aggregation algorithm ensures identifiability (asymptotically recovering ground-truth scores) and rapid convergence, enabling accurate model comparisons with relatively little data. We introduce \u221e-LLMBench for language models and \u221e-LMMBench for vision-language models, unifying evaluations across leaderboards and arenas in these domains, and showcasing targeted querying over a wide-range of capabilities. Our algorithm recovers ground truth rankings with large Kendall \u03c4 correlations when compared to standard aggregation on homogeneous metrics, even with up to 95% of measurements missing. This approach reduces evaluation cost by up to 20\u00d7 with little to no compromise in performance. Overall, we present the first large-scale \u221e-benchmarks for lifelong, efficient evaluation of language and vision-language models which can aggregate over open-ended heterogeneous sample-level testing to evolve alongside the rapid development of foundation models."
    },
    {
        "title": "No Access, No Safety: Free Lunch Adversarial Attacks on Black-box NLP Models",
        "link_suffix": "/forum?id=LuSZGyud4O",
        "link": "https://openreview.net/forum?id=LuSZGyud4O",
        "pdf_link": "https://openreview.net/pdf?id=LuSZGyud4O",
        "keywords": "Text Adversarial Attacks\uff0c Trustworthy artificial intelligence",
        "abstract": "Textual adversarial attacks confuse Natural Language Processing (NLP) models,\nsuch as Large Language Models (LLMs), by finely modifying the text, resulting\nin incorrect decisions. Although existing adversarial attacks are effective, they\ntypically rely on knowing the victim model, using extensive queries, or grasping\ntraining data, which limits their real-world applications. In situations where there\nis neither knowledge of nor access to the victim model, we introduce the Free\nLunch Adversarial Attack (FLA), demonstrating that attackers can successfully\nexecute attacks armed only with victim texts. To prevent access to the victim\nmodel, we create a shadow dataset with publicly available pre-trained models and\nclustering methods as a foundation for developing substitute models. To address\nthe low attack success rate (ASR) due to insufficient information feedback, we\npropose the hierarchical substitution model design, generating substitute models\nthat approximate the victim\u2019s decision boundaries to enhance ASR. Concurrently,\nwe use diverse adversarial example generation, employing various attack methods\nto reduce the frequency of model training, balancing effectiveness with efficiency.\nExperiments with the Emotion and SST5 datasets show that the FLA outperforms\nexisting state-of-the-art methods  while lowering the attack cost to\nzero. More importantly, we discover that FLA poses a significant threat to LLMs\nsuch as Qwen2 and the GPT family, and achieves the highest ASR of 45.99% even\nwithout access to the API, confirming that advanced NLP models still face serious\nsecurity risks."
    },
    {
        "title": "Edge Importance Inference Towards Neighborhood Aware GNNs",
        "link_suffix": "/forum?id=Twyc3qZ3py",
        "link": "https://openreview.net/forum?id=Twyc3qZ3py",
        "pdf_link": "https://openreview.net/pdf?id=Twyc3qZ3py",
        "keywords": "GNNs, variational inference, stochastic process",
        "abstract": "Comprehensive model tuning and meticulous training for determining proper scope of neighborhood where graph neural networks (GNNs) aggregate information requires high computation overhead and significant human effort. We propose a probabilistic GNN model that captures the expansion of neighborhood scope as a stochastic process and adaptively sample edges to identify critical pathways contributing to generating informative node features. We develop a novel variational inference algorithm to jointly approximate the posterior of the count of neighborhood hops and learn GNN weights while accounting for edge importance. Experiments on multiple benchmarks demonstrate that by adapting the neighborhood scope to a given dataset our model outperforms GNN variants that require grid search or heuristics for neighborhood scope selection."
    },
    {
        "title": "3D-free meets 3D priors: Novel View Synthesis from a Single Image with Pretrained Diffusion Guidance",
        "link_suffix": "/forum?id=VLuJL8cnGk",
        "link": "https://openreview.net/forum?id=VLuJL8cnGk",
        "pdf_link": "https://openreview.net/pdf?id=VLuJL8cnGk",
        "keywords": "3D-free, View Consistency, Background Inclusion, Guidance Models",
        "abstract": "Recent 3D novel view synthesis (NVS) methods are limited to single-object-centric scenes and struggle with complex environments. They often require extensive 3D data for training, lacking generalization beyond the training distribution. Conversely, 3D-free methods can generate text-controlled views of complex, in-the-wild scenes using a pretrained stable diffusion model without the need for a large amount of 3D-based training data, but lack camera control. In this paper, we introduce a method capable of generating camera-controlled viewpoints from a single input image, by combining the benefits of 3D-free and 3D-based approaches. Our method excels in handling complex and diverse scenes without extensive training or additional 3D and multiview data. It leverages widely available pretrained NVS models for weak guidance, integrating this knowledge into a 3D-free view synthesis approach to achieve the desired results. Experimental results demonstrate that our method outperforms existing models in both qualitative and quantitative evaluations, providing high-fidelity and consistent novel view synthesis at desired camera angles across a wide variety of scenes."
    },
    {
        "title": "Does learning the right latent variables necessarily improve in-context learning?",
        "link_suffix": "/forum?id=TSlJ3ikcBZ",
        "link": "https://openreview.net/forum?id=TSlJ3ikcBZ",
        "pdf_link": "https://openreview.net/pdf?id=TSlJ3ikcBZ",
        "keywords": "in-context learning, transformers, attention, latent variable, shortcuts",
        "abstract": "Large autoregressive models like Transformers can solve tasks through in-context learning (ICL) without learning new weights, suggesting avenues for efficiently solving new tasks. For many tasks, e.g., linear regression, the data factorizes: examples are independent given a task latent that generates the data, e.g., linear coefficients. While an optimal predictor leverages this factorization by inferring task latents, it is unclear if Transformers implicitly do so or if they instead exploit heuristics and statistical shortcuts enabled by attention layers. Both scenarios have inspired active ongoing work. In this paper, we systematically investigate the effect of explicitly inferring task latents. We minimally modify the Transformer architecture with a bottleneck designed to prevent shortcuts in favor of more structured solutions, and then compare performance against standard Transformers across various ICL tasks. Contrary to intuition and some recent works, we find little discernible difference between the two; biasing towards task-relevant latent variables does not lead to better out-of-distribution performance, in general. Curiously, we find that while the bottleneck effectively learns to extract latent task variables from context, downstream processing struggles to utilize them for robust prediction. Our study highlights the intrinsic limitations of Transformers in achieving structured ICL solutions that generalize, and shows that while inferring the right latents aids interpretability, it is not sufficient to alleviate this problem."
    },
    {
        "title": "Needle Threading: Can LLMs Follow Threads Through Near-Million-Scale Haystacks?",
        "link_suffix": "/forum?id=wHLMsM1SrP",
        "link": "https://openreview.net/forum?id=wHLMsM1SrP",
        "pdf_link": "https://openreview.net/pdf?id=wHLMsM1SrP",
        "keywords": "LLMs, Long Context, Evaluation",
        "abstract": "As the context limits of Large Language Models (LLMs) increase, the range of\npossible applications and downstream functions broadens. In many real-world\ntasks, decisions depend on details scattered across collections of often disparate\ndocuments containing mostly irrelevant information. Long-context LLMs appear\nwell-suited to this form of complex information retrieval and reasoning, which has\ntraditionally proven costly and time-consuming. However, although the development of longer context models has seen rapid gains in recent years, our understanding of how effectively LLMs use their context has not kept pace. To address\nthis, we conduct a set of retrieval experiments designed to evaluate the capabilities\nof 17 leading LLMs, such as their ability to follow threads of information through\nthe context window. Strikingly, we find that many models are remarkably thread-\nsafe: capable of simultaneously following multiple threads without significant loss\nin performance. Still, for many models, we find the effective context limit is significantly shorter than the supported context length, with accuracy decreasing as\nthe context window grows. Our study also highlights the important point that token counts from different tokenizers should not be directly compared\u2014they often\ncorrespond to substantially different numbers of written characters. We release\nour code and long context experimental data."
    },
    {
        "title": "Hough Voting-based Prompt Learning for Segment Anything Model",
        "link_suffix": "/forum?id=nxZbKWhUeZ",
        "link": "https://openreview.net/forum?id=nxZbKWhUeZ",
        "pdf_link": "https://openreview.net/pdf?id=nxZbKWhUeZ",
        "keywords": "Prompt Learning, Segmentation Anything Model, Few shot learning",
        "abstract": "Segment Anything Models (SAMs) like SEEM and SAM have achieved great performance on various downstream datasets at the cost of crafting spatial and semantic prompts. Previous prompt learning methods can learn prompts automatically but largely focus on learning semantic prompts, while how to learn effective spatial prompts that are important to SAMs is largely under-explored. Inspired by Hough Voting that detects a complex object by voting from its parts, we propose Hough Voting-based Spatial Prompt Learning (HoughSpaPL) that designs three types of voting mechanisms to learn three distinct spatial prompts for different subregions of the visual concept (e.g., things and stuff), which capture complementary spatial clues and vote together to guide SAMs to generate a precise segmentation mask for the visual concept. Following the same philosophy, we design Hough Voting-based Semantic Prompt Learning (HoughSemPL) that learns distinct semantic prompts for different sub-regions of the visual concept, which capture complementary semantic clues and vote together to predict a accurate semantic label for the generated mask. Extensive experiments show that our proposed techniques achieve superior prompt learning performance over popular segmentation datasets. Codes will be released."
    },
    {
        "title": "SPARTUN3D: Situated Spatial Understanding of 3D World in Large Language Model",
        "link_suffix": "/forum?id=FGMkSL8NR0",
        "link": "https://openreview.net/forum?id=FGMkSL8NR0",
        "pdf_link": "https://openreview.net/pdf?id=FGMkSL8NR0",
        "keywords": "Situated Understanding in 3D Scen, 3D VL, LLM",
        "abstract": "Integrating the 3D world into large language models (3D-based LLMs) has been a promising research direction for 3D scene understanding. However, current 3D-based LLMs fall short in situated understanding due to two key limitations: 1) existing 3D datasets are constructed from a global perspective of the 3D scenes and lack situated context.\n2) the architectures of the current 3D-based LLMs lack an explicit mechanism for aligning situated spatial information between 3D representations and natural language, limiting their performance in tasks requiring precise spatial reasoning. \nIn this work, we address these issues by introducing a scalable situated 3D dataset, named Spartun3D, that incorporates various situated spatial information.\nIn addition, we propose a situated spatial alignment module to enhance the learning between 3D visual representations and their corresponding textual descriptions. Our experimental results demonstrate that both our dataset and alignment module enhance situated spatial understanding ability."
    },
    {
        "title": "Supervised Contrastive Block Disentanglement",
        "link_suffix": "/forum?id=eB2QgsohdN",
        "link": "https://openreview.net/forum?id=eB2QgsohdN",
        "pdf_link": "https://openreview.net/pdf?id=eB2QgsohdN",
        "keywords": "disentanglement, block disentanglement, out-of-distribution generalization, domain generalization, distribution shift, spurious correlations, robustness",
        "abstract": "Real-world datasets often combine data collected under different experimental conditions. Although this yields larger datasets, it also introduces spurious correlations that make it difficult to accurately model the phenomena of interest. We address this by learning two blocks of latent variables to independently represent the phenomena of interest and the spurious correlations. The former are correlated with the target variable $y$ and invariant to the environment variable $e$, while the latter depend on $e$. The invariance of the phenomena of interest to $e$ is highly sought-after but difficult to achieve on real-world datasets. Our primary contribution is an algorithm called Supervised Contrastive Block Disentanglement (SCBD) that is highly effective at enforcing this invariance. It is based purely on supervised contrastive learning, and scales to real-world data better than existing approaches. We empirically validate SCBD on two challenging problems. The first is domain generalization, where we achieve strong performance on a synthetic dataset, as well as on Camelyon17-WILDS. SCBD introduces a single hyperparameter $\\alpha$ that controls the degree of invariance to $e$. When we increase $\\alpha$ to strengthen the degree of invariance, there is a monotonic improvement in out-of-distribution performance at the expense of in-distribution performance. The consistency of this relationship makes model selection with SCBD more reliable than existing algorithms, which do not elicit such a relationship. The second is a scientific problem of batch correction. Here, we demonstrate the utility of SCBD by learning representations of single-cell perturbations from 26 million Optical Pooled Screening images that are nearly free of technical artifacts induced by the variation across wells."
    },
    {
        "title": "Task Diversity Shortens the ICL Plateau",
        "link_suffix": "/forum?id=LbceJJc9h2",
        "link": "https://openreview.net/forum?id=LbceJJc9h2",
        "pdf_link": "https://openreview.net/pdf?id=LbceJJc9h2",
        "keywords": "In-context learning, Transformers, Training dynamics, Task diversity, Multi-task",
        "abstract": "In-context learning (ICL) describes a language model's ability to generate outputs based on a set of input demonstrations and a subsequent query. To understand this remarkable capability, researchers have studied simplified, stylized models. These studies have consistently observed long loss plateaus, during which models exhibit minimal improvement, followed by a sudden, rapid surge of learning. In this work, we reveal that training on multiple diverse ICL tasks simultaneously shortens the loss plateaus, making each task easier to learn. This finding is surprising as it contradicts the natural intuition that the combined complexity of multiple ICL tasks would lengthen the learning process, not shorten it. Our result suggests that the recent success in large-scale training of language models may be attributed not only to the richness of the data at scale but also to the easier optimization (training) induced by the diversity of natural language training data."
    },
    {
        "title": "Distributed In-Context Learning under Non-IID Among Clients",
        "link_suffix": "/forum?id=7H1jbTaOIn",
        "link": "https://openreview.net/forum?id=7H1jbTaOIn",
        "pdf_link": "https://openreview.net/pdf?id=7H1jbTaOIn",
        "keywords": "in-context learning, distributed system, large language model",
        "abstract": "Advancements in large language models (LLMs) have shown their effectiveness in multiple compli-\ncated natural language reasoning tasks. A key challenge remains in adapting these models efficiently\nto new or unfamiliar tasks. In-context learning (ICL) provides a promising solution for few-shot\nadaptation by retrieving a set of data points relevant to a query, called in-context examples (ICE),\nfrom a training dataset and providing them during the inference as context. Most existing studies\nutilize a centralized training dataset, yet many real-world datasets may be distributed among multiple\nclients, and remote data retrieval can be associated with costs. Especially when the client data are\nnon-identical independent distributions (non-IID), retrieving from clients a proper set of ICEs needed\nfor a test query presents critical challenges. In this paper, we first show that in this challenging\nsetting, test queries will have different preferences among clients because of non-IIDness, and equal\ncontribution often leads to suboptimal performance. We then introduce a novel approach to tackle\nthe distributed non-IID ICL problem when a data usage budget is present. The principle is that each\nclient\u2019s proper contribution (budget) should be designed according to the preference of each query for\nthat client. Our approach uses a data-driven manner to allocate a budget for each client, tailored to\neach test query. Through extensive empirical studies on diverse datasets, our framework demonstrates\nsuperior performance relative to competing baselines."
    },
    {
        "title": "Optimal Protocols for Continual Learning via Statistical Physics and Control Theory",
        "link_suffix": "/forum?id=rhhQjGj09A",
        "link": "https://openreview.net/forum?id=rhhQjGj09A",
        "pdf_link": "https://openreview.net/pdf?id=rhhQjGj09A",
        "keywords": "machine learning theory, statistical physics, online learning, continual learning, optimal control theory",
        "abstract": "Artificial neural networks often struggle withcatastrophic forgettingwhen learning multiple tasks sequentially, as training on new tasks degrades the performance on previously learned tasks. Recent theoretical work has addressed this issue by analysing learning curves in synthetic frameworks under predefined training protocols. However, these protocols relied on heuristics and lacked a solid theoretical foundation assessing their optimality. In this paper, we fill this gap by combining exact equations for training dynamics, derived using statistical physics techniques, with optimal control methods. We apply this approach to teacher-student models for continual learning and multi-task problems, obtaining a theory for task-selection protocols maximising performance while minimising forgetting. Our theoretical analysis offers non-trivial yet interpretable strategies for mitigating catastrophic forgetting, shedding light on how optimal learning protocols modulate established effects, such as the influence of task similarity on forgetting. Finally, we validate our theoretical findings with experiments on real-world data."
    },
    {
        "title": "BOIL: Learning Environment Personalized Information",
        "link_suffix": "/forum?id=GLmOWcqvE3",
        "link": "https://openreview.net/forum?id=GLmOWcqvE3",
        "pdf_link": "https://openreview.net/pdf?id=GLmOWcqvE3",
        "keywords": "learning on graphs, Information Theory, Pagerank, applications to robotics, probabilistic methods",
        "abstract": "Navigating complex environments poses challenges for multi-agent systems, requiring efficient extraction of insights from limited information. In this paper, we introduce the Blackbox Oracle Information Learning (BOIL) process, a scalable solution for extracting valuable insights from the environment structure. Leveraging the Pagerank algorithm and common information maximization, BOIL facilitates the extraction of information to guide long-term agent behavior applicable to problems such as coverage, patrolling, and stochastic reachability. Through experiments, we demonstrate the efficacy of BOIL in generating strategy distributions conducive to improved performance over extended time horizons, surpassing heuristic approaches in complex environments."
    },
    {
        "title": "Do Unlearning Methods Remove Information from Language Model Weights?",
        "link_suffix": "/forum?id=uDjuCpQH5N",
        "link": "https://openreview.net/forum?id=uDjuCpQH5N",
        "pdf_link": "https://openreview.net/pdf?id=uDjuCpQH5N",
        "keywords": "Unlearning, LLMs, Evaluation, RMU, Fine-tuning, Red-teaming, Safety",
        "abstract": "Large Language Models' knowledge of how to perform cyber-security attacks, create bioweapons, and manipulate humans poses risks of misuse. Previous work has proposed methods to unlearn this knowledge. Historically, it has been unclear whether unlearning techniques are removing information from the model weights or just making it harder to access. To disentangle these two objectives, we propose an adversarial evaluation method to test for the removal of information from model weights: we give an attacker access to some facts that were supposed to be removed, and using those, the attacker tries to recover other facts from the same distribution that cannot be guessed from the accessible facts. We show that using fine-tuning on the accessible facts can recover 88% of the pre-unlearning accuracy when applied to current unlearning methods, revealing the limitations of these methods in removing information from the model weights."
    },
    {
        "title": "Learning Generalizable Skills from Offline Multi-Task Data for Multi-Agent Cooperation",
        "link_suffix": "/forum?id=HR1ujVR0ig",
        "link": "https://openreview.net/forum?id=HR1ujVR0ig",
        "pdf_link": "https://openreview.net/pdf?id=HR1ujVR0ig",
        "keywords": "Reinforcement Learning, Multi-Agent Reinforcemenr Learning",
        "abstract": "Learning cooperative multi-agent policy from offline multi-task data that can generalize to unseen tasks with varying numbers of agents and targets is an attractive problem in many scenarios.\nAlthough aggregating general behavior patterns among multiple tasks as skills to improve policy transfer is a promising approach,\ntwo primary challenges hinder the further advancement of skill learning in offline multi-task MARL. \nFirstly, extracting general cooperative behaviors from various action sequences as common skills lack bringing cooperative temporal knowledge into them.\nSecondly, existing works only involve common skills and can not adaptively choose independent knowledge as task-specific skills in each task for fine-grained action execution.\nTo address these challenges, we propose an approach named Hierarchical and Separate Skill Discovering (HiSSD) for generalizable offline multi-task MARL through skill learning.\nHiSSD leverages a hierarchical framework that jointly learns common and task-specific skills.\nThe common skills learn cooperative temporal knowledge and enable in-sample exploration for offline multi-task MARL.\nThe task-specific skills represent the priors of each task and achieve a task-guided fine-grained action execution.\nTo verify the advancement of our method, we conduct experiments on multi-agent MuJoCo and SMAC benchmarks.\nAfter training policy using HiSSD on offline multi-task data, the empirical results show that HiSSD assigns effective cooperative behaviors and obtains superior performance in unseen tasks."
    },
    {
        "title": "Understanding the Connection between Low-Dimensional Representation and Generalization via Interpolation",
        "link_suffix": "/forum?id=A9yKCUQNnc",
        "link": "https://openreview.net/forum?id=A9yKCUQNnc",
        "pdf_link": "https://openreview.net/pdf?id=A9yKCUQNnc",
        "keywords": "Low-Dimensional Representation, Interpolation, Generalization",
        "abstract": "In recent years, numerous studies have demonstrated the close connection between neural networks' generalization performance and their ability to learn low-dimensional representations of data. However, the theoretical foundation linking low-dimensional representations to generalization remains underexplored. In this work, we propose a theoretical framework to analyze this relationship from the perspective of interpolation and convex combinations. We argue that lower-dimensional representations increase the likelihood of new samples being expressed as convex combinations of the training set, thereby enhancing interpolation probability. We derive a generalization error upper bound under the interpolation regime, which becomes tighter as the dimensionality of the representation decreases. Furthermore, we investigate how the structure of the manifold affects interpolation probability by examining the volume of the convex hull formed by the manifold. Our theoretical and experimental results show that larger convex hull volumes are associated with higher interpolation probabilities. Additionally, we explore the impact of training data volume on interpolation, finding a significant power-law relationship between increased data volume, convex hull volume and interpolation probability. Overall, this study highlights the critical role of low-dimensional representations in improving the generalization performance of neural networks, supported by both theoretical insights and experimental evidence."
    },
    {
        "title": "Visual Haystacks: A Vision-Centric Needle-In-A-Haystack Benchmark",
        "link_suffix": "/forum?id=9JCNPFL1f9",
        "link": "https://openreview.net/forum?id=9JCNPFL1f9",
        "pdf_link": "https://openreview.net/pdf?id=9JCNPFL1f9",
        "keywords": "Large Multimodal Models, Visual Question Answering",
        "abstract": "Large Multimodal Models (LMMs) have made significant strides in visual question-answering for single images. Recent advancements like long-context LMMs have allowed them to ingest larger, or even multiple, images. However, the ability to process a large number of visual tokens does not guarantee effective retrieval and reasoning for multi-image question answering (MIQA), especially in real-world applications like photo album searches or satellite imagery analysis. In this work, we first assess the limitations of current benchmarks for long-context LMMs. We address these limitations by introducing a new vision-centric, long-context benchmark, \"Visual Haystacks (VHs)\". We comprehensively evaluate both open-source and proprietary models on VHs, and demonstrate that these models struggle when reasoning across potentially unrelated images, perform poorly on cross-image reasoning, as well as exhibit biases based on the placement of key information within the context window. Towards a solution, we introduce MIRAGE (Multi-Image Retrieval Augmented Generation), an open-source, lightweight visual-RAG framework that processes up to 10k images on a single 40G A100 GPU\u2014far surpassing the 1k-image limit of contemporary models. MIRAGE demonstrates up to 13% performance improvement over existing open-source LMMs on VHs, sets a new state-of-the-art on the RetVQA multi-image QA benchmark, and achieves competitive performance on single-image QA with state-of-the-art LMMs."
    },
    {
        "title": "A Hitchhiker's Guide to Scaling Law Estimation",
        "link_suffix": "/forum?id=xGM5shdGJD",
        "link": "https://openreview.net/forum?id=xGM5shdGJD",
        "pdf_link": "https://openreview.net/pdf?id=xGM5shdGJD",
        "keywords": "Scaling Laws, llms, language, pretraining, open, metascience, efficient, evaluation",
        "abstract": "Scaling laws predict the loss of a target machine learning model by extrapolating from easier-to-train models with fewer parameters or smaller training sets. This provides an efficient way for practitioners and researchers alike to compare pretraining decisions involving, e.g., optimizers, datasets, and model architectures. Despite the widespread use of scaling laws to model the dynamics of language model training, there has been little work on understanding how to best estimate and interpret them.\nWe collect (and release) a large-scale dataset containing losses and downstream evaluations for 485 previously published pretrained models. We use these to estimate more than 1000 scaling laws, then derive a set of best practices for estimating scaling laws in new model families. \nWe find that fitting scaling laws to intermediate checkpoints of training runs (and not just their final losses) substantially improves accuracy, and that---all else equal---estimates of performance are generally most accurate when derived from other models of similar sizes. However, because there is a significant degree of variability across model seeds, training multiple models at a given scale is sometimes more useful. Moreover, while model families differ in the way they scale, they are often similar enough that a target model's behavior can often be predicted from a single model of the same architecture, along with estimates of scaling parameters derived from other model families."
    },
    {
        "title": "A Manifold Perspective on the Statistical Generalization of Graph Neural Networks",
        "link_suffix": "/forum?id=WRLj18zwz6",
        "link": "https://openreview.net/forum?id=WRLj18zwz6",
        "pdf_link": "https://openreview.net/pdf?id=WRLj18zwz6",
        "keywords": "generalization analysis, graph neural networks, manifold neural networks",
        "abstract": "Graph Neural Networks (GNNs) extend convolutional neural networks to operate on graphs. Despite\ntheir impressive performances in various graph learning tasks, the theoretical understanding of\ntheir generalization capability is still lacking. Previous GNN generalization bounds ignore the\nunderlying graph structures, often leading to bounds that increase with the number of nodes \u2013 a\nbehavior contrary to the one experienced in practice. In this paper, we take a manifold perspective\nto establish the statistical generalization theory of GNNs on graphs sampled from a manifold in the\nspectral domain. As demonstrated empirically, we prove that the generalization bounds of GNNs\ndecrease linearly with the size of the graphs in the logarithmic scale, and increase linearly with the\nspectral continuity constants of the filter functions. Notably, our theory explains both node-level and\ngraph-level tasks. Our result has two implications: i) guaranteeing the generalization of GNNs to\nunseen data over manifolds; ii) providing insights into the practical design of GNNs, i.e., restrictions\non the discriminability of GNNs are necessary to obtain a better generalization performance. We\ndemonstrate our generalization bounds of GNNs using synthetic and multiple real-world datasets."
    },
    {
        "title": "Self-Training on Unpaired Data Improves Multi-Modal Alignment",
        "link_suffix": "/forum?id=baNW94qdsU",
        "link": "https://openreview.net/forum?id=baNW94qdsU",
        "pdf_link": "https://openreview.net/pdf?id=baNW94qdsU",
        "keywords": "Self-Training, Multi-Modal Representation Alignment",
        "abstract": "In the past few years, multimodal foundation models,  e.g., CLIP, learned from a massive amount of paired multimodal data, emerged and exhibited impressive cross-modal ability in many applications. Yet collecting high-quality paired data is generally costly or even infeasible in certain cases, and the amount of paired multimodal data is several orders fewer than that of unpaired unimodal data, i.e., data without any correspondence. Our work focuses on alleviating the excessive demand for paired language-image data by leveraging the abundant unpaired data. We introduce a new approach for vision-language alignment, which we call Language-Image Self-Training (LIST). LIST consists of two key ingredients that function in a synergistic loop: i) a captioner model trained alternatively with the augmented paired data and the unpaired data with synthetic captions, both derived from the data engine, and ii) a data engine that synthesizes a diverse spectrum of captions for both paired and unpaired images with the captioner, integrating synthetic captions with the web-scraped ones to enhance the quality of paired data using off-the-shelf Large Language Models.  We observe that the LIST methodology not only significantly improves the alignment between vision and language representations across multiple major benchmarks\u2014zero-shot image classification, image-text retrieval, and compositional evaluation\u2014but also demonstrates strong generalization to audio-language representation alignment."
    },
    {
        "title": "Attic: A New Architecture for Tabular In-Context Learning Transformers",
        "link_suffix": "/forum?id=DSl9sSuUhp",
        "link": "https://openreview.net/forum?id=DSl9sSuUhp",
        "pdf_link": "https://openreview.net/pdf?id=DSl9sSuUhp",
        "keywords": "tabular classification, tabular in-context learning transformers, architecture",
        "abstract": "Tabular In-Context Learning (ICL) transformers, such as TabPFN and TabForestPFN, have shown strong performance on tabular classification tasks. In this paper, we introduce Attic, a new architecture for ICL-transformers. Unlike TabPFN and TabForestPFN, where one token represents all features of one observation, Attic assigns one token to each feature of every observation. This simple architectural change results in a significant performance boost. As a result, we can confidently say that neural networks outperform tree-based methods like XGBoost."
    },
    {
        "title": "Spatially-aware Photo-realistic Face Relighting using Joint Embedding of Light Properties",
        "link_suffix": "/forum?id=BkLLtZX7AZ",
        "link": "https://openreview.net/forum?id=BkLLtZX7AZ",
        "pdf_link": "https://openreview.net/pdf?id=BkLLtZX7AZ",
        "keywords": "Face Relighting, Joint Light Property Embedding, Realistic Shadows",
        "abstract": "Single image face relighting is the challenging problem of estimating the illumination cast on images by a point light source varying in position, intensity and possibly colour. Learning the relationship between the light source properties and the face location is critical to the photo-realism of the estimated relit image. Prior works do not explicitly model this relationship which adversely affects the accuracy and photo-realism of the estimated relit image. We present a novel framework that explicitly models this relationship by integrating a novel light feature embedding with self-attention and cross attention layers in a custom image relighting network. Our proposed method estimates more photo-realistic relit images with accurate shadows and outperforms prior works despite being trained only on synthetic data. Our method is able to generalize to out-of-training light source positions and also achieves unsupervised adaptation from synthetic to real images."
    },
    {
        "title": "Fine-tuned In-Context Learning Transformers are Excellent Tabular Data Classifiers.",
        "link_suffix": "/forum?id=pE0UM18TQh",
        "link": "https://openreview.net/forum?id=pE0UM18TQh",
        "pdf_link": "https://openreview.net/pdf?id=pE0UM18TQh",
        "keywords": "tabular classification, tabular in-context learning transformer, fine-tuning",
        "abstract": "The recently introduced TabPFN pretrains an In-Context Learning (ICL) transformer on synthetic data to perform tabular data classification. In this work, we extend TabPFN to the fine-tuning setting, resulting in a significant performance boost. We also discover that fine-tuning enables ICL-transformers to create complex decision boundaries, a property regular neural networks do not have. Based on this observation, we propose to pretrain ICL-transformers on a new forest dataset generator which creates datasets that are unrealistic, but have complex decision boundaries. TabForest, the ICL-transformer pretrained on this dataset generator, shows better fine-tuning performance when pretrained on more complex datasets. Additionally, TabForest outperforms TabPFN on some real-world datasets when fine-tuning, despite having lower zero-shot performance due to the unrealistic nature of the pretraining datasets. By combining both dataset generators, we create TabForestPFN, an ICL-transformer that achieves excellent fine-tuning performance and good zero-shot performance."
    },
    {
        "title": "Decentralized Blockchain-based Robust Multi-agent Multi-armed Bandit",
        "link_suffix": "/forum?id=PA3MWNDD6O",
        "link": "https://openreview.net/forum?id=PA3MWNDD6O",
        "pdf_link": "https://openreview.net/pdf?id=PA3MWNDD6O",
        "keywords": "Online learning, Multi-agent Bandit, Blockchain",
        "abstract": "We study a robust, i.e. in presence of malicious participants, multi-agent multi-armed bandit problem where multiple participants are distributed on a fully decentralized blockchain, with the possibility of some being malicious. The rewards of arms are homogeneous among the honest participants, following time-invariant stochastic distributions, which are revealed to the participants only when certain conditions are met to ensure that the coordination mechanism is secure enough. The coordination mechanism's objective is to efficiently ensure the cumulative rewards gained by the honest participants are maximized. To this end and to the best of our knowledge, we are the first to incorporate advanced techniques from blockchains, as well as novel mechanisms, into such a cooperative decision making framework to design optimal strategies for honest participants. This framework allows various malicious behaviors and the maintenance of security and participant privacy. More specifically, we select a pool of validators who communicate to all participants, design a new consensus mechanism based on digital signatures for these validators, invent a UCB-based strategy that requires less information from participants through secure multi-party computation, and design the chain-participant interaction and an incentive mechanism to encourage participants' participation. Notably, we are the first to prove the theoretical regret of the proposed algorithm and claim its optimality. Unlike existing work that integrates blockchains with learning problems such as federated learning which mainly focuses on  optimality via computational experiments, we demonstrate that the regret of honest participants is upper bounded by $\\log{T}$ under certain assumptions. The regret bound is consistent with the multi-agent multi-armed bandit problem without malicious participants and the robust multi-agent multi-armed bandit problem with purely Byzantine attacks which do not affect the entire system."
    },
    {
        "title": "Do Symbolic or Black-Box Representations Generalise Better In Learned Optimisation?",
        "link_suffix": "/forum?id=MpA6HMD7Wq",
        "link": "https://openreview.net/forum?id=MpA6HMD7Wq",
        "pdf_link": "https://openreview.net/pdf?id=MpA6HMD7Wq",
        "keywords": "reinforcement learning, meta learning, optimisation",
        "abstract": "Until recently, behind every algorithmic advance in machine learning was a human researcher. Now, however, algorithms can be meta-learned automatically, with little human input. However, to be truly useful, such algorithms must generalise beyond their training distribution. This is especially challenging in reinforcement learning (RL), where transferring algorithms between environments with vastly different dynamics is difficult and training on diverse environments often requires prohibitively expensive large-scale data collection.Learned optimisation is a branch of algorithmic discovery that meta-learns optimiser update rules. Learned optimisers can be classified into two groups: black-box algorithms, where the optimiser is a neural network; or symbolic algorithms, where the optimiser is represented using mathematical functions or code. While some claim that symbolic algorithms generalise better than black-box ones, testing such assertions is complicated by the fact that symbolic algorithms typically include additional hyperparameters, and thus their evaluation is done many-shot. This is an unfair comparison with the zero-shot evaluation of black-box optimisers. In this work, we build a pipeline to discover symbolic optimisers which are hyperparameter-free, enabling a fair comparison of the generalisation of symbolic optimisers with that of an open-source state-of-the-art black-box optimiser trained for RL. Based on our analysis, we propose suggestions to improve the symbolic optimiser discovery pipeline for RL, with an overall objective of reducing the need for hyperparameter tuning to train an agent."
    }
]
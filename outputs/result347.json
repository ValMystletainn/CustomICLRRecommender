[
    {
        "title": "ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models",
        "link_suffix": "/forum?id=KhvBlzwehb",
        "link": "https://openreview.net/forum?id=KhvBlzwehb",
        "pdf_link": "https://openreview.net/pdf?id=KhvBlzwehb",
        "keywords": "benchmark for MLLMs, active perception, visual comprehension and reasoning",
        "abstract": "Active perception, a crucial human capability, involves setting a goal based on the current understanding of the environment and performing actions to achieve that goal. Despite significant efforts in evaluating Multimodal Large Language Models (MLLMs), active perception has been largely overlooked. To address this gap, we propose a novel benchmark named ActiView to evaluate active perception in MLLMs. Since comprehensively assessing active perception is challenging, we focus on a specialized form of Visual Question Answering (VQA) that eases the evaluation yet challenging for existing MLLMs. Given an image, we restrict the perceptual field of a model, requiring it to actively zoom or shift its perceptual field based on reasoning to answer the question successfully. We conduct extensive evaluation over 27 models, including proprietary and open-source models, and observe that the ability to read and comprehend multiple images simultaneously plays a significant role in enabling active perception. Results reveal a significant gap in the active perception capability of MLLMs, indicating that this area deserves more attention. We hope that our benchmark could help develop methods for MLLMs to understand multimodal inputs in more natural and holistic ways."
    },
    {
        "title": "Provable Post-Deployment Deterioration Monitoring",
        "link_suffix": "/forum?id=lHBQrqVYji",
        "link": "https://openreview.net/forum?id=lHBQrqVYji",
        "pdf_link": "https://openreview.net/pdf?id=lHBQrqVYji",
        "keywords": "Deterioration Monitoring, AI Safety, Trustworthy ML, AI for Healthcare, Guardrails for AI",
        "abstract": "Data distribution often changes when deploying a machine learning model into a new environment, but not all shifts degrade model performance, making interventions like retraining unnecessary. This paper addresses model post-deployment deterioration (PDD)  monitoring in the context of unlabeled deployment distributions. We formalize unsupervised PDD monitoring within the model disagreement framework where deterioration is detected if an auxiliary model, performing well on training data, shows significant prediction disagreement with the deployed model on test data. We propose D-PDDM, a principled monitoring algorithm achieving low false positive rates under non-deteriorating shifts and provide sample complexity bounds for high true positive rates under deteriorating shifts. Empirical results on both standard benchmark and a real-world large-scale healthcare dataset demonstrate the effectiveness of the framework in addition to its viability as an alert mechanism for existing high-stakes ML pipelines."
    },
    {
        "title": "Different Rates for Different Weights: Decoupled Relative Learning Rate Schedules",
        "link_suffix": "/forum?id=BUpdp5gETF",
        "link": "https://openreview.net/forum?id=BUpdp5gETF",
        "pdf_link": "https://openreview.net/pdf?id=BUpdp5gETF",
        "keywords": "learning rate, transformer, mixture of experts, LLM",
        "abstract": "In this work, we introduce a novel approach for optimizing neural network training by adjusting learning rates across weights of different components in Transformer models. Traditional methods often apply a uniform learning rate across all network layers, potentially overlooking the unique dynamics of each part. Remarkably, our introduced Relative Learning Rate Schedules (RLRS) method accelerates the training process by 13.6%, particularly in complex models such as the Mixture of Experts (MoE). Hyperparameters of RLRS can be efficiently tuned on smaller models and then extrapolated to 27x larger ones. This simple and effective method results in a substantial reduction in training time and computational resources, offering a practical and scalable solution for optimizing large-scale neural networks."
    },
    {
        "title": "Data Exfiltration in Diffusion Models: A Backdoor Attack Approach",
        "link_suffix": "/forum?id=T6qIMnokrI",
        "link": "https://openreview.net/forum?id=T6qIMnokrI",
        "pdf_link": "https://openreview.net/pdf?id=T6qIMnokrI",
        "keywords": "Backdoor Attack, Data Exfiltration, Diffusion Model",
        "abstract": "As diffusion models (DMs) become increasingly susceptible to adversarial attacks, this paper investigates a novel method of data exfiltration through strategically implanted backdoors. Unlike conventional techniques that directly alter data, we pioneer the use of unique trigger embeddings for each image to enable covert data retrieval. Furthermore, we extend our exploration to text-to-image diffusion models such as Stable Diffusion by introducing the Caption Backdoor Subnet (CBS), which exploits these models for both image and caption extraction. This innovative approach not only reveals an unexplored facet of diffusion model security but also contributes valuable insights toward enhancing the resilience of generative models against sophisticated threats."
    },
    {
        "title": "GenPlan: Automated Floor Plan Generation",
        "link_suffix": "/forum?id=kA5egaJjya",
        "link": "https://openreview.net/forum?id=kA5egaJjya",
        "pdf_link": "https://openreview.net/pdf?id=kA5egaJjya",
        "keywords": "Floor Plans, Transformers, Architecture, CNNs, GNNs, Autoencoders, Residential, 3D Graphics",
        "abstract": "We present GenPlan, a novel deep learning architecture for generating architectural floor plans. GenPlan provides flexibility and precision in room placement, offering architects and developers new avenues for creative exploration. We adapted an autoencoder-like structure comprising of two encoders and four specialized decoders that predict the centers of different rooms. These predictions are converted into graph along with the other constraints and used as inputs for a Transformer-based graph neural network (GNN), which is responsible for delineating room boundaries and refining the predicted room centers. The Graph Transformer Network ensures that the generated floor plans are realistic and executable in real-life. GenPlan\u2019s methodological innovation provides heightened control during the design phase, serving as a valuable tool for automating and refining the architectural design process."
    },
    {
        "title": "Flavors of Margin: Implicit Bias of Steepest Descent in Homogeneous Neural Networks",
        "link_suffix": "/forum?id=BEpaPHDl9r",
        "link": "https://openreview.net/forum?id=BEpaPHDl9r",
        "pdf_link": "https://openreview.net/pdf?id=BEpaPHDl9r",
        "keywords": "implicit bias, steepest descent, deep neural networks",
        "abstract": "We study the implicit bias of the family of steepest descent algorithms, including gradient descent, sign gradient descent and coordinate descent, in deep homogeneous neural networks. We prove that an algorithm-dependent geometric margin increases during training and characterize the late-stage bias of the algorithms. In particular, we define a generalized notion of stationarity for optimization problems and show that the algorithms progressively reduce a (generalized) Bregman divergence, which quantifies proximity to such stationary points of a margin-maximization problem. We then experimentally zoom into the trajectories of neural networks optimized with various steepest descent algorithms, highlighting connections to the implicit bias of Adam."
    },
    {
        "title": "EXPLOITING DISTRIBUTION CONSTRAINTS FOR SCALABLE AND EFFICIENT IMAGE RETRIEVAL",
        "link_suffix": "/forum?id=d0tlL0ZWlu",
        "link": "https://openreview.net/forum?id=d0tlL0ZWlu",
        "pdf_link": "https://openreview.net/pdf?id=d0tlL0ZWlu",
        "keywords": "image retrieval, efficiency, foundation models",
        "abstract": "Image retrieval is crucial in robotics and computer vision, with downstream applications in robot place recognition and vision-based product recommendations. Modern retrieval systems face two key challenges: scalability and efficiency.\nState-of-the-art image retrieval systems train specific neural networks for each dataset, an approach that lacks scalability. Furthermore, since retrieval speed is directly proportional to embedding size, existing systems that use large embeddings lack efficiency. To tackle scalability, recent works propose using off-the-shelf foundation models. However, these models, though applicable across datasets, fall short in achieving performance comparable to that of dataset-specific models. Our key observation is that, while foundation models capture necessary subtleties for effective retrieval, the underlying distribution of their embedding space can negatively impact cosine similarity searches. We introduce Autoencoders with Strong Variance Constraints (AE-SVC), which, when used for projection, significantly improves the performance of foundation models. We provide an in-depth theoretical analysis of AE-SVC. Addressing efficiency, we introduce Single-Shot Similarity Space Distillation ((SS)2D), a novel approach to learn embeddings with adaptive sizes that offers a better trade-off between size and performance. We conducted extensive experiments on four retrieval datasets, including Stan-\nford Online Products (SoP) and Pittsburgh30k, using four different off-the-shelf foundation models, including DinoV2 and CLIP. AE-SVC demonstrates up to a 16% improvement in retrieval performance, while (SS)2D shows a further 10% improvement for smaller embedding sizes."
    },
    {
        "title": "Protein Sequence Domain Annotation using Language Models",
        "link_suffix": "/forum?id=Bd2wAQZxJW",
        "link": "https://openreview.net/forum?id=Bd2wAQZxJW",
        "pdf_link": "https://openreview.net/pdf?id=Bd2wAQZxJW",
        "keywords": "Protein homology benchmark, protein language models, protein sequence annotation, homology search, protein machine learning, protein function prediction",
        "abstract": "Protein function inference relies on annotating protein domains via sequence similarity, often modeled through profile Hidden Markov Models (profile HMMs), which capture evolutionary diversity within related domains. However, profile HMMs make strong simplifying independence assumptions when modeling residues in a sequence. Here, we introduce PSALM (Protein Sequence Annotation using Language Models), a hierarchical approach that relaxes these assumptions and uses representations of protein sequences learned by protein language models to enable high-sensitivity, high-specificity residue-level protein sequence annotation. We also develop the Multi-Domain Protein Homology Benchmark (MDPH-Bench), a benchmark for protein sequence domain annotation, where training and test sequences have been rigorously split to share no similarity between any of their domains at a given threshold of sequence identity. Prior benchmarks, which split one domain family at a time, do not support methods for annotating multi-domain proteins, where training and test sequences need to have multiple domains from different families. We validate PSALM's performance on MDPH-Bench and highlight PSALM as a promising alternative to HMMER, a state-of-the-art profile HMM-based method, for protein sequence annotation."
    },
    {
        "title": "PRE-TRAIN WITH BACKPROPAGATION AND FINE-TUNE  WITH A BIO-PLAUSIBLE LEARNING RULE",
        "link_suffix": "/forum?id=KUX2T1cY8w",
        "link": "https://openreview.net/forum?id=KUX2T1cY8w",
        "pdf_link": "https://openreview.net/pdf?id=KUX2T1cY8w",
        "keywords": "Bio-plausible, credit assignment, backpropagation, sign-symmetry, adversarial robustness",
        "abstract": "Backpropagation (BP) has long been the cornerstone of deep neural network training. While neural networks trained with backpropagation typically have high accuracy and precision, they suffer from limitations in their robustness to adversarial perturbation. Biologically plausible (bio-plausible) learning rules, on the other hand, are more robust. Yet, they typically underperform in terms of accuracy and precision, which has limited their widespread adoption. In this work, we aim to bridge this gap. We propose a novel approach where neural networks are pre-trained using backpropagation and fine-tuned using bio-plausible learning rules. We use several types of Sign-Symmetry learning methods to fine-tune models pre-trained using backpropagation. We explore the effectiveness of this approach in two tasks, image classification and image retrieval, then demonstrate that it improves robustness against gradient-based adversarial attacks while offering comparable accuracy and precision compared to the use of backpropagation alone. These findings show the benefit of mixing backpropagation and bio-plausible learning rules, suggesting the need for further research by the community to evaluate this approach on other tasks."
    },
    {
        "title": "LLM Distillation for Efficient Few-Shot Multiple Choice Question Answering",
        "link_suffix": "/forum?id=1TJSnL3ywS",
        "link": "https://openreview.net/forum?id=1TJSnL3ywS",
        "pdf_link": "https://openreview.net/pdf?id=1TJSnL3ywS",
        "keywords": "Few-shot learning, Multiple Choice Question Answering (MCQA), Data generation, Knowledge distillation, Multiple Choice Question Answering (MCQA)",
        "abstract": "Multiple Choice Question Answering (MCQA) is an important problem with numerous real-world applications, such as medicine, law, and education. The high cost of building MCQA datasets makes few-shot learning pivotal in this domain. While Large Language Models (LLMs) can enable few-shot learning, their direct application in real-world scenarios is often hindered by their high computational cost. To address this challenge, we propose a simple yet effective approach that uses LLMs for data generation and scoring. Our approach utilizes LLMs to create MCQA data which contains questions and choices, and to assign probability scores to the generated choices. We then use the generated data and LLM-assigned scores to finetune a smaller and more efficient encoder-only model, DeBERTa-v3-base by leveraging distillation loss. Extensive experiments on the Massive Multitask Language Understanding (MMLU) benchmark demonstrate that our method improves accuracy from 28.9% to 39.3%, representing a gain of over 10% compared to a baseline finetuned directly on 5-shot examples. This shows the effectiveness of LLM-driven data generation and knowledge distillation for few-shot MCQA."
    },
    {
        "title": "Recurrent Diffusion for Large-Scale Parameter Generation",
        "link_suffix": "/forum?id=CXIiV1iU3G",
        "link": "https://openreview.net/forum?id=CXIiV1iU3G",
        "pdf_link": "https://openreview.net/pdf?id=CXIiV1iU3G",
        "keywords": "parameter generation",
        "abstract": "Parameter generation has struggled to scale up for a long time, significantly lim-\niting its range of applications. In this study, we introduce Recurrent diffusion for\nlarge-scale Parameter Generation, called RPG. We first divide the trained parame-\nters into non-overlapping parts, after which a recurrent model is proposed to learn\ntheir relationships. The recurrent model\u2019s outputs, as conditions, are then fed into\na diffusion model to generate the neural network parameters. Using only a sin-\ngle GPU, recurrent diffusion enables us to generate popular vision and language\nmodels such as ConvNeXt-L and LoRA parameters of LLaMA-7B. Meanwhile,\nacross various architectures and tasks, the generated parameters consistently per-\nform comparable results over trained networks. Notably, our approach also shows\nthe potential to generate models for handling unseen tasks. This suggests that\nrecurrent diffusion largely increases the practicality of parameter generation"
    },
    {
        "title": "CinePile: A Long Video Question Answering Dataset and Benchmark",
        "link_suffix": "/forum?id=RW7Z1W1Hux",
        "link": "https://openreview.net/forum?id=RW7Z1W1Hux",
        "pdf_link": "https://openreview.net/pdf?id=RW7Z1W1Hux",
        "keywords": "Datasets and benchmarking, Video understanding, Multi-modal learning, Visual question answering, Long-form video, Metrics and benchmarks",
        "abstract": "Current datasets for long-form video understanding often fall short of providing genuine long-form comprehension challenges, as many tasks derived from these datasets can be successfully tackled by analyzing just one or a few random frames from a video. To address this issue, we present a novel dataset and benchmark, CinePile, specifically designed for authentic long-form video understanding. This paper details our innovative approach for creating a question-answer dataset, utilizing advanced LLMs with human-in-the-loop and building upon human-generated raw data. Our comprehensive dataset comprises 305,000 multiple-choice questions (MCQs), covering various visual and multimodal aspects, including temporal comprehension, understanding human-object interactions, and reasoning about events or actions within a scene. Additionally, we fine-tuned open-source Video-LLMs on the training split and evaluated both open-source and proprietary video-centric LLMs on the test split of our dataset. The findings indicate that although current models underperform compared to humans, fine-tuning these models can lead to significant improvements in their performance."
    },
    {
        "title": "Textural or Textual: How Visual Models Understand Texts in Images",
        "link_suffix": "/forum?id=8vGgdc8wOu",
        "link": "https://openreview.net/forum?id=8vGgdc8wOu",
        "pdf_link": "https://openreview.net/pdf?id=8vGgdc8wOu",
        "keywords": "Typographic attack, Vision-Language Pre-taining, Intrinsic Dimension, CLIP",
        "abstract": "It is widely assumed that typographic attacks succeed because multimodal pre-trained visual models can recognize the semantics of text within images, allowing text to interfere with image understanding. However, the assumption that these models truly comprehend textual semantics remains unclear and underexplored. We investigate how the CLIP encoder represents textual semantics and identify the mechanisms through which text disrupts visual semantic understanding. To facilitate this analysis, we propose a novel ToT (Texture or Textual) dataset, which includes a subset that disentangles orthographic forms (i.e., the visual shape of words) from their semantics. Using Intrinsic Dimension (ID) to assess layer-wise representation complexity, we examine whether the representations are built on texture or textual information under typographic manipulations. Contrary to the common belief that semantics are progressively built across layers, we find that texture and semantics compete in the early layers. In the later layers, while semantic accuracy improves, this gain primarily stems from texture learning that aids orthographic recognition. Only in the final block does the visual model construct a genuine semantic representation."
    },
    {
        "title": "AlphaEdit: Null-Space Constrained Model Editing for Language Models",
        "link_suffix": "/forum?id=HvSytvg3Jh",
        "link": "https://openreview.net/forum?id=HvSytvg3Jh",
        "pdf_link": "https://openreview.net/pdf?id=HvSytvg3Jh",
        "keywords": "Model Editing, Null-Space, Large Language Model",
        "abstract": "Large language models (LLMs)  often exhibit hallucinations due to incorrect or outdated knowledge. Hence, model editing methods have emerged to enable targeted knowledge updates. To achieve this, a prevailing paradigm  is the locating-then-editing approach, which first locates influential parameters and then edits them by introducing a perturbation. While effective, current studies have demonstrated that this perturbation inevitably disrupt the originally preserved knowledge within LLMs, especially in sequential editing scenarios.\nTo address this, we introduce AlphaEdit, a novel solution that projects perturbation onto the null space of the preserved knowledge before applying it to the parameters. We theoretically prove that this projection ensures the output of post-edited LLMs remains unchanged when queried about the preserved knowledge, thereby mitigating the issue of disruption. \nExtensive experiments on various LLMs, including LLaMA3, GPT2-XL, and GPT-J, show that AlphaEdit boosts the performance of most locating-then-editing methods by an average of 36.4% with a single line of additional code for projection solely."
    },
    {
        "title": "From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with LLM-Guided Knowledge",
        "link_suffix": "/forum?id=DlqRpj68xe",
        "link": "https://openreview.net/forum?id=DlqRpj68xe",
        "pdf_link": "https://openreview.net/pdf?id=DlqRpj68xe",
        "keywords": "reward shaping, reinforcement learning, large language model",
        "abstract": "Q-shaping is an extension of Q-value initialization and serves as an alternative to reward shaping for incorporating domain knowledge to accelerate agent training, thereby improving sample efficiency by directly shaping Q-values. This approach is both general and robust across diverse tasks, allowing for immediate impact assessment while guaranteeing optimality. We evaluated Q-shaping across 20 different environments using a large language model (LLM) as the heuristic provider. The results demonstrate that Q-shaping significantly enhances sample efficiency, achieving a \\textbf{16.87%} improvement over the best baseline in each environment and a \\textbf{253.80%} improvement compared to LLM-based reward shaping methods. These findings establish Q-shaping as a superior and unbiased alternative to conventional reward shaping in reinforcement learning."
    },
    {
        "title": "Scaling FP8 training to trillion-token LLMs",
        "link_suffix": "/forum?id=E1EHO0imOb",
        "link": "https://openreview.net/forum?id=E1EHO0imOb",
        "pdf_link": "https://openreview.net/pdf?id=E1EHO0imOb",
        "keywords": "quantization, fp8, llms, training, acceleration, compression",
        "abstract": "We train, for the first time, large language models using FP8 precision on datasets up to 2 trillion tokens --- a 20-fold increase over previous limits. Through these extended training runs, we uncover critical instabilities in FP8 training that were not observable in earlier works with shorter durations. We trace these instabilities to outlier amplification by the SwiGLU activation function. Interestingly, we show, both analytically and empirically, that this amplification happens only over prolonged training periods, and link it to a  SwiGLU weight alignment process. To address this newly identified issue, we introduce Smooth-SwiGLU, a novel modification that ensures stable FP8 training without altering function behavior. We also demonstrate, for the first time, FP8 quantization of both Adam optimizer moments. Combining these innovations, we successfully train a 7B parameter model using FP8 precision on 256 Intel Gaudi2 accelerators, achieving on-par results with the BF16 baseline while delivering up to a $\\sim$ 34 % throughput improvement. A reference implementation is supplied inhttps://github.com/Anonymous1252022/Megatron-DeepSpeed"
    },
    {
        "title": "Discrete Distribution Networks",
        "link_suffix": "/forum?id=xNsIfzlefG",
        "link": "https://openreview.net/forum?id=xNsIfzlefG",
        "pdf_link": "https://openreview.net/pdf?id=xNsIfzlefG",
        "keywords": "Generative Models, Image Generation",
        "abstract": "We introduce a novel generative model, the Discrete Distribution Networks (DDN), that approximates data distribution using hierarchical discrete distributions. We posit that since the features within a network inherently capture distributional information, enabling the network to generate multiple samples simultaneously, rather than a single output, may offer an effective way to represent distributions. Therefore, DDN fits the target distribution, including continuous ones, by generating multiple discrete sample points. To capture finer details of the target data, DDN selects the output that is closest to the Ground Truth (GT) from the coarse results generated in the first layer. This selected output is then fed back into the network as a condition for the second layer, thereby generating new outputs more similar to the GT. As the number of DDN layers increases, the representational space of the outputs expands exponentially, and the generated samples become increasingly similar to the GT. This hierarchical output pattern of discrete distributions endows DDN with unique property: more general zero-shot conditional generation. We demonstrate the efficacy of DDN and its intriguing properties through experiments on CIFAR-10 and FFHQ."
    },
    {
        "title": "3DGraphLLM: Combining Semantic Graphs and Large Language Models for 3D Referred Object Grounding",
        "link_suffix": "/forum?id=or9OfAC3kb",
        "link": "https://openreview.net/forum?id=or9OfAC3kb",
        "pdf_link": "https://openreview.net/pdf?id=or9OfAC3kb",
        "keywords": "Referred Object Grounding, 3D Scene Graph, LLM, 3D Referred Object Grounding, 3D Scene Understanding",
        "abstract": "A 3D scene graph represents a compact scene model, storing information about the objects and the semantic relationships between them, making its use promising for robotic tasks. When interacting with a user, an embodied intelligent agent should be capable of responding to various queries about the scene formulated in natural language. Large Language Models (LLMs) are beneficial solutions for user-robot interaction due to their natural language understanding and reasoning abilities. Recent methods for creating learnable representations of 3D scenes have demonstrated the potential to improve the quality of LLMs responses by adapting to the 3D world. However, the existing methods do not explicitly utilize information about the semantic relationships between objects, limiting themselves to information about their coordinates. In this work, we propose a method 3DGraphLLM for constructing a learnable representation of a 3D scene graph. The learnable representation is used as input for LLMs to perform 3D referred object grounding task. In our experiments on popular ScanRefer, RIORefer, and Multi3DRefer datasets, we demonstrate the advantage of this approach over baseline methods that do not use information about the semantic relationships between objects."
    },
    {
        "title": "Chain-of-Thought Provably Enables Learning the (Otherwise) Unlearnable",
        "link_suffix": "/forum?id=N6pbLYLeej",
        "link": "https://openreview.net/forum?id=N6pbLYLeej",
        "pdf_link": "https://openreview.net/pdf?id=N6pbLYLeej",
        "keywords": "large language models, learning theory, chain-of-thought",
        "abstract": "Modern language models have demonstrated remarkable reasoning capabilities by using chain-of-thought (CoT). One hypothesis about the inner workings of CoT is that it breaks down originally complex tasks into smaller subtasks that are more amenable to learning. We formalize this notion by showing possibility and impossibility results of learning from in-context demonstrations with and without CoT. In particular, with CoT, we examine a family of learning algorithms that learn a task step-by-step, capable of composing simpler functions from individual reasoning steps to form an overall complex function. This process reduces the difficulty of learning a task to that of the hardest reasoning step in the chain. Moreover, we prove Transformers can express this algorithm and thus they can efficiently in-context learn arbitrary tasks as long as these tasks can be decomposed into a finite number of subtasks, each of which are efficiently learnable. In contrast, without CoT, we demonstrate that there exist tasks that are inherently unlearnable by the same algorithm. Overall, our results suggest several provably effective ways for decomposing target problems to instantiate CoT. Empirically, we demonstrate our proposed CoT construction significantly enhances the reasoning capabilities of real-world LLMs in solving challenging arithmetic reasoning tasks, including learning polynomials and Boolean formulas."
    },
    {
        "title": "Programming Every Example: Lifting Pre-training Data Quality like Experts at Scale",
        "link_suffix": "/forum?id=UNxCphTxWp",
        "link": "https://openreview.net/forum?id=UNxCphTxWp",
        "pdf_link": "https://openreview.net/pdf?id=UNxCphTxWp",
        "keywords": "Large Language Models, Pre-training, Data Refinement, Data Engineering",
        "abstract": "Large language model pre-training has traditionally relied on human experts to craft heuristics for improving the corpora quality, resulting in numerous rules developed to date. However, these rules lack the flexibility to address the unique characteristics of individual example effectively.\nMeanwhile, applying tailored rules to every example is impractical for human experts.\nIn this paper, we demonstrate that even small language models, with as few as 0.3B parameters, can exhibit substantial\ndata refining capabilities comparable to those of human experts.\nWe introduce Programming Every Example (ProX), a novel framework that treats data refinement as a programming task, enabling models to refine corpora by generating and executing fine-grained operations, such as string normalization, for each individual example at scale.\nExperimental results show that models pre-trained on ProX-curated data outperform either original data or data curated via selection methods by more than 2% across 10 downstream benchmarks.\nIts effectiveness spans various model sizes (0.3B~1.7B) and pre-training corpora (C4, RedPajama-V2, and FineWeb).\nFurthermore, ProX shows great potential in domain-specific continual pre-training: models trained on OpenWebMath refined by ProX outperform human-crafted rule-based methods, improving accuracy by 7.6% on Mistral-7B, 14.6% on Llama-2-7B, and 20.3% on CodeLlama-7B within 10B tokens, comparable to Llemma-7B trained on 200B tokens. ProX significantly reduces training FLOPs, offering an efficient path for LLM pre-training."
    },
    {
        "title": "Glad: A Streaming Scene Generator for Autonomous Driving",
        "link_suffix": "/forum?id=ZFxpclrCCf",
        "link": "https://openreview.net/forum?id=ZFxpclrCCf",
        "pdf_link": "https://openreview.net/pdf?id=ZFxpclrCCf",
        "keywords": "Video Generation; Autonomous Driving",
        "abstract": "The generation and simulation of diverse real-world scenes have significant application value in the field of autonomous driving, especially for the corner cases. Recently, researchers have explored employing neural radiance fields or diffusion models to generate novel views or synthetic data under driving scenes. However, these approaches suffer from unseen scenes or restricted video length, thus lacking sufficient adaptability for data generation and simulation. To address these issues, we propose a simple yet effective framework, named Glad, to generate video data in a frame-by-frame style. To ensure the temporal consistency of synthetic video, we introduce a latent variable propagation module, which views the hidden features of previous frame as noise prior and injects it into the latent features of current frame. In addition, we design a streaming data sampler to orderly sample the original image in a video clip at continuous iterations. \nGiven the reference frame, our Glad can be viewed as a streaming simulator by generating the videos for specific scenes. \nExtensive experiments are performed on the widely-used nuScenes dataset. Experimental results demonstrate that our proposed  Glad achieves promising performance, serving as a strong baseline for online generation. We will release the source code and models publicly."
    },
    {
        "title": "GAMEBOT: Gaming Arena for Model Evaluation - Battle of Tactics",
        "link_suffix": "/forum?id=dr0s6aGYb7",
        "link": "https://openreview.net/forum?id=dr0s6aGYb7",
        "pdf_link": "https://openreview.net/pdf?id=dr0s6aGYb7",
        "keywords": "LLM evaluation, benchmark, competitive game",
        "abstract": "Large Language Models (LLMs) are increasingly deployed in real-world applications that demand complex reasoning. To track progress, we require robust benchmarks to evaluate their capabilities beyond superficial pattern recognition. However, existing benchmarks either suffer from data contamination or lack legibility. In this paper, we introduce GAMEBOT, a novel benchmark for evaluating LLMs in competitive gaming environments that addresses these limitations. GAMEBOT decomposes complex reasoning in games into modular subproblems, targeting abilities like rule understanding and strategy instruction following. We develop Chain-of-Thought (CoT) prompts that leverage domain knowledge to guide LLMs and automatically validate their intermediate reasoning steps against ground truth. This approach allows us to assess not only the accuracy of final decisions but also the quality of the underlying reasoning process. We benchmark 17 prominent LLMs across eight diverse games, encompassing various strategic abilities and game characteristics. GAMEBOT offers four advantages: (1) Mitigation of Data Contamination: Dynamic game states minimize overlap with pre-training data. (2) Legibility: Evaluation of intermediate reasoning steps enables fine-grained scrutiny of LLM behavior. (3) Difficulty: The games effectively differentiate top-performing models. (4) Stronger Baselines: Our curated CoT prompts establish competitive baselines for future research. We hope GAMEBOT stimulates further work that seeks a deeper understanding of LLM reasoning capabilities in strategic settings."
    },
    {
        "title": "Out-of-Distribution Detection using Synthetic Data Generation",
        "link_suffix": "/forum?id=8mM5NzC7da",
        "link": "https://openreview.net/forum?id=8mM5NzC7da",
        "pdf_link": "https://openreview.net/pdf?id=8mM5NzC7da",
        "keywords": "Out-of-distribution, Large Language Models, Natural Language Processing, Alignment, Safety",
        "abstract": "Distinguishing in- and out-of-distribution (OOD) inputs is crucial for reliable deployment of classification systems. However, OOD data is typically unavailable or difficult to collect, posing a significant challenge for accurate OOD detection. In this work, we present a method that harnesses the generative capabilities of Large Language Models (LLMs) to create high-quality synthetic OOD proxies, eliminating the dependency on any external OOD data source. We study the efficacy of our method on classical text classification tasks such as toxicity detection and sentiment classification as well as classification tasks arising in LLM development and deployment, such as training a reward model for RLHF and detecting misaligned generations. Extensive experiments on nine InD-OOD dataset pairs and various model sizes show that our approach dramatically lowers false positive rates (achieving a perfect zero in some cases) while maintaining high accuracy on in-distribution tasks, outperforming baseline methods by a significant margin."
    },
    {
        "title": "Neuro-symbolic Entity Alignment via Variational Inference",
        "link_suffix": "/forum?id=NNUiUwQWx6",
        "link": "https://openreview.net/forum?id=NNUiUwQWx6",
        "pdf_link": "https://openreview.net/pdf?id=NNUiUwQWx6",
        "keywords": "Entity alignment, neuro-symbolic reasoning, graph representation learning",
        "abstract": "Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying equivalent entity pairs. Existing methods can be categorized into symbolic and neural models. Symbolic models, while precise, struggle with substructure heterogeneity and sparsity, whereas neural models, although effective, generally lack interpretability and cannot handle uncertainty. We propose NeuSymEA, a probabilistic neuro-symbolic framework that combines the strengths of both methods. NeuSymEA models the joint probability of all possible pairs' truth scores in a Markov random field, regulated by a set of rules, and optimizes it with the variational EM algorithm. In the E-step, a neural model parameterizes the truth score distributions and infers missing alignments. In the M-step, the rule weights are updated based on the observed and inferred alignments. To facilitate interpretability, we further design a path-ranking-based explainer upon this framework that generates supporting rules for the inferred alignments. Experiments on benchmarks demonstrate that NeuSymEA not only significantly outperforms baselines in terms of effectiveness and robustness, but also provides interpretable results."
    },
    {
        "title": "Math for AI: On the Generalization of Learning Mathematical Problem Solving",
        "link_suffix": "/forum?id=th63j8qHa6",
        "link": "https://openreview.net/forum?id=th63j8qHa6",
        "pdf_link": "https://openreview.net/pdf?id=th63j8qHa6",
        "keywords": "Large Language Models, Mathematical Reasoning, Reasoning Generalization",
        "abstract": "There has been a growing interest in enhancing the mathematical problem-solving (MPS) capabilities of LLMs. While some researchers focus on developing specialized math models to advance AI for math, others study mathematical reasoning with a math for AI perspective, positing that integrating mathematical reasoning data could enable LLMs to perform complex reasoning more broadly. This hypothesis draws from neuroscience studies which show that solving mathematical problems aids in the development of general reasoning skills in humans. The concept of ''math for AI'' has gained particular relevance as the research community increasingly focuses on complex reasoning -- Given the scarcity of complex and lengthy chain-of-thought data, MPS emerges as a prime candidate for collecting or synthesizing substantial volumes of intricate thought processes, thus serving as a potential key resource for enhancing general complex reasoning. However, it remains unclear whether skills acquired through learning MPS can extend to other reasoning tasks or merely improve MPS-specific benchmark scores. \nIn this paper, we present a comprehensive empirical analysis to address this question.\nSpecifically, we explore three prevalent methods for improving MPS: (1) continual pretraining on mathematical text; (2) instruction pretraining on large-scale QA pairs synthesized from raw text; and (3) instruction tuning on MPS datasets. \nThrough controlled experiments and evaluations across seven distinct reasoning domains, we find that extensive continual pretraining on mathematical texts can improve performance on most non-MPS reasoning tasks generally. However, other dominant approaches of enhancing MPS performance fail to achieve significant gains on broad reasoning tasks. These findings indicate that most readily available data sources do not support the ''math for AI'' objective in enhancing non-MPS tasks. Identifying which data sources best contribute to the acquisition of complex reasoning skills remains a crucial question for future research."
    }
]
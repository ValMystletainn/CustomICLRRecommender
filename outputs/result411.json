[{"title": "DeFoG: Defogging Discrete Flow Matching for Graph Generation", "link_suffix": "/forum?id=ZGRRC514rI", "link": "https://openreview.net/forum?id=ZGRRC514rI", "pdf_link": "https://openreview.net/pdf?id=ZGRRC514rI", "keywords": "Graph Generation, Discrete Flow Models, Molecule Generation, Permutation Equivariance, Flow Matching", "abstract": "Graph generation is fundamental in diverse scientific applications, due to its ability to reveal the underlying distribution of complex data, and eventually generate new, realistic data points.\nDespite the success of diffusion models in this domain, those face limitations in sampling efficiency and flexibility, stemming from the tight coupling between the training and sampling stages.\nTo address this, we propose DeFoG, a novel framework using discrete flow matching for graph generation. DeFoG employs a flow-based approach that features an efficient linear interpolation noising process and a flexible denoising process based on a continuous-time Markov chain formulation.\nWe leverage an expressive graph transformer and ensure desirable node permutation properties to respect graph symmetry.\nCrucially, our framework enables a disentangled design of the training and sampling stages, enabling more effective and efficient optimization of model performance.\nWe navigate this design space by introducing several algorithmic improvements that boost the model performance, consistently surpassing existing diffusion models.\nWe also theoretically demonstrate that, for general discrete data, discrete flow models can faithfully replicate the ground truth distribution -  a result that naturally extends to graph data and reinforces DeFoG's foundations.\nExtensive experiments show that DeFoG achieves state-of-the-art results on synthetic and molecular datasets, improving both training and sampling efficiency over diffusion models, and excels in conditional generation on a digital pathology dataset.", "title_embedding_index": 20500, "title_abs_embedding_index": 20525}, {"title": "Granularity Matters in Long-Tail Learning", "link_suffix": "/forum?id=BLvCdxAi8W", "link": "https://openreview.net/forum?id=BLvCdxAi8W", "pdf_link": "https://openreview.net/pdf?id=BLvCdxAi8W", "keywords": "Long-Tail Learning; Granularity; Category extrapolation", "abstract": "Balancing training on long-tail data distributions remains a long-standing challenge in deep learning. While methods such as re-weighting and re-sampling help alleviate the imbalance issue, limited sample diversity continues to hinder models from learning robust and generalizable feature representations, particularly for tail classes. In contrast to existing methods, we offer a novel perspective on long-tail learning, inspired by an observation: datasets with finer granularity tend to be less affected by data imbalance. In this paper, we investigate this phenomenon through both quantitative and qualitative studies, showing that increased granularity enhances the generalization of learned features in tail categories. Motivated by these findings, we propose a method to increase dataset granularity through category extrapolation. Specifically, we introduce open-set auxiliary classes that are visually similar to existing ones, aiming to enhance representation learning for both head and tail classes. This forms the core contribution and insight of our approach. To automate the curation of auxiliary data, we leverage large language models (LLMs) as knowledge bases to search for auxiliary categories and retrieve relevant images through web crawling. To prevent the overwhelming presence of auxiliary classes from disrupting training, we introduce a neighbor-silencing loss that encourages the model to focus on class discrimination within the target dataset. During inference, the classifier weights for auxiliary categories are masked out, leaving only the target class weights for use.  Extensive experiments and ablation studies on three standard long-tail benchmarks demonstrate the effectiveness of our approach, notably outperforming strong baseline methods that use the same amount of data. The code will be made publicly available.", "title_embedding_index": 20501, "title_abs_embedding_index": 20526}, {"title": "M3CoL: Harnessing Shared Relations via Multimodal Mixup Contrastive Learning for Multimodal Classification", "link_suffix": "/forum?id=xnWikQRJBR", "link": "https://openreview.net/forum?id=xnWikQRJBR", "pdf_link": "https://openreview.net/pdf?id=xnWikQRJBR", "keywords": "Contrastive learning, multimodal learning, representation learning, mutlimodal classification", "abstract": "Deep multimodal learning has shown remarkable success by leveraging contrastive learning to capture explicit one-to-one relations across modalities. However, real-world data often exhibits shared relations beyond simple pairwise associations. We propose M3CoL, a Multimodal Mixup Contrastive Learning approach to capture nuanced shared relations inherent in multimodal data. Our key contribution is a Mixup-based contrastive loss that learns robust representations by aligning mixed samples from one modality with their corresponding samples from other modalities thereby capturing shared relations between them. For multimodal classification tasks, we introduce a framework that integrates a fusion module with unimodal prediction modules for auxiliary supervision during training, complemented by our proposed Mixup-based contrastive loss. Through extensive experiments on diverse datasets (N24News, ROSMAP, BRCA, and Food-101), we demonstrate that M3CoL effectively captures shared multimodal relations and generalizes across domains. It outperforms state-of-the-art methods on N24News, ROSMAP, and BRCA, while achieving comparable performance on Food-101. Our work highlights the significance of learning shared relations for robust multimodal learning, opening up promising avenues for future research.", "title_embedding_index": 20502, "title_abs_embedding_index": 20527}, {"title": "Collaborative and Efficient Personalization with Mixtures of Adaptors", "link_suffix": "/forum?id=IaFAvyaBOc", "link": "https://openreview.net/forum?id=IaFAvyaBOc", "pdf_link": "https://openreview.net/pdf?id=IaFAvyaBOc", "keywords": "federated learning, collaborative learning, adaptors", "abstract": "Non-iid data is prevalent in real-world federated learning problems. Data heterogeneity can come in different types in terms of distribution shifts. In this work, we are interested in the heterogeneity that comes from concept shifts, i.e., shifts in the prediction across clients. In particular, we consider multi-task learning, where we want the model to adapt to the task of the client. We propose a parameter-efficient framework to tackle this issue, where each client learns to mix between parameter-efficient adaptors according to its task. We use Low-Rank Adaptors (LoRAs) as the backbone and extend its concept to other types of layers. We call our framework Federated Low-Rank Adaptive Learning (FLoRAL). This framework is not an algorithm but rather a model parameterization for a multi-task learning objective, so it can work on top of any algorithm that optimizes this objective, which includes many algorithms from the literature. FLoRAL is memory-efficient, and clients are personalized with small states (e.g., one number per adaptor) as the adaptors themselves are federated. Hence, personalization is--in this sense--federated as well. Even though clients can personalize more freely by training an adaptor locally, we show that collaborative and efficient training of adaptors is possible and performs better. We also show that FLoRAL can outperform an ensemble of full models with optimal cluster assignment, which demonstrates the benefits of federated personalization and the robustness of FLoRAL to overfitting. We show promising experimental results on synthetic datasets, real-world federated multi-task problems such as MNIST, CIFAR-10, and CIFAR-100. We also provide a theoretical analysis of local SGD on a relaxed objective and discuss the effects of aggregation mismatch on convergence.", "title_embedding_index": 20503, "title_abs_embedding_index": 20528}, {"title": "Bayesian Policy Distillation via Offline RL for Lightweight and Fast Inference", "link_suffix": "/forum?id=zz9jAssrwL", "link": "https://openreview.net/forum?id=zz9jAssrwL", "pdf_link": "https://openreview.net/pdf?id=zz9jAssrwL", "keywords": "neural network compression, reinforcement learning, robot learning", "abstract": "High-performance deep reinforcement learning faces tremendous challenges when implemented on cost-effective low-end embedded systems due to its heavy computational burden. To address this issue, we propose a policy distillation method called Bayesian Policy Distillation (BPD), which effectively retrains small-sized neural networks through an offline reinforcement learning approach. BPD exploits Bayesian neural networks to distill already designed high-performance policy networks by adopting value optimizing, behavior cloning, and sparsity-inducing strategies. Simulation results reveal that the proposed BPD successfully compresses the policy networks, making them lighter and achieving faster inference time. Furthermore, the proposed approach is demonstrated with a real inverted pendulum system and reduced the inference time and memory size by 78 % and 98 %, respectively.", "title_embedding_index": 20504, "title_abs_embedding_index": 20529}, {"title": "Hadamard Representations: Augmenting Hyperbolic Tangents in RL", "link_suffix": "/forum?id=9JE3HogPCw", "link": "https://openreview.net/forum?id=9JE3HogPCw", "pdf_link": "https://openreview.net/pdf?id=9JE3HogPCw", "keywords": "Representation Learning, Reinforcement Learning, Activation Functions", "abstract": "Activation functions are one of the key components of a deep neural network. The most commonly used activation functions can be classed into the category of continuously differentiable (e.g. tanh) and linear-unit functions (e.g. ReLU), both having their own strengths and drawbacks with respect to downstream performance and representation capacity through learning (e.g. measured by the number of dead neurons and the effective rank). In reinforcement learning, the performance of continuously differentiable activations often falls short as compared to linear-unit functions. We provide insights into the vanishing gradients associated with the former, and show that the dying neuron problem is not exclusive to ReLU's. To alleviate vanishing gradients and the resulting dying neuron problem occurring with continuously differentiable activations, we propose a Hadamard representation. Using deep Q-networks and proximal policy optimization in the Atari domain, we show faster learning, a reduction in dead neurons and increased effective rank.", "title_embedding_index": 20505, "title_abs_embedding_index": 20530}, {"title": "Methods for Convex(L0,L1)-Smooth Optimization: Clipping, Acceleration, and Adaptivity", "link_suffix": "/forum?id=0wmfzWPAFu", "link": "https://openreview.net/forum?id=0wmfzWPAFu", "pdf_link": "https://openreview.net/pdf?id=0wmfzWPAFu", "keywords": "generalized smoothness, first-order optimization, convex optimization, Polyak stepsizes, gradient clipping, adaptive optimization, acceleration", "abstract": "Due to the non-smoothness of optimization problems in Machine Learning, generalized smoothness assumptions have gained much attention in recent years. One of the most popular assumptions of this type is $(L_0, L_1)$-smoothness  (Zhang et al., 2020). In this paper, we focus on the class of (strongly) convex $(L_0, L_1)$-smooth functions and derive new convergence guarantees for several existing methods. In particular, we derive improved convergence rates for Gradient Descent with (Smoothed) Gradient Clipping and for Gradient Descent with Polyak Stepsizes. In contrast to the existing results, our rates do not rely on the standard smoothness assumption and do not suffer from the exponential dependency from the initial distance to the solution. We also extend these results to the stochastic case under the over-parameterization assumption, propose a new accelerated method for convex  $(L_0, L_1)$-smooth optimization, and derive new convergence rates for Adaptive Gradient Descent (Malitsky and Mishchenko, 2020).", "title_embedding_index": 20506, "title_abs_embedding_index": 20531}, {"title": "DRL: DISCRIMINATIVE REPRESENTATION LEARNING FOR CLASS INCREMENTAL LEARNING", "link_suffix": "/forum?id=a59NMkKPob", "link": "https://openreview.net/forum?id=a59NMkKPob", "pdf_link": "https://openreview.net/pdf?id=a59NMkKPob", "keywords": "class incremental learning", "abstract": "Non-rehearsal class incremental learning (CIL) is pivotal in real-world scenarios such as data streaming applications and data security. \nDespite the remarkable progress in research on CIL, it remains an extremely challenging task due to three  conundrums: increasingly large model complexity, non-smooth representation shift during incremental learning and inconsistency between stage-wise sub-problem optimization and global inference. In this work, we propose the Discriminative Representation Learning (\\emph{DRL}) method to deal with these challenges specifically. To conduct incremental learning effectively and yet efficiently, our \\emph{DRL} is built upon a pre-trained large model with excellent representation learning capability, and increasingly augments the model by learning a lightweight adapter with a small amount of parameter learning overhead in each incremental learning stage. While the adapter is responsible for adapting the model to new classes of data involved in current learning stage, it can inherit and propagate the representation capability from the current model via parallel connection between them. As a result, such design can guarantee a smooth representation shift between different stages of incremental learning. Furthermore, to alleviate the issue of the training-inference inconsistency induced by the stage-wise sub-optimization, we design the Margin-CE loss, which imposes a hard margin between classification boundaries to push for more discriminative representation learning, thereby narrowing down the gap between stage-wise local optimization over a subset of data and global inference on all classes of data. Extensive experiments on six benchmarks reveal that our \\emph{DRL} consistently outperforms other state-of-the-art methods throughout the entire CIL period while maintaining high efficiency in both training and inference phases.", "title_embedding_index": 20507, "title_abs_embedding_index": 20532}, {"title": "Geometric Inductive Biases of Deep Networks: The Role of Data and Architecture", "link_suffix": "/forum?id=cmXWYolrlo", "link": "https://openreview.net/forum?id=cmXWYolrlo", "pdf_link": "https://openreview.net/pdf?id=cmXWYolrlo", "keywords": "Optimization, Deep Neural Networks, Deep Learning, Deep Learning Theory, Machine Learning Theory", "abstract": "In this paper, we propose thegeometric invariance hypothesis (GIH), which argues that when training a neural network, the input-space curvature remains invariant under transformation in certain directions determined by its architecture. Starting with a simple non-linear binary classification problem residing on a hyperplane in a high dimensional space, we observe that while an MLP can solve this problem regardless of the orientation of the hyperplane, this is not the case for a ResNet. Motivated by this example, we define two maps that provide a compactarchitecture-dependentsummary of the input-space geometry of a neural network and its evolution during training, which we dub the average geometry and average geometry evolution, respectively. By investigating these two maps through theoretical and empirical means, we show that GIH is caused by the average geometry evolution being close to the projection of data covariance onto average geometry, resulting in an invariance property when the average geometry is low-rank. Finally, we present extensive experimental results to observe the consequences of GIH and how it relates to generalization in neural networks.", "title_embedding_index": 20508, "title_abs_embedding_index": 20533}, {"title": "Scaling Laws for Diffusion Transformers", "link_suffix": "/forum?id=iIGNrDwDuP", "link": "https://openreview.net/forum?id=iIGNrDwDuP", "pdf_link": "https://openreview.net/pdf?id=iIGNrDwDuP", "keywords": "Scaling Laws, Diffusion Models, Transformers, Generative Models", "abstract": "Diffusion transformers (DiT) have already achieved appealing synthesis and scaling properties in content recreation, \\emph{e.g.,} image and video generation.However, scaling laws of DiT are less explored, which usually offer precise predictions regarding optimal model size and data requirements given a specific compute budget.Therefore, experiments across a broad range of compute budgets, from \\texttt{1e17} to \\texttt{6e18} FLOPs are conducted to confirm the existence of scaling laws in DiT \\emph{for the first time}. Concretely, the loss of pretraining DiT also follows a power-law relationship with the involved compute.Based on the scaling law, we can not only determine the optimal model size and required data but also accurately predict the text-to-image generation loss given a model with 1B parameters and a compute budget of \\texttt{1e21} FLOPs.Additionally, we also demonstrate that the trend of pretraining loss matches the generation performances (\\emph{e.g.,} FID), even across various datasets, which complements the mapping from compute to synthesis quality and thus provides a predictable benchmark that assesses model performance and data quality at a reduced cost.", "title_embedding_index": 20509, "title_abs_embedding_index": 20534}, {"title": "FedPeWS: Personalized Warmup via Subnetworks for Enhanced Heterogeneous Federated Learning", "link_suffix": "/forum?id=MeSfNZjGvN", "link": "https://openreview.net/forum?id=MeSfNZjGvN", "pdf_link": "https://openreview.net/pdf?id=MeSfNZjGvN", "keywords": "federated learning, heterogeneous federated learning, subnetworks, personalized warmup", "abstract": "Statistical data heterogeneity is a significant barrier to convergence in federated learning (FL). While prior work has advanced heterogeneous FL through better optimization objectives, these methods fall short when there is \\textit{extreme} data heterogeneity among collaborating participants. We hypothesize that convergence under extreme data heterogeneity is primarily hindered due to the aggregation of conflicting updates from the participants in the initial collaboration rounds. To overcome this problem, we propose a warmup phase where each participant learns a personalized mask and updates only a subnetwork of the full model. This \\textit{personalized warmup} allows the participants to focus initially on learning specific \\textit{subnetworks} tailored to the heterogeneity of their data. After the warmup phase, the participants revert to standard federated optimization, where all parameters are communicated. We empirically demonstrate that the proposed personalized warmup via subnetworks (\\texttt{FedPeWS}) approach improves accuracy and convergence speed over standard federated optimization methods.", "title_embedding_index": 20510, "title_abs_embedding_index": 20535}, {"title": "Unlocking the Theory Behind Scaling 1-Bit Neural Networks", "link_suffix": "/forum?id=x5YEibapUM", "link": "https://openreview.net/forum?id=x5YEibapUM", "pdf_link": "https://openreview.net/pdf?id=x5YEibapUM", "keywords": "1-bit neural network, quantization, neural tangent kernel", "abstract": "Recently, 1-bit Large Language Models (LLMs) have emerged, showcasing an impressive combination of efficiency and performance that rivals traditional LLMs. Research by Wang et al. (2023); Ma et al. (2024) indicates that the performance of these 1-bit LLMs progressively improves as the number of parameters increases, hinting at the potential existence of aScaling Law for 1-bit Neural Networks. In this paper, we present the \\emph{first theoretical} result that rigorously establishes this scaling law for 1-bit models. We prove that, despite the constraint of weights restricted to $\\{-1, +1\\}$, the dynamics of model training inevitably align with kernel behavior as the network width grows. This theoretical breakthrough guarantees convergence of the 1-bit model to an arbitrarily small loss as width increases. Furthermore, we introduce the concept of the generalization difference, defined as the gap between the outputs of 1-bit networks and their full-precision counterparts, and demonstrate that this difference maintains a negligible level as network width scales. Building on the work of Kaplan et al. (2020), we conclude by examining how the training loss scales as a power-law function of the model size, dataset size, and computational resources utilized for training. Our findings underscore the promising potential of scaling 1-bit neural networks, suggesting that int1 could become the standard in future neural network precision.", "title_embedding_index": 20511, "title_abs_embedding_index": 20536}, {"title": "Noisy Data Pruning by Label Distribution Discrimination", "link_suffix": "/forum?id=6PGT9OJX5N", "link": "https://openreview.net/forum?id=6PGT9OJX5N", "pdf_link": "https://openreview.net/pdf?id=6PGT9OJX5N", "keywords": "data pruning; coreset selection; noise label learning; data centric-ai", "abstract": "Data pruning aims to prune large-scale datasets into concise subsets, thereby reducing computational costs during model training.\nWhile a variety of data pruning methods have been proposed, most focus on meticulously curated datasets, and relatively few studies address real-world datasets containing noisy labels. In this paper, we empirically analyze the shortcomings of previous gradient-based methods, revealing that geometry-based methods exhibit greater resilience to noisy labels. Consequently, we propose a novel two-stage noisy data pruning method that incorporates selection and re-labeling processes, which takes into account geometric neighboring information. Specifically, we utilize the distribution divergence between a given label and the predictions of its neighboring samples as an importance metric for data pruning. To ensure reliable neighboring predictions, we employ feature propagation and label propagation to refine these predictions effectively. Furthermore, we utilize re-labeling methods to correct selected subsets and consider the coverage of both easy and hard samples at different pruning rates. Extensive experiments demonstrate the effectiveness of the proposed method, not only on real-world benchmarks but also on synthetic datasets, highlighting its suitability for practical applications with noisy label scenarios.", "title_embedding_index": 20512, "title_abs_embedding_index": 20537}, {"title": "InsBank: Evolving Instruction Subset for Ongoing Alignment", "link_suffix": "/forum?id=9wvVFldF0u", "link": "https://openreview.net/forum?id=9wvVFldF0u", "pdf_link": "https://openreview.net/pdf?id=9wvVFldF0u", "keywords": "Large Language Model, Instruction Tuning, Data Efficient Training", "abstract": "Pre-trained large language models (LLMs) typically undergo instruction fine-tuning to improve alignment. Recent research highlights that the quality and diversity of instruction data are more critical than data quantity, prompting the selection of diverse, high-quality instruction subsets to reduce training costs. However, how to evolve these selected subsets alongside the development of new instruction data remains insufficiently explored. To achieve LLMs' ongoing alignment, we introduce Instruction Bank (InsBank), a continuously updated repository that integrates the latest valuable instructional data. We further propose Progressive Instruction Bank Evolution (PIBE), a novel framework designed to evolve InsBank effectively and efficiently over time. It firstly employs a gradual data selection strategy to maintain long-term efficiency, utilizing a representation-based diversity score that captures relationships between data points and retains historical information for comprehensive diversity evaluation. This also allows for flexible combination of diversity and quality scores during data selection and ranking. Extensive experiments demonstrate that PIBE significantly outperforms baseline methods in evolving InsBank. Additionally, PIBE enables users to flexibly extract smaller subsets based on their specific budget.", "title_embedding_index": 20513, "title_abs_embedding_index": 20538}, {"title": "Spatiotemporal Contrast Are Natural Urban Scene Learners", "link_suffix": "/forum?id=oEMSM8HHpj", "link": "https://openreview.net/forum?id=oEMSM8HHpj", "pdf_link": "https://openreview.net/pdf?id=oEMSM8HHpj", "keywords": "contrastive learning, self-supervied learning, street view images", "abstract": "Street view imagery is a widely utilized representation of urban visual environments and supports various sustainable development tasks such as environmental perception and socio-economic assessment. However, it is challenging for existing image representations to specifically encode the dynamic urban environment (such as pedestrians, vehicles, and vegetation), the built environment (including buildings, roads, and urban infrastructure), and the environmental ambiance (such as the cultural and socioeconomic atmosphere) depicted in street view imagery to address downstream tasks related to the city.\nThis work innovatively leverages temporal and spatial attributes of street view imagery to propose an unsupervised learning framework suitable for diverse downstream tasks. By employing street view images captured at the same location over time and spatially nearby views at the same time, we construct contrastive learning tasks designed to learn the temporal-invariant characteristics of the built environment and the spatial-invariant neighborhood ambiance. Our approach significantly outperforms traditional supervised and unsupervised methods in tasks such as visual place recognition, socioeconomic estimation, and human-environment perception. Moreover, we demonstrate the varying behaviors of image representations learned through different contrastive learning strategies across various downstream tasks. This study systematically discusses representation learning strategies for urban studies based on street view images, providing a benchmark that enhances the applicability of visual data in urban science.", "title_embedding_index": 20514, "title_abs_embedding_index": 20539}, {"title": "Hierarchical Prompts with Context-aware Calibration for Open-Vocabulary Object Detection", "link_suffix": "/forum?id=jCNRcHrfLo", "link": "https://openreview.net/forum?id=jCNRcHrfLo", "pdf_link": "https://openreview.net/pdf?id=jCNRcHrfLo", "keywords": "open-vocabulary object detection, prompts tuning, knowledge distillation", "abstract": "Open Vocabulary Object Detection (OVD) aims to extend to novel classes solely through text descriptions, by learning the mapping between images and text from the base class. However, current methods focus on establishing connections between the visual regions of the target objects and their corresponding category names to learn prompts, ignoring richer contextual information and shared knowledge about these categories, which can easily lead to overfitting on known base categories and exhibit poor generalization to novel classes. To address the above problems, we propose Hierarchical prompts with Context-Aware calibration (HiCA) for open-vocabulary object detection, which integrates high-level semantic and contextual information into the detector from both linguistic and visual perspectives.\nHierarchical prompts effectively map regions with superior-level semantics, which encompasses shared knowledge of both base and novel classes, thereby enhancing the model's generalization ability to novel classes. Context-aware calibration utilizes the visual context of the image to establish the correlation between contextual information and categories, thereby minimizing the adverse effects of the background and enhancing generalization to novel classes. Extensive experiments demonstrate that the hierarchical prompts with context-aware calibration can effectively improve the performance of the open vocabulary detection methods. Especially on the OV-COCO, we achieve 57.2%  base class mAP, surpassing the current state-of-the-art by 2.4% while achieving the best overall mAP.", "title_embedding_index": 20515, "title_abs_embedding_index": 20540}, {"title": "A Simple but Strong Baseline for Sounding Video Generation: Effective Adaptation of Audio and Video Diffusion Models for Joint Generation", "link_suffix": "/forum?id=WqL4wOU3tw", "link": "https://openreview.net/forum?id=WqL4wOU3tw", "pdf_link": "https://openreview.net/pdf?id=WqL4wOU3tw", "keywords": "sounding video generation, diffusion models, audio-visual, audio generation, video generation", "abstract": "In this work, we build a simple but strong baseline for sounding video generation. Given base diffusion models for audio and video, we integrate them with additional modules into a single model and train it to make the model jointly generate audio and video. To enhance alignment between audio-video pairs, we introduce two novel mechanisms in our model. The first one is timestep adjustment, which provides different timestep information to each base model. It is designed to align how samples are generated along with timesteps across modalities. The second one is a new design of the additional modules, termed Cross-Modal Conditioning as Positional Encoding (CMC-PE). In CMC-PE, cross-modal information is embedded as if it represents temporal position information, and the embeddings are fed into the model like positional encoding. Compared with the popular cross-attention mechanism, CMC-PE provides a better inductive bias for temporal alignment in the generated data. Experimental results validate the effectiveness of the two newly introduced mechanisms and also demonstrate that our method outperforms existing methods. The source code will be released upon acceptance.", "title_embedding_index": 20516, "title_abs_embedding_index": 20541}, {"title": "Minimax Optimal Reinforcement Learning with Quasi-Optimism", "link_suffix": "/forum?id=i8LCUpKvAz", "link": "https://openreview.net/forum?id=i8LCUpKvAz", "pdf_link": "https://openreview.net/pdf?id=i8LCUpKvAz", "keywords": "Reinforcement Learning, Tabular Reinforcement Learning, Regret Analysis", "abstract": "In our quest for a reinforcement learning (RL) algorithm that is both practical and provably optimal, we introduce EQO (Exploration via Quasi-Optimism). Unlike existing minimax optimal approaches, EQO avoids reliance on empirical variances and employs a simple bonus term proportional to the inverse of the state-action visit count. Central to EQO is the concept ofquasi-optimism, where estimated values need not be fully optimistic, allowing for a simpler yet effective exploration strategy. The algorithm achieves the sharpest known regret bound for tabular RL under the mildest assumptions, proving that fast convergence can be attained with a practical and computationally efficient approach. Empirical evaluations demonstrate that EQO consistently outperforms existing algorithms in both regret performance and computational efficiency, providing the best of both theoretical soundness and practical effectiveness.", "title_embedding_index": 20517, "title_abs_embedding_index": 20542}, {"title": "Weakly-Supervised Affordance Grounding Guided by Part-Level Semantic Priors", "link_suffix": "/forum?id=0823rvTIhs", "link": "https://openreview.net/forum?id=0823rvTIhs", "pdf_link": "https://openreview.net/pdf?id=0823rvTIhs", "keywords": "weakly supervised affordance grounding, foundation model, pseudo label", "abstract": "In this work, we focus on the task of weakly supervised affordance grounding, where a model is trained to identify affordance regions on objects using human-object interaction images and egocentric object images without dense labels. \nPrevious works are mostly built upon class activation maps, which are effective for semantic segmentation but may not be suitable for locating actions and functions. Leveraging recent advanced foundation models, we develop a supervised training pipeline based on pseudo labels. The pseudo labels are generated from an off-the-shelf part segmentation model, guided by a mapping from affordance to part names.\nFurthermore, we introduce three key enhancements to the baseline model: a label refining stage, a fine-grained feature alignment process, and a lightweight reasoning module. These techniques harness the semantic knowledge of static objects embedded in off-the-shelf foundation models to improve affordance learning, effectively bridging the gap between objects and actions.\nExtensive experiments demonstrate that the performance of the proposed model has achieved a breakthrough improvement over existing methods.", "title_embedding_index": 20518, "title_abs_embedding_index": 20543}, {"title": "Active Preference Optimization via Maximizing Learning Capacity", "link_suffix": "/forum?id=bRfVj0Sh88", "link": "https://openreview.net/forum?id=bRfVj0Sh88", "pdf_link": "https://openreview.net/pdf?id=bRfVj0Sh88", "keywords": "active learning, preference learning, preference optimization", "abstract": "The success of deep learning in various complex tasks relies heavily on large amounts of annotated data, which can be prohibitively expensive to acquire. Techniques such as reinforcement learning with human feedback (RLHF) and direct preference optimization (DPO) have emerged as methods for fine-tuning models by leveraging human preferences, but they come with significant costs, especially when applied to large-scale language models (LLMs). Recent efforts to reduce these costs have focused on active preference optimization, which uses certainty-based selection to minimize the annotation burden. However, the two-step process of selecting uncertain input prompts and then acquiring completions can lead to sub-optimal pairings, potentially limiting model learning capacity. This paper suggests that divAPO eliminates suboptimal pairings that are typical of two-step methods and enhances learning capacity by selecting the most informative preference pairs in a single phase, taking into account both data distribution probabilities and preference model certainty. Through experiments on complicated Language tasks, we demonstrate that our method achieves significant performance improvements over existing approaches.", "title_embedding_index": 20519, "title_abs_embedding_index": 20544}, {"title": "AGLP: A Graph Learning Perspective for Semi-supervised Domain Adaptation", "link_suffix": "/forum?id=UWOQ6w5yvX", "link": "https://openreview.net/forum?id=UWOQ6w5yvX", "pdf_link": "https://openreview.net/pdf?id=UWOQ6w5yvX", "keywords": "Semi-Supervised Domain Adaptation, Graph, Transfer learning", "abstract": "In semi-supervised domain adaptation (SSDA), the model aims to leverage partially labeled target domain data along with a large amount of labeled source domain data to enhance its generalization capability for the target domain. A key advantage of SSDA is its ability to significantly reduce reliance on labeled data, thereby lowering the costs and time associated with data preparation. Most existing SSDA methods utilize information from domain labels and class labels but overlook the structural information of the data. To address this issue, this paper proposes a graph learning perspective (AGLP) for semi-supervised domain adaptation. We apply the graph convolutional network to the instance graph which allow structural information to propagate along the weighted graph edges. The proposed AGLP model has several advantages. First, to the best of our knowledge, this is the first work to model structural information in SSDA. Second, the proposed model can effectively learn domain-invariant and semantic representations, reducing domain discrepancies in SSDA. Extensive experimental results on multiple standard benchmarks demonstrate that the proposed AGLP algorithm outperforms state-of-the-art semi-supervised domain adaptation methods.", "title_embedding_index": 20520, "title_abs_embedding_index": 20545}, {"title": "SgCG: Semantic-guided Contrastive Generalization for  Medical Image Segmentation", "link_suffix": "/forum?id=G9HV5upWhx", "link": "https://openreview.net/forum?id=G9HV5upWhx", "pdf_link": "https://openreview.net/pdf?id=G9HV5upWhx", "keywords": "Medical Image Segmentation;Semantic-Guided;Contrastive Generalization; Domain-invariant Feature", "abstract": "After training on the source domain, deep learning models often struggle to generalize effectively to unknown target domains with differing data distributions. This is an even more severe challenge when the target domain is not available. In this paper, we tackle the problem of domain-generalized medical image segmentation by introducing a novel semantic-guided contrastive generalization algorithm, termed SgCG. The method aligns different multi-source domains based on semantic distributions to learn domain-invariant features. \nSpecifically, we implement a novel contrastive generalization loss at the pixel level that incorporates semantic distributions from the source domains. This approach facilitates the clustering of pixel representations from the same category while effectively separating those from different categories, thereby improving the model's segmentation performance while learning domain-invariant features.  Furthermore, we establish an upper bound estimation for the SgCG approach by integrating a contrastive generalization loss which include an infinite number of both similar and dissimilar pixel pairs. Despite the simplicity and straightforwardness of the approach, our empirical analysis reveals mechanisms that can maximize the potential of SgCG. We demonstrate the effectiveness of our approach using two public benchmarks for generalizable segmentation in medical images, where it achieves state-of-the-art performance.", "title_embedding_index": 20521, "title_abs_embedding_index": 20546}, {"title": "Safety Layers in Aligned Large Language Models: The Key to LLM Security", "link_suffix": "/forum?id=kUH1yPMAn7", "link": "https://openreview.net/forum?id=kUH1yPMAn7", "pdf_link": "https://openreview.net/pdf?id=kUH1yPMAn7", "keywords": "safety layers, LLM security, LLM alignment", "abstract": "Aligned LLMs are secure, capable of recognizing and refusing to answer malicious questions. However, the role of internal parameters in maintaining such security is not well understood yet, further these models can be vulnerable to security degradation when fine-tuned with non-malicious backdoor or normal data. To address these challenges, our work uncovers the mechanism behind security in aligned LLMs at the parameter level, identifying a small set of contiguous layers in the middle of the model that are crucial for distinguishing malicious queries from normal ones, referred to as \"safety layers\". We first confirm the existence of these safety layers by analyzing variations in input vectors within the model's internal layers. Additionally, we leverage the over-rejection phenomenon and parameters scaling analysis to precisely locate the safety layers. Building on these findings, we propose a novel fine-tuning approach, Safely Partial-Parameter Fine-Tuning (SPPFT), that fixes the gradient of the safety layers during fine-tuning to address the security degradation. Our experiments demonstrate that the proposed approach can significantly preserve LLM security while maintaining performance and reducing computational resources compared to full fine-tuning.", "title_embedding_index": 20522, "title_abs_embedding_index": 20547}, {"title": "ACE: Attack Combo Enhancement Against Machine Learning Models", "link_suffix": "/forum?id=3Hg5ufmfRu", "link": "https://openreview.net/forum?id=3Hg5ufmfRu", "pdf_link": "https://openreview.net/pdf?id=3Hg5ufmfRu", "keywords": "machine learning security and privacy, membership inference, attribute inference, property inference, adversarial examples", "abstract": "Machine learning (ML) models are proving to be vulnerable to a variety of attacks that allow the adversary to learn sensitive information, cause mispredictions, and more. \nWhile these attacks have been extensively studied, current research predominantly focuses on analyzing each attack type individually.\nIn practice, however, adversaries may employ multiple attack strategies simultaneously rather than relying on a single approach.\nThis prompts a crucial yet underexplored question: when the adversary has multiple attacks at their disposal, are they able to mount or enhance the effect of one attack with another?\nIn this paper, we take the first step in studying the intentional interactions among different attacks, which we define as attack combos. \nSpecifically, we focus on four well-studied attacks during the model's inference phase: adversarial examples, attribute inference, membership inference, and property inference. \nTo facilitate the study of their interactions, we propose a taxonomy based on three stages of the attack pipeline: preparation, execution, and evaluation.\nUsing this taxonomy, we identify four effective attack combos, such as property inference assisting attribute inference at its preparation level and adversarial examples assisting property inference at its execution level. \nWe conduct extensive experiments on the attack combos using three ML model architectures and three benchmark image datasets.\nEmpirical results demonstrate the effectiveness of these four attack combos.\nWe implement and release a modular, reusable toolkit, ACE. \nArguably, our work serves as a call for researchers and practitioners to consider advanced adversarial settings involving multiple attack strategies, aiming to strengthen the security and robustness of AI systems.", "title_embedding_index": 20523, "title_abs_embedding_index": 20548}, {"title": "Q-Bench-Video: Benchmarking the Video Quality Understanding of LMMs", "link_suffix": "/forum?id=VaUy5GZO3f", "link": "https://openreview.net/forum?id=VaUy5GZO3f", "pdf_link": "https://openreview.net/pdf?id=VaUy5GZO3f", "keywords": "Large multi-modal model, benchmark, video quality assessment", "abstract": "With the rising interest in research on Large Multi-modal Models (LMMs) for video understanding, many studies have emphasized general video comprehension capabilities, neglecting thesystematic exploration into video quality understanding. To address this oversight, we introduceQ-Bench-Videoin this paper, a new benchmark specifically designed to evaluate LMMs' proficiency in discerning video quality.a)To ensure the diversity of video sources, Q-Bench-Video encompasses videos from natural scenes, computer graphics (CG), and AI-generated content (AIGC).b)Building on the traditional multiple-choice questions format with theYes-or-NoandWhat-Howcategories, we includeOpen-endedquestions to better evaluate complex scenarios. Additionally, we incorporate thevideo pair quality comparisonquestion to enhance comprehensiveness.c)Beyond the traditionalTechnical,Aesthetic, andTemporaldistortions, we have expanded our evaluation aspects to include the dimension ofAIGCdistortions, which addresses the increasing demand for video generation. Finally, we collect a total of 2,378 question-answer pairs and test them on 12 open-source & 5 proprietary LMMs. Our findings indicate that while LMMs have a foundational understanding of video quality, their performance remains incomplete and imprecise, with a notable discrepancy compared to human-level performance. ThroughQ-Bench-Video, we seek to catalyze community interest, stimulate further research, and unlock the untapped potential of LMMs to close the gap in video quality understanding.", "title_embedding_index": 20524, "title_abs_embedding_index": 20549}]
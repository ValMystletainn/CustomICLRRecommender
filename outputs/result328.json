[
    {
        "title": "A General Framework for Producing Interpretable Semantic Text Embeddings",
        "link_suffix": "/forum?id=23uY3FpQxc",
        "link": "https://openreview.net/forum?id=23uY3FpQxc",
        "pdf_link": "https://openreview.net/pdf?id=23uY3FpQxc",
        "keywords": "Semantic Text Embedding, Interpretability, Question Generation, Question Answering",
        "abstract": "Semantic text embedding is essential to many tasks in Natural Language Processing (NLP). While black-box models are capable of generating high-quality embeddings, their lack of interpretability limits their use in tasks that demand transparency. Recent approaches have improved interpretability by leveraging domain-expert-crafted or LLM-generated questions, but these methods rely heavily on expert input or well-prompt design, which restricts their generalizability and ability to generate discriminative questions across a wide range of tasks. To address these challenges, we introduce \\algo{CQG-MBQA} (Contrastive Question Generation - Multi-task Binary Question Answering), a general framework for producing interpretable semantic text embeddings across diverse tasks. Our framework systematically generates highly discriminative, low cognitive load yes/no questions through the \\algo{CQG} method and answers them efficiently with the \\algo{MBQA} model, resulting in interpretable embeddings in a cost-effective manner. We validate the effectiveness and interpretability of \\algo{CQG-MBQA} through extensive experiments and ablation studies, demonstrating that it delivers embedding quality comparable to many advanced black-box models while maintaining inherently interpretability. Additionally, \\algo{CQG-MBQA} outperforms other interpretable text embedding methods across various downstream tasks. The source code is available at \\url{https://anonymous.4open.science/r/CQG-MBQA-483F/}."
    },
    {
        "title": "SoLAR: Surrogate Label Aware GNN Rewiring",
        "link_suffix": "/forum?id=eT6zYrd1wl",
        "link": "https://openreview.net/forum?id=eT6zYrd1wl",
        "pdf_link": "https://openreview.net/pdf?id=eT6zYrd1wl",
        "keywords": "graph neural networks, graph rewiring, homophily, heterophily, knowledge distillation",
        "abstract": "Rewiring the input graph of graph neural networks (GNNs) has been proposed as a pre-processing step to address issues like over-squashing and over-smoothing. However, most existing techniques rely solely on topology-based modifications, neglecting performance-critical node label information. To fill this gap, we propose SoLAR (Surrogate Label Aware Rewiring), a method that rewires the graph based on predicted node labels from a surrogate model. We prove its effectiveness in a theoretically tractable setting highlighting two key mechanisms that enable its success. The first is a denoising effect, while the second is a novel knowledge distillation-inspired process, where information from a surrogate model is encoded into the graph structure. Extensive experiments demonstrate consistent improvements of SoLAR across various datasets. Notably, the best surrogate models arise from iterative SoLAR, and reusing the same model class is a competitive strategy."
    },
    {
        "title": "R2C: Mapping Room to Chessboard to Unlock LLM As Low-Level Action Planner",
        "link_suffix": "/forum?id=ysAX5ORQoX",
        "link": "https://openreview.net/forum?id=ysAX5ORQoX",
        "pdf_link": "https://openreview.net/pdf?id=ysAX5ORQoX",
        "keywords": "Embodied AI, Large Language Model, Embodied Instruction Following, Robotic Planning",
        "abstract": "This paper explores the potential of leveraging large language models (LLMs) as low-level action planners capable of executing long-horizon tasks based on natural language instructions. Although LLMs can act as the \"brain\" of robots by excelling in high-level task planning, they are not yet capable of directly guiding the \"body\" to execute low-level motion plans. This limitation stems from a communication gap between the \"brain\" and the \"body\". Specifically, LLMs lack access to rich spatial semantic information from the robot's real-time observations, hindering their ability to generate precise and actionable low-level plans.To address this, we propose a unified framework that bridges high-level and low-level planning by establishing an efficient communication interface between LLMs and robots. Our insight is to formulate the task as playing chess with LLMs. We map the room into a semantic chessboard, which we call Room to Chessboard (R2C). Each grid represents the position and size of objects inside the room. We find that chessboard is \\textbf{succinct} enough for LLMs to conduct semantic searches with global view of the room. Also, the chessboard is \\textbf{informative} enough to convey detailed environmental state for LLMs to predict executable low-level actions. Additionally, we enhance decision-making through a Chain-of-Thought (CoT) paradigm, improving LLMs' interpretability and action reasoning. We implement R2C using both fine-tuned open-source LLMs and closed-source models like GPT-4, and demonstrate its efficacy on the challenging ALFRED benchmark. Our results show that with communication based on chessboard, LLMs can serve as effective low-level action planners, and can generalizes well to open-vocabulary robotic planning tasks. View the demos on our project page:https://anonymous4cv.github.io/Room2Chessboard."
    },
    {
        "title": "Novelty Unlocking with Multiobjective Generative Models: Batch Diversity of Human Motions",
        "link_suffix": "/forum?id=xNwmWaq2KN",
        "link": "https://openreview.net/forum?id=xNwmWaq2KN",
        "pdf_link": "https://openreview.net/pdf?id=xNwmWaq2KN",
        "keywords": "Multiobjective optimization;Diverse In-Betweening Human Motions",
        "abstract": "Current generative models have shown potential performance in many tasks, which typically focus on generating samples that closely adhere to a given distribution, often overlooking the requirement to produce optimal diverse solutions in a batch diversity.\nRecognizing that maintaining ``diversity\" has been a longstanding challenge in multiobjective optimization, we were inspired to introduce a multiobjective optimization approach to enhance diversity in a single pass.\nThis paper utilizes the in-betweening human motion generation task as an example and introduces the multiobjective generative models to demonstrate the effectiveness of the proposed method in producing diverse and smooth human motion sequences. The resulting method, termed the \\textit{Multiobjective Generation Framework with In-Betweening Motion Model} (MGF-IMM), frames the human motion in-betweening task as a bi-objective optimization problem. The designed in-betweening motion model is then integrated into a nondominated sorting-based optimization framework to address this bi-objective optimization problem.\nThrough comprehensive qualitative and quantitative experiments, MGF-IMM has demonstrated state-of-the-art performance, surpassing the latest methods and validating its superiority in generating diverse in-betweening human motions."
    },
    {
        "title": "Unifying Causal Representation Learning with the Invariance Principle",
        "link_suffix": "/forum?id=lk2Qk5xjeu",
        "link": "https://openreview.net/forum?id=lk2Qk5xjeu",
        "pdf_link": "https://openreview.net/pdf?id=lk2Qk5xjeu",
        "keywords": "Causal representation learning, Identifiability, Invariance",
        "abstract": "Causal representation learning aims at recovering latent causal variables from high-dimensional observations to solve causal downstream tasks, such as predicting the effect of new interventions or more robust classification. A plethora of methods have been developed, each tackling carefully crafted problem settings that lead to different types of identifiability. The folklore is that these different settings are important, as they are often linked to different rungs of Pearl's causal hierarchy, although not all neatly fit. Our main contribution is to show thatmany existing causal representation learning approaches methodologically align the representation to known data symmetries. Identification of the variables is guided by equivalence classes across different \"data pockets\" that are not necessarily causal. This result suggests important implications, allowing us to unify many existing approaches in a single method that can mix and match different assumptions, including non-causal ones, based on the invariances relevant to our application. It also significantly benefits applicability, which we demonstrate by improving treatment effect estimation on real-world high-dimensional ecological data. Overall, this paper clarifies the role of causality assumptions in the discovery of causal variables and shifts the focus to preserving data symmetries."
    },
    {
        "title": "A Multiscale Frequency Domain Causal Framework for Enhanced Pathological Analysis",
        "link_suffix": "/forum?id=6xrDPHhwD3",
        "link": "https://openreview.net/forum?id=6xrDPHhwD3",
        "pdf_link": "https://openreview.net/pdf?id=6xrDPHhwD3",
        "keywords": "Causal Inference, Pathological Image Analysis",
        "abstract": "Multiple Instance Learning (MIL) in digital Pathology Whole Slide Image (WSI) analysis has shown significant progress. However, due to data bias and unobservable confounders, this paradigm still faces challenges in terms of performance and interpretability. Existing MIL methods might identify patches that do not have true diagnostic significance, leading to false correlations, and experience difficulties in integrating multi-scale features and handling unobservable confounders. To address these issues, we propose a new Multi-Scale Frequency Domain Causal framework (MFC). Our framework, guided by Information Bottleneck theory, identifies the minimum sufficient statistic for the WSI. This property allows us to fine-tune the backbone network based only on weak labeling at the WSI level to generate task-specific representations. We further integrate the Multi-Layer Spatial Representation Module (MSRM), Frequency Domain Structure Representation Module (FSRM), and Causal Memory Intervention Module (CMIM) to enhance the model's performance and interpretability. Experimental results on Camelyon16 and TCGA-NSCLC dataset show that, compared to previous work, our method has significantly improved accuracy and generalization ability, providing a new theoretical perspective for medical image analysis and potentially advancing the field further."
    },
    {
        "title": "PowerSoftmax: Towards secure LLM Inference Over Encrypted Data",
        "link_suffix": "/forum?id=wWhZ2RFAxF",
        "link": "https://openreview.net/forum?id=wWhZ2RFAxF",
        "pdf_link": "https://openreview.net/pdf?id=wWhZ2RFAxF",
        "keywords": "Secure LLMs, Secure Transformers, Privacy Preserving, Homomorphic Encryption (HE)",
        "abstract": "Modern cryptographic methods for implementing privacy-preserving LLMs such as Homomorphic Encryption require the LLMs to have a polynomial form. Forming such a representation is challenging because Transformers include non-polynomial components, such as Softmax and layer normalization. Previous approaches have either directly approximated pre-trained models with large-degree polynomials, which are less efficient over HE, or replaced non-polynomial components with easier-to-approximate primitives before training, e.g., Softmax with pointwise attention. The latter approach might introduce scalability challenges.We present a new HE-friendly variant of self-attention that offers a stable form for training and is easy to approximate with polynomials for secure inference. Our work introduces the first polynomial LLMs with 32 layers and over a billion parameters, exceeding the size of previous models by more than tenfold. The resulting models demonstrate reasoning and in-context learning (ICL) capabilities comparable to standard transformers of the same size, representing a breakthrough in the field. Finally, we provide a detailed latency breakdown for each computation over encrypted data, paving the way for further optimization, and explore the differences in inductive bias between transformers relying on our HE-friendly variant and standard transformers. Our code is attached as a supplement."
    },
    {
        "title": "Latent Score-Based Reweighting for Robust Classification on Imbalanced Tabular Data",
        "link_suffix": "/forum?id=HSLClc1a7W",
        "link": "https://openreview.net/forum?id=HSLClc1a7W",
        "pdf_link": "https://openreview.net/pdf?id=HSLClc1a7W",
        "keywords": "robustness, score model, reweighting",
        "abstract": "Machine learning models often perform well on tabular data by optimizing average prediction accuracy. However, they may underperform on specific subsets due to inherent biases and spurious correlations in the training data, such as associations with non-causal features like demographic information. These biases lead to critical robustness issues as models may inherit or amplify them, resulting in poor performance where such misleading correlations do not hold. Existing mitigation methods have significant limitations: some require prior group labels, which are often unavailable, while others focus solely on the conditional distribution $P(Y|X)$, upweighting misclassified samples without effectively balancing the overall data distribution $P(X)$. To address these shortcomings, we propose a latent score-based reweighting framework. It leverages score-based models to capture the joint data distribution $P(X, Y)$ without relying on additional prior information. By estimating sample density through the similarity of score vectors with neighboring data points, our method identifies underrepresented regions and upweights samples accordingly. This approach directly tackles inherent data imbalances, enhancing robustness by ensuring a more uniform dataset representation. Experiments on various tabular datasets under distribution shifts demonstrate that our method effectively improves performance on imbalanced data."
    },
    {
        "title": "WeatherGFM: Learning a Weather Generalist Foundation Model via In-context Learning",
        "link_suffix": "/forum?id=izjNI5bcOV",
        "link": "https://openreview.net/forum?id=izjNI5bcOV",
        "pdf_link": "https://openreview.net/pdf?id=izjNI5bcOV",
        "keywords": "AI for Science, Weather foundation model, in-context learning",
        "abstract": "The Earth's weather system involves intricate weather data modalities and diverse weather understanding tasks, which hold significant value to human life. \nExisting data-driven models focus on single weather understanding tasks (e.g., weather forecasting). \nWhile these models have achieved promising results, they fail to tackle various complex tasks within a single and unified model. \nMoreover, the paradigm that relies on limited real observations for a single scenario hinders the model's performance upper bound.\nInspired by the in-context learning paradigm from visual foundation models and large language models, in this paper, we introduce the first generalist weather generalist foundation model (WeatherGFM) to address weather understanding tasks in a unified manner. \nSpecifically, we first unify the representation and definition for diverse weather understanding tasks.\nSubsequently, we design weather prompt formats to handle different weather data modalities, including single, multiple, and temporal modalities. \nFinally, we adopt a visual prompting question-answering paradigm for the training of unified weather understanding tasks. \nExtensive experiments indicate that our WeatherGFM can effectively handle up to ten weather understanding tasks, including weather forecasting, super-resolution, weather image translation, and post-processing. Our method also showcases generalization ability on unseen tasks."
    },
    {
        "title": "Design of Ligand-Binding Proteins with Atomic Flow Matching",
        "link_suffix": "/forum?id=p6eQRlaxGo",
        "link": "https://openreview.net/forum?id=p6eQRlaxGo",
        "pdf_link": "https://openreview.net/pdf?id=p6eQRlaxGo",
        "keywords": "protein generation, protein-ligand interaction, protein binder design",
        "abstract": "Designing novel proteins that bind to small molecules is a long-standing challenge in computational biology, with applications in developing catalysts, biosensors, and more. Current computational methods rely on the assumption that the binding pose of the target molecule is known, which is not always feasible, as conformations of novel targets are often unknown and tend to change upon binding. In this work, we formulate proteins and molecules as unified biotokens, and present AtomFlow, a novel deep generative model under the flow-matching framework for the design of ligand-binding proteins from the 2D target molecular graph alone. Operating on representative atoms of biotokens, AtomFlow captures the flexibility of ligands and generates ligand conformations and protein backbone structures iteratively. We consider the multi-scale nature of biotokens and demonstrate that AtomFlow can be effectively trained on a subset of structures from the Protein Data Bank, by matching flow vector field using an SE(3) equivariant structure prediction network. Experimental results show that our method can generate high-fidelity ligand-binding proteins and achieve performance comparable to the state-of-the-art model RFDiffusionAA, while not requiring bound ligand structures. As a general framework, AtomFlow holds the potential to be applied to various biomolecule generation tasks in the future."
    },
    {
        "title": "Implicit Functional Bayesian Deep Learning",
        "link_suffix": "/forum?id=ohHtdp3jDi",
        "link": "https://openreview.net/forum?id=ohHtdp3jDi",
        "pdf_link": "https://openreview.net/pdf?id=ohHtdp3jDi",
        "keywords": "Bayesian Deep Learning, function space, variational inference",
        "abstract": "Bayesian deep learning (BDL) is believed to be an effective approach to enabling uncertainty estimation and improving the generalisation and robustness of classical deep learning with the help of the Bayesian principle. Considering its non-meaningful weight-space prior and problematic Kullback-Leibler (KL) divergence, functional inference with Wasserstein distance has recently emerged as a promising direction in this field. However, existing efforts require different types of degenerations to achieve tractable Wasserstein distance computation, which limits the predictive and uncertainty estimation capabilities. In this paper, we propose two novel implicit functional BDL (ifBDL) approaches, i.e., implicit functional Bayesian neural networks and implicit functional Bayesian deep ensemble. The common idea is to implicitly transform the BDL posterior to a Gaussian process via the neural tangent kernel to facilitate tractable 2-Wasserstein distance computation and preserve the neural network parameterization. The experimental evaluations on standard tasks show that ifBDL has superior predictive and uncertainty estimation capabilities compared to existing weight-space and function-space approaches."
    },
    {
        "title": "Haste Makes Waste: Teaching Image Restoration to Learn Distributions from Pixels to Patterns",
        "link_suffix": "/forum?id=59r0ntInvF",
        "link": "https://openreview.net/forum?id=59r0ntInvF",
        "pdf_link": "https://openreview.net/pdf?id=59r0ntInvF",
        "keywords": "Image Restoration, Low-level Vision, Training Strategy",
        "abstract": "In this paper, we revisit the image restoration (IR) task and propose a new training strategy that models the IR problem as a distribution mapping challenge from two perspectives, i.e., (1) the intra-pixel regression and (2) the inter-pixel interaction. At the beginning of optimization, due to the pattern distribution involving a group of pixels within a neighborhood, it is not very easy for the model to capture such multi-pixel distribution mapping. A more optimal solution would be firstly teaching the model to learn a relatively simple yet important distribution w.r.t the pixel-by-pixel mapping between the degraded/clean pixels, as warming up. By doing so, the learned distribution is served as a prior, regarded as an injection of a kind of inductive bias into the model's whole optimization procedure. Subsequently, as conventional, the model is shifted to focus on the mapping distribution of the cross-pixel patterns, which ensures the consistency and fidelity of the image patterns. The final learned mapping is a joint distribution, which transfers the knowledge from the pixel distributions to the pattern ones. Experimental results indicate that under the compact and elegant training paradigm, the newly learned joint distribution is closer to the ideal one and yields a stronger representation ability, to circumvent the dilemma of the difficulty for existing methods to learn the patterns mapping distribution between degraded/clean images right off the bat."
    },
    {
        "title": "Rethinking the Influence of Distribution Adjustment in Incremental Segmentation",
        "link_suffix": "/forum?id=lnVPfgRnIV",
        "link": "https://openreview.net/forum?id=lnVPfgRnIV",
        "pdf_link": "https://openreview.net/pdf?id=lnVPfgRnIV",
        "keywords": "Incremental segmentation, knowledge distribution",
        "abstract": "In an ever-changing world, incremental segmentation learning faces challenges due to the need for pixel-level accuracy and the practical application of gradually obtained samples.\nWhile most existing methods excel in stability by freezing model parameters or employing \nother regularization techniques to preserve the distribution of old knowledge, these approaches often fall short of achieving satisfactory plasticity.\nThis phenomenon arises from the limited allocation of parameters for learning new knowledge.\nMeanwhile, in such a learning manner, the distribution of old knowledge cannot be optimized as new knowledge accumulates.\nAs a result, the feature distribution of newly learned knowledge overlaps with old knowledge, leading to inaccurate segmentation performance on new classes and insufficient plasticity.\nThis issue prompts us to explore how both old and new knowledge representations can be dynamically and simultaneously adjusted in the feature space during incremental learning. \nTo address this, we conduct a mathematical structural analysis, which indicates that compressing the feature subspace and promoting sparse distribution is beneficial in allocating more space for new knowledge in incremental segmentation learning.\nFollowing compression principles, high-dimensional knowledge is projected into a lower-dimensional space in a contracted and dimensionally reduced manner. Regarding sparsity, the exclusivity of multiple peaks in Gaussian mixture distributions across different classes is preserved. \nThrough effective knowledge transfer, both up-to-date and long-standing knowledge can dynamically adapt within a unified space, facilitating efficient adaptation to continuously incoming and evolving data.\nExtensive experiments across various incremental settings consistently demonstrate the significant improvements provided by our proposed method. In particular, regarding the plasticity of in the incremental stage, our approach outperforms the state-of-the-art method by 11.7% in MIoU scores for the challenging 10-1 setting. Source code is available in the supplementary materials."
    },
    {
        "title": "On Uniform, Bayesian, and PAC-Bayesian Deep Ensembles",
        "link_suffix": "/forum?id=gvmoBNuf5f",
        "link": "https://openreview.net/forum?id=gvmoBNuf5f",
        "pdf_link": "https://openreview.net/pdf?id=gvmoBNuf5f",
        "keywords": "deep learning, ensemble methods, Bayesian model average, PAC-Bayesian generalization bounds",
        "abstract": "It is common practice to combine deep neural networks to ensembles. These deep ensembles can profit from the cancellation of errors effect: Errors by ensemble members may average out and the ensemble achieves better generalization performance than each individual network.  Bayesian neural networks learn a posterior distribution over  model parameters, and sampling and weighting networks according to this posterior yields an ensemble model referred to as Bayes ensemble. In this study, we stress that neither the sampling nor the weighting in a Bayes ensemble are particularly well-suited for increasing generalization performance, as they do not support the cancellation of errors effect, which is evident in the limit from the Bernstein-von~Mises theorem for misspecified models. In contrast, a weighted average of models, where the weights are optimized by minimizing a PAC-Bayesian generalization bound, can improve generalization performance. This requires that the optimization takes correlations between models into account, which can be achieved by minimizing the tandem loss at the cost that hold-out data for estimating error correlations need to be available. The PAC-Bayesian weighting increases the robustness against correlated models and models with lower performance in an ensemble. This allows us to safely add several models from the same learning process to an ensemble, instead of using early-stopping for selecting a single weight configuration. Our study presents empirical results supporting these conceptual considerations on four different classification datasets. We show that state-of-the-art Bayes ensembles from the literature, despite being computationally demanding, do not improve over simple uniformly weighted deep ensembles and cannot match the performance of deep ensembles weighted by optimizing the tandem loss, which additionally come with non-vacuous generalization guarantees."
    },
    {
        "title": "Universal Concavity-Aware Descent Rate for Optimizers",
        "link_suffix": "/forum?id=cCcaJzPAnb",
        "link": "https://openreview.net/forum?id=cCcaJzPAnb",
        "pdf_link": "https://openreview.net/pdf?id=cCcaJzPAnb",
        "keywords": "nonconvex optimization, optimization, convergence rate, objective function sub-optimality, objective sub-optimality, quasi newton optimization, numerical methods, lipschitz adaptive, eigenspace lipschitz",
        "abstract": "Many machine learning problems involve a challenging task of calibrating parameters in a computational model to fit the training data; this task is especially challenging for non-convex problems.  Many optimization algorithms have been proposed to assist in calibrating these parameters, each with its respective advantages in different scenarios, but it is often difficult to determine the scenarios for which an algorithm is best suited.  To contend with this challenge, much work has been done on proving the rate at which these optimizers converge to their final solution, however the wide variety of such convergence rate bounds, each with their own different assumptions, convergence metrics, tightnesses, and parameters (which may or may not be known to the practitioner) make comparing these convergence rates difficult.  To help with this problem, we present a minmax-optimal algorithm and, by comparison to it, give a single descent bound which is applicable to a very wide family of optimizers, tasks, and data (including all of the most prevalent ones), which also puts special emphasis on being tight even in parameter subspaces in which the cost function is concave."
    },
    {
        "title": "RNAinformer: Generative RNA Design with Tertiary Interactions",
        "link_suffix": "/forum?id=DumcCxxzka",
        "link": "https://openreview.net/forum?id=DumcCxxzka",
        "pdf_link": "https://openreview.net/pdf?id=DumcCxxzka",
        "keywords": "RNA, RNA Design, RNA Inverse Folding, Transformers, Generative Design, Axial Attention, pseduoknots, multiplets",
        "abstract": "The function of an RNA molecule depends on its structure and a strong structure-to-function relationship is already achieved on the secondary structure level of RNA. Therefore, the secondary structure based design of RNAs is one of the major challenges in computational biology. A common approach of RNA design is inverse RNA folding. However, existing RNA design approaches cannot invert all folding algorithms because they cannot represent all types of base interactions. In this work, we propose RNAinformer, a novel generative transformer based approach to the inverse RNA folding problem. Leveraging axial-attention, we directly model the secondary structure input represented as an adjacency matrix in a 2D latent space, which allows us to invert all existing secondary structure prediction algorithms. Consequently, RNAinformer is the first model capable of designing RNAs from secondary structures with all base interactions, including non-canonical base pairs and tertiary interactions like pseudoknots and base multiplets. We demonstrate RNAinformer\u2019s state-of-the-art performance across different RNA design benchmarks and showcase its novelty by inverting different RNA secondary structure prediction algorithms."
    },
    {
        "title": "dnaGrinder: a lightweight and high-capacity genomic foundation model",
        "link_suffix": "/forum?id=phWflQbLhu",
        "link": "https://openreview.net/forum?id=phWflQbLhu",
        "pdf_link": "https://openreview.net/pdf?id=phWflQbLhu",
        "keywords": "DNA, Genome, Language Model, Foundation Model",
        "abstract": "The task of understanding and interpreting the complex information encoded within genomic sequences remains a grand challenge in biological research and clinical applications. In this context, recent advancements in large language model research have led to the development of both encoder-only and decoder-only foundation models designed to decode intricate information in DNA sequences. However, several issues persist, particularly regarding the efficient management of long-range dependencies inherent in genomic sequences, the effective representation of nucleotide variations, and the considerable computational costs associated with large model architectures and extensive pretraining datasets. Current genomic foundation models often face a critical tradeoff: smaller models with mediocre performance versus larger models with improved performance. To address these challenges, we introduce dnaGrinder, a unique and efficient genomic foundation model. dnaGrinder excels at managing long-range dependencies within genomic sequences while minimizing computational costs without compromising performance. It achieves results that are not just comparable but often superior to leading DNA models such as Nucleotide Transformer and DNABERT-2. Furthermore, dnaGrinder is designed for easy fine-tuning on workstation-grade GPUs, accommodating input lengths exceeding 17,000 tokens. On a single high-performance GPU, it supports sequences longer than 140,000 tokens, making it a highly efficient and accessible tool for both basic biological research and clinical applications."
    },
    {
        "title": "Overcoming label shift in targeted federated learning",
        "link_suffix": "/forum?id=nwETBpOPiC",
        "link": "https://openreview.net/forum?id=nwETBpOPiC",
        "pdf_link": "https://openreview.net/pdf?id=nwETBpOPiC",
        "keywords": "Federated learning, Label shift, distribution shift, non-iid",
        "abstract": "Federated learning enables multiple actors to collaboratively train models without sharing private data. This unlocks the potential for scaling machine learning to diverse applications. Existing algorithms for this task are well-justified when clients and the intended target domain share the same distribution of features and labels, but this assumption is often violated in real-world scenarios. One common violation is label shift, where the label distributions differ across clients or between clients and the target domain, which can significantly degrade model performance. To address this problem, we propose FedPALS, a novel model aggregation scheme that adapts to label shifts by leveraging knowledge of the target label distribution at the central server. Our approach ensures unbiased updates under stochastic gradient descent, ensuring robust generalization across clients with diverse, label-shifted data. Extensive experiments on image classification demonstrate that FedPALS consistently outperforms standard baselines by aligning model aggregation with the target domain. Our findings reveal that conventional federated learning methods suffer severely in cases of extreme client sparsity, highlighting the critical need for target-aware aggregation. FedPALS offers a principled and practical solution to mitigate label distribution mismatch, ensuring models trained in federated settings can generalize effectively to label-shifted target domains."
    },
    {
        "title": "Following the Human Thread in Social Navigation",
        "link_suffix": "/forum?id=M8OGl34Pmg",
        "link": "https://openreview.net/forum?id=M8OGl34Pmg",
        "pdf_link": "https://openreview.net/pdf?id=M8OGl34Pmg",
        "keywords": "Embodied AI, Social Navigation, Human Trajectories",
        "abstract": "The success of collaboration between humans and robots in shared environments relies on the robot's real-time adaptation to human motion. Specifically, in Social Navigation, the agent should be close enough to assist but ready to back up to let the human move freely, avoiding collisions. Human trajectories emerge as crucial cues in Social Navigation, but they are partially observable from the robot's egocentric view and computationally complex to process.We present the first Social Dynamics Adaptation model (SDA) based on the robot's state-action history to infer the social dynamics. We propose a two-stage Reinforcement Learning framework: the first learns to encode the human trajectories into social dynamics and learns a motion policy conditioned on this encoded information, the current status, and the previous action. Here, the trajectories are fully visible, i.e., assumed as privileged information. In the second stage, the trained policy operates without direct access to trajectories. Instead, the model infers the social dynamics solely from the history of previous actions and statuses in real-time.\nTested on the novel Habitat 3.0 platform, SDA sets a novel state-of-the-art (SotA) performance in finding and following humans.The code will be released upon acceptance."
    },
    {
        "title": "RD2Bench: Toward Data-Centric Automatic R&D",
        "link_suffix": "/forum?id=w0es2hinsd",
        "link": "https://openreview.net/forum?id=w0es2hinsd",
        "pdf_link": "https://openreview.net/pdf?id=w0es2hinsd",
        "keywords": "Real-world Data-centric automatic R&D Benchmark, data-centric automatic R&D, trustworthy models",
        "abstract": "The progress of humanity is driven by those successful discoveries accompanied by countless failed experiments. Researchers often seek the potential research directions by reading and then verifying them through experiments. The process imposes a significant burden on researchers. In the past decade, the data-driven black-box deep learning method has demonstrated its effectiveness in a wide range of real-world scenarios, which exacerbates the experimental burden of researchers and thus renders the potential successful discoveries veiled. Therefore, automating such a research and development (R&D) process is an urgent need. In this paper, we serve as the first effort to formalize the goal by proposing a Real-world Data-centric automatic R&D Benchmark, namely RD2Bench. RD2Bench benchmarks all the operations in data-centric automatic R&D (D-CARD) as a whole to navigate future work toward our goal directly. We focus on evaluating the interaction and synergistic effects of various model capabilities and aiding in selecting well-performing trustworthy models.\n    Although RD2Bench is very challenging to the state-of-the-art (SOTA) large language model (LLM) named GPT-4, indicating ample research opportunities and more research efforts, LLMs possess promising potential to bring more significant development to D-CARD: They are able to implement some simple methods without adopting any additional techniques. We appeal to future work to take developing techniques for tackling automatic R&D into consideration, thus bringing the opportunities of the potential revolutionary upgrade to human productivity."
    },
    {
        "title": "Subequivariant Morphology-Behavior Co-Evolution in 3D Environments",
        "link_suffix": "/forum?id=MueN6LyTmS",
        "link": "https://openreview.net/forum?id=MueN6LyTmS",
        "pdf_link": "https://openreview.net/pdf?id=MueN6LyTmS",
        "keywords": "Geometric Graph, Reinforcement Learning, Morphology-Behavior Co-Evolution, 3D, Subequivariance",
        "abstract": "The co-evolution of morphology and behavior in 3D space has garnered considerable interest in the field of embodied intelligence. \nWhile recent studies have highlighted the considerable benefits of geometric symmetry for tasks like learning to locomote, navigate, and explore in dynamic 3D environments, its role within co-evolution setup remains unexplored.\nExisting benchmarks encounter several key issues: 1) the task lacks consideration for spatial geometric information; 2) the method lacks geometric symmetry to deal with the complexities in 3D environments.\nIn this work, we propose a novel setup, named Subequivariant Morphology-Behavior Co-Evolution in 3D Environments (3DS-MB), to address the identified limitations.\nTo be specific, we propose EquiEvo, which injects geometric symmetry, i.e., subequivariance, to construct dynamic, learnable local reference frames, enabling the joint policy to generalize to diverse task spatial structures, thereby improving co-evolution efficiency.\nThen, we evaluate EquiEvo on the proposed environments, where our method consistently and significantly outperforms existing approaches in tasks such as locomotion navigation and adversarial scenarios.\nExtensive experiments underscore the importance of subequivariance for the co-evolution of morphology and behavior, effective morphology-task mapping and robust morphology-behavior mapping."
    },
    {
        "title": "Mitigating Robust Overfitting in Wasserstein Distributionally Robust Optimization",
        "link_suffix": "/forum?id=sq5LLWk5SN",
        "link": "https://openreview.net/forum?id=sq5LLWk5SN",
        "pdf_link": "https://openreview.net/pdf?id=sq5LLWk5SN",
        "keywords": "Adversarial examples; robust overfitting; WDRO",
        "abstract": "Wasserstein distributionally robust optimization (WDRO) optimizes against worst-case distributional shifts within a specified uncertainty set, leading to enhanced generalization on unseen adversarial examples, compared to standard adversarial training which focuses on pointwise adversarial perturbations. However, WDRO still suffers fundamentally from the robust overfitting problem, as it does not consider statistical error. We address this gap by proposing a novel robust optimization framework under a new uncertainty set for both adversarial noise (Wasserstein distance) and statistical error (Kullback-Leibler divergence). Our theoretical analysis establishes that out-of-distribution adversarial performance is at least as good as the in-distribution robust performance with high probability. Furthermore, we derive conditions under which Stackelberg and Nash equilibria exist between the learner and the adversary. Finally, through extensive experiments, we demonstrate that our method significantly mitigates robust overfitting and enhances robustness within the framework of WDRO."
    },
    {
        "title": "Interpretable Dimensionality Reduction by Feature-preserving Manifold Approximation and Projection",
        "link_suffix": "/forum?id=CxwtuhU40F",
        "link": "https://openreview.net/forum?id=CxwtuhU40F",
        "pdf_link": "https://openreview.net/pdf?id=CxwtuhU40F",
        "keywords": "Interpretable, Gradient, Tangent space, Manifold learning",
        "abstract": "Nonlinear dimensionality reduction often lacks interpretability due to the absence of source features in low-dimensional embedding space. We propose FeatureMAP, an interpretable method that preserves source features by tangent space embedding. The core of FeatureMAP is to use local principal component analysis (PCA) to approximate tangent spaces. By leveraging these tangent spaces, FeatureMAP computes gradients to locally reveal feature directions and importance. Additionally, FeatureMAP embeds the tangent spaces into low-dimensional space while preserving alignment between them, providing local gauges for projecting the high-dimensional data points. Unlike UMAP, FeatureMAP employs anisotropic projection to preserve both the manifold structure and the original data density. We apply FeatureMAP to interpreting digit classification, object detection and MNIST adversarial examples, where it effectively distinguishes digits and objects using feature importance and provides explanations for misclassifications in adversarial attacks. We also compare FeatureMAP with other state-of-the-art methods using both local and global metrics."
    },
    {
        "title": "Fox-TTS: Scalable Flow Transformers for Expressive Zero-Shot Text to Speech",
        "link_suffix": "/forum?id=pWdkM9NNCA",
        "link": "https://openreview.net/forum?id=pWdkM9NNCA",
        "pdf_link": "https://openreview.net/pdf?id=pWdkM9NNCA",
        "keywords": "Expressive Text-to-Speech, flow-matching models, zero-shot generalization",
        "abstract": "Expressive zero-shot text-to-speech (TTS) synthesis aims at synthesizing high-fidelity speech that closely mimics a brief stylized recording without additional training. Despite the advancements in this area, several challenges persist: 1) Current methods, which encompass implicit prompt engineering through in-context learning or by using pre-trained speaker identification models, often struggle to fully capture the acoustic characteristics of the stylized speaker; 2) Attaining high-fidelity voice cloning for a stylized speaker typically requires large amounts of specific data for fine-tuning; 3) There is no benchmark tailored for the expressive zero-shot TTS scenarios. To address them, we presentFox-TTS, a family of large-scale models for high-quality expressive zero-shot TTS. We introduce an improved flow-matching Transformer model coupled with a novel learnable speaker encoder. Within the speaker encoder, we incorporate three key designs: temporal mean pooling, temporal data augmentation, and an information bottleneck used for trading off pronunciation stability and speaker similarity in an explainable manner. Moreover, we have collected \\textit{Fox-eval}, the first multi-speaker, multi-style benchmark that is specially designed for expressive zero-shot scenarios. Extensive experiments show that Fox-TTS achieves on-par quality with human recordings in normal scenarios and state-of-the-art performance in expressive scenarios. Audio samples are available athttps://fox-tts.github.io/."
    },
    {
        "title": "AVG-LLaVA: A Large Multimodal Model with Adaptive Visual Granularity",
        "link_suffix": "/forum?id=94d2OjTags",
        "link": "https://openreview.net/forum?id=94d2OjTags",
        "pdf_link": "https://openreview.net/pdf?id=94d2OjTags",
        "keywords": "Large multimodal model, multi-stage training, adaptive visual granularity",
        "abstract": "Recently, when dealing with high-resolution images, dominant large multimodal models (LMMs) usually divide them into multiple local images and one global image, which will lead to a large number of visual tokens. In this work, we introduce AVG-LLaVA, an LMM that can adaptively select the appropriate visual granularity based on the input image and instruction. This approach not only reduces the number of visual tokens and speeds up inference, but also improves the overall model performance. Specifically, we introduce the following modules based on LLaVA-NeXT: (a) a visual granularity scaler that includes multiple pooling layers to obtain visual tokens with different granularities; (b) a visual granularity router, which includes a Transformer layer, an MLP layer, and a voter layer, used to select the appropriate visual granularity based on the image and instruction. Furthermore, we propose RGLF, a novel training paradigm that aims at aligning the granularity predicted by the router with the preferences of the LMM, without the need for additional manually annotated data. Extensive experiments and analysis show that AVG-LLaVA achieves superior performance across 11 benchmarks, as well as significantly reduces the number of visual tokens and speeds up inference (e.g., an 85.3% reduction in visual tokens and a 2.53$\\times$ increase in inference speed on the AI2D benchmark)."
    }
]
[
    {
        "title": "Reflection Window: Text Generation with Selective Refinement",
        "link_suffix": "/forum?id=aS1IhKdLPP",
        "link": "https://openreview.net/forum?id=aS1IhKdLPP",
        "pdf_link": "https://openreview.net/pdf?id=aS1IhKdLPP",
        "keywords": "Selective Refinement, Autogressive Text Generation, Reflection Window, Large Language Model",
        "abstract": "The autoregressive approach to text generation in large language models (LLMs), while widely used, is inherently suboptimal due to the lack of a built-in mechanism to perform refinement and/or correction of the generated content. In this paper, we consider optimality in terms of the joint probability over the generated response, when jointly considering all tokens at the same time. We theoretically characterize the potential deviation of the autoregressively generated response from and its globally optimal counterpart that is of the same length. Our analysis suggests that we need to be cautious when noticeable uncertainty arises during text generation, which may signal the sub-optimality of the generation history. To address the pitfall of autoregressive text generation, we propose an approach that incorporates a sliding reflection window and a pausing criterion, such that reflection and generation can be carried out interchangeably as the generation proceeds. Our approach utilizes a selective refinement mechanism to strike the balance between efficiency and optimality, and the experimental results demonstrate the effectiveness of our method."
    },
    {
        "title": "Sequential Controlled Langevin Diffusions",
        "link_suffix": "/forum?id=dImD2sgy86",
        "link": "https://openreview.net/forum?id=dImD2sgy86",
        "pdf_link": "https://openreview.net/pdf?id=dImD2sgy86",
        "keywords": "variational inference, sequential importance sampling, monte carlo, SDEs, diffusion models",
        "abstract": "An effective approach for sampling from an unnormalized density is based on the idea of gradually transporting samples from an easy prior to the complicated target measure. Two popular approaches are (1) Sequential Monte Carlo (SMC), where this transport is performed through successive annealed densities with the help of iterative resampling steps and (2) the recently developed diffusion-based sampling approaches, where a learned dynamical transport is used. Despite the common goal, both approaches have different, often complementary, advantages and drawbacks. The resampling steps in SMC allow to focus on promising regions of the space, often leading to robust performance, however, the algorithm typically lacks the flexibility of learnable transitions. Diffusion samplers, on the other hand, are learned, and can potentially better adapt themselves to the target at hand, yet often suffer from training instabilities. In this work, we present a principled framework of combining SMC with diffusion samplers by viewing both methods in continuous time and considering measures on path space. This culminates in the new Sequential Controlled Langevin Diffusion (SCLD) sampling method, which is able to utilize the benefits of both methods and reaches improved performance on multiple benchmark problems, in many cases using only 10% of\nthe training budget of previous diffusion samplers."
    },
    {
        "title": "HOPE for a Robust Parameterization of Long-memory State Space Models",
        "link_suffix": "/forum?id=RZwtbg3qYD",
        "link": "https://openreview.net/forum?id=RZwtbg3qYD",
        "pdf_link": "https://openreview.net/pdf?id=RZwtbg3qYD",
        "keywords": "state space model, sequence modeling, Long-Range Arena, long memory",
        "abstract": "State-space models (SSMs) that utilize linear, time-invariant (LTI) systems are known for their effectiveness in learning long sequences. To achieve state-of-the-art performance, an SSM often needs a specifically designed initialization, and the training of state matrices is on a logarithmic scale with a very small learning rate. To understand these choices from a unified perspective, we view SSMs through the lens of Hankel operator theory. Building upon it, we develop a new parameterization scheme, called HOPE, for LTI systems that utilizes Markov parameters within Hankel operators. Our approach helps improve the initialization and training stability, leading to a more robust parameterization. We efficiently implement these innovations by nonuniformly sampling the transfer functions of LTI systems, and they require fewer parameters compared to canonical SSMs. When benchmarked against HiPPO-initialized models such as S4 and S4D, an SSM parameterized by Hankel operators demonstrates improved performance on Long-Range Arena (LRA) tasks. Moreover, our new parameterization endows the SSM with non-decaying memory within a fixed time window, which is empirically corroborated by a sequential CIFAR-10 task with padded noise."
    },
    {
        "title": "Optimal Transport for Probabilistic Circuits",
        "link_suffix": "/forum?id=FJ6p5PaHFF",
        "link": "https://openreview.net/forum?id=FJ6p5PaHFF",
        "pdf_link": "https://openreview.net/pdf?id=FJ6p5PaHFF",
        "keywords": "Probabilistic circuits, Wasserstein, Optimization, Learning",
        "abstract": "We introduce a novel optimal transport framework for probabilistic circuits (PCs). While it has been shown recently that divergences between distributions represented as certain classes of PCs can be computed tractably, to the best of our knowledge, there is no existing approach to compute the Wasserstein distance between probability distributions given by PCs. We consider a Wasserstein-type distance that restricts the coupling measure of the associated optimal transport problem to be a probabilistic circuit. We then develop an algorithm for computing this distance by solving a series of small linear programs and derive the circuit conditions under which this is tractable. Furthermore, we show that we can also retrieve the optimal transport plan between the PCs from the solutions to these linear programming problems. We then consider the empirical Wasserstein distance between a PC and a dataset, and show that we can estimate the PC parameters to minimize this distance through an efficient iterative algorithm."
    },
    {
        "title": "Temporal Visiting-Monitoring Feature Interaction Learning for Modelling Structured Electronic Health Records",
        "link_suffix": "/forum?id=HmmN0Mxze7",
        "link": "https://openreview.net/forum?id=HmmN0Mxze7",
        "pdf_link": "https://openreview.net/pdf?id=HmmN0Mxze7",
        "keywords": "Structured EHR, Clinical Prediction, Temporal Feature Interaction",
        "abstract": "Electronic health records (EHRs) contain patients\u2019 longitudinal visit records, and modelling EHRs can be applied to various clinical prediction tasks. Previous works primarily focus on visit sequences and perform feature interaction on visit-level data to capture patient states. Nonetheless, incorporating finer-grained monitoring sequences simultaneously in structured EHRs, where each visit involves multiple monitoring sessions, can improve prediction performance. However, these studies have not accounted for the relationships between visit-level and monitoring-level data. To fill this gap, we propose an EHRs modelling method aimed at modelling the dynamic interaction between visit-level and monitoring-level data and capturing finer-grained health trends. We first capture the dynamic influence between medical data, and then perform a visiting-monitoring feature interaction on the relationships between visit data and monitoring data, to obtain the representation of patients' state for clinical prediction. We conducted extensive experiments on disease prediction and drug recommendation tasks, with MIMIC-III and MIMIC-IV datasets, demonstrating that our method outperforms state-of-the-art models significantly."
    },
    {
        "title": "Toward Foundation Model for Multivariate Wearable Sensing of Physiological Signals",
        "link_suffix": "/forum?id=XhdckVyXKg",
        "link": "https://openreview.net/forum?id=XhdckVyXKg",
        "pdf_link": "https://openreview.net/pdf?id=XhdckVyXKg",
        "keywords": "Foundation Model, Signal Processing, Representation Learning, Wearable Sensing, Digital Healthcare",
        "abstract": "Foundation models in recent literature have the ability to run inference, mainly forecasting, on any type of time series data, thanks to the informative representations comprising waveform features. Wearable sensing data, on the other hand, contain more variability in both patterns and frequency bands of interest and generally emphasize more on the ability to infer healthcare-related outcomes. The main challenge of crafting a foundation model for wearable sensing physiological signals is to learn effective representations that enable quick adaptation to diverse application scenarios with arbitrary numbers and types of wearable sensors. In this work, we propose NormWear, a step toward such a foundation model, aiming to extract generalized and informative wearable sensing representations. NormWear has been pretrained on a large set of physiological signals, including PPG, ECG, EEG, GSR, and IMU, from various public resources. For a holistic assessment, we perform a downstream evaluation on various public wearable sensing datasets, comprising 12 applications in the areas of mental health, body state inference, biomarker estimations, and disease risk evaluations. We show that NormWear significantly outperforms the solid baseline approaches for time series modeling. In addition, leveraging a novel representation-alignment-match-based method, we achieve the representation transformation from physiological into semantic space. Such a transformation enables the possibility of zero-shot inference of our proposed foundation model on custom wearable signal-based health applications. Finally, we conduct a non-linear dynamic analysis on the waveform features extracted by the model at each intermediate layer. This analysis quantifies the model's internal processes and offers a clearer understanding of its behavior in a meaningful way that helps build greater trust in the model's inference among end users."
    },
    {
        "title": "Enhancing Uncertainty Estimation and Interpretability with Bayesian Non-negative Decision Layer",
        "link_suffix": "/forum?id=xJXq6FkqEw",
        "link": "https://openreview.net/forum?id=xJXq6FkqEw",
        "pdf_link": "https://openreview.net/pdf?id=xJXq6FkqEw",
        "keywords": "Factor Analysis, Uncertainty Estimation, explainable AI",
        "abstract": "Although deep neural networks have demonstrated significant success due to their\npowerful expressiveness, most models struggle to meet practical requirements for\nuncertainty estimation. Concurrently, the entangled nature of deep neural net-\nworks leads to a multifaceted problem, where various localized explanation tech-\nniques reveal that multiple unrelated features influence the decisions, thereby un-\ndermining interpretability. To address these challenges, we develop a Bayesian\nNonnegative Decision Layer (BNDL), which reformulates deep neural networks\nas a conditional Bayesian non-negative factor analysis. By leveraging stochastic\nlatent variables, the BNDL can model complex dependencies and provide robust\nuncertainty estimation. Moreover, the sparsity and non-negativity of the latent\nvariables encourage the model to learn disentangled representations and decision\nlayers, thereby improving interpretability. We also offer theoretical guarantees\nthat BNDL can achieve effective disentangled learning. In addition, we developed\na corresponding variational inference method utilizing a Weibull variational in-\nference network to approximate the posterior distribution of the latent variables.\nOur experimental results demonstrate that with enhanced disentanglement capa-\nbilities, BNDL not only improves the model\u2019s accuracy but also provides reliable\nuncertainty estimation and improved interpretability."
    },
    {
        "title": "Understanding Mistakes in Transformers through Token-level Semantic Dependencies",
        "link_suffix": "/forum?id=Ayf42Bo6sk",
        "link": "https://openreview.net/forum?id=Ayf42Bo6sk",
        "pdf_link": "https://openreview.net/pdf?id=Ayf42Bo6sk",
        "keywords": "transformer mistakes, token-level semantic depdendencies",
        "abstract": "Despite the high performance of the transformer model, it sometimes produces unfaithful information. To understand the cause of this issue, we explore how semantically dependent information is encoded within the model. Specifically, we investigate how tokens in multi-head self-attention transformer models encode semantically dependent information.\nTo help us identify semantic information encoded within a token, intuitively, our method analyzes how a token's value shifts in response to changes in semantics. BERT, LLaMA and GPT models are analyzed.\nWe have observed some interesting and similar behaviors in their mechanisms for encoding semantically dependent information:\n1). Most tokens primarily retain their original semantic information, even as they pass through multiple layers.\n2). Semantically dependent information is usually encoded together within a token.\n3). The semantic dependency within a token is sensitive to even irrelevant changes in context and order of prompts.\n4). Mistakes made by the model can be attributed to some tokens that falsely encode semantic dependencies.\nOur findings potentially can help develop more robust and accurate transformer models by pinpointing the mechanisms behind semantic encoding."
    },
    {
        "title": "Revisiting the expressiveness of CNNs: a mathematical framework for feature extraction",
        "link_suffix": "/forum?id=laKmMbx6x4",
        "link": "https://openreview.net/forum?id=laKmMbx6x4",
        "pdf_link": "https://openreview.net/pdf?id=laKmMbx6x4",
        "keywords": "convolutional networks, feature extraction, deep learning theory",
        "abstract": "Over the past decade deep learning has revolutionized the field of computer vision, with convolutional neural network models proving to be very effective for image classification benchmarks. Given their widespread adoption, several theoretical works have analyzed their expressiveness, and study the class of piecewise linear functions that they can realize. However, a fundamental theoretical questions remain answered: why are piecewise linear functions effective for feature extraction tasks that arise in image classification? We address this question in this paper by introducing a simplified mathematical model for feature extraction, based on classical template matching algorithms that are commonly used in computer vision. We then prove that convolutional neural network classifiers can solve this class of image classification problems, by constructing piecewise linear functions that detect the presence of features, and showing that they can be realized by convolutional neurons. We also discuss the interpretability of the networks we construct, and compare them with those obtained via gradient-based optimization methods by conducting experiments on simple datasets."
    },
    {
        "title": "Towards Flexible and Controllable Unknown Rejection",
        "link_suffix": "/forum?id=sejvgf030w",
        "link": "https://openreview.net/forum?id=sejvgf030w",
        "pdf_link": "https://openreview.net/pdf?id=sejvgf030w",
        "keywords": "Unknown Rejection, Reliability, Open-world classification",
        "abstract": "Reliable prediction is an essential requirement for deep neural models that are deployed in open environments, where both covariate and semantic out-of-distribution (OOD) data arise naturally. Recent studies have formulated and pursued two problems named OOD generalization and detection independently, where the former aims to correctly recognize covariate shifts while the latter focuses on rejecting semantic shifts. However, existing methods are misaligned with real-world applications in two aspects. First, in practice, to make safe decisions, a reliable model should accept correctly recognized inputs while rejecting both those misclassified covariate-shifted and semantic-shifted examples. Second, considering the potential existing trade-off between rejecting different failure cases, more convenient, controllable, and flexible unknown rejection approaches are needed. To meet the above requirements, we propose a novel and elegantly simple unknown rejection framework to unify and facilitate classification with rejection under both covariate and semantic shifts. Our key insight is that by separating and consolidating failure-specific reliability knowledge with low-rank adapters and then integrating them, we can enhance the unknown rejection ability effectively and flexibly. Extensive experiments demonstrate the superiority of our framework."
    },
    {
        "title": "QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero Overhead",
        "link_suffix": "/forum?id=xHPVGmLXjd",
        "link": "https://openreview.net/forum?id=xHPVGmLXjd",
        "pdf_link": "https://openreview.net/pdf?id=xHPVGmLXjd",
        "keywords": "KV-Cache, Quantization, JL Transform, Fast AutoRegressive Models",
        "abstract": "Serving LLMs requires substantial memory due to the storage requirements of Key-Value (KV) embeddings in the KV cache, which grows with sequence length. An effective approach to compress KV cache is quantization.However, traditional quantization methods face significant memory overhead due to the need to store quantization constants (at least a zero point and a scale) in full precision per data block. Depending on the block size, this overhead can add 1 or 2 bits per quantized number. We introduce QJL, a new quantization approach that consists of a Johnson-Lindenstrauss (JL) transform followed by sign-bit quantization. In contrast to existing methods, QJL eliminates memory overheads by removing the need for storing quantization constants. We propose an asymmetric estimator for the inner product of two vectors and demonstrate that applying QJL to one vector and a standard JL transform without quantization to the other provides an unbiased estimator with minimal distortion. We have developed an efficient implementation of the QJL sketch and its corresponding inner product estimator, incorporating a lightweight CUDA kernel for optimized computation. When applied across various LLMs and NLP tasks to quantize the KV cache to only 3 bits, QJL demonstrates a more than fivefold reduction in KV cache memory usage without compromising accuracy, all while achieving faster runtime."
    },
    {
        "title": "GREC: Doubly Efficient Privacy-preserving Recommender Systems for Resource-Constrained Devices",
        "link_suffix": "/forum?id=aE0XTpl6oM",
        "link": "https://openreview.net/forum?id=aE0XTpl6oM",
        "pdf_link": "https://openreview.net/pdf?id=aE0XTpl6oM",
        "keywords": "Federated learning, recommender system, secure aggregation",
        "abstract": "Federated recommender system (FedRec) has emerged as a solution to protect user data through collaborative training techniques. However, the real-world implementation of FedRec is hindered by two critical resource constraints of edge devices: a) limited upload bandwidth and b) limited user computational power and storage. Existing methods addressing the first issue, such as message compression techniques, often result in accuracy degradation or potential privacy leakage. For the second issue, most federated learning (FL) protocols assume that users must store and maintain the entire model locally for private inference, which is resource intensive. To address these challenges, we propose doubly efficient privacy-perserving recommender systems (GREC) consisting of both training and inference phase. To reduce communication costs during the training phase, we design a lossless secure aggregation (SecAgg) protocol based on functional secret sharing leveraging the sparsity of the update matrix. During the inference phase, we implement a user-side post-processing local differential privacy (LDP) algorithm to ensure privacy while shifting the bulk of computation to the cloud. Our framework reduces uplink communication costs by up to 90x compared to existing SecAgg protocols and decreases user-side computation time during inference by an average of 11x compared to full-model inference. This makes GREC a practical and scalable solution for deploying federated recommender systems on resource-constrained devices."
    },
    {
        "title": "In-Context Reinforcement Learning From Suboptimal Historical Data",
        "link_suffix": "/forum?id=FXJm5r17Q7",
        "link": "https://openreview.net/forum?id=FXJm5r17Q7",
        "pdf_link": "https://openreview.net/pdf?id=FXJm5r17Q7",
        "keywords": "In-context Learning; Transformer; Reinforcement Learning",
        "abstract": "Large-scale transformer models have achieved remarkable empirical successes, largely due to their in-context learning capabilities. Inspired by this, we explore training an autoregressive transformer for in-context Reinforcement Learning (RL). In this setting, we initially train a transformer on an offline dataset consisting of trajectories collected from various RL instances, and then fix and use this transformer to create an action policy for new RL instances. Notably, we consider the setting where the offline dataset contains trajectories sampled from suboptimal behavioral policies. In this case, standard autoregressive training corresponds to imitation learning and results in suboptimal performance. To address this, we propose the Decision Importance Transformer (DIT), which emulates the actor-critic algorithm in an in-context manner. In particular, we first train a transformer-based value function that estimates the advantage functions of the behavior policies that collected the suboptimal trajectories. Then we train a transformer-based policy via a weighted maximum likelihood estimation loss, where the weights are constructed based on the trained value function to steer the suboptimal policies to the optimal ones. We conduct extensive experiments to test the performance of DIT on both bandit and Markov Decision Process problems. Our results show that DIT achieves superior performance, particularly when the offline dataset contains suboptimal historical data."
    },
    {
        "title": "MDPE: A Multimodal Deception Dataset with Personality and Emotional Characteristics",
        "link_suffix": "/forum?id=EqCbc4wrzy",
        "link": "https://openreview.net/forum?id=EqCbc4wrzy",
        "pdf_link": "https://openreview.net/pdf?id=EqCbc4wrzy",
        "keywords": "deception detection; affective computing; multimodal dataset",
        "abstract": "Deception detection has garnered increasing attention in recent years due to the significant growth of digital media and heightened ethical and security concerns. It has been extensively studied using multimodal methods, including video, audio, and text. In addition, individual differences in deception production and detection are believed to play a crucial role.Although some studies have utilized individual information such as personality traits to enhance the performance of deception detection, current systems remain limited, partly due to a lack of sufficient datasets for evaluating performance. To address this issue, we introduce a multimodal deception dataset MDPE. Besides deception features, this dataset also includes individual differences information in personality and emotional expression characteristics. It can explore the impact of individual differences on deception behavior. It comprises over 104 hours of deception and emotional videos from 193 subjects. Furthermore, we conducted numerous experiments to provide valuable insights for future deception detection research. MDPE not only supports deception detection, but also provides conditions for tasks such as personality recognition and emotion recognition, and can even study the relationships between them. We believe that MDPE will become a valuable resource for promoting research in the field of affective computing."
    },
    {
        "title": "ING-VP: MLLMs Cannot Play Easy Vision-based Games Yet",
        "link_suffix": "/forum?id=inpLTODeA6",
        "link": "https://openreview.net/forum?id=inpLTODeA6",
        "pdf_link": "https://openreview.net/pdf?id=inpLTODeA6",
        "keywords": "Multimodal, Benchmark, Game, Planning",
        "abstract": "As multimodal large language models (MLLMs) continue to demonstrate increasingly competitive performance across a broad spectrum of tasks, more intricate and comprehensive benchmarks have been developed to assess these cutting-edge models. These benchmarks introduce new challenges to core capabilities such as perception, reasoning, and planning. However, existing multimodal benchmarks fall short in providing a focused evaluation of multi-step planning based on spatial relationships in images. To bridge this gap, we present ING-VP, the first INteractive Game-based Vision Planning benchmark, specifically designed to assess the spatial imagination and multi-step reasoning abilities of MLLMs. ING-VP features 6 distinct games, encompassing 300 levels, each with 6 unique configurations. A single model engages in over 60,000 rounds of interaction. The benchmark framework allows for multiple comparison settings, including image-only vs. text-only inputs, single-step vs. multi-step reasoning, and with-history vs. without-history conditions, offering valuable insights into the model\u2019s capabilities.\nWe evaluated numerous state-of-the-art MLLMs, with the highest-performing model, Claude-3.5 Sonnet, achieving an average accuracy of only 3.37%, far below the anticipated standard.\nThis work aims to provide a specialized evaluation framework to drive advancements in MLLMs' capacity for complex spatial reasoning and planning."
    },
    {
        "title": "Flow Score Distillation for Diverse Text-to-3D Generation",
        "link_suffix": "/forum?id=Zkrsr7vAaG",
        "link": "https://openreview.net/forum?id=Zkrsr7vAaG",
        "pdf_link": "https://openreview.net/pdf?id=Zkrsr7vAaG",
        "keywords": "text to 3D, score distillation, diffusion model, 3D generation",
        "abstract": "Recent advancements in Text-to-3D generation have yielded remarkable progress, particularly through methods that rely on Score Distillation Sampling (SDS). While SDS exhibits the capability to create impressive 3D assets, it is hindered by its inherent maximum-likelihood-seeking essence, resulting in limited diversity in generation outcomes. In this paper, we discover that the Denoise Diffusion Implicit Models (DDIM) generation process (i.e. PF-ODE) can be succinctly expressed using an analogue of SDS loss. One step further, one can see SDS as a generalized DDIM generation process. Following this insight, we show that the noise sampling strategy in the noise addition stage significantly restricts the diversity of generation results. To address this limitation, we present an innovative noise sampling approach and introduce a novel text-to-3D method called Flow Score Distillation (FSD). Our validation experiments across various text-to-image Diffusion Models demonstrate that FSD substantially enhances generation diversity and quality."
    },
    {
        "title": "Unified Uncertain Dual-prompts cross-domain Segmentation framework for medical image segmentation",
        "link_suffix": "/forum?id=V5Y7HdPXEA",
        "link": "https://openreview.net/forum?id=V5Y7HdPXEA",
        "pdf_link": "https://openreview.net/pdf?id=V5Y7HdPXEA",
        "keywords": "Unsupervised Medical Image Segmentation;",
        "abstract": "Unsupervised cross-domain segmentation addresses the challenge of label dependence in cross-domain medical image segmentation. Yet, most existing methods treat domain adaptation and segmentation as \\textbf{\\textit{Two Separate Steps}} and primarily focus on global domain adaptation, lacking the ability to prioritize segmentation-specific information during domain adaptation. Additionally, extracting domain-invariant feature representation remains an unavoidable challenge for cross-domain segmentation. These challenges significantly reduce segmentation performance. To this end, we propose a novel  Unified Uncertain Dual-prompts cross-domain Segmentation framework (UUDS) for unsupervised cross-domain medical image segmentation. Specifically, our UUDS forms a unified framework by integrating domain adaptation and segmentation models, facilitating interaction between the two tasks, and addressing the challenge of emphasizing segmentation semantics while domain adaptation. Additionally, UUDS creatively uses dual-prompts, domain and segmentation prompts, to learn domain-invariant feature representation, ensuring that model can learn domain-invariant feature representation from cross-domain space. Furthermore, to facilitate interaction between the two tasks, UUDS uses uncertainty estimation to dynamically compute the label of segmentation for directly supervising the cross-domain adaptation, making the semantic information from unlabeled target images can directly supervise the process of domain adaptation and keeping the model sensitive to segmentation. Extensive experimental results on two public unsupervised cross-modality medical image segmentation demonstrate that UUDS outperforms state-of-the-art methods in unsupervised cross-modality medical image segmentation, highlighting its effectiveness in addressing domain shifts and marking a significant breakthrough."
    },
    {
        "title": "Rethinking Adversarial Attacks as Protection Against Diffusion-based Mimicry",
        "link_suffix": "/forum?id=tiJzOop4u6",
        "link": "https://openreview.net/forum?id=tiJzOop4u6",
        "pdf_link": "https://openreview.net/pdf?id=tiJzOop4u6",
        "keywords": "Generative Model; Diffusion Model; Adversarial Attack",
        "abstract": "Diffusion models have demonstrated an remarkable capability to edit or imitate images, which has raised concerns regarding the safeguarding of intellectual property. To address these concerns, the adoption of adversarial attacks, which introduce adversarial perturbations that can fool the targeted diffusion model into protected images , has emerged as a viable solution. Consequently, diffusion models, like many other deep network models, are believed to be susceptible to adversarial attacks. However, in this work, we draw attention to an important oversight in existing research, as all previous studies have focused solely on attacking latent diffusion models (LDMs), neglecting adversarial examples for diffusion models in the pixel space (PDMs). Through extensive experiments, we demonstrate that nearly all existing adversarial attack methods designed for LDMs, as well as adaptive attacks designed for PDMs, fail when applied to PDMs. We attribute the vulnerability of LDMs to their encoders, indicating that diffusion models exhibit strong robustness against adversarial attacks. Building upon this insight, we find that PDMs can be used as an off-the-shelf purifier to effectively eliminate adversarial patterns generated by LDMs, thereby maintaining the integrity of images. Notably, we highlight that most existing protection methods can be easily bypassed using PDM-based purification. We hope our findings prompt a reevaluation of adversarial samples for diffusion models as potential protection methods."
    },
    {
        "title": "Decision Information Meets Large Language Models: The Future of Explainable Operations Research",
        "link_suffix": "/forum?id=W2dR6rypBQ",
        "link": "https://openreview.net/forum?id=W2dR6rypBQ",
        "pdf_link": "https://openreview.net/pdf?id=W2dR6rypBQ",
        "keywords": "Operations Research Problems; Large Language Models",
        "abstract": "Operations Research (OR) is vital for decision-making in many industries. While recent OR methods have seen significant improvements in automation and efficiency through integrating Large Language Models (LLMs), they still struggle to produce meaningful explanations. This lack of clarity raises concerns about transparency and trustworthiness in OR applications. To address these challenges, we propose a comprehensive framework, Explainable Operations Research (EOR), emphasizing actionable and understandable explanations accompanying optimization. The core of EOR is the concept of Decision Information, which emerges from what-if analysis and focuses on evaluating the impact of complex constraints (or parameters) changes on decision-making. Specifically, we utilize bipartite graphs to quantify the changes in the OR model and adopt LLMs to improve the explanation capabilities. Additionally, we introduce the first industrial benchmark to rigorously evaluate the effectiveness of explanations and analyses in OR, establishing a new standard for transparency and clarity in the field."
    },
    {
        "title": "DESIRE: Dynamic Knowledge Consolidation for Rehearsal-Free Continual Learning",
        "link_suffix": "/forum?id=dOkuRMrWtL",
        "link": "https://openreview.net/forum?id=dOkuRMrWtL",
        "pdf_link": "https://openreview.net/pdf?id=dOkuRMrWtL",
        "keywords": "Class-incremental learning, Model merging",
        "abstract": "Continual learning aims to equip models with the ability to retain previously learned knowledge like a human. Recent work incorporating Parameter-Efficient Fine-Tuning has revitalized the field by introducing lightweight extension modules. However, existing methods usually overlook the issue of information leakage caused by the fact that the experiment data have been used in pre-trained models. Once these duplicate data are removed in the pre-training phase, their performance can be severely affected. In this paper, we propose a new LoRA-based rehearsal-free method named $\\textbf{DESIRE}$. Our method avoids imposing additional constraints during training to mitigate catastrophic forgetting, thereby maximizing the learning of new classes. To integrate knowledge from old and new tasks, we propose two efficient post-processing modules. On the one hand, we retain only two sets of LoRA parameters for merging and propose dynamic representation consolidation to calibrate the merged feature representation. On the other hand, we propose decision boundary refinement to address classifier bias when training solely on new class data. Extensive experiments demonstrate that our method achieves state-of-the-art performance on multiple datasets and strikes an effective balance between stability and plasticity. Our code will be publicly available."
    },
    {
        "title": "Skill Expansion and Composition in Parameter Space",
        "link_suffix": "/forum?id=GLWf2fq0bX",
        "link": "https://openreview.net/forum?id=GLWf2fq0bX",
        "pdf_link": "https://openreview.net/pdf?id=GLWf2fq0bX",
        "keywords": "Skill expansion, skill composition, parameter-efficient finetuning, decision making",
        "abstract": "Human excels at reusing prior knowledge to address new challenges and develop skills while solving problems. This paradigm becomes increasingly popular in the development of autonomous agents, as it develops systems that can self-evolve in response to new challenges like human beings. However, previous methods suffer from limited training efficiency when expanding new skills and fail to fully leverage prior knowledge to facilitate new task learning. We propose Parametric Skill Expansion and Composition (PSEC), a new framework designed to iteratively evolve the agents' capabilities and efficiently address new challenges by maintaining a manageable skill library. This library can progressively integrate skill primitives as plug-and-play LoRA modules, facilitating efficient and flexible skill expansion. This structure also enables the direct skill compositions in parameter space by merging LoRA modules that encode different primitives, leveraging shared information across skills to effectively program new skills. Based on this, we propose a context-aware modular to dynamically activate different skills to collaboratively handle new tasks. Empowering diverse applications including multi-objective composition, dynamics shift, and continual policy shift, the results on D4RL, DSRL benchmarks, and the DeepMind Control Suite show that PSEC exhibits superior capacity to leverage prior knowledge to efficiently tackle new challenges, as well as expand its skill libraries to evolve the capabilities."
    },
    {
        "title": "Understanding Distribution Alignment Through Category Separability In An Infant-Inspired Domain Adaptation Task",
        "link_suffix": "/forum?id=MwMoE1y0Nb",
        "link": "https://openreview.net/forum?id=MwMoE1y0Nb",
        "pdf_link": "https://openreview.net/pdf?id=MwMoE1y0Nb",
        "keywords": "domain adaptation, distribution shift, infant learning, self-supervised learning",
        "abstract": "We introduce a novel distribution shift considering the tradeoff between object instances and viewpoints occurring in human and embodied visual experience; we study this problem through the lens of domain adaptation. We show that the performance of a well-known domain adaptation method, Joint Adaptation Network (JAN), deteriorates in the absence of ImageNet pretraining. We hypothesize that the separability of source and target category clusters in the feature space plays a crucial role in the effectiveness of JAN. To this end, we propose 3 metrics to measure category separability in the feature space and show that separability in the pretrained network is strongly correlated with downstream JAN accuracy. Further, we propose two novel loss functions increasing target separability by aligning the distribution of within-domain pairwise distances between the source and target cluster. Our experiments show that the application of these loss functions improves downstream performance on the test set."
    },
    {
        "title": "VideoUntier: Language-guided Video Feature Disentanglement",
        "link_suffix": "/forum?id=aClIuYLG47",
        "link": "https://openreview.net/forum?id=aClIuYLG47",
        "pdf_link": "https://openreview.net/pdf?id=aClIuYLG47",
        "keywords": "representation learning, cross-modal learning, video recognition",
        "abstract": "Most of existing text-video retrieval works learn features comprehensively representing complicated video contents. This leads to the difficulty of textual-visual feature alignment, because text queries convey more concise cues like certain objects and events the user desires to retrieve. To pursue a more compact video representation and accurate textual-visual feature matching, this paper introduces a novel VideoUntier to disentangle video features. VideoUntier first generates 'object' and 'event' tokens from query texts. It subsequently spots and merges visual tokens related to concepts in the query. In other words, we use 'object' and 'event' tokens to represent cues of query, which therefore supervise the disentanglement and extraction of meaningful visual features from videos. VideoUntier finally leads to compact visual tokens explicitly depicting query objects and events. Extensive experiments on three widely-used datasets demonstrate the promising performance and domain generalization capability of our method. For instance, our method shows better efficiency and consistently outperforms many recent works like ProST on three datasets. We hope to inspire future work for collaborative cross-modal learning with certain modality as guidance."
    },
    {
        "title": "Boosting Parallel Algorithms in Linear Queries for Non-Monotone Submodular Maximization",
        "link_suffix": "/forum?id=pshLnZzIbW",
        "link": "https://openreview.net/forum?id=pshLnZzIbW",
        "pdf_link": "https://openreview.net/pdf?id=pshLnZzIbW",
        "keywords": "Submodular Maximization, Non-Monotone, Parallel Algorithms",
        "abstract": "In this work, we propose two efficient parallel algorithms, $\\mathsf{LinAst}$ and $\\mathsf{LinAtg}$, that improve both the approximation ratio and query complexity of existing practical parallel algorithms for the non-monotone submodular maximization over the ground set of sized $n$ under a cardinality constraint $k$. Specifically, our algorithms keep the best adaptive complexity of $O(\\log n)$  while significantly improving the approximation ratio from $1/6-\\epsilon$ to $0.193-\\epsilon$ and reducing the query complexity from $O(n\\log (k))$ to $O(n)$.The key building block of our algorithms is $\\mathsf{LinAdapt}$, a constant  approximation ratio within $O(\\log n)$ sequence rounds and linear queries. $\\mathsf{LinAdapt}$ can reduce the query complexity by providing $O(1)$ guesses of the optimal value.  We further introduce the $\\mathsf{BoostAdapt}$ algorithm returning a better ratio of $1/4-\\epsilon$ within $O(\\log (n)\\log (k))$ adaptive complexity and $O(n\\log (k))$ query complexity. Our $\\mathsf{BoostAdapt}$ works in a novel staggered greedy threshold framework that alternately constructs two disjoint sets in $O(\\log k)$ sequential rounds.  Besides theoretical analysis, the experiment results on validated benchmarks confirm the superiority of our algorithms in terms of solution quality, the number of required queries, and running time over cutting-edge algorithms."
    },
    {
        "title": "xTED: Cross-Domain Adaptation via Diffusion-Based Trajectory Editing",
        "link_suffix": "/forum?id=Nh8NLlIfBv",
        "link": "https://openreview.net/forum?id=Nh8NLlIfBv",
        "pdf_link": "https://openreview.net/pdf?id=Nh8NLlIfBv",
        "keywords": "Cross-Domain Policy Transfer, Embodied Decision Making, Diffusion Models",
        "abstract": "Reusing pre-collected data from different domains is an appealing solution for decision-making tasks that have insufficient data in the target domain but are relatively abundant in other related domains.\n            Existing cross-domain policy transfer methods mostly aim at learning domain correspondences or corrections to facilitate policy learning, such as learning domain/task-specific discriminators, representations, or policies. This design philosophy often results in heavy model architectures or task/domain-specific modeling, lacking flexibility.\n            This reality makes us wonder: can we directly bridge the domain gaps universally at the data level, instead of relying on complex downstream cross-domain policy transfer models?\n            In this study, we propose theCross-DomainTrajectoryEDiting (xTED) framework that employs a specially designed diffusion model for cross-domain trajectory adaptation.\n            Our proposed model architecture effectively captures the intricate dependencies among states, actions, and rewards, as well as the dynamics patterns within target data. By utilizing the pre-trained diffusion as a prior, source domain trajectories can be transformed to match with target domain properties while preserving original semantic information. \n            This process implicitly corrects underlying domain gaps, enhancing state realism and dynamics reliability in the source data, and allowing flexible incorporation with various downstream policy learning methods.\n            Despite its simplicity, xTED demonstrates superior performance in extensive simulation andreal-robot experiments."
    }
]
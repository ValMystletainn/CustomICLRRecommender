[
    {
        "title": "MVTokenFlow: High-quality 4D Content Generation using Multiview Token Flow",
        "link_suffix": "/forum?id=zu7cBTPsDb",
        "link": "https://openreview.net/forum?id=zu7cBTPsDb",
        "pdf_link": "https://openreview.net/pdf?id=zu7cBTPsDb",
        "keywords": "4D Generation, Dynamic 3D Gaussian Splatting, Dynamic Reconstruction, Diffusion Models",
        "abstract": "In this paper, we present MVTokenFlow for high-quality 4D content creation from monocular videos. Recent advancements in generative models such as video diffusion models and multiview diffusion models enable us to create videos or 3D models. However, extending these generative models for dynamic 4D content creation is still a challenging task that requires the generated content to be consistent spatially and temporally. To address this challenge, MVTokenFlow utilizes the multiview diffusion model to generate multiview images on different timesteps, which attains spatial consistency across different viewpoints and allows us to reconstruct a reasonable coarse 4D field. Then, MVTokenFlow further regenerates all the multiview images using the rendered 2D flows as guidance. The 2D flows effectively associate pixels from different timesteps and improve the temporal consistency by reusing tokens in the regeneration process. Finally, the regenerated images are spatiotemporally consistent and utilized to refine the coarse 4D field to get a high-quality 4D field. Experiments demonstrate the effectiveness of our design and show significantly improved quality than baseline methods."
    },
    {
        "title": "OMNIBAL: TOWARDS FAST INSTRUCT-TUNING FOR VISION-LANGUAGE MODELS VIA OMNIVERSE COMPUTATION BALANCE",
        "link_suffix": "/forum?id=N80ER2he6l",
        "link": "https://openreview.net/forum?id=N80ER2he6l",
        "pdf_link": "https://openreview.net/pdf?id=N80ER2he6l",
        "keywords": "Fast Vision-Language Training; 3D parallel",
        "abstract": "Vision-language instruct-tuning models have recently made significant progress due to their more comprehensive understanding of the world. In this work, we discover that large-scale 3D parallel training on those models leads to an imbalanced computation load across different devices. The vision and language parts are inherently heterogeneous:  their data distribution and model architecture differ significantly, which affects distributed training efficiency. To address this issue, we rebalance the computational load from data, model, and memory perspectives, achieving more balanced computation across devices.  Specifically, for the data, instances are grouped into new balanced mini-batches within and across devices. A search-based method is employed for the model to achieve a more balanced partitioning. For memory optimization, we adaptively adjust the re-computation strategy for each partition to utilize the available memory fully. These three perspectives are not independent but are closely connected, forming an omniverse balanced training framework. extensive experiments are conducted to validate the effectiveness of our method. Compared with the open-source training code of InternVL-Chat, training time is reduced greatly, achieving about 1.8x speed-up. Our method's efficacy and generalizability are further validated across various models and datasets. Codes will be released athttps://github.com/anonymousiclr293/omnibal_example."
    },
    {
        "title": "Pooling And Attention: What Are Effective Designs For LLM-Based Embedding Models?",
        "link_suffix": "/forum?id=CWAvMSNUqT",
        "link": "https://openreview.net/forum?id=CWAvMSNUqT",
        "pdf_link": "https://openreview.net/pdf?id=CWAvMSNUqT",
        "keywords": "Representation learning; Embedding Model; LLM; Information Retrieval",
        "abstract": "The significant advancements of Large Language Models (LLMs) in generative tasks have led to a growing body of work exploring LLM-based embedding models. While these models, employing different pooling and attention strategies, have achieved state-of-the-art performance on public embedding benchmarks, questions still arise about what constitutes an effective design for LLM-based embedding models. However, these models are often trained on different datasets, using different LLM base models or training settings. Moreover, evaluations on public embedding benchmarks often fail to report statistical significance, making it difficult to determine which designs truly contribute to final performance. This complicates the process for practitioners seeking optimal training recipes for LLM-based embedding models. In this study, we conduct a large-scale experiment by training a series of LLM-based embedding models using the same training data and base model but differing in their pooling and attention strategies. The results show that there is no one-size-fits-all solution: while bidirectional attention and an additional trainable pooling layer outperform in text similarity and information retrieval tasks, they do not significantly surpass simpler designs like EOS-last token pooling and default causal attention in clustering and classification tasks. Furthermore, we propose a new pooling strategy, Multi-Layers Trainable Pooling, which transforms the outputs of all hidden layers, rather than just the last layer, using a cross-attention network. This method proves to be statistically superior in text similarity and retrieval tasks compared to existing pooling methods. Overall, this paper sheds light on effective training strategies for LLM-based embedding models."
    },
    {
        "title": "Open-World Test-Time Training: Self-Training with Contrastive Learning",
        "link_suffix": "/forum?id=Tzlmaaiytv",
        "link": "https://openreview.net/forum?id=Tzlmaaiytv",
        "pdf_link": "https://openreview.net/pdf?id=Tzlmaaiytv",
        "keywords": "Open-World, Test-Time Training, Self-Training, Contrastive Learning, Transfer learning",
        "abstract": "Traditional test-time training (TTT) methods, while addressing domain shifts, often assume a consistent class set that limits their applicability in real-world scenarios with infinite variety. Open-World Test-Time Training (OWTTT) addresses the challenge of generalizing deep learning models to unknown target domain distributions, especially in the presence of strong Out-of-Distribution (OOD) data. Existing TTT methods often struggle to maintain performance when confronted with strong OOD data. In OWTTT, the primary focus has been on distinguishing between strong and weak OOD data. However, during the early stages of TTT, initial feature extraction is hampered by interference from strong OOD and corruptions, leading to reduced contrast and premature classification of certain classes as strong OOD. To handle this problem, we introduce Open World Dynamic Contrastive Learning (OWDCL), an innovative approach that leverage contrastive learning to augment positive sample pairs. This strategy not only enhances contrast in the early stages but also significantly enhances model robustness in later stages. In comparison datasets, our OWDCL model achieves state-of-the-art performance."
    },
    {
        "title": "Rethinking Brain-to-Image Reconstruction: What Should We Decode from fMRI Signals?",
        "link_suffix": "/forum?id=UUNTAwJIIn",
        "link": "https://openreview.net/forum?id=UUNTAwJIIn",
        "pdf_link": "https://openreview.net/pdf?id=UUNTAwJIIn",
        "keywords": "neural decoding, brain-to-image reconstruction, pseudo-foveated image synthesis, fMRI-to-foveated image decoding",
        "abstract": "Recently, notable advancements have been achieved in brain-to-image reconstruction. However, the assumption that the recorded brain activities faithfully mirror the complete high-resolution images conflicts with the workings of human vision and cognitive systems. \nIn this study, we present a novel approach, fMRI-to-foveated image (FitFovea), which redefines the brain-to-image reconstruction process to better align with cognitive science principles. FitFovea comprises three key stages: pseudo-foveated image synthesis, fMRI-to-foveated image reconstruction and stimulus image generation. In the first stage, FitFovea constructs new {fMRI, pseudo-foveated image} pairs from existing fMRI-image data using saliency prediction and foveated rendering techniques. Next, during the foveated image reconstruction phase, the information captured by human vision is decoded from fMRI signals with maximum accuracy. The final stage, stimulus image generation, is considered not as a strict reconstruction but rather as a postprocessing step. This stage is akin to existing brain-to-image decoding methods, which often emphasize semantic fidelity rather than pixel-level reconstruction. To validate our approach, we introduce the brain score metric to quantify the correlation between images and corresponding brain responses. The superior results validate the rationale behind decoding pseudo-foveated images from fMRI data and demonstrate the feasibility of our newly-devised pipeline based on synthesized pseudo-foveated image training data."
    },
    {
        "title": "IntLoRA: Integral Low-rank Adaptation of Quantized Diffusion Models",
        "link_suffix": "/forum?id=f4mQ2SU5tp",
        "link": "https://openreview.net/forum?id=f4mQ2SU5tp",
        "pdf_link": "https://openreview.net/pdf?id=f4mQ2SU5tp",
        "keywords": "Parameter efficient fine tuning, Network quantization, Diffusion model",
        "abstract": "Fine-tuning large-scale text-to-image diffusion models for various downstream tasks has yielded impressive results. However, the heavy computational burdens of tuning large models prevent personal customization. Recent advances have attempted to employ parameter-efficient fine-tuning (PEFT) techniques to adapt the floating-point (FP) or quantized pre-trained weights. Nonetheless, the adaptation parameters in existing works are still restricted to FP arithmetic, hindering hardware-friendly acceleration. In this work, we propose IntLoRA, to further push the efficiency limits by using integer type (INT) low-rank parameters to adapt the quantized diffusion models. By working in the integer arithmetic, our IntLoRA offers three key advantages: (i) for fine-tuning, the pre-trained weights are quantized, reducing memory usage; (ii) for storage, both pre-trained and low-rank weights are in INT which consumes less disk space; (iii) for inference, IntLoRA weights can be naturally merged into quantized pre-trained weights through efficient integer multiplication or bit-shifting, eliminating additional post-training quantization. Extensive experiments demonstrate that IntLoRA can achieve performance on par with or even superior to the vanilla LoRA, accompanied by significant efficiency improvements."
    },
    {
        "title": "Integrating the Expression and Discrimination via Bilateral Compensation for Molecular Property Prediction",
        "link_suffix": "/forum?id=eWs2Zxxwwn",
        "link": "https://openreview.net/forum?id=eWs2Zxxwwn",
        "pdf_link": "https://openreview.net/pdf?id=eWs2Zxxwwn",
        "keywords": "Molecular property prediction, Self-supervised learning",
        "abstract": "Predicting molecular properties plays an important role in both scientific research and industrial applications. Given that different molecular properties are influenced by specific atoms or functional groups, it is essential to incorporate both types of information. Previous approaches either leverage subgraph information in self-supervised learning to pre-train atom-based architectures or develop subgraph-based architectures tailored to specific downstream tasks. However, these methods often lack a thorough analysis or theoretical support concerning the expressive capabilities of these two types of representations. Moreover, they typically rely on fixed coupling representations, which cannot adaptively prioritize more discriminative information for various downstream tasks.\nIn this paper, we introduce a Route-guided Bilateral Compensation (RBC) architecture that explicitly extracts atom-wise and subgraph-wise information through two decoupled branches and integrates them via a route module. Theoretically, we demonstrate that our decomposition-polymerization subgraph-wise branch exhibits greater expressive power than the atom-wise branch, and that the integration process reduces the generalization error bound. Furthermore, we propose a coordinated self-supervised learning strategy that incorporates node-level masked graph reconstruction tasks for atomic and lexicalized subgraph tokens, alongside a graph-level contrastive learning task. For different downstream tasks, the route module facilitates dynamic integration, enhancing the discriminative power of the final representation. External experiments verify the effectiveness of our method."
    },
    {
        "title": "DenoiseVAE: Learning Molecule-Adaptive Noise Distributions for Denoising-based 3D Molecular Pre-training",
        "link_suffix": "/forum?id=ym7pr83XQr",
        "link": "https://openreview.net/forum?id=ym7pr83XQr",
        "pdf_link": "https://openreview.net/pdf?id=ym7pr83XQr",
        "keywords": "3D Molecular pre-training via denoising, Molecular property prediction",
        "abstract": "Denoising learning of 3D molecules learns molecular representations by imposing noises into the equilibrium conformation and predicting the added noises to recover the equilibrium conformation, which essentially captures the information of molecular force fields. Due to the specificity of Potential Energy Surfaces, the probabilities of physically reasonable noises for each atom in different molecules are different. However, existing methods apply the shared heuristic hand-crafted noise sampling strategy to all molecules, resulting in inaccurate force field learning. In this paper, we propose a novel 3D molecular pre-training method, namely DenoiseVAE, which employs a Noise Generator to acquire atom-specific noise distributions for different molecules. It utilizes the stochastic reparameterization technique to sample noisy conformations from the generated distributions, which are inputted into a Denoising Module for denoising. The Noise Generator and the Denoising Module are jointly learned in a manner conforming with the paradigm of Variational Auto Encoder. Consequently, the sampled noisy conformations can be more diverse, adaptive, and informative, and thus DenoiseVAE can learn representations that better reveal the molecular force fields. Extensive experiments show that DenoiseVAE outperforms the current state-of-the-art methods on various molecular property prediction tasks, demonstrating the effectiveness of it."
    },
    {
        "title": "Retrieval Augmented Time Series Forecasting",
        "link_suffix": "/forum?id=GYwH71ugtC",
        "link": "https://openreview.net/forum?id=GYwH71ugtC",
        "pdf_link": "https://openreview.net/pdf?id=GYwH71ugtC",
        "keywords": "Time series forecasting, Retrieval augmented model, Deep learning",
        "abstract": "Time series forecasting uses historical data to predict future trends, leveraging the relationships between past observations and available features. In this paper, we propose, RAFT, a retrieval-augmented time series forecasting method to provide sufficient inductive biases and complement the model's learning capacity. When forecasting the subsequent time frames, we directly retrieve historical data candidates from the training dataset with patterns most similar to the input, and utilize the future values of these candidates alongside the inputs to obtain predictions. This simple approach augments the model's capacity by externally providing information about past patterns via retrieval modules. Our empirical evaluations on eight benchmark datasets show that RAFT consistently outperforms contemporary baselines, an average win ratio of 86% for multivariate forecasting and 80% for univariate forecasting tasks."
    },
    {
        "title": "Fine-tuning CLIP\u2019s Last Visual Projector: A Few-Shot Cornucopia",
        "link_suffix": "/forum?id=ep4FPuE1w3",
        "link": "https://openreview.net/forum?id=ep4FPuE1w3",
        "pdf_link": "https://openreview.net/pdf?id=ep4FPuE1w3",
        "keywords": "Few-shot classification, CLIP, transfer learning",
        "abstract": "We consider the problem of adapting a contrastively pretrained vision-language model like CLIP (Radford et al., 2021) for few-shot classification. The existing literature addresses this problem by learning a linear classifier of the frozen visual features, optimizing word embeddings, or learning external feature adapters. This paper introduces an alternative way for CLIP adaptation without adding \u201cexternal\u201d parameters to optimize. We find that simply fine-tuning the last projection matrix of the vision encoder leads to strong performance compared to the existing baselines. Furthermore, we show that regularizing training with the distance between the fine-tuned and pretrained matrices adds reliability for adapting CLIP through this layer. Perhaps surprisingly, this approach, coined ProLIP, yields performances on par or better than state of the art on 11 few-shot classification benchmarks, few-shot domain generalization, cross-dataset transfer and test-time adaptation. Code will be made available online."
    },
    {
        "title": "SoftCVI: Contrastive variational inference with self-generated soft labels",
        "link_suffix": "/forum?id=PiZtlzMWUj",
        "link": "https://openreview.net/forum?id=PiZtlzMWUj",
        "pdf_link": "https://openreview.net/pdf?id=PiZtlzMWUj",
        "keywords": "contrastive learning, variational inference",
        "abstract": "Estimating a distribution given access to its unnormalized density is pivotal in Bayesian inference, where the posterior is generally known only up to an unknown normalizing constant. Variational inference and Markov chain Monte Carlo methods are the predominant tools for this task; however, both are often challenging to apply reliably, particularly when the posterior has complex geometry. Here, we introduce Soft Contrastive Variational Inference (SoftCVI), which allows a family of variational objectives to be derived through a contrastive estimation framework. The approach parameterizes a classifier in terms of a variational distribution, reframing the inference task as a contrastive estimation problem aiming to identify a single true posterior sample among a set of samples. Despite this framing, we do not require positive or negative samples, but rather learn by sampling the variational distribution and computing ground truth soft classification labels from the unnormalized posterior itself. The objectives have zero variance gradient when the variational approximation is exact, without the need for specialized gradient estimators. We empirically investigate the performance on a variety of Bayesian inference tasks, using both simple (e.g. normal) and expressive (normalizing flow) variational distributions. We find that SoftCVI can be used to form objectives which are stable to train and mass-covering, frequently outperforming inference with other variational approaches."
    },
    {
        "title": "MEMO: Memory-Guided and Emotion-Aware Talking Video Generation",
        "link_suffix": "/forum?id=CpgWRFqxhD",
        "link": "https://openreview.net/forum?id=CpgWRFqxhD",
        "pdf_link": "https://openreview.net/pdf?id=CpgWRFqxhD",
        "keywords": "Talking Head, Video Generation, Diffusion Models",
        "abstract": "Advances in video diffusion models have unlocked the potential for realistic audio-driven talking video generation. However, it is still highly challenging to ensure seamless audio-lip synchronization, maintain long-term identity consistency, and achieve natural expressions aligned with the audio in generated talking videos. To address these challenges, we proposeMemory-guidedEMOtion-aware diffusion (MEMO), an end-to-end audio-driven portrait animation approach to generate identity-consistent and expressive talking videos. Our approach is built around two key modules: (1) a memory-guided temporal module, which enhances long-term identity consistency and smooth motion by developing memory states that store information from all previously generated frames and guide temporal modeling through linear attention; and (2) an emotion-aware audio module, which replaces traditional cross attention with multi-modal attention to enhance audio-video interaction, while detecting emotions from the audio to refine facial expressions via emotion adaptive layer norm. Moreover, MEMO is trained on a large-scale, high-quality dataset of talking head videos without relying on facial inductive biases such as face landmarks or bounding boxes. Extensive experiments demonstrate that MEMO generates more realistic talking videos across a wide range of audio types, surpassing state-of-the-art talking video diffusion methods in human evaluations in terms of emotion-audio alignment, identity consistency and overall quality, respectively."
    },
    {
        "title": "Quantile Regression for Distributional Reward Models in RLHF",
        "link_suffix": "/forum?id=UXpwNNiMRC",
        "link": "https://openreview.net/forum?id=UXpwNNiMRC",
        "pdf_link": "https://openreview.net/pdf?id=UXpwNNiMRC",
        "keywords": "RLHF, LLM, alignment, reward models",
        "abstract": "Reinforcement learning from human feedback (RLHF) has become a key method for aligning large language models (LLMs) with human preferences through the use of reward models. However, traditional reward models typically generate point estimates, which oversimplify the diversity and complexity of human values and preferences. In this paper, we introduce Quantile Reward Models (QRMs), a novel approach to reward modeling that learns a distribution over rewards instead of a single scalar value.  Our method uses quantile regression to estimate a full, potentially multimodal distribution over preferences, providing a more powerful and nuanced representation of preferences. This distributional approach can better capture the diversity of human values, addresses label noise, and accommodates conflicting preferences by modeling them as distinct modes in the distribution. Our experimental results show that QRM outperforms comparable traditional point-estimate models on RewardBench. Furthermore, we demonstrate that the additional information provided by the distributional estimates can be utilized in downstream applications, such as risk-aware reinforcement learning, resulting in LLM policies that generate fewer extremely negative responses. Our code and model will be released."
    },
    {
        "title": "Halton Scheduler for Masked  Generative Image Transformer",
        "link_suffix": "/forum?id=RDVrlWAb7K",
        "link": "https://openreview.net/forum?id=RDVrlWAb7K",
        "pdf_link": "https://openreview.net/pdf?id=RDVrlWAb7K",
        "keywords": "Image Synthesis, MaskGIT, Halton Sequence",
        "abstract": "Masked Generative Image Transformers (MaskGIT) have emerged as a scalable and efficient image generation framework, able to deliver high-quality visuals with low inference costs. However, MaskGIT's token unmasking scheduler, an essential component of the framework, has not received the attention it deserves. We analyze the sampling objective in MaskGIT, based on the mutual information between tokens, and elucidate its shortcomings. We then propose a new sampling strategy based on our Halton scheduler instead of the original Confidence scheduler. More precisely, our method selects the token's position according to a quasi-random, low-discrepancy Halton sequence. Intuitively, that method spreads the tokens spatially, progressively covering the image uniformly at each step. Our analysis shows that it allows reducing non-recoverable sampling errors, leading to simpler hyper-parameter tuning and better quality images. Our scheduler does not require retraining or noise injection and may serve as a simple drop-in replacement for the original sampling strategy. Evaluation of both class-to-image synthesis on ImageNet and text-to-image generation on the COCO dataset demonstrates that the Halton scheduler outperforms the Confidence scheduler quantitatively by reducing the FID and qualitatively by generating more diverse and more detailed images. Our code is publicly available on [link redacted]."
    },
    {
        "title": "Process-Driven Autoformalization in Lean 4",
        "link_suffix": "/forum?id=k8KsI84Ds7",
        "link": "https://openreview.net/forum?id=k8KsI84Ds7",
        "pdf_link": "https://openreview.net/pdf?id=k8KsI84Ds7",
        "keywords": "Large Language Models, Autoformalization, Lean 4, Formal Math, Process Supervision, Formal Reasoning, Mathematical Reasoning, AI for Math, Automated Theorem Proving",
        "abstract": "Autoformalization, the conversion of natural language mathematics into formal languages, offers significant potential for advancing mathematical reasoning. However, existing efforts are limited to formal languages with substantial online corpora and struggle to keep pace with rapidly evolving languages like Lean 4. To bridge this gap, we propose a large-scale dataset \\textbf{Form}alization for \\textbf{L}ean~\\textbf{4} (\\textbf{\\dataset}) designed to comprehensively evaluate the autoformalization capabilities of large language models (LLMs), encompassing both statements and proofs in natural and formal languages. Additionally, we introduce the\n\\textbf{P}rocess-\\textbf{D}riven \\textbf{A}utoformalization (\\textbf{\\method}) framework\nthat leverages the precise feedback from Lean 4 compilers to enhance autoformalization. \nExtensive experiments demonstrate that \\method improves autoformalization, enabling higher compiler accuracy and human-evaluation scores using less filtered training data. \nMoreover, when fine-tuned with data containing detailed process information, \\method exhibits enhanced data utilization, resulting in more substantial improvements in autoformalization for Lean 4."
    },
    {
        "title": "LESS IS MORE: HIGH-VALUE DATA SELECTION FOR VISUAL INSTRUCTION TUNING",
        "link_suffix": "/forum?id=BydkbNH0gj",
        "link": "https://openreview.net/forum?id=BydkbNH0gj",
        "pdf_link": "https://openreview.net/pdf?id=BydkbNH0gj",
        "keywords": "Visual Instruction Tuning, Data Selection",
        "abstract": "Visual instruction tuning is the key to building large vision language mod-\nels (LVLMs), which can greatly improve the task generalization and solving capa-\nbilities by learning a mixture of instruction data from diverse visual tasks. Previ-\nous work mostly collects multiple existing visual instruction datasets via heuristic\nways for training (even more than a million instructions), which may introduce\ndata redundancy and enlarge the training cost. To investigate this issue, we con-\nduct a series of empirical studies, which reveal a significant redundancy within the\nvisual instruction datasets, and show that greatly reducing the amount of instruc-\ntions from several tasks even do not affect the performance. Based on the findings,\nwe propose a high-value data selection approach $\\textbf{TIVE}$, to eliminate redundancy\nwithin the visual instruction data and reduce the training cost. In TIVE, we first\nestimate the instance influence score on its corresponding task, and the task dif-\nficulty score, based on the gradient-based influence functions. Then, we leverage\nthe two kinds of scores to determine the task proportion within the selected visual\ninstruction subset, and select high-value instances for each task, respectively. Ex-\nperiments on various LVLMs show that our approach using only about 15% data\ncan achieve comparable average performance to the full-data fine-tuned model\nacross eight benchmarks, even surpassing it on four of the benchmarks. Our code\nand data will be publicly released."
    },
    {
        "title": "SemanticMIM: Marring Masked Image Modeling with Semantics Compression for General Visual Representation",
        "link_suffix": "/forum?id=IiwyThOFXL",
        "link": "https://openreview.net/forum?id=IiwyThOFXL",
        "pdf_link": "https://openreview.net/pdf?id=IiwyThOFXL",
        "keywords": "Self-supervised learning, Masked image modeling",
        "abstract": "This paper represents a neat yet effective framework, named SemanticMIM, to integrate the advantages of masked image modeling (MIM) and contrastive learning (CL) for general visual representation. We conduct a thorough comparative analysis between CL and MIM, revealing that their complementary advantages fundamentally stem from two distinct phases, i.e., compression and reconstruction. Specifically, SemanticMIM leverages a proxy architecture that customizes interaction between image and mask tokens, bridging these two phases to achieve general visual representation with the property of abundant semantic and positional awareness. Through extensive qualitative and quantitative evaluations, we demonstrate that SemanticMIM effectively amalgamates the benefits of CL and MIM, leading to significant enhancement of performance and feature linear separability. SemanticMIM also offers notable interpretability through attention response visualization."
    },
    {
        "title": "MaskTab: Masked Tabular Data Modeling for Learning with Missing Features",
        "link_suffix": "/forum?id=Exkm5OReTY",
        "link": "https://openreview.net/forum?id=Exkm5OReTY",
        "pdf_link": "https://openreview.net/pdf?id=Exkm5OReTY",
        "keywords": "tabular data prediction, masked learning, missing features",
        "abstract": "Tabular machine learning has garnered increasing attention due to its practical value. Unlike the complete and standardized data often assumed in academia, tabular data primarily originates from industrial contexts and usually faces the issue of incomplete data samples, i.e., some features of a sample may be unpredictably missing. In this work, we introduce MaskTab, a masked tabular data modeling framework designed to facilitate model learning despite missing features. Instead of pursuing to accurately restore missing features like existing imputation methods, we jointly approach missing feature modeling and downstream tasks (e.g., classification) with a unified objective. Concretely, we propose to randomly drop out some solid features during training, equipped with a missing-related masked attention mechanism, to help the model rely more on trustworthy features when making decisions. Experiments on the very recent industry-grade benchmark, TabReD, suggest that our method surpasses the second DNN-based competitor by a clear margin, demonstrating its effectiveness and robustness in real-world scenarios. We will release the code and the model to facilitate reproduction."
    },
    {
        "title": "Injecting Vision Language into Autoregressive Image Generation",
        "link_suffix": "/forum?id=K5wFwpaUvK",
        "link": "https://openreview.net/forum?id=K5wFwpaUvK",
        "pdf_link": "https://openreview.net/pdf?id=K5wFwpaUvK",
        "keywords": "autoregressive models, image generation, text-to-image, customized image generation",
        "abstract": "Autoregressive (AR) models have become central to modern foundation models like large language models (LLMs) and visual-language models (VLMs). Recently, AR-based approaches have extended into text-to-image generation. Although these text-to-image AR models have been trained for visual-language token interaction, they often struggle when conditioned on visual inputs. Focusing on this drawback, in this paper, we are curious about one question: how can we inject vision information to a pre-trained AR model to ensure its output reflects visual conditions? We answer this question with a simple yet effective solution termed InjectAR. Our key insight is that, while a pre-trained AR model cannot handle visual inputs directly, its inherent capability for visual-language interaction can indeed support visual feature extraction. Consequently, with only a few newly introduced parameters and minimal training, a pre-trained AR generation model can successfully accommodate both text and image conditions and produce visually appealing results. To manage the relationship between textual and visual inputs, we reinforce InjectAR with a hierarchical attention mechanism, which subdivides the attention scores for textual tokens into their corresponding visual components, preventing either modality from dominating the output. As the first AR model with this capability, extensive experiments show that InjectAR achieves performance on par with, or even surpasses, state-of-the-art diffusion models. Moreover, unlike diffusion models, once trained, our method has the potential for flexible control over the positions of visual objects. Our codes will be available."
    },
    {
        "title": "PredFormer: Transformers Are Effective Spatial-Temporal Predictive Learners",
        "link_suffix": "/forum?id=avNVrQ8D2v",
        "link": "https://openreview.net/forum?id=avNVrQ8D2v",
        "pdf_link": "https://openreview.net/pdf?id=avNVrQ8D2v",
        "keywords": "Video Prediction, Spatio-temporal Prective Learning, Spatio-temporal Forecasting",
        "abstract": "Spatiotemporal predictive learning methods generally fall into two categories: recurrent-based approaches, which face challenges in parallelization and performance, and recurrent-free methods, which employ convolutional neural networks (CNNs) as encoder-decoder architectures. These methods benefit from strong inductive biases but often at the expense of scalability and generalization. This paper proposes PredFormer, a pure transformer-based framework for spatiotemporal predictive learning. Motivated by the Vision Transformers (ViT) design, PredFormer leverages carefully designed Gated Transformer blocks, following a comprehensive analysis of 3D attention mechanisms, including full-, factorized-, and interleaved- spatial-temporal attention. With its recurrent-free, transformer-based design, PredFormer is both simple and efficient, significantly outperforming previous methods by large margins. Extensive experiments on synthetic and real-world datasets demonstrate that PredFormer achieves state-of-the-art performance. On Moving MNIST, PredFormer achieves a 51.3% reduction in MSE relative to SimVP. For TaxiBJ, the model decreases MSE by 33.1% and boosts FPS from 533 to 2364. Additionally, on WeatherBench, it reduces MSE by 11.1% while enhancing FPS from 196 to 404. These performance gains in both accuracy and efficiency demonstrate PredFormer's potential for real-world applications. The source code and trained models will be made available to the public."
    },
    {
        "title": "MonST3R: A Simple Approach for Estimating Geometry in the Presence of Motion",
        "link_suffix": "/forum?id=lJpqxFgWCM",
        "link": "https://openreview.net/forum?id=lJpqxFgWCM",
        "pdf_link": "https://openreview.net/pdf?id=lJpqxFgWCM",
        "keywords": "3D computer vision, structure from motion, depth estimation",
        "abstract": "Estimating geometry from dynamic scenes, where objects move and deform over time, remains a core challenge in computer vision. Current approaches often rely on multi-stage pipelines or global optimizations that decompose the problem into subtasks, like depth and flow, leading to complex systems prone to errors. In this paper, we present Motion DuSt3R (MonST3R), a novel geometry-first approach\nthat directly estimates per-timestep geometry from dynamic scenes. Our key insight is that by simply estimating a pointmap for each timestep, we can effectively adapt DUSt3R\u2019s representation, previously only used for static scenes, to dynamic scenes. However, this approach presents a significant challenge: the scarcity of suitable training data, namely dynamic, posed videos with depth labels. Despite this, we show that by posing the problem as a fine-tuning task, identifying several suitable datasets, and strategically training the model on this limited data, we can surprisingly enable the model to handle dynamics, even without an explicit motion representation. Based on this, we introduce new optimizations for several downstream video-specific tasks and demonstrate strong performance on video depth and camera pose estimation, outperforming prior work in terms of robustness and efficiency. Moreover, MonST3R shows promising results for primarily feed-forward 4D reconstruction. Interactive 4D results are available at:https://monst3r-paper.github.io/"
    },
    {
        "title": "Multidimensional Trajectory Optimization for Flow and Diffusion",
        "link_suffix": "/forum?id=oHbmiaeyUL",
        "link": "https://openreview.net/forum?id=oHbmiaeyUL",
        "pdf_link": "https://openreview.net/pdf?id=oHbmiaeyUL",
        "keywords": "Multidimensional Coefficient, Multidimensional Trajectory Optimization, Flow, Diffusion, Simulation Dynamics, Adversarial Training",
        "abstract": "In flow and diffusion-based generative modeling, conventional methods rely on unidimensional coefficients for the trajectory of differential equations. In this work, we first introduce a multidimensional coefficient that generalizes the conventional unidimensional coefficient into multiple dimensions. We also propose a new multidimensional trajectory optimization, which suggests a novel trajectory optimality determined by the final transportation quality rather than predefined properties like straightness. Our approach employs simulation dynamics and adversarial training to optimize these inference trajectories. To empirically validate our method, we conduct experiments on various generative models, including EDM and Stochastic Interpolant, across multiple datasets such as 2D synthetic datasets, CIFAR-10, FFHQ, and AFHQv2. Remarkably, inference using our optimized multidimensional trajectory achieves significant performance improvements with low NFE (e.g., 5), achieving state-of-the-art results in CIFAR-10 conditional generation. The introduction of multidimensional trajectory optimization enhances model efficiency and opens new avenues for exploration in flow and diffusion-based generative modeling."
    },
    {
        "title": "GSLoc: Efficient Camera Pose Refinement via 3D Gaussian Splatting",
        "link_suffix": "/forum?id=mP7uV59iJM",
        "link": "https://openreview.net/forum?id=mP7uV59iJM",
        "pdf_link": "https://openreview.net/pdf?id=mP7uV59iJM",
        "keywords": "Visual Localization, Camera Pose Estimation, 3D Gaussian Splatting",
        "abstract": "We leverage 3D Gaussian Splatting (3DGS) as a scene representation and propose a novel test-time camera pose refinement framework, GSLoc. This framework enhances the localization accuracy of state-of-the-art absolute pose regression and scene coordinate regression methods. The 3DGS model renders high-quality synthetic images and depth maps to facilitate the establishment of 2D-3D correspondences. GSLoc obviates the need for training feature extractors or descriptors by operating directly on RGB images, utilizing the 3D foundation model, MASt3R, for precise 2D matching. To improve the robustness of our model in challenging outdoor environments, we incorporate an exposure-adaptive module within the 3DGS framework. Consequently, GSLoc enables efficient one-shot pose refinement given a single RGB query and a coarse initial pose estimation. Our proposed approach surpasses leading NeRF-based optimization methods in both accuracy and runtime across indoor and outdoor visual localization benchmarks, achieving new state-of-the-art accuracy on two indoor datasets."
    },
    {
        "title": "Black Sheep in the Herd: Playing with Spuriously Correlated Attributes for Vision-Language Recognition",
        "link_suffix": "/forum?id=g1fkhbhHjL",
        "link": "https://openreview.net/forum?id=g1fkhbhHjL",
        "pdf_link": "https://openreview.net/pdf?id=g1fkhbhHjL",
        "keywords": "Few-shot Adaptation, Prompt Learning, Vision-Language Models",
        "abstract": "Few-shot adaptation for Vision-Language Models (VLMs) presents a dilemma: balancing in-distribution accuracy with out-of-distribution generalization. Recent research has utilized low-level concepts such as visual attributes to enhance generalization. However, this study reveals that VLMs overly rely on a small subset of attributes on decision-making, which co-occur with the category but are not inherently part of it, termed spuriously correlated attributes. This biased nature of VLMs results in poor generalization. To address this, 1) we first propose Spurious Attribute Probing (SAP), identifying and filtering out these problematic attributes to significantly enhance the generalization of existing attribute-based methods; 2) We introduce Spurious Attribute Shielding (SAS), a plug-and-play module that mitigates the influence of these attributes on prediction, seamlessly integrating into various Parameter-Efficient Fine-Tuning (PEFT) methods. In experiments, SAP and SAS significantly enhance accuracy on distribution shifts across 11 datasets and 3 generalization tasks without compromising downstream performance, establishing a new state-of-the-art benchmark."
    },
    {
        "title": "Democratic Training Against Universal Adversarial Perturbations",
        "link_suffix": "/forum?id=4M0BRyGMnJ",
        "link": "https://openreview.net/forum?id=4M0BRyGMnJ",
        "pdf_link": "https://openreview.net/pdf?id=4M0BRyGMnJ",
        "keywords": "Neural network adversarial attack; Universal adversarial perturbation; Adversarial attack defense",
        "abstract": "Despite their advances and success, real-world deep neural networks are known to be vulnerable to adversarial attacks. Universal adversarial perturbation, an input-agnostic attack, poses a serious threat for them to be deployed in security-sensitive systems. In this case, a single universal adversarial perturbation deceives the model on a range of clean inputs without requiring input-specific optimization, which makes it particularly threatening. In this work, we observe that universal adversarial perturbations usually lead to abnormal entropy spectrum in hidden layers, which suggests that the prediction is dominated by a small number of ``feature'' in such cases (rather than democratically by many features). Inspired by this, we propose an efficient yet effective defense method for mitigating UAPs called Democratic Training by performing entropy-based model enhancement to suppress the effect of the universal adversarial perturbations in a given model. \\emph{Democratic Training} is evaluated with 6 neural networks trained on 4 benchmark datasets and 4 types of state-of-the-art universal adversarial attack methods. The results show that it effectively reduces the attack success rate, improves model robustness and preserves the model accuracy on clean samples."
    }
]
[
    {
        "title": "Overcoming Knowledge Barriers: Online Imitation Learning from Visual Observation with Pretrained World Models",
        "link_suffix": "/forum?id=EbOhZyxIzQ",
        "link": "https://openreview.net/forum?id=EbOhZyxIzQ",
        "pdf_link": "https://openreview.net/pdf?id=EbOhZyxIzQ",
        "keywords": "World Models, Foundation Models, Pretraining, Imitation Learning from Observation, Decision-making",
        "abstract": "Pretraining and finetuning models has become increasingly popular in decision-making. But there are still serious impediments in Imitation Learning from Observation (ILfO) with pretrained models. This study identifies two primary obstacles: the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB). The EKB emerges due to the pretrained models' limitations in handling novel observations, which leads to inaccurate action inference. Conversely, the DKB stems from the reliance on limited demonstration datasets, restricting the model's adaptability across diverse scenarios. \nWe propose separate solutions to overcome each barrier and apply them to Action Inference by Maximising Evidence (AIME), a state-of-the-art algorithm.\nThis new algorithm, AIME-NoB, integrates online interactions and a data-driven regulariser to mitigate the EKB. Additionally, it uses a surrogate reward function to broaden the policy's supported states, addressing the DKB. Our experiments on vision-based control tasks from the DeepMind Control Suite and MetaWorld benchmarks show that AIME-NoB significantly improves sample efficiency and converged performance, presenting a robust framework for overcoming the challenges in ILfO with pretrained models."
    },
    {
        "title": "Knockout: A simple way to handle missing inputs",
        "link_suffix": "/forum?id=xof0bvftR1",
        "link": "https://openreview.net/forum?id=xof0bvftR1",
        "pdf_link": "https://openreview.net/pdf?id=xof0bvftR1",
        "keywords": "Applied Machine Learning, Marginalization, Missing inputs, Multi-modality",
        "abstract": "Deep learning models can extract predictive and actionable information from complex inputs. The richer the inputs, the better these models usually perform. However, models that leverage rich inputs (e.g., multi-modality) can be difficult to deploy widely, because some inputs may be missing at inference. Current popular solutions to this problem include marginalization, imputation, and training multiple models. Marginalization can obtain calibrated predictions but it is computationally costly and therefore only feasible for low dimensional inputs. Imputation may result in inaccurate predictions because it employs point estimates for missing variables and does not work well for high dimensional inputs (e.g., images). Training multiple models whereby each model takes different subsets of inputs can work well but requires knowing missing input patterns in advance. Furthermore, training and retaining multiple models can be costly. We propose an efficient way to learn both the conditional distribution using full inputs and the marginal distributions. Our method, Knockout, randomly replaces input features with appropriate placeholder values during training. We provide a theoretical justification of Knockout and show that it can be viewed as an implicit marginalization strategy. We evaluate Knockout in a wide range of simulations and real-world datasets and show that it can offer strong empirical performance."
    },
    {
        "title": "Familiarity-Aware Evidence Compression for Retrieval-Augmented Generation",
        "link_suffix": "/forum?id=Zd8ODMYMBZ",
        "link": "https://openreview.net/forum?id=Zd8ODMYMBZ",
        "pdf_link": "https://openreview.net/pdf?id=Zd8ODMYMBZ",
        "keywords": "Evidence Compression, Retrieval Augmented Generation, Parametric and Non-parametric Knowledge",
        "abstract": "Retrieval-augmented generation (RAG) improves large language models (LMs) by incorporating non-parametric knowledge through evidence retrieved from external sources. However, it often struggles to cope with inconsistent and irrelevant information that can distract the LM from its tasks, especially when multiple evidence pieces are required. While compressing the retrieved evidence with a compression model aims to address this issue, the compressed evidence may still be unfamiliar to the target model used for downstream tasks, potentially failing to utilize the evidence effectively. We propose FaviComp (Familiarity-aware Evidence Compression), a novel training-free evidence compression technique that makes retrieved evidence more familiar to the target model, while seamlessly integrating parametric knowledge from the model. Specifically, FaviComp proactively composes the compressed evidence in a way to lower the perplexity of the target model by combining decoding probabilities from both the compression model and the target model to generate context that is more familiar to the target model. This approach balances the integration of parametric and non-parametric knowledge, which is especially helpful in complex tasks where the retrieved evidence set may not contain all the necessary information. Experimental results show that FaviComp consistently outperforms most recent evidence compression baselines across multiple open-domain QA datasets, improving accuracy by up to 23.91% while achieving high compression rates. Additionally, we demonstrate the effective integration of both parametric and non-parametric knowledge during evidence compression."
    },
    {
        "title": "Robustness Inspired Graph Backdoor Defense",
        "link_suffix": "/forum?id=trKNi4IUiP",
        "link": "https://openreview.net/forum?id=trKNi4IUiP",
        "pdf_link": "https://openreview.net/pdf?id=trKNi4IUiP",
        "keywords": "Backdoor Defense, Graph Neural Network",
        "abstract": "Graph Neural Networks (GNNs) have achieved promising results in tasks such as node classification and graph classification. However, recent studies reveal that GNNs are vulnerable to backdoor attacks, posing a significant threat to their real-world adoption. Despite initial efforts to defend against specific graph backdoor attacks, there is no work on defending against various types of backdoor attacks where generated triggers have different properties. Hence, we first empirically verify that prediction variance under edge dropping is a crucial indicator for identifying poisoned nodes. With this observation, we propose using random edge dropping to detect backdoors and theoretically show that it can efficiently distinguish poisoned nodes from clean ones. Furthermore, we introduce a novel robust training strategy to efficiently counteract the impact of the triggers. Extensive experiments on real-world datasets show that our framework can effectively identify poisoned nodes, significantly degrade the attack success rate, and maintain clean accuracy when defending against various types of graph backdoor attacks with different properties. Our code is available at:https://anonymous.4open.science/r/RIGBD-A670."
    },
    {
        "title": "Counterfactual Explanations for 3D Point-Cloud Classifiers",
        "link_suffix": "/forum?id=XQED8Nk9mu",
        "link": "https://openreview.net/forum?id=XQED8Nk9mu",
        "pdf_link": "https://openreview.net/pdf?id=XQED8Nk9mu",
        "keywords": "explainability, counterfactual, 3D, point-cloud",
        "abstract": "Explainable AI (XAI) seeks to tackle the opacity of deep neural network decisions. Moving beyond the conventional focus on 2D imagery, our research provides the first method to provide Counterfactual Explanations (CEs) for 3D point cloud classifiers. Specifically, we introduce two strategies for 3D CEs using a diffusion model to generate CEs that maintain both semantic consistency and data fidelity in 3D contexts. To this end, we devise novel losses and constraints to boost the realism and practicality of counterfactual instances. Furthermore, we establish a new benchmark with evaluation metrics designed specifically for 3D point clouds allowing future methods to be assessed using it. Altogether, our contributions bridge a key gap in the field of explainability, steering towards more transparent and fair AI methodologies."
    },
    {
        "title": "Risk Aware Negative Sampling in Link Prediction",
        "link_suffix": "/forum?id=dfdrb2sZUw",
        "link": "https://openreview.net/forum?id=dfdrb2sZUw",
        "pdf_link": "https://openreview.net/pdf?id=dfdrb2sZUw",
        "keywords": "graph neural networks, link prediction, negative sampling",
        "abstract": "It is commonly believed that Message Passing Neural Networks (MPNNs) struggle in link prediction settings due to limitations in their expressive power. Recent work has focused on developing more expressive model classes, which are capable of learning link representations through techniques such as labeling tricks, the inclusion of structural features, or the use of subgraph methods. These approaches have yielded significant performance improvements across a range of benchmark datasets. However, an interesting question remains: have we fully wrung out the performance by optimizing the other aspects of the training process? In this work, we present results that indicate that significant amounts of model performance have been left on the table by the use of easy negative-samples during training. We theoretically explore the generalization gap and excess risk to quantify the performance loss caused by easy negatives. Motivated by this analysis, we introduce Risk Aware Negative Sampling in Link Prediction (RANS), which efficiently performs dynamic hard-negative-mining. Empirical results show that a simple GCN augmented by RANS realizes between 20% and 50% improvements in predictive accuracy when compared with the same model trained with standard negative samples."
    },
    {
        "title": "Classroom-Inspired Multi-Mentor Distillation with Adaptive Learning Strategies",
        "link_suffix": "/forum?id=8xpR7IXcE8",
        "link": "https://openreview.net/forum?id=8xpR7IXcE8",
        "pdf_link": "https://openreview.net/pdf?id=8xpR7IXcE8",
        "keywords": "Multi-Mentor Knowledge Distillation, Adaptive Learning Strategies, Dynamic Mentor Selection",
        "abstract": "We proposeClassroomKD, a novel multi-mentor knowledge distillation framework inspired by classroom environments to enhance knowledge transfer between student and multiple mentors. Unlike traditional methods that rely on fixed mentor-student relationships, our framework dynamically selects and adapts the teaching strategies of diverse mentors based on their effectiveness for each data sample. ClassroomKD comprises two main modules: theKnowledge Filtering (KF)Module and theMentoringModule. The KF Module dynamically ranks mentors based on their performance for each input, activating only high-quality mentors to minimize error accumulation and prevent information loss. The Mentoring Module adjusts the distillation strategy by tuning each mentor's influence according to the performance gap between the student and mentors, effectively modulating the learning pace. Extensive experiments on image classification (CIFAR-100 and ImageNet) and 2D human pose estimation (COCO Keypoints and MPII Human Pose) demonstrate that ClassroomKD outperforms existing knowledge distillation methods for different network architectures. Our results highlight that a dynamic and adaptive approach to mentor selection and guidance leads to more effective knowledge transfer, paving the way for enhanced model performance through distillation."
    },
    {
        "title": "Generalization in VAE and Diffusion Models: A Unified Information-Theoretic Analysis",
        "link_suffix": "/forum?id=NGB6YNnO5o",
        "link": "https://openreview.net/forum?id=NGB6YNnO5o",
        "pdf_link": "https://openreview.net/pdf?id=NGB6YNnO5o",
        "keywords": "Generalization bounds; information theory; generative models; VAE; diffusion models;",
        "abstract": "Despite the empirical success of Diffusion Models (DMs) and Variational Autoencoders (VAEs), their generalization performance remains theoretically underexplored, particularly lacking a full consideration of the shared encoder-generator structure. Leveraging recent information-theoretic tools, we propose a unified theoretical framework that guarantees the generalization of both the encoder and generator by treating them as randomized mappings. This framework further enables (1) a refined analysis for VAEs, accounting for the generator's generalization, which was previously overlooked; (2) illustrating an explicit trade-off in generalization terms for DMs that depends on the diffusion time $T$; and (3) providing estimable bounds for DMs based solely on the training data, allowing the selection of the optimal $T$ and the integration of such bounds into the optimization process to improve model performance. Empirical results on both synthetic and real datasets illustrate the validity of the proposed theory."
    },
    {
        "title": "OGBench: Benchmarking Offline Goal-Conditioned RL",
        "link_suffix": "/forum?id=M992mjgKzI",
        "link": "https://openreview.net/forum?id=M992mjgKzI",
        "pdf_link": "https://openreview.net/pdf?id=M992mjgKzI",
        "keywords": "reinforcement learning",
        "abstract": "Offline goal-conditioned reinforcement learning (GCRL) is a major problem in reinforcement learning (RL) because it provides a simple, unsupervised, and domain-agnostic way to acquire diverse behaviors and representations from unlabeled data without rewards. Despite the importance of this setting, we lack a standard benchmark that can systematically evaluate the capabilities of offline GCRL algorithms. In this work, we propose OGBench, a new, high-quality benchmark for algorithms research in offline goal-conditioned RL. OGBench consists of 7 types of environments, 59 datasets, and reference implementations of 6 representative offline GCRL algorithms. We have designed these challenging and realistic environments and datasets to directly probe different capabilities of algorithms, such as stitching, long-horizon reasoning, and the ability to handle high-dimensional inputs and stochasticity. While representative algorithms may rank similarly on prior benchmarks, our experiments reveal stark strengths and weaknesses in these different capabilities, providing a strong foundation for building new algorithms. Videos:https://ogbenchauthors.github.io/ogbench-anon/"
    },
    {
        "title": "Representational Knowledge Distillation Across Wearable Biosignals",
        "link_suffix": "/forum?id=wgHJDHW65K",
        "link": "https://openreview.net/forum?id=wgHJDHW65K",
        "pdf_link": "https://openreview.net/pdf?id=wgHJDHW65K",
        "keywords": "Health, Foundation models, Knowledge distillation, Unsupervised learning, Self-supervised learning, Biosignals, Wearable devices",
        "abstract": "Modern wearable devices can conveniently and continuously record various biosignals in the many different environments of daily living, ultimately enabling a rich view of individual health. However, not all biosignals are the same: high-fidelity measurements, such as photoplethysmography (PPG), contain more physiological information, but require optical sensors with a high power footprint. In a resource-constrained setting, such high-fidelity biosignals may be unavailable. Alternatively, a lower-fidelity biosignal, such as those from an accelerometer, has a significantly smaller power footprint and is available in almost any wearable device. Here, we demonstrate that we can distill representational knowledge across biosignals with different levels of fidelity, i.e., from PPG to accelerometer, using 20 million minutes of unlabeled data collected from ~172K participants in the Apple Heart and Movement Study under informed consent. Our knowledge distillation framework does not require labels; we pre-train PPG encoders via self-supervised learning, and then distill the representational knowledge from the PPG encoders to accelerometer encoders. We first demonstrate strong cross-modal alignment on unseen data, e.g., 99.2% top-1 accuracy for retrieving PPG embeddings from accelerometer embeddings. We show that distilled accelerometer encoders have significantly more informative representations compared to self-supervised or supervised encoders trained on accelerometer data for downstream targets, observed by at least 23%-49% improved performance for predicting heart rate and heart rate variability. We also demonstrate that our framework can be applied to different encoder architectures with different pre-training strategies of the strong encoder, and can be used to simultaneously do cross-modality distillation and model compression. Additionally, we perform various ablations for augmentations, hyperparameters and multi-modal training. We believe our proposed representational knowledge distillation framework may unlock new opportunities for developing digital biomarkers from any wearable device with lower-fidelity biosignals, and help individuals track their health more frequently and conveniently."
    },
    {
        "title": "Burning RED: Unlocking Subtask-Driven Reinforcement Learning and Risk-Awareness in Average-Reward Markov Decision Processes",
        "link_suffix": "/forum?id=5y3QbuK6HD",
        "link": "https://openreview.net/forum?id=5y3QbuK6HD",
        "pdf_link": "https://openreview.net/pdf?id=5y3QbuK6HD",
        "keywords": "Reinforcement Learning, Average Reward Reinforcement Learning, Risk-Sensitive Reinforcement Learning, Markov Decision Processes, CVaR",
        "abstract": "Average-reward Markov decision processes (MDPs) provide a foundational framework for sequential decision-making under uncertainty. However, average-reward MDPs have remained largely unexplored in reinforcement learning (RL) settings, with the majority of RL-based efforts having been allocated to episodic and discounted MDPs. In this work, we study a unique structural property of average-reward MDPs and utilize it to introduce Reward-Extended Differential (or RED) reinforcement learning: a novel RL framework that can be used to effectively and efficiently solve various subtasks simultaneously in the average-reward setting. We introduce a family of RED learning algorithms for prediction and control, including proven-convergent algorithms for the tabular case. We then showcase the power of these algorithms by demonstrating how they can be used to learn a policy that optimizes, for the first time, the well-known conditional value-at-risk (CVaR) risk measure in a fully-online manner, without the use of an explicit bi-level optimization scheme or an augmented state-space."
    },
    {
        "title": "Optimal Causal Representations and the Causal Information Bottleneck",
        "link_suffix": "/forum?id=qac43AwuL9",
        "link": "https://openreview.net/forum?id=qac43AwuL9",
        "pdf_link": "https://openreview.net/pdf?id=qac43AwuL9",
        "keywords": "causal representation learning, causal inference, information bottleneck, information theory",
        "abstract": "To effectively study complex causal systems, it is often useful to construct representations that simplify parts of the system by discarding irrelevant details while preserving key features.\nThe Information Bottleneck (IB) method is a widely used approach in representation learning that compresses random variables while retaining information about a target variable.\nTraditional methods like IB are purely statistical and ignore underlying causal structures, making them ill-suited for causal tasks.\nWe propose the Causal Information Bottleneck (CIB), a causal extension of the IB, which compresses a set of chosen variables while maintaining causal control over a target variable.\nThis method produces representations which are causally interpretable, and which can be used when reasoning about interventions.\nWe present experimental results demonstrating that the learned representations accurately capture causality as intended."
    },
    {
        "title": "Stabilizing Reinforcement Learning in Differentiable Multiphysics Simulation",
        "link_suffix": "/forum?id=DRiLWb8bJg",
        "link": "https://openreview.net/forum?id=DRiLWb8bJg",
        "pdf_link": "https://openreview.net/pdf?id=DRiLWb8bJg",
        "keywords": "reinforcement learning, differentiable simulation",
        "abstract": "Recent advances in GPU-based parallel simulation have enabled practitioners\nto collect large amounts of data and train complex control policies using deep\nreinforcement learning (RL), on commodity GPUs. However, such successes for\nRL in robotics have been limited to tasks sufficiently simulated by fast rigid-body\ndynamics. Simulation techniques for soft bodies are comparatively several orders\nof magnitude slower, thereby limiting the use of RL due to sample complexity\nrequirements. To address this challenge, this paper presents both a novel RL\nalgorithm and a simulation platform to enable scaling RL on tasks involving\nrigid bodies and deformables. We introduce Soft Analytic Policy Optimization\n(SAPO), a maximum entropy first-order model-based actor-critic RL algorithm\nwhich uses first-order analytic gradients from differentiable simulation to train a\nstochastic actor to maximize expected return and entropy. Alongside our approach,\nwe develop Rewarped, a parallel differentiable multiphysics simulation platform\nthat supports simulating various materials beyond rigid bodies. We re-implement\nchallenging manipulation & locomotion tasks in Rewarped, and show that SAPO\noutperforms baselines over a range of tasks that involve interaction between rigid\nbodies, articulations, and deformables."
    },
    {
        "title": "Scale-Invariant Continuous Implicit Neural Representations For Object Counting",
        "link_suffix": "/forum?id=9swCsnoNX4",
        "link": "https://openreview.net/forum?id=9swCsnoNX4",
        "pdf_link": "https://openreview.net/pdf?id=9swCsnoNX4",
        "keywords": "scale invariance, implicit neural representation, object counting",
        "abstract": "Many existing object counting methods rely on density map estimation (DME) using convolutional neural networks (CNNs) on discrete grid image representations. However, these methods struggle with large variations in object size or input image resolution, typically due to different imaging conditions and perspective effects. Furthermore, discrete grid representations of density maps result in information loss with blurred or vanished details for low-resolution inputs.\nTo overcome these limitations, we design Scale-Invariant Implicit neural representations for counting (SI-INR) to map arbitrary-scale input signals into a continuous function space, where each function produces density values over continuous spatial coordinates. SI-INR achieves robust counting performances with respect to changing object sizes, outperforming existing methods on commonly used diverse datasets with different target objects."
    },
    {
        "title": "From Attention to Prediction Maps: Per-Class Gradient-Free Transformer Explanations",
        "link_suffix": "/forum?id=dVLrqe2a7c",
        "link": "https://openreview.net/forum?id=dVLrqe2a7c",
        "pdf_link": "https://openreview.net/pdf?id=dVLrqe2a7c",
        "keywords": "explainable ai, vision transformer",
        "abstract": "The Vision Transformer (ViT) has become a standard model architecture in computer vision, especially for classification tasks. As such, explaining ViT predictions has attracted significant research efforts in recent years. Many methods rely on attention maps, which highlight \\emph{where} in the image the network directs its attention. In this paper, we introduce Prediction~Maps -- a novel explanation method that complements attention maps by revealing \\emph{what} the network sees. Prediction maps visualize how each patch token within a given layer is associated with each possible class. This is done by utilizing the classification head at the output of the network, originally trained to be fed with the class token at the last layer. Specifically, to obtain the prediction map of a particular layer, we apply the classification head to every patch token within that layer. We show that prediction maps provide complementary information to attention maps and illustrate that combining them leads to state-of-the-art explainability performance. Furthermore, since our proposed method is neither gradient- nor perturbation-based, it offers superior computational and memory efficiency compared to competing methods."
    },
    {
        "title": "Multiscale Training of Convolutional Neural Networks",
        "link_suffix": "/forum?id=n0YCAMVh8b",
        "link": "https://openreview.net/forum?id=n0YCAMVh8b",
        "pdf_link": "https://openreview.net/pdf?id=n0YCAMVh8b",
        "keywords": "Multilevel Stochastic Gradient Descent, Multiscale Training, Mesh Free Convolutions",
        "abstract": "Convolutional Neural Networks (CNNs) are the backbone of many deep learning methods, but optimizing them remains computationally expensive. To address this, we explore multiscale training frameworks and mathematically identify key challenges, particularly when dealing with noisy inputs. Our analysis reveals that in the presence of noise, the gradient of standard CNNs in multiscale training may fail to converge as the mesh-size approaches to $0$, undermining the optimization process. This insight drives the development of Mesh-Free Convolutions (MFCs), which are independent of input scale and avoid the pitfalls of traditional convolution kernels. We demonstrate that MFCs, with their robust gradient behavior, ensure convergence even with noisy inputs, enabling more efficient neural network optimization in multiscale settings. To validate their generality and effectiveness, we show that MFCs can seamlessly replace standard convolutional layers across diverse architectures and benchmarks, delivering substantial computational speedups without sacrificing performance."
    },
    {
        "title": "DOPL: Direct Online Preference Learning for Restless Bandits with Preference Feedback",
        "link_suffix": "/forum?id=2iYVBqRHK4",
        "link": "https://openreview.net/forum?id=2iYVBqRHK4",
        "pdf_link": "https://openreview.net/pdf?id=2iYVBqRHK4",
        "keywords": "Restless Multi-Armed Bandits, Preference Feedback, Online Preference Learning",
        "abstract": "Restless multi-armed bandits (RMAB) has been widely used to model constrained sequential decision making problems, where the state of each restless arm evolves according to a Markov chain and each state transition generates a scalar reward. However, the success of RMAB crucially relies on the availability and quality of reward signals. Unfortunately, specifying an exact reward function in practice can be challenging and even infeasible. In this paper, we introduce Pref-RMAB,  a new RMAB model in the presence of preference signals, where the decision maker only observes pairwise preference feedback rather than scalar reward from the activated arms at each decision epoch. Preference feedback, however, arguably contains less information than the scalar reward, which makes Pref-RMAB seemingly more difficult. To address this challenge, we present a direct online preference learning (DOPL) algorithm for Pref-RMAB to efficiently explore the unknown environments, adaptively collect preference data in an online manner, and directly leverage the preference feedback for decision-makings. We prove that DOPL yields a sublinear regret. To our best knowledge, this is the first algorithm to ensure $\\tilde{\\mathcal{O}}(\\sqrt{T\\ln T})$ regret for RMAB with preference feedback. Experimental results further demonstrate the effectiveness of DOPL."
    },
    {
        "title": "Weak-to-Strong Jailbreaking on Large Language Models",
        "link_suffix": "/forum?id=Nazzz5GJ4g",
        "link": "https://openreview.net/forum?id=Nazzz5GJ4g",
        "pdf_link": "https://openreview.net/pdf?id=Nazzz5GJ4g",
        "keywords": "LLM, AI safety, Jailbreaking",
        "abstract": "Large language models (LLMs) are vulnerable to jailbreak attacks -- resulting in harmful, unethical, or biased text generations. However, existing jailbreaking methods are computationally costly. In this paper, we propose the weak-to-strong jailbreaking attack, an efficient method to attack aligned LLMs to produce harmful text. Our key intuition is based on the observation that jailbroken and aligned models only differ in their initial decoding distributions. The weak-to-strong attack's key technical insight is using two smaller models (a safe and an unsafe one) to adversarially modify a significantly larger safe model's decoding probabilities. We evaluate the weak-to-strong attack on 5 diverse LLMs from 3 organizations. The results show our method can increase the misalignment rate to over 99% on two datasets with just one forward pass per example. Our study exposes an urgent safety issue that needs to be addressed when aligning LLMs. As an initial attempt, we propose a defense strategy to protect against such attacks, but creating more advanced defenses remains challenging."
    },
    {
        "title": "Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification",
        "link_suffix": "/forum?id=cv2iMNWCsh",
        "link": "https://openreview.net/forum?id=cv2iMNWCsh",
        "pdf_link": "https://openreview.net/pdf?id=cv2iMNWCsh",
        "keywords": "Uncertainty Estimation, Model Averaging, Credal Stes, Probability Intervals, Out-of-Distribution Detection",
        "abstract": "This paper presents an innovative approach, called credal wrapper, to formulating a credal set representation of model averaging for Bayesian neural networks (BNNs) and deep ensembles (DEs), capable of improving uncertainty estimation in classification tasks. Given a finite collection of single predictive distributions derived from BNNs or DEs, the proposed credal wrapper approach extracts an upper and a lower probability bound per class, acknowledging the epistemic uncertainty due to the availability of a limited amount of distributions. Such probability intervals over classes can be mapped on a convex set of probabilities (a credal set) from which, in turn, a unique prediction can be obtained using a transformation called intersection probability transformation. In this article, we conduct extensive experiments on several out-of-distribution (OOD) detection benchmarks, encompassing various dataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C, CIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network architectures (such as VGG16, ResNet-18/50, EfficientNet B2, and ViT Base). Compared to the BNN and DE baselines, the proposed credal wrapper method exhibits superior performance in uncertainty estimation and achieves a lower expected calibration error on corrupted data."
    },
    {
        "title": "Discovering Temporally Compositional Neural Manifolds with Switching Infinite GPFA",
        "link_suffix": "/forum?id=2iCIHgE8KG",
        "link": "https://openreview.net/forum?id=2iCIHgE8KG",
        "pdf_link": "https://openreview.net/pdf?id=2iCIHgE8KG",
        "keywords": "Computational neuroscience, neural data analysis, Bayesian nonparametrics, latent variable modelling;",
        "abstract": "Gaussian Process Factor Analysis (GPFA) is a powerful latent variable model for extracting low-dimensional manifolds underlying population neural activities. However, one limitation of standard GPFA models is that the number of latent factors needs to be pre-specified or selected through heuristic-based processes, and that all factors contribute at all times. We propose the infinite GPFA model, a fully Bayesian non-parametric extension of the classical GPFA by incorporating an Indian Buffet Process (IBP) prior over the factor loading process, such that it is possible to infer a potentially infinite set of latent factors, and the identity of those factors that contribute to neural firings in a compositional manner at each time point. Learning and inference in the infinite GPFA model is performed through variational expectation-maximisation, and we additionally propose scalable extensions based on sparse variational Gaussian Process methods. We empirically demonstrate that the infinite GPFA model correctly infers dynamically changing activations of latent factors on a synthetic dataset. By fitting the infinite GPFA model to population activities of hippocampal place cells during spatial navigation, we identify non-trivial and behaviourally meaningful dynamics in the neural encoding process."
    },
    {
        "title": "For Better or For Worse? Learning Minimum Variance Features With Label Augmentation",
        "link_suffix": "/forum?id=LCL8SMGxDY",
        "link": "https://openreview.net/forum?id=LCL8SMGxDY",
        "pdf_link": "https://openreview.net/pdf?id=LCL8SMGxDY",
        "keywords": "feature learning, mixup, label smoothing, spurious correlations",
        "abstract": "Data augmentation has been pivotal in successfully training deep learning models on classification tasks over the past decade. An important subclass of data augmentation techniques - which includes both label smoothing and Mixup - involves modifying not only the input data but also the input label during model training. In this work, we analyze the role played by the label augmentation aspect of such methods. We first prove that linear models on binary classification data trained with label augmentation learn only the minimum variance features in the data, while standard training (which includes weight decay) can learn higher variance features. We then use our techniques to show that even for nonlinear models and general data distributions, the label smoothing and Mixup losses are lower bounded by a function of the model output variance. Lastly, we demonstrate empirically that this aspect of label smoothing and Mixup can be a positive and a negative. On the one hand, we show that the strong performance of label smoothing and Mixup on image classification benchmarks is correlated with learning low variance hidden representations. On the other hand, we show that Mixup and label smoothing can be more susceptible to low variance spurious correlations in the training data."
    },
    {
        "title": "Permute-and-Flip: An optimally stable and watermarkable decoder for LLMs",
        "link_suffix": "/forum?id=YyVVicZ32M",
        "link": "https://openreview.net/forum?id=YyVVicZ32M",
        "pdf_link": "https://openreview.net/pdf?id=YyVVicZ32M",
        "keywords": "LLM, Watermark, AI Safety, Decoding",
        "abstract": "In this paper, we propose a new decoding method called Permute-and-Flip (PF) decoder. It enjoys stability properties similar to the standard sampling decoder, but is provably up to 2x better in its quality-stability tradeoff than sampling and never worse than any other decoder. We also design a cryptographic watermarking scheme analogous to Aaronson (2023)'s Gumbel watermark, but naturally tailored for PF decoder. The watermarking scheme does not change the distribution to sample, while allowing arbitrarily low false positive rate and high recall whenever the generated text has high entropy. Our experiments show that the PF decoder (and its watermarked counterpart) significantly outperform(s) naive sampling (and its Gumbel watermarked counterpart) in terms of perplexity, while retaining the same stability (and detectability), hence making it a promising new approach for LLM decoding. We provide the code in the supplementary materials."
    },
    {
        "title": "ECGN: A CLUSTER-AWARE APPROACH TO GRAPH NEURAL NETWORKS FOR IMBALANCED CLASSIFICATION.",
        "link_suffix": "/forum?id=el2pNeLrRC",
        "link": "https://openreview.net/forum?id=el2pNeLrRC",
        "pdf_link": "https://openreview.net/pdf?id=el2pNeLrRC",
        "keywords": "Graph Neural Networks, Uniform Node Updates Issue, Imbalanced Node Classification, Cluster Specific Updates, Synthetic Node Generation",
        "abstract": "Classifying nodes in a graph is a common problem. The ideal classifier must\nadapt to any imbalances in the class distribution. It must also use information in\nthe clustering structure of real-world graphs. Existing Graph Neural Networks\n(GNNs) have not addressed both problems together. We propose the Enhanced\nCluster-aware Graph Network (ECGN), a novel method that addresses these is-\nsues by integrating cluster-specific training with synthetic node generation. Unlike\ntraditional GNNs that apply the same node update process for all nodes, ECGN\nlearns different aggregations for different clusters. We also use the clusters to gen-\nerate new minority-class nodes in a way that helps clarify the inter-class decision\nboundary. By combining cluster-aware embeddings with a global integration step,\nECGN enhances the quality of the resulting node embeddings. Our method works\nwith any underlying GNN and any cluster generation technique. Experimental\nresults show that ECGN consistently outperforms its closest competitors by up to\n11% on some widely-studied benchmark datasets. The GitHub implementation\nfor implementation and replication is publicly available onhttps://github.com/anonymous753341/ECGN."
    },
    {
        "title": "Neocortical cell type classification from electrophysiology recordings using deep neural networks",
        "link_suffix": "/forum?id=5w8xpFWkns",
        "link": "https://openreview.net/forum?id=5w8xpFWkns",
        "pdf_link": "https://openreview.net/pdf?id=5w8xpFWkns",
        "keywords": "neuroscience, electrophysiology, cell type, classification",
        "abstract": "Understanding the neural code requires identifying different functional units involved in the neural circuits. One way to identify these functional units is to solve a neuron type classification problem. For decades, current-clamp electrophysiology recordings have provided the means to classify the neurons based on subtle differences in action potential shapes and spiking patterns. However, significant variations in neuronal type definitions, classification pipelines, and intrinsic variability in the neuronal activities make unambiguous determination of neuron type challenging. Previous solutions to this electrophysiology-based cell type classification problem consisted of dimensionality reduction juxtaposed with clustering using hand-crafted action potential features. Recent discoveries have allowed genetics-based cell-type classifications, which have fewer ambiguities, but they are less practical in vivo and have even lower throughput. Leveraging the unprecedented ground truth data published in the Allen Institute Cell Types Database, which contains anatomical, genetic, and electrophysiological characterizations of neurons in the mouse neocortex, we construct a robust and efficient convolutional neural network (CNN) that successfully classifies neurons according to their genetic label or broad type (excitatory or inhibitory) solely using current-clamp electrophysiology recordings. The CNN is configured as a multiple-input single-output network consisting of three subnetworks that take in the raw time series electrophysiology recording as well as the real and imaginary components of its Fourier coefficients. Our single pipeline method is fast and streamlined while simultaneously outperforming a previous method. Furthermore, our method achieves classification with more classes using only a single current-clamp time series trace as the input. This end-to-end convolutional neural network-based classification method removes the need for hand-crafted features, specific knowledge, or human intervention for quick identification of the neocortical cell type with high accuracy, enabling interpretation of experimental data in a bias-free manner and understanding of a much broader scientific context."
    },
    {
        "title": "Online Decision Deferral under Budget Constraints",
        "link_suffix": "/forum?id=of25Zg4AdM",
        "link": "https://openreview.net/forum?id=of25Zg4AdM",
        "pdf_link": "https://openreview.net/pdf?id=of25Zg4AdM",
        "keywords": "Online Learning, Human-AI Collaboration",
        "abstract": "Machine Learning (ML) models are increasingly used to support or substitute decision making. In applications where skilled experts are a limited resource, it is crucial to reduce their burden and automate decisions when the performance of an ML model is at least of equal quality. \nHowever, models are often pre-trained and fixed, while tasks arrive sequentially and their distribution may shift. In that case, the respective performance of the decision makers may change, and the deferral algorithm must remain adaptive. We propose a contextual bandit model of this online decision making problem. Our framework includes budget constraints and different types of partial feedback models. Beyond the theoretical guarantees of our algorithm, we propose efficient extensions that achieve remarkable performance on real-world datasets."
    }
]
[{"title": "OmniKV: Dynamic Context Selection for Efficient Long-Context LLMs", "link_suffix": "/forum?id=ulCAPXYXfa", "link": "https://openreview.net/forum?id=ulCAPXYXfa", "pdf_link": "https://openreview.net/pdf?id=ulCAPXYXfa", "keywords": "Efficient LLMs, KV cache, Long Context LLMs", "abstract": "During the inference phase of Large Language Models (LLMs) with long context, a substantial portion of GPU memory is allocated to the KV cache, with memory usage increasing as the sequence length grows. To mitigate the GPU memory footprint associate with KV cache, some previous studies have discarded less important tokens based on the sparsity identified in attention scores in long context scenarios. However, we argue that attention scores cannot indicate the future importance of tokens in subsequent generation iterations, because attention scores are calculated based on current hidden states. Therefore, we propose OmniKV, a token-dropping-free and training-free inference method that reduces KV cache GPU memory usage by over 75% without performance degradation. Moreover, OmniKV maintains even accelerates inference efficiency in long-text scenarios. The core innovative insight of OmniKV is: Within a single generation iteration, there is a high degree of similarity in the important tokens identified across consecutive layers. Extensive experiments demonstrate that OmniKV achieves state-of-the-art performance across multiple benchmarks, with particularly advantages in chain-of-thoughts scenarios. By using a single A100 and Llama-3-8B, OmniKV can handle a 450K context with a decoding latency of 7.52 tokens/s, which is 1.87 times faster than the original model running on three A100 GPUs in pipeline.", "title_embedding_index": 17850, "title_abs_embedding_index": 17875}, {"title": "Approximating Optima of Nonconvex Functions", "link_suffix": "/forum?id=vAoyZWyDEc", "link": "https://openreview.net/forum?id=vAoyZWyDEc", "pdf_link": "https://openreview.net/pdf?id=vAoyZWyDEc", "keywords": "Computablity of Approximate Optima, Non-convex functions", "abstract": "We study the computability of approximating optima of non-convex functions. We give a simple proof to show that the problem of finding the optimal value (and optimal point) or its approximation is not even computable in the oracle setting. We also give a property a function has to satisfy if its global optima can be approximated. Next we give an example of such a global property we call basin of attraction. Then we give a simple algorithm which converges to the global optima when this is known. Finally, we give some numerical results.", "title_embedding_index": 17851, "title_abs_embedding_index": 17876}, {"title": "Realistic World Model for Autonomous Driving: Integrating Physical Constraints and Multi-agent Interactions", "link_suffix": "/forum?id=r91tAISb88", "link": "https://openreview.net/forum?id=r91tAISb88", "pdf_link": "https://openreview.net/pdf?id=r91tAISb88", "keywords": "Autonomous Driving, World Model, Trajectory Forecasting, Motion Planning", "abstract": "Ensuring safety in autonomous driving, particularly in complex and dynamic environments, remains a significant challenge. To address this issue, we propose a novel traffic world model. While existing trajectory forecasting methods typically focus on predicting individual agents and may neglect critical factors such as vehicle dimensions, orientation, and physical constraints, our model incorporates these elements comprehensively. Unlike previous methods that often result in unrealistic scenarios such as collisions or off-road driving, our model integrates physical constraints and introduces innovative loss functions\u2014including safe distance loss and road departure loss\u2014to ensure that the generated trajectories are both realistic and feasible. By simultaneously predicting the trajectories of all agents and explicitly modeling interactions across various scenarios, our approach significantly enhances realism and safety. Our world model functions as a generator, simulator, and trajectory forecasting tool, demonstrating substantial improvements over traditional methods and achieving competitive performance in reducing collision and off-road rates.", "title_embedding_index": 17852, "title_abs_embedding_index": 17877}, {"title": "A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?", "link_suffix": "/forum?id=nzh8Z8d1Zc", "link": "https://openreview.net/forum?id=nzh8Z8d1Zc", "pdf_link": "https://openreview.net/pdf?id=nzh8Z8d1Zc", "keywords": "benchmark, large language model", "abstract": "Large language models (LLMs) have exhibited remarkable capabilities across various domains and tasks, pushing the boundaries of our knowledge in learning and cognition. The latest model, OpenAI's o1, stands out as the first LLM with an internalized chain-of-thought technique using reinforcement learning strategies. While it has demonstrated surprisingly strong capabilities on various general language tasks, its performance in specialized fields such as medicine remains unknown. To this end, this report provides a comprehensive exploration of o1 on different medical scenarios, examining 3 key aspects: understanding, reasoning, and multilinguality. Specifically, our evaluation encompasses 6 tasks using data from 37 medical datasets, including two newly constructed and more challenging question-answering (QA) tasks based on professional medical quizzes from the New England Journal of Medicine (NEJM) and The Lancet. These datasets offer greater clinical relevance compared to standard medical QA benchmarks such as MedQA, translating more effectively into real-world clinical utility. Our analysis of o1 suggests that the enhanced reasoning ability of LLMs may (significantly) benefit their capability to understand various medical instructions and reason through complex clinical scenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average of 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios. But meanwhile, we identify several weaknesses in both the model capability and the existing evaluation protocols, including hallucination, inconsistent multilingual ability, and discrepant metrics for evaluation. We will release our raw data and model outputs for future research.", "title_embedding_index": 17853, "title_abs_embedding_index": 17878}, {"title": "Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning", "link_suffix": "/forum?id=X2x2DuGIbx", "link": "https://openreview.net/forum?id=X2x2DuGIbx", "pdf_link": "https://openreview.net/pdf?id=X2x2DuGIbx", "keywords": "Adversarial Machine Learning, Certified Robustness, Reinforcement Learning, Poisoning Attack", "abstract": "Similar to other machine learning frameworks, Offline Reinforcement Learning (RL) is shown to be vulnerable to poisoning attacks, due to its reliance on externally sourced datasets, a vulnerability that is exacerbated by its sequential nature. To mitigate the risks posed by RL poisoning, we extend certified defenses to provide larger guarantees against adversarial manipulation, ensuring robustness for both per-state actions, and the overall expected cumulative reward. Our approach leverages properties of Differential Privacy, in a manner that allows this work to span both continuous and discrete spaces, as well as stochastic and deterministic environments---significantly expanding the scope and applicability of achievable guarantees. Empirical evaluations demonstrate that our approach ensures the performance drops to no more than 50% with up to 7% of the training data poisoned, significantly improving over the 0.008% in prior work (Wu et al., 2022), while producing certified radii that is 5 times larger as well. This highlights the potential of our framework to enhance safety and reliability in offline RL.", "title_embedding_index": 17854, "title_abs_embedding_index": 17879}, {"title": "Compress Guidance in Conditional Diffusion Sampling", "link_suffix": "/forum?id=C1E0Oo5qgK", "link": "https://openreview.net/forum?id=C1E0Oo5qgK", "pdf_link": "https://openreview.net/pdf?id=C1E0Oo5qgK", "keywords": "Diffusion model, guidance, generative models, compact diffusion", "abstract": "We found that enforcing guidance throughout the sampling process is often counterproductive due to the model-fitting issue, where samples are `tuned' to match the classifier\u2019s parameters rather than generalizing the expected condition. This work identifies and quantifies the problem, demonstrating that reducing or excluding guidance at numerous timesteps can mitigate this issue. By distributing a small amount of guidance over a large number of sampling timesteps, we observe a significant improvement in image quality and diversity while also reducing the required guidance timesteps by nearly 40%. This approach addresses a major challenge in applying guidance effectively to generative tasks. Consequently, our proposed method, termed Compress Guidance, allows for the exclusion of a substantial number of guidance timesteps while still surpassing baseline models in image quality. We validate our approach through benchmarks on label-conditional and text-to-image generative tasks across various datasets and models.", "title_embedding_index": 17855, "title_abs_embedding_index": 17880}, {"title": "Machine Unlearning For Alleviating Negative Transfer In Partial-Set Source-Free Unsupervised Domain Adaptation", "link_suffix": "/forum?id=f5o6kWRC0A", "link": "https://openreview.net/forum?id=f5o6kWRC0A", "pdf_link": "https://openreview.net/pdf?id=f5o6kWRC0A", "keywords": "Source-Free Domain Adaptation, Unsupervised domain adaptation, Machine unlearning", "abstract": "Source-free Unsupervised Domain Adaptation (SFUDA) aims to adjust a source model trained on a labeled source domain to a related but unlabeled target domain without accessing the source data. Many SFUDA methods are studied in closed-set scenarios where the target domain and source domain categories are perfectly aligned. However, a more practical scenario is a partial-set scenario where the source label space subsumes the target one. In this paper, we prove that reducing the differences between the source and target domains in the partial-set scenario helps to achieve domain adaptation. And we propose a simple yet effective SFUDA framework called the Machine Unlearning Framework to alleviate the negative transfer problem in the partial-set scenario, thereby allowing the model to focus on the target domain category. Specifically, we first generate noise samples for each category that only exists in the source domain and generate pseudo-labeled samples from the target domain. Then, in the forgetting stage, we use these samples to train the model, making it behave like the model has never seen the class that only exists in the source domain before. Finally, in the adaptation stage, we use only the pseudo-labeled samples to conduct self-supervised training on the model, making it more adaptable to the target domain. Our method is easy to implement and pluggable, suitable for various pre-trained models. Experimental results show that our method can well alleviate the negative transfer problem and improve model performance under various target domain category settings.", "title_embedding_index": 17856, "title_abs_embedding_index": 17881}, {"title": "The Role of Label Noise in the Feature Learning Process", "link_suffix": "/forum?id=TroV1cbgoG", "link": "https://openreview.net/forum?id=TroV1cbgoG", "pdf_link": "https://openreview.net/pdf?id=TroV1cbgoG", "keywords": "Label noise, Feature Learning, Training Dynamics", "abstract": "Deep learning with noisy labels presents significant challenges.\nIn this work, we theoretically characterize the role of label noise in training neural networks from a feature learning perspective.\nSpecifically, we consider asignal-noisedata distribution, where each data point comprises a label-dependent signal and label-independent noise, and rigorously analyze the training dynamics of a two-layer convolutional neural network under this data setting, along with the presence of label noise.\nParticularly, we identify two stages in which the dynamics exhibit distinct patterns.\nInStage I, the model perfectly fits all the clean samples (i.e., samples without label noise) while ignoring the noisy ones (i.e., samples with noisy labels).\nIn the first stage, the model learns the signal from the clean samples, which generalizes well on unseen data.\nInStage II, as the training loss converges, the gradient in the direction of noise surpasses that of the signal, leading to over-fitting on noisy samples.\nEventually, the model memorizes the noise present in the noisy samples, which degrades its generalization ability.\nIn contrast, when training without label noise, the dynamics do not exhibit this two-stage pattern.\nFurthermore, our results provide theoretical supports for two widely used techniques for tackling label noise: early stopping and sample selection.\nExperiments on both synthetic and real-world datasets confirm our theoretical findings.", "title_embedding_index": 17857, "title_abs_embedding_index": 17882}, {"title": "Challenge Me: Enhancing Conversational Consistency of LLMs by Learning with Questioning Feedback", "link_suffix": "/forum?id=SMKgohbroH", "link": "https://openreview.net/forum?id=SMKgohbroH", "pdf_link": "https://openreview.net/pdf?id=SMKgohbroH", "keywords": "AI Safety, LLM, Conversational Consistency", "abstract": "As Large Language Models (LLMs) increasingly integrate into critical decision-support systems, ensuring their conversational consistency becomes paramount for reliable and trustworthy AI-assisted services, especially in high-stakes domains such as healthcare and legal advice. In this work, we study the critical issue of conversational inconsistency in LLMs, where models provide contradictory information across multiple dialogue turns. We introduce a novel Conversationally Consistent Supervised Fine-Tuning (CC-SFT) method that explicitly accounts for two-turn conversations. Our approach combines a first-round loss, a second-round loss, and a consistency loss based on Wasserstein distance to encourage coherent responses across turns. We evaluate our method on three diverse datasets (OpenBookQA, GSM8K, and MedQA-USMLE) using three LLMs (Llama v3.1, Mistral AI, and Gemma). Experimental results demonstrate that CC-SFT significantly reduces conversational inconsistency compared to standard fine-tuning, with lower flipping rates and improved accuracy in second-round responses. We provide theoretical convergence guarantees for our method and analyze the impact of the consistency loss coefficient. Our code is publicly available at \\url{https://github.com/anonymous4science/llm_conversational_consistency}.", "title_embedding_index": 17858, "title_abs_embedding_index": 17883}, {"title": "Two Sparse Matrices are Better than One: Sparsifying Neural Networks with Double Sparse Factorization", "link_suffix": "/forum?id=DwiwOcK1B7", "link": "https://openreview.net/forum?id=DwiwOcK1B7", "pdf_link": "https://openreview.net/pdf?id=DwiwOcK1B7", "keywords": "sparse factorization, pruning", "abstract": "Neural networks are often challenging to work with due to their large size and complexity. To address this, various methods aim to reduce model size by sparsifying or decomposing weight matrices, such as magnitude pruning and low-rank or block-diagonal factorization. In this work, we present Double Sparse Factorization (DSF), where we factorize each weight matrix into two sparse matrices. Although solving this problem exactly is computationally infeasible, we propose an efficient heuristic based on alternating minimization via ADMM that achieves state-of-the-art results, enabling unprecedented sparsification of neural networks. For instance, in a one-shot pruning setting, our method can reduce the size of the LLaMA2-13B model by 50% while maintaining better performance than the dense LLaMA2-7B model. We also compare favorably with Optimal Brain Compression, the state-of-the-art layer-wise pruning approach for convolutional neural networks. Furthermore, accuracy improvements of our method persist even after further model fine-tuning.", "title_embedding_index": 17859, "title_abs_embedding_index": 17884}, {"title": "Learning Effective Multi-modal Trackers via Modality-Sensitive Tuning", "link_suffix": "/forum?id=dKZCfzRlm3", "link": "https://openreview.net/forum?id=dKZCfzRlm3", "pdf_link": "https://openreview.net/pdf?id=dKZCfzRlm3", "keywords": "Multi-modal Tracking; Cross-modal Fine-Tuning", "abstract": "This paper tackles the critical issue of constructing multi-modal trackers by effectively adapting the extensive knowledge of pre-trained RGB trackers to auxiliary modalities.To address the challenges, we propose a novel modality sensitivity-aware tuning framework, namely MST, which delicately models the learning process via adaptive tuning of model weights by inherent modality characteristics. Specifically, we first investigate the parameter modality-sensitivity as a criterion for measuring a precise element-wise essentiality for multi-modal adaptation. Then, in the tuning phase, we further leverage such sensitivity to bolster the stability and coherence of multi-modal representations, thereby enhancing generalization capabilities. Extensive experiments showcase the effectiveness of the proposed method, surpassing current state-of-the-art techniques across various multi-modal tracking scenarios and demonstrating remarkable performance even in extreme conditions. The source code will be publicly available.", "title_embedding_index": 17860, "title_abs_embedding_index": 17885}, {"title": "Information-Theoretic Active Correlation Clustering", "link_suffix": "/forum?id=q6TelS1z7N", "link": "https://openreview.net/forum?id=q6TelS1z7N", "pdf_link": "https://openreview.net/pdf?id=q6TelS1z7N", "keywords": "active learning, active clustering, correlation clustering, acquisition function", "abstract": "We study correlation clustering where the pairwise similarities are not known in advance. For this purpose, we employ active learning to query pairwise similarities in a cost-efficient way. We propose a number of effective information-theoretic acquisition functions based on entropy and information gain. We extensively investigate the performance of our methods in different settings and demonstrate their superior performance compared to the alternatives.", "title_embedding_index": 17861, "title_abs_embedding_index": 17886}, {"title": "Attention-aware Post-training Quantization without Backpropagation", "link_suffix": "/forum?id=0L8wZ9WRah", "link": "https://openreview.net/forum?id=0L8wZ9WRah", "pdf_link": "https://openreview.net/pdf?id=0L8wZ9WRah", "keywords": "Quantization, Hyper-scale LLMs, Attention, Hessian", "abstract": "Quantization offers a promising solution for deploying large-scale language models (LLMs) on resource-constrained devices. However, early quantization methods, developed for smaller networks like ResNet, rely on gradient-based optimization, which becomes impractical for hyper-scale LLMs with billions of parameters. While recently proposed backpropagation-free post-training quantization (PTQ) methods alleviate this issue, their performance is limited by a lack of inter-layer dependency consideration. In this paper, we introduce a novel PTQ algorithm that incorporates inter-layer dependencies without relying on backpropagation. The key innovation is the development of attention-aware Hessian matrices that capture inter-layer interactions within the attention module. Extensive experiments demonstrate that our approach significantly outperforms conventional PTQ methods, particularly at low bit-widths.", "title_embedding_index": 17862, "title_abs_embedding_index": 17887}, {"title": "SHIFT-RESILIENT DIFFUSIVE IMPUTATION FOR VARIABLE SUBSET FORECASTING", "link_suffix": "/forum?id=s7Q1j5Hqpw", "link": "https://openreview.net/forum?id=s7Q1j5Hqpw", "pdf_link": "https://openreview.net/pdf?id=s7Q1j5Hqpw", "keywords": "data mining; variable subset forecasting; distribution shift", "abstract": "It is common for sensor failures to result in missing data, leading to training sets being complete while test sets have only a small subset of variables. The challenge lies in utilizing incomplete data for forecasting, which is known as the Variable Subset Forecasting (VSF). In VSF tasks, significant distribution shift is present. One type is inter-series shift, which indicates changes in correlations between different series, and the other type is intra-series shift, which refers to substantial distribution differences within the same series across different time windows. Existing approaches to solving VSF tasks typically involve imputing the missing data first and then making predictions using the completed series. However, these methods do not account for the shift inherent in VSF tasks, resulting in poor model performance. To address these challenges, we propose a Shift-Resilient Diffusive Imputation (SRDI) framework against the shift. Specifically, SRDI integrates divide-conquer strategy with the denoising process, that decomposes the input into invariant patterns and variant patterns, representing the temporally stable parts of inter-series correlation and the highly fluctuating parts, respectively. By extracting spatiotemporal features from each separately and then appropriately combining them, inter-series shift can be effectively mitigated. Then, we innovatively organize SRDI and the forecasting model into a meta-learning paradigm tailored for VSF scenarios. We address the intra-series shift by treating time windows as tasks during training and employing an adaptation process before testing. Extensive experiments on four datasets have demonstrated our superior performance compared with state-of-the-art methods.", "title_embedding_index": 17863, "title_abs_embedding_index": 17888}, {"title": "LLaCA: Multimodal Large Language Continual Assistant", "link_suffix": "/forum?id=G9qA1JZ0Sy", "link": "https://openreview.net/forum?id=G9qA1JZ0Sy", "pdf_link": "https://openreview.net/pdf?id=G9qA1JZ0Sy", "keywords": "Multimodal Continual Instruction Tuning, Anti-Forgetting, Exponential Movement Average, LoRA, LLaVA", "abstract": "Instruction tuning guides the Multimodal Large Language Models (MLLMs) in aligning different modalities by designing text instructions, which seems to be an essential technique to enhance the capabilities and controllability of foundation models. In this framework, Multimodal Continual Instruction Tuning (MCIT) is adopted to continually instruct MLLMs to follow human intent in sequential datasets. We observe existing gradient update would heavily destroy the tuning performance on previous datasets and the zero-shot ability during continual instruction tuning. Exponential Moving Average (EMA) update policy owns the ability to trace previous parameters, which can aid in decreasing forgetting. However, its stable balance weight cannot deal with the ever-changing datasets, leading to the out-of-balance between plasticity and stability of MLLMs. In this paper, we propose a method called Multimodal Large Language Continual Assistant (LLaCA) to address the challenge. Starting from the trade-off prerequisite and EMA update, we propose the plasticity and stability ideal condition. Based on Taylor expansion in the loss function, we find the optimal balance weight is basically according to the gradient information and previous parameters. We automatically determine the balance weight and significantly improve the performance. Through comprehensive experiments on LLaVA-1.5 in a continual visual-question-answering benchmark, compared with baseline, our approach not only highly improves anti-forgetting ability (with reducing forgetting from 22.67 to 2.68), but also significantly promotes continual tuning performance (with increasing average accuracy from 41.31 to 61.89). Our code will be published soon.", "title_embedding_index": 17864, "title_abs_embedding_index": 17889}, {"title": "HRVMamba: High-Resolution Visual State Space Model for Dense Prediction", "link_suffix": "/forum?id=4UxXe3JZta", "link": "https://openreview.net/forum?id=4UxXe3JZta", "pdf_link": "https://openreview.net/pdf?id=4UxXe3JZta", "keywords": "Mamba, Dense Prediction, Human pose estimation, Semantic segmentation", "abstract": "Recently, State Space Models (SSMs) with efficient hardware-aware designs, \\ie, Mamba, have demonstrated significant potential in computer vision tasks due to their linear computational complexity with respect to token length and their global receptive field. However, Mamba's performance on dense prediction tasks, including human pose estimation and semantic segmentation, has been constrained by three key challenges: insufficient inductive bias, long-range forgetting, and low-resolution output representation.\nTo address these challenges, we introduce the Dynamic Visual State Space (DVSS) block, which utilizes multi-scale convolutional kernels to extract local features across different scales and enhance inductive bias, and employs deformable convolution to mitigate the long-range forgetting problem while enabling adaptive spatial aggregation based on input and task-specific information. By leveraging the multi-resolution parallel design proposed in HRNet, we introduce High-Resolution Visual State Space Model (HRVMamba) based on the DVSS block, which preserves high-resolution representations throughout the entire process while promoting effective multi-scale feature learning.\nExtensive experiments highlight HRVMamba's impressive performance on dense prediction tasks, achieving competitive results against existing benchmark models without bells and whistles.\nWe will make the source code publicly accessible.", "title_embedding_index": 17865, "title_abs_embedding_index": 17890}, {"title": "Tuning Timestep-Distilled Diffusion Model Using Pairwise Sample Optimization", "link_suffix": "/forum?id=fXnE4gB64o", "link": "https://openreview.net/forum?id=fXnE4gB64o", "pdf_link": "https://openreview.net/pdf?id=fXnE4gB64o", "keywords": "Diffusion Models;", "abstract": "Recent advancements in timestep-distilled diffusion models have enabled high-quality image generation that rivals non-distilled multi-step models, but with significantly fewer inference steps. While such models are attractive for applications due to the low inference cost and latency, fine-tuning them with a naive diffusion objective would result in degraded and blurry outputs. An intuitive alternative is to repeat the diffusion distillation process with a fine-tuned teacher model, which produces good results but is cumbersome and computationally intensive: the distillation training usually requires magnitude higher of training compute compared to fine-tuning for specific image styles. In this paper, we present an algorithm named pairwise sample optimization (PSO), which enables the direct fine-tuning of an arbitrary timestep-distilled diffusion model. PSO introduces additional reference images sampled from the current time-step distilled model, and increases the relative likelihood margin between the training images and reference images. This enables the model to retain its few-step generation ability, while allowing for fine-tuning of its output distribution. We also demonstrate that PSO is a generalized formulation which be flexible extended to both offline-sampled and online-sampled pairwise data, covering various popular objectives for diffusion model preference optimization. We evaluate PSO in both preference optimization and other fine-tuning tasks, including style transfer and concept customization. We show that PSO can directly adapt distilled models to human-preferred generation with both offline and online-generated pairwise preference image data. PSO also demonstrates effectiveness in style transfer and concept customization by directly tuning timestep-distilled diffusion models.", "title_embedding_index": 17866, "title_abs_embedding_index": 17891}, {"title": "Counting in small transformers: The delicate interplay between attention and feed-forward layers", "link_suffix": "/forum?id=UatDdAlr2x", "link": "https://openreview.net/forum?id=UatDdAlr2x", "pdf_link": "https://openreview.net/pdf?id=UatDdAlr2x", "keywords": "attention, mechanistic interpretability, architecture, toy model, counting, activation function", "abstract": "How do different architectural design choices influence the space of solutions that a transformer can implement and learn? How do different components interact with each other to shape the model's hypothesis space? We investigate these questions by characterizing the solutions simple transformer blocks can implement when challenged to solve the histogram task -- counting the occurrences of each item in an input sequence from a fixed vocabulary. Despite its apparent simplicity, this task exhibits a rich phenomenology: our analysis reveals a strong inter-dependence between the model's predictive performance and the vocabulary and embedding sizes, the token-mixing mechanism and the capacity of the feed-forward block. In this work, we characterize two different counting strategies that small transformers can implement theoretically: relation-based and inventory-based counting, the latter being less efficient in computation and memory. The emergence of either strategy is heavily influenced by subtle synergies among hyperparameters and components, and depends on seemingly minor architectural tweaks like the inclusion of softmax in the attention mechanism. By introspecting models \\textit{trained} on the histogram task, we verify the formation of both mechanisms in practice. Our findings highlight that even in simple settings, slight variations in model design can cause significant changes to the solutions a transformer learns.", "title_embedding_index": 17867, "title_abs_embedding_index": 17892}, {"title": "Identify Critical KV Cache in LLM Inference from an Output Perturbation Perspective", "link_suffix": "/forum?id=lRTDMGYCpy", "link": "https://openreview.net/forum?id=lRTDMGYCpy", "pdf_link": "https://openreview.net/pdf?id=lRTDMGYCpy", "keywords": "KV Cache Compression, Efficient LLM Inference", "abstract": "Large language models have driven numerous paradigm shifts in the field of natural language processing, achieving remarkable success in various real-world applications through scaling model size and leveraging long-sequence context reasoning.\nHowever, the transformer architecture, which relies on self-attention, incurs substantial storage and runtime costs when handling long-sequence inference, particularly due to the generation of extensive Key-Value (KV) cache.\nRecent studies aim to mitigate storage and latency issues while maintaining output quality by reducing the KV cache size, through the elimination of less critical entries, yet they rely on a basic empirical intuition of identifying critical cache entries based solely on top attention weights.\nIn this paper, we present the first formal investigation into the problem of identifying critical KV cache entries from the perspective of attention output perturbation.\nBy analyzing the output perturbation caused when only critical KV cache entries are used instead of the entire cache, we reveal that, in addition to the commonly used attention weights, the value states within KV entries and the pretrained parameters matrix are also important. Based on this finding, we propose a novel perturbation-constrained selection algorithm to identify critical cache entries by optimizing the worst-case output perturbation.\nExtensive evaluations on 16 datasets from Longbench, along with detailed empirical analysis, have comprehensively confirmed the effectiveness of constraining output perturbation perspective in identifying critical KV cache. When combined with state-of-the-art cache eviction methods, it can achieve up to an additional 34% cache memory savings while maintaining the same generation quality.", "title_embedding_index": 17868, "title_abs_embedding_index": 17893}, {"title": "LoCA: Location-Aware Cosine Adaptation for Parameter-Efficient Fine-Tuning", "link_suffix": "/forum?id=4NRjdISWby", "link": "https://openreview.net/forum?id=4NRjdISWby", "pdf_link": "https://openreview.net/pdf?id=4NRjdISWby", "keywords": "Parameter-efficient fine-tuning, discrete cosine transform, transfer learning, adaptation", "abstract": "Low-rank adaptation (LoRA) has become a prevalent method for adapting pre-trained large language models to downstream tasks. However, the simple low-rank decomposition form may constrain the optimization flexibility. To address this limitation, we introduce Location-aware Cosine Adaptation (LoCA), a novel frequency-domain parameter-efficient fine-tuning method based on inverse Discrete Cosine Transform (iDCT) with selective locations of learnable components. We begin with a comprehensive theoretical comparison between frequency-domain and low-rank decompositions for fine-tuning pre-trained large models. Our analysis reveals that frequency-domain approximation with carefully selected frequency components can surpass the expressivity of traditional low-rank-based methods. Furthermore, we demonstrate that iDCT offers a more efficient implementation compared to inverse Discrete Fourier Transform (iDFT), allowing for better selection and tuning of frequency components while maintaining equivalent expressivity to the optimal iDFT-based adaptation. By employing finite-difference approximation to estimate gradients for discrete locations of learnable coefficients on the DCT spectrum, LoCA dynamically selects the most informative frequency components during training. Experiments on diverse language and vision fine-tuning tasks demonstrate that LoCA offers enhanced parameter efficiency while maintains computational feasibility comparable to low-rank-based methods.", "title_embedding_index": 17869, "title_abs_embedding_index": 17894}, {"title": "Build-A-Scene: Interactive 3D Layout Control for Diffusion-Based Image Generation", "link_suffix": "/forum?id=gg6dPtdC1C", "link": "https://openreview.net/forum?id=gg6dPtdC1C", "pdf_link": "https://openreview.net/pdf?id=gg6dPtdC1C", "keywords": "Diffusion Models, Text-to-Image, Layout Control", "abstract": "We propose a diffusion-based approach for Text-to-Image (T2I) generation with interactive 3D layout control.\nLayout control has been widely studied to alleviate the shortcomings of T2I diffusion models in understanding objects' placement and relationships from text descriptions.\nNevertheless, existing approaches for layout control are limited to 2D layouts, require the user to provide a static layout beforehand, and fail to preserve generated images under layout changes.\nThis makes these approaches unsuitable for applications that require 3D object-wise control and iterative refinements, e.g, interior design and complex scene generation. \nTo this end, we leverage the recent advancements in depth-conditioned T2I models and propose a novel approach for interactive 3D layout control.\nWe replace the traditional 2D boxes used in layout control with 3D boxes.\nFurthermore, we revamp the T2I task as a multi-stage generation process, where at each stage, the user can insert, change, and move an object in 3D while preserving objects from earlier stages.\nWe achieve this through a novel Dynamic Self-Attention (DSA) module and a consistent 3D object translation strategy.\nTo evaluate our approach, we establish a benchmark and an evaluation protocol for interactive 3D layout control.\nExperiments show that our approach can generate complicated scenes based on 3D layouts, outperforming the standard depth-conditioned T2I methods by two-folds on object generation success rate.\nMoreover, it outperforms all methods in comparison on preserving objects under layout changes.", "title_embedding_index": 17870, "title_abs_embedding_index": 17895}, {"title": "PartEdit: Fine-Grained Image Editing using Pre-Trained Diffusion Models", "link_suffix": "/forum?id=2QXC4NX8oC", "link": "https://openreview.net/forum?id=2QXC4NX8oC", "pdf_link": "https://openreview.net/pdf?id=2QXC4NX8oC", "keywords": "Diffusion models, Text-to-Image, Image Editing", "abstract": "We present the first text-based image editing approach for object parts based on pre-trained diffusion models.\nDiffusion-based image editing approaches capitalized on the deep understanding of diffusion models of image semantics to perform a variety of edits.\nHowever, existing diffusion models lack sufficient understanding of many object parts, hindering fine-grained edits requested by users.\nTo address this, we propose to expand the knowledge of pre-trained diffusion models to allow them to understand various object parts, enabling them to perform fine-grained edits.\nWe achieve this by learning special textual tokens that correspond to different object parts through an efficient token optimization process.\nThese tokens are optimized to produce reliable localization masks at each inference step to localize the editing region.\nLeveraging these masks, we design feature-blending and adaptive thresholding strategies to execute the edits seamlessly.\nTo evaluate our approach, we establish a benchmark and an evaluation protocol for part editing.\nExperiments show that our approach outperforms existing editing methods on all metrics and is preferred by users 77-90% of the time in conducted user studies.", "title_embedding_index": 17871, "title_abs_embedding_index": 17896}, {"title": "Learning Dynamics of Deep Matrix Factorization Beyond the Edge of Stability", "link_suffix": "/forum?id=J4Dvxv7WnG", "link": "https://openreview.net/forum?id=J4Dvxv7WnG", "pdf_link": "https://openreview.net/pdf?id=J4Dvxv7WnG", "keywords": "edge of stability, deep matrix factorization", "abstract": "Deep neural networks trained using gradient descent with a fixed learning rate $\\eta$ often operate in the regime of ``edge of stability'' (EOS), where the largest eigenvalue of the Hessian exceeds the stability threshold $2/\\eta$. In this regime, the training loss oscillates but decreases over long timescales. In this work, we present a fine-grained analysis of the learning dynamics of (deep) matrix factorization beyond EOS, showing that within this regime, loss oscillations follow a 2-period fixed orbit in a small subspace, with the subspace dimension exactly characterized by the learning rate. Our analysis explains two key phenomena in deep nonlinear networks: (i) simple models and tasks do not always exhibit EOS; and (ii) oscillations occur within top features. Lastly, we also demonstrate that fine-tuning deep networks using low-rank adaptation with large learning rates induces catapult dynamics in the loss, which has the potential to improve generalization.", "title_embedding_index": 17872, "title_abs_embedding_index": 17897}, {"title": "TopER: Topological Embeddings in Graph Representation Learning", "link_suffix": "/forum?id=SrGP0ILoYa", "link": "https://openreview.net/forum?id=SrGP0ILoYa", "pdf_link": "https://openreview.net/pdf?id=SrGP0ILoYa", "keywords": "Graph embeddings, graph classification, graph representation learning, interpretability, data visualization, topological data analysis", "abstract": "Graph embeddings serve as the cornerstone for graph representation learning, facilitating the exploration of graphs by machine learning methods. However, prevalent deep learning techniques rely on black-box, high-dimensional graph embeddings. There is a pressing need for an interpretable, low-dimensional embedding approach to empower efficient graph visualization and provide practical tools to study graph datasets effectively.In this paper, we present a novel low-dimensional graph embedding method calledTopological Evolution Rate (TopER), which simplifies a key concept of topological data analysis known asfiltration. TopER calculates the evolution rate of graph substructures induced by a filtration function on nodes or edges, resulting in interpretable 2D visualizations of graph datasets. Our experiments demonstrate that this new embedding method achieves highly competitive performance compared to the latest deep learning models in graph classification tasks on benchmark datasets. We further provide theoretical stability guarantees for TopER.", "title_embedding_index": 17873, "title_abs_embedding_index": 17898}, {"title": "LDMol: Text-to-Molecule Diffusion Model with Structurally Informative Latent Space", "link_suffix": "/forum?id=GOgB6QoXwx", "link": "https://openreview.net/forum?id=GOgB6QoXwx", "pdf_link": "https://openreview.net/pdf?id=GOgB6QoXwx", "keywords": "Diffusion models, Molecule generation, Representation learning", "abstract": "With the emergence of diffusion models as the frontline of generative models, many researchers have proposed molecule generation techniques with conditional diffusion models. However, the unavoidable discreteness of a molecule makes it difficult for a diffusion model to connect raw data with highly complex conditions like natural language. To address this, we present a novel latent diffusion model dubbed LDMol for text-conditioned molecule generation. LDMol comprises a molecule autoencoder that produces a learnable and structurally informative feature space, and a natural language-conditioned latent diffusion model. In particular, recognizing that multiple SMILES notations can represent the same molecule, we employ a contrastive learning strategy to extract feature space that is aware of the unique characteristics of the molecule structure. LDMol outperforms the existing baselines on the text-to-molecule generation benchmark, suggesting a potential for diffusion models can outperform autoregressive models in text data generation with a better choice of the latent domain. Furthermore, we show that LDMol can be applied to downstream tasks such as molecule-to-text retrieval and text-guided molecule editing, demonstrating its versatility as a diffusion model.", "title_embedding_index": 17874, "title_abs_embedding_index": 17899}]
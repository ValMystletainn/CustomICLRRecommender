[{"title": "Pretraining Decision Transformers with Reward Prediction for In-Context Structured Bandit Learning", "link_suffix": "/forum?id=ppcVng610J", "link": "https://openreview.net/forum?id=ppcVng610J", "pdf_link": "https://openreview.net/pdf?id=ppcVng610J", "keywords": "Structured bandit, in-context learning, Decision Transformers", "abstract": "In this paper, we study the multi-task structured bandit problem where the goal is to learn a near-optimal algorithm that minimizes cumulative regret. The tasks share a common structure and the algorithm exploits the shared structure to minimize the cumulative regret for an unseen but related test task. We use a transformer as a decision-making algorithm to learn this shared structure so as to generalize to the test task. The prior work of pretrained decision transformers like \\dpt\\ requires access to the optimal action during training which may be hard in several scenarios. Diverging from these works, our learning algorithm does not need the knowledge of optimal action per task during training but predicts a reward vector for each of the actions using only the observed offline data from the diverse training tasks. Finally, during inference time, it selects action using the reward predictions employing various exploration strategies in-context for an unseen test task. We show that our model outperforms other SOTA methods like \\dpt, and Algorithmic Distillation (\\ad) over a series of experiments on several structured bandit problems (linear, bilinear, latent, non-linear). Interestingly, we show that our algorithm, without the knowledge of the underlying problem structure, can learn a near-optimal policy in-context by leveraging the shared structure across diverse tasks. We further extend the field of pre-trained decision transformers by showing that they can leverage unseen tasks with new actions and still learn the underlying latent structure to derive a near-optimal policy. We validate this over several experiments to show that our proposed solution is very general and has wide applications to potentially emergent online and offline strategies at test time. Finally, we theoretically analyze the performance of our algorithm and obtain generalization bounds in the in-context multi-task learning setting.", "title_embedding_index": 16550, "title_abs_embedding_index": 16575}, {"title": "FullDiffusion: Diffusion Models Without Time Truncation", "link_suffix": "/forum?id=1rg56KzwsS", "link": "https://openreview.net/forum?id=1rg56KzwsS", "pdf_link": "https://openreview.net/pdf?id=1rg56KzwsS", "keywords": "diffusion models, time truncation", "abstract": "Diffusion models are predominantly used for generative modeling, which synthesize samples by simulating the reverse process of a stochastic differential equation (SDE) that diffuses data into Gaussian noise.\nHowever, when simulating the reverse SDE, the SDE solver suffers from numerical instability near the time boundary; hence, in practice, the simulation is terminated before reaching the boundary point.\nThis heuristic time truncation hinders the rigorous formulation of diffusion models, and requires additional costs of hyperparameter tuning.\nMoreover, such numerical instability often occurs even in training, especially when using a maximum likelihood loss.\nTherefore, the current diffusion model heavily relies on the time truncation technique in both training and inference.\nIn this paper, we propose a method that completely eliminates the heuristic of time truncation.\nOur method eliminates numerical instability during maximum likelihood training by modifying the parameterization of the noise predictor and the noise schedule. We also propose a novel SDE solver that can simulate without time truncation by taking advantage of the semi-linear structure of the reverse SDE.\nThese improvements enable stable training and sampling of diffusion models without relying on time truncation.\nIn our experiments, we tested the effectiveness of our method on the CIFAR-10 and ImageNet-32 datasets by evaluating the test likelihood and the sample quality measured by the Fr\u00e9chet inception distance (FID). \nWe observe that our method consistently improve performance in both test likelihood and the FID compared to the baseline model of DDPM++.", "title_embedding_index": 16551, "title_abs_embedding_index": 16576}, {"title": "Text Attributed Graph Node Classification Using Sheaf Neural Networks and Large Language Models", "link_suffix": "/forum?id=V8cMqUZT8o", "link": "https://openreview.net/forum?id=V8cMqUZT8o", "pdf_link": "https://openreview.net/pdf?id=V8cMqUZT8o", "keywords": "Text Attributed Graph, Sheaf Neural Networks, Large Language Models", "abstract": "Text-Attributed Graphs (TAGs) seamlessly integrate textual data with graph structures, presenting unique challenges and opportunities for jointly modeling text and graph information. Recent advancements in Large Language Models (LLMs) have significantly enhanced the generative and predictive capabilities of text modeling. However, existing graph models often fall short in capturing intricate node relationships, as their edge representations are typically limited to scalar values.In this paper, we introduce \\model, a novel method that encodes rich and complex relational information between nodes as edge vectors. During the message-passing phase, \\model aggregates both neighbor node representations and edge vectors to update the central node's representation, eliminating the need to fine-tune the LLMs on the text-attributed graph.Specifically, for a given TAG, \\model is trained to minimize the prediction errors of the LLM in forecasting the next word in node text sequences. Furthermore, we enhance \\model's performance by incorporating prompt-based fine-tuning techniques. Once trained, \\model can be seamlessly adapted to various downstream tasks.Extensive node classification experiments across multiple domains demonstrate that \\model consistently achieves state-of-the-art performance, validating its effectiveness in capturing complex relationships within TAGs. Additionally, we conduct ablation studies and scalability analyses to ensure the robustness and applicability of our approach.", "title_embedding_index": 16552, "title_abs_embedding_index": 16577}, {"title": "HQGS: High-Quality Novel View Synthesis with Gaussian Splatting in Degraded Scenes", "link_suffix": "/forum?id=25Zlvl7JxW", "link": "https://openreview.net/forum?id=25Zlvl7JxW", "pdf_link": "https://openreview.net/pdf?id=25Zlvl7JxW", "keywords": "3D Reconstruction, 3D Gaussian Splatting", "abstract": "3D Gaussian Splatting (3DGS) has shown promising results for Novel View Synthesis. However, while it is quite effective when based on high-quality images, its performance declines as image quality degrades, due to lack of resolution, motion blur, noise, compression artifacts, or other factors common in real-world data collection. While some solutions have been proposed for specific types of degradation, general techniques are still missing. To address the problem, we propose a robust HQGS that significantly enhances the 3DGS under various degradation scenarios. We first analyze that 3DGS lacks sufficient attention in some detailed regions in low-quality scenes, leading to the absence of Gaussian primitives in those areas and resulting in loss of detail in the rendered images. To address this issue, we focus on leveraging edge structural information to provide additional guidance for 3DGS, enhancing its robustness. First, we introduce an edge-semantic fusion guidance module that combines rich texture information from high-frequency edge-aware maps with semantic information from images. The fused features serve as prior guidance to capture detailed distribution across different regions, bringing more attention to areas with a higher concentration of Gaussian primitives. Additionally, we present a structural cosine similarity loss to complement pixel-level constraints, further improving the quality of the rendered images. Extensive experiments demonstrate that our method offers better robustness and achieves the best results across various degraded scenes. The source code and trained models will be made available to the public.", "title_embedding_index": 16553, "title_abs_embedding_index": 16578}, {"title": "A Reoptimization Framework for Mixed Integer Linear Programming with Dynamic Parameters", "link_suffix": "/forum?id=scdGzuwC9u", "link": "https://openreview.net/forum?id=scdGzuwC9u", "pdf_link": "https://openreview.net/pdf?id=scdGzuwC9u", "keywords": "Mixed Integer Linear Programming; reoptimization;", "abstract": "Many real-world applications, such as logistics, routing, scheduling, and production planning, involve dynamic systems that require continuous updates to solutions for new Mixed Integer Linear Programming (MILP) problems. These new instances may differ in parameters like objective functions, constraints, and variable bounds. While reoptimization techniques have been explored for Linear Programming (LP) and specific MILP problems, their effectiveness in general MILP is limited. In this work, we propose a two-stage reoptimization framework for efficiently identifying high-quality feasible solutions. Specifically, we first utilize the historical solving process information to predict the high confidence solving space for modified MILPs to contain high-quality solutions. Based on the prediction results, we fix a part of variables to apply the prediction intervals and use the Thompson Sampling algorithm to determine the set of variables to fix and optimize the predicted probability with the updates of solutions from the solver. Extensive experiments across nine reoptimization datasets show that our VP-OR outperforms the state-of-the-art methods, achieving highly accurate solutions under strict time limits and demonstrating faster convergence with smaller primal gaps.", "title_embedding_index": 16554, "title_abs_embedding_index": 16579}, {"title": "Interpretable Boundary-based Watermark Up to the condition of Lov\\'asz Local Lemma", "link_suffix": "/forum?id=xyysYa4YvF", "link": "https://openreview.net/forum?id=xyysYa4YvF", "pdf_link": "https://openreview.net/pdf?id=xyysYa4YvF", "keywords": "Watermark, Model extraction attacks, Intellectual property protection", "abstract": "Watermarking techniques have emerged as pivotal safeguards to defend the intellectual property of deep neural networks against model extraction attacks. Most existing watermarking methods rely on the identification of samples within randomly selected trigger sets. However, this paradigm is inevitably disrupted by the ambiguous points that exhibit poor discriminability, thus leading to the misidentification between benign and stolen models. To tackle this issue, in this paper, we propose a boundary-based watermarking method that enhances the discernibility of trigger set, further improving the ability in distinguish benign and stolen models. Specifically, we select trigger samples on the decision boundary of base model and assigned them labels with the least probabilities, while providing a tight bound based on the Lov'asz Local Lemma. This approach ensures the watermark's reliability in identifying stolen models by improving discriminability of trigger samples. Meanwhile, we provide theoretical proof to demonstrate that the watermark can be effectively guaranteed under the constraints guided by the Lov'asz Local Lemma. Experimental results demonstrate that our method outperforms the state-of-the-art watermarking methods on CIFAR-10, CIFAR-100 and ImageNet datasets. Code and data will be released publicly upon the paper acceptance.", "title_embedding_index": 16555, "title_abs_embedding_index": 16580}, {"title": "CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation", "link_suffix": "/forum?id=vaEPihQsAA", "link": "https://openreview.net/forum?id=vaEPihQsAA", "pdf_link": "https://openreview.net/pdf?id=vaEPihQsAA", "keywords": "Audio-driven Human Animation.+Diffusion Model.+Generative Model.+Human Video Generation", "abstract": "Diffusion-based video generation technology has advanced significantly, catalyzing a proliferation of research in human animation. While breakthroughs have been made in driving human animation through various modalities for portraits, most of current solutions for human body animation still focus on video-driven methods, leaving audio-driven taking body generation relatively underexplored. In this paper, we introduce CyberHost, a one-stage audio-driven talking body generation framework that addresses common synthesis degradations in half-body animation, including hand integrity, identity consistency, and natural motion.\nCyberHost's key designs are twofold. Firstly, the Region Attention Module (RAM) maintains a set of learnable, implicit, identity-agnostic latent features and combines them with identity-specific local visual features to enhance the synthesis of critical local regions. Secondly, the Human-Prior-Guided Conditions introduce more human structural priors into the model, reducing uncertainty in generated motion patterns and thereby improving the stability of the generated videos.\nTo our knowledge, CyberHost is the first one-stage audio-driven human diffusion model capable of zero-shot video generation for the human body. Extensive experiments demonstrate that CyberHost surpasses previous works in both quantitative and qualitative aspects. CyberHost can also be extended to video-driven and audio-video hybrid-driven scenarios, achieving similarly satisfactory results.", "title_embedding_index": 16556, "title_abs_embedding_index": 16581}, {"title": "Seeker: Enhancing Exception Handling in Code with a LLM-based Multi-Agent Approach", "link_suffix": "/forum?id=kNvwWXp6xD", "link": "https://openreview.net/forum?id=kNvwWXp6xD", "pdf_link": "https://openreview.net/pdf?id=kNvwWXp6xD", "keywords": "Alignment, Code Generation, Code Robustness, Agent Framework, RAG", "abstract": "In real-world software development, improper or missing exception handling can severely impact the robustness and reliability of code. Exception handling mechanisms require developers to detect, capture, and manage exceptions according to high standards, but many developers struggle with these tasks, leading to fragile code. This problem is particularly evident in open-source projects and impacts the overall quality of the software ecosystem.\nTo address this challenge, we explore the use of large language models (LLMs) to improve exception handling in code. Through extensive analysis, we identify three key issues: Insensitive Detection of Fragile Code, Inaccurate Capture of Exception Types, and Distorted Handling Solutions. These problems are widespread across real-world repositories, suggesting that robust exception handling practices are often overlooked or mishandled.\nIn response, we propose \\emph{Seeker}, a multi-agent framework inspired by expert developer strategies for exception handling. Seeker uses agents\u2014Scanner, Detector, Predator, Ranker, and Handler\u2014to assist LLMs in detecting, capturing, and resolving exceptions more effectively. Our work is the first systematic study on leveraging LLMs to enhance exception handling practices, providing valuable insights for future improvements in code reliability.", "title_embedding_index": 16557, "title_abs_embedding_index": 16582}, {"title": "Redefining Temporal Modeling in Video Diffusion: The Vectorized Timestep Approach", "link_suffix": "/forum?id=XYuWS3nrw3", "link": "https://openreview.net/forum?id=XYuWS3nrw3", "pdf_link": "https://openreview.net/pdf?id=XYuWS3nrw3", "keywords": "Diffusion Model, Video Generation, Image-to-Video Generation, Video Interpolation, Long Video Generation, Zero-Shot", "abstract": "Diffusion models have revolutionized image generation, and their extension to video generation has shown promise. However, current video diffusion models (VDMs) rely on a scalar timestep variable applied at the clip level, which limits their ability to model complex temporal dependencies needed for various tasks like image-to-video generation. To address this limitation, we propose a frame-aware video diffusion model (FVDM), which introduces a novel vectorized timestep variable (VTV). Unlike conventional VDMs, our approach allows each frame to follow an independent noise schedule, enhancing the model's capacity to capture fine-grained temporal dependencies.\nFVDM's flexibility is demonstrated across multiple tasks, including standard video generation, image-to-video generation, video interpolation, and long video synthesis. Through a diverse set of VTV configurations, we achieve superior quality in generated videos, overcoming challenges such as catastrophic forgetting during fine-tuning and limited generalizability in zero-shot methods.\nOur empirical evaluations show that FVDM outperforms state-of-the-art methods in video generation quality, while also excelling in extended tasks. By addressing fundamental shortcomings in existing VDMs, FVDM sets a new paradigm in video synthesis, offering a robust framework with significant implications for generative modeling and multimedia applications.", "title_embedding_index": 16558, "title_abs_embedding_index": 16583}, {"title": "Energy and Memory-Efficient Federated Learning with Ordered Layer Freezing and Tensor Operation Approximation", "link_suffix": "/forum?id=xbW6EGve6a", "link": "https://openreview.net/forum?id=xbW6EGve6a", "pdf_link": "https://openreview.net/pdf?id=xbW6EGve6a", "keywords": "Federated Learning, Resource-Constrained devices, Computation and Communication Overheads, Layer Freezing, Tensor Operation Approximation", "abstract": "The effectiveness of Federated Learning (FL) in the context of the Internet of Things (IoT) is hindered by the resource constraints of IoT devices, such as limited computing capability, memory space and bandwidth support. These constraints create significant computation and communication bottlenecks for training and transmitting deep neural networks. Various FL frameworks have been proposed to reduce computation and communication overheads through dropout or layer freezing. However, these approaches often sacrifice accuracy or neglect memory constraints. In this work, we introduce Federated Learning with Ordered Layer Freezing (FedOLF) to improve energy efficiency and reduce memory footprint while maintaining accuracy. Additionally, we employ the Tensor Operation Approximation technique to reduce the communication (and accordingly energy) cost, which can better preserve accuracy compared to traditional quantization methods. Experimental results demonstrate that FedOLF achieves higher accuracy and energy efficiency as well as lower memory footprint across EMNIST, CIFAR-10, CIFAR-100, and CINIC-10 benchmarks compared to existing methods.", "title_embedding_index": 16559, "title_abs_embedding_index": 16584}, {"title": "Cyclic Contrastive Knowledge Transfer for Open-Vocabulary Object Detection", "link_suffix": "/forum?id=JU9oHs7ivN", "link": "https://openreview.net/forum?id=JU9oHs7ivN", "pdf_link": "https://openreview.net/pdf?id=JU9oHs7ivN", "keywords": "Contrastive Learning, Knowledge Transfer, Open-Vocabulary Object Detection", "abstract": "In pursuit of detecting unstinted objects that extend beyond predefined categories, prior arts of open-vocabulary object detection (OVD) typically resort to pretrained vision-language models (VLMs) for base-to-novel category generalization. However, to mitigate the misalignment between upstream image-text pretraining and downstream region-level perception, additional supervisions are indispensable, e.g., image-text pairs or pseudo annotations generated via self-training strategies. In this work, we propose CCKT-Det trained without any extra supervision. The proposed framework constructs a cyclic and dynamic knowledge transfer from language queries and visual region features extracted from VLMs, which forces the detector to closely align with the visual-semantic space of VLMs. Specifically, 1) we prefilter and inject semantic priors to guide the learning of queries, and 2) introduce a regional contrastive loss to improve the awareness of queries on novel objects. CCKT-Det can consistently improve performance as the scale of VLMs increases, all while requiring the detector at a moderate level of computation overhead. Comprehensive experimental results demonstrate that our method achieves performance gain of +2.9% and +10.2% AP_{50} over previous state-of-the-arts on the challenging COCO benchmark, both without and with a stronger teacher model.", "title_embedding_index": 16560, "title_abs_embedding_index": 16585}, {"title": "Towards Reliable Offline Reinforcement Learning via Lyapunov Uncertainty Control", "link_suffix": "/forum?id=fWx1CKgPCc", "link": "https://openreview.net/forum?id=fWx1CKgPCc", "pdf_link": "https://openreview.net/pdf?id=fWx1CKgPCc", "keywords": "Offline reinforcement learning; Reliable offline reinforcement learning; Lyapunov Uncertainty Control;", "abstract": "Learning trustworthy and reliable offline policies presents significant challenges due to the inherent uncertainty in pre-collected datasets. In this paper, we propose a novel offline reinforcement learning method to tackle this issue. Inspired by the concepts of Lyapunov stability and control-invariant sets from control theory, the central idea is to introduce a restricted state space for the agent to operate within. This approach allows the learned models to exhibit reduced Bellman uncertainty and make reliable decisions. To achieve this, we regulate the expected Bellman uncertainty associated with the new policy, ensuring that its growth trend in subsequent states remains within acceptable limits. The resulting method, termed Lyapunov Uncertainty Control (LUC), is shown to guarantee that the agent remains within a low-uncertainty state enclosure throughout its entire trajectory. \nFurthermore, we perform extensive theoretical and experimental analysis to showcase the effectiveness and feasibility of the proposed LUC.", "title_embedding_index": 16561, "title_abs_embedding_index": 16586}, {"title": "Transformer Meets Twicing: Harnessing Unattended Residual Information", "link_suffix": "/forum?id=16kG5aNleS", "link": "https://openreview.net/forum?id=16kG5aNleS", "pdf_link": "https://openreview.net/pdf?id=16kG5aNleS", "keywords": "transformers, self-attention, oversmoothing, nonlocal smoothing, nonparametric regression", "abstract": "Transformer-based deep learning models have achieved state-of-the-art performance across numerous language and vision tasks. While the self-attention mechanism, a core component of transformers, has proven capable of handling complex data patterns, it has been observed that the representational capacity of the attention matrix degrades significantly across transformer layers, thereby hurting its overall performance. In this work, we leverage the connection between self-attention computations and low-pass non-local means  (NLM) smoothing filters and propose the Twicing Attention, a novel attention mechanism that useskernel twicing procedurein nonparametric regression to alleviate the low-pass behavior of associated NLM smoothing with compelling theoretical guarantees. This approach enables the extraction and reuse of meaningful information retained in the residuals following the imperfect smoothing operation at each layer. Our proposed method offers two key advantages over standard self-attention: 1) a provably slower decay of representational capacity and 2) improved accuracy across various data modalities and tasks. We empirically demonstrate the performance gains of our model over baseline transformers on multiple tasks and benchmarks, including image classification and language modeling, on both clean and corrupted data.", "title_embedding_index": 16562, "title_abs_embedding_index": 16587}, {"title": "Learning-based Mechanism Design: Scalable, Truthful, and Continuum Approaches for Utility Maximization", "link_suffix": "/forum?id=ga4LyaucKr", "link": "https://openreview.net/forum?id=ga4LyaucKr", "pdf_link": "https://openreview.net/pdf?id=ga4LyaucKr", "keywords": "automated mechanism design, differential economics, function approximation, mechanism representation", "abstract": "Mechanism design is a crucial topic at the intersection of computer science and economics. \nThis paper addresses the automated mechanism design problem by leveraging machine learning and neural networks. \nThe objective is to design atruthful,expressiveandefficientmechanism that maximizes the platform's expected utility, given that the players' types are drawn from a pre-specified distribution.We present a general mechanism design model that captures two critical features: hidden information and strategic behavior. \nSubsequently, we propose thePFM-Netframework, which parameterizes the menu mechanism class by function approximation and identifies an optimal mechanism through ingenious optimization techniques. \nWe also provide both theoretical and empirical justifications for the advantages of our approach. \nExperimental results demonstrate the effectiveness of PFM-Net over traditional and learning-based baselines, \nenabling the PFM-Net framework to serve as a new paradigm for automated mechanism design.", "title_embedding_index": 16563, "title_abs_embedding_index": 16588}, {"title": "SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction", "link_suffix": "/forum?id=Bmzv2Gch9v", "link": "https://openreview.net/forum?id=Bmzv2Gch9v", "pdf_link": "https://openreview.net/pdf?id=Bmzv2Gch9v", "keywords": "Motion Prediction, Trajectory Prediction, Autonomous Driving, Self-Supervised Learning", "abstract": "Predicting the future motion of surrounding agents is essential for autonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed environments. However, the scarcity of large-scale driving datasets has hindered the development of robust and generalizable motion prediction models, limiting their ability to capture complex interactions and road geometries. Inspired by recent advances in natural language processing (NLP) and computer vision (CV), self-supervised learning (SSL) has gained significant attention in the motion prediction community for learning rich and transferable scene representations. Nonetheless, existing pre-training methods for motion prediction have largely focused on specific model architectures and single dataset, limiting their scalability and generalizability.\nTo address these challenges, we propose SmartPretrain, a general and scalable SSL framework for motion prediction that is both model-agnostic and dataset-agnostic. Our approach integrates contrastive and reconstructive SSL, leveraging the strengths of both generative and discriminative paradigms to effectively represent spatiotemporal evolution and interactions without imposing architectural constraints. Additionally, SmartPretrain employs a dataset-agnostic scenario sampling strategy that integrates multiple datasets, enhancing data volume, diversity, and robustness.\nExtensive experiments on multiple datasets demonstrate that SmartPretrain consistently improves the performance of state-of-the-art prediction models across datasets, data splits and main metrics. For instance, SmartPretrain significantly reduces the MissRate of Forecast-MAE by 10.6%. These results highlight SmartPretrain's effectiveness as a unified, scalable solution for motion prediction, breaking free from the limitations of the small-data regime.", "title_embedding_index": 16564, "title_abs_embedding_index": 16589}, {"title": "Examining Why Perturbation-Based Fidelity Metrics are Inconsistent", "link_suffix": "/forum?id=HNJJEWfo0Z", "link": "https://openreview.net/forum?id=HNJJEWfo0Z", "pdf_link": "https://openreview.net/pdf?id=HNJJEWfo0Z", "keywords": "Fidelity Metric, Perturbation, Inconsistency, XAI, Explainability, Interpretability", "abstract": "Saliency maps are commonly employed as a post-hoc method to explain the decision-making processes of Deep Learning models. Despite their widespread use, ensuring the fidelity of saliency maps is challenging due to the absence of ground truth. Therefore, researchers have developed fidelity metrics to evaluate the fidelity of saliency maps. However, prior investigations have uncovered statistical inconsistencies in existing fidelity metrics using multiple perturbation techniques without delving into the underlying causes. Our study aims to explore the origins of these observed inconsistencies. Our analysis examines the correctness of the assumptions made by the existing fidelity metrics using different types of perturbation to perturb the images. Our findings reveal that the assumptions made by existing fidelity metrics do not always hold true. Consequently, the existing fidelity metrics become inconsistent and unreliable. Thus, we recommend a cautious interpretation of fidelity metrics and the choice of perturbation technique when evaluating the fidelity of saliency maps in eXplainable Artificial Intelligence (XAI) applications.", "title_embedding_index": 16565, "title_abs_embedding_index": 16590}, {"title": "Enhancing Solutions for Complex PDEs: Introducing Translational Equivariant Attention in Fourier Neural Operators", "link_suffix": "/forum?id=ZtTgoomrT1", "link": "https://openreview.net/forum?id=ZtTgoomrT1", "pdf_link": "https://openreview.net/pdf?id=ZtTgoomrT1", "keywords": "Attentive Equivariant Convolution, Fourier Neural Operator", "abstract": "Neural operators extend conventional neural networks by expanding their functional mapping capabilities across various function spaces, thereby promoting the solving of partial differential equations (PDEs). A particularly notable method within this framework is the Fourier Neural Operator (FNO), which draws inspiration from Green's function method to directly approximate operator kernels in the frequency domain. However, after empirical observation and theoretical validation, we demonstrate that the FNO predominantly approximates operator kernels within the low-frequency domain. This limitation results in a restricted capability to solve complex PDEs, particularly those characterized by rapidly changing coefficients and highly oscillatory solution spaces. To address this challenge, inspired by the attentive equivariant convolution, we propose a novel \\textbf{T}ranslational \\textbf{E}quivariant \\textbf{F}ourier \\textbf{N}eural \\textbf{O}perator (\\textbf{TE-FNO}) which utilizes equivariant attention to enhance the ability of FNO to capture high-frequency features. We perform experiments on forward and reverse problems of multiscale elliptic equations, Navier-Stokes equations, and other physical scenarios. The results demonstrate that the proposed approach achieves superior performance across these benchmarks, particularly for equations characterized by rapid coefficient variations.", "title_embedding_index": 16566, "title_abs_embedding_index": 16591}, {"title": "Test-time Zero-shot Recognition with Good Attributes", "link_suffix": "/forum?id=A78MiKnGrL", "link": "https://openreview.net/forum?id=A78MiKnGrL", "pdf_link": "https://openreview.net/pdf?id=A78MiKnGrL", "keywords": "Test-time adaptation, prompt learning, attribute search, soft voting, vision recognition", "abstract": "Test-time adaptation (TTA) has emerged as a zero-shot learning approach to address distribution shifts across domains without needing source data. While current methods focus on adapting vision and language models (VLMs) using prompt tuning, they struggle with ambiguous categories due to the challenge of selecting relevant attributes in the absence of labels. To address this issue, we propose a novel framework, termed Search4Prompt, which aims to identify \"good'' attributes and learn tailored prompts during test-time prompt learning (TTPL). Search4Prompt consists of two main components: the Retrieve-based Attribute Search (RAS) and the Implicit-Explicit Attribute Injection (IEAI) module. RAS constructs an attribute bank by generating detailed descriptions for predefined categories, and then identifies the most relevant attributes based on the semantic similarity between the test image and the attributes. This enables the selection of \"good\" attributes that are well-suited to the test samples. The IEAI module operates in two ways. First, it employs pseudo-label learning, where the selected attributes contribute to a voting process that implicitly injects attribute knowledge into prompt learning. Second, it augments the original category names with the selected attributes, explicitly enhancing the semantic representation of ambiguous categories. This dual approach improves the model's discriminability during test-time prompt learning. Experimental results demonstrate that Search4Prompt outperforms existing TTA methods on several benchmark datasets, confirming its effectiveness in narrowing domain gaps and handling ambiguous categories.", "title_embedding_index": 16567, "title_abs_embedding_index": 16592}, {"title": "GAOKAO-Eval: Does High Scores Truly Reflect Strong Capabilities in LLMs?", "link_suffix": "/forum?id=1tZLONFMjm", "link": "https://openreview.net/forum?id=1tZLONFMjm", "pdf_link": "https://openreview.net/pdf?id=1tZLONFMjm", "keywords": "Large Language Model, Benchmark", "abstract": "Large Language Models (LLMs) are commonly evaluated using human-crafted benchmarks, under the premise that higher scores implicitly reflect stronger human-like performance. However, there is growing concern that LLMs may \u201cgame\u201d these benchmarks due to data leakage, achieving high scores while struggling with tasks straightforward for humans. \nTo substantively address the problem, we create GAOKAO-Eval, a comprehensive benchmark based on China's National College Entrance Examination (Gaokao) and conduct closed-book evaluations for representative models released prior to Gaokao.\nContrary to prevailing consensus, even when addressing data leakage and comprehensiveness, GAOKAO-Eval reveals that high scores still fail to truly reflect human-aligned capabilities. To better understand this mismatch, We introduce the Rasch model from cognitive psychology to analyze LLM scoring patterns and identify two key discrepancies: 1) anomalous consistant  performance across various question difficultiess, and 2) high variance in performance on questions of similar difficulty. In addition, we identified inconsistent grading of LLM-generated answers among teachers and recurring mistake patterns. we find that the phenomenon are well-grounded in the motivations behind OpenAI o1, and o1's reasoning-as-difficulties can mitigate the mismatch. These results show that GAOKAO-Eval can reveal limitations in LLM capabilities not captured by current benchmarks and highlight the need for more LLM-aligned difficulty analysis.", "title_embedding_index": 16568, "title_abs_embedding_index": 16593}, {"title": "Adversarial Robustness Overestimation and Instability in TRADES", "link_suffix": "/forum?id=qx07JhIs8E", "link": "https://openreview.net/forum?id=qx07JhIs8E", "pdf_link": "https://openreview.net/pdf?id=qx07JhIs8E", "keywords": "Adversarial training, Robustness, Obfuscated gradients, TRADES", "abstract": "This paper examines the phenomenon of probabilistic robustness overestimation in TRADES, a prominent adversarial training method. Our study reveals that TRADES sometimes yields disproportionately high PGD validation accuracy compared to the AutoAttack testing accuracy in the multiclass classification task. This discrepancy highlights a significant overestimation of robustness for these instances, potentially linked to gradient masking. We further analyze the parameters contributing to unstable models that lead to overestimation. Our findings indicate that smaller batch sizes, lower beta values (which control the weight of the robust loss term in TRADES), larger learning rates, and higher class complexity (e.g., CIFAR-100 versus CIFAR-10) are associated with an increased likelihood of robustness overestimation. By examining metrics such as the First-Order Stationary Condition (FOSC), inner-maximization, and gradient information, we identify the underlying cause of this phenomenon as gradient masking and provide insights into it. Furthermore, our experiments show that certain unstable training instances may return to a state without robust overestimation, inspiring our attempts at a solution. In addition to adjusting parameter settings to reduce instability or retraining when overestimation occurs, we recommend incorporating Gaussian noise in inputs when the FOSC score exceed the threshold. This method aims to mitigate robustness overestimation of TRADES and other similar methods at its source, ensuring more reliable representation of adversarial robustness during evaluation.", "title_embedding_index": 16569, "title_abs_embedding_index": 16594}, {"title": "Jump Your Steps: Optimizing Sampling Schedule of Discrete Diffusion Models", "link_suffix": "/forum?id=pD6TiCpyDR", "link": "https://openreview.net/forum?id=pD6TiCpyDR", "pdf_link": "https://openreview.net/pdf?id=pD6TiCpyDR", "keywords": "Discrete diffusion models, Efficient sampling", "abstract": "Diffusion models have seen notable success in continuous domains, leading to the development of discrete diffusion models (DDMs) for discrete variables. Despite recent advances, DDMs face the challenge of slow sampling speeds. While parallel sampling methods like $\\tau$-leaping accelerate this process, they introduceCompounding Decoding Error(CDE), where discrepancies arise between the true distribution and the approximation from parallel token generation, leading to degraded sample quality. In this work, we presentJump Your Steps(JYS), a novel approach that optimizes the allocation of discrete sampling timesteps by minimizing CDE without extra computational cost. More precisely, we derive a practical upper bound on CDE and propose an efficient algorithm for searching for the optimal sampling schedule. Extensive experiments across image, music, and text generation show that JYS significantly improves sampling quality, establishing it as a versatile framework for enhancing DDM performance for fast sampling.", "title_embedding_index": 16570, "title_abs_embedding_index": 16595}, {"title": "Trusted Multi-View Classification via Evolutionary Multi-View Fusion", "link_suffix": "/forum?id=M3kBtqpys5", "link": "https://openreview.net/forum?id=M3kBtqpys5", "pdf_link": "https://openreview.net/pdf?id=M3kBtqpys5", "keywords": "Trusted multi-view classification, evolutionary multi-view fusion, multi-view learning", "abstract": "Multi-view classification methodologies grounded in the Dempster-Shafer theory, renowned for their reliability in decision-making, have garnered significant application across various safety-critical domains due to their capacity to provide a degree of trustworthiness for each view. However, the adoption of a late fusion strategy by these methodologies constrains the interaction of information among views, thereby leading to suboptimal utilization of multi-view data. A recent advancement aimed at mitigating this limitation involves the generation of a pseudo view by concatenating all individual views. Nonetheless, the effectiveness of this pseudo view may be compromised when incorporating underperforming views, such as those afflicted by noise. Furthermore, the integration of a pseudo view exacerbates the issue of imbalanced multi-view learning, as it contains a disproportionate amount of information compared to individual views. To address these multifaceted challenges, we propose an approach termed Enhancing Trusted multi-view classification via Evolutionary multi-view Fusion (TEF). Specifically, we introduce an evolutionary multi-view architecture search method to generate a high-quality fusion architecture serving as the pseudo view, thus enabling adaptive selection of views and fusion operators. Subsequently, each view within the fusion architecture is enhanced by concatenating the decision output of the fusion architecture with its respective view. Our experimental findings underscore the efficacy of this straightforward yet potent strategy in mitigating the imbalanced multi-view learning problem, consequently enhancing TEF's performance, particularly on complex many-view datasets featuring more than three views compared to its counterparts. Comprehensive experimental evaluations conducted on six multi-view datasets corroborate the superior performance of our proposed method over other trusted multi-view learning approaches.", "title_embedding_index": 16571, "title_abs_embedding_index": 16596}, {"title": "Knapsack Schema Linking Agent for LLM-Based Text-to-SQL Generation", "link_suffix": "/forum?id=JffVqPWQgg", "link": "https://openreview.net/forum?id=JffVqPWQgg", "pdf_link": "https://openreview.net/pdf?id=JffVqPWQgg", "keywords": "Large Language Models, Text-to-SQL, Schema Linking", "abstract": "Generating SQLs according to user queries (text-to-SQL) is a long-standing sequential challenge, where the accuracy of the initial schema linking significantly impacts the subsequent SQL generation performance. However, existing models often focus more on SQL generation and less on the schema linking task, leading to potential missing or redundant schema linking and suboptimal SQL generation performance. The underlying reason is that schema linking is not a simple selection problem but a \\textbf{Knapsack problem}, which should consider both the \\textit{value} of the schema linking in terms of missing important information and the \\textit{weight} of the schema linking in terms of providing redundant information. Motivated by this, we provide two tailored SL benchmarks and two tailored metrics to train SL agents and to evaluate the missing and redundant schema linking. In this paper, we propose the \\textbf{\\underline{K}n\\underline{a}psack \\underline{S}chema \\underline{L}inking \\underline{A}gent (KaSLA)}, which can link the most valuable and least redundant schema subsets for both tables and columns. KaSLA proposes a nomination-guaranteed score function to predict the importance score of each schema, and then utilizes the importance score to estimate the value and the weight of each schema. Then, by estimating the capacity of a given user query from historical SQL records, KaSLA employs efficient dynamic programming to select the most valuable schema set within the estimated capacity. Extensive experiments on two benchmark datasets demonstrate the superior performance of KaSLA over 12 state-of-the-art baselines. Especially on the popular and challenging BIRD benchmark, KaSLA can outperform the baselines by over 5.72%.", "title_embedding_index": 16572, "title_abs_embedding_index": 16597}, {"title": "3D Vision-Language Gaussian Splatting", "link_suffix": "/forum?id=SSE9myD9SG", "link": "https://openreview.net/forum?id=SSE9myD9SG", "pdf_link": "https://openreview.net/pdf?id=SSE9myD9SG", "keywords": "3D Scene Understanding, Gaussian Splatting, Open-vocabulary Semantic Segmentation", "abstract": "Recent advancements in 3D reconstruction methods and vision-language models have propelled the development of multi-modal 3D scene understanding, which has vital applications in robotics, autonomous driving, and virtual/augmented reality. However, current multi-modal scene understanding approaches have naively embedded semantic representations into 3D reconstruction methods without striking a balance between visual and language modalities, which leads to unsatisfying semantic rasterization of translucent or reflective objects, as well as over-fitting on color modality. To alleviate these limitations, we propose a solution that adequately handles the distinct visual and semantic modalities, i.e., a 3D vision-language Gaussian splatting model for scene understanding, to put emphasis on the representation learning of language modality. We propose a novel cross-modal rasterizer, using modality fusion along with a smoothed semantic indicator for enhancing semantic rasterization. We also employ a camera-view blending technique to improve semantic consistency between existing and synthesized views, thereby effectively mitigating over-fitting. Extensive experiments demonstrate that our method achieves state-of-the-art performance in open-vocabulary semantic segmentation, surpassing existing methods by a significant margin.", "title_embedding_index": 16573, "title_abs_embedding_index": 16598}, {"title": "DAPE V2: Process Attention Score as Feature Map for Length Extrapolation", "link_suffix": "/forum?id=XT1Cx6cH2a", "link": "https://openreview.net/forum?id=XT1Cx6cH2a", "pdf_link": "https://openreview.net/pdf?id=XT1Cx6cH2a", "keywords": "Transformers, data-adaptive positional encoding, long context, length generalization", "abstract": "The attention mechanism is a fundamental component of the Transformer model, contributing to interactions among distinct tokens, in contrast to earlier feed-forward neural networks. In general, the attention scores are determined simply by the key-query products. However, this work's occasional trial (combining DAPE and NoPE) of including additional MLPs on attention scores without position encoding indicates that the classical key-query multiplication may limit the performance of Transformers. \nIn this work, we conceptualize attention as a feature map and apply the convolution operator (for neighboring attention scores across different heads) to mimic the processing methods in computer vision. Specifically,the main contribution of this paper is identifying and interpreting the Transformer length extrapolation problem as a result of the limited expressiveness of the naive query and key dot product, and we successfully translate the length extrapolation issue into a well-understood feature map processing problem.The novel insight, which can be adapted to various attention-related models, reveals that the current Transformer architecture has the potential for further evolution.  Extensive experiments demonstrate that treating attention as a feature map and applying convolution as a processing method significantly enhances Transformer performance.", "title_embedding_index": 16574, "title_abs_embedding_index": 16599}]
[{"title": "Step-Controlled DPO: Leveraging Stepwise Errors for Enhancing Mathematical Reasoning of Language Models", "link_suffix": "/forum?id=ZRDa2IT1sQ", "link": "https://openreview.net/forum?id=ZRDa2IT1sQ", "pdf_link": "https://openreview.net/pdf?id=ZRDa2IT1sQ", "keywords": "large language model, mathematical reasoning, alignment with relative feedback", "abstract": "Direct Preference Optimization (DPO) has proven effective at improving the performance of large language models (LLMs) on downstream tasks such as reasoning and alignment. In this work, we propose Step-Controlled DPO (SCDPO), a method for automatically providing stepwise error supervision by creating negative samples of mathematical reasoning rationales that start making errors at a specified step. By applying these samples in DPO training, SCDPO can better align the model to avoid reasoning errors and output accurate reasoning steps. Qualitative analysis of the credit assignment of SCDPO and DPO demonstrates the effectiveness of SCDPO at identifying errors in mathematical solutions. We then apply SCDPO to an InternLM2-20B model, resulting in a 20B model that achieves competitive scores of 88.5% on GSM8K and 58.1% on MATH, rivaling all other open-source LLMs, showing the great potential of our method. The code, models and data are released to inspire future work.", "title_embedding_index": 20800, "title_abs_embedding_index": 20825}, {"title": "From Graph Embedding to LKH: Bridging Learning and Heuristics for a Streamlined General TSP Solver", "link_suffix": "/forum?id=iXBYYbYTvX", "link": "https://openreview.net/forum?id=iXBYYbYTvX", "pdf_link": "https://openreview.net/pdf?id=iXBYYbYTvX", "keywords": "Traveling salesman problem, graph embedding", "abstract": "The Traveling Salesman Problem (TSP) is known as one of the most notorious NP-hard combinatorial optimization problems. \nIn recent decades, researchers from fields such as computer science, operations research, and artificial intelligence including deep learning (DL) have made numerous attempts on the problem. \nAmong the works, the Lin-Kernighan-Helsgaun (LKH) heuristic algorithm is one of the most competent methods for obtaining optimal or near-optimal solutions. \nDespite the rapid development in DL-based solvers, few of them can defeat LKH in terms of both running efficiency and solution quality across different distributions.\nIn this paper, we would introduce a very novel approach that enhances LKH with graph embedding (GE) techniques in solving general TSP (distances can be non-metric and asymmetric), named as Embed-LKH. \nIt is presented as two stages: i) in the GE stage, it transforms the distances to transition probabilities, then conduct GE given the transition probabilities, and finally it uses the learned embeddings to construct the so-called `ghost distances'; ii) in the LKH stage, LKH generates candidates based on the ghost distances but searches tours according to the original distances. As the experiments show, compared with the original LKH counterpart, in most cases, our approach can obtain better solutions within the same amount of trials across six distance distributions (non-metric and asymmetric: normal, uniform, exponential, metric and symmetric: Euclidean 2D/10D/50D) and two problem scales (TSP-100/1000). The source files, running scripts, and data will be made publicly available after the review.", "title_embedding_index": 20801, "title_abs_embedding_index": 20826}, {"title": "Adaptive Masking Enhances Visual Grounding", "link_suffix": "/forum?id=Ndq4g76MyH", "link": "https://openreview.net/forum?id=Ndq4g76MyH", "pdf_link": "https://openreview.net/pdf?id=Ndq4g76MyH", "keywords": "Vocabulary Grounding, multimodal", "abstract": "In recent years, zero-shot and few-shot learning in visual grounding have garnered considerable attention, largely due to the success of large-scale vision-language pre-training on expansive datasets such as LAION-5B and DataComp-1B. However, the continuous expansion of these datasets presents significant challenges, particularly with respect to data availability and computational overhead, thus creating a bottleneck in the advancement of low-shot learning capabilities. In this paper, we propose a novel approach, \\textbf{I}nterpretative \\textbf{MA}sking with \\textbf{G}aussian Radiation Mod\\textbf{E}ling, aimed at enhancing vocabulary grounding in low-shot learning scenarios without necessitating an increase in dataset size. Drawing inspiration from cognitive science and the recent success of masked autoencoders (MAE), our method leverages adaptive masking on salient regions of the feature maps generated by the vision backbone. This enables the model to learn robust, generalized representations through the reconstruction of occluded information, thereby facilitating effective attention to both local and global features. We evaluate the efficacy of our approach on benchmark datasets, including COCO and ODinW, demonstrating its superior performance in zero-shot and few-shot tasks. Experimental results consistently show that IMAGE outperforms baseline models, achieving enhanced generalization and improved performance in low-shot scenarios. These findings highlight the potential of adaptive feature manipulation through attention mechanisms and Gaussian modeling as a promising alternative to approaches that rely on the continual scaling of dataset sizes for the advancement of zero-shot and few-shot learning.", "title_embedding_index": 20802, "title_abs_embedding_index": 20827}, {"title": "Ensembles of Low-Rank Expert Adapters", "link_suffix": "/forum?id=l0gZS0sAlf", "link": "https://openreview.net/forum?id=l0gZS0sAlf", "pdf_link": "https://openreview.net/pdf?id=l0gZS0sAlf", "keywords": "Language Model, LoRA, MoE, Ensembles", "abstract": "The training and fine-tuning of large language models (LLMs) often involve diverse textual data from multiple sources, which poses challenges due to conflicting gradient directions, hindering optimization and specialization.  These challenges can undermine model generalization across tasks, resulting in reduced downstream performance.  Recent research suggests that fine-tuning LLMs on carefully selected, task-specific subsets of data can match or even surpass the performance of using the entire dataset.  Building on these insights, we propose the Ensembles of Low-Rank Expert Adapters (ELREA) framework to improve the model's capability to handle diverse tasks.  ELREA clusters the training instructions based on their gradient directions, representing different areas of expertise and thereby reducing conflicts during optimization.  Expert adapters are then trained on these clusters, utilizing the low-rank adaptation (LoRA) technique to ensure training efficiency and model scalability.  During inference, ELREA combines predictions from the most relevant expert adapters based on the input data's gradient similarity to the training clusters, ensuring optimal adapter selection for each task.  Experiments show that our method outperforms baseline LoRA adapters trained on the full dataset and other ensemble approaches with similar training and inference complexity across a range of domain-specific tasks.", "title_embedding_index": 20803, "title_abs_embedding_index": 20828}, {"title": "Does Refusal Training in LLMs Generalize to the Past Tense?", "link_suffix": "/forum?id=aJUuere4fM", "link": "https://openreview.net/forum?id=aJUuere4fM", "pdf_link": "https://openreview.net/pdf?id=aJUuere4fM", "keywords": "Jailbreaking, adversarial attacks, adversarial robustness, AI safety", "abstract": "Refusal training is widely used to prevent LLMs from generating harmful, undesirable, or illegal outputs. We reveal a curious generalization gap in the current refusal training approaches: simply reformulating a harmful request in the past tense (e.g.,\"How to make a Molotov cocktail?\"to\"How did people make a Molotov cocktail?\") is often sufficient to jailbreak many state-of-the-art LLMs. We systematically evaluate this method on Llama-3 8B, Claude-3.5 Sonnet, GPT-3.5 Turbo, Gemma-2 9B, Phi-3-Mini, GPT-4o-mini, GPT-4o, o1-mini, o1-preview, and R2D2 models using GPT-3.5 Turbo as a reformulation model. For example, the success rate of this simple attack on GPT-4o increases from 1% using direct requests to 88% using 20 past-tense reformulation attempts on harmful requests from JailbreakBench with GPT-4 as a jailbreak judge. Interestingly, we also find that reformulations in the future tense are less effective, suggesting that refusal guardrails tend to consider past historical questions more benign than hypothetical future questions. Moreover, our experiments on fine-tuning GPT-3.5 Turbo show that defending against past reformulations is feasible when past tense examples are explicitly included in the fine-tuning data. Overall, our findings highlight that the widely used alignment techniques---such as SFT, RLHF, and adversarial training---employed to align the studied models can be brittle and do not always generalize as intended.", "title_embedding_index": 20804, "title_abs_embedding_index": 20829}, {"title": "Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks", "link_suffix": "/forum?id=hXA8wqRdyV", "link": "https://openreview.net/forum?id=hXA8wqRdyV", "pdf_link": "https://openreview.net/pdf?id=hXA8wqRdyV", "keywords": "Jailbreaking, adversarial attacks, adversarial robustness, AI safety", "abstract": "We show that even the most recent safety-aligned LLMs are not robust to simpleadaptivejailbreaking attacks. First, we demonstrate how to successfully leverage access tologprobsfor jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize a target logprob (e.g., of the token``Sure''), potentially with multiple restarts. In this way, we achieve 100% attack success rate---according to GPT-4 as a judge---on Vicuna-13B, Mistral-7B, Phi-3-Mini, Nemotron-4-340B, Llama-2-Chat-7B/13B/70B, Llama-3-Instruct-8B, Gemma-7B, GPT-3.5, GPT-4o, and R2D2 from HarmBench that was adversarially trained against the GCG attack. We also show how to jailbreakallClaude models---that do not expose logprobs---via either a transfer or prefilling attack with a100% success rate. In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models---a task that shares many similarities with jailbreaking---which is the algorithm that brought us thefirst placein a recent trojan detection competition. The common theme behind these attacks is thatadaptivityis crucial: different models are vulnerable to different prompting templates (e.g., R2D2 is very sensitive to in-context learning prompts), some models have unique vulnerabilities based on their APIs (e.g., prefilling for Claude), and in some settings, it is crucial to restrict the token search space based on prior knowledge (e.g., for trojan detection).", "title_embedding_index": 20805, "title_abs_embedding_index": 20830}, {"title": "GUARANTEED USER FAIRNESS IN RECOMMENDATION", "link_suffix": "/forum?id=DqU4AB4wRy", "link": "https://openreview.net/forum?id=DqU4AB4wRy", "pdf_link": "https://openreview.net/pdf?id=DqU4AB4wRy", "keywords": "Recommendation Systems, Fairness in RS, Conformal Prediction", "abstract": "Although recommender systems (RS) have been well-developed for various fields of applications,\nthey suffer from the crisis of platform credibility with respect to RS confidence and fairness, which\nmay drive users away from the platform and result in the failure of the platform\u2019s long-term success.\nIn recent years, a few works have tried to solve either the model confidence or fairness issue,\nwhile there is no statistical guarantee for these methods. It is therefore an urgent need to solve\nboth issues with a unifying framework with statistical guarantee. In this paper, we propose a novel\nand reliable framework called Guaranteed User Fairness in Recommendation (GUFR) to dynamically\ngenerate prediction sets for users across various groups, which are guaranteed 1) to include\nthe ground-truth items with user-predefined high confidence/probability (e.g., 90%); 2) to ensure\nuser fairness across different groups; 3) to have the minimum average set size. We further design an\nefficient algorithm named Guaranteed User Fairness Algorithm (GUFA) to optimize the proposed\nmethod, and upper bounds of the risk and fairness metric are derived to help speed up the optimization\nprocess. Moreover, we provide rigorous theoretical analysis with respect to risk and fairness\ncontrol as well as the minimum set size. Extensive experiments also validate the effectiveness of the\nproposed framework, which aligns with our theoretical analysis. The code is publicly available athttps://anonymous.4open.science/r/GUFR-76EC.", "title_embedding_index": 20806, "title_abs_embedding_index": 20831}, {"title": "Parameter-Efficient Fine-Tuning of State Space Models", "link_suffix": "/forum?id=27n0kvWgqT", "link": "https://openreview.net/forum?id=27n0kvWgqT", "pdf_link": "https://openreview.net/pdf?id=27n0kvWgqT", "keywords": "parameter-efficient fine-tuning, state space model, mamba, lora", "abstract": "Deep State Space Models (SSMs), such as Mamba(Gu \\& Dao, 2023), have emerged as powerful tools for language modeling, offering high performance with efficient inference and linear scaling in sequence length. However, the application of parameter-efficient fine-tuning (PEFT) methods to SSM-based models remains largely unexplored. This paper aims to systematically study two key questions: (i) How do existing PEFT methods perform on SSM-based models? (ii) Which modules are most effective for fine-tuning? We conduct an empirical benchmark of four basic PEFT methods on SSM-based models. Our findings reveal that prompt-based methods (e.g., prefix-tuning) are no longer effective, an empirical result further supported by theoretical analysis. In contrast, LoRA remains effective for SSM-based models. We further investigate the optimal application of LoRA within these models, demonstrating both theoretically and experimentally that applying LoRA to linear projection matrices without modifying SSM modules yields the best results, as LoRA is not effective at tuning SSM modules. To further improve performance, we introduce LoRA with Selective Dimension tuning (SDLoRA), which selectively updates certain channels and states on SSM modules while applying LoRA to linear projection matrices. Extensive experimental results show that this approach outperforms standard LoRA.", "title_embedding_index": 20807, "title_abs_embedding_index": 20832}, {"title": "LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear Patterns for Robust Time Series Forecasting", "link_suffix": "/forum?id=JeZS4jQF77", "link": "https://openreview.net/forum?id=JeZS4jQF77", "pdf_link": "https://openreview.net/pdf?id=JeZS4jQF77", "keywords": "Time Series Forecasting, Deep learning.", "abstract": "Forecasting models are pivotal in a data-driven world with vast volumes of time series data that appear as a compound of vast $\\textbf{Li}$near and $\\textbf{No}$nlinear patterns. \nRecent deep time series forecasting models struggle to utilize seasonal and trend decomposition to separate the entangled components. Such a strategy only explicitly extracts simple linear patterns like trends, leaving the other linear modes and vast unexplored nonlinear patterns to the residual. Their flawed linear and nonlinear feature extraction models and shallow-level decomposition limit their adaptation to the diverse patterns present in real-world scenarios.\nGiven this, we innovate Recursive Residual Decomposition by introducing explicit extraction of both linear and nonlinear patterns. This deeper-level decomposition framework, which is named $\\textbf{LiNo}$, captures linear patterns using a Li block which can be a moving average kernel, and models nonlinear patterns using a No block which can be a Transformer encoder. The extraction of these two patterns is performed alternatively and recursively. To achieve the full potential of LiNo, we develop the current simple linear pattern extractor to a general learnable autoregressive model, and design a novel No block that can handle all essential nonlinear patterns.\nRemarkably, the proposed LiNo achieves state-of-the-art on thirteen real-world benchmarks under univariate and multivariate forecasting scenarios. Experiments show that current forecasting models can deliver more robust and precise results through this advanced Recursive Residual Decomposition. We hope this work could offer insight into designing more effective forecasting models. Code is available at this anonymous repository:https://anonymous.4open.science/r/LiNo-8225/.", "title_embedding_index": 20808, "title_abs_embedding_index": 20833}, {"title": "Compositional Risk Minimization", "link_suffix": "/forum?id=YtAhOVCy2t", "link": "https://openreview.net/forum?id=YtAhOVCy2t", "pdf_link": "https://openreview.net/pdf?id=YtAhOVCy2t", "keywords": "Compositional Generalization, Out of Distribution Generalization, Provable Extrapolation", "abstract": "In this work, we tackle a challenging and extreme form of subpopulation shift, which is termed compositional shift. Under compositional shifts, some combinations of attributes are totally absent from the training distribution but present in the test distribution. We model the data with flexible additive energy distributions, where each energy term represents an attribute, and derive a simple alternative to empirical risk minimization termed compositional risk minimization (CRM). We first train an additive energy classifier to predict the multiple attributes and then adjust this classifier to tackle compositional shifts. We provide an extensive theoretical analysis of CRM, where we show that our proposal extrapolates to special affine hulls of seen attribute combinations. Empirical evaluations on benchmark datasets confirms the improved robustness of CRM compared to other methods from the literature designed to tackle various forms of subpopulation shifts.", "title_embedding_index": 20809, "title_abs_embedding_index": 20834}, {"title": "D-FINE: Redefine Regression Task of DETRs as Fine-grained Distribution Refinement", "link_suffix": "/forum?id=MFZjrTFE7h", "link": "https://openreview.net/forum?id=MFZjrTFE7h", "pdf_link": "https://openreview.net/pdf?id=MFZjrTFE7h", "keywords": "Object Detection, Real-Time, Detection Transformer, Knowledge Distillation", "abstract": "We introduce D-FINE, a powerful real-time object detector that achieves outstanding localization precision by redefining the bounding box regression task in DETR models. D-FINE comprises two key components: Fine-grained Distribution Refinement (FDR) and Global Optimal Localization Self-Distillation (GO-LSD). FDR transforms the regression process from predicting fixed coordinates to iteratively refining probability distributions, which serve as a fine-grained intermediate representation, significantly enhancing localization accuracy. GO-LSD is a bidirectional optimization strategy that utilizes the model's own refined distributions to enhance earlier layers through self-distillation, while simplifying the prediction task for subsequent layers. Additionally, D-FINE incorporates lightweight optimizations in computationally intensive modules and operations, achieving a better balance between speed and accuracy. Specifically, D-FINE-L / X achieves 54.0% / 55.8% AP on the COCO dataset at 129 / 81 FPS on an NVIDIA T4 GPU. When pretrained on Objects365, D-FINE-L / X attains 56.9% / 59.0% AP at 81 FPS, surpassing all existing real-time detectors. Furthermore, our method significantly enhances the performance of a wide range of DETR models by up to 5.3% AP with negligible extra parameters and training costs. Our code and models will be made publicly available.", "title_embedding_index": 20810, "title_abs_embedding_index": 20835}, {"title": "Preference Optimization for Combinatorial Optimization Problems", "link_suffix": "/forum?id=8QkpCRio53", "link": "https://openreview.net/forum?id=8QkpCRio53", "pdf_link": "https://openreview.net/pdf?id=8QkpCRio53", "keywords": "Combinatorial Optimization, Reinforcement Learning, Preference-Based Reinforcement Learning", "abstract": "Reinforcement Learning (RL) has emerged as a powerful tool for neural combinatorial optimization, enabling models to learn heuristics that solve complex problems without requiring optimal solutions. Despite significant progress, existing RL approaches face challenges such as diminishing reward signals and inefficient exploration in vast combinatorial action spaces, leading to inefficient learning. In this paper, we propose $Preference \n\\ Optimization (PO)$, a novel framework that transforms quantitative reward signals into qualitative preference signals via statistical comparison modeling, emphasizing the superiority among generated solutions. Methodologically, by reparameterizing the reward function in terms of policy probabilities and utilizing preference models like Bradley-Terry and Thurstone, we formulate an entropy-regularized optimization objective that aligns the policy directly with preferences while avoiding intractable computations. Furthermore, we integrate heuristic local search techniques into the fine-tuning process to generate high-quality preference pairs, helping the policy escape local optima. Empirical results on standard combinatorial optimization benchmarks, such as the Traveling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP), demonstrate that our method outperforms traditional RL algorithms, achieving superior sample efficiency and solution quality. Our work offers a simple yet efficient algorithmic advancement in neural combinatorial optimization.", "title_embedding_index": 20811, "title_abs_embedding_index": 20836}, {"title": "ComfyGen: Prompt-Adaptive Workflows for Text-to-Image Generation", "link_suffix": "/forum?id=IzQB2pIa3F", "link": "https://openreview.net/forum?id=IzQB2pIa3F", "pdf_link": "https://openreview.net/pdf?id=IzQB2pIa3F", "keywords": "Text-to-Image Generation, Workflow prediction, LLM Applications", "abstract": "The practical use of text-to-image generation has evolved from simple, monolithic models to complex workflows that combine multiple specialized components. While workflow-based approaches can lead to improved image quality, crafting effective workflows requires significant expertise, owing to the large number of available components, their complex inter-dependence, and their dependence on the generation prompt. Here, we introduce the novel task ofprompt-adaptive workflow generation, where the goal is to automatically tailor a workflow to each user prompt. We propose two LLM-based approaches to tackle this task: a tuning-based method that learns from user-preference data, and a training-free method that uses the LLM to select existing flows. Both approaches lead to improved image quality when compared to monolithic models or generic, prompt-independent workflows. Our work shows that prompt-dependent flow prediction offers a new pathway to improving text-to-image generation quality, complementing existing research directions in the field.", "title_embedding_index": 20812, "title_abs_embedding_index": 20837}, {"title": "Laplace Sample Information:  Data Informativeness Through a Bayesian Lens", "link_suffix": "/forum?id=qO6dk9KfIp", "link": "https://openreview.net/forum?id=qO6dk9KfIp", "pdf_link": "https://openreview.net/pdf?id=qO6dk9KfIp", "keywords": "Sample informativeness, Sample Information, Sample  Difficulty, Long-tailed distribution, Leave-one-out retraining, KL Divergence", "abstract": "Accurately estimating the informativeness of individual samples in a dataset is an important objective in deep learning, as it can guide sample selection, which can improve model efficiency and accuracy by removing redundant or potentially harmful samples. \nWe propose $\\text{\\textit{Laplace Sample Information}}$ ($\\mathsf{LSI}$) measure of sample informativeness grounded in information theory widely applicable across model architectures and learning settings.\n$\\mathsf{LSI}$ leverages a Bayesian approximation to the weight posterior and the KL divergence to measure the change in the parameter distribution induced by a sample of interest from the dataset.\nWe experimentally show that $\\mathsf{LSI}$ is effective in ordering the data with respect to typicality, detecting mislabeled samples, measuring class-wise informativeness, and assessing dataset difficulty.\nWe demonstrate these capabilities of $\\mathsf{LSI}$ on image and text data in supervised and unsupervised settings.\nMoreover, we show that $\\mathsf{LSI}$ can be computed efficiently through probes and transfers well to the training of large models.", "title_embedding_index": 20813, "title_abs_embedding_index": 20838}, {"title": "Structural-Entropy-Based Sample Selection for Efficient and Effective Learning", "link_suffix": "/forum?id=xUMI52rrW7", "link": "https://openreview.net/forum?id=xUMI52rrW7", "pdf_link": "https://openreview.net/pdf?id=xUMI52rrW7", "keywords": "Sample selection, graph, structural entropy, blue noise sampling", "abstract": "Sample selection improves the efficiency and effectiveness of machine learning models by providing informative and representative samples. Typically, samples can be modeled as a sample graph, where nodes are samples and edges represent their similarities. Most existing methods are based on local information, such as the training difficulty of samples, thereby overlooking global information, such as connectivity patterns. This oversight can result in suboptimal selection because global information is crucial for ensuring that the selected samples well represent the structural properties of the graph. To address this issue, we employ structural entropy to quantify global information and losslessly decompose it from the whole graph to individual nodes using the Shapley value. Based on the decomposition, we present $\\textbf{S}$tructural-$\\textbf{E}$ntropy-based sample $\\textbf{S}$election ($\\textbf{SES}$), a method that integrates both global and local information to select informative and representative samples. SES begins by constructing a $k$NN-graph among samples based on their similarities. It then measures sample importance by combining structural entropy (global metric) with training difficulty (local metric). Finally, SES applies importance-biased blue noise sampling to select a set of diverse and representative samples. Comprehensive experiments on three learning scenarios --- supervised learning, active learning, and continual learning --- clearly demonstrate the effectiveness of our method.", "title_embedding_index": 20814, "title_abs_embedding_index": 20839}, {"title": "Improving Autoregressive Image Generation by Mitigating Gradient Bias in Softmax", "link_suffix": "/forum?id=HFAIxjBB6K", "link": "https://openreview.net/forum?id=HFAIxjBB6K", "pdf_link": "https://openreview.net/pdf?id=HFAIxjBB6K", "keywords": "Image Generation, Autoregressive Generative Model, Softmax", "abstract": "Softmax is the most commonly used probabilistic activation function in classification tasks, partly due to its tendency to over-penalize non-target classes with high prediction scores. However, this property becomes detrimental in autoregressive generation tasks, where multiple valid predictions may exist. Unlike conventional classification task, which seeks a single correct answer, autoregressive models are expected to assign high probabilities to various plausible outputs to ensure diversity in generation. However, during training, gradient bias caused by Softmax over-penalizes non-target predictions with high probabilities, limiting output diversity and hindering optimization convergence. To alleviate this, we propose Gradient Suppressed Softmax (GS-Softmax), which reduces the gradient contributions of high-probability non-target classes. Through experiments, we demonstrate that GS-Softmax improves both the diversity of generated content and optimization convergence. Code and pre-trained models will be made public.", "title_embedding_index": 20815, "title_abs_embedding_index": 20840}, {"title": "Stable Segment Anything Model", "link_suffix": "/forum?id=ooxj2Audlq", "link": "https://openreview.net/forum?id=ooxj2Audlq", "pdf_link": "https://openreview.net/pdf?id=ooxj2Audlq", "keywords": "Segment Anything Model, Interactive Segmentation, Segmentation Stability, Deformable Feature Sampling", "abstract": "The Segment Anything Model (SAM) achieves remarkable promptable segmentation given high-quality prompts which, however, often require good skills to specify. To make SAM robust to casual prompts, this paper presents the first comprehensive analysis on SAM\u2019s segmentation stability across a diverse spectrum of prompt qualities, notably imprecise bounding boxes and insufficient points. Our key finding reveals that given such low-quality prompts, SAM\u2019s mask decoder tends to activate image features that are biased towards the background or confined to specific object parts. To mitigate this issue, our key idea consists of calibrating solely SAM\u2019s mask attention by adjusting the sampling locations and amplitudes of image features, while the original SAM model architecture and weights remain unchanged. Consequently, our deformable sampling plugin (DSP) enables SAM to adaptively shift attention to the prompted target regions in a data-driven manner. During inference, dynamic routing plugin (DRP) is proposed that toggles SAM between the deformable and regular grid sampling modes, conditioned on the input prompt quality. Thus, our solution, termed Stable-SAM, offers several advantages: 1) improved SAM\u2019s segmentation stability across a wide range of prompt qualities, while 2) retaining SAM\u2019s powerful promptable segmentation efficiency and generality, with 3) minimal learnable parameters (0.08 M) and fast adaptation. Extensive experiments validate the effectiveness and advantages of our approach, underscoring Stable-SAM as a more robust solution for segmenting anything.", "title_embedding_index": 20816, "title_abs_embedding_index": 20841}, {"title": "Unfiltered and Unseen: Universal Multimodal Jailbreak Attacks on Text-to-Image Model Defenses", "link_suffix": "/forum?id=sshYEYQ82L", "link": "https://openreview.net/forum?id=sshYEYQ82L", "pdf_link": "https://openreview.net/pdf?id=sshYEYQ82L", "keywords": "Diffusion Model, Not-Safe-for- Work (NSFW), Adversarial Attack, Jailbreak Attack", "abstract": "Text-to-Image (T2I) models have revolutionized the synthesis of visual content from textual descriptions. However, their potential misuse for generating Not-Safe-For-Work (NSFW) content presents significant risks. While developers have implemented prompt filters and safety checkers, these defense mechanisms have proven inadequate against determined adversaries. In this paper, we introduce U3-Attack, a novel multimodal jailbreak attack against T2I models that effectively circumvents existing safeguards to generate NSFW images. \nTo achieve a universal attack, U3-Attack constructs a context-independent paraphrase candidate set for each sensitive word in the text modality. This approach enables practical attacks against prompt filters with minimal perturbation. In the image modality, we propose a two-stage adversarial patch generation strategy that does not require access to the T2I model's internal architecture or parameters. This design makes our attack applicable to both open-source models and online T2I platforms.\nExtensive experiments demonstrate the effectiveness of our method across various T2I models, including Stable Diffusion, Leonardo.Ai, and Runway. Our work exposes critical vulnerabilities in current T2I model defenses and underscores the urgent need for more robust safety measures in this rapidly evolving field.", "title_embedding_index": 20817, "title_abs_embedding_index": 20842}, {"title": "Sharper Bounds of Non-Convex Stochastic Gradient Descent with Momentum", "link_suffix": "/forum?id=x45vUUY4nT", "link": "https://openreview.net/forum?id=x45vUUY4nT", "pdf_link": "https://openreview.net/pdf?id=x45vUUY4nT", "keywords": "learning theory, nonconvex optimization, stochastic gradient descent", "abstract": "Stochastic gradient descent with momentum (SGDM) has been widely used in machine learning. However, in non-convex domains, high probability learning bounds for SGDM are scarce. In this paper, we provide high probability convergence bounds and generalization bounds for SGDM. Firstly, we establish these bounds for the gradient norm in the general non-convex case. The derived convergence bounds are tighter than the theoretical results of related work, and to our best knowledge, the derived generalization bounds are the first ones for SGDM. Then, if the Polyak-{\\L}ojasiewicz condition is satisfied, we establish these bounds for the error of the function value, instead of the gradient norm. Moreover, the derived learning bounds have faster rates than the general non-convex case. Finally,  we further provide sharper generalization bounds by considering a mild Bernstein condition on the gradient. In the case of low noise, their learning rates can reach $\\widetilde{\\mathcal{O}}(1/n^2)$, where $n$ is the sample size. Overall, we relatively systematically investigate the high probability learning bounds for non-convex SGDM.", "title_embedding_index": 20818, "title_abs_embedding_index": 20843}, {"title": "Look, Compare and Draw:  Differential Query Transformer for Automatic Oil Painting", "link_suffix": "/forum?id=pGg658qADW", "link": "https://openreview.net/forum?id=pGg658qADW", "pdf_link": "https://openreview.net/pdf?id=pGg658qADW", "keywords": "Automatic Oil Painting, Stroke-based Rendering, Style Transfer, Sequence Prediction", "abstract": "This work introduces a new approach to automatic oil painting that emphasizes the creation of dynamic and expressive brushstrokes. A pivotal challenge lies in mitigating the duplicate and common-place strokes, which often lead to less aesthetic outcomes. Inspired from the human painting process, i.e., observing, comparing, and drawing, we incorporate differential image analysis into a neural oil painting model, allowing the model to effectively concentrate on the incremental impact of successive brushstrokes. To operationalize this concept, we propose the Differential Query Transformer (DQ-Transformer), a new architecture that leverages differentially derived image representations enriched with positional encoding to guide the stroke prediction process. This integration enables the model to maintain heightened sensitivity to local details, resulting in more refined and nuanced stroke generation. Furthermore, we incorporate adversarial training into our framework, enhancing the accuracy of stroke prediction and thereby improving the overall realism and fidelity of the synthesized paintings. Extensive qualitative evaluations, complemented by a controlled user study, validate that our DQ-Transformer surpasses existing methods in both visual realism and artistic authenticity, typically achieving these results with fewer strokes. The stroke-by-stroke painting animations are available on our anonymous website:https://differential-query-painter.github.io/DQ-painter/.", "title_embedding_index": 20819, "title_abs_embedding_index": 20844}, {"title": "Dreamguider: Improved Training free Diffusion-based Conditional Generation", "link_suffix": "/forum?id=Hpu3KIX8Am", "link": "https://openreview.net/forum?id=Hpu3KIX8Am", "pdf_link": "https://openreview.net/pdf?id=Hpu3KIX8Am", "keywords": "Diffusion, Automatic Parameter estimation, Zero shot generation", "abstract": "Diffusion models have emerged as a formidable tool for training-free conditional generation. However, a key hurdle in inference-time guidance techniques is the need for compute-heavy backpropagation through the diffusion network for estimating the guidance direction. Moreover, these techniques often require handcrafted parameter tuning on a case-by-case basis. Although some recent works have introduced minimal compute methods for linear inverse problems, a generic lightweight guidance solution to both linear and non-linear guidance problems is still missing. To this end, we propose Dreamguider, a method that enables inference-time guidance without compute-heavy backpropagation through the diffusion network. The key idea is to regulate the gradient flow through a time-varying factor. Moreover, we propose an empirical guidance scale that works for a wide variety of tasks, hence removing the need for handcrafted parameter tuning. We further introduce an effective lightweight augmentation strategy that significantly boosts the performance during inference-time guidance. We present experiments using Dreamguider on multiple  tasks across multiple datasets and models to show the effectiveness of the proposed modules. To facilitate further research, we will make the code public after the review process.", "title_embedding_index": 20820, "title_abs_embedding_index": 20845}, {"title": "ProtoSnap: Prototype Alignment For Cuneiform Signs", "link_suffix": "/forum?id=XHTirKsQV6", "link": "https://openreview.net/forum?id=XHTirKsQV6", "pdf_link": "https://openreview.net/pdf?id=XHTirKsQV6", "keywords": "Machine learning for social sciences, Ancient character recognition, generative models", "abstract": "The cuneiform writing system served as the medium for transmitting knowledge\nin the ancient Near East for a period of over three thousand years. Cuneiform\nsigns have a complex internal structure which is the subject of expert paleographic\nanalysis, as variations in sign shapes bear witness to historical developments and\ntransmission of writing and culture over time. However, prior automated techniques\nmostly treat sign types as categorical and do not explicitly model their highly varied\ninternal configurations. In this work, we present an unsupervised approach for\nrecovering the fine-grained internal configuration of cuneiform signs by leveraging\npowerful generative models and the appearance and structure of prototype font\nimages as priors. Our approach, ProtoSnap, enforces structural consistency on\nmatches found with deep image features to estimate the diverse configurations\nof cuneiform characters, snapping a skeleton-based template to photographed\ncuneiform signs. We provide a new benchmark of expert annotations and evaluate\nour method on this task. Our evaluation shows that our approach succeeds in\naligning prototype skeletons to a wide variety of cuneiform signs. Moreover, we\nshow that conditioning on structures produced by our method allows for generating\nsynthetic data with correct structural configurations, significantly boosting the\nperformance of cuneiform sign recognition beyond existing techniques, in particular\nover rare signs. We will release our code and data to the research community,\nforeseeing their use in a variety of applications in the digital humanities.", "title_embedding_index": 20821, "title_abs_embedding_index": 20846}, {"title": "Learning Fine-Grained Representations through Textual Token Disentanglement in Composed Video Retrieval", "link_suffix": "/forum?id=wGa2plE8ka", "link": "https://openreview.net/forum?id=wGa2plE8ka", "pdf_link": "https://openreview.net/pdf?id=wGa2plE8ka", "keywords": "Composed Video Retrieval; Fine-grained Representation; Feature Disentanglement", "abstract": "With the explosive growth of video data, finding videos that meet detailed requirements in large datasets has become a significant challenge. To address this, the composed video retrieval task has been introduced, enabling users to retrieve videos using complex queries that involve both visual and textual information. However, existing composed video retrieval methods struggle to meet the demands of fine-grained retrieval for two main reasons: the lack of a video retrieval dataset with fine-grained description and the absence of effective approaches for fine-grained video retrieval. To overcome these challenges, we first construct a large-scale fine-grained dataset, FineCVR-1M, with 1,010,071 video-text triplets in an automated process. This process identifies key concept changes between video pairs to generate textual descriptions for both static and action concepts.  For fine-grained retrieval methods, the key challenge lies in understanding the detailed requirements. Text descriptions serve as clear expressions of intent, allowing the model to distinguish fine-grained needs through textual feature disentanglement. Therefore, we propose a textual Feature Disentanglement and Cross-modal Alignment framework (FDCA) that disentangles features at both the sentence and token levels. At the sequence level, we separate the text features into retained and injected features. At the token level, an Auxiliary Token Disentangling mechanism is proposed to explicitly disentangle texts into retained, injected, and excluded tokens. The disentanglement at both levels extracts fine-grained features, which are aligned and fused with the reference video to extract global representations for video retrieval. Experiments on the FineCVR-1M dataset demonstrate the superior performance of our approach.", "title_embedding_index": 20822, "title_abs_embedding_index": 20847}, {"title": "Salvage: Shapley-distribution Approximation Learning Via Attribution Guided Exploration for Explainable Image Classification", "link_suffix": "/forum?id=WBUVagRgsd", "link": "https://openreview.net/forum?id=WBUVagRgsd", "pdf_link": "https://openreview.net/pdf?id=WBUVagRgsd", "keywords": "Explainability, XAI, feature attribution", "abstract": "The integration of deep learning into critical vision application areas has given rise to a necessity for techniques that can explain the rationale behind predictions. In this paper, we address this need by introducing Salvage, a novel removal-based explainability method for image classification. Our approach involves training an explainer model that learns the prediction distribution of the classifier on masked images. We first introduce the concept of Shapley-distributions, which offers a more accurate approximation of classification probability distributions than existing methods. Furthermore, we address the issue of unbalanced important and unimportant features. In such settings, naive uniform sampling of feature subsets often results in a highly unbalanced ratio of samples with high and low prediction likelihoods, which can hinder effective learning. To mitigate this, we propose an informed sampling strategy that leverages approximated feature importance scores, thereby reducing imbalance and facilitating the estimation of underrepresented features. After incorporating these two principles into our method, we conducted an extensive analysis on the ImageNette, MURA, and Pet datasets. The results show that Salvage outperforms various baseline explainability methods, including attention-, gradient-, and removal-based approaches, both qualitatively and quantitatively. Furthermore, we demonstrate that our explainer model can serve as a fully explainable classifier without a major decrease in classification performance, paving the way for fully explainable image classification.", "title_embedding_index": 20823, "title_abs_embedding_index": 20848}, {"title": "SG-Adapter: Enhancing Text-to-Image Generation with Scene Graph Guidance", "link_suffix": "/forum?id=KCYDpqSpqg", "link": "https://openreview.net/forum?id=KCYDpqSpqg", "pdf_link": "https://openreview.net/pdf?id=KCYDpqSpqg", "keywords": "diffusion models, scene graph, image generation", "abstract": "Recent advancements in text-to-image generation have been propelled by the development of diffusion models and multi-modality learning. However, since text is typically represented sequentially in these models, it often falls short in providing accurate contextualization and structural control. So the generated images do not consistently align with human expectations, especially in complex scenarios involving multiple objects and relationships. In this paper, we introduce the Scene Graph Adapter(SG-Adapter), leveraging the structured representation of scene graphs to rectify inaccuracies in the original text embeddings. The SG-Adapter's explicit and non-fully connected graph representation greatly improves the fully connected, transformer-based text representations. This enhancement is particularly notable in maintaining precise correspondence in scenarios involving multiple relationships. To address the challenges posed by low-quality annotated datasets like Visual Genome, we have manually curated a highly clean, multi-relational scene graph-image paired dataset MultiRels. Furthermore, we design three metrics derived from GPT-4V to effectively and thoroughly measure the correspondence between images and scene graphs. Both qualitative and quantitative results validate the efficacy of our approach in controlling the correspondence in multiple relationships.", "title_embedding_index": 20824, "title_abs_embedding_index": 20849}]
[
    {
        "title": "CLIP-MoE: Towards Building Mixture of Experts for CLIP with Diversified Multiplet Upcycling",
        "link_suffix": "/forum?id=e4em5klSEw",
        "link": "https://openreview.net/forum?id=e4em5klSEw",
        "pdf_link": "https://openreview.net/pdf?id=e4em5klSEw",
        "keywords": "Mixture of Experts, Contrastive Learning, Multimodal Learning, Multimodal Large Language Models",
        "abstract": "In recent years, Contrastive Language-Image Pre-training (CLIP) has become a cornerstone in multimodal intelligence. \nHowever, recent studies have identified that the information loss in the encoding process of CLIP is substantial. Such deficiency significantly limits the ability of a single CLIP model to handle images rich in visual detail. In this work, we propose a simple yet effective model-agnostic strategy, $\\textbf{Diversified Multiplet Upcycling (DMU)}$ for CLIP. It integrates multiple CLIP models that capture diversified, complementary information into a Mixture of Experts (MoE) architecture. Inspired by the recently proposed Multistage Contrastive Learning (MCL), which constructs multiple CLIP models that share the same structure while capturing different complementary information, Diversified Multiplet Upcycling efficiently fine-tunes a series of CLIP models from a dense pre-trained CLIP checkpoint to capture different feature distributions, sharing parameters except for the Feed-Forward Network (FFN). These models are then transformed into a $\\textbf{CLIP-MoE}$ with a larger model capacity but minimal computational overhead. Extensive experiments demonstrate the significant performance of CLIP-MoE across various zero-shot retrieval, zero-shot image classification tasks, and downstream Multimodal Large Language Model (MLLM) benchmarks by serving as a vision encoder. Furthermore, Diversified Multiplet Upcycling enables the conversion of any dense CLIP model into CLIP-MoEs, which can seamlessly replace CLIP in a plug-and-play manner without requiring further adaptation in downstream frameworks. Through Diversified Multiplet Upcycling, we aim to provide valuable insights for future research on developing more efficient and effective multimodal learning systems."
    },
    {
        "title": "Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data",
        "link_suffix": "/forum?id=sMyXP8Tanm",
        "link": "https://openreview.net/forum?id=sMyXP8Tanm",
        "pdf_link": "https://openreview.net/pdf?id=sMyXP8Tanm",
        "keywords": "Discrete Diffusion Models, Diffusion Models, Language Modeling, Concrete Score, Score Entropy",
        "abstract": "Discrete diffusion models with absorbing processes have shown promise in language modeling. The key quantities to be estimated are the ratios between the marginal probabilities of two transitive states at all timesteps, called the concrete score. In this paper, we reveal that the concrete score in absorbing diffusion can be expressed as conditional probabilities of clean data, multiplied by a time-dependent scalar in an analytic form. Motivated by this finding, we propose reparameterized absorbing discrete diffusion (RADD), a dedicated diffusion model without time-condition that characterizes the time-independent conditional probabilities. Besides its simplicity, RADD can reduce the number of function evaluations (NFEs) by caching the output of the time-independent network when the noisy sample remains unchanged in a sampling interval, which enables sampling acceleration. Built upon the new perspective of conditional distributions, we further unify absorbing discrete diffusion and any-order autoregressive models (AO-ARMs), showing that the upper bound on the negative log-likelihood for the diffusion model can be interpreted as an expected negative log-likelihood for AO-ARMs. Further, our RADD models achieve SOTA performance among diffusion models on 5 zero-shot language modeling benchmarks (measured by perplexity) at the GPT-2 scale."
    },
    {
        "title": "SPA-BENCH: A COMPREHENSIVE BENCHMARK FOR SMARTPHONE AGENT EVALUATION",
        "link_suffix": "/forum?id=OZbFRNhpwr",
        "link": "https://openreview.net/forum?id=OZbFRNhpwr",
        "pdf_link": "https://openreview.net/pdf?id=OZbFRNhpwr",
        "keywords": "AI Agent, LLM, MLLM, Benchmark, Smartphone Control",
        "abstract": "Smartphone agents are increasingly important for helping users control devices efficiently, with (Multimodal) Large Language Model (MLLM)-based approaches emerging as key contenders. Fairly comparing these agents is essential but challenging, requiring a varied task scope, the integration of agents with different implementations, and a generalisable evaluation pipeline to assess their strengths and weaknesses. In this paper, we present SPA-Bench, a comprehensive SmartPhone Agent Benchmark designed to evaluate (M)LLM-based agents in an interactive environment that simulates real-world conditions. SPA-Bench offers three key contributions: (1) A diverse set of tasks covering system and third-party apps in both English and Chinese, focusing on features commonly used in daily routines; (2) A plug-and-play framework enabling real-time agent interaction with Android devices, integrating over ten agents with the flexibility to add more; (3) A novel evaluation pipeline that automatically assesses agent performance across multiple dimensions, encompassing seven metrics related to task completion and resource consumption. Our extensive experiments across tasks and agents reveal challenges like interpreting mobile user interfaces, action grounding, memory retention, and execution costs. We propose future research directions to ease these difficulties, moving closer to real-world smartphone agent applications."
    },
    {
        "title": "Haland: Human-AI Coordination via Policy Generation from Language-guided Diffusion",
        "link_suffix": "/forum?id=jlEDDCYLvV",
        "link": "https://openreview.net/forum?id=jlEDDCYLvV",
        "pdf_link": "https://openreview.net/pdf?id=jlEDDCYLvV",
        "keywords": "Multi-agent Reinforcement Learning, Human-AI Coordination, Coordination and Cooperation, Reinforcement Learning",
        "abstract": "Developing intelligent agents that can effectively coordinate with diverse human partners is a fundamental goal of artificial general intelligence. Previous approaches typically generate a variety of partners to cover human policies, and then either train a single universal agent or maintain multiple best-response (BR) policies for different partners. However, the first direction struggles with the stochastic and multimodal nature of human behaviors, and the second relies on costly few-shot adaptations during policy deployment, which is unbearable in real-world applications such as healthcare and autonomous driving. Recognizing that human partners can easily articulate their preferences or behavioral styles through natural languages and make conventions beforehand, we propose a framework for Human-AI Coordination via Policy Generation from Language-guided Diffusion, referred to as Haland. Haland first trains BR policies for various partners using reinforcement learning, and then compresses policy parameters into a single latent diffusion model, conditioned on task-relevant language derived from their behaviors.  Finally, the alignment between task-relevant and natural languages is achieved to facilitate efficient human-AI coordination. Empirical evaluations across diverse cooperative environments demonstrate that Haland generates agents with significantly enhanced zero-shot coordination performance, utilizing only natural language instructions from various partners, and outperforms existing methods by approximately 89.64%."
    },
    {
        "title": "Faster Rates for Private Adversarial Bandits",
        "link_suffix": "/forum?id=SbV2eJC7Ci",
        "link": "https://openreview.net/forum?id=SbV2eJC7Ci",
        "pdf_link": "https://openreview.net/pdf?id=SbV2eJC7Ci",
        "keywords": "Differential Privacy, Bandits",
        "abstract": "We design new differentially private algorithms for the problems of adversarial bandits and bandits with expert advice. For adversarial bandits, we give a simple and efficient conversion of any non-private bandit algorithm to a private bandit algorithm. Instantiating our conversion with existing non-private bandit algorithms gives a regret upper bound of $O\\left(\\frac{\\sqrt{KT}}{\\sqrt{\\epsilon}}\\right)$, improving upon the existing upper bound $O\\left(\\frac{\\sqrt{KT \\log(KT)}}{\\epsilon}\\right)$ for all $\\epsilon \\leq 1$. In particular, our algorithms allow for sublinear expected regret even when $\\epsilon \\leq \\frac{1}{\\sqrt{T}}$, establishing the first known separation between central and local differential privacy for this problem. For bandits with expert advice, we give the first differentially private algorithms, with expected regret $O\\left(\\frac{\\sqrt{NT}}{\\sqrt{\\epsilon}}\\right), O\\left(\\frac{\\sqrt{KT\\log(N)}\\log(KT)}{\\epsilon}\\right)$, and $\\tilde{O}\\left(\\frac{N^{1/6}K^{1/2}T^{2/3}\\log(NT)}{\\epsilon^{1/3}} + \\frac{N^{1/2}\\log(NT)}{\\epsilon}\\right)$, where $K$ and $N$ are the number of actions and experts respectively. These rates allow us to get sublinear regret for different combinations  of small and large $K, N$ and $\\epsilon.$"
    },
    {
        "title": "Subject Information Extraction for Novelty Detection with Domain Shifts",
        "link_suffix": "/forum?id=sLtuNGkKfH",
        "link": "https://openreview.net/forum?id=sLtuNGkKfH",
        "pdf_link": "https://openreview.net/pdf?id=sLtuNGkKfH",
        "keywords": "novelty detection",
        "abstract": "Unsupervised novelty detection (UND), aimed at identifying novel samples, is essential in fields like medical diagnosis, cybersecurity, and industrial quality control. Most existing UND methods assume that the training data and testing normal data originate from the same domain and only consider the distribution variation between training data and testing data. However, in real scenarios, it is common for normal testing and training data to originate from different domains, a challenge known as domain shift. The discrepancies between training and testing data often lead to incorrect classification of normal data as novel by existing methods. A typical situation is that testing normal data and training data describe the same subject, yet they differ in the background conditions. To address this problem, we introduce a novel method that separates subject information from background variation encapsulating the domain information to enhance detection performance under domain shifts. The proposed method minimizes the mutual information between the representations of the subject and background while modelling the background variation using a deep Gaussian mixture model, where the novelty detection is conducted on the subject representations solely and hence is not affected by the variation of domains. Extensive experiments demonstrate that our model generalizes effectively to unseen domains and significantly outperforms baseline methods, especially under substantial domain shifts between training and testing data."
    },
    {
        "title": "A Simple Efficiency Incremental Learning Framework via Vision-Language Model with Multi-Adapters",
        "link_suffix": "/forum?id=rkAqvDnnmO",
        "link": "https://openreview.net/forum?id=rkAqvDnnmO",
        "pdf_link": "https://openreview.net/pdf?id=rkAqvDnnmO",
        "keywords": "Continual learning; CLIP; Adapter",
        "abstract": "Incremental Learning (IL) aims to learn new tasks while preserving previous knowledge. Integration of the zero-shot learning capabilities of pre-trained vision-language models into IL methods has been a significant advancement. However, these methods face three primary challenges: 1) the need for improved training efficiency; 2) the need for a memory bank to store previous data; and 3) the need for a strong backbone to augment the model\u2019s capabilities. In this paper, we propose the $\\textbf{SimE}$ that is a $\\textbf{Sim}$ple $\\textbf{E}$fficiency framework which is the vision-language model with an adapter designed for solving the IL task. We report a remarkable phenomenon that there is not always a direct positive correlation between the number of adaptive adapter connections and the model's incremental learning (IL) capabilities. While increasing the number of adapter connections between transformer blocks positively impacts model performance, within transformer blocks, adding more adaptive connections in smaller incremental stages does not enhance, and may even degrade the model's IL ability. Such improvement only occurs at advanced incremental stages. Extensive experimental results show SimE surpasses traditional methods by 9.6% on TinyImageNet and outperforms other CLIP-based methods by 5.3% on CIFAR-100. Notably, the SimE, with only thousands of parameters and a 0-size memory bank, exceeds the ZSCL with 140 million parameters and also beats the CoOP with a 1000-size memory bank. Besides, we also conduct a systematic study to enhance the utilization of the zero-shot capabilities of CLIP. We suggest that the backbone of the encoder in SimE use the image encoder from CLIP that is pre-trained on large datasets, like LAION-2B, and larger model sizes, such as ViT-L/14, for IL tasks."
    },
    {
        "title": "DeepRTL: Bridging Verilog Understanding and Generation with a Unified Representation Model",
        "link_suffix": "/forum?id=2hcfoCHKoB",
        "link": "https://openreview.net/forum?id=2hcfoCHKoB",
        "pdf_link": "https://openreview.net/pdf?id=2hcfoCHKoB",
        "keywords": "Large Language Model, Program Representation Learning, Verilog Understanding and Generation",
        "abstract": "Recent advancements in large language models (LLMs) have demonstrated significant potential in automating the generation of hardware description language (HDL) code from high-level natural language instructions. While fine-tuning has improved these models' performance in hardware design tasks, prior efforts have largely focused on Verilog code generation, overlooking the equally critical task of Verilog understanding. Furthermore, existing models suffer from weak alignment between natural language descriptions and Verilog code, which hampers the generation of high-quality, synthesizable designs. To overcome these limitations, we present DeepRTL, a unified representation model that excels in both Verilog understanding and generation. Based on CodeT5+, DeepRTL is fine-tuned on a comprehensive dataset that aligns Verilog code with rich, multi-level natural language descriptions. We also introduce the first benchmark for Verilog understanding, alongside two novel metrics, embedding similarity and GPT score, that capture semantic similarity more accurately than traditional metrics like BLEU and ROUGE, which are limited to surface-level n-gram overlaps. DeepRTL's progressive training strategy enables it to significantly outperform GPT-4 in Verilog understanding tasks, while achieving performance on par with OpenAI's o1-preview model in Verilog generation tasks."
    },
    {
        "title": "Can LLMs Evaluate Complex Attribution in QA? Automatic Benchmarking Using Knowledge Graphs",
        "link_suffix": "/forum?id=zP8HygcAMY",
        "link": "https://openreview.net/forum?id=zP8HygcAMY",
        "pdf_link": "https://openreview.net/pdf?id=zP8HygcAMY",
        "keywords": "Large Language Model, Attributed Question Answering, Knowledge Graph",
        "abstract": "The attribution of question answering (QA), which is to get evidences for supporting the generated answer, has attracted wide research attention. The current methods for automatically evaluating the attribution, typically relying on Large Language Models (LLMs), are still inadequate, particularly in recognizing subtle differences between attributions, and in measuring complex attribution reasoning. Existing benchmarks, which are primarily based on manual annotations, suffer from limited evaluation settings with incomplete and coarse attribution categories and reasoning scenarios, hindering the evaluation and advancement of attribution evaluators. To address this gap, we introduce Complex Attributed Question Answering (CAQA), a large-scale benchmark automatically generated using Knowledge Graphs (KGs), containing more comprehensive attribution categories and complex attribution reasoning scenarios. Our experiments with two specifically developed evaluators and nine LLM evaluators reveal that they struggle in identifying negative attribution categories and handling complex attribution reasoning in both zero-shot and few-shot settings, but mostly perform relatively well in the fine-tuning setting. Moreover, all evaluators perform inadequately in fine-grained attribution identification scenarios. The experiments also demonstrate that CAQA is consistent with human annotations, and is promising for selecting and developing more effective attribution evaluators in QA."
    },
    {
        "title": "Bridging the Gap between Semantic Correspondence and Robust Visual Representation",
        "link_suffix": "/forum?id=UbugxiPs6y",
        "link": "https://openreview.net/forum?id=UbugxiPs6y",
        "pdf_link": "https://openreview.net/pdf?id=UbugxiPs6y",
        "keywords": "semantic correspondence, foundation models",
        "abstract": "Predicting cross-image semantic correspondence among various instances within the same category is a fundamental but challenging task in computer vision. Models are supposed to characterize both high-level semantic features and low-level texture information to accurately finds the correspondence between pixels. The quality of features directly affects the matching results. Recently, pre-trained models with self-supervised training methods have demonstrated promising performance in representation learning and can serve as a strong backbone to provide robust visual features. However, existing methods have been found to poorly adapt to such features. Their complex designs of the matching module do not yield significant performance boost due to the disruption of the original representation and the absence of high-resolution low-level information. In this work, we introduce a simple yet effective framework named ViTSC to unlock the substantial potential of self-supervised vision transformers for semantic correspondence. We introduce three key components: a cross-perception module to align semantic features of the same part from different images while preserving the original representation as much as possible, an auxiliary loss to eliminate ambiguity from semantically similar objects, and a low-level correlation-guided upsampler to generate high-resolution flow maps for precise localization. ViTSC shows reliable semantic correspondence performance, surpassing previous state-of-the-art methods on all three standard benchmarks SPair-71k, PF-PASCAL and PF-WILLOW."
    },
    {
        "title": "AddSR: Accelerating Diffusion-based Blind Super-Resolution with Adversarial Diffusion Distillation",
        "link_suffix": "/forum?id=BpKbKeY0La",
        "link": "https://openreview.net/forum?id=BpKbKeY0La",
        "pdf_link": "https://openreview.net/pdf?id=BpKbKeY0La",
        "keywords": "Image super-resolution",
        "abstract": "Blind super-resolution methods based on Stable Diffusion (SD) demonstrate impressive generative capabilities in reconstructing clear, high-resolution (HR) images with intricate details from low-resolution (LR) inputs. However, their practical applicability is often limited by poor efficiency, as they require hundreds to thousands of sampling steps.\nInspired by Adversarial Diffusion Distillation (ADD), we incorporate this approach to design a highly effective and efficient blind super-resolution method. Nonetheless, two challenges arise: First, the original ADD significantly reduces result fidelity, leading to a perception-distortion imbalance. Second, SD-based methods are sensitive to the quality of the conditioning input, while LR images often have complex degradation, which further hinders effectiveness.\nTo address these issues, we introduce a Timestep-Adaptive ADD (TA-ADD) to mitigate the perception-distortion imbalance caused by the original ADD. Furthermore, we propose a prediction-based self-refinement strategy to estimate HR, which allows for the provision of more high-frequency information without the need for additional modules.\nExtensive experiments show that our method,~\\name, generates superior restoration results while being significantly faster than previous SD-based state-of-the-art models (e.g., $7\\times$ faster than SeeSR)."
    },
    {
        "title": "A method for identifying causality in the response of nonlinear dynamical systems",
        "link_suffix": "/forum?id=6GWvBa60LZ",
        "link": "https://openreview.net/forum?id=6GWvBa60LZ",
        "pdf_link": "https://openreview.net/pdf?id=6GWvBa60LZ",
        "keywords": "Nonlinear dynamical systems, causality, application to physical sciences, deep learning, noise estimation",
        "abstract": "Predicting the response of nonlinear dynamical systems subject to random, broadband excitation is important across a range of scientific disciplines, such as structural dynamics and neuroscience. Building data-driven models requires experimental measurements of the system input and output, but it can be difficult to determine whether inaccuracies in the model stem from modelling errors or noise.  This paper presents a novel method to identify the causal component of the input-output data from measurements of a system in the presence of output noise, as a function of frequency, without needing a high fidelity model. An output prediction, calculated using an available model, is optimally combined with noisy measurements of the output to predict the input to the system. The parameters of the algorithm balance the two output signals and are utilised to calculate a nonlinear coherence metric as a measure of causality. This method is applicable to a broad class of nonlinear dynamical systems. There are currently no solutions to this problem in the absence of a complete benchmark model."
    },
    {
        "title": "MaskMamba: A Hybrid Mamba-Transformer Model for Masked Image Generation",
        "link_suffix": "/forum?id=ev2KNFmvux",
        "link": "https://openreview.net/forum?id=ev2KNFmvux",
        "pdf_link": "https://openreview.net/pdf?id=ev2KNFmvux",
        "keywords": "Masked Image Modeling, Bidirectional Mamba, In-context Condition, Non-autoregressive image synthesis",
        "abstract": "Image generation models have encountered challenges related to scalability and quadratic complexity, primarily due to the reliance on Transformer-based backbones. In this study, we introduce MaskMamba, a novel hybrid model that integrates Mamba and Transformer architectures, utilizing Masked Image Modeling for non-autoregressive image synthesis. We meticulously redesign the bidirectional Mamba architecture by implementing two key modifications: (1) replacing causal convolutions with standard convolutions to better capture global context, and (2) utilizing concatenation instead of multiplication, which significantly boosts performance while accelerating inference speed. Additionally, we explore various hybrid schemes of MaskMamba, including both serial and grouped parallel arrangements. Furthermore, we incorporate an in-context condition that allows our model to perform both class-to-image and text-to-image generation tasks. Our MaskMamba outperforms Mamba-based and Transformer-based models in generation quality. Notably, it achieves a remarkable 54.44% improvement in inference speed at a resolution of $2048\\times 2048$ over Transformer."
    },
    {
        "title": "TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs",
        "link_suffix": "/forum?id=1KvYxcAihR",
        "link": "https://openreview.net/forum?id=1KvYxcAihR",
        "pdf_link": "https://openreview.net/pdf?id=1KvYxcAihR",
        "keywords": "Large Language Models; Benchmark; Strategic Reasoning; Game Theory; Theory of Mind",
        "abstract": "The rapid advancement of large language models (LLMs) has accelerated their application in reasoning, with strategic reasoning drawing increasing attention.\nTo evaluate the strategic reasoning capabilities of LLMs, game theory, with its concise structure, has become the preferred approach for many researchers.\nHowever, current research typically focuses on a limited selection of games, resulting in low coverage of game types. \nAdditionally, classic game scenarios carry risks of data leakage, and the benchmarks used often lack extensibility, rendering them inadequate for evaluating state-of-the-art models.\nTo address these challenges, we propose TMGBench, a benchmark characterized by comprehensive game type coverage, novel and diverse scenarios, and flexible game organization. \nSpecifically, we incorporate all 144 game types summarized by the Robinson-Goforth topology of 2\u00d72 games, which are constructed as classic games in our benchmark. \nFurthermore, we employ synthetic data generation techniques to create diverse, higher-quality game scenarios through topic guidance and human inspection for each classic game, which we refer to as story-based games.\nLastly, to provide a sustainable evaluation framework adaptable to increasingly powerful LLMs, we treat the aforementioned games as atomic units and organize them into more complex forms through sequential, parallel, and nested structures.\nWe conducted a comprehensive evaluation of mainstream LLMs, covering tests on rational reasoning, reasoning robustness, Theory-of-Mind capabilities, and reasoning in complex game forms. \nThe results revealed that \nLLMs still have flaws in the accuracy and consistency of strategic reasoning processes, and their levels of mastery over Theory-of-Mind also vary.\nAdditionally, o1-mini, the latest reasoning model from OpenAI, was also evaluated across the sequential, parallel, and nested game structures and reached accuracy rates of 66.6%, 60.0%, and 70.0%, respectively, highlighting the challenges posed by TMGBench."
    },
    {
        "title": "TempMe: Video Temporal Token Merging for Efficient Text-Video Retrieval",
        "link_suffix": "/forum?id=lVp97zZ5i8",
        "link": "https://openreview.net/forum?id=lVp97zZ5i8",
        "pdf_link": "https://openreview.net/pdf?id=lVp97zZ5i8",
        "keywords": "Text-Video Retrieval, Efficient Fine-tuning, Temporal Redundancy",
        "abstract": "Most text-video retrieval methods utilize the text-image pre-trained models like CLIP as a backbone, incorporating complex modules that result in high computational overhead. The inherent differences between image and video modalities make this problem further challenging. In a classic pipeline, each sampled frame is processed by the image encoder independently, which significantly increases complexity and complicates practical deployment. As a result, efficient text-video retrieval becomes a hot and tough topic. The primary challenge here arises from two aspects: 1. From the perspective of trainable parameter, current parameter-efficient fine-tuning methods incur high inference costs. 2. From the perspective of inference, current token compression methods are mainly designed for image to reduce spatial redundancy but overlook temporal redundancy in consecutive frames of a video. To tackle these problems, we propose Temporal Token Merging (TempMe), a parameter- and inference-efficient text-video retrieval architecture that can be integrated effectively with both parameter-efficient and full fine-tuning methods. Specifically, we introduce a progressive multi-granularity framework. By gradually combining neighboring clips, we merge redundant temporal tokens across different frames besides redundant spatial tokens inside the same frame to better extract video-level features, leading to lower complexity and better performance. Extensive experiments validate the superiority of our TempMe. Compared to previous parameter-efficient text-video retrieval methods, TempMe significantly reduces output tokens by 95% and GFLOPs by 51%, while achieving a 1.8X speedup and a 4.4% R-Sum improvement. With full fine-tuning, TempMe achieves a significant 7.9% R-Sum improvement, trains 1.57X faster, and utilizes 75.2% GPU memory usage. Anonymous code is available athttps://anonymous.4open.science/r/TempMe-E074."
    },
    {
        "title": "Predicting the Energy Landscape of Stochastic Dynamical System via  Physics-informed Self-supervised Learning",
        "link_suffix": "/forum?id=PxRATSTDlS",
        "link": "https://openreview.net/forum?id=PxRATSTDlS",
        "pdf_link": "https://openreview.net/pdf?id=PxRATSTDlS",
        "keywords": "dynamical system, energy landscape, deep learning",
        "abstract": "Energy landscapes play a crucial role in shaping dynamics of many real-world complex systems. System evolution is often modeled as particles moving on a landscape under the combined effect of energy-driven drift and noise-induced diffusion, where the energy governs the long-term motion of the particles. Estimating the energy landscape of a system has been a longstanding interdisciplinary challenge, hindered by the high operational costs or the difficulty of obtaining supervisory signals. Therefore, the question of how to infer the energy landscape in the absence of true energy values is critical. In this paper, we propose a physics-informed self-supervised learning method to learn the energy landscape from the evolution trajectories of the system. It first maps the system state from the observation space to a discrete landscape space by an adaptive codebook, and then explicitly integrates energy into the graph neural Fokker-Planck equation, enabling the joint learning of energy estimation and evolution prediction. Experimental results across interdisciplinary systems demonstrate that our estimated energy has a correlation coefficient above 0.9 with the ground truth, and evolution prediction accuracy exceeds the baseline by an average of 17.65%. The code is available in the anonymous repository:https://anonymous.4open.science/r/PESLA-0D9A/README.md"
    },
    {
        "title": "Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective",
        "link_suffix": "/forum?id=YFdopzmpdr",
        "link": "https://openreview.net/forum?id=YFdopzmpdr",
        "pdf_link": "https://openreview.net/pdf?id=YFdopzmpdr",
        "keywords": "continual learning; incremental learning; stability-plasticity dilemma",
        "abstract": "The quest for Continual Learning (CL) seeks to empower neural networks with the ability to learn and adapt incrementally. Central to this pursuit is addressing the stability-plasticity dilemma, which involves striking a balance between two conflicting objectives: preserving previously learned knowledge and acquiring new knowledge. Existing studies have proposed numerous CL methods to achieve this trade-off. However, these methods often overlook the impact of basic architecture on stability and plasticity, thus the trade-off is limited to the parameter level. In this paper, we delve into the conflict between stability and plasticity at the architectural level. We reveal that under an equal parameter constraint, deeper networks exhibit better plasticity, while wider networks are characterized by superior stability. To address this architectural-level dilemma, we introduce a novel framework denoted Dual-Architecture (Dual-Arch), which serves as a plug-in component for CL. This framework leverages the complementary strengths of two distinct and independent networks: one dedicated to plasticity and the other to stability. Each network is designed with a specialized and lightweight architecture, tailored to its respective objective. Extensive experiments across datasets and CL methods demonstrate that Dual-Arch can enhance the performance of existing CL methods while being up to 87% more compact in terms of parameters than the baselines."
    },
    {
        "title": "Improving Offline-to-Online Reinforcement Learning with Q Conditioned State Entropy Exploration",
        "link_suffix": "/forum?id=tR2qSmSOQ3",
        "link": "https://openreview.net/forum?id=tR2qSmSOQ3",
        "pdf_link": "https://openreview.net/pdf?id=tR2qSmSOQ3",
        "keywords": "Offline-to-online Reinforcement Learning",
        "abstract": "Studying how to fine-tune offline reinforcement learning (RL) pre-trained policy is profoundly significant for enhancing the sample efficiency of RL algorithms. However, directly fine-tuning pre-trained policies often results in sub-optimal performance. This is primarily due to the distribution shift between offline pre-training and online fine-tuning stages. Specifically, the distribution shift limits the acquisition of effective online samples, ultimately impacting the online fine-tuning performance. In order to narrow down the distribution shift between offline and online stages, we proposed Q conditioned state entropy (QCSE) as intrinsic reward. Specifically, QCSE maximizes the state entropy of all samples individually, considering their respective Q values. This approach encourages exploration of low-frequency samples while penalizing high-frequency ones, and implicitly achieves State Marginal Matching (SMM), thereby ensuring optimal performance, solving the asymptotic sub-optimality of constraint-based approaches. Additionally, QCSE can seamlessly integrate into various RL algorithms, enhancing online fine-tuning performance. To validate our claim, we conduct extensive experiments, and observe significant improvements with QCSE ( about 10.9% for CQL and 8% for Cal-QL). Furthermore, we extended experimental tests to other algorithms, affirming the generality of QCSE."
    },
    {
        "title": "Dimension Agnostic Neural Processes",
        "link_suffix": "/forum?id=uGJxl2odR0",
        "link": "https://openreview.net/forum?id=uGJxl2odR0",
        "pdf_link": "https://openreview.net/pdf?id=uGJxl2odR0",
        "keywords": "Neural Processes, varying dimension, regression, bayesian optimization",
        "abstract": "Meta-learning aims to train models that can generalize to new tasks with limited labeled data by extracting shared features across diverse task datasets. Additionally, it accounts for prediction uncertainty during both training and evaluation, a concept known as uncertainty-aware meta-learning. Neural Process (NP) is a well-known uncertainty-aware meta-learning method that constructs implicit stochastic processes using parametric neural networks, enabling rapid adaptation to new tasks. However, existing NP methods face challenges in accommodating diverse input dimensions and learned features, limiting their broad applicability across regression tasks. To address these limitations and advance the utility of NP models as general regressors, we introduce Dimension Agnostic Neural Process (DANP). DANP incorporates Dimension Aggregator Block (DAB) to transform input features into a fixed-dimensional space, enhancing the model's ability to handle diverse datasets. Furthermore, leveraging the Transformer architecture and latent encoding layers, DANP learns a wider range of features that are generalizable across various tasks. Through comprehensive experimentation on various synthetic and practical regression tasks, we empirically show that DANP outperforms previous NP variations, showcasing its effectiveness in overcoming the limitations of traditional NP models and its potential for broader applicability in diverse regression scenarios."
    },
    {
        "title": "Input Compensation for Pruned Models",
        "link_suffix": "/forum?id=MKpiaqh7R0",
        "link": "https://openreview.net/forum?id=MKpiaqh7R0",
        "pdf_link": "https://openreview.net/pdf?id=MKpiaqh7R0",
        "keywords": "model pruning, model compression",
        "abstract": "Though foundation models are powerful, they are large and require substantial memory and computation resources for serving.\nTo tackle this issue, many pruning methods have been proposed to reduce the model size, thereby achieving memory and computational efficiency. These methods either identify and retrain the important weights or \\textit{adjust the unpruned weights} to compensate for the removed weights. In this paper, we propose a novel approach called input compensation (IC) to boost the performance of pruned models, i.e., \\textit{adjust the input} to compensate for the removed weights. We learn a compensation pool to construct input-dependent compensation to reduce the error caused by pruning. Different from existing pruning methods, which are designed in the parameter space, the proposed IC is designed in the input space. Hence, IC is complementary to existing methods and can be integrated with them.\nExtensive experiments on various tasks, including image classification, language modeling, and image generation, demonstrate that IC is effective in improving the performance of pruned models."
    },
    {
        "title": "Genomic Foundationless Models: Pretraining Does Not Promise Performance",
        "link_suffix": "/forum?id=kDZKEtDnT1",
        "link": "https://openreview.net/forum?id=kDZKEtDnT1",
        "pdf_link": "https://openreview.net/pdf?id=kDZKEtDnT1",
        "keywords": "genomics, biology, deep learning, pretraining",
        "abstract": "The success of Large Language Models has enabled the development of Genomic Foundation Models (GFMs) through similar unsupervised pretraining techniques. To assess the effectiveness of pretraining in genomics, we conducted a comprehensive evaluation of seven different GFMs across various benchmarks, comparing them to their counterparts with randomly initialized weights.  Surprisingly, we found that randomly initialized models can match or even surpass the performance of pretrained GFMs in finetuning and feature extraction tasks. We also discovered that pretrained GFMs fail to capture clinically relevant genetic mutations, which are crucial for understanding genetic disorders and phenotypic traits. Our results indicate that most of the current pretrained GFMs lack a ``foundational'' understanding of genomics and offer minimal utility, if any, even for basic tasks such as sequence classification. These findings highlight the need for developing novel architectures and training methods tailored for genomic applications. The code is available through this anonymous linkhttps://github.com/nxifemwt/GFMs."
    },
    {
        "title": "Multimodal Banking Dataset: Understanding Client Needs through Event Sequences",
        "link_suffix": "/forum?id=ns0KIpfQVy",
        "link": "https://openreview.net/forum?id=ns0KIpfQVy",
        "pdf_link": "https://openreview.net/pdf?id=ns0KIpfQVy",
        "keywords": "multimodal, multi-temporal, event sequence",
        "abstract": "Financial organizations collect a huge amount of data about clients that typically\nhas a temporal (sequential) structure and is collected from various sources (modal-\nities). Due to privacy issues, there are no large-scale open-source multimodal\ndatasets of event sequences, which significantly limits the research in this area. In\nthis paper, we present the industrial-scale publicly available multimodal banking\ndataset, MBD, that contains more than 2M corporate clients with several modal-\nities: 950M bank transactions, 1B geo position events, 5M embeddings of dia-\nlogues with technical support and monthly aggregated purchases of four bank\u2019s\nproducts. All entries are properly anonymized from real proprietary bank data.\nUsing this data, we introduce a novel multimodal benchmark that incorporates\ntwo open-source finansical datasets.We provide numerical results demonstrating\nour multimodal baselines\u2019 superiority over single-modal techniques for each task.\nAs a result, the proposed dataset and benchmark can open new perspectives and\nfacilitate the future development of practically important large-scale multimodal\nalgorithms for event sequences."
    },
    {
        "title": "VideoGuide: Improving Video Diffusion Models without Training Through a Teacher's Guide",
        "link_suffix": "/forum?id=VmR3QvfLxt",
        "link": "https://openreview.net/forum?id=VmR3QvfLxt",
        "pdf_link": "https://openreview.net/pdf?id=VmR3QvfLxt",
        "keywords": "diffusion model, video diffusion model, tuning-free, video generation",
        "abstract": "Text-to-image (T2I) diffusion models have revolutionized visual content creation, but extending these capabilities to text-to-video (T2V) generation remains a challenge, particularly in preserving temporal consistency. Existing methods that aim to improve consistency often cause trade-offs such as reduced imaging quality and impractical computational time. To address these issues we introduce VideoGuide, a novel framework that enhances the temporal consistency of pretrained T2V models without the need for additional training or fine-tuning. Instead, VideoGuide leverages any pretrained video diffusion model (VDM) or itself as a guide during the early stages of inference, improving temporal quality by interpolating the guiding model\u2019s denoised samples into the sampling model's denoising process. The proposed method brings about significant improvement in temporal consistency and image fidelity, providing a cost-effective and practical solution that synergizes the strengths of various video diffusion models. Furthermore, we demonstrate prior distillation, revealing that base models can achieve enhanced text coherence by utilizing the superior data prior of the guiding model through the proposed method. Project Page:https://videoguide2025.github.io/"
    },
    {
        "title": "Variational Bayesian Pseudo-Coreset",
        "link_suffix": "/forum?id=0NAVeUm7sk",
        "link": "https://openreview.net/forum?id=0NAVeUm7sk",
        "pdf_link": "https://openreview.net/pdf?id=0NAVeUm7sk",
        "keywords": "Bayesian Pseudo-Coreset, Variational Inference",
        "abstract": "The success of deep learning requires large datasets and extensive training, which can create significant computational challenges. To address these challenges, pseudo-coresets, small learnable datasets that mimic the entire data, have been proposed. Bayesian Neural Networks, which offer predictive uncertainty and probabilistic interpretation for deep neural networks, also face issues with large-scale datasets due to their high-dimensional parameter space. Prior works on Bayesian Pseudo-Coresets (BPC) attempt to reduce the computational load for computing weight posterior distribution by a small number of pseudo-coresets but suffer from memory inefficiency during BPC training and sub-optimal results. To overcome these limitations, we propose Variational Bayesian Pseudo-Coreset (VBPC), a novel approach that utilizes variational inference to efficiently approximate the posterior distribution, reducing memory usage and computational costs while improving performance across benchmark datasets."
    },
    {
        "title": "Blind Baselines Beat Membership Inference Attacks for Foundation Models",
        "link_suffix": "/forum?id=BXMoS69LLR",
        "link": "https://openreview.net/forum?id=BXMoS69LLR",
        "pdf_link": "https://openreview.net/pdf?id=BXMoS69LLR",
        "keywords": "machine learning privacy, evaluation, membership inference attacks, machine learning security, foundation models",
        "abstract": "Membership inference (MI) attacks try to determine if a data sample was used to train a machine learning model. For foundation models trained on unknown Web data, MI attacks are often used to detect copyrighted training materials, measure test set contamination, or audit machine unlearning. Unfortunately, we find that evaluations of MI attacks for foundation models are flawed, because they sample members and non-members from different distributions. For 9 published MI evaluation datasets, we show that blind attacks---that distinguish the member and non-member distributions without looking at any trained model---outperform state-of-the-art MI attacks. Existing evaluations thus tell us nothing about membership leakage of a foundation model's training data."
    }
]
[
    {
        "title": "G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model",
        "link_suffix": "/forum?id=px1674Wp3C",
        "link": "https://openreview.net/forum?id=px1674Wp3C",
        "pdf_link": "https://openreview.net/pdf?id=px1674Wp3C",
        "keywords": "Large Language Model, Mathematical Reasoning",
        "abstract": "Large language models (LLMs) have shown remarkable proficiency in human-level reasoning and generation capabilities, which encourages extensive research on their application in mathematical problem solving. However, current work has been largely focused on text-based mathematical problems, with limited investigation in problems involving multi-modal geometric information. Addressing this gap, we aim to enable LLMs to solve geometric problems by understanding image input. We first identify the limitations of current Multimodal Large Language Models (MLLMs) in this area: they struggle to accurately comprehend basic geometric elements and their relationships. To address these challenges, we leverage the inherent attribute of logical structure compactness in geometric figures, utilizing text-only Large Language Models (LLMs) to curate a comprehensive multimodal geometry dataset. This dataset, named Geo170k, contains more than 170K geometric image-caption and question-answer pairs. Utilizing the Geo170k dataset, we introduce G-LLaVA, a model that demonstrates exceptional performance in solving geometric problems. It significantly outperforms GPT4-V on the geometry task of MathVista benchmark with only 7B parameters."
    },
    {
        "title": "Complementary Label Learning with Positive Label Guessing and Negative Label Enhancement",
        "link_suffix": "/forum?id=LPRxGZ7Oax",
        "link": "https://openreview.net/forum?id=LPRxGZ7Oax",
        "pdf_link": "https://openreview.net/pdf?id=LPRxGZ7Oax",
        "keywords": "Complementary label learning, negative label enhancement, weakly supervised learning",
        "abstract": "Complementary label learning (CLL) is a weakly supervised learning paradigm that constructs a multi-class classifier only with complementary labels, specifying classes that the instance does not belong to. We reformulate CLL as an inverse problem that infers the full label information from the output space information. To be specific, we propose to split the inverse problem into two subtasks: positive label guessing (PLG) and negative label enhancement (NLE), collectively called PLNL. Specifically, we use well-designed criteria for evaluating the confidence of the model output, accordingly divide the training instances into three categories: highly-confident, moderately-confident and under-confident. For highly-confident instances, we perform PLG to assign them pseudo labels for supervised training. For moderately-confident and under-confident instances, we perform NLE by enhancing their negative label set with different levels and train them with the augmented negative labels iteratively. In addition, we unify PLG and NLE into a consistent framework, in which we can view all the pseudo-labeling-based methods from the perspective of negative label recovery. We prove that the error rates of both PLG and NLE are upper bounded, and based on that we can construct a classifier consistent with that learned by clean full labels. Extensive experiments demonstrate the superiority of PLNL over the state-of-the-art CLL methods, e.g., on STL-10, we increase the classification accuracy from 34.96% to 55.25%. The code has been submitted to supplementary material."
    },
    {
        "title": "Automatic Jailbreaking of Text-to-Image Generative AI Systems for Copyright Infringement",
        "link_suffix": "/forum?id=t1nZzR7ico",
        "link": "https://openreview.net/forum?id=t1nZzR7ico",
        "pdf_link": "https://openreview.net/pdf?id=t1nZzR7ico",
        "keywords": "Copyright, jailbreaking, T2I model",
        "abstract": "Recent AI systems have shown extremely powerful performance, even surpassing human performance, on various tasks such as information retrieval, language generation, and image generation based on large language models (LLMs). At the same time, there are diverse safety risks that can cause the generation of malicious contents by circumventing the alignment in LLMs, which are often referred to as jailbreaking. However, most of the previous works only focused on the text-based jailbreaking in LLMs, and the jailbreaking of the text-to-image (T2I) generation system has been relatively overlooked. In this paper, we first evaluate the safety of the commercial T2I generation systems, such as ChatGPT, Copilot, and Gemini, on copyright infringement with naive prompts. From this empirical study, we find that Copilot and Gemini block only 5% and 11.25% of the attacks with naive prompts, respectively, while ChatGPT blocks 96.25% of them. Then, we further propose a stronger automated jailbreaking pipeline for T2I generation systems, which produces prompts that bypass their safety guards. Our automated jailbreaking framework leverages an LLM optimizer to generate prompts to maximize degree of violation from the generated images without any weight updates or gradient computation. Surprisingly, our simple yet effective approach successfully jailbreaks the Copilot and ChatGPT with 0.0% and 6.25% block rate, respectively, making it generate copyrighted contents in 73.3% of the time. Finally, we explore various defense strategies, such as post-generation filtering and machine unlearning techniques, but found that they were inadequate, which suggests the necessity of stronger defense mechanisms."
    },
    {
        "title": "Provable Convergence of Single-Timescale Neural Actor-Critic in Continuous Spaces",
        "link_suffix": "/forum?id=iC4hBE9xYe",
        "link": "https://openreview.net/forum?id=iC4hBE9xYe",
        "pdf_link": "https://openreview.net/pdf?id=iC4hBE9xYe",
        "keywords": "Single-Timescale Actor-Critic, Continuous State-Action Space, Deep Neural Networks",
        "abstract": "Actor-critic (AC) algorithms have been the powerhouse behind many successful yet challenging applications. However, the theoretical understanding of finite-time convergence in AC's most practical form remains elusive. Existing research often oversimplifies the algorithm and only considers simple finite state and action spaces. We analyze the more practical single-timescale AC on continuous state and action spaces and use deep neural network approximations for both critic and actor. \nOur analysis reveals that the iterates of the more practical framework we consider converge towards the stationary point at rate $\\widetilde{\\mathcal{O}}(T^{-1/2})+\\widetilde{\\mathcal{O}}(m^{-1/2})$, where $T$ is the total number of iterations and $m$ is the width of the deep neural network.  To our knowledge, this is the first finite-time analysis of single-timescale AC in continuous state and action spaces, which further narrows the gap between theory and practice."
    },
    {
        "title": "Linearly Controlled Language Generation with Performative Guarantees",
        "link_suffix": "/forum?id=t8ctvylFn7",
        "link": "https://openreview.net/forum?id=t8ctvylFn7",
        "pdf_link": "https://openreview.net/pdf?id=t8ctvylFn7",
        "keywords": "control theory, representation engineering, large language models",
        "abstract": "The increasing prevalence of Large Language Models (LMs) in critical applications highlights the need for controlled language generation strategies that are not only computationally efficient but that also enjoy performance guarantees. To achieve this, we use a common model of concept semantics as linearly represented in an LM\u2019s latent space. In particular, we take the view that natural language generation traces a trajectory in this continuous semantic space, realized by the language model\u2019s hidden activations. This view permits a control-theoretic treatment of text generation in latent space, in which we propose a lightweight, gradient-free intervention that dynamically steers trajectories away from regions corresponding to undesired meanings. Crucially, we show that this intervention, which we compute in closed form, is guaranteed (in probability) to steer the output into the allowed region. Finally, we demonstrate on a toxicity avoidance objective that the intervention steers language away from undesired content while maintaining text quality."
    },
    {
        "title": "Can Model Randomization Offer Robustness Against Query-Based Black-Box Attacks?",
        "link_suffix": "/forum?id=DpnY7VOktT",
        "link": "https://openreview.net/forum?id=DpnY7VOktT",
        "pdf_link": "https://openreview.net/pdf?id=DpnY7VOktT",
        "keywords": "query-based black-box attacks, model randomness, diversity, adversarial defense, trustworthy machine learning, safety and responsible AI",
        "abstract": "Deep neural networks are misguided by simple-to-craft, imperceptible adversarial perturbations to inputs. Now, it is possible to craft such perturbations solely using model outputs and black-box attack algorithms. These algorithms compute adversarial examples by iteratively querying a model and inspecting responses. Attacks success in near information vacuums pose a significant challenge for developing\nmitigations. We investigate a new idea for a defense driven by a fundamental insight\u2014to compute an adversarial example, attacks depend on the relationship between successive responses to queries to optimize a perturbation. Therefore, to obfuscate this relationship, we investigate randomly sampling a model from a set to generate a response to a query. Effectively, this model randomization violates the attacker's expectation of the unknown parameters of a model to remain static between queries to extract information to guide the search toward an adversarial example. It is not immediately clear if model randomization can lead to sufficient obfuscation to confuse query-based black-box attacks or how such a method could be built. Our theoretical analysis proves model randomization always increases resilience to query-based black-box attacks. We demonstrate with extensive empirical studies using 6 state-of-the-art attacks under all three perturbation objectives ($l_\\infty, l_2, l_0$) and adaptive attacks, our proposed method injects sufficient uncertainty through obfuscation to yield a highly effective defense."
    },
    {
        "title": "EIBench: Assessing the Emotion Interpretation ability of Vision Large Language Models",
        "link_suffix": "/forum?id=AuckJjoD99",
        "link": "https://openreview.net/forum?id=AuckJjoD99",
        "pdf_link": "https://openreview.net/pdf?id=AuckJjoD99",
        "keywords": "Emotion Interpretation, Large Language Model",
        "abstract": "Affect computing is crucial in fields such as human-computer interaction, healthcare, and market research, yet emotion's ambiguity and subjectivity challenge current recognition techniques. We propose Emotion Interpretation (EI), a task that interprets the reasons behind emotions, and create the Emotion Interpretation Benchmark (EIBench) using a VLLM-assisted dataset construction method, Coarse-to-Fine Self-Ask (CFSA), with carefully human in-the-loop annotation. EIBench includes 1,615 basic and 50 multi-faceted complex emotion interpretation samples. Experiments show limited proficiency of existing models in EI, with the best achieving 62.41% accuracy in the zero-shot setting and some performing lower than the text-only LLaMA-3 model (6.26%) in the caption-provided setting. Different personas assigned also differ the benchmark results. Overcoming the challenges posed by EI can result in more empathetic AI systems, thereby enhancing human-computer interaction and emotion-sensitive applications."
    },
    {
        "title": "Calibrated Physics-Informed Uncertainty Quantification",
        "link_suffix": "/forum?id=cF6OoaYcRa",
        "link": "https://openreview.net/forum?id=cF6OoaYcRa",
        "pdf_link": "https://openreview.net/pdf?id=cF6OoaYcRa",
        "keywords": "Surrogate Models, Uncertainty Quantification, Neural-PDE, Physics-Informed, Conformal Prediction",
        "abstract": "Neural PDEs have emerged as inexpensive surrogate models for numerical PDE solvers. While they offer efficient approximations, they often lack robust uncertainty quantification (UQ), limiting their practical utility. Existing UQ methods for these models typically have high computational demands and lack guarantees. We introduce a novel framework for calibrated physics-informed uncertainty quantification to address these limitations. Our approach leverages physics residual errors as a nonconformity score within a conformal prediction (CP) framework. This enables data-free, model-agnostic, and statistically guaranteed uncertainty estimates. Our framework utilises convolutional layers as finite difference stencils for gradient estimation, our framework provides inexpensive coverage bounds for the violation of conservation laws within model predictions. In our experiments, we utilise CP to obtain marginal coverage for each cell and joint coverage over the entire prediction domain of various PDEs."
    },
    {
        "title": "The Buffer Mechanism for Multi-Step Information Reasoning in Language Models",
        "link_suffix": "/forum?id=5Ky0W6sp8W",
        "link": "https://openreview.net/forum?id=5Ky0W6sp8W",
        "pdf_link": "https://openreview.net/pdf?id=5Ky0W6sp8W",
        "keywords": "Large language model, buffer mechanism, thinking strategies, multi-step reasoning",
        "abstract": "Large language models have consistently struggled with complex reasoning tasks, such as mathematical problem-solving. Investigating the internal reasoning mechanisms of these models can help us design better model architectures and training strategies, ultimately enhancing their reasoning capability. In this study, we constructed a symbolic dataset to investigate the mechanisms by which Transformer models employ vertical thinking strategy based on their inherent structure and horizontal thinking strategy based on Chain of Thought to achieve multi-step reasoning. We introduced the concept of buffer mechanism: the model stores various information in distinct buffers and selectively extracts them through the query-key matrix. We proposed a random matrix-based algorithm to enhance the model's reasoning ability, resulting in a 75% reduction in the training time required for the GPT-2 model to achieve generalization capability on the PrOntoQA dataset. These findings provide new insights into understanding the mechanisms of large language models."
    },
    {
        "title": "Emergence of a High-Dimensional Abstraction Phase in Language Transformers",
        "link_suffix": "/forum?id=0fD3iIBhlV",
        "link": "https://openreview.net/forum?id=0fD3iIBhlV",
        "pdf_link": "https://openreview.net/pdf?id=0fD3iIBhlV",
        "keywords": "interpretability, intrinsic dimension, large language models",
        "abstract": "A language model (LM) is a mapping from a linguistic context to an output token. However, much remains to be known about this mapping, including how its geometric properties relate to its function. We take a high-level geometric approach to its analysis, observing, across five pre-trained transformer-based LMs and three input datasets, a distinct phase characterized by high intrinsic dimensionality. During this phase, representations (1) correspond to the first full linguistic abstraction of the input; (2) are the first to viably transfer to downstream tasks; (3) predict each other across different LMs. Moreover, we find that an earlier onset of the phase strongly predicts better language modelling performance. In short, our results suggest that a central high-dimensionality phase underlies core linguistic processing in many common LM architectures."
    },
    {
        "title": "Domain-specific Benchmarking of Vision-Language Models: A Task Augmentation Framework Using Metadata",
        "link_suffix": "/forum?id=1CeIRl147S",
        "link": "https://openreview.net/forum?id=1CeIRl147S",
        "pdf_link": "https://openreview.net/pdf?id=1CeIRl147S",
        "keywords": "VLM, Benchmark, Annotation, Ambiguity",
        "abstract": "The reliable and objective evaluation of AI models is essential for measuring scientific progress and translating methods into practice. However, in the nascent field of multimodal foundation models, validation has proven to be even more complex and error-prone compared to the field of narrow, task-specific AI. One open question that has not received much attention is how to set up strong vision language model (VLM) benchmarks while sparing human annotation costs. This holds specifically for domain-specific foundation models designed to serve a predefined specific purpose (e.g. pathology, autonomous driving) for which performance on test data should translate into real-life success. Given this gap in the literature, our contribution is three-fold: (1) In analogy to the concept of data augmentation in traditional ML, we propose the concept of task augmentation - a resource-efficient method for creating multiple tasks from a single existing task using metadata annotations. To this end, we use three sources to enhance existing datasets with relevant metadata: human annotators (e.g. for annotating truncation), predefined rules (e.g. for converting instance segmentations to the number of objects), and existing models (e.g. depth models to compute which object is closer to the camera). (2) We apply our task augmentation concept to several domains represented by the well-known data sets COCO (e.g. kitchen, wildlife domain) and KITTI (autonomous driving domain) datasets to generate domain-specific VLM benchmarks with highly reliable reference data. As a unique feature compared to existing benchmarks, we quantify the ambiguity of the human answer for each task for each image by acquiring human answers from a total of six raters, contributing a total of 162,946 human baseline answers to the 37,171 tasks generated on 1,704 images. (3) Finally, we use our framework to benchmark a total of 21 open and frontier closed models. Our large-scale analysis suggests that (I) model performance varies across domains, (II) open models have narrowed the gap to closed models significantly, (III) the recently released Qwen2 72B is the strongest open model, (IV) human raters outperform all VLMs by a large margin, and (V) many open models (56%) perform worse than the random baseline. By analyzing performance variability and relations across domains and tasks, we further show that task augmentation is a viable strategy for transforming single tasks into many and could serve as a blueprint for addressing dataset sparsity in various domains."
    },
    {
        "title": "Embedding Learning for Approximating Person-specific Cognitive Similarity",
        "link_suffix": "/forum?id=EQz0C5PSyR",
        "link": "https://openreview.net/forum?id=EQz0C5PSyR",
        "pdf_link": "https://openreview.net/pdf?id=EQz0C5PSyR",
        "keywords": "Psychological embedding, Metric learning, Similarity, Cognitive representation, Autoencoder, Medical image",
        "abstract": "Metric learning is often applied in scenarios where labels are well-defined or where there is a ground truth for semantic similarity between data points. However, in expert domains such as medical data, where experts perceive features and similarities differently on an individual basis, modeling psychological embeddings at the individual level can be beneficial. Such embeddings can predict factors that influence behavior, such as individual uncertainty, and support personalized learning strategies. Despite this potential, the amount of person-specific behavioral data that can be collected through similarity behavior sampling is insufficient in most scenarios, making modeling individual cognitive embeddings challenging and underexplored. In this study, we proposed integrating supervised learning on small-scale similarity sampling data with unsupervised autoencoder-based manifold learning to approximate person-specific psychological embeddings with significantly improved similarity inference performance. We conducted a large-scale experiment with 121 clinical physicians, measured their cognitive similarities using medical image data, and implemented person-specific models. Our results demonstrate that even in complex expert domains, such as medical imaging, where cognitive similarity varies between individuals, person-specific psychological embeddings can be effectively approximated using limited behavioral data."
    },
    {
        "title": "KidSat: satellite imagery to map childhood poverty",
        "link_suffix": "/forum?id=JEmNgjuQHU",
        "link": "https://openreview.net/forum?id=JEmNgjuQHU",
        "pdf_link": "https://openreview.net/pdf?id=JEmNgjuQHU",
        "keywords": "satellite imagery, remote sensing, social science, global health, economic, health and development indicators",
        "abstract": "Satellite imagery has emerged as an important tool to analyze demographic, health, and development indicators. While various deep learning models have been built for these tasks, each is specific to a particular problem, with few standard benchmarks available. We propose a new dataset pairing satellite imagery and high-quality survey data on child poverty to benchmark satellite feature representations. Our dataset consists of 33,608 images, each 10 km \u00d7 10 km, from 16 countries in Eastern and Southern Africa in the time period 1997-2022. As defined by UNICEF, multidimensional child poverty comprises six fundamental factors\u2014housing, sanitation, water, nutrition, education, and health (UNICEF, 2021)\u2014which can be calculated from geocoded, face-to-face Demographic and Health Surveys (DHS) Program data. Using our dataset we benchmark multiple feature representations for encoding satellite imagery, from low-level satellite imagery models such as MOSAIKS (Rolf et al., 2021), to deep learning foundation models, which include both generic vision models such as DINOv2 (Oquab et al., 2023) and specific satellite imagery models such as SatMAE (Cong et al., 2022). As part of the benchmark, we test spatial as well as temporal generalization, by testing on unseen locations, and on data beyond the training years. We provide open source code to reproduce and extend our entire pipeline: building the satellite imagery dataset, obtaining ground truth data from DHS, and comparing the various models considered in our work."
    },
    {
        "title": "DiffStroke: High-Quality Mask-free Image Manipulation with Partial Sketches",
        "link_suffix": "/forum?id=3rnraGvyNr",
        "link": "https://openreview.net/forum?id=3rnraGvyNr",
        "pdf_link": "https://openreview.net/pdf?id=3rnraGvyNr",
        "keywords": "Image manipulation, sketch-based image editing, mask-free, diffusion model",
        "abstract": "Sketches offer a simple yet powerful way to represent object configurations, making them ideal for local image structure manipulation. Traditional methods often treat sketch-based editing as an image inpainting task, requiring both user-provided strokes and masks, which hinders the user experience. Although recent mask-free stroke-based editing methods are more convenient, they often produce significant artifacts or unintentionally modify irrelevant regions. To overcome these challenges, we propose DiffStroke, a mask-free method for high-quality image editing using only partial sketches. Trainable plug-and-play Image-Stroke Fusion (ISF) modules and an effective mask estimator are developed to address the limitations of previous conditional control diffusion models in preserving style consistency and protecting irrelevant areas. The ISF modules fuse stroke encodings with source image features as input conditions, enabling DiffStroke to control local shapes while preserving overall style consistency. The mask estimator automatically predicts masks to preserve irrelevant regions without the need for manual input. Specifically, DiffStroke blends the estimated clean latent image with the encoded source image using the predicted mask, with the mask estimator trained to minimize the error between the blended result and the latent target image. Experimental results on natural and facial images demonstrate that DiffStroke outperforms previous methods in both simple and complex stroke-based image editing tasks."
    },
    {
        "title": "Self-Supervised Grid Cells Without Path Integration",
        "link_suffix": "/forum?id=UIZyvnA0yi",
        "link": "https://openreview.net/forum?id=UIZyvnA0yi",
        "pdf_link": "https://openreview.net/pdf?id=UIZyvnA0yi",
        "keywords": "Grid cells, Path Integration, AI, NeuroAI",
        "abstract": "Grid cells, found in the medial Entorhinal Cortex, are known for their regular spatial firing patterns. These cells have been proposed as the neural solution to a range of computational tasks, from performing path integration to serving as a metric for space. Their exact function, however, remains fiercely debated. In this work, we explore the consequences of demanding local distance preservation in networks subject to a capacity constraint. We consider two distinct self-supervised models, a feedforward network that learns to solve a purely spatial, local distance-based encoding task, and a recurrent network that solves the same problem during path integration. Surprisingly, we find that this task leads to the emergence of highly grid cell-like representations in both networks. However, the recurrent network also features units with band-like representations. We subsequently prune velocity inputs to subsets of recurrent units, and find that their grid score is negatively correlated with path integration contribution. Thus, grid cells emerge without path integration in the feedforward network, and they appear significantly less important than band cells for path integration in the recurrent network. Our work provides a minimal model for learning grid-like spatial representations, and questions the role of grid cells as neural path integrators. Instead, it seems that local distance preservation and high population capacity is a more likely candidate task for learning grid cells in artificial neural networks."
    },
    {
        "title": "Collaborative Discrete-Continuous Black-Box Prompt Learning for Language Models",
        "link_suffix": "/forum?id=sdLGY9Dj5r",
        "link": "https://openreview.net/forum?id=sdLGY9Dj5r",
        "pdf_link": "https://openreview.net/pdf?id=sdLGY9Dj5r",
        "keywords": "Black-box prompt learning, discrete optimization",
        "abstract": "Large Scale Pre-Trained Language Models (PTMs) have demonstrated unprecedented capabilities across diverse natural language processing tasks. \nAdapting such models to downstream tasks is computationally intensive  and time-consuming, particularly in black-box scenarios common in Language-Model-as-a-Service (LMaaS) environments, where model parameters and gradients are inaccessible. Recently, black-box prompt learning using zeroth-order gradients has emerged as a promising approach to address these challenges by optimizing learnable continuous prompts in embedding spaces, starting with \\textit{randomly initialized discrete text prompts}.  However, its reliance on randomly initialized discrete prompts limits adaptability to diverse downstream tasks or models. To address this limitation,\nthis paper introduces ZO-PoG, a novel framework that optimizes prompts through a collaborative approach, combining Policy Gradient optimization for initial discrete text prompts and Zeroth-Order optimization for continuous prompts in embedding space. By optimizing collaboratively between discrete and continuous prompts, ZO-PoG maximizes adaptability to downstream tasks, achieving superior results without direct access to the model\u2019s internal structures.\nImportantly, we establish the sub-linear convergence of ZO-PoG under mild assumptions.\nThe experiments on different datasets demonstrate significant improvements in various tasks compared to the baselines. \nOur code is available at the following anonymous URL:https://anonymous.4open.science/r/ZO-PoG-12B4."
    },
    {
        "title": "Singular Value Adaptation for Parameter-Efficient Fine Tuning",
        "link_suffix": "/forum?id=VpeAsLmcvg",
        "link": "https://openreview.net/forum?id=VpeAsLmcvg",
        "pdf_link": "https://openreview.net/pdf?id=VpeAsLmcvg",
        "keywords": "Transfer learning, Adaptation, Parameter-Efficient Fine-tuning",
        "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has become a crucial approach in handling the growing complexity of large models and vast datasets across multiple fields such as Computer Vision or Natural Language Processing. Among the most promising of these methods are Low-Rank Adaptation (LoRA) and its derivatives, which fine-tune a pre-trained weight matrix $\\mathbf{W}$ by introducing a low-rank update matrix $\\mathbf{\\Delta W}$. While these approaches have demonstrated strong empirical performance, they remain largely heuristic, with little theoretical grounding to explain their behavior or guide the design of $\\mathbf{\\Delta W}$ for different objectives. This lack of theoretical insight limits our understanding of when these methods are most effective and how they can be systematically improved. In this paper, we propose a theoretical framework for analyzing and designing LoRA-based methods, with a focus on the formulation of $\\mathbf{\\Delta W}$. By establishing a deeper understanding of the interplay between $\\mathbf{W}$ and $\\mathbf{\\Delta W}$, we aim to enable more efficient and targeted fine-tuning strategies, opening the door to novel variants that strike an optimal balance between performance and efficiency. Our proposed method - \\textbf{Si}ngular \\textbf{V}alue \\textbf{A}daptation - uses insights from our theoretical framework to incorporate inductive biases on the formulation of $\\mathbf{\\Delta W}$, leading to a PEFT method that is up to 50$\\times$ more parameter efficient that LoRA, while achieving comparable or better performance across various vision and language tasks."
    },
    {
        "title": "Effective and Efficient Adversarial Detection for Vision-Language Models via A Single Vector",
        "link_suffix": "/forum?id=EWP9BVRRbA",
        "link": "https://openreview.net/forum?id=EWP9BVRRbA",
        "pdf_link": "https://openreview.net/pdf?id=EWP9BVRRbA",
        "keywords": "Visual Language Models, Adversarial Attacks, Attacking Directions, Adversarial Defense, Detection of Adversarial Samples",
        "abstract": "Visual Language Models (VLMs) are vulnerable to adversarial attacks, especially those from adversarial images, which is however under-explored in literature.\nTo facilitate research on this critical safety problem, we first construct a new laRge-scaleAdervsarial images dataset withDiverse hArmfulResponses (RADAR), given that existing datasets are either small-scale or only contain limited types of harmful responses.\nWith the new RADAR dataset, we further develop a novel and effective  iN-timeEmbedding-basedAdveRSarialImageDEtection (NEARSIDE) method, which exploits a single vector that distilled from the hidden states of VLMs, which we callthe attacking direction, to achieve the detection of adversarial images against benign ones in the input. \nExtensive experiments with two victim VLMs, LLaVA and MiniGPT-4, well demonstrate the effectiveness, efficiency,\nand cross-model transferrability of our proposed method. Our code is included in the supplementary file and will be made publicly available."
    },
    {
        "title": "Training-Free Retrieval-Augmented Generation for Knowledge-Intensive Visual Question Answering",
        "link_suffix": "/forum?id=IlleFmPNb6",
        "link": "https://openreview.net/forum?id=IlleFmPNb6",
        "pdf_link": "https://openreview.net/pdf?id=IlleFmPNb6",
        "keywords": "Retrieval-Augmented Generation, Visual Question Answering, Multi-modal Large Language Model",
        "abstract": "Recent advancements in multimodal large language models (MLLMs) have achieved strong performance in vision-language tasks such as visual question answering (VQA). However, these models struggle with knowledge-intensive VQA (KI-VQA) tasks that require fine-grained domain knowledge, as seen in benchmarks such as Encyclopedic VQA and InfoSeek. To address these challenges, we propose a novel retrieval-augmented generation (RAG) framework, referred to as KIRA, designed to enhance the capability of MLLMs for KI-VQA without task-specific fine-tuning. Our target is to integrate general image-text similarity with detailed knowledge context to achieve precise entity recognition. To this end, we leverage CLIP to obtain general image-text matching, and design a verification mechanism according to detailed question-text relevance to improve recognition accuracy. We evaluate our method on KI-VQA benchmarks, demonstrating significant improvements of 47.5% on Encyclopedic VQA and 16.2% on InfoSeek, all achieved without additional training. These results highlight the potential of our training-free, plug-and-play framework for solving knowledge-intensive visual question answering tasks."
    },
    {
        "title": "Relation-Aware Diffusion for Heterogeneous Graphs with Partially Observed Features",
        "link_suffix": "/forum?id=TPYwwqF0bv",
        "link": "https://openreview.net/forum?id=TPYwwqF0bv",
        "pdf_link": "https://openreview.net/pdf?id=TPYwwqF0bv",
        "keywords": "missing features, imputation, heterogeneous graph",
        "abstract": "Diffusion-based imputation methods, which impute missing features through the iterative propagation of observed features, have shown impressive performance in homogeneous graphs. However, these methods are not directly applicable to heterogeneous graphs, which have multiple types of nodes and edges, due to two key issues: (1) the presence of nodes with undefined features hinders diffusion-based imputation; (2) treating various edge types equally during diffusion does not fully utilize information contained in heterogeneous graphs. To address these challenges, this paper presents a novel imputation scheme that enables diffusion-based imputation in heterogeneous graphs. Our key idea involves (1) assigning a {\\it virtual feature} to an undefined node feature and (2) determining the importance of each edge type during diffusion according to a new criterion. Through experiments, we demonstrate that our virtual feature scheme effectively serves as a bridge between existing diffusion-based methods and heterogeneous graphs, maintaining the advantages of these methods. Furthermore, we confirm that adjusting the importance of each edge type leads to significant performance gains on heterogeneous graphs. Extensive experimental results demonstrate the superiority of our scheme in both semi-supervised node classification and link prediction tasks on heterogeneous graphs with missing rates ranging from low to exceedingly high."
    },
    {
        "title": "Towards Lightweight Deep Watermarking Framework",
        "link_suffix": "/forum?id=j7b4mm7Ec9",
        "link": "https://openreview.net/forum?id=j7b4mm7Ec9",
        "pdf_link": "https://openreview.net/pdf?id=j7b4mm7Ec9",
        "keywords": "machine vision, deep learning-based watermarking",
        "abstract": "Deep learning-based watermarking models play a crucial role in copyright protection across various applications. However, many high-performance models are limited in practical deployment due to their large number of parameters. Meanwhile, the robustness and invisibility performance of existing lightweight models are unsatisfactory. This presents a pressing need for a watermarking model that combines lightweight capacity with satisfactory performance. Our research identifies a key reason that limits the performance of existing watermarking frameworks: a mismatch between commonly used decoding losses (e.g., mean squared error and binary cross-entropy loss) and the actual decoding goal, leading to parameter redundancy. We propose two innovative solutions: (1) Decoding-oriented surrogate loss (DO), which redesigns the loss function to mitigate the influence of decoding-irrelevant optimization directions; and (2) Detachable projection head (PH), which incorporates a detachable redundant module during training to handle these irrelevant directions and is discarded during inference. Additionally, we propose a novel watermarking framework comprising five submodules, allowing for independent parameter reduction in each component. Our proposed model achieves better efficiency, invisibility, and robustness while utilizing only 2.2% of the parameters compared to state-of-the-art frameworks. By improving efficiency while maintaining robust copyright protection, our model is well-suited for practical applications in resource-constrained environments. The DO and PH methods are designed to be plug-and-play, facilitating seamless integration into future lightweight models."
    },
    {
        "title": "Debiasing Vison-Language Models with Text-Only Training",
        "link_suffix": "/forum?id=vVVtTVIR5O",
        "link": "https://openreview.net/forum?id=vVVtTVIR5O",
        "pdf_link": "https://openreview.net/pdf?id=vVVtTVIR5O",
        "keywords": "Vison Language Models, Group Robustness, Fairness, CLIP",
        "abstract": "Pre-trained vision-language models (VLMs), such as CLIP, have exhibited remarkable performance across various downstream tasks by aligning text and images in a unified embedding space.  However, due to the imbalanced distribution of pre-trained datasets, CLIP suffers from the bias problem in real-world applications. Existing debiasing methods struggle to obtain sufficient image samples for minority groups and incur high costs for group labeling. To address the limitations, we propose aText-OnlyDebiasing framework calledTOD, leveraging a text-as-image training paradigm to mitigate visual biases. Specifically, this approach repurposes the text encoder to function as an image encoder, thereby eliminating the need for image data. Simultaneously, it utilizes a large language model (LLM) to generate a balanced text dataset, which is then used for prompt tuning. However, we observed that the model overfits to the text modality because label names, serving as supervision signals, appear explicitly in the texts. To address this issue, we further introduce a Multi-Target Prediction (MTP) task that motivates the model to focus on complex contexts and distinguish between target and biased information. Extensive experiments on the Waterbirds and CelebA datasets show that our method significantly improves group robustness, achieving state-of-the-art results among image-free methods and even competitive performance compared to image-supervised methods. Furthermore, the proposed method can be adapted to challenging scenarios with multiple or unknown bias attributes, demonstrating its strong generalization and robustness."
    },
    {
        "title": "TIPS: Two-Level Prompt for Rehearsal-free Continual Learning",
        "link_suffix": "/forum?id=QYgtZRTv3e",
        "link": "https://openreview.net/forum?id=QYgtZRTv3e",
        "pdf_link": "https://openreview.net/pdf?id=QYgtZRTv3e",
        "keywords": "Continual Learning; Prompt Learning; Catastrophic Forgetting",
        "abstract": "Continual learning based on prompt tuning creates a key-value pool, where these key-value pairs are called prompts. Prompts are retrieved using input images as queries and input into a frozen backbone network. It requires training only a few parameters to quickly adapt to downstream tasks. Compared to other traditional Continual learning methods, it is more effective in resisting catastrophic forgetting. However, the effectiveness of these methods heavily depends on the selection strategy. \nMost existing methods overlook the model plasticity since they focus on solving the model's stability issues, leading to a sharp decline in performance for new tasks in long task sequences of incremental learning.\nTo address these limitations, we propose a novel prompt-based continual learning method called TIPS, which mainly consists of two modules: (1) design a novel two-level prompt selection strategy combined with a set of adaptive weights for sparse joint tuning, aiming to improve the accuracy of prompt selection; (2) design a semantic distillation module that enhances the generalization ability to unknown new classes by creating a language token and utilizing the encapsulated semantic information of class names.\nWe validated TIPS on four datasets across three incremental scenarios. \nOur method outperformed the current state of the art (SOTA) by 2.03%, 4.78%, 1.18%, and 5.59% on CIFAR (10 tasks), ImageNet-R (20 tasks), CUB (10 tasks), and DomainNet (20 tasks). \nNotably, our approach consistently surpasses or matches SOTA in all settings, maintaining stable prompt selection accuracy throughout multiple incremental learning sessions."
    },
    {
        "title": "Rotated Runtime Smooth: Training-Free Activation Smoother for accurate INT4 inference",
        "link_suffix": "/forum?id=WG7GzGx3G9",
        "link": "https://openreview.net/forum?id=WG7GzGx3G9",
        "pdf_link": "https://openreview.net/pdf?id=WG7GzGx3G9",
        "keywords": "Large language model, Quantization, INT4 inference",
        "abstract": "Large language models have demonstrated promising capabilities upon scaling up parameters. However, serving large language models incurs substantial computation and memory movement costs due to their large scale. Quantization methods have been employed to reduce service costs and latency. Nevertheless, outliers in activations hinder the development of INT4 weight-activation quantization. Existing approaches separate outliers and normal values into two matrices or migrate outliers from activations to weights, suffering from high latency or accuracy degradation. Based on observing activations from large language models, outliers can be classified into channel-wise and spike outliers.\nIn this work, we propose Rotated Runtime Smooth (RRS), a plug-and-play activation smoother for quantization, consisting of Runtime Smooth and the Rotation operation. Runtime Smooth (RS) is introduced to eliminatechannel-wise outliersby smoothing activations with channel-wise maximums during runtime. The Rotation operation can narrow the gap betweenspike outliersand normal values, alleviating the effect of victims caused by channel-wise smoothing.\nThe proposed method outperforms the state-of-the-art method in the LLaMA and Qwen families and improves WikiText-2 perplexity from 57.33 to 6.66 for INT4 inference."
    },
    {
        "title": "Unearthing Large Scale Domain-Specific Knowledge from Public Corpora",
        "link_suffix": "/forum?id=8EM1A6qfX5",
        "link": "https://openreview.net/forum?id=8EM1A6qfX5",
        "pdf_link": "https://openreview.net/pdf?id=8EM1A6qfX5",
        "keywords": "domain-specific knowledge, data collection, large language model",
        "abstract": "Large language models (LLMs) have demonstrated remarkable potential in various tasks, however, there remains a significant lack of open-source models and data for specific domains. Previous work has primarily focused on manually specifying resources and collecting high-quality data for specific domains, which is extremely time-consuming and labor-intensive. To address this limitation, we introduce large models into the data collection pipeline to guide the generation of domain-specific information and retrieve relevant data from Common Crawl (CC), a large public corpus. We refer to this approach as Retrieve-from-CC. It not only collects data related to domain-specific knowledge but also mines the data containing potential reasoning procedures from the public corpus. By applying this method, we have collected a knowledge domain-related dataset named Retrieve-Pile, which covers four main domains, including the sciences, humanities, and other categories. Through the analysis of Retrieve-Pile, Retrieve-from-CC can effectively retrieve relevant data from the covered knowledge domains and significantly improve the performance in tests of mathematical and knowledge-related reasoning abilities."
    }
]
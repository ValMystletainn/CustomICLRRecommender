[{"title": "Variational Search Distributions", "link_suffix": "/forum?id=1vrpdV9U3i", "link": "https://openreview.net/forum?id=1vrpdV9U3i", "pdf_link": "https://openreview.net/pdf?id=1vrpdV9U3i", "keywords": "black box optimization, Bayesian optimization, variational inference, generative models, level set estimation", "abstract": "We develop variational search distributions (VSD), a method for finding discrete, combinatorial designs of a rare desired class in a batch sequential manner with a fixed experimental budget. We formalize the requirements and desiderata for this problem and formulate a solution via variational inference. In particular, VSD uses off-the-shelf gradient based optimization routines, can learn powerful generative models for designs, and can take advantage of scalable predictive models. We derive asymptotic convergence rates for learning the true conditional generative distribution of designs with certain configurations of our method. After illustrating the generative model on images, we empirically demonstrate that VSD can outperform existing baseline methods on a set of real sequence-design problems in various biological systems.", "title_embedding_index": 9150, "title_abs_embedding_index": 9175}, {"title": "Verbalized Bayesian Persuasion", "link_suffix": "/forum?id=E6B0bbMFbi", "link": "https://openreview.net/forum?id=E6B0bbMFbi", "pdf_link": "https://openreview.net/pdf?id=E6B0bbMFbi", "keywords": "Large Language Models, Information Design, Bayesian Persuasion, Game Theory, Multiagent Systems", "abstract": "The study of information design explores how an information designer can influence the optimal behavior of players to achieve a specific objective through the strategic selection of the information provided. \nThis paper focuses on a case, Bayesian Persuasion (BP), where the information designer holds an informational advantage over only one player.\nWhile information design originates from everyday human communication, traditional game-theoretic or multi-agent reinforcement learning methods often model information structures as discrete or continuous scalars or vectors, this approach fails to capture the nuances of natural language, significantly limiting their applicability in real-world scenarios.\nBy leveraging the powerful language understanding and generation capabilities of large language models (LLMs), this paper proposes a verbalized BP framework that extends classic BP to real-world games involving human dialogues for the first time. \nSpecifically, we map the classic BP to a verbalized mediator-augmented game, where LLMs instantiate the information designer and receiver.\nTo efficiently solve the game in the language space, we transform agents' policy optimization into prompt optimization and propose a generalized equilibrium-finding algorithm with a convergence guarantee. \nNumerical experiments in realistic dialogue scenarios, such as recommendation letters, courtroom interactions, and law enforcement, validate that the VBP framework can reproduce theoretical results in classic settings and discover effective persuasion strategies in more complex natural language and multistage settings.", "title_embedding_index": 9151, "title_abs_embedding_index": 9176}, {"title": "Multi-Task Best Arm Identification with Risk Constraint", "link_suffix": "/forum?id=eq8jOD0tgl", "link": "https://openreview.net/forum?id=eq8jOD0tgl", "pdf_link": "https://openreview.net/pdf?id=eq8jOD0tgl", "keywords": "Multi-Task\uff0cBest Arm Identification\uff0cRisk Constraint\uff0c Fixed Confidence", "abstract": "Best Arm Identification is a very challenging problem in sequential decision-making with many real-world applications. Existing works typically assume that all arms are feasible or/and deal with expectation-based constraints with strong assumptions, loose sample complexity bounds, and non-optimal algorithms. This paper introduces a multi-task best arm identification problem with risk constraint in the fixed-confidence setting, where each arm has multiple performance metrics. The agent aims to optimize one metric while ensuring that the quantiles of other metrics remain below specified thresholds for each task. We first derive a tight, instance-dependent lower bound on sample complexity. Based on this bound, we establish optimality conditions for the static optimal sampling ratio and illustrate how it balances among different tasks and constraints, while addressing the trade-off between optimality and feasibility. We derive a Track-and-Stop strategy with asymptotically optimal sample complexity and a computationally efficient strategy that iteratively solves the optimality conditions.  Finally, we extend our results to the linear bandit setting. Numerical experiments show that our algorithm performs relatively well.", "title_embedding_index": 9152, "title_abs_embedding_index": 9177}, {"title": "DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured LLM Inference", "link_suffix": "/forum?id=2c7pfOqu9k", "link": "https://openreview.net/forum?id=2c7pfOqu9k", "pdf_link": "https://openreview.net/pdf?id=2c7pfOqu9k", "keywords": "LLM inference, attention, memory-efficiency, tree-based decoding", "abstract": "Large language models (LLMs) are increasingly employed for complex tasks that process multiple generation calls in a tree structure with shared prefixes of tokens, including few-shot prompting, multi-step reasoning, speculative decoding, etc. However, existing inference systems for tree-based applications are inefficient due to improper partitioning of queries and KV cache during attention calculation.This leads to two main issues: (1) a lack of memory access (IO) reuse for KV cache of shared prefixes, and (2) poor load balancing.As a result, there is redundant KV cache IO between GPU global memory and shared memory, along with low GPU utilization. To address these challenges, we propose DeFT(Decoding with Flash Tree-Attention), a hardware-efficient attention algorithm with prefix-aware and load-balanced KV cache partitions. DeFT reduces the number of read/write operations of KV cache during attention calculation throughKV-Guided Grouping, a method that avoids repeatedly loading KV cache of shared prefixes in attention computation. Additionally, we proposeFlattened Tree KV Splitting, a mechanism that ensures even distribution of the KV cache across partitions with little computation redundancy, enhancing GPU utilization during attention computations. By reducing 73-99$%$ KV cache IO and nearly 100$%$ IO for partial results during attention calculation, DeFT achieves up to 2.52/3.82$\\times$ speedup in the end-to-end/attention latency across three practical tree-based workloads compared to state-of-the-art attention algorithms.", "title_embedding_index": 9153, "title_abs_embedding_index": 9178}, {"title": "Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models", "link_suffix": "/forum?id=77gQUdQhE7", "link": "https://openreview.net/forum?id=77gQUdQhE7", "pdf_link": "https://openreview.net/pdf?id=77gQUdQhE7", "keywords": "Best-of-N sampling, Reinforcement Learning, Language models", "abstract": "Recent studies indicate that effectively utilizing inference-time compute is crucial for attaining good performance from large language models (LLMs). Specifically, the Best-of-N (BoN) inference strategy, where an LLM generates multiple responses and a verifier selects the best, has shown strong empirical performance. Motivated by this, we develop a novel inference-aware fine-tuning paradigm, which encompasses the BoN-aware inference framework as a special case. We devise the first imitation learning and reinforcement learning (RL) methods for fine-tuning LLMs using BoN, overcoming the challenging, non-differentiable argmax operator in BoN. We empirically demonstrate that our BoN-aware models implicitly learn a per-example \"meta-strategy\", which interleaves best responses with more diverse responses that might be better suited to a test-time input\u2014a process reminiscent of the exploration-exploitation trade-off in RL. Our experiments demonstrate the effectiveness of BoN-aware fine-tuning in terms of improved performance and inference-time compute. In particular, we show that our methods improve the BoN performance of Gemma 2B on Hendrycks MATH from 26.8% to 30.8%, and Pass@K from 60% to 67%.", "title_embedding_index": 9154, "title_abs_embedding_index": 9179}, {"title": "SONAR: A Synthetic AI-Audio Detection Framework and Benchmark", "link_suffix": "/forum?id=rGGwXo0Fo0", "link": "https://openreview.net/forum?id=rGGwXo0Fo0", "pdf_link": "https://openreview.net/pdf?id=rGGwXo0Fo0", "keywords": "Audio deepfake detection, benchmarking", "abstract": "Recent advances in Text-to-Speech (TTS) and Voice-Conversion (VC) using generative Artificial Intelligence (AI) technology have made it possible to generate high-quality and realistic human-like audio. This introduces significant challenges to distinguishing AI-synthesized speech from the authentic human voice and could raise potential issues of misuse for malicious purposes such as impersonation and fraud, spreading misinformation, deepfakes, and scams. However, existing detection techniques for AI-synthesized audio have not kept pace and often exhibit poor generalization across diverse datasets. In this paper, we introduce SONAR, asynthetic AI-AudioDetectionFramework and Benchmark, aiming to provide a comprehensive evaluation for distinguishing cutting-edge AI-synthesized auditory content. SONAR includes a novel evaluation dataset sourced from 9 diverse audio synthesis platforms, including leading TTS providers and state-of-the-art TTS models. It is the first framework to uniformly benchmark AI-audio detection across both traditional and foundation model-based deepfake detection systems. Through extensive experiments, we reveal the generalization limitations of existing detection methods and demonstrate that foundation models exhibit stronger generalization capabilities, which can be attributed to their model size and the scale and quality of pretraining data. Additionally, we explore the effectiveness and efficiency of few-shot fine-tuning in improving generalization, highlighting its potential for tailored applications, such as personalized detection systems for specific entities or individuals. Code and dataset are available athttps://anonymous.4open.science/r/SONAR", "title_embedding_index": 9155, "title_abs_embedding_index": 9180}, {"title": "Neural Spacetimes for DAG Representation Learning", "link_suffix": "/forum?id=skGSOcrIj7", "link": "https://openreview.net/forum?id=skGSOcrIj7", "pdf_link": "https://openreview.net/pdf?id=skGSOcrIj7", "keywords": "Directed Graphs, Quasi-metrics", "abstract": "We propose a class of trainable deep learning-based geometries called Neural SpaceTimes (NSTs), which can universally represent nodes in weighted Directed Acyclic Graphs (DAGs) as events in a spacetime manifold. While most works in the literature focus on undirected graph representation learning or causality embedding separately, our differentiable geometry can encode both graph edge weights in its spatial dimensions and causality in the form of edge directionality in its temporal dimensions. We use a product manifold that combines a quasi-metric (for space) and a partial order (for time). NSTs are implemented as three neural networks trained in an end-to-end manner: an embedding network, which learns to optimize the location of nodes as events in the spacetime manifold, and two other networks that optimize the space and time geometries in parallel, which we call a neural (quasi-)metric and a neural partial order, respectively. The latter two networks leverage recent ideas at the intersection of fractal geometry and deep learning to shape the geometry of the representation space in a data-driven fashion, unlike other works in the literature that use fixed spacetime manifolds such as Minkowski space or De Sitter space to embed DAGs. Our main theoretical guarantee is a universal embedding theorem, showing that any $k$-point DAG can be embedded into an NST with $1+\\mathcal{O}(\\log(k))$ distortion while exactly preserving its causal structure. The total number of parameters defining the NST is sub-cubic in $k$ and linear in the width of the DAG. If the DAG has a planar Hasse diagram, this is improved to $\\mathcal{O}(\\log(k) + 2)$ spatial and 2 temporal dimensions. We validate our framework computationally with synthetic weighted DAGs and real-world network embeddings; in both cases, the NSTs achieve lower embedding distortions than their counterparts using fixed spacetime geometries.", "title_embedding_index": 9156, "title_abs_embedding_index": 9181}, {"title": "How to Find the Exact Pareto Front for Multi-Objective MDPs?", "link_suffix": "/forum?id=S4dItvpvAv", "link": "https://openreview.net/forum?id=S4dItvpvAv", "pdf_link": "https://openreview.net/pdf?id=S4dItvpvAv", "keywords": "Multi-objective optimization, Markov decision Process", "abstract": "Multi-objective Markov Decision Processes (MDPs) are receiving increasing attention, as real-world decision-making problems often involve conflicting objectives that cannot be addressed by a single-objective MDP. \nThe Pareto front identifies the set of policies that cannot be dominated, providing a foundation for finding Pareto optimal solutions that can efficiently adapt to various preferences.\nHowever, finding the Pareto front is a highly challenging problem. Most existing methods either (i) rely on traversing the continuous preference space, which is impractical and results in approximations that are difficult to evaluate against the true Pareto front, or (ii) focus solely on deterministic Pareto optimal policies, from which there are no known techniques to characterize the full Pareto front. Moreover, finding the structure of the Pareto front itself remains unclear even in the context of dynamic programming, where the MDP is fully known in advance.\nIn this work, we address the challenge of efficiently discovering the Pareto front. \nBy investigating the geometric structure of the Pareto front in MO-MDP, we uncover a key property: the Pareto front is on the boundary of a convex polytope whose vertices all correspond to deterministic policies, and neighboring vertices of the Pareto front differ by only one state-action pair of the deterministic policy, almost surely.\nThis insight transforms the global comparison across all policies into a localized search among deterministic policies that differ by only one state-action pair, drastically reducing the complexity of searching for the exact Pareto front. \nWe develop an efficient algorithm that identifies the vertices of the Pareto front by solving a single-objective MDP only once and then traversing the edges of the Pareto front, making it more efficient than existing methods. Furthermore, the entire Pareto front can be found in $V$ iterations, where $V$ represents the number of vertices on the Pareto front.\nOur empirical studies demonstrate the effectiveness of our theoretical strategy in discovering the Pareto front efficiently.", "title_embedding_index": 9157, "title_abs_embedding_index": 9182}, {"title": "Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning", "link_suffix": "/forum?id=sVNfWhtaJC", "link": "https://openreview.net/forum?id=sVNfWhtaJC", "pdf_link": "https://openreview.net/pdf?id=sVNfWhtaJC", "keywords": "in-context learning, differential privacy, large language models", "abstract": "Large Language Models (LLMs) rely on the contextual information embedded in examples/demonstrations to perform in-context learning (ICL). To mitigate the risk of LLMs potentially leaking private information contained in examples in the prompt, we introduce a novel data-adaptive differentially private algorithm calledAdaDPSynto generate synthetic examples from the private dataset and then use these synthetic examples to perform ICL. The objective of AdaDPSyn is to adaptively adjust the noise level in the data synthesis mechanism according to the inherent statistical properties of the data, thereby preserving high ICL accuracy while maintaining formal differential privacy guarantees. A key innovation in AdaDPSyn is thePrecision-Focused Iterative Radius Reductiontechnique, which dynamically refines the aggregation radius - the scope of data grouping for noise addition - based on patterns observed in data clustering, thereby minimizing the amount of additive noise. We conduct extensive experiments on standard benchmarks and compare AdaDPSyn with DP few-shot generation algorithm (Tang et al., 2023). The experiments demonstrate that AdaDPSyn not only outperforms DP few-shot generation, but also maintains high accuracy levels close to those of non-private baselines, providing an effective solution for ICL with privacy protection.", "title_embedding_index": 9158, "title_abs_embedding_index": 9183}, {"title": "Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation", "link_suffix": "/forum?id=cXxfVkRCHJ", "link": "https://openreview.net/forum?id=cXxfVkRCHJ", "pdf_link": "https://openreview.net/pdf?id=cXxfVkRCHJ", "keywords": "offline-to-online reinforcement learning, data augmentation, diffusion models", "abstract": "Offline-to-online Reinforcement Learning (O2O RL) aims to perform online fine-tuning on an offline pre-trained policy to minimize costly online interactions. Existing methods have used offline data or online data to generate new data for data augmentation, which has led to performance improvement during online fine-tuning. However, they have not fully analyzed and utilized both types of data simultaneously. Offline data helps prevent agents from settling too early on suboptimal policies by providing diverse data, while online data improves training stability and speeds up convergence. In this paper, we propose a data augmentation approach, Classifier-Free Diffusion Generation (CFDG). Considering the differences between offline data and online data, we use conditional diffusion to generate both types of data for augmentation in the online phase, aiming to improve the quality of sample generation. Experimental results show that CFDG outperforms replaying the two data types or using a standard diffusion model to generate new data. Our method is versatile and can be integrated with existing offline-to-online RL algorithms. By implementing CFDG to popular methods IQL, PEX and APL, we achieve a notable 15% average improvement in empirical performance on the D4RL benchmark like MuJoCo and AntMaze.", "title_embedding_index": 9159, "title_abs_embedding_index": 9184}, {"title": "Enhancing Learning with Label Differential Privacy by Vector Approximation", "link_suffix": "/forum?id=IwPXYk6BV9", "link": "https://openreview.net/forum?id=IwPXYk6BV9", "pdf_link": "https://openreview.net/pdf?id=IwPXYk6BV9", "keywords": "label differential privacy", "abstract": "Label differential privacy (DP) is a framework that protects the privacy of labels in training datasets, while the feature vectors are public. Existing approaches protect the privacy of labels by flipping them randomly, and then train a model to make the output approximate the privatized label. However, as the number of classes K increases, stronger randomization is needed, thus the performances of these methods become significantly worse. In this paper, we propose a vector approximation approach, which is easy to implement and introduces little additional computational overhead. Instead of flipping each label into a single scalar, our method converts each label into a random vector with K components, whose expectations reflect class conditional probabilities. Intuitively, vector approximation retains more information than scalar labels. A brief theoretical analysis shows that the performance of our method only decays slightly with K. Finally, we conduct experiments on both synthesized and real datasets, which validate our theoretical analysis as well as the practical performance of our method.", "title_embedding_index": 9160, "title_abs_embedding_index": 9185}, {"title": "DM-Tune: Quantizing Diffusion Models with Mixture-of-Gaussian Guided Noise Tuning", "link_suffix": "/forum?id=m8ERGrOf1f", "link": "https://openreview.net/forum?id=m8ERGrOf1f", "pdf_link": "https://openreview.net/pdf?id=m8ERGrOf1f", "keywords": "Diffusion Models, Quantization, Low-Precision GPU Kernels, Noise-Tuning", "abstract": "Diffusion models have become essential generative tools for tasks such as image generation, video creation, and inpainting, but their high computational and memory demands pose challenges for efficient deployment. Contrary to the traditional belief that full-precision computation ensures optimal image quality, we demonstrate that a fine-grained mixed-precision strategy can surpass full-precision models in terms of image quality, diversity, and text-to-image alignment. However, directly implementing such strategies can lead to increased complexity and reduced runtime performance due to the overheads of managing multiple precision formats and casting operations. To address this, we introduce DM-Tune, which replaces complex mixed-precision quantization with a unified low-precision format, supplemented by noise-tuning, to improve both image generation quality and runtime efficiency. The proposed noise-tuning mechanism is a type of fine-tuning that reconstructs the mixed-precision output by learning adjustable noise through a parameterized nonlinear function consisting of Gaussian and linear components. Key steps in our framework include identifying sensitive layers for quantization, modeling quantization noise, and optimizing runtime with custom low-precision GPU kernels that support efficient noise-tuning. Experimental results across various diffusion models and datasets demonstrate that DM-Tune not only significantly improves runtime but also enhances diversity, quality, and text-to-image alignment compared to FP32, FP8, and state-of-the-art mixed-precision methods. Our approach is broadly applicable and lays a solid foundation for simplifying complex mixed-precision strategies at minimal cost.", "title_embedding_index": 9161, "title_abs_embedding_index": 9186}, {"title": "KinDEL: DNA-Encoded Library Dataset for Kinase Inhibitors", "link_suffix": "/forum?id=63r2sTjkCv", "link": "https://openreview.net/forum?id=63r2sTjkCv", "pdf_link": "https://openreview.net/pdf?id=63r2sTjkCv", "keywords": "DEL, small molecule, benchmark, dataset", "abstract": "DNA-Encoded Libraries (DEL) are combinatorial small molecule libraries that offer an efficient way to characterize diverse chemical spaces. Selection experiments using DELs are pivotal to drug discovery efforts, enabling high-throughput screens for hit finding. However, limited availability of public DEL datasets hinders the advancement of computational techniques designed to process such data. To bridge this gap, we present KinDEL, one of the first large, publicly available DEL datasets on two kinases: Mitogen-Activated Protein Kinase 14 (MAPK14) and Discoidin Domain Receptor Tyrosine Kinase 1 (DDR1). Interest in this data modality is growing due to its ability to generate extensive supervised chemical data that densely samples around select molecular structures. Demonstrating one such application of the data, we benchmark different machine learning techniques to develop predictive models for hit identification; in particular, we highlight recent structure-based probabilistic approaches. Finally, we provide biophysical assay data, both on- and off-DNA, to validate our models on a smaller subset of molecules. Data and code for our benchmarks can be found at:https://kin-del-2024.s3.us-west-2.amazonaws.com/kindel.zip", "title_embedding_index": 9162, "title_abs_embedding_index": 9187}, {"title": "Online Neuro-Symbolic Predicate Invention for High-Level Planning", "link_suffix": "/forum?id=QOfswj7hij", "link": "https://openreview.net/forum?id=QOfswj7hij", "pdf_link": "https://openreview.net/pdf?id=QOfswj7hij", "keywords": "learning abstractions for planning, neuro-symbolic ai, concept learning", "abstract": "Broadly intelligent agents should form task-specific abstractions that selectively expose the essential elements of a task, while abstracting away the complexity of the raw sensorimotor space. In this work, we present Neuro-Symbolic Predicates, a first-order abstraction language that combines the strengths of symbolic and neural knowledge representations. We outline an online algorithm for inventing such predicates and learning abstract world models. We compare our approach to hierarchical reinforcement learning, vision-language model planning, and symbolic predicate invention approaches, on both in- and out-of-distribution tasks across five simulated robotic domains. Results show that our approach offers better sample complexity, stronger out-of-distribution generalization, and improved interpretability.", "title_embedding_index": 9163, "title_abs_embedding_index": 9188}, {"title": "Mechanistic Unlearning: Robust Knowledge Unlearning and Editing via Mechanistic Localization", "link_suffix": "/forum?id=vsU2veUpiR", "link": "https://openreview.net/forum?id=vsU2veUpiR", "pdf_link": "https://openreview.net/pdf?id=vsU2veUpiR", "keywords": "Model Editing, Unlearning, Mechanistic Interpretability, Localization, Adversarial Robustness", "abstract": "Methods for knowledge editing and unlearning in large language models seek to edit or remove undesirable knowledge or capabilities without compromising general language modeling performance. This work investigates how mechanistic interpretability---which, in part, aims to identify model components (circuits) associated to specific interpretable mechanisms that make up a model capability---can improve the precision and effectiveness of editing and unlearning. \nWe find a stark difference in unlearning and edit robustness when training components localized by different methods. We highlight an important distinction between methods that localize components based primarily on preserving outputs, and those finding high level mechanisms with predictable intermediate states.\nIn particular, localizing edits/unlearning to components associated with the \\textit{lookup-table mechanism} for factual recall 1) leads to more robust edits/unlearning across different input/output formats, and 2) resists attempts to relearn the unwanted information, while also reducing unintended side effects compared to baselines, on both a sports facts dataset and the CounterFact dataset across multiple models.\nWe also find that certain localized edits disrupt the latent knowledge in the model more than any other baselines, making unlearning more robust to various attacks.", "title_embedding_index": 9164, "title_abs_embedding_index": 9189}, {"title": "Towards Bridging Generalization and Expressivity of Graph Neural Networks", "link_suffix": "/forum?id=BOQpRtI4F5", "link": "https://openreview.net/forum?id=BOQpRtI4F5", "pdf_link": "https://openreview.net/pdf?id=BOQpRtI4F5", "keywords": "gnn, expressivity, generalization", "abstract": "Expressivity and generalization are two critical aspects of graph neural networks (GNNs). While significant progress has been made in studying the expressivity of GNNs, much less is known about their generalization capabilities, particularly when dealing with the inherent complexity of graph-structured data.\nIn this work, we address the intricate relationship between expressivity and generalization in GNNs. Theoretical studies conjecture a trade-off between the two: highly expressive models risk overfitting, while those focused on generalization may sacrifice expressivity. However, empirical evidence often contradicts this assumption, with expressive GNNs frequently demonstrating strong generalization. We explore this contradiction by introducing a novel framework that connects GNN generalization to the variance in graph structures they can capture. This leads us to propose a $k$-variance margin-based generalization bound that characterizes the structural properties of graph embeddings in terms of their upper-bounded expressive power. Our analysis does not rely on specific GNN architectures, making it broadly applicable across GNN models. We further uncover a trade-off between intra-class concentration and inter-class separation, both of which are crucial for effective generalization. Through case studies and experiments on real-world datasets, we demonstrate that our theoretical findings align with empirical results, offering a deeper understanding of how expressivity can enhance GNN generalization.", "title_embedding_index": 9165, "title_abs_embedding_index": 9190}, {"title": "Intermediate Layer Classifiers for OOD generalization", "link_suffix": "/forum?id=ByCV9xWfNK", "link": "https://openreview.net/forum?id=ByCV9xWfNK", "pdf_link": "https://openreview.net/pdf?id=ByCV9xWfNK", "keywords": "transfer learning, intermediate layers, learning dynamics, OOD generalization", "abstract": "Deep classifiers are known to be sensitive to data distribution shifts, primarily due to their reliance on spurious correlations in training data. It has been suggested that these classifiers can still find useful features in the network's last layer that hold up under such shifts. In this work, we question the use of last-layer representations for out-of-distribution (OOD) generalisation and explore the utility of intermediate layers. To this end, we introduce Intermediate Layer Classifiers (ILCs). We discover that intermediate layer representations frequently offer substantially better generalisation than those from the penultimate layer. In many cases, zero-shot OOD generalisation using earlier-layer representations approaches the few-shot performance of retraining on penultimate layer representations. This is confirmed across multiple datasets, architectures, and types of distribution shifts. Our analysis suggests that intermediate layers are less sensitive to distribution shifts compared to the penultimate layer. These findings highlight the importance of understanding how information is distributed across network layers and its role in OOD generalisation, while also pointing to the limits of penultimate layer representation utility.", "title_embedding_index": 9166, "title_abs_embedding_index": 9191}, {"title": "Dual-level Bias Mitigation via Fairness-guided Distribution Discrepancy", "link_suffix": "/forum?id=wCO966fAHd", "link": "https://openreview.net/forum?id=wCO966fAHd", "pdf_link": "https://openreview.net/pdf?id=wCO966fAHd", "keywords": "Fairness, Trust-worthy Machine Learning", "abstract": "Modern artificial intelligence predominantly relies on pre-trained models, which are fine-tuned for specific downstream tasks rather than built from scratch. However, a key challenge persists: the fairness of learned representations in pre-trained models is not guaranteed when transferred to new tasks, potentially leading to biased outcomes, even if fairness constraints were applied during the original training. To address this issue, we propose Dual-level Bias Mitigation (DBM), which measures the fairness-guided distribution discrepancy between representations of different demographic groups. By optimizing both the fairness-guided distribution discrepancy and the task-specific objective, DBM ensures fairness at both the representation and task levels. Theoretically, we provide the generalization error bound of the fairness-guided distribution discrepancy to support the efficacy of our approach. Experimental results on multiple benchmark datasets demonstrate that DBM effectively mitigates bias in fine-tuned models on downstream tasks across a range of fairness metrics.", "title_embedding_index": 9167, "title_abs_embedding_index": 9192}, {"title": "Part321: Recognizing 3D Object Parts from a 2D Image Using 1-Shot Annotations", "link_suffix": "/forum?id=jdFoxDnBwY", "link": "https://openreview.net/forum?id=jdFoxDnBwY", "pdf_link": "https://openreview.net/pdf?id=jdFoxDnBwY", "keywords": "3D Vision, 3D from 2D, Part recognition, One-shot", "abstract": "Recognizing object parts from images plays a pivotal role in various real-world applications. However, existing work mostly learn models from large-scale 2D part annotations. In this paper, we propose a part recognition model that can recognize 3D parts from a 2D image with only annotations of parts on one 3D mesh model for each object category. Specifically, we build a category-level 3D feature bank for meshes that could overcome geometric variance among objects and precisely align with diverse 2D images of this object category. To achieve this, we propose to learn two types of correspondence. Firstly, we learn mesh-to-mesh correspondence between distinct 3D mesh models by matching geometry-aware features, which allows us to create a shared 3D feature bank for this object category. Secondly, we establish mesh-to-image correspondence by aligning features in the 3D feature bank with features extracted from 2D images. During inference, given a single image, our method recognizes 3D object parts via a Render-and-Compare approach. It predicts object parts by gradient-based optimizing each part\u2019s 3D configuration, minimizing a feature-level reconstruction loss between the projected 3D features and the image features while ensuring geometric consistency between object parts. The position, rotation, and shape of each part are optimized to match the cues from the image, thus recognizing the 3D parts from a 2D image. Experiments on VehiclePart3D, PartImageNet, and UDA Part dataset show our method outperforms baselines significantly for 2D part segmentation and pioneering 3D part recognition from a single image.", "title_embedding_index": 9168, "title_abs_embedding_index": 9193}, {"title": "Lightweight Predictive 3D Gaussian Splats", "link_suffix": "/forum?id=PbheqxnO1e", "link": "https://openreview.net/forum?id=PbheqxnO1e", "pdf_link": "https://openreview.net/pdf?id=PbheqxnO1e", "keywords": "Gaussian splatting", "abstract": "Recent approaches representing 3D objects and scenes using Gaussian splats show increased rendering speed across a variety of platforms and devices. While rendering such representations is indeed extremely efficient, storing and transmitting them is often prohibitively expensive. To represent large-scale scenes, one often needs to store millions of 3D Gaussian, which can occupy up to gigabytes of storage. This creates a significant practical barrier, preventing widespread adoption on resource-constrained devices.\nIn this work, we propose a new representation that dramatically reduces the hard drive footprint while featuring similar or improved quality when compared to the standard 3D Gaussian splats. This representation leverages the inherent feature sharing among splats in the close proximity using a hierarchical tree structure, with which only the parent splats need to be stored. We present a method for constructing tree structures from naturally unstructured point clouds. Additionally, we propose the adaptive tree manipulation to prune the redundant trees in the space, while spawn new ones from the significant  children splats during the optimization process. On the benchmark datasets, we achieve 20x storage reduction in hard-drive footprint with improved fidelity compared to the vanilla 3DGS and 2-5x reduction compared to the exiting compact solutions.  More importantly, we demonstrate the practical application of our method in real-world rendering on mobile devices and AR glasses.", "title_embedding_index": 9169, "title_abs_embedding_index": 9194}, {"title": "PACE: Physics Informed Uncertainty Aware Climate Emulator", "link_suffix": "/forum?id=7fuddaTrSu", "link": "https://openreview.net/forum?id=7fuddaTrSu", "pdf_link": "https://openreview.net/pdf?id=7fuddaTrSu", "keywords": "Physics Informed Machine Learning, Climate Modelling", "abstract": "Climate models serve as critical tools for evaluating the effects of climate change and projecting future climate scenarios. However, the reliance on numerical simulations of physical equations renders them computationally intensive and inefficient. While deep learning methodologies have made significant progress in weather forecasting, they are still unstable for climate emulation tasks. Here, we propose PACE, a lightweight 684K parameter Physics Informed Uncertainty Aware Climate Emulator. PACE emulates temperature and precipitation stably for 86 years while only being trained on emissions data. We incorporate a fundamental physical law of advection-diffusion in PACE accounting for boundary conditions and empirically estimating the diffusion co-efficient and flow velocities from concentrations data. PACE has been trained on 15 climate models provided by ClimateSet outperforming baselines across most of the climate models and advancing a new state of the art in a climate diagnostic task.", "title_embedding_index": 9170, "title_abs_embedding_index": 9195}, {"title": "Memorization in In-Context Learning", "link_suffix": "/forum?id=vl8VpW2niQ", "link": "https://openreview.net/forum?id=vl8VpW2niQ", "pdf_link": "https://openreview.net/pdf?id=vl8VpW2niQ", "keywords": "Memorization, In-Context Learning, Large Language Models", "abstract": "In-context learning (ICL) has proven to be an effective strategy for improving the performance of large language models (LLMs) with no additional training. However, the exact mechanism behind this performance improvement remains unclear. This study is the first to show how ICL surfaces memorized training data and to explore the correlation between this memorization and performance on downstream tasks across various ICL regimes: zero-shot, few-shot, and many-shot. Our most notable findings include: (1) ICL significantly surfaces memorization compared to zero-shot learning in most cases; (2) demonstrations, without their labels, are the most effective element in surfacing memorization; (3) ICL improves performance when the surfaced memorization in few-shot regimes reaches a high level (about 40%); and (4) there is a very strong correlation between performance and memorization in ICL when it outperforms zero-shot learning. Overall, our study uncovers memorization as a new factor impacting ICL, raising an important question: to what extent do LLMs truly generalize from demonstrations in ICL, and how much of their success is due to memorization?", "title_embedding_index": 9171, "title_abs_embedding_index": 9196}, {"title": "Escaping Saddle Point Efficiently in Minimax and Bilevel Optimizations", "link_suffix": "/forum?id=kZulKA2APd", "link": "https://openreview.net/forum?id=kZulKA2APd", "pdf_link": "https://openreview.net/pdf?id=kZulKA2APd", "keywords": "Nonconvex optimization; Bilevel optimization; Saddle point", "abstract": "Hierarchical optimization is attracting significant attentions as it can be applied to a broad range of machine learning tasks. Recently, many algorithms are proposed to improve the theoretical results of minimax and bilevel optimizations. Among these works, a core issue that has not been well studies is to escape saddle point and find local minimum. In this paper, thus, we investigate the methods to achieve second-order optimality for nonconvex minimax and bilevel optimization. Specifically, we propose a new algorithm named PRGDA without the computation of second order derivative of the primal function. In nonconvex-strongly-concave minimax optimization, we prove that our algorithm can find a second-order stationary point with the gradient complexity that matches state-of-the-art result to find first-order stationary point. To our best knowledge, PRGDA is the first stochastic algorithm that is guaranteed to obtain the second-order stationary point for nonconvex minimax problems. In nonconvex-strongly-convex bilevel optimization, our method also achieves better gradient complexity to find local minimum. Finally, we conduct two numerical experiments to validate the performance of our new method.", "title_embedding_index": 9172, "title_abs_embedding_index": 9197}, {"title": "FMint: Bridging Human Designed and Data Pretrained Models for Differential Equation Foundation Model", "link_suffix": "/forum?id=SvjFHucuDZ", "link": "https://openreview.net/forum?id=SvjFHucuDZ", "pdf_link": "https://openreview.net/pdf?id=SvjFHucuDZ", "keywords": "dynamical systems, foundation model, in-context learning, multi-modal", "abstract": "The fast simulation of dynamical systems is a key challenge in many scientific and engineering applications, such as weather forecasting, disease control, and drug discovery. With the recent success of deep learning, there is increasing interest in using neural networks to solve differential equations in a data-driven manner. However, existing methods are either limited to specific types of differential equations or require large amounts of data for training. This restricts their practicality in many real-world applications, where data is often scarce or expensive to obtain. To address this, we propose a novel multi-modal foundation model, named \\textbf{FMint} (\\textbf{F}oundation \\textbf{M}odel based on \\textbf{In}i\\textbf{t}ialization), to bridge the gap between human-designed and data-driven models for the fast simulation of dynamical systems. Built on a decoder-only transformer architecture with in-context learning, FMint utilizes both numerical and textual data to learn a universal error correction scheme for dynamical systems, using prompted sequences of coarse solutions from traditional solvers. The model is pre-trained on a corpus of 40K ODEs, and we perform extensive experiments on challenging ODEs that exhibit chaotic behavior and of high dimensionality. Our results demonstrate the effectiveness of the proposed model in terms of both accuracy and efficiency compared to classical numerical solvers, highlighting FMint's potential as a general-purpose solver for dynamical systems. Our approach achieves an accuracy improvement of 1 to 2 orders of magnitude over state-of-the-art dynamical system simulators, and delivers a 5X speedup compared to traditional numerical algorithms.", "title_embedding_index": 9173, "title_abs_embedding_index": 9198}, {"title": "DSPart: A Large-scale Diffusion-generated Synthetic Dataset with Annotations from 3D Parts", "link_suffix": "/forum?id=K3jv45pptT", "link": "https://openreview.net/forum?id=K3jv45pptT", "pdf_link": "https://openreview.net/pdf?id=K3jv45pptT", "keywords": "Synthetic dataset, Semantic Part Segmentation, 3D Parts Annotation", "abstract": "Object parts provide representations that enable a detailed and interpretable understanding of object structures, making part recognition crucial for various real-world applications. However, acquiring pixel-level part annotations is both expensive and time-consuming. Rendering 3D object models with their 3D part annotations is a promising solution since it allows the generation of unlimited synthetic data samples with precise 3D control and accurate part segmentation masks. Nevertheless, these synthetic datasets suffer from a lack of realism, resulting in large domain gaps. In this paper, we present a large-scale realistic synthetic dataset with part annotations, namely Diffusion-generated Synthetic Parts (DSPart), for both rigid objects and animals. For images in DSPart, we obtain 2D part masks from 3D part annotations by leveraging recent advances in diffusion models with 3D control. In addition to offering more diverse and realistic textures, prior knowledge of diffusion models enables the object to exhibit more physically realistic interactions with the ground plane and other spatial contexts. We annotate $475$ representative shape instances from $50$ object categories for DSPart-Rigid and use $3,065$ high-quality SMAL models fitted poses from $40$ animal categories for DSPart-Animal. Experimental results demonstrate the potential of our dataset in training robust part segmentation models, effectively bridging the gap between synthetic and real-world data.", "title_embedding_index": 9174, "title_abs_embedding_index": 9199}]
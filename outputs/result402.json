[
    {
        "title": "Understanding Llava's Visual Question Answering in a Mechanistic View",
        "link_suffix": "/forum?id=Pw7Wb3dGvg",
        "link": "https://openreview.net/forum?id=Pw7Wb3dGvg",
        "pdf_link": "https://openreview.net/pdf?id=Pw7Wb3dGvg",
        "keywords": "Llava, multimodal LLM, mechanistic interpretability, interpretability tool, visual question answering",
        "abstract": "Understanding the mechanisms behind Large Language Models (LLMs) is crucial for designing improved models and strategies. While recent studies have yielded valuable insights into the mechanisms of textual LLMs, the mechanisms of Multi-modal Large Language Models (MLLMs) remain underexplored. In this paper, we apply mechanistic interpretability methods to analyze the visual question answering (VQA) mechanisms in the first MLLM, Llava. We compare the mechanisms between VQA and textual QA (TQA) in color answering tasks and find that: a) VQA exhibits a mechanism similar to the in-context learning mechanism observed in TQA; b) the visual features exhibit significant interpretability when projecting the visual embeddings into the embedding space; and c) Llava enhances the existing capabilities of the corresponding textual LLM Vicuna during visual instruction tuning. Based on these findings, we develop an interpretability tool to help users and researchers identify important visual locations for final predictions, aiding in the understanding of visual hallucination. Our method demonstrates faster and more effective results compared to existing interpretability approaches. Our code, data and interpretability tool will be made available on GitHub."
    },
    {
        "title": "Framer: Interactive Frame Interpolation",
        "link_suffix": "/forum?id=Lp40Z40N07",
        "link": "https://openreview.net/forum?id=Lp40Z40N07",
        "pdf_link": "https://openreview.net/pdf?id=Lp40Z40N07",
        "keywords": "Video Frame Interpolation; Interactive; Diffusion Model; Correspondence Modeling",
        "abstract": "We propose Framer for interactive frame interpolation, which targets producing smoothly transitioning frames between two images as per user creativity. Concretely, besides taking the start and end frames as inputs, our approach supports customizing the transition process by tailoring the trajectory of some selected keypoints. Such a design enjoys two clear benefits. First, incorporating human interaction mitigates the issue arising from numerous possibilities of transforming one image to another, and in turn enables finer control of local motions. Second, as the most basic form of interaction, keypoints help establish the correspondence across frames, enhancing the model to handle challenging cases (e.g., objects on the start and end frames are of different shapes and styles). It is noteworthy that our system also offers an \"autopilot\" mode, where we introduce a module to estimate the keypoints and refine the trajectory automatically, to simplify the usage in practice. Extensive experimental results demonstrate the appealing performance of Framer on various applications, such as image morphing, time-lapse video generation, cartoon interpolation, etc. The code, the model, and the interface will be released to facilitate further research."
    },
    {
        "title": "Understanding and Mitigating Gender Bias in LLMs via Interpretable Model Editing",
        "link_suffix": "/forum?id=6xqPekRv7f",
        "link": "https://openreview.net/forum?id=6xqPekRv7f",
        "pdf_link": "https://openreview.net/pdf?id=6xqPekRv7f",
        "keywords": "large language models, gender bias, mechanistic interpretability, model editing",
        "abstract": "Large language models (LLMs) have achieved great success in various tasks. While LLMs can learn powerful capabilities from large datasets, they also inherit the gender bias present in that data. Existing studies usually propose methods to reduce bias by data cleaning and model retraining/fine-tuning. Although these methods have shown some success, the cost of designing data and retraining/fine-tuning an LLM increases significantly as the model size grows larger. Furthermore, a lack of understanding of the mechanisms behind gender bias prevents researchers from effectively tailoring solutions to address it. In this paper, we utilize mechanistic interpretability methods to construct the neuron circuits for gender bias cases and locate the important neurons storing gender bias. Then we propose the Interpretable Model Editing (Interpret-ME) method to reduce gender bias without designing huge datasets or fine-tuning. Compared to fine-tuning methods, our approach shows competitive results in reducing gender bias across experiments with 8 LLMs. At the same time, our method does not affect the performance in other tasks. Overall, our analysis is useful for understanding the mechanism of gender bias and our method paves a potential way for reducing bias."
    },
    {
        "title": "PersonalVideo: High ID-Fidelity Video Customization With Static Images",
        "link_suffix": "/forum?id=ndtFyx7UWs",
        "link": "https://openreview.net/forum?id=ndtFyx7UWs",
        "pdf_link": "https://openreview.net/pdf?id=ndtFyx7UWs",
        "keywords": "Video identity customization; Text to video generation",
        "abstract": "The current text-to-video (T2V) generation has made significant progress in synthesizing realistic general videos, but it is still unexplored in identity-specific human video generation with customized ID images. The key challenge lies in maintaining high ID fidelity consistently while preserving the original motion dynamic and prompt following after the identity injection. Current video identity customization methods mainly rely on reconstructing given identity images on text-to-image models, which have a divergent distribution with the T2V model. This process introduces a tuning-inference gap, leading to identity inaccuracy and dynamic degradation.  To tackle this problem, we propose a novel framework, dubbed $\\textbf{PersonalVideo}$, that applies direct supervision on videos synthesized by the T2V model to bridge the gap. Specifically, we introduce a learnable Spatial Identity Adapter under the supervision of pixel-space ID loss, which customizes the specific identity and preserves the original T2V model\u2019s abilities (e.g., motion dynamic and prompt following). Furthermore, we employ simulated prompt augmentation to reduce overfitting by supervising generated results in more semantic scenarios, gaining good robustness even with only a single reference image available. Extensive experiments demonstrate our method\u2019s superiority in delivering high identity faithfulness while preserving the inherent video generation qualities of the original T2V model, outshining prior approaches. Notably, our PersonalVideo seamlessly integrates with pre-trained SD components, such as ControlNet and style LoRA, requiring no extra tuning overhead."
    },
    {
        "title": "LucidPPN: Unambiguous Prototypical Parts Network for User-centric Interpretable Computer Vision",
        "link_suffix": "/forum?id=BM9qfolt6p",
        "link": "https://openreview.net/forum?id=BM9qfolt6p",
        "pdf_link": "https://openreview.net/pdf?id=BM9qfolt6p",
        "keywords": "xai, interpretability, prototypical parts",
        "abstract": "Prototypical parts networks combine the power of deep learning with the explainability of case-based reasoning to make accurate, interpretable decisions. They follow the this looks like that reasoning, representing each prototypical part with patches from training images. However, a single image patch comprises multiple visual features, such as color, shape, and texture, making it difficult for users to identify which feature is important to the model.To reduce this ambiguity, we introduce the Lucid Prototypical Parts Network (LucidPPN), a novel prototypical parts network that separates color prototypes from other visual features. Our method employs two reasoning branches: one for non-color visual features, processing grayscale images, and another focusing solely on color information. This separation allows us to clarify whether the model's decisions are based on color, shape, or texture. Additionally, LucidPPN identifies prototypical parts corresponding to semantic parts of classified objects, making comparisons between data classes more intuitive, e.g., when two bird species might differ primarily in belly color.Our experiments demonstrate that the two branches are complementary and together achieve results comparable to baseline methods. More importantly, LucidPPN generates less ambiguous prototypical parts, enhancing user understanding."
    },
    {
        "title": "CausalESC: Breaking Causal Cycles for Emotional Support Conversations with Temporal Causal HMM",
        "link_suffix": "/forum?id=CB2r9PwuRQ",
        "link": "https://openreview.net/forum?id=CB2r9PwuRQ",
        "pdf_link": "https://openreview.net/pdf?id=CB2r9PwuRQ",
        "keywords": "Emotional Support Conversation, Causal Learning, Text Generation",
        "abstract": "Emotional Support Conversation (ESC) is a rapidly advancing task focused on alleviating a seeker's emotional distress. The intricate interplay between cognition, emotion, and behavior presents substantial challenges for existing approaches, which often struggle to capture the dynamic evolution of the seeker's internal state during conversations. To address this, we propose \\textbf{CausalESC}, a model designed to dynamically represent the seeker's internal states, by assuming that the generative process governing the mutual influence among these factors follows a first-order Markov property, with \\iid random variables. The model comprises a prior network, that disentangles the seeker's emotions, cognition, and behavior, and a posterior network, which decouples the support strategy factors. The prior network also models the psychological causality of the seeker within each conversation round. To account for the varying effects of support strategies on the seeker's intrinsic states, we incorporate a support intervention module to capture these impacts. Additionally, a holistic damping transfer  mechanism is designed to regulate the complex interactions among cognition, emotion, behavior, and strategy, ensuring that changes remain within a reasonable range. Our model effectively breaks causal cycles and achieves causal representation learning. Both automatic and human evaluations demonstrate the effectiveness of our model, emphasizing the advantages of modeling the evolution of the seeker's internal state under support strategies."
    },
    {
        "title": "Unveiling Language Skills under Circuits",
        "link_suffix": "/forum?id=VwyKSnMmrr",
        "link": "https://openreview.net/forum?id=VwyKSnMmrr",
        "pdf_link": "https://openreview.net/pdf?id=VwyKSnMmrr",
        "keywords": "Interpretability of Language Models",
        "abstract": "The exploration of language skills in language models (LMs) has always been one of the central goals in mechanistic interpretability. However, existing circuit analyses often fall short in representing the full functional scope of these models, primarily due to the exclusion of Feed-Forward layers. Additionally, isolating the effect of a single language skill from a text, which inherently involves multiple entangled skills, poses a significant challenge. To address these gaps, we introduce a novel concept, Memory Circuit, a minimum unit that fully and independently manipulates the memory-reading functionality of a language model, and disentangle the transformer model precisely into a circuit graph which is an ensemble of paths connecting different memory circuits. Based on this disentanglement, we identify salient circuit paths, named as skill paths, responsible for three crucial language skills, i.e., the Previous Token Skill, Induction Skill and In-Context Learning (ICL) Skill, leveraging causal effect estimation through interventions and counterfactuals. Our experiments on various datasets confirm the correspondence between our identified skill paths and language skills, and validate three longstanding hypotheses: 1) Language skills are identifiable through circuit dissection; 2) Simple language skills reside in shallow layers, whereas complex language skills are found in deeper layers; 3) Complex language skills are formed on top of simpler language skills. Our codes are available at:https://anonymous.4open.science/r/language_skill."
    },
    {
        "title": "On the Entropy of Language Models in Getting Semantic from Tokens",
        "link_suffix": "/forum?id=z3DMFpaP6m",
        "link": "https://openreview.net/forum?id=z3DMFpaP6m",
        "pdf_link": "https://openreview.net/pdf?id=z3DMFpaP6m",
        "keywords": "LLM evaluation",
        "abstract": "Large language models (LLMs) are widely recognized for their exceptional capacity to capture semantic meaning. Yet, there remains no established metric to quantify this capability. In this work, we introduce a quantitative metric, Information Emergence (IE), designed to measure LLMs\u2019 ability to extract semantics from input tokens. We formalize \u201csemantics\u201d as the meaningful information abstracted from a sequence of tokens and, leveraging information theory, quantify this through comparing the reduction in entropy observed for a sequence of tokens (macro-level) and individual tokens (micro-level). To achieve this, we design a light-weight estimator to compute the mutual information at both micro and macro levels for each transformer layer, which is agnostic to different tasks and language model architectures. We apply IE in both synthetic in-context learning (ICL) scenarios and natural sentence contexts. Experiments show a high-level informativeness of our metric reflected in semantic faithfulness, sensitivity, and connection with emergence. In addition, we highlight some interesting findings: 1) IE explains why ICL offers clearer semantics and benefits compared to natural text through changes\nin entropy. 2) We could associate certain hallucination phenomenon with increased variance in IE. 3) IE can effectively differentiate between human-written and LLM generated text, proving especially useful for extremely large and closed-source language models. Our codes are available at:https://anonymous.4open.science/r/Emergence/."
    },
    {
        "title": "PASER: Post-Training Data Selection for Efficient Pruned Large Language Model Recovery",
        "link_suffix": "/forum?id=Mh8blXreJW",
        "link": "https://openreview.net/forum?id=Mh8blXreJW",
        "pdf_link": "https://openreview.net/pdf?id=Mh8blXreJW",
        "keywords": "Large Language Model, Model Pruning, Recovery Training, Data Selection",
        "abstract": "Model pruning is an effective approach for compressing Large Language Models (LLMs) and improving inference efficiency. However, this process often leads to significant degradation of model capabilities. While post-training techniques such as instruction tuning are commonly employed to recover model performance, existing methods often overlook the uneven deterioration of model capabilities and incur high computational costs due to extensive recovery training. Moreover, some instruction data irrelevant to model capability recovery may introduce negative effects. To address these challenges, we propose thePost-training dAtaSelection method forEfficient pruned large language modelRecovery (PASER). PASER aims to identify instructions where model capabilities are most severely compromised within a certain recovery data budget. Our approach first applies manifold learning and spectral clustering to group recovery data in the semantic space, revealing capability-specific instruction sets. We then adaptively allocate the data budget to different clusters based on the degrees of model capability degradation. In each cluster, we prioritize data samples where model performance has declined dramatically. To mitigate potential negative transfer, we also detect and filter out conflicting or irrelevant recovery data. Extensive experiments demonstrate that PASER significantly outperforms conventional baselines, effectively recovering the general capabilities of pruned LLMs while utilizing merely 4%-20% of the original post-training data and substantially reducing training computational overhead."
    },
    {
        "title": "Actra: Optimized Transformer Architecture for Vision-Language-Action Models in Robot Learning",
        "link_suffix": "/forum?id=PPDheO2z5v",
        "link": "https://openreview.net/forum?id=PPDheO2z5v",
        "pdf_link": "https://openreview.net/pdf?id=PPDheO2z5v",
        "keywords": "Robotics, Embodied AI, Transformer, Multimodality, Contrastive Learning, Dynamics Learning, Multimodal Alignment",
        "abstract": "Vision-language-action models have gained significant attention for their ability to model trajectories in robot learning. However, most existing models rely on Transformer models with vanilla causal attention, which we find suboptimal for processing segmented multi-modal sequences. Additionally, the autoregressive generation approach falls short in generating multi-dimensional actions. In this paper, we introduce Actra, an optimized Transformer architecture featuring trajectory attention and learnable action queries, designed to efficiently process segmented multi-modal trajectories in language-conditioned robot imitation learning. Furthermore, we propose a contrastive dynamics learning objective to enhance its understanding of environment dynamics and multi-modal alignment, complementing the primary behavior cloning objective. Through extensive experiments on three large-scale robot manipulation benchmarks, Actra exhibits substantial performance improvements over state-of-the-art models."
    },
    {
        "title": "BDC-Occ: Binarized Deep Convolution Unit For Binarized Occupancy Network",
        "link_suffix": "/forum?id=vKG270UOg4",
        "link": "https://openreview.net/forum?id=vKG270UOg4",
        "pdf_link": "https://openreview.net/pdf?id=vKG270UOg4",
        "keywords": "3D occupancy prediction;  binarized networks",
        "abstract": "Existing 3D occupancy networks demand significant hardware resources, hindering the deployment of edge devices. Binarized Neural Networks (BNNs) offer a potential solution by substantially reducing computational and memory requirements. However, their performances decrease notably compared to full-precision networks. In addition, it is challenging to enhance the performance of the binarized model by increasing the number of binarized convolutional layers, which limits its practicability for 3D occupancy prediction. This paper presents two original insights into binarized convolution, substantiated with theoretical proofs: (a) $1\\times1$ binarized convolution introduces minimal binarization errors as the network deepens, and (b) binarized convolution is inferior to full-precision convolution in capturing cross-channel feature importance. Building on the above insights, we propose a novel binarized deep convolution (BDC) unit that significantly enhances performance, even when the number of binarized convolutional layers increases. Specifically, in the BDC unit, additional binarized convolutional kernels are constrained to $1\\times1$ to minimize the effects of binarization errors. Further, we propose a per-channel refinement branch to reweight the output via first-order approximation. Then, we partition the 3D occupancy networks into four convolutional modules, using the proposed BDC unit to binarize them. The proposed BDC unit minimizes binarization errors and improves perceptual capability while significantly boosting computational efficiency, meeting the stringent requirements for accuracy and speed in occupancy prediction. Extensive quantitative and qualitative experiments validate that the proposed BDC unit supports state-of-the-art precision in occupancy prediction and object detection tasks with substantially reduced parameters and operations. Code is provided in the supplementary material and will be open-sourced upon review."
    },
    {
        "title": "WARP: On the Benefits of Weight Averaged Rewarded Policies",
        "link_suffix": "/forum?id=i0e0OMK8xM",
        "link": "https://openreview.net/forum?id=i0e0OMK8xM",
        "pdf_link": "https://openreview.net/pdf?id=i0e0OMK8xM",
        "keywords": "LLM, Alignment, RLHF, Model Merging",
        "abstract": "Reinforcement learning from human feedback (RLHF) aligns large language models by encouraging their generations to have high rewards, using a reward model trained on human preferences. To prevent forgetting of pre-trained knowledge, RLHF usually incorporates a KL regularization; this forces the policy to remain close to its initialization, though it hinders the reward optimization. To address the trade-off between KL and reward, in this paper we introduce a novel alignment strategy named Weight Averaged Rewarded Policies (WARP), merging policies in the weight space at three distinct stages. First, it uses the exponential moving average of the policy as a dynamic anchor in the KL regularization. Second, it applies spherical interpolation to merge independently fine-tuned policies into a new enhanced one. Third, it linearly interpolates between this merged model and the initialization, to recover features from pre-training. This procedure is then applied iteratively, with each iteration's final model used as an advanced initialization for the next, progressively refining the KL-reward Pareto front, achieving superior rewards at fixed KL. Experiments with Gemma policies validate that WARP improves their quality and alignment, outperforming open-source models."
    },
    {
        "title": "Improving Diffusion-based Data Augmentation with Inversion Circle Interpolation",
        "link_suffix": "/forum?id=dxoryzjsCW",
        "link": "https://openreview.net/forum?id=dxoryzjsCW",
        "pdf_link": "https://openreview.net/pdf?id=dxoryzjsCW",
        "keywords": "Data Augmentation, Diffusion, Inversion Circle Interpolation",
        "abstract": "Data Augmentation (DA), i.e., synthesizing faithful and diverse samples to expand the original training set, is a prevalent and effective strategy to improve various visual recognition tasks. With the powerful image generation ability, diffusion-based DA has shown strong performance gains on different benchmarks. In this paper, we analyze today\u2019s diffusion-based DA methods, and argue that they can- not take account of both faithfulness and diversity, which are two critical keys for generating high-quality samples and boosting final classification performance. To this end, we propose a novel Diffusion-based Inversion Interpolation DA method: Diff-II. Specifically, Diff-II consists of three main steps: 1) Category concepts learning: Learning concept embeddings for each category. 2) Inversion interpolation: Calculating the inversion for each image, and conducting random circle interpolation for two randomly sampled inversions from the same category. 3) Two-stage denoising: Using different prompts to generate synthesized images in a coarse-to-fine manner. Extensive experiments on multiple image classification tasks (e.g., few-shot, long-tailed, and out-of-distribution classification) have demonstrated its effectiveness over state-of-the-art diffusion-based DA methods."
    },
    {
        "title": "Segmentation using efficient residual networks with attention-fusion modules",
        "link_suffix": "/forum?id=zSHoaTNlmA",
        "link": "https://openreview.net/forum?id=zSHoaTNlmA",
        "pdf_link": "https://openreview.net/pdf?id=zSHoaTNlmA",
        "keywords": "Segmentation, Attention mechanisms, Efficient residual networks",
        "abstract": "Fusing the global and local semantic information in segmentation networks is a challenging task with the problems of computational cost and long-range dependencies to improve state-of-the-art methods. Based on the recent success of transformers and attention mechanisms, this research utilizes an encoder-decoder architecture named SERNet-Former, integrating convolutional neural networks with attention-based algorithms for efficient segmentation. Accordingly, attention-boosting modules are employed together with the conventional residual networks to deal with the computational cost in deriving the feature maps of the global context in the encoder, generating the unique baseline architecture, Efficient-ResNet. The decoder network is developed with additional attention-fusion networks leveraging the semantic information from the global and local contexts. Attention-fusion networks also deploy additional convolution layers in the decoder part and improve the efficiency of the network in the one-to-one conversion of the semantic information. The challenging CamVid and Cityscapes datasets are used to develop and test the network and observe the improvements by the proposed methods applied to the residual networks. Accordingly, SERNet-Former sets state-of-the-art results (84.6 % mean IoU) on the CamVid and (87.3 % mean IoU) the Cityscapes validation datasets, and challenging results (84.8 % mean IoU) on the Cityscapes test dataset. The project repository will be shared with the reader."
    },
    {
        "title": "From Data to Model: Anomaly Detection of 3D GPR Data in CuDeRes Model Space",
        "link_suffix": "/forum?id=rYTlmSlxia",
        "link": "https://openreview.net/forum?id=rYTlmSlxia",
        "pdf_link": "https://openreview.net/pdf?id=rYTlmSlxia",
        "keywords": "Cubic Decay Reservoir Network (CuDeRes), Ground Penetrating Radar (GPR), Learning in the Model Space, Reservoir Computing",
        "abstract": "Ground Penetrating Radar (GPR) offers in-depth subterranean insights, yet subsurface anomaly detection in GPR data remains challenging due to limited training data, typically confined to some normal data samples free from any subsurface structures or anomalies, and the variability of subsurface conditions. In response, this paper introduces practical and accurate subsurface anomaly detection within the Cubic Decay Reservoir Network (CuDeRes) model space. Our approach employs commonly available normal GPR data, segmented into blocks. Each data block is independently fitted using the introduced CuDeRes, which incorporates three reservoirs with spatial decay to adequately capture the data-inherent multi-directional dynamics, resulting in a compact fitted readout model. Representing each data block with the fitted model, together with the distance measurement between models, the original GPR data blocks are mapped into the CuDeRes model space, and the fitted models are collected into a \"Model Depot\". For subsequent anomaly detection in newly collected GPR data, the same segmentation and CuDeRes fitting approaches are applied, where the data blocks are represented by fitted models for comparative assessment against the model depot. Anomalies are detected through model dissimilarities, and subsequently clustered within the CuDeRes model space, allowing us to accurately identify the data blocks with potential subsurface anomalies and ascertain their anomaly types. Experiments on real-world GPR data demonstrate the practical effectiveness of our approach, notably using only limited normal data."
    },
    {
        "title": "Delving into Temperature Scaling for Adaptive Conformal Prediction",
        "link_suffix": "/forum?id=qpI6GO80ri",
        "link": "https://openreview.net/forum?id=qpI6GO80ri",
        "pdf_link": "https://openreview.net/pdf?id=qpI6GO80ri",
        "keywords": "trustworthy machine learning, conformal prediction, confidence calibration",
        "abstract": "Conformal prediction, as an emerging uncertainty qualification technique, constructs prediction sets that are guaranteed to contain the true label with pre-defined probability. Previous works often employ temperature scaling to calibrate the classifier, assuming that confidence calibration can benefit conformal prediction. In this work, we empirically show that current confidence calibration methods (e.g., temperature scaling) normally lead to larger prediction sets in adaptive conformal prediction. Theoretically, we prove that a prediction with higher confidence could result in a smaller prediction set on expectation. Inspired by the analysis, we propose \\textbf{Conformal Temperature Scaling} (ConfTS), a variant of temperature scaling that aims to improve the efficiency of adaptive conformal prediction. Specifically, ConfTS optimizes the temperature value by minimizing the gap between the threshold and the non-conformity score of the ground truth for a held-out validation dataset. In this way, the temperature value obtained would lead to an optimal set with high efficiency without violating the coverage. Experiments demonstrate that our method can effectively enhance adaptive conformal prediction methods in both efficiency and conditional coverage, reducing the average size of APS and RAPS by approximately 50$%$ on ImageNet with error rate $\\alpha=0.1$."
    },
    {
        "title": "SimDiffPDE: Simple Diffusion Baselines for Solving Partial Differential Equations",
        "link_suffix": "/forum?id=JQV9gH55Az",
        "link": "https://openreview.net/forum?id=JQV9gH55Az",
        "pdf_link": "https://openreview.net/pdf?id=JQV9gH55Az",
        "keywords": "Partial Differential Equations, Diffusion Model, Fluid Dynamics, Machine Learning in PDEs, Generative Models",
        "abstract": "We showcase good capabilities of the plain diffusion model with Transformers (SimDiffPDE) for general partial differential equations (PDEs) solving from various aspects, namely simplicity in model structure, scalability in model size, flexibility in training paradigm, and universality between different PDEs. Specifically, SimDiffPDE reformulates PDE-solving problems as the image-to-image translation problem, and employs plain and non-hierarchical diffusion model with Transformer to generate the solutions conditioned on the initial states/parameters of PDEs. We further propose a multi-scale noise to explicitly guide the diffusion model in capturing information of different frequencies within the solution domain of PDEs. SimDiffPDE achieves a remarkable improvement of +51.4% on the challenging Navier-Stokes equations. In benchmark tests for solving PDEs, such as Darcy Flow, Airfoil, and Pipe for fluid dynamics, as well as Plasticity and Elasticity for solid mechanics, our SimDiffPDE-B achieves significant relative improvements of +21.1%, +11.3%, +15.2%, +25.0%, and +23.4%, respectively. Models and code shall be released upon acceptance."
    },
    {
        "title": "Certifying Language Model Robustness with Fuzzed Randomized Smoothing: An Efficient Defense Against Backdoor Attacks",
        "link_suffix": "/forum?id=USI3ZbuFaV",
        "link": "https://openreview.net/forum?id=USI3ZbuFaV",
        "pdf_link": "https://openreview.net/pdf?id=USI3ZbuFaV",
        "keywords": "Language Model, Textual Backdoor Attack, Certified Robustness, Fuzzed Randomized Smoothing",
        "abstract": "The widespread deployment of pre-trained language models (PLMs) has exposed them to textual backdoor attacks, particularly those planted during the pre-training stage. These attacks pose significant risks to high-reliability applications, as they can stealthily affect multiple downstream tasks. While certifying robustness against such threats is crucial, existing defenses struggle with the high-dimensional, interdependent nature of textual data and the lack of access to original poisoned pre-training data. To address these challenges, we introduceFuzzedRandomizedSmoothing (FRS), a novel approach for efficiently certifying language model robustness against backdoor attacks. FRS integrates software robustness certification techniques with biphased model parameter smoothing, employing Monte Carlo tree search for proactive fuzzing to identify vulnerable textual segments within the Damerau-Levenshtein space. This allows for targeted and efficient text randomization, while eliminating the need for access to poisoned training data during model smoothing.  Our theoretical analysis demonstrates that FRS achieves a broader certified robustness radius compared to existing methods. Extensive experiments across various datasets, model configurations, and attack strategies validate FRS's superiority in terms of defense efficiency, accuracy, and robustness."
    },
    {
        "title": "StyleMaster: Towards Flexible Stylized Image Generation with Diffusion Models",
        "link_suffix": "/forum?id=B282LrYgpA",
        "link": "https://openreview.net/forum?id=B282LrYgpA",
        "pdf_link": "https://openreview.net/pdf?id=B282LrYgpA",
        "keywords": "image stylization, diffusion model",
        "abstract": "Stylized Text-to-Image Generation (STIG) aims to generate images based on text prompts and style reference images. We in this paper propose a novel framework dubbed StyleMaster for this task by leveraging pretrained Stable Diffusion (SD), which addresses previous problems such as misinterpreted style and inconsistent semantics. The enhancement lies in two novel modules: multi-source style embedder and dynamic attention adapter. In order to provide SD with better style embeddings, we propose the multi-source style embedder, which considers both global and local level visual information along with textual information, thereby offering both complementary style-related and semantic-related knowledge. Additionally, aiming for better balance between the adapter capacity and semantic control, the proposed dynamic attention adapter is applied to the diffusion UNet in which adaptation weights are dynamically calculated based on the style embeddings. Two objective functions are introduced to optimize the model alongside the denoising loss, which can further enhance semantic and style consistency. Extensive experiments demonstrate the superiority of StyleMaster over existing methods, rendering images with variable target styles while successfully maintaining the semantic information from the text prompts."
    },
    {
        "title": "Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving?",
        "link_suffix": "/forum?id=JxhgSAnrsG",
        "link": "https://openreview.net/forum?id=JxhgSAnrsG",
        "pdf_link": "https://openreview.net/pdf?id=JxhgSAnrsG",
        "keywords": "Large Language Model; Vision-Language Representation Learning",
        "abstract": "Rapid advancements in Autonomous Driving (AD) tasks turned a significant shift toward end-to-end fashion, particularly in the utilization of vision-language models (VLMs) that integrate robust logical reasoning and cognitive abilities to enable comprehensive end-to-end planning. However, these VLM-based approaches tend to integrate 2D vision tokenizers and a large language model (LLM) for ego-car planning, which lack 3D geometric priors as a cornerstone of reliable planning. Naturally, this observation raises a critical concern: Can a 2D-tokenized LLM accurately perceive the 3D environment? Our evaluation of current VLM-based methods across 3D object detection, vectorized map construction, and environmental caption suggests that the answer is, unfortunately, NO. In other words, 2D-tokenized LLM fails to provide reliable autonomous driving. In response, we introduce DETR-style 3D perceptrons as 3D tokenizers, which connect LLM with a one-layer linear projector. This simple yet elegant strategy, termed Atlas, harnesses the inherent priors of the 3D physical world, enabling it to simultaneously process high-resolution multi-view images and employ spatiotemporal modeling. Despite its simplicity, Atlas demonstrates superior performance in both 3D detection and ego planning tasks on nuScenes dataset, proving that 3D-tokenized LLM is the key to reliable autonomous driving. The code and datasets will be released."
    },
    {
        "title": "Combating inherent noise for direct preference optimization",
        "link_suffix": "/forum?id=MlxeUVCQgD",
        "link": "https://openreview.net/forum?id=MlxeUVCQgD",
        "pdf_link": "https://openreview.net/pdf?id=MlxeUVCQgD",
        "keywords": "Direct Preference Optimization",
        "abstract": "Direct Preference Optimization (DPO) has recently gained traction as a promising approach to align large models with human feedback. It is notable for its effectiveness and ease of application across various models, including Large Language Models (LLMs) and Diffusion Models (DMs). However, the quality of preference data used in DPO training has been largely overlooked. Current datasets, whether annotated by deep learning metrics or crowd-sourced human judgments, often contain noisy labels. This noise can adversely affect the performance of DPO. \nTo address this issue, we propose a novel approach that incorporates a noise-aware metric into the DPO objective. This metric, which includes intra-annotator confidence and inter-annotator stability, helps identify and mitigate the impact of noisy data. We introduce an Adaptive-DPO loss function which improves the DPO loss in two ways: one aims to reduce the influence of noisy samples, while the other is to amplify the impact of clean samples. Our experiments demonstrate that this method effectively handles both synthetic and natural noisy data, leading to improved performance in visual and textual generation tasks. This underscores the practical value of our approach in enhancing model robustness amidst noisy preference data."
    },
    {
        "title": "Rethinking the generalization of drug target affinity prediction algorithms via similarity aware evaluation",
        "link_suffix": "/forum?id=j7cyANIAxV",
        "link": "https://openreview.net/forum?id=j7cyANIAxV",
        "pdf_link": "https://openreview.net/pdf?id=j7cyANIAxV",
        "keywords": "Drug-Target Affinity Prediction, Similarity-Aware Evaluation",
        "abstract": "Drug-target binding affinity prediction is a fundamental task for drug discovery.  It has been extensively explored in literature and promising results are reported. However, in this paper we demonstrate that the results may be misleading and cannot be well generalized to real practice. The core observation is that the canonical randomized split of testset in conventional evaluation leaves the testset dominated by samples with high similarity to trainset. Performance of models is severely degraded on samples with lower similarity to trainset but the drawback is highly overlooked in current evaluation. As a result, the performance can hardly be trusted when the model meets low-similarity samples in real practice.  To address this problem, we propose a framework of similarity aware evaluation in which a novel split methodology is proposed to adapt to any target distribution. This is achieved by a formulation of optimization problems which are approximately and efficiently solved by gradient descent. We perform extensive experiments across five representative methods in four datasets for two typical target evaluation and compare with various counterpart methods. Results demonstrate that the proposed split methodology can significantly better fit target distributions and guide the development of models."
    },
    {
        "title": "Inferring Time-Varying Internal Models of Agents Through Dynamic Structure Learning",
        "link_suffix": "/forum?id=tE9gdaxHeB",
        "link": "https://openreview.net/forum?id=tE9gdaxHeB",
        "pdf_link": "https://openreview.net/pdf?id=tE9gdaxHeB",
        "keywords": "Decision Making, Causal World Models, Structure Learning, Reinforcement Learning, Cognitive Modeling, Natural Intelligence",
        "abstract": "Reinforcement learning (RL) models usually assume a stationary internal model structure of agents, which consists of fixed learning rules and environment representations. However, this assumption does not allow accounting for real problem solving by individuals who can exhibit irrational behaviors or hold inaccurate beliefs about their environment. In this work, we present a novel framework called Dynamic Structure Learning (DSL), which allows agents to adapt their learning rules and internal representations dynamically. This structural flexibility enables a deeper understanding of how individuals learn and adapt in real-world scenarios. The DSL framework reconstructs the most likely sequence of agent structures\u2014sourced from a pool of learning rules and environment models\u2014based on observed behaviors. The method provides insights into how an agent's internal structure model evolves as it transitions between different structures throughout the learning process. We applied our framework to study rat behavior in a maze task. Our results demonstrate that rats progressively refine their mental map of the maze, evolving from a suboptimal representation associated with repetitive errors to an optimal one that guides efficient navigation. Concurrently, their learning rules transition from heuristic-based to more rational approaches.  These findings underscore the importance of both credit assignment and representation learning in complex behaviors. By going beyond simple reward-based associations, our research offers valuable insights into the cognitive mechanisms underlying decision-making in natural intelligence. DSL framework allows better understanding and modeling how individuals in real-world scenarios exhibit a level of adaptability that current AI systems have yet to achieve."
    },
    {
        "title": "Enhancing Human Body Generation in Diffusion Models with Dual-Level Prior Knowledge",
        "link_suffix": "/forum?id=qC3pfTGOxz",
        "link": "https://openreview.net/forum?id=qC3pfTGOxz",
        "pdf_link": "https://openreview.net/pdf?id=qC3pfTGOxz",
        "keywords": "diffusion models, human body generation",
        "abstract": "The development of diffusion models (DMs) has greatly enhanced text-to-image generation, outperforming previous methods like generative adversarial networks (GANs) in terms of image quality and text alignment. However, accurately generating human body images remains challenging, often resulting in disproportionate figures and anatomical errors, which limits their practical applications in areas such as portrait generation. While previous methods such as HcP have shown promising results, limitations including wrongly kept prior, insufficient human-related knowledge, and limited generalization ability still exist due to the specific design of fully-supervised learning with only pose-related information. In this study, we introduce a novel method to enhance pretrained diffusion models for realistic human body generation by incorporating dual-level human prior knowledge. Our approach involves learning shape-level details with the human-related tokens in the original prompts, and learning pose-level prior by adding a learnable pose-aware token to each text prompt. We use a two-stage training strategy to rectify the cross attentions with a bind-then-generalize process, leveraging multiple novel objectives along with adversarial training. Our extensive experiments show that this method significantly improves the ability of SD1.5 and SDXL pretrained models to generate human bodies, reducing deformities and enhancing practical utility."
    },
    {
        "title": "Learning with Analogical Reasoning for Robust Few-Shot Learning",
        "link_suffix": "/forum?id=jPlghr8io4",
        "link": "https://openreview.net/forum?id=jPlghr8io4",
        "pdf_link": "https://openreview.net/pdf?id=jPlghr8io4",
        "keywords": "few-shot learning, analogical reasoning, noisy label learning, contrastive learning, transformer",
        "abstract": "Few-shot learning (FSL) is challenging due to limited support data for model training. The situation is much worse when the support data is contaminated with noise. To address this issue, in this work we propose a novel $\\textbf{T}$ransformer-based $\\textbf{A}$nalogical $\\textbf{R}$easoning model for $\\textbf{N}$oisy $\\textbf{F}$ew-$\\textbf{S}$hot learning (TarNFS), by mimicing the human's ability of learning by analogy. Concretely, we assume the existence of a large human cultivated knowledge base, and hypothesize that similar concepts in the knowledge base are visually similar in the latent space as well. Then we design a transformer-based analogical reasoning model to utilize inter-concept connections among these concepts, aiming to build robust and discriminative classification boundaries. In addition, we propose a task-level contrastive learning to analogically learn from negative tasks to facilitate model optimization with noisy tasks during training. Experiments demonstrate that our TarNFS enables more effective learning from limited and imperfect data. It not only improves the generalization ability of FSL in different noisy settings but also achieves competitive performance in the common clean FSL settings."
    }
]
[{"title": "GeoBench: A new benchmark on Symbolic Regression with Geometric Expressions", "link_suffix": "/forum?id=TqzNI4v9DT", "link": "https://openreview.net/forum?id=TqzNI4v9DT", "pdf_link": "https://openreview.net/pdf?id=TqzNI4v9DT", "keywords": "Symbolic Regression, Geometry", "abstract": "Symbolic regression (SR) is a powerful technique for deriving mathematical expressions from data. With the emergence of numerous SR methods, SRBench made a significant contribution by providing a standardized testing platform that includes 130 SR datasets and evaluates 14 SR methods. However, the methods included in SRBench are outdated, and the dataset does not feature results from more recent approaches such as TPSR. Additionally, the metrics used in SRBench do not adequately capture the full capabilities of symbolic regression methods, and the benchmark data has scientific problems. Although Matsubara et al. (2022) address some of these issues,\ntheir approach remains incomplete.  In response, we propose a new benchmark consisting of 71 expressions derived from geometric contexts, categorized into three difficulty levels: easy, medium, and hard. We evaluate 20 SR methods on these expressions, focusing exclusively on the symbolic regression capability of each model, assessed through recovery rates across the different levels and overall. We provide a detailed methodology for reproducing the experiments and include results for newly developed SR methods within this updated benchmark. The results demonstrate significant variation in symbolic regression ability across models.", "title_embedding_index": 12150, "title_abs_embedding_index": 12175}, {"title": "FIRING-Net: A filtered feature recycling network for speech enhancement", "link_suffix": "/forum?id=TJp3LnQgSX", "link": "https://openreview.net/forum?id=TJp3LnQgSX", "pdf_link": "https://openreview.net/pdf?id=TJp3LnQgSX", "keywords": "speech enhancement, target and non-target features, self-attention", "abstract": "Current deep neural networks for speech enhancement (SE) aim to minimize the distance between the output signal and the clean target by filtering out noise features from input features. However, when noise and speech components are highly similar, SE models struggle to learn effective discrimination patterns. To address this challenge, we propose a Filter-Recycle-Interguide framework termed Filter-Recycle-INterGuide NETwork (FIRING-Net) for SE, which filters the input features to extract target features and recycles the filtered-out features as non-target features. These two feature sets then guide each other to refine the features, leading to the aggregation of speech information within the target features and noise information within the non-target features. The proposed FIRING-Net mainly consists of a Local Module (LM) and a Global Module (GM). The LM uses outputs of the speech extraction network as target features and the residual between input and output as non-target features. The GM leverages the energy distribution of self-attention map to extract target and non-target features guided by highest and lowest energy regions. Both LM and GM include interaction modules to leverage the two feature sets in an inter-guided manner for collecting speech from non-target features and filtering out noise from target features. Experiments confirm the effectiveness of the Filter-Recycle-Interguide framework, with FIRING-Net achieving a strong balance between SE performance and computational efficiency, surpassing comparable models across various SNR levels and noise environments.", "title_embedding_index": 12151, "title_abs_embedding_index": 12176}, {"title": "Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering", "link_suffix": "/forum?id=1i6lkavJ94", "link": "https://openreview.net/forum?id=1i6lkavJ94", "pdf_link": "https://openreview.net/pdf?id=1i6lkavJ94", "keywords": "Conformal Prediction, Generative Models, Risk Control, Active Learning, Language Models", "abstract": "Generative models lack rigorous statistical guarantees with respect to their predictions. In this work, we propose Sequential Conformal Prediction for Generative Models (SCOPE-Gen), a sequential conformal prediction method producing prediction sets that satisfy a rigorous statistical guarantee called conformal admissibility control. This guarantee means that the prediction sets contain at least one admissible (or valid) example, with high probability. To this end, our method first samples an initial set of i.i.d. examples from a black box generative model. Then, this set is iteratively pruned via so-called greedy filters. As a consequence of the iterative generation procedure, admissibility of the final prediction set factorizes as a Markov chain, where each factor can be controlled separately, using conformal prediction. In comparison to prior work, our method demonstrates a large reduction in the number of admissibility evaluations during calibration. This is crucial e.g. in safety-critical applications, where these evaluations must be conducted manually by domain experts and are therefore costly and time consuming. We highlight the advantages of our method in terms of admissibility evaluations and cardinality of the prediction set through experiments in natural language generation and molecular graph extension tasks.", "title_embedding_index": 12152, "title_abs_embedding_index": 12177}, {"title": "AutoPR: Automatically Pull Request Generation for Fix Issued Bugs of CodeBase", "link_suffix": "/forum?id=6FNYXWHRbz", "link": "https://openreview.net/forum?id=6FNYXWHRbz", "pdf_link": "https://openreview.net/pdf?id=6FNYXWHRbz", "keywords": "Automated Software Development;Program Repair;AI Software Engineers;Collaborative Agent Technologies;In-Memory Caching;Routing Algorithms", "abstract": "Over the past few decades, researchers have made significant strides in automating software development processes. This evolution has transformed the way software is created, maintained, and enhanced. Recently, the integration of Large Language Models (LLMs) into software development has opened new horizons. Researchers have investigated the potential of LLMs and demonstrated that they provide strong performance gains. These models can understand natural language instructions, generate code snippets, and even identify and fix bugs, thereby streamlining the development process. However, software engineering encompasses more than just coding; it involves the continuous improvement of programs to facilitate software maintenance and evolution. This includes tasks like program repair to fix bugs and feature additions to enhance functionality. Traditional automation tools often fall short in these areas, highlighting the need for more advanced solutions. Inspired by these insights, we have developed a novel automated program repair method called \\textit{AutoPR}. AutoPR represents a new generation of AI software engineers, leveraging routing algorithms, in-memory caching, and collaborative agent technologies. Its design addresses the current efficiency bottlenecks and quality issues faced in software development.", "title_embedding_index": 12153, "title_abs_embedding_index": 12178}, {"title": "Federated Continual Learning Goes Online: Uncertainty-Aware Memory Management for Vision Tasks and Beyond", "link_suffix": "/forum?id=f65RuQgVlp", "link": "https://openreview.net/forum?id=f65RuQgVlp", "pdf_link": "https://openreview.net/pdf?id=f65RuQgVlp", "keywords": "Federated Continual Learning, Catastrophic Forgetting, Uncertainty Estimation", "abstract": "Given the ability to model more realistic and dynamic problems, Federated Continual Learning (FCL) has been increasingly investigated recently. A well-known problem encountered in this setting is the so-called catastrophic forgetting, for which the learning model is inclined to focus on more recent tasks while forgetting the previously learned knowledge. The majority of the current approaches in FCL propose generative-based solutions to solve said problem. However, this setting requires multiple training epochs over the data, implying an offline setting where datasets are stored locally and remain unchanged over time. Furthermore, the proposed solutions are tailored for vision tasks solely. To overcome these limitations, we propose a new approach to deal with different modalities in the online scenario where new data arrive in streams of mini-batches that can only be processed once. To solve catastrophic forgetting, we propose an uncertainty-aware memory-based approach.  Specifically, we suggest using an estimator based on the Bregman Information (BI) to compute the model's variance at the sample level. Through measures of predictive uncertainty, we retrieve samples with specific characteristics, and \u2013 by retraining the model on such samples \u2013 we demonstrate the potential of this approach to reduce the forgetting effect in realistic settings while maintaining data confidentiality and competitive communication efficiency compared to state-of-the-art approaches.", "title_embedding_index": 12154, "title_abs_embedding_index": 12179}, {"title": "\ud83e\udd14Emoji2Idiom: Benchmarking Cryptic Symbol Understanding of Multimodal Large Language Models", "link_suffix": "/forum?id=YxOG4FjZLd", "link": "https://openreview.net/forum?id=YxOG4FjZLd", "pdf_link": "https://openreview.net/pdf?id=YxOG4FjZLd", "keywords": "Multimodal Large Language Models, Benchmark, Vision and Language", "abstract": "Vision and Language are two major modalities in Artificial Intelligence research. Bridging the gap between these modalities has long been a key focus in the multimodal community. Inspired by human cognition, we believe that if a model can see an image and directly associate it with its linguistic meaning, the model possesses high-level intelligence that spans vision and language. In our work, we focus on emojis in images, a widely-used \"cryptic symbol'', with a data form of both visual and linguistic features. Specifically, we first propose the novel task of translating emojis in images to corresponding idioms, thereby challenging Multimodal Large Language Models (MLLMs) to (1) understand the semantic correlation between language and emojis, and (2) reason the intricate linguistic meaning from the emojis in images. To facilitate the advancement of this task, we construct a high-quality benchmark, Emoji2Idiom following the process of automatic model generation and human manual filtering. Based on our constructed Emoji2Idiom, we employ multiple advanced MLLMs to conduct extensive experiments and detailed analyses, demonstrating that existing MLLMs do not yet have enough capability to understand and reason the linguistic information from visual data. We believe our proposed benchmark and interesting discoveries will encourage the community to attach importance to the intelligence of MLLMs directly associating language from vision, to give MLLMs more comprehensive vision-language understanding ability.", "title_embedding_index": 12155, "title_abs_embedding_index": 12180}, {"title": "ExVideo: Extending Video Diffusion Models via Parameter-Efficient Post-Tuning", "link_suffix": "/forum?id=Hhx3swAQAZ", "link": "https://openreview.net/forum?id=Hhx3swAQAZ", "pdf_link": "https://openreview.net/pdf?id=Hhx3swAQAZ", "keywords": "generative models, video synthesis, post tuning", "abstract": "Recently, advancements in video synthesis have attracted significant attention. Video synthesis models such as AnimateDiff and Stable Video Diffusion have demonstrated the practical applicability of diffusion models in creating dynamic visual content. The emergence of SORA has further spotlighted the potential of video generation technologies. Despite advancements, the extension of video lengths remains constrained by computational resources. Most existing video synthesis models are limited to generating short video clips. In this paper, we propose a novel post-tuning methodology for video synthesis models, called ExVideo. This approach is designed to enhance the capability of current video synthesis models, allowing them to produce content over extended temporal durations while incurring lower training expenditures. In particular, we design extension strategies across common temporal model architectures respectively, including 3D convolution, temporal attention, and positional embedding. To evaluate the efficacy of our proposed post-tuning approach, we trained ExSVD, an extended model based on Stable Video Diffusion model. Our approach enhances the model's capacity to generate up to $5\\times$ its original number of frames, requiring only 1.5k GPU hours of training on a dataset comprising 40k videos. Importantly, the substantial increase in video length doesn't compromise the model's innate generalization capabilities, and the model showcases its advantages in generating videos of diverse styles and resolutions. We will release the source code and the enhanced model publicly.", "title_embedding_index": 12156, "title_abs_embedding_index": 12181}, {"title": "GaussianBlock: Building Part-Aware Compositional and Editable 3D Scene by Primitives and Gaussians", "link_suffix": "/forum?id=wrXCIsysqB", "link": "https://openreview.net/forum?id=wrXCIsysqB", "pdf_link": "https://openreview.net/pdf?id=wrXCIsysqB", "keywords": "3D Decompostion, 3D Reconstruction, 3D Editing", "abstract": "Recently, with the development of Neural Radiance Fields and Gaussian Splatting, 3D reconstruction techniques have achieved remarkably high fidelity. However, the latent representations learnt by these methods are highly entangled and lack interpretability. In this paper, we propose a novel part-aware compositional reconstruction method, called GaussianBlock, that enables semantically coherent and disentangled representations, allowing for precise and physical editing akin to building blocks, while simultaneously maintaining high fidelity.\nOur GaussianBlock introduces a hybrid representation that leverages the advantages of both primitives, known for their flexible actionability and editability, and 3D Gaussians, which excel in reconstruction quality. Specifically, we achieve semantically coherent primitives through a novel attention-guided centering loss derived from 2D semantic priors, complemented by a dynamic splitting and fusion strategy. \nFurthermore, we utilize 3D Gaussians that hybridize with primitives to refine structural details and enhance fidelity. \nAdditionally, a binding inheritance strategy is employed to strengthen and maintain the connection between the two. \nOur reconstructed scenes are evidenced to be disentangled, compositional, and compact across diverse benchmarks, enabling seamless, direct and precise editing while maintaining high quality.", "title_embedding_index": 12157, "title_abs_embedding_index": 12182}, {"title": "How Far are Today's Time-Series Models from Real-world Weather Forecasting Applications?", "link_suffix": "/forum?id=x9cXrOQskc", "link": "https://openreview.net/forum?id=x9cXrOQskc", "pdf_link": "https://openreview.net/pdf?id=x9cXrOQskc", "keywords": "Time-series benchmark, large scale spatial-temporal dataset\uff0c numerical weather prediction model", "abstract": "The development of Time-Series Forecasting (TSF) techniques is often hindered by the lack of comprehensive datasets. This is particularly problematic for time-series weather forecasting, where commonly used datasets suffer from significant limitations such as small size, limited temporal coverage, and sparse spatial distribution. These constraints severely impede the optimization and evaluation of TSF models, resulting in benchmarks that are not representative of real-world applications, such as operational weather forecasting. In this work, we introduce the WEATHER-5K dataset, a comprehensive collection of observational weather data that better reflects real-world scenarios. As a result, it enables a better training of models and a more accurate assessment of the real-world forecasting capabilities of TSF models, pushing them closer to in-situ applications. Through extensive benchmarking against operational Numerical Weather Prediction (NWP) models, we provide researchers with a clear assessment of the gap between academic TSF models and real-world weather forecasting applications. This highlights the significant performance disparity between TSF and NWP models by analyzing performance across detailed weather variables, extreme weather event prediction, and model complexity comparison. Finally, we summarise the result into recommendations to the users and highlight potential areas required to facilitate further TSF research.\nThe dataset and benchmark implementation will be publicly available.", "title_embedding_index": 12158, "title_abs_embedding_index": 12183}, {"title": "Overcoming Lookback Window Limitations: Exploring Longer Windows in Long-Term Time Series Forecasting", "link_suffix": "/forum?id=hVpAjJPfgZ", "link": "https://openreview.net/forum?id=hVpAjJPfgZ", "pdf_link": "https://openreview.net/pdf?id=hVpAjJPfgZ", "keywords": "long-term time series forcasting, Mamba, Information Bottleneck", "abstract": "Long-term time series forecasting (LTSF) aims to predict future trends based on historical data. While longer lookback windows theoretically provide more comprehensive insights, current Transformer-based models face the Lookback Window Limitation (LWL). On one hand, longer windows introduce redundant information, which can hinder model learning. On the other hand, Transformers tend to overfit temporal noise rather than extract meaningful temporal information when dealing with longer sequences, compounded by their quadratic complexity. In this paper, we aim to overcome LWL, enabling models to leverage more historical information for improved performance. Specifically, to mitigate information redundancy, we introduce the Information Bottleneck Filter (IBF), which applies information bottleneck theory to extract essential subsequences from the input. Additionally, to address the limitations of the Transformer architecture in handling long sequences, we propose the Hybrid-Transformer-Mamba (HTM), which combines the linear complexity and long-range modeling capabilities of Mamba with the Transformer's strength in modeling short sequences. We integrate these two model-agnostic modules into various existing methods and conduct experiments on seven datasets. The results demonstrate that incorporating these modules effectively overcomes the lookback window limitations. Notably, by combining them with the Patch strategy, we design the PIH (\\textbf{P}atch-\\textbf{I}BF-\\textbf{H}TM), successfully extending the window length to 1024\u2014a significantly larger window than previously achieved\u2014and achieving state-of-the-art results, highlighting the potential of exploring even longer windows.", "title_embedding_index": 12159, "title_abs_embedding_index": 12184}, {"title": "GEOMETRIC SIGNATURES OF COMPOSITIONALITY ACROSS A LANGUAGE MODEL\u2019S LIFETIME", "link_suffix": "/forum?id=q5lJxCXjiY", "link": "https://openreview.net/forum?id=q5lJxCXjiY", "pdf_link": "https://openreview.net/pdf?id=q5lJxCXjiY", "keywords": "geometry, compositionality, representation learning", "abstract": "Compositionality, the notion that the meaning of an expression is constructed from the meaning of its parts and syntactic rules, permits the infinite productivity of human language. For the first time, artificial language models (LMs) are able to match human performance in a number of compositional generalization tasks. However, much remains to be understood about the representational mechanisms underlying these abilities. We take a high-level geometric approach to this problem by relating the degree of compositionality in a dataset to the intrinsic dimensionality of its representations under an LM, a measure of feature complexity. We find not only that the degree of dataset compositionality is reflected in representations' intrinsic dimensionality, but that the relationship between compositionality and geometric complexity arises due to learned linguistic features over training. Finally, our analyses reveal a striking contrast between linear and nonlinear dimensionality, showing that they respectively encode formal and semantic aspects of linguistic composition.", "title_embedding_index": 12160, "title_abs_embedding_index": 12185}, {"title": "CompGS: Unleashing 2D Compositionality for Compositional Text-to-3D via Dynamically Optimizing 3D Gaussians", "link_suffix": "/forum?id=o0qrehZW94", "link": "https://openreview.net/forum?id=o0qrehZW94", "pdf_link": "https://openreview.net/pdf?id=o0qrehZW94", "keywords": "Compositional 3D Generation, Gaussian Splatting", "abstract": "Recent breakthroughs in text-guided image generation have significantly advanced the field of 3D generation. While generating a single high-quality 3D object is now feasible, generating multiple objects with reasonable interactions within a 3D space, a.k.a. compositional 3D generation, presents substantial challenges. This paper introduces CompGS, a novel generative framework that employs 3D Gaussian Splatting (GS) for efficient, compositional text-to-3D content generation. To achieve this goal, two core designs are proposed: (1) 3D Gaussians Initialization with 2D compositionality: We transfer the well-established 2D compositionality to initialize the Gaussian parameters on an entity-by-entity basis, ensuring both consistent 3D priors for each entity and reasonable interactions among multiple entities; (2) Dynamic Optimization: We propose a dynamic strategy to optimize 3D Gaussians using Score Distillation Sampling (SDS) loss. CompGS first automatically decomposes 3D Gaussians into distinct entity parts, enabling optimization at both the entity and composition levels. Additionally, CompGS optimizes across objects of varying scales by dynamically adjusting the spatial parameters of each entity, enhancing the generation of fine-grained details, particularly in smaller entities. Qualitative comparisons and quantitative evaluations on T3Bench demonstrate the effectiveness of CompGS in generating compositional 3D objects with superior image quality and semantic alignment over existing methods. CompGS can also be easily extended to controllable 3D editing, facilitating scene generation. We hope CompGS will provide new insights to the compositional 3D generation. Codes will be released to the research community.", "title_embedding_index": 12161, "title_abs_embedding_index": 12186}, {"title": "Enhanced multi-task learning of imputation and prediction via feature relationship graph learning", "link_suffix": "/forum?id=ZWthVveg7X", "link": "https://openreview.net/forum?id=ZWthVveg7X", "pdf_link": "https://openreview.net/pdf?id=ZWthVveg7X", "keywords": "Missing values, imputation, feature selection, graph nueral network, multi-task learning", "abstract": "Missing values present significant challenges in machine learning, often degrading predictive performance. Traditional and deep learning imputation methods often overlook the relationships between features and their connections to downstream tasks. To address these gaps, we propose PIG (multi-task learning of Prediction and Imputation via feature-relationship Graph learning), a model that integrates imputation and prediction by leveraging feature interdependencies. \nPIG utilizes a graph-based approach to capture intricate feature relationships, thereby enhancing the accuracy of both imputation and downstream tasks. Our strategic training process begins with pre-training for both tasks, ensuring the model learns effective representations. This is followed by fine-tuning the entire model to further optimize imputation and downstream tasks simultaneously.\nWe evaluated our method using nine benchmark datasets, three for regression and six for classification.\nOur method showed superior imputation and prediction performance across nine datasets, achieving an average rank of 1.33 for both imputation and regression tasks and 1.83 for imputation and 1.17 for classification tasks. Additionally, in sensitivity analysis with respect to missing rates, our method demonstrated its robustness, especially in predictive performance, compared to other methods that showed significant degradation.", "title_embedding_index": 12162, "title_abs_embedding_index": 12187}, {"title": "Equivariant Masked Position Prediction for Efficient Molecular Representation", "link_suffix": "/forum?id=Nue5iMj8n6", "link": "https://openreview.net/forum?id=Nue5iMj8n6", "pdf_link": "https://openreview.net/pdf?id=Nue5iMj8n6", "keywords": "Self-supervised Learning; Graph Neural Network; Molecular Property Prediction;", "abstract": "Graph neural networks (GNNs) have shown considerable promise in computational chemistry. However, the limited availability of molecular data raises concerns regarding GNNs' ability to effectively capture the fundamental principles of physics and chemistry, which constrains their generalization capabilities. To address this challenge, we introduce a novel self-supervised approach termed Equivariant Masked Position Prediction (EMPP), grounded in intramolecular potential and force theory. Unlike conventional attribute masking techniques, EMPP formulates a nuanced position prediction task that is more well-defined and enhances the learning of quantum mechanical features. EMPP also bypasses the approximation of the Gaussian mixture distribution commonly used in denoising methods, allowing for more accurate acquisition of physical properties. Experimental results indicate that EMPP significantly enhances performance of advanced molecular architectures, surpassing state-of-the-art self-supervised approaches. The code for EMPP is anonymously released inhttps://github.com/AnonymousACode/EMPP.", "title_embedding_index": 12163, "title_abs_embedding_index": 12188}, {"title": "S-LoRA: Scalable Low-Rank Adaptation for Class Incremental Learning", "link_suffix": "/forum?id=5U1rlpX68A", "link": "https://openreview.net/forum?id=5U1rlpX68A", "pdf_link": "https://openreview.net/pdf?id=5U1rlpX68A", "keywords": "Continual learning; Low-rank adaptation", "abstract": "Continual Learning (CL) with foundation models has recently emerged as a promising approach to harnessing the power of pre-trained models for sequential tasks. Existing prompt-based methods generally use a gating mechanism to select relevant prompts aligned with the test query for further processing. However, the success of these methods largely depends on the precision of the gating mechanism, which becomes less scalable with additional computational overhead as tasks increases. \nTo overcome these issues, we propose a Scalable Low-Rank Adaptation (S-LoRA) method for CL (in particular class incremental learning), which incrementally decouples the learning of the direction and magnitude of LoRA parameters. S-LoRA supports efficient inference by  employing the last-stage trained model for direct testing without a gating process. Our theoretical and empirical analysis demonstrates that S-LoRA tends to follow a low-loss trajectory that converges to an overlapped low-loss region, resulting in an excellent stability-plasticity trade-off in CL. Furthermore, based on our findings, we develop variants of S-LoRA with further improved scalability. Extensive experiments across multiple CL benchmarks and various foundation models consistently validate the effectiveness of S-LoRA.", "title_embedding_index": 12164, "title_abs_embedding_index": 12189}, {"title": "Two-Stage Pretraining for Molecular Property Prediction in the Wild", "link_suffix": "/forum?id=R8YCBH5HWo", "link": "https://openreview.net/forum?id=R8YCBH5HWo", "pdf_link": "https://openreview.net/pdf?id=R8YCBH5HWo", "keywords": "large-scale pretraining, molecular property prediction", "abstract": "Accurate property prediction is crucial for accelerating the discovery of new compounds. Although deep learning models have achieved remarkable success, their performance often relies on large amounts of labeled data that are expensive and time-consuming to obtain. Thus, there is a growing need for models that can perform well with limited experimentally-validated data. In this work, we introduce MoleVers, a versatile pretrained model designed for various types of molecular property predictionin the wild, i.e., where experimentally-validated molecular property labels are scarce. MoleVers adopts a two-stage pretraining strategy. In the first stage, the model learns molecular representations from large unlabeled datasets via masked atom prediction anddynamic denoising, a novel task enabled by a new branching encoder architecture. In the second stage, MoleVers is further pretrained using auxiliary labels obtained with inexpensive computational methods, enabling supervised learning without the need for costly experimental data. This two-stage framework allows MoleVers to learn representations that generalize effectively across various downstream datasets. We evaluate MoleVers on a new benchmark comprising 22 molecular datasets with diverse types of properties, the majority of which contain 50 or fewer training labels reflecting real-world conditions. MoleVers achieves state-of-the-art results on 20 out of the 22 datasets, and ranks second among the remaining two, highlighting its ability to bridge the gap between data-hungry models and real-world conditions where practically-useful labels are scarce.", "title_embedding_index": 12165, "title_abs_embedding_index": 12190}, {"title": "PETRA: Parallel End-to-end Training with Reversible Architectures", "link_suffix": "/forum?id=0fhzSFsGUT", "link": "https://openreview.net/forum?id=0fhzSFsGUT", "pdf_link": "https://openreview.net/pdf?id=0fhzSFsGUT", "keywords": "Model parallelism, Delayed gradient, Reversible architectures", "abstract": "Reversible architectures have been shown to be capable of performing on par with their non-reversible architectures, being applied in deep learning for memory savings and generative modeling. In this work, we show how reversible architectures can solve challenges in parallelizing deep model training. We introduce PETRA, a novel alternative to backpropagation for parallelizing gradient computations. PETRA facilitates effective model parallelism by enabling stages (i.e., a set of layers) to compute independently on different devices, while only needing to communicate activations and gradients between each other. By decoupling the forward and backward passes and keeping a single updated version of the parameters, the need for weight stashing is also removed. We develop a custom autograd-like training framework for PETRA, and we demonstrate its effectiveness on standard computer vision benchmarks, achieving competitive accuracies comparable to backpropagation using ResNet-18, ResNet-34, and ResNet-50 models.", "title_embedding_index": 12166, "title_abs_embedding_index": 12191}, {"title": "Towards Understanding the Universality of Transformers for Next-Token Prediction", "link_suffix": "/forum?id=yWoV4Ca6ji", "link": "https://openreview.net/forum?id=yWoV4Ca6ji", "pdf_link": "https://openreview.net/pdf?id=yWoV4Ca6ji", "keywords": "Transformers, In-Context Learning, Deep Learning Theory", "abstract": "Causal Transformers are trained to predict the next token for a given context. While it is widely accepted that self-attention is crucial for encoding the causal structure of sequences, the precise underlying mechanism behind this in-context autoregressive learning ability remains unclear. In this paper, we take a step towards understanding this phenomenon by studying the approximation ability of Transformers for next-token prediction. Specifically, we explore the capacity of causal Transformers to predict the next token $x_{t+1}$ given an autoregressive sequence $(x_1, \\dots, x_t)$ as a prompt, where $ x_{t+1} = f(x_t) $, and $ f $ is a context-dependent function that varies with each sequence.\nOn the theoretical side, we focus on specific instances, namely when $ f $ is linear or when $ (x_t)$ is periodic. We explicitly construct a Transformer (with linear, exponential, or softmax attention) that learns the mapping $f$ in-context through a causal kernel descent method. The causal kernel descent method we propose provably estimates $x_{t+1} $ based solely on past and current observations $ (x_1, \\dots, x_t) $, with connections to the Kaczmarz algorithm in Hilbert spaces. We present experimental results that validate our theoretical findings and suggest their applicability to more general mappings $f$.", "title_embedding_index": 12167, "title_abs_embedding_index": 12192}, {"title": "A-Bench: Are LMMs Masters at Evaluating AI-generated Images?", "link_suffix": "/forum?id=4muXQ5r8Ol", "link": "https://openreview.net/forum?id=4muXQ5r8Ol", "pdf_link": "https://openreview.net/pdf?id=4muXQ5r8Ol", "keywords": "Large multi-modal models, AI-generated images, Benchmark", "abstract": "How to accurately and efficiently assess AI-generated images (AIGIs) remains a critical challenge for generative models. Given the high costs and extensive time commitments required for user studies, many researchers have turned towards employing large multi-modal models (LMMs) as AIGI evaluators, the precision and validity of which are still questionable. Furthermore, traditional benchmarks often utilize mostly natural-captured content rather than AIGIs to test the abilities of LMMs, leading to a noticeable gap for AIGIs. Therefore, we introduceA-Benchin this paper, a benchmark designed to diagnosewhether LMMs are masters at evaluating AIGIs. Specifically,A-Benchis organized under two key principles: 1) Emphasizing both high-level semantic understanding and low-level visual quality perception to address the intricate demands of AIGIs. 2) Various generative models are utilized for AIGI creation, and various LMMs are employed for evaluation, which ensures a comprehensive validation scope. Ultimately, 2,864 AIGIs from 16 text-to-image models are sampled, each paired with question-answers annotated by human experts. We hope thatA-Benchwill significantly enhance the evaluation process and promote the generation quality for AIGIs.", "title_embedding_index": 12168, "title_abs_embedding_index": 12193}, {"title": "Look Around and Find Out: OOD Detection with Relative Angles", "link_suffix": "/forum?id=xQit6JBDR5", "link": "https://openreview.net/forum?id=xQit6JBDR5", "pdf_link": "https://openreview.net/pdf?id=xQit6JBDR5", "keywords": "out-of-distribution, out-of-distribution detection, decision boundaries", "abstract": "Deep learning systems deployed in real-world applications often encounter data that is different from their in-distribution (ID). A reliable system should ideally abstain from making decisions in this out-of-distribution (OOD) setting. Existing state-of-the-art methods primarily focus on feature distances, such as k-th nearest neighbors and distances to decision boundaries, either overlooking or ineffectively using in-distribution statistics. In this work, we propose a novel angle-based metric for OOD detection that is computed relative to the in-distribution structure. We demonstrate that the angles between feature representations and decision boundaries, viewed from the mean of in-distribution features, serve as an effective discriminative factor between ID and OOD data. Our method achieves state-of-the-art performance on CIFAR-10 and ImageNet benchmarks, reducing FPR95 by 0.88% and 7.74% respectively. Our scoring function is compatible with existing feature space regularization techniques, enhancing performance. Additionally, its scale-invariance property enables creating an ensemble of models for OOD detection via simple score summation.", "title_embedding_index": 12169, "title_abs_embedding_index": 12194}, {"title": "Visual Transformation Telling", "link_suffix": "/forum?id=qu6UMVT4k1", "link": "https://openreview.net/forum?id=qu6UMVT4k1", "pdf_link": "https://openreview.net/pdf?id=qu6UMVT4k1", "keywords": "visual reasoning, transformation, captioning", "abstract": "Humans can naturally reason from superficial state differences (e.g. ground wetness) to transformations descriptions (e.g. raining) according to their life experience. In this paper, we propose a new visual reasoning task to test this transformation reasoning ability in real-world scenarios, calledVsualTransformationTelling (VTT). Given a series of states (i.e., images), VTT requires to describe the transformation occurring between every two adjacent states. Different from existing visual reasoning tasks that focus on surface state reasoning, the advantage of VTT is that it captures the underlying causes, e.g. actions or events, behind the differences among states. We collect a novel dataset which comprise 13,547 samples to support the study of transformation reasoning. Each sample involves several key state images along with their transformation descriptions. Our dataset spans diverse real-world activities, providing a rich resource for training and evaluation with automated, human, and LLM assessments. To construct an initial benchmark for VTT, we test models including traditional visual storytelling (CST, GLACNet) or dense video captioning methods (Densecap) and advanced multimodal large language models (LLaVA v1.5-7B, Qwen-VL-chat, Gemini-1.5, GPT-4o, and GPT-4), as well as their upgraded versions based on our learning on human reasoning. Experimental results reveal that even state-of-the-art models still have a significant gap with human performance in VTT, highlighting substantial areas for improvement.", "title_embedding_index": 12170, "title_abs_embedding_index": 12195}, {"title": "Robust Spike-based Decoupled Federated Information Bottleneck Learning with Spiking Neural Network under System Heterogeneity", "link_suffix": "/forum?id=qDCkEHN3m8", "link": "https://openreview.net/forum?id=qDCkEHN3m8", "pdf_link": "https://openreview.net/pdf?id=qDCkEHN3m8", "keywords": "Spiking neural network, federated learning, spike-based learning, neuromorphic computing", "abstract": "As embedded devices become increasingly prevalent in intelligent systems, low-power system in resource-constrained environments has emerged as a key challenge. Spiking neural networks (SNNs), with their sparse and event-driven computation, have shown great potential as a low-power candidate for embedded devices. In federated learning scenarios, where multiple energy-constrained devices collaborate, adopting efficient SNN models with effective training methods is critical. However, research on training SNNs within federated learning systems is still very limited, particularly in terms of how to achieve both energy efficiency and robustness under system heterogeneity. This gap presents a significant opportunity for further exploration of SNNs in distributed learning settings. In this paper, we investigate a significant and innovative problem in robust spike-based federated learning, particularly in the presence of noise, and system heterogeneity. We majorly consider two types of system heterogeneity in this study, including data and client participation heterogeneity. To address this, we propose a novel federated learning framework, spike-based decoupled federated information-bottleneck learning (SDFIL), to enable robust, low-power federated learning through SNNs under system heterogeneity. Specifically, we design a decoupled information bottleneck principle tailored for local SNN training to maximize the mutual information between ground truth and model predictions while minimizing mutual information between intermediate representations. This method effectively minimizes the impact of outliers in non-independent and identically distributed (non-IID) data on model updates, thereby enhancing the performance of federated SNNs, resulting in enhanced robustness and reduced sensitivity to outliers. We evaluate the proposed SDFIL algorithm across a variety of settings, including different noise levels and varying degrees of system heterogeneity. The experimental results indicate that SDFIL demonstrates superior robustness compared to competing methods and generally achieves an improvement in overall accuracy of 5% to 10%. Additionally, it can achieve up to 7.7\u00d7 higher energy efficiency compared to traditional artificial neural networks (ANNs).", "title_embedding_index": 12171, "title_abs_embedding_index": 12196}, {"title": "LogicJitter: Let LLMs play Logic Games and they will Detect Misinformation", "link_suffix": "/forum?id=mfTM4UdYnC", "link": "https://openreview.net/forum?id=mfTM4UdYnC", "pdf_link": "https://openreview.net/pdf?id=mfTM4UdYnC", "keywords": "llm, misinformation, rule based AI, toxicity", "abstract": "In the face of the growing challenge of online information overload, the ability to accurately differentiate between genuine information and misinformation has become increasingly critical both from an individual and societal point of view. Current methodologies for misinformation detection predominantly rely on supervised approaches, which depend heavily on large labeled datasets. However, these datasets are not only costly and time-consuming to produce, but they are also susceptible to issues such as labeling bias, time leakage, the inherent subjectivity of the task, and domain-specific limitations. In this paper, we aim to overcome the aforementioned challenges by proposing a novel and cost-effective strategy to enhance the logical reasoning capabilities of Large Language Models (LLMs), thereby improving their ability to detect misinformation. Our approach, termed LogicJitter, employs a data augmentation technique during fine-tuning that generates both correct and incorrect statements within rule-based logic games. Moreover, these games are designed to counteract well-known human cognitive biases and logical fallacies. Hence, the primary contributions of this work include demonstrating the effectiveness of logical reasoning pre-training on LLMs and providing an open-source PyTorch package for the automatic generation of correct and incorrect logic-based training data.", "title_embedding_index": 12172, "title_abs_embedding_index": 12197}, {"title": "Language-driven 3D Human Pose Estimation: Grounding Motion from Text Descriptions", "link_suffix": "/forum?id=gVw9gFgAXh", "link": "https://openreview.net/forum?id=gVw9gFgAXh", "pdf_link": "https://openreview.net/pdf?id=gVw9gFgAXh", "keywords": "language-driven 3D human pose estimation, text-motion interaction", "abstract": "In an NBA game scenario, consider the challenge of locating and analyzing the 3D poses of players performing a user-specified action, such as attempting a shot. Traditional 3D human pose estimation (3DHPE) methods often fall short in such complex, multi-person scenes due to their lack of semantic integration and reliance on isolated pose data. To address these limitations, we introduce Language-Driven 3D Human Pose Estimation (L3DHPE), a novel approach that extends 3DHPE to general multi-person contexts by incorporating detailed language descriptions. We present Panoptic-L3D, the first dataset designed for L3DHPE, featuring 3,838 linguistic annotations for 1,476 individuals across 588 videos, with 6,035 masks and 91k frame-level 3D skeleton annotations. Additionally, we propose Cascaded Pose Perception (CPP), a benchmarking method that simultaneously performs language-driven mask segmentation and 3D pose estimation within a unified model. CPP first learns 2D pose information, utilizes a body fusion module to aid in mask segmentation, and employs a mask fusion module to mitigate mask noise before outputting 3D poses. Our extensive evaluation of CPP and existing benchmarks on the Panoptic-L3D dataset demonstrates the necessity of this novel task and dataset for advancing 3DHPE. Our dataset can be accessed athttps://languagedriven3dposeestimation.github.io/.", "title_embedding_index": 12173, "title_abs_embedding_index": 12198}, {"title": "Comparison Visual Instruction Tuning", "link_suffix": "/forum?id=dhuQJseaBA", "link": "https://openreview.net/forum?id=dhuQJseaBA", "pdf_link": "https://openreview.net/pdf?id=dhuQJseaBA", "keywords": "Large Multimodal Models, visual instruction tuning, commonalities and differences", "abstract": "Comparing two images in terms of Commonalities and Differences (CaD) is a fundamental human capability that forms the basis of advanced visual reasoning and interpretation. It is essential for the generation of detailed and contextually relevant descriptions, performing comparative analysis, novelty detection, and making informed decisions based on visual data. However, surprisingly, little attention has been given to these fundamental concepts in the best current mimic of human visual intelligence - Large Multimodal Models (LMMs). We develop and contribute a new two-phase approach CaD-VI for collecting synthetic visual instructions, together with an instruction-following dataset CaD-Inst containing 349K image pairs with CaD instructions collected using CaD-VI. Our approach significantly improves the CaD spotting capabilities in LMMs, advancing the SOTA on a diverse set of related tasks by up to 17.5%. It is also complementary to existing difference-only instruction datasets, allowing automatic targeted refinement of those resources increasing their effectiveness for CaD tuning by up to 10%. Additionally, we propose an evaluation benchmark with 7.5K open-ended QAs to assess the CaD understanding abilities of LMMs.", "title_embedding_index": 12174, "title_abs_embedding_index": 12199}]
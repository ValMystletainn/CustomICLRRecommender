[
    {
        "title": "NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models",
        "link_suffix": "/forum?id=yaOe2xBcLC",
        "link": "https://openreview.net/forum?id=yaOe2xBcLC",
        "pdf_link": "https://openreview.net/pdf?id=yaOe2xBcLC",
        "keywords": "Hallucination Mitigation, Large Language Models, TruthfulQA, Representation Editing, Multiple Choice Question Answering, Attention Heads",
        "abstract": "Hallucinations in Large Language Models (LLMs) remain a major obstacle, particularly in high-stakes applications where factual accuracy is critical. While representation editing and reading methods have made strides in reducing hallucinations, their heavy reliance on specialised tools and training on in-domain samples, makes them difficult to scale and prone to overfitting. This limits their accuracy gains and generalizability to diverse datasets. This paper presents a lightweight method, Norm Voting (NoVo), which harnesses the untapped potential of attention head norms to dramatically enhance factual accuracy in zero-shot multiple-choice questions (MCQs). NoVo begins by automatically selecting truth-correlated head norms with an efficient, inference-only algorithm using only 30 random samples, allowing NoVo to effortlessly scale to diverse datasets. Afterwards, selected head norms are employed in a simple voting algorithm, which yields significant gains in prediction accuracy. On TruthfulQA MC1, NoVo surpasses the current state-of-the-art and all previous methods by an astounding margin---at least 19 accuracy points. NoVo demonstrates exceptional generalization to 20 diverse datasets, with significant gains in over 90% of them, far exceeding all current representation editing and reading methods. NoVo also reveals promising gains to finetuning strategies and building textual adversarial defence. NoVo's effectiveness with head norms opens new frontiers in LLM interpretability, robustness and reliability."
    },
    {
        "title": "Audio-Agent: Leveraging LLMs For Audio Generation, Editing and Composition",
        "link_suffix": "/forum?id=J8yH8ontdq",
        "link": "https://openreview.net/forum?id=J8yH8ontdq",
        "pdf_link": "https://openreview.net/pdf?id=J8yH8ontdq",
        "keywords": "Agent, Audio Generation, Large language model, Diffusion Model",
        "abstract": "We introduce Audio-Agent, a multimodal framework for audio generation, editing and composition based on text or video inputs. Conventional approaches for text-to-audio (TTA) tasks often make single-pass inferences from text descriptions. While straightforward, this design struggles to produce high-quality audio when given complex text conditions. In our method, we utilize a pre-trained TTA diffusion network as the audio generation agent to work in tandem with GPT-4, which decomposes the text condition into atomic, specific instructions, and calls the agent for audio generation. Consequently, Audio-Agent generates high-quality audio that is closely aligned with the provided text or video while also supporting variable-length generation. For video-to-audio (VTA) tasks, most existing methods require training a timestamp detector to synchronize video events with generated audio, a process that can be tedious and time-consuming. We propose a simpler approach by fine-tuning a pre-trained Large Language Model (LLM), e.g., Gemma2-2B-it, to obtain both semantic and temporal conditions to bridge video and audio modality. Thus our framework provides a comprehensive solution for both TTA and VTA tasks without substantial computational overhead in training."
    },
    {
        "title": "BEARD: Benchmarking the Adversarial Robustness for Dataset Distillation",
        "link_suffix": "/forum?id=QjNHmfA3IB",
        "link": "https://openreview.net/forum?id=QjNHmfA3IB",
        "pdf_link": "https://openreview.net/pdf?id=QjNHmfA3IB",
        "keywords": "Dataset distillation, benchmark, adversarial robustness, dataset condensation, adversarial game framework",
        "abstract": "Dataset Distillation (DD) is an emerging technique that compresses large-scale datasets into significantly smaller synthesized datasets while preserving high test performance and enabling the efficient training of large models. However, current research primarily focuses on enhancing evaluation accuracy under limited compression ratios, often overlooking critical security concerns such as adversarial robustness. A key challenge in evaluating this robustness lies in the complex interactions between distillation methods, model architectures, and adversarial attack strategies, which complicate standardized assessments. To address this, we introduce BEARD, an open and unified benchmark designed to systematically assess the adversarial robustness of DD methods, including DM, IDM, and BACON. BEARD encompasses a variety of adversarial attacks (e.g., FGSM, PGD, C&W) on distilled datasets like CIFAR-10/100 and TinyImageNet. Utilizing an adversarial game framework, it introduces three key metrics: Robustness Ratio (RR), Attack Efficiency Ratio (AE), and Comprehensive Robustness-Efficiency Index (CREI). Our analysis includes unified benchmarks, various Images Per Class (IPC) settings, and the effects of adversarial training. Results are available on the BEARD Leaderboard, along with a library providing model and dataset pools to support reproducible research. Access the code at BEARD."
    },
    {
        "title": "CPSample: Classifier Protected Sampling for Guarding Training Data During Diffusion",
        "link_suffix": "/forum?id=LIBLIlk5M9",
        "link": "https://openreview.net/forum?id=LIBLIlk5M9",
        "pdf_link": "https://openreview.net/pdf?id=LIBLIlk5M9",
        "keywords": "diffusion, privacy, data protection, mode collapse",
        "abstract": "Diffusion models have a tendency to exactly replicate their training data, especially when trained on small datasets.  Most prior work has sought to mitigate this problem by imposing differential privacy constraints or masking parts of the training data, resulting in a notable substantial decrease in image quality. We present CPSample, a method that modifies the sampling process to prevent training data replication while preserving image quality. CPSample utilizes a classifier that is trained to overfit on random binary labels attached to the training data. CPSample then uses classifier guidance to steer the generation process away from the set of points that can be classified with high certainty, a set that includes the training data. CPSample achieves FID scores of 4.97 and 2.97 on CIFAR-10 and CelebA-64, respectively, without producing exact replicates of the training data.  Unlike prior methods intended to guard the training images, CPSample only requires training a classifier rather than retraining a diffusion model, which is computationally cheaper. Moreover, our technique provides diffusion models with greater robustness against membership inference attacks, wherein an adversary attempts to discern which images were in the model's training dataset. We show that CPSample behaves like a built-in rejection sampler, and we demonstrate its capabilities to prevent mode collapse in Stable Diffusion."
    },
    {
        "title": "Fusion-X: Advancing LLM Ability with Adaptive Heterogeneous Model Integration",
        "link_suffix": "/forum?id=omDJBxoPUh",
        "link": "https://openreview.net/forum?id=omDJBxoPUh",
        "pdf_link": "https://openreview.net/pdf?id=omDJBxoPUh",
        "keywords": "Model integration, Large language models, Knowledge Interference",
        "abstract": "Training LLMs presents significant challenges, including data access, privacy concerns, the complexity of training schedules, and limited resources.\nTherefore, a more accessible approach involves integrating existing LLMs, each tailored for different tasks or trained on distinct datasets, into an advanced and robust model with enhanced capabilities.Popular methods like ensemble and weight merging require substantial memory and struggle to adapt to changing data environments.\nRecent efforts have aimed to transfer only the collective knowledge of multiple LLMs to the target LLM. However, the resulting fused model often suffers from interference and performance degradation due to a lack of flexibility in the fusion process, including candidate selection and training pipeline. To address these issues, we propose a dynamic fusion framework to adaptively select LLMs for integration. \nSpecifically, to diminish knowledge interference during LLM fusion, we introduce an adaptive selection network. It is a learnable mechanism that explicitly evaluates and selects the best-performing source LLMs based on their rewards, allowing us to fuse knowledge from a flexible number model candidates. \nTo improve the knowledge fusion process, we propose a dynamic weighted fusion strategy that considers the intrinsic characteristics of candidate LLMs during fusion. \nAdditionally, we incorporate a feedback-driven loss function to prevent the selector from converging to a state where it consistently assigns the same candidates. \nOur experiments demonstrate that our method consistently enhances model performance across multiple benchmarks, yielding an improvement of up to 2.2%. Additionally, our approach achieves a notable reduction in knowledge interference, showing up to 50% decrease compared to existing work."
    },
    {
        "title": "Policy Consistency in Multi-Agent Reinforcement Learning with Mixed Reward",
        "link_suffix": "/forum?id=GRXlkYg7Nz",
        "link": "https://openreview.net/forum?id=GRXlkYg7Nz",
        "pdf_link": "https://openreview.net/pdf?id=GRXlkYg7Nz",
        "keywords": "Multi-agent System, Reinforcement Learning, Sparse Reward, Policy Consistency, Individual Reward",
        "abstract": "The sparsity of team rewards poses a significant challenge that hinders the effective learning of optimal team policies in cooperative multi-agent reinforcement learning. One common approach to mitigate this issue involves augmenting sparse rewards with individual rewards to guide policy training. However, a significant drawback of such approaches is that modifying the reward function can potentially alter the optimal policy. To tackle this challenge, we propose a novel multi-agent policy optimization approach that ensures consistency between the mixed policy (learned from a combination of individual and team rewards) and the team policy (based solely on team rewards), through a new policy consistency constraint that aligns the returns of both policies in policy optimization model. We further develop an iterated policy optimization procedure to solve the formulated problem, deriving an approximate optimization objective for each iteration of the mixed and team policies. Experimental evaluation conducted in the StarCraft II Multi-Agent Challenge Environment (SMAC), Multi-Agent Particle Environment (MPE), and Google Research Football (GRF) environments demonstrate that our proposed approach effectively addresses the policy inconsistency problem, ${\\it i.e.}$, it consistently outperforms strong baseline methods."
    },
    {
        "title": "SubZero: Random Subspace Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning",
        "link_suffix": "/forum?id=FK6T0U4Mg1",
        "link": "https://openreview.net/forum?id=FK6T0U4Mg1",
        "pdf_link": "https://openreview.net/pdf?id=FK6T0U4Mg1",
        "keywords": "Zeroth-order optimization, Large Language Models (LLMs), fine-tuning, random subspace",
        "abstract": "Fine-tuning Large Language Models (LLMs) has proven effective for a variety of downstream tasks. However, as LLMs grow in size, the memory demands for backpropagation become increasingly prohibitive. Zeroth-order (ZO) optimization methods offer a memory-efficient alternative by using forward passes to estimate gradients, but the variance of gradient estimates typically scales linearly with the model's parameter dimension\u2014a significant issue for LLMs. In this paper, we propose the random Subspace Zeroth-order (SubZero) optimization to address the challenges posed by LLMs' high dimensionality. We introduce a low-rank perturbation tailored for LLMs that significantly reduces memory consumption while improving training performance.  Additionally, we prove  that our gradient estimation closely approximates the backpropagation gradient, exhibits lower variance than traditional ZO methods, and ensures convergence when combined with SGD. Experimental results show that SubZero enhances fine-tuning performance and achieves faster convergence compared to standard ZO approaches like MeZO across various language modeling tasks. The source code will be released publicly."
    },
    {
        "title": "CodeCipher: Learning To Obfuscate Source Code Against LLMs",
        "link_suffix": "/forum?id=bIup4xWg9K",
        "link": "https://openreview.net/forum?id=bIup4xWg9K",
        "pdf_link": "https://openreview.net/pdf?id=bIup4xWg9K",
        "keywords": "Code obfuscation; LLM privacy; Large Language Models of Code",
        "abstract": "While code large language models have made significant strides in AI-assisted coding tasks, there are growing concerns about privacy challenges. The user code is transparent to the cloud LLM service provider, inducing risks of unauthorized training, reading, and execution of the user code.  In this paper, we propose CodeCipher, a novel method that perturbs privacy from code while preserving the original response from LLMs. CodeCipher transforms the LLM's embedding matrix so that each row corresponds to a different word in the original matrix, forming a token-to-token confusion mapping for obfuscating source code. The new embedding matrix is optimized through minimizing the task-specific loss function. To tackle the challenge from the discrete and sparse nature of word vector spaces, CodeCipher adopts a discrete optimization strategy that aligns the updated vector to the nearest valid token in the vocabulary before each gradient update. We demonstrate the effectiveness of our approach on three AI-assisted coding tasks including code completion, summarization, and translation. Results show that our model successfully confuses the privacy in source code while preserving the original LLM's performance."
    },
    {
        "title": "DB-GPT-Hub: Towards Open Benchmarking Text-to-SQL Empowered by Large Language Models",
        "link_suffix": "/forum?id=NmILZXKcOi",
        "link": "https://openreview.net/forum?id=NmILZXKcOi",
        "pdf_link": "https://openreview.net/pdf?id=NmILZXKcOi",
        "keywords": "text-to-sql, supervised finetuning, LLM, DB-GPT",
        "abstract": "Large language models (LLMs) becomes the dominant paradigm for the challenging task of text-to-SQL. LLM-empowered text-to-SQL methods are typically categorized into prompting-based and tuning approaches. Compared to prompting-based methods, benchmarking fine-tuned LLMs for text-to-SQL is important yet under-explored, partially attributed to the prohibitively high computational cost. In this paper, we present DB-GPT-Hub, an open benchmark suite for LLM-empowered text-to-SQL, which primarily focuses on tuning LLMs at large scales. The proposed benchmark consists of: 1. a standardized and comprehensive evaluation of text-to-SQL tasks by fine-tuning medium to large-sized open LLMs; 2. a modularized and easy-to-extend codebase with mainstream LLMs and experimental scenarios supported, which prioritizes fine-tuning methods but can be easily extended to prompt-based setting. Our work investigates the potential gains and the performance boundaries of tuning approaches, compared to prompting approaches and explores optimal solutions tailored to specific scenarios. We hope \\textit{DB-GPT-Hub}, along with these findings, enables further research and broad applications that would otherwise be difficult owing to the absence of a dedicated open benchmark. The project code has been released anonymously athttps://github.com/anonymity-360/DB-GPT-Hub."
    },
    {
        "title": "Tuning Frequency Bias of State Space Models",
        "link_suffix": "/forum?id=wkHcXDv7cv",
        "link": "https://openreview.net/forum?id=wkHcXDv7cv",
        "pdf_link": "https://openreview.net/pdf?id=wkHcXDv7cv",
        "keywords": "state-space models, sequence models, Long-Range Arena, frequency bias",
        "abstract": "State space models (SSMs) leverage linear, time-invariant (LTI) systems to effectively learn sequences with long-range dependencies. By analyzing the transfer functions of LTI systems, we find that SSMs exhibit an implicit bias toward capturing low-frequency components more effectively than high-frequency ones. This behavior aligns with the broader notion of frequency bias in deep learning model training. We show that the initialization of an SSM assigns it an innate frequency bias and that training the model in a conventional way does not alter this bias. Based on our theory, we propose two mechanisms to tune frequency bias: either by scaling the initialization to tune the inborn frequency bias; or by applying a Sobolev-norm-based filter to adjust the sensitivity of the gradients to high-frequency inputs, which allows us to change the frequency bias via training. Using an image-denoising task, we empirically show that we can strengthen, weaken, or even reverse the frequency bias using both mechanisms. By tuning the frequency bias, we can also improve SSMs' performance on learning long-range sequences, averaging an $88.26\\%$ accuracy on the Long-Range Arena (LRA) benchmark tasks."
    },
    {
        "title": "Leveraging Flatness to Improve Information-Theoretic Generalization Bounds for SGD",
        "link_suffix": "/forum?id=pSdE7PIA64",
        "link": "https://openreview.net/forum?id=pSdE7PIA64",
        "pdf_link": "https://openreview.net/pdf?id=pSdE7PIA64",
        "keywords": "information theory; implicit bias; deep learning theory; convex optimization; learning theory",
        "abstract": "Information-theoretic generalization bounds have been used to study the generalization of learning algorithms. These bounds are intrinsically data- and algorithm-dependent so that one can exploit the properties of data and algorithm to derive tighter bounds. However, we observe such algorithm dependence is still inadequate in existing information-theoretic bounds for SGD because they have not adequately leveraged the algorithmic bias toward flat minima of SGD. Since the flatness of minima given by SGD is crucial for SGD's generalization, the bounds fail to capture the improved generalization under better flatness and are also numerically loose. This paper derives a more flatness-leveraged information-theoretic bound for the flatness-favoring SGD. The bound indicates that the learned models generalize better if the large-variance directions of the final weight covariance have small local curvatures in the loss landscape. Experiments on deep neural networks show that our bound not only correctly reflects the better generalization when flatness is improved, but is also numerically tighter by being only a few percentages looser.  This is achieved by a technique called \"omniscient trajectory.\" When applied to Gradient Descent on convex-Lipschitz-Bounded (CLB) problems, it yields an $O(1/\\sqrt{n})$ minimax rate for excess risks, which has been shown to be impossible for representative existing information-theoretic bounds."
    },
    {
        "title": "Prompt Distribution Matters: Tuning Visual Prompt Through Semantic Metric Guidance",
        "link_suffix": "/forum?id=NWH2pdKu2I",
        "link": "https://openreview.net/forum?id=NWH2pdKu2I",
        "pdf_link": "https://openreview.net/pdf?id=NWH2pdKu2I",
        "keywords": "visual prompt tuning, parameter-efficient fine-tuning, metric learning",
        "abstract": "Visual Prompt Tuning (VPT) has become a promising solution for Parameter-Efficient Fine-Tuning (PEFT) of pre-trained Vision Transformer (ViT) models on downstream vision tasks. VPT partially fine-tunes a set of learnable tokens while keeping the majority of the model parameters frozen. Recent research has explored modifying the connection structures of the prompts. However, the fundamental correlation and distribution between the prompts and image tokens remain unexplored. In this paper, we leverage \\textit{metric learning} techniques to investigate how the distribution of prompts affects fine-tuning and transfer learning performance. Specifically, we propose a novel framework, \\textbf{D}istribution \\textbf{A}ware \\textbf{V}isual \\textbf{P}rompt Tuning (DA-VPT), to guide the distributions of the prompts by learning the distance metric from their class-related semantic data. Our method demonstrates that the prompts can serve as an effective bridge to share semantic information between image patches and the class token. We extensively evaluated our approach on popular benchmarks in both recognition and segmentation tasks. The results show the effectiveness of our proposed method and offer a new direction for PEFT optimization in vision transformers. We demonstrate that our approach enables more effective and efficient fine-tuning of ViT models by leveraging semantic information to guide the learning of the prompts, leading to improved performance on various downstream vision tasks."
    },
    {
        "title": "NGTTA: Non-parametric Geometry-driven Test Time Adaption for 3D Point Cloud Segmentation",
        "link_suffix": "/forum?id=bdHjLCcMSP",
        "link": "https://openreview.net/forum?id=bdHjLCcMSP",
        "pdf_link": "https://openreview.net/pdf?id=bdHjLCcMSP",
        "keywords": "Point Cloud Segmentation, Test Time Adaption",
        "abstract": "Previous Test Time Adaption (TTA) methods usually suffer from training collapse when they are transferred to complex 3D scenes for point cloud segmentation due to the significant domain gap between the source and target data.\n To solve this issue, we propose NGTTA, a stable test time adaption method guided by non-parametric geometry.  In NGTTA, we leverage the distribution of non-parametric geometry on target data as an \u201cintermediate domain\u201d to reduce the domain gap and guide the stable learning of the source model on target data. \n Specifically, we use the source domain model and a non-parametric geometric model to extract the embedding features and geometric features of the point cloud, respectively. Then, a category-balance sampler is designed to filter easy samples and hard samples in the input data to address the class imbalance issue in semantic segmentation. Inspired by previous work, we use easy samples for entropy minimization loss and pseudo-label prediction to fine-tune the source domain model. The difference is that we refine the pseudo labels not only by considering the soft voting among their nearest neighbors in the model embedding feature space but also in the geometric space, which can prevent the accumulation of errors caused by model feature shifts.  Furthermore, we believe that hard samples can effectively represent the distribution differences between the source domain and the target domain. Therefore, we propose to distill the geometric features of hard samples into the source domain model in the early stages of training to quickly converge to an \"intermediate domain\" that is similar to the target domain. By taking advantage of the ability of the non-parametric geometric to represent the underlying manifolds of the target data, our method efficiently reduces the difficulty of the domain adaption. We conduct the main experiments on the more challenge \\textbf{\\textit{sim-to-real}} benchmark about synthetic dataset 3DFRONT and the real-world datasets ScanNet and S3DIS for 3D segmentation task. Results show that our method can efficiently improve the mIOU by over \\textbf{3%} on 3DFRONT$\\rightarrow$ ScanNet and \\textbf{7%} on 3DFRONT$\\rightarrow$ S3DIS."
    },
    {
        "title": "BTBS-LNS: Binarized-Tightening, Branch and Search on Learning LNS Policies for MIP",
        "link_suffix": "/forum?id=siHHqDDzvS",
        "link": "https://openreview.net/forum?id=siHHqDDzvS",
        "pdf_link": "https://openreview.net/pdf?id=siHHqDDzvS",
        "keywords": "Large neighborhood search, Reinforcement learning, Bound tightening",
        "abstract": "Learning to solve large-scale Mixed Integer Program (MIP) problems is an emerging research topic, and Policy learning-based Large Neighborhood Search (LNS) has been a popular paradigm. However, the explored space of LNS policy is often limited even in the training phase, making the learned policy sometimes wrongly fix some potentially important variables early in the search, leading to local optimum in some cases. Moreover, many methods only assume binary variables to deal with. We present a practical approach, termed Binarized-Tightening Branch-and-Search for Large Neighborhood Search (BTBS-LNS). It comprises of three key techniques: 1) the ``Binarized Tightening\" technique for integer variables to handle their wide range by binary encoding and bound tightening; 2) an attention-based tripartite graph to capture global correlations among variables and constraints for an MIP instance; 3) an extra branching network as a global view, to identify and optimize wrongly-fixed backdoor variables at each search step. Experiments show its superior performance over the open-source solver SCIP and LNS baselines. Moreover, it performs competitively with, and sometimes  better than the commercial solver Gurobi (v9.5.0), especially on MIPLIB2017 benchmark chosen by Hans Mittelmann, where our method can deliver 10% better primal gaps compared with Gurobi in a 300s cut-off time."
    },
    {
        "title": "Evidence from the Synthetic Laboratory: Language Models as Auction Participants",
        "link_suffix": "/forum?id=XZ71GHf8aB",
        "link": "https://openreview.net/forum?id=XZ71GHf8aB",
        "pdf_link": "https://openreview.net/pdf?id=XZ71GHf8aB",
        "keywords": "Language Model, Auction, Behavioral Economics, learning",
        "abstract": "This paper investigates the auction behavior of simulated AI agents (large language models, or LLMs), validating a novel synthetic data-generating process to help discipline the study and design of auctions. We begin by benchmarking these LLM agents against established experimental results that study agreement or departure between realized economic behavior and predictions from theory; i.e., revenue equivalence between first-price and second-price auctions and improved play in obviously strategy-proof auctions. We find that when LLM-based agents diverge from the predictions of theory, they do so in a way that agrees with behavioral traits observed in the existing experimental economics literature (e.g., risk aversion, and weak play in 'complicated' auctions). Our results also suggest that LLMs are bad at playing auctions 'out of the box' but can improve their play when given the opportunity to learn. This learning is robust to various prompt specifications and holds across a variety of settings. We run 1,000+ auctions for less than $100 with GPT-4o and GPT-4, and develop a framework flexible enough to run auction experiments with any LLM model and a wide range of auction design specifications."
    },
    {
        "title": "Incorporating continuous dependence implies better generalization ability",
        "link_suffix": "/forum?id=7xJgPtLHfm",
        "link": "https://openreview.net/forum?id=7xJgPtLHfm",
        "pdf_link": "https://openreview.net/pdf?id=7xJgPtLHfm",
        "keywords": "Generalization, Physics Informed Neural Network, Continuous Dependence, Ordinary Differential Equations",
        "abstract": "When applying deep-learning-based solvers to differential equations, a key challenge is how to improve their generalization ability, so that the pre-trained models could be easily adapted to new scenarios of interest. In this paper, inspired by the well-known mathematical statements on the continuous dependence of solutions to ordinary differential equations on initial values and parameters, we make a non-trivial extension of the physics-informed neural networks by incorporating additional information on the continuous dependence of solutions (abbreviated as cd-PINN). Our cd-PINN integrates the advantages of neural operators and Meta-PINN, requiring only few labeled data while enabling solving ordinary differential equations with respect to new initial values and parameters in a fast and accurate way without fine-tuning. As demonstrated through novel examples like the Logistic model, the Lotka-Volterra model as well as damped harmonic oscillators, the accuracy of cd-PINN under those untrained conditions is usually 1-3 orders of magnitude higher than PINN. Meanwhile, the GPU time cost for training in the two approaches is comparable. Therefore, we expect our cd-PINN would be particularly useful in improving the efficiency and accuracy of deep-learning-based solvers for differential equations."
    },
    {
        "title": "Extending Mercer's expansion to indefinite and asymmetric kernels",
        "link_suffix": "/forum?id=jZwwMxG8PO",
        "link": "https://openreview.net/forum?id=jZwwMxG8PO",
        "pdf_link": "https://openreview.net/pdf?id=jZwwMxG8PO",
        "keywords": "Kernel methods, Mercer's expansion, Indefinite kernels, Convergence behavior.",
        "abstract": "Mercer's expansion and Mercer's theorem are cornerstone results in kernel theory. While the classical Mercer's theorem only considers continuous symmetric positive definite kernels, analogous expansions are effective in practice for indefinite and asymmetric kernels. In this paper we extend Mercer's expansion to continuous kernels, providing a rigorous theoretical underpinning for indefinite and asymmetric kernels. We begin by demonstrating that Mercer's expansion may not be pointwise convergent for continuous indefinite kernels, before proving that the expansion of continuous kernels with bounded variation uniformly in each variable separably converges pointwise almost everywhere, almost uniformly, and unconditionally almost everywhere. We also describe an algorithm for computing Mercer's expansion for general kernels and give new decay bounds on its terms."
    },
    {
        "title": "Event-Customized Image Generation",
        "link_suffix": "/forum?id=88Qm4fGWzX",
        "link": "https://openreview.net/forum?id=88Qm4fGWzX",
        "pdf_link": "https://openreview.net/pdf?id=88Qm4fGWzX",
        "keywords": "Customized Image Generation, Diffusion Model",
        "abstract": "Customized Image Generation, generating customized images with user-specified concepts, has raised significant attention due to its creativity and novelty. With impressive progress achieved in subject customization, some pioneer works further explored the customization of action and interaction beyond entity (i.e., human, animal, and object) appearance. However, these approaches only focus on basic actions and interactions between two entities, and their effects are limited by insufficient ''exactly same'' reference images. To extend customized image generation to more complex scenes for general real-world applications, we propose a new task: event-customized image generation. Given a single reference image, we define the ''event'' as all specific actions, poses, relations, or interactions between different entities in the scene. This task aims at accurately capturing the complex event and generating customized images with various target entities. To solve this task, we proposed a novel training-free event customization method: FreeEvent. Specifically, FreeEvent introduces two extra paths alongside the general diffusion denoising process: 1) Entity switching path: it applies cross-attention guidance and regulation for target entity generation. 2) Event transferring path: it injects the spatial feature and self-attention maps from the reference image to the target image for event generation. To further facilitate this new task, we collected two evaluation benchmarks: SWiG-Event and Real-Event. Extensive experiments and ablations have demonstrated the effectiveness of FreeEvent."
    },
    {
        "title": "A Statistical Approach for Controlled Training Data Detection",
        "link_suffix": "/forum?id=XAN8G0rvoB",
        "link": "https://openreview.net/forum?id=XAN8G0rvoB",
        "pdf_link": "https://openreview.net/pdf?id=XAN8G0rvoB",
        "keywords": "Large language models, Training data detection, Knockoffs",
        "abstract": "Detecting training data for large language models (LLMs) is attracting growing attention, particularly in applications that require high reliability. While numerous endeavors have been made to tackle this issue, ensuring controlled results often remains overlooked. To fill this gap, we proposeKnockoff Inference-basedTraining dataDetector (KTD), a novel method that achieve rigorous false discovery rate (FDR) control in training data detection. Specifically, KTD generates synthetic knockoff samples that seamlessly replace original data points without compromising contextual integrity. A novel knockoff statistic, which incorporates multiple knockoff draws, is then calculated to ensure FDR control while maintaining high power. Our theoretical analysis demonstrates KTD's asymptotic optimality in terms of FDR control and power. Empirical experiments on real-world datasets such as WikiMIA, XSum and Real Time BBC News further validate KTD's superior performance compared to existing methods."
    },
    {
        "title": "Discriminating image representations with principal distortions",
        "link_suffix": "/forum?id=ugXGFCS6HK",
        "link": "https://openreview.net/forum?id=ugXGFCS6HK",
        "pdf_link": "https://openreview.net/pdf?id=ugXGFCS6HK",
        "keywords": "representational similarity metric; Fisher information; information geometry; perception",
        "abstract": "Image representations (artificial or biological) are often compared in terms of their global geometry; however, representations with similar global structure can have strikingly different local geometries. Here, we propose a framework for comparing a set of image representations in terms of their local geometries. We quantify the local geometry of a representation using the Fisher information matrix, a standard statistical tool for characterizing the sensitivity to local stimulus distortions, and use this as a substrate for a metric on the local geometry in the vicinity of a base image. This metric may then be used to optimally differentiate a set of models, by finding a pair of \"principal distortions\" that maximize the variance of the models under this metric. We use this framework to compare a set of simple models of the early visual system, identifying a novel set of image distortions that allow immediate comparison of the models by visual inspection. In a second example, we apply our method to a set of deep neural network models and reveal differences in the local geometry that arise due to architecture and training types. These examples highlight how our framework can be used to probe for informative differences in local sensitivities between complex computational models, and suggest how it could be used to compare model representations with human perception."
    },
    {
        "title": "CtrlA: Adaptive Retrieval-Augmented Generation via Inherent Control",
        "link_suffix": "/forum?id=QYvtX2XA8p",
        "link": "https://openreview.net/forum?id=QYvtX2XA8p",
        "pdf_link": "https://openreview.net/pdf?id=QYvtX2XA8p",
        "keywords": "Retrieval-Augmented Generation, Large Language Model",
        "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising solution for mitigating hallucinations of large language models (LLMs) with retrieved external knowledge. Adaptive RAG enhances this approach by enabling dynamic retrieval during generation, activating retrieval only when the query exceeds LLM's internal knowledge. Existing methods primarily focus on detecting LLM's confidence via statistical uncertainty. Instead, we present the first attempts to solve adaptive RAG from a representation perspective and develop an inherent control-based framework, termed CtrlA. Specifically, we extract the features that represent the honesty and confidence directions of LLM and adopt them to control LLM behavior and guide retrieval timing decisions. We also design a simple yet effective query formulation strategy to support adaptive retrieval. Experiments show that CtrlA is superior to existing adaptive RAG methods on a diverse set of tasks, the honesty steering can effectively make LLMs more honest and confidence monitoring is a promising indicator of retrieval trigger. Our anonymous codes are submitted with the paper and will be publicly available."
    },
    {
        "title": "Maximum Coverage in Turnstile Streams with Applications to Fingerprinting Measures",
        "link_suffix": "/forum?id=yfZJdCijo6",
        "link": "https://openreview.net/forum?id=yfZJdCijo6",
        "pdf_link": "https://openreview.net/pdf?id=yfZJdCijo6",
        "keywords": "maximum coverage, turnstile streams, sketching",
        "abstract": "In the maximum coverage problem we aim to choose at most $k$ subsets such that the number of distinct items covered by the subsets is maximized. The input can be formalized by an $n \\times d$ matrix $A$ where there are $n$ items in the universe and $d$ input subsets. $A_{ij}$ is nonzero if item $i$ is in subset $j$ and is $0$ otherwise. To our knowledge, we are the first to create a linear sketch to solve maximum coverage which can lead to large runtime improvements and allow for implementation in distributed and streaming environments. We specifically focus on the application to turnstile streams which allows deletions. Here, the updates are of the form $(i,j,\\pm 1)$ which performs $A_{ij} = A_{ij} \\pm 1$. Previous work mainly considers the more restrictive set-arrival model where each update reveals an entire column of $A$ or the insertion-only model which does not allow deletions. We design an algorithm with an $\\tilde{O}(d/\\epsilon^3)$ space bound, which is nearly optimal for constant $k$. We then turn to fingerprinting for risk measurement where the aim is to monitor which $k$ columns of an input $n \\times d$ dataset poses the highest re-indentification risk. Our maximum coverage sketch directly enables a solution of targeted fingerprinting for risk measurement. Furthermore, we give an independent result of independent interest: a sketch related to the complement of $F_k$ for $k \\geq 2$. We use this sketch to create a streaming algorithm for general fingerprinting for risk management. Empirical evaluation confirms the practicality of our fingerprinting algorithms and shows a speedup of up to $210$x over prior work. We also demonstrate the use of our general fingerprinting algorithm as a dimensionality reduction technique, facilitating enhanced feature selection efficiency."
    },
    {
        "title": "Q-Supervised Contrastive Representation: A State Decoupling Framework for Safe Offline Reinforcement Learning",
        "link_suffix": "/forum?id=qkVsGBff9s",
        "link": "https://openreview.net/forum?id=qkVsGBff9s",
        "pdf_link": "https://openreview.net/pdf?id=qkVsGBff9s",
        "keywords": "Safe Reinforcement Learning, Offline Reinforcement Learning, Representation Learning, Contrastive Learning, Self-Supervised Learning",
        "abstract": "Safe offline reinforcement learning (RL), which aims to learn the safety-guaranteed policy without risky online interaction with environments, has attracted growing recent attention for safety-critical scenarios. However, existing approaches encounter out-of-distribution problems during the testing phase, which can result in potentially unsafe outcomes. This issue arises due to the infinite possible combinations of reward-related and cost-related states. In this work, we proposeState Decoupling with Q-supervised Contrastive representation(SDQC), a novel framework that decouples the global observations into reward- and cost-related representations for decision-making, thereby improving the generalization capability for unfamiliar global observations.\nCompared with the classical representation learning methods, which typically require model-based estimation (e.g., bisimulation), we theoretically prove that our Q-supervised method generates a coarser representation while preserving the optimal policy, resulting in improved generalization performance. Experiments on DSRL benchmark problems provide compelling evidence that SDQC surpasses other baseline algorithms, especially for its exceptional ability to achieve almost zero violations in more than half of the tasks, \nwhile the state-of-the-art algorithm can only achieve the same level of success in a quarter of the tasks. Further, we demonstrate that SDQC possesses superior generalization ability when confronted with unseen environments."
    },
    {
        "title": "PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions",
        "link_suffix": "/forum?id=xuQSp75HmP",
        "link": "https://openreview.net/forum?id=xuQSp75HmP",
        "pdf_link": "https://openreview.net/pdf?id=xuQSp75HmP",
        "keywords": "Diffusion Model, Image Generation, Image-to-Image",
        "abstract": "This paper presents a versatile image-to-image visual assistant, PixWizard, designed for image generation, manipulation, and translation based on free-from language instructions. To this end, we tackle a variety of vision tasks into a unified image-text-to-image generation framework and curate an Omni Pixel-to-Pixel Instruction-Tuning Dataset. By constructing detailed instruction templates in natural language, we comprehensively include a large set of diverse vision tasks such as text-to-image generation, image restoration, image grounding, dense image prediction, image editing, controllable generation, inpainting/outpainting, and more. Furthermore, we adopt Diffusion Transformers (DiT) as our foundation model and extend its capabilities with a flexible any resolution mechanism, enabling the model to dynamically process images based on the aspect ratio of the input, closely aligning with human perceptual processes. The model also incorporates structure-aware and semantic-aware guidance to facilitate effective fusion of information from the input image. Our experiments demonstrate that PixWizard not only shows impressive generative and understanding  abilities for images with diverse resolutions but also exhibits promising generalization capabilities with unseen tasks and human instructions."
    },
    {
        "title": "SG-I2V: Self-Guided Trajectory Control in Image-to-Video Generation",
        "link_suffix": "/forum?id=uQjySppU9x",
        "link": "https://openreview.net/forum?id=uQjySppU9x",
        "pdf_link": "https://openreview.net/pdf?id=uQjySppU9x",
        "keywords": "zero-shot, tuning-free, self-guided, image-to-video diffusion, trajectory control",
        "abstract": "Methods for image-to-video generation have achieved impressive, photo-realistic quality. However, adjusting specific elements in generated videos, such as object motion or camera movement, is often a tedious process of trial and error, e.g., involving re-generating videos with different random seeds. Recent techniques address this issue by fine-tuning a pre-trained model to follow conditioning signals, such as bounding boxes or point trajectories. Yet, this fine-tuning procedure can be computationally expensive, and it requires datasets with annotated object motion, which can be difficult to procure. Here, we propose SG-I2V, a framework for controllable image-to-video generation that is self-guided\u2014i.e., offering zero-shot control using a pre-trained image-to-video diffusion model without fine-tuning or external guidance. Our zero-shot method outperforms unsupervised baselines while being competitive with supervised models in terms of visual quality and motion fidelity. Additional video results are available on our project page:https://sgi2v-paper.github.io/"
    }
]
[
    {
        "title": "Direct Alignment of Language Models via Quality-Aware Self-Refinement",
        "link_suffix": "/forum?id=tcdbBbHHPo",
        "link": "https://openreview.net/forum?id=tcdbBbHHPo",
        "pdf_link": "https://openreview.net/pdf?id=tcdbBbHHPo",
        "keywords": "Reinforcement Learning; Language Model",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been commonly used to align the behaviors of Large Language Models (LLMs) with human preferences. Recently, a popular alternative is Direct Policy Optimization (DPO), which replaces an LLM-based reward model with the policy itself, thus obviating the need for extra memory and training time to learn the reward model. However, DPO does not consider the relative qualities of the positive and negative responses, and can lead to sub-optimal training outcomes.To alleviate this problem, we investigate the use of intrinsic knowledge within the on-the-fly fine-tuning LLM to obtain relative qualities and help to refine the loss function. Specifically, we leverage the knowledge of the LLM to design a refinement function to estimate the quality of both the positive and negative responses. We show that the constructed refinement function can help self-refine the loss function under mild assumptions.  The refinement function  is integrated  into DPO and its variant Identity Policy Optimization (IPO).Experiments across various evaluators indicate that they can improve the performance of the fine-tuned models over DPO and IPO."
    },
    {
        "title": "MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network",
        "link_suffix": "/forum?id=Tepaft7632",
        "link": "https://openreview.net/forum?id=Tepaft7632",
        "pdf_link": "https://openreview.net/pdf?id=Tepaft7632",
        "keywords": "Anomaly Detection, Model-agnostic, Self-supervised Clustering, Hypersphere Collapse, One-directed Adaptive loss",
        "abstract": "In this paper, we propose MADCluster, a novel model-agnostic anomaly detection framework utilizing self-supervised clustering. MADCluster is applicable to various deep learning architectures and addresses the 'hypersphere collapse' problem inherent in existing deep learning-based anomaly detection methods. The core idea is to cluster normal pattern data into a `single cluster' while simultaneously learning the cluster center and mapping data close to this center. Also, to improve expressiveness and enable effective single clustering, we propose a new 'One-directed Adaptive loss'. The optimization of this loss is mathematically proven. MADCluster consists of three main components: Base Embedder capturing high-dimensional temporal dynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous center updates. Its model-agnostic characteristics are achieved by applying various architectures to the Base Embedder. Experiments on four time series benchmark datasets demonstrate that applying MADCluster improves the overall performance of comparative models. In conclusion, the compatibility of MADCluster shows potential for enhancing model performance across various architectures."
    },
    {
        "title": "TopGQ: Post-Training Quantization for GNNs via Topology Based Node Grouping",
        "link_suffix": "/forum?id=6tvW2OuGNc",
        "link": "https://openreview.net/forum?id=6tvW2OuGNc",
        "pdf_link": "https://openreview.net/pdf?id=6tvW2OuGNc",
        "keywords": "Graph Neural Networks, Neural Network Quantization",
        "abstract": "Graph neural networks (GNN) suffer from huge computational and memory costs in processing large graph data on resource-constrained devices. One effective solution to reduce costs is neural network quantization, replacing complex high-bit operations with efficient low-bit operations. However, to recover from the error induced by lower precision, existing methods require extensive computational costs for retraining, which are many times larger than conventional GNN training. In this circumstance, we propose TopGQ, the first post-training quantization (PTQ) framework for GNNs, enabling an order of magnitude faster quantization without backpropagation. We analyze the feature magnitude of vertices and observe that it is correlated to the topology regarding their neighboring vertices. From these findings, TopGQ proposes to group vertices with similar topology information of inward degree and localized Wiener index to share quantization parameters within the group. Then, TopGQ absorbs the group-wise scale into the adjacency matrix for efficient inference by enabling quantized matrix multiplication of node-wise quantized features. The results show that TopGQ outperforms SOTA GNN quantization methods in performance with a significantly faster quantization speed."
    },
    {
        "title": "Unleashing the Power of Selective State Space Models in Vision-Language Models",
        "link_suffix": "/forum?id=0A6f1b66pE",
        "link": "https://openreview.net/forum?id=0A6f1b66pE",
        "pdf_link": "https://openreview.net/pdf?id=0A6f1b66pE",
        "keywords": "Vision-Language Models; Mamba;",
        "abstract": "While emerging multi-modal large language models (MLLM) have demonstrated impressive advances, the quadratic complexity of their Transformer-based LLMs (3B or larger) inevitably leads to considerable computational overhead. On the other hand, the recently proposed selective state space model (i.e., Mamba) enjoys both model capacity and computational efficiency, making it an ideal component to enhance MLLM's efficiency and performance. However, recent attempts to introduce Mamba into MLLMs simply replace their LLMs with Mamba, ignoring the unique characteristics of either side. We argue that such a naive combination cannot exhibit the potential of Mamba in MLLMs. In this paper, we delve into harnessing Mamba's unique properties, and propose tailored designs from both multi-modal input and architectural perspectives to unleash its true power. First, we fully utilize Mamba's linear complexity to construct visual long sequences for a thorough perception at a minor efficiency burden. To integrate the scanning mechanism with the built visual long sequence, we devise a novel cross-stitch scanning approach to capture and fuse spatial and semantic properties simultaneously, enhancing the interaction of visual information and the vision-language alignment. Built upon these designs, we propose MambaVLM, a simple yet effective MLLM framework that exhibits highly competitive results across multiple benchmarks. Moreover, our framework is also compatible with Transformer-based LLMs (e.g., Vicuna), demonstrating remarkable training and inference efficiency. Notably, with only 0.66M data and 14 hours training on a single A800 node, our MambaVLM outperforms LLaVA-1.5 by significant margins and performs on par or even better than the 1.4B data trained Qwen-VL. The appealing results from both effectiveness and efficiency aspects indicate the promising prospects of Mamba in MLLMs."
    },
    {
        "title": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency",
        "link_suffix": "/forum?id=weM4YBicIP",
        "link": "https://openreview.net/forum?id=weM4YBicIP",
        "pdf_link": "https://openreview.net/pdf?id=weM4YBicIP",
        "keywords": "Diffusion Model, Avatar, Portrait Animation, Audio-Condition Video Generation",
        "abstract": "With the introduction of video diffusion model, audio-conditioned human video generation has recently achieved significant breakthroughs in both the naturalness of motion and the synthesis of portrait details. Due to the limited control of audio signals in driving human motion, existing methods often add auxiliary spatial signals such as movement regions to stabilize movements, which compromise the naturalness and freedom of motion. To address this issue, we propose an end-to-end audio-only conditioned video diffusion model named Loopy. Specifically, we designed two key modules: an inter- and intra-clip temporal module and an audio-to-latents module. These enable the model to better utilize long-term motion dependencies and establish a stronger audio-portrait movement correlation. Consequently, the model can generate more natural and stable portrait videos with subtle facial expressions, without the need for manually setting movement constraints. Extensive experiments show that Loopy outperforms recent audio-driven portrait diffusion models, delivering more lifelike and high-quality results across various scenarios. Video samples are available athttps://loopyavataranony.github.io/"
    },
    {
        "title": "ECLayr: Fast and Robust Topological Layer based on Differentiable Euler Characteristic Curve",
        "link_suffix": "/forum?id=RKXcTwWqVa",
        "link": "https://openreview.net/forum?id=RKXcTwWqVa",
        "pdf_link": "https://openreview.net/pdf?id=RKXcTwWqVa",
        "keywords": "Topological Data Analysis, Deep Learning, Euler Characteristic Curve",
        "abstract": "In the realm of Topological Data Analysis, persistent homology has traditionally served as a primary tool for extracting topological features. However, approaches relying on persistent homology often encounter practical challenges due to their high computational costs. To address this issue, we propose a computationally efficient novel topological layer tailored for general deep learning architectures, leveraging the Euler Characteristic Curve (ECC). Unlike methods based on persistent homology, ECC offers computational advantages by circumventing the need for persistent homology calculation, while still allowing access to crucial information about the underlying topological structure. The proposed layer can readily adapt to diverse data modalities by allowing appropriate filtration according to the user's preference, enabling its application across various learning problems without data preprocessing. We present a novel technique for stable backpropagation that effectively mitigates the vanishing gradient problems commonly encountered in existing methods, allowing for seamless integration of our layer into deep learning models. We go on to present stability analysis, showing that the proposed layer is robust against noise and outliers. We apply our method to topological autoencoders, showing that the standard loss function can effectively regularize topological structures of the latent space. Through classification experiments across various datasets, we illustrate the benefits of our approach in mitigating information loss under conditions of data scarcity or data contamination."
    },
    {
        "title": "Revisiting Vector-Quantization for Blind Image Restoration",
        "link_suffix": "/forum?id=W0UioG6hs1",
        "link": "https://openreview.net/forum?id=W0UioG6hs1",
        "pdf_link": "https://openreview.net/pdf?id=W0UioG6hs1",
        "keywords": "Vector-Quantization, Image Restoration",
        "abstract": "Vector-Quantization (VQ) generative models are widely used to learn a high-quality (HQ) codebook and a decoder as powerful generative priors for blind image restoration (BIR). In this paper, we revisit the key VQ process in VQ-based BIR methods, and provide three close observations on the side effects of VQ for code index prediction: 1) confining the representational capability of HQ codebook, 2) being error-prone on code index prediction, and 3) under-valuing the low-quality (LQ) feature for BIR. These observations motivate us to replace discrete VQ selection by continuous feature transformation from input LQ image to output HQ image with the HQ codebook. To this end, in this paper, we propose a new Self-in-Cross-Attention (SinCA) module to augment the HQ codebook with the LQ feature of input LQ image and perform cross-attention between LQ feature and input-augmented codebook. In this way, our SinCA extends the representational capability of the HQ codebook and effectively leverages the self-expressiveness property of input LQ image. Experiments on four typical VQ-based BIR methods demonstrate that, by replacing the VQ process with transformers using our SinCA, they achieve better quantitative and qualitative performance on blind image super-resolution and blind face restoration. The code will be publicly released."
    },
    {
        "title": "Unsupervised Meta-Learning via In-Context Learning",
        "link_suffix": "/forum?id=Jprs1v2wPA",
        "link": "https://openreview.net/forum?id=Jprs1v2wPA",
        "pdf_link": "https://openreview.net/pdf?id=Jprs1v2wPA",
        "keywords": "meta-learning, unsupervised learning, in-context learning",
        "abstract": "Unsupervised meta-learning aims to learn feature representations from unsupervised datasets that can transfer to downstream tasks with limited labeled data.\nIn this paper, we propose a novel approach to unsupervised meta-learning that leverages the generalization abilities of in-context learning observed in transformer architectures. Our method reframes meta-learning as a sequence modeling problem, enabling the transformer encoder to learn task context from support images and utilize it to predict query images. \nAt the core of our approach lies the creation of diverse tasks generated using a combination of data augmentations and a mixing strategy that challenges the model during training while fostering generalization to unseen tasks at test time. \nExperimental results on benchmark datasets showcase the superiority of our approach over existing unsupervised meta-learning baselines, establishing it as the new state-of-the-art in the field. Remarkably, our method achieves competitive results with supervised and self-supervised approaches, underscoring the efficacy of the model in leveraging generalization over memorization."
    },
    {
        "title": "Predicting User Behaviors with Scene via Dual Sequence Networks",
        "link_suffix": "/forum?id=nW54N85eDT",
        "link": "https://openreview.net/forum?id=nW54N85eDT",
        "pdf_link": "https://openreview.net/pdf?id=nW54N85eDT",
        "keywords": "dual sequence networks, scene-aware, behavior prediction",
        "abstract": "Modeling sequential user behaviors for future action prediction is crucial in improving user's information retrieval experience. Recent studies highlight the importance of incorporating contextual information to enhance prediction performance. One crucial and typical contextual information is the scene feature that is often crafted by app or website designers, such as \"text2product search\" and \"recommendation\" within an e-commence app. Different scenes exhibit different usage habits and distinct product themes, leading to significant distribution gap in user engagement across them. Popular sequential behavior models either ignore the scene feature or merely use it as attribute embeddings, which could lead to substantial information loss or cannot capture the inter-dependencies between scene and item in modeling dynamic user interests. In this work, we propose a novel Dual Sequence Prediction network (DSPnet) to effectively capture the inter-dependencies between scene and item sequences for future behavior prediction. DSPnet consists of two parallel networks dedicated to predicting scene and item sequences, and a sequence feature enhancement module to capture the inter-dependencies. Further, considering the randomness and noise in learning sequence dynamics, we introduce Conditional Contrastive Regularization (CCR) loss to capture the invariance of similar historical sequences. Theoretical analysis suggests that DSPnet can learn the joint relationships between scene and item sequences, and also show better robustness on real-world user behaviors. Extensive experiments are conducted on one public benchmark and two collected industrial datasets. The codes and collected datasets will be made public soon."
    },
    {
        "title": "Enhancing Training Robustness through Influence Measure",
        "link_suffix": "/forum?id=KjBG4JNOc2",
        "link": "https://openreview.net/forum?id=KjBG4JNOc2",
        "pdf_link": "https://openreview.net/pdf?id=KjBG4JNOc2",
        "keywords": "local influence measure, training robustness, active learning",
        "abstract": "In the field of machine learning, the pursuit of robust and accurate models is ongoing. A key aspect of achieving robustness lies in identifying which data points in the training set should be excluded and which high-quality, potentially unlabeled data points outside the training set should be incorporated to improve the model's performance on unseen data. To accomplish this, an effective metric is needed to evaluate the contribution of each data point toward enhancing overall model performance. This paper proposes the use of an influence measure as a metric to assess the impact of training data on test set performance. Additionally, we introduce a data selection method to optimize the training set as well as a dynamic active learning algorithm driven by the influence measure. The effectiveness of these methods is demonstrated through extensive simulations and real-world datasets."
    },
    {
        "title": "Defending Membership Inference Attacks via Privacy-aware Sparsity Tuning",
        "link_suffix": "/forum?id=WDDyTcaP1L",
        "link": "https://openreview.net/forum?id=WDDyTcaP1L",
        "pdf_link": "https://openreview.net/pdf?id=WDDyTcaP1L",
        "keywords": "Membership Inference Attacks (MIA), Machine Learning Security, Data Privacy, Overparameterization",
        "abstract": "Over-parameterized models are typically vulnerable to membership inference attacks, which aim to determine whether a specific sample is included in the training of a given model. Previous Weight regularizations (e.g., L1 regularization) typically impose uniform penalties on all parameters, leading to a suboptimal tradeoff between model utility and privacy. In this work, we first show that only a small fraction of parameters substantially impact the privacy risk. In light of this, we propose Privacy-aware Sparsity Tuning (PAST)\u2014a simple fix to the L1 Regularization\u2014by employing adaptive penalties to different parameters. Our key idea behind PAST is to promote sparsity in parameters that significantly contribute to privacy leakage. In particular, we construct the adaptive weight for each parameter based on its privacy sensitivity, i.e., the gradient of the loss gap with respect to the parameter. Using PAST, the network shrinks the loss gap between members and non-members, leading to strong resistance to privacy attacks. Extensive experiments demonstrate the superiority of PAST, achieving a state-of-the-art balance in the privacy-utility trade-off."
    },
    {
        "title": "What should an AI assessor optimise for?",
        "link_suffix": "/forum?id=YWaXJWd9nu",
        "link": "https://openreview.net/forum?id=YWaXJWd9nu",
        "pdf_link": "https://openreview.net/pdf?id=YWaXJWd9nu",
        "keywords": "Assessor Models, Predictable AI, Regression problems, Error metrics",
        "abstract": "An AI assessor is an external, ideally independent system that predicts an indicator, e.g., a loss value, of another AI system. Assessors can leverage information from the test results of many other AI systems and have the flexibility of being trained on any loss function: from squared error to toxicity metrics. Here we address the question: is it always optimal to train the assessor for the target loss? Or could it be better to train for a different loss and then map predictions back to the target loss? Using ten regression problems with tabular data, we experimentally explore this question for regression losses with monotonic and nonmonotonic mappings and find that, contrary to intuition, optimising for more informative losses is not generally better. Surprisingly though, some monotonic transformations, such as the logistic loss used to minimise the absolute or squared error, are promising."
    },
    {
        "title": "Reconstruct the Understanding of Grokking through Dynamical Systems",
        "link_suffix": "/forum?id=a8XwgTZzE0",
        "link": "https://openreview.net/forum?id=a8XwgTZzE0",
        "pdf_link": "https://openreview.net/pdf?id=a8XwgTZzE0",
        "keywords": "interpretability, grokking, dynamical systems, progress measures",
        "abstract": "\\textbf{Grokking}, or the \\textbf{delayed generalization phenomenon}, describes the abrupt and rapid improvement in test accuracy that occurs after a model has been overfitted for a prolonged period. This phenomenon was first identified by Power in the context of operations on a prime number field. Over the past two years, a range of mathematical analyses has been conducted to investigate grokking, typically involving the use of the hidden progress measure which mean a function that can anticipate the occurrence of grokking. We believe that a comprehensive and rigorous mathematical modeling approach can invigorate the research on this task and provide a unified perspective for understanding previous research. This paper introduces a novel approach by modeling the task as a unique dynamical system. Using mathematical derivation within this framework, we propose a robust hidden progress measure that effectively captures the grokking phenomenon across all operations on prime number fields. This approach not only provides a more complete understanding but also offers deeper insights into the underlying architecture of the model. Based on this understanding, we also proposed a method to accelerate grokking without involving regularization or altering the model architecture."
    },
    {
        "title": "EDiSon: Efficient Design-and-Control Optimization with Reinforcement Learning and Adaptive Design Reuse",
        "link_suffix": "/forum?id=8hVCcrGaAu",
        "link": "https://openreview.net/forum?id=8hVCcrGaAu",
        "pdf_link": "https://openreview.net/pdf?id=8hVCcrGaAu",
        "keywords": "Agent Design, Design Optimization, Reinforcement Learning, Design Automation",
        "abstract": "Seeking good designs is a central goal of many important domains, such as robotics, integrated circuits (IC), medicine, and materials science. These design problems are expensive, time-consuming, and traditionally performed by human experts. Moreover, the barriers to domain knowledge make it challenging to propose a universal solution that generalizes to different design problems. In this paper, we propose a new method called Efficient Design and Stable Control (EDiSon) for automatic design and control in different design problems. The key ideas of our method are (1) interactive sequential modeling of the design and control process and (2) adaptive exploration and design replay. To decompose the difficulty of learning design and control as a whole, we leverage sequential modeling for both the design process and control process, with a design policy to generate step-by-step design proposals and a control policy to optimize the objective by operating the design. With deep reinforcement learning (RL), the policies learn to find good designs by maximizing a reward signal that evaluates the quality of designs. Furthermore, we propose an adaptive exploration and replay strategy based on a design memory that maintains high-quality designs generated so far. By regulating between constructing a design from scratch or replaying a design from memory to refine it, EDiSon balances the trade-off between exploration and exploitation in the design space and stabilizes the learning of the control policy. In the experiments, we evaluate our method in robotic morphology design and Tetris-based design tasks. Our results show that our method effectively learns to explore high-quality designs and outperforms previous results in terms of design score and efficiency."
    },
    {
        "title": "Boltzmann-Aligned Inverse Folding Model as a Predictor of Mutational Effects on Protein-Protein Interactions",
        "link_suffix": "/forum?id=lzdFImKK8w",
        "link": "https://openreview.net/forum?id=lzdFImKK8w",
        "pdf_link": "https://openreview.net/pdf?id=lzdFImKK8w",
        "keywords": "Mutational Effects; Protein-Protein Interactions",
        "abstract": "Predicting the change in binding free energy ($\\Delta \\Delta G$) is crucial for understanding and modulating protein-protein interactions, which are critical in drug design.\nDue to the scarcity of experimental $\\Delta\\Delta G$ data, \nexisting methods focus on pre-training, \nwhile alignment receives less attention.\nIn this work, we propose the Boltzmann Alignment technique to transfer knowledge from pre-trained inverse folding models to $\\Delta\\Delta G$ prediction.\nWe begin by analyzing the thermodynamic definition of $\\Delta\\Delta G$ and introducing the Boltzmann distribution to connect energy with protein conformational distribution. \nHowever, the protein conformational distribution is intractable; therefore, we employ Bayes\u2019 theorem to circumvent direct estimation and instead utilize the log-likelihood provided by protein inverse folding models for $\\Delta\\Delta G$ estimation. \nCompared to previous inverse folding-based methods, our method explicitly accounts for the unbound state of protein complex in the $\\Delta \\Delta G$ thermodynamic cycle, introducing a physical inductive bias and achieving both supervised and unsupervised state-of-the-art (SoTA) performance.\nExperimental results on SKEMPI v2 indicate that our method achieves Spearman coefficients of 0.3201 (unsupervised) and 0.5134 (supervised) on SKEMPI v2, significantly surpassing the previously reported SoTA values of 0.2632 and 0.4324, respectively.\nFuthermore, we demonstrate the capability of our method on binding\nenergy prediction, protein-protein docking and antibody optimization tasks."
    },
    {
        "title": "PointACL: Point Cloud Understanding via  Attention-Driven Contrastive Learning",
        "link_suffix": "/forum?id=5k5Tco1z3G",
        "link": "https://openreview.net/forum?id=5k5Tco1z3G",
        "pdf_link": "https://openreview.net/pdf?id=5k5Tco1z3G",
        "keywords": "Point Cloud Understanding, Attention-Driven Contrastive Learning",
        "abstract": "Recently Transformer-based models have advanced point cloud understanding by leveraging self-attention mechanisms, however, these methods often overlook latent information in less prominent regions, leading to increased sensitivity to perturbations and limited global comprehension. To solve this issue, we introduce PointACL, an attention-driven contrastive learning framework designed to address these limitations. Our method employs an attention-driven dynamic masking strategy that guides the model to focus on under-attended regions, enhancing the understanding of global structures within the point cloud. Then we combine the original pre-training loss with a contrastive learning loss, improving feature discrimination and generalization. Extensive experiments validate the effectiveness of PointACL, as it achieves state-of-the-art performance across a variety of 3D understanding tasks, including object classification, part segmentation, and few-shot learning. Specifically, when integrated with different Transformer backbones like Point-MAE and PointGPT, PointACL demonstrates improved performance on datasets such as ScanObjectNN, ModelNet40, and ShapeNetPart. This highlights its superior capability in capturing both global and local features, as well as its enhanced robustness against perturbations and incomplete data."
    },
    {
        "title": "Poisson-Dirac Neural Networks for Modeling Coupled Dynamical Systems across Domains",
        "link_suffix": "/forum?id=U1DjXQeJRx",
        "link": "https://openreview.net/forum?id=U1DjXQeJRx",
        "pdf_link": "https://openreview.net/pdf?id=U1DjXQeJRx",
        "keywords": "neural ordinary differential equations, coupled system, Poisson system, Dirac structure",
        "abstract": "Deep learning has achieved great success in modeling dynamical systems, providing data-driven simulators to predict complex phenomena, even without known governing equations. However, existing models have two major limitations: their narrow focus on mechanical systems and their tendency to treat systems as monolithic. These limitations reduce their applicability to dynamical systems in other domains, such as electrical and hydraulic systems, and to coupled systems. To address these limitations, we propose Poisson-Dirac Neural Networks (PoDiNNs), a novel framework based on the Dirac structure that unifies the port-Hamiltonian and Poisson formulations from geometric mechanics. This framework enables a unified representation of various dynamical systems across multiple domains as well as their interactions and degeneracies arising from couplings. Our experiments demonstrate that PoDiNNs offer improved accuracy and interpretability in modeling unknown coupled dynamical systems from data."
    },
    {
        "title": "Positive Mining in Graph Contrastive Learning",
        "link_suffix": "/forum?id=V0Hyw9Tz5W",
        "link": "https://openreview.net/forum?id=V0Hyw9Tz5W",
        "pdf_link": "https://openreview.net/pdf?id=V0Hyw9Tz5W",
        "keywords": "Graph Contrastive Learning, Unsupervised representation learning, Mixture model, loss functions",
        "abstract": "Graph Contrastive Learning (GCL), which aims to capture representations from unlabeled graphs, has made significant progress in recent years.   In GCL, InfoNCE-based loss functions play a crucial role by ensuring that positive node pairs\u2014those that are similar\u2014are drawn closer together in the representational space, while negative pairs, which are dissimilar, are pushed apart.    The primary focus of recent research has been on refining the contrastive loss function, particularly by adjusting the weighting of negative nodes.   This is achieved by changing the weight between negative node pairs, or by using node similarity to select the positive node associated with the anchor node.      Despite the substantial success of these GCL techniques, there remains a belief that the nodes identified as positive or negative may not accurately reflect the true positives and negatives.       To tackle this challenge, we introduce an innovative method known as Positive Mining Graph Contrastive Learning (PMGCL).       This method consists in calculating the probability of positive samples between the anchor node and other nodes using a mixture model, thereby identifying nodes that have a higher likelihood of being true positives in relation to the anchor node.       We have conducted a comprehensive evaluation of PMGCL on a range of real-world graph datasets.       The experimental findings indicate that PMGCL significantly outperforms traditional GCL methods.       Our method not only achieves state-of-the-art results in unsupervised learning benchmarks but also exceeds the performance of supervised learning benchmarks in certain scenarios."
    },
    {
        "title": "EnvBridge: Bridging Diverse Environments with Cross-Environment Knowledge Transfer for Embodied AI",
        "link_suffix": "/forum?id=idnMNjlEj5",
        "link": "https://openreview.net/forum?id=idnMNjlEj5",
        "pdf_link": "https://openreview.net/pdf?id=idnMNjlEj5",
        "keywords": "LLM Agent, Robotic Manipulation, Cross-Environment Knowledge Transfer",
        "abstract": "In recent years, Large Language Models (LLMs) have demonstrated high reasoning capabilities, drawing attention for their applications as agents in various decision-making processes. One notably promising application of LLM agents is robotic manipulation. Recent research has shown that LLMs can generate text planning or control code for robots, providing substantial flexibility and interaction capabilities.\nHowever, these methods still face challenges in terms of flexibility and applicability across different environments, limiting their ability to adapt autonomously. Current approaches typically fall into two categories: those relying on environment-specific policy training, which restricts their transferability, and those generating code actions based on fixed prompts, which leads to diminished performance when confronted with new environments. These limitations significantly constrain the generalizability of agents in robotic manipulation.\nTo address these limitations, we propose a novel method called EnvBridge. This approach involves the retention and transfer of successful robot control codes from source environments to target environments. EnvBridge enhances the agent's adaptability and performance across diverse settings by leveraging insights from multiple environments. Notably, our approach alleviates environmental constraints, offering a more flexible and generalizable solution for robotic manipulation tasks.\nWe validated the effectiveness of our method using robotic manipulation benchmarks: RLBench, MetaWorld, and CALVIN. Our experiments demonstrate that LLM agents can successfully leverage diverse knowledge sources to solve complex tasks. Consequently, our approach significantly enhances the adaptability and robustness of robotic manipulation agents in planning across diverse environments."
    },
    {
        "title": "Reaction Graph: Toward Modeling Chemical Reactions  with 3D Molecular Structures",
        "link_suffix": "/forum?id=jy6iAfARAI",
        "link": "https://openreview.net/forum?id=jy6iAfARAI",
        "pdf_link": "https://openreview.net/pdf?id=jy6iAfARAI",
        "keywords": "Chemical Reaction Modeling, Reaction Graph, 3D Molecular Structure, AI for Chemistry",
        "abstract": "Accurately modeling chemical reactions using Artificial Intelligence (AI) can accelerate discovery and development, especially in fields like drug design and material science.  Although AI has made remarkable advancements in single molecule recognition, such as predicting molecular properties, the study of interactions between molecules, particularly chemical reactions, has been relatively overlooked. In this paper, we introduce Reaction Graph (RG), a unified graph representation that encapsulates the 3D molecular structures within chemical reactions.  RG integrates the molecular graphs of reactants and products into a cohesive framework, effectively capturing the interatomic relationships pertinent to the reaction process. Additionally, it incorporates the 3D structure information of molecules in a simple yet effective manner. We conduct experiments on a range of tasks, including chemical reaction classification, condition prediction,  and yield prediction. RG achieves the highest accuracy across six datasets, demonstrating the effectiveness of the proposed method. The code will be publicly available."
    },
    {
        "title": "On Exploring Visual Attention Shrinking for Accelerating VLMs for Video Understanding",
        "link_suffix": "/forum?id=oS79Tw3G0c",
        "link": "https://openreview.net/forum?id=oS79Tw3G0c",
        "pdf_link": "https://openreview.net/pdf?id=oS79Tw3G0c",
        "keywords": "Visual Language model, Inference Acceleration, Visual Attention Shrinking",
        "abstract": "Vision-language models (VLMs) have shown promise in a variety of challenging video comprehension tasks. VLMs typically extract frames from the source video and take the corresponding encoded visual tokens as input. A rapid increase in the number of visual tokens, e.g., when handling lengthy videos, can swiftly lead to a long-context dilemma during the inference process of VLMs, posing an efficiency challenge for real-world applications. Given that significant redundant and task-irrelevant information may exist in the visual tokens across both spatial and temporal axes, we advocate removing less important visual tokens during the prefilling phase of the inference procedure to improve the computation and storage efficiency of VLMs. We first identify an interesting phenomenon termed as \\emph{Visual Attention Shrinking (VAS)}, wherein certain visual tokens receive progressively diminishing attention during the processing stages of the model. This implies that the model itself knows what to care about and what to discard. With this understanding, we develop a robust algorithm to detect attention shrinking at each layer of the model using states from preceding layers. Based on the detection results, we perform token removal in both temporal and spatial axes. Our approach does not require parameterized modifications to the original VLM and is compatible with the prevalent KV cache strategy. Through extensive experiments across different VLMs, our approach witnesses an average speedup of $1.98\\times$ in generating the first response token, utilizing only 47.2% of the visual tokens, without compromising the task performance. Additionally, when applied to the huge VILA1.5-40B, our method can achieve up to $4.16\\times$ speedup compared to the vanilla model."
    },
    {
        "title": "Show-o: One Single Transformer to Unify Multimodal Understanding and Generation",
        "link_suffix": "/forum?id=o6Ynz6OIQ6",
        "link": "https://openreview.net/forum?id=o6Ynz6OIQ6",
        "pdf_link": "https://openreview.net/pdf?id=o6Ynz6OIQ6",
        "keywords": "Multimodal understanding and generation, large language model",
        "abstract": "We present a unified transformer, i.e., Show-o, that unifies multimodal understanding and generation. Unlike fully autoregressive models, Show-o unifies autoregressive and (discrete) diffusion modeling to adaptively handle inputs and outputs of various and mixed modalities. The unified model flexibly supports a wide range of vision-language tasks including visual question-answering, text-to-image generation, text-guided inpainting/extrapolation, and mixed-modality generation. Across various benchmarks, it demonstrates comparable or superior performance to existing individual models with an equivalent or larger number of parameters tailored for understanding or generation. This significantly highlights its potential as a next-generation foundation model."
    },
    {
        "title": "Wasserstein-Regularized Conformal Prediction under General Distribution Shift",
        "link_suffix": "/forum?id=aJ3tiX1Tu4",
        "link": "https://openreview.net/forum?id=aJ3tiX1Tu4",
        "pdf_link": "https://openreview.net/pdf?id=aJ3tiX1Tu4",
        "keywords": "conformal prediction, distribution shift, non-exchangeability",
        "abstract": "Conformal prediction yields a prediction set with guaranteed $1-\\alpha$ coverage of the true target under the i.i.d. assumption, \nwhich can fail and lead to a gap between $1-\\alpha$ and the actual coverage. Prior studies bound the gap using total variation distance, which cannot identify the gap changes under distribution shift at different $\\alpha$, thus serving as a weak indicator of prediction set validity. Besides, existing methods are mostly limited to covariate shifts, while general joint distribution shifts are more common in practice but less researched. In response, we first propose a Wasserstein distance-based upper bound of the coverage gap and analyze the bound using probability measure pushforwards between the shifted joint data and conformal score distributions, enabling a separation of the effect of covariate and concept shifts over the coverage gap. We exploit the separation to design algorithms based on importance weighting and regularized representation learning (WR-CP) to reduce the Wasserstein bound with a finite-sample error bound. WR-CP achieves a controllable balance between conformal prediction accuracy and efficiency. Experiments on six datasets prove that WR-CP can reduce coverage gaps to 3.1% across different confidence levels and outputs prediction sets 38% smaller than the worst-case approach on average."
    },
    {
        "title": "Improving Unsupervised Constituency Parsing via Maximizing Semantic Information",
        "link_suffix": "/forum?id=qyU5s4fzLg",
        "link": "https://openreview.net/forum?id=qyU5s4fzLg",
        "pdf_link": "https://openreview.net/pdf?id=qyU5s4fzLg",
        "keywords": "unsupervised constituency parsing, information theory, semantic information",
        "abstract": "Unsupervised constituency parsers organize phrases within a sentence into a tree-shaped syntactic constituent structure that reflects the organization of sentence semantics. \nHowever, the traditional objective of maximizing sentence log-likelihood (LL) does not explicitly account for the close relationship between the constituent structure and the semantics, resulting in a weak correlation between LL values and parsing accuracy.\nIn this paper, we introduce a novel objective for training unsupervised parsers: maximizing the information between constituent structures and sentence semantics (SemInfo). \nWe introduce a bag-of-substrings model to represent the semantics and apply the probability-weighted information metric to estimate the SemInfo.\nAdditionally, we develop a Tree Conditional Random Field (TreeCRF)-based model to apply the SemInfo maximization objective to Probabilistic Context-Free Grammar (PCFG) induction, the state-of-the-art method for unsupervised constituency parsing. \nExperiments demonstrate that SemInfo correlates more strongly with parsing accuracy than LL.\nOur algorithm significantly enhances parsing accuracy by an average of 7.85 points across five PCFG variants and in four languages, achieving new state-of-the-art results in three of the four languages."
    },
    {
        "title": "GaLore+: Boosting Low-Rank Adaptation for LLMs with Cross-Head Projection",
        "link_suffix": "/forum?id=n8MNWHfhTO",
        "link": "https://openreview.net/forum?id=n8MNWHfhTO",
        "pdf_link": "https://openreview.net/pdf?id=n8MNWHfhTO",
        "keywords": "large language models, parameter-efficient fine-tuning, low-rank",
        "abstract": "Recent low-rank training methods, such as GaLore, have significantly reduced the memory required to optimize large language models (LLMs). However, these methods often suffer from time-consuming low-rank projection estimations. In particular, the singular value decomposition (SVD) in GaLore can consume more than 80% of the total training time. To address this issue, we propose GaLore$+$, which uses cross-head low-rank projection to reduce the substantial time consumption in estimating low-rank projections for multi-head attention. In addition, we employ randomized subspace iteration to achieve fast SVD. To further enhance performance, we propose sparsely coded residuals to reduce the errors caused by low-rank approximation on the first- and second-order moments of the optimizers and weight updates. We evaluate GaLore$+$ on arithmetic reasoning and natural language generation datasets. Our experiments demonstrate that GaLore$+$ delivers superior performance while achieving approximately $4\\times$ fine-tuning speed compared to vanilla GaLore."
    }
]
[
    {
        "title": "Rethinking end-to-end prediction of adsorption energies from a causal perspective",
        "link_suffix": "/forum?id=UO6JmbwVkC",
        "link": "https://openreview.net/forum?id=UO6JmbwVkC",
        "pdf_link": "https://openreview.net/pdf?id=UO6JmbwVkC",
        "keywords": "Graph Neural Network, Material Discovery, Catalyst, AI for Science",
        "abstract": "Adsorption energy is an important descriptor of catalytic activity in the field of catalysis, and significant efforts have been made to develop accurate predictive machine-learning models to replace expensive quantum chemistry calculations. Although it can be inferred by total energy predictions, research has mostly focused on the end-to-end prediction of adsorption energies due to the common belief that total energy is more challenging to predict than adsorption energy. In this study, we first analyzed the causal graph of adsorption energies and revealed that the indirect approach, which infers adsorption energy from total energy predictions, could provide better identifiability, leading to improved accuracy and generalization ability. We also improved the graph property normalization method for total energy prediction and achieved a halved Mean Absolute Error compared to direct adsorption energy prediction for the catalyst in-domain scenario. In the more challenging catalyst out-of-domain scenario, we found that the error primarily comes from predicting the individual energy of unseen catalyst atoms, and the error can be canceled when total energy predictions are used to infer adsorption energy. Consequently, our model achieves a MAE of approximately 0.2 eV for all tasks in the OC20 S2EF task, outperforming end-to-end models trained on datasets 50$\\times$ larger. Given the evidence presented in this study, future research should prioritize the development of total energy models to enhance the accuracy and efficiency of machine-learning approaches in material discovery."
    },
    {
        "title": "ADePT: Adaptive Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning",
        "link_suffix": "/forum?id=fswihJIYbd",
        "link": "https://openreview.net/forum?id=fswihJIYbd",
        "pdf_link": "https://openreview.net/pdf?id=fswihJIYbd",
        "keywords": "Natural Language Processing, Large Language Models, Parameter-efficient Fine-tuning",
        "abstract": "Prompt Tuning (PT) enables the adaptation of Pre-trained Large Language Models (PLMs) to downstream tasks by optimizing a small amount of soft virtual tokens, which are prepended to the input token embeddings. Recently, Decomposed Prompt Tuning (DePT) has demonstrated superior adaptation capabilities by decomposing the soft prompt into a shorter soft prompt and a pair of low-rank matrices. The product of the pair of low-rank matrices is added to the input token embeddings to offset them. Additionally, DePT achieves faster inference compared to PT due to the shorter soft prompt. However, in this paper, we find that the fixed token embedding offsets of DePT restricts its ability to generalize across diverse model inputs, and that the shared embedding offsets across many token embeddings result in sub-optimization. To tackle these issues, we introduce \\textbf{A}daptive \\textbf{De}composed \\textbf{P}rompt \\textbf{T}uning (ADePT), which is composed of  a short soft prompt and a shallow token-shared feed-forward neural network. ADePT utilizes the token-shared feed-forward neural network to learn the embedding offsets for each token, enabling adaptive embedding offsets that varies according to the model input and a better optimization of token embedding offsets. This enables ADePT achieve superior adaptation performance without requiring more inference time or additional trainable parameters compared to vanilla PT and its variants. In comprehensive experiments across 22 natural language processing (NLP) tasks and two typical PLMs of different scales, we show that ADePT consistently surpasses the leading parameter-efficient fine-tuning (PEFT) methods, and even outperforms the full fine-tuning baseline in certain scenarios. The code can be available in the supplementary materials."
    },
    {
        "title": "Discrete Inversion: A Controllable Latent Space for Multinomial Diffusion and Masked Generative Models",
        "link_suffix": "/forum?id=NFEnBqknoX",
        "link": "https://openreview.net/forum?id=NFEnBqknoX",
        "pdf_link": "https://openreview.net/pdf?id=NFEnBqknoX",
        "keywords": "Masked Generative Modeling; Discrete Diffusion Model; Multinomial Diffusion",
        "abstract": "Discrete diffusion models have achieved notable success in tasks like image generation and masked language modeling, yet they face limitations in controlled content editing. This paper introduces {\\bf Discrete Inversion}, the first approach to enable precise inversion for discrete diffusion models, including multinomial diffusion and masked generative models. By recording noise sequences and masking patterns during the forward diffusion process, Discrete Inversion facilitates accurate reconstruction and controlled edits without the need for predefined masks or attention map manipulation. We demonstrate the effectiveness of our method across both image and text domains, evaluating it on models like VQ-Diffusion, Paella, and RoBERTa. Our results show that Discrete Inversion not only preserves high fidelity in the original data but also enables flexible and user-friendly editing in discrete spaces, significantly advancing the capabilities of discrete generative models."
    },
    {
        "title": "Protecting Minorities in Diffusion Models via Capacity Allocation",
        "link_suffix": "/forum?id=kEZb7WmCoG",
        "link": "https://openreview.net/forum?id=kEZb7WmCoG",
        "pdf_link": "https://openreview.net/pdf?id=kEZb7WmCoG",
        "keywords": "Diffusion Models, Imbalance",
        "abstract": "Diffusion models have advanced quickly in image generation. However, their performance declines significantly on the imbalanced data commonly encountered in real-world scenarios. Current research on imbalanced diffusion models focuses on improving the objective function to facilitate knowledge transfer between majorities and minorities, thereby enhancing the generation of minority samples. In this paper, we make the first attempt to address the imbalanced data challenges in diffusion models from the perspective of model capacity. Specifically, majorities occupy most of the model capacity because of their larger representation, consequently restricting the capacity available for minority classes. To tackle this challenge, we propose Protecting Minorities via Capacity ALLocation (CALL). We reserve capacity for minority expertise by low-rank decomposing the model parameters and allocate the corresponding knowledge to the reserved model capacity through a capacity allocation loss function. Extensive experiments demonstrate that our method, which is orthogonal to existing methods, consistently and significantly improves the robustness of diffusion models on imbalanced data."
    },
    {
        "title": "Dobi-SVD: Differential SVD for LLM Compression and Some New Perspectives",
        "link_suffix": "/forum?id=kws76i5XB8",
        "link": "https://openreview.net/forum?id=kws76i5XB8",
        "pdf_link": "https://openreview.net/pdf?id=kws76i5XB8",
        "keywords": "Model Compression, Low-Rank Decomposition, SVD, Effecient LLM, Differentiable",
        "abstract": "Large language models (LLMs) have sparked a new wave of AI applications; however, their substantial computational costs and memory demands pose significant challenges to democratizing access to LLMs for a broader audience. Singular Value Decomposition (SVD), a technique studied for decades, offers a hardware-independent and flexibly tunable solution for LLM compression. In this paper, we present new directions using SVD: we first theoretically analyze the optimality of truncating weights and truncating activations, then we further identify three key issues on SVD-based LLM compression, including (1) How can we determine the optimal truncation position for each weight matrix in LLMs? (2) How can we efficiently update the weight matrices based on truncation position? (3) How can we address the inherent \"injection\" nature that results in the information loss of the SVD? We propose an effective approach,Dobi-SVD, to tackle the three issues. \nFirst, we propose adifferentiabletruncation-value learning mechanism, along with gradient-robust backpropagation, enabling the model to adaptively find the optimal truncation positions. Next, we utilize the Eckart-Young-Mirsky theorem to derive a theoreticallyoptimalweight update formula through rigorous mathematical analysis. Lastly, by observing and leveraging the quantization-friendly nature of matrices after SVD decomposition, we reconstruct a mapping between truncation positions and memory requirements, establishing abijectionfrom truncation positions to memory. \nExperimental results show that with a 40% parameter-compression rate, our method achieves a perplexity of 9.07 on the Wikitext2 dataset with the compressed LLama-7B model, a 78.7% improvement over the state-of-the-art SVD for LLM compression method. \nWe emphasize that Dobi-SVD is the first to achieve such a high-ratio LLM compression with minimal performance drop. We hope that the inference speedup\u2014up to 12.4x on 12GB NVIDIA Titan Xp GPUs and 4x on 80GB A100 GPUs with minimal performance degradation\u2014will benefit the broader community, extending applications beyond LLMs to areas such as robotics."
    },
    {
        "title": "Episodic Control-Based Adversarial Policy Learning in Two-player Competitive Games",
        "link_suffix": "/forum?id=SPcmEiiDDo",
        "link": "https://openreview.net/forum?id=SPcmEiiDDo",
        "pdf_link": "https://openreview.net/pdf?id=SPcmEiiDDo",
        "keywords": "Reinforcement Learning; Adversarial Policy Training; Episodic Control",
        "abstract": "Training adversarial agents to attack neural network policies has proven to be both effective and practical. However, we observe that existing methods can be further enhanced by distinguishing between states leading to win or lose and encouraging the policy training to prioritize winning states. In this paper, we address this gap by introducing an episodic control-based approach for adversarial policy training. Our method extracts the historical evaluations for states from historical experiences with an episodic memory, and then incorporating these evaluations into the rewards to improve the adversarial policy optimization. We evaluate our approach using two-player competitive games in MuJoCo simulation environments, demonstrating that our method establishes the most promising attack performance and defense difficulty against the victims among the existing adversarial policy training techniques."
    },
    {
        "title": "Task-specific Meta-feature Selection for Few-shot Segmentation",
        "link_suffix": "/forum?id=Xv6djzJKl3",
        "link": "https://openreview.net/forum?id=Xv6djzJKl3",
        "pdf_link": "https://openreview.net/pdf?id=Xv6djzJKl3",
        "keywords": "Computer Vision, Semantic Segmentation, Few-Shot Segmentation",
        "abstract": "Few-shot segmentation (FSS) aims to segment new category images given only a few labeled samples. Most previous works concentrate on the design of intricate query decoders to perform feature matching or aggregation between the support and query. In this paper, we revisit a widely overlooked aspect of existing FSS methods, i.e., the exploration of pretrained backbone features. We find that treating all feature channels equally is suboptimal and propose a Task-specific Channel-wise Modulation Network (TCMNet) to focus more attention on task-aware channels, facilitating more effective utilization of pre-trained features. The proposed TCMNet enjoys several merits. First, we design a self-modulation block that injects the gradient information into channel-wise attention layers, thereby enhancing the discriminability between target and background features. Second, a cross-calibration block is introduced to align the support features toward the query according to the target gradient and representations, which mitigates the impact of intra-class diversity. Extensive experimental results on COCO-20i  and Pascal-5i  benchmarks demonstrate that the TCMNet, as a general plugin, consistently achieves significant improvements over different query decoders and also achieves state-of-the-art results. In addition, the decent performance achieved by exploring the backbone features may inspire another direction for developing more comprehensive FSS models."
    },
    {
        "title": "Transition Path Sampling with Improved Off-Policy Training of Diffusion Path Samplers",
        "link_suffix": "/forum?id=WQV9kB1qSU",
        "link": "https://openreview.net/forum?id=WQV9kB1qSU",
        "pdf_link": "https://openreview.net/pdf?id=WQV9kB1qSU",
        "keywords": "transition path sampling, molecular dynamics simulation",
        "abstract": "Understanding transition pathways between meta-stable states in molecular systems is crucial to advance material design and drug discovery. However, unbiased molecular dynamics simulations are computationally infeasible due to the high energy barriers separating these states. Although recent machine learning techniques offer potential solutions, they are often limited to simple systems or rely on collective variables (CVs) derived from costly domain expertise. In this paper, we introduce a novel approach that trains diffusion path samplers (DPS) for transition path sampling (TPS) without the need for CVs. We recast the problem as an amortized sampling of the target path measure, minimizing the log-variance divergence between the path measure induced by our DPS and the target path measure. To ensure scalability for high-dimensional tasks, we introduce (1) a new off-policy training objective based on learning control variates with replay buffers and (2) a scale-based equivariant parameterization of the bias forces. We evaluate our approach, coined TPS-DPS, on a synthetic double-well potential and three peptides: Alanine Dipeptide, Polyproline Helix, and Chignolin. Results show that our approach produces more realistic and diverse transition pathways compared to existing baselines. We also provide links toproject pageandcode."
    },
    {
        "title": "Clothing-disentangled 3D character generation from a single image",
        "link_suffix": "/forum?id=UrbTqU2xrb",
        "link": "https://openreview.net/forum?id=UrbTqU2xrb",
        "pdf_link": "https://openreview.net/pdf?id=UrbTqU2xrb",
        "keywords": "3D human  reconstruction; 3D human generation",
        "abstract": "This paper tackles the challenge of generating clothing-disentangled 3D characters from a single image. Existing approaches typically employ multi-layer 3D representations to model the body and each garment and then iteratively optimize these representations to fit the observations, which is time-consuming and not scalable. To address this, we propose the first feed-forward method enabling efficient and robust clothing disentanglement. Our approach first generates the multi-view images for each component of the clothed character and then employs a generalizable multi-view reconstruction method to create the 3D models of each component. For high-quality disentanglement, we propose a two-stage disentanglement approach that first disentangles each component in the 2D image space and then generates the multi-view images for each part. During the 2D component disentanglement stage, we introduce a novel multi-part diffusion model that allows information exchange among different components. Additionally, for component combination, we incorporate a novel combination attention mechanism into the multi-view diffusion model, enabling the integration of information from multiple parts to create the final combined character. For training, we have contributed a large clothing-disentangled character dataset consisting of more than 10k anime characters. Extensive experiments demonstrate that our proposed approach not only facilitates efficient and high-quality disentangled 3D character generation with distinct clothing layers but also supports various cloth editing applications."
    },
    {
        "title": "Cross Resolution Encoding-Decoding For Detection Transformers",
        "link_suffix": "/forum?id=KGRV73Zcqt",
        "link": "https://openreview.net/forum?id=KGRV73Zcqt",
        "pdf_link": "https://openreview.net/pdf?id=KGRV73Zcqt",
        "keywords": "Cross Resolution, Encoding and Decoding, DETR, Detection",
        "abstract": "Detection Transformers (DETR) are renowned object detection pipelines, however\ncomputationally efficient multiscale detection using DETR is still challenging. In\nthis paper, we propose a Cross-Resolution Encoding-Decoding (CRED) mechanism\nthat allows DETR to achieve the accuracy of high-resolution detection while\nhaving the speed of low-resolution detection. CRED is based on two modules;\nCross Resolution Attention Module (CRAM) and One Step Multiscale Attention\n(OSMA). CRAM is designed to transfer the knowledge of low-resolution encoder\noutput to a high-resolution feature. While OSMA is designed to fuse multiscale\nfeatures in a single step and produce a feature map of a desired resolution enriched\nwith multiscale information. When used in prominent DETR methods, CRED\ndelivers accuracy similar to the high-resolution DETR counterpart in roughly 50%\nfewer FLOPs. Specifically, state-of-the-art DN-DETR, when used with CRED\n(calling CRED-DETR), becomes 76% faster, with \u223c 50% reduced FLOPs than its\nhigh-resolution counterpart with 202 G FLOPs on MS-COCO benchmark. We plan\nto release pretrained CRED-DETRs for use by the community."
    },
    {
        "title": "Taming Overconfidence in LLMs: Reward Calibration in RLHF",
        "link_suffix": "/forum?id=l0tg0jzsdL",
        "link": "https://openreview.net/forum?id=l0tg0jzsdL",
        "pdf_link": "https://openreview.net/pdf?id=l0tg0jzsdL",
        "keywords": "Calibration, RLHF, Large Language Models",
        "abstract": "Language model calibration refers to the alignment between the confidence of the model and the actual performance of its responses.\nWhile previous studies point out the overconfidence phenomenon in Large Language Models (LLMs) and show that LLMs trained with Reinforcement Learning from Human Feedback (RLHF) are overconfident with a more sharpened output probability, in this study, we reveal that RLHF tends to lead models to express verbalized overconfidence in their own responses. We investigate the underlying cause of this overconfidence and demonstrate that reward models used for Proximal Policy Optimization (PPO) exhibit inherent biases towards high-confidence scores regardless of the actual quality of responses. Building upon this insight, we propose two PPO variants: PPO-M: $\\underline{PPO}$ with Calibrated Reward $\\underline{M}$odeling and PPO-C: $\\underline{PPO}$ with Calibrated Reward $\\underline{C}$alculation. PPO-M integrates explicit confidence scores in reward model training, which calibrates reward models\nto better capture the alignment between response quality and verbalized confidence. PPO-C adjusts the reward score during PPO based on the difference between the current reward and the moving average of past rewards. Both PPO-M and PPO-C can be seamlessly integrated into the current PPO pipeline and do not require additional golden labels. We evaluate our methods on both $\\texttt{Llama3-8B}$ and $\\texttt{Mistral-7B}$ across six diverse datasets including multiple-choice and open-ended generation. Experiment results demonstrate that both of our methods can reduce calibration error and maintain performance comparable to standard PPO. We further show that they do not compromise model capabilities in open-ended conversation settings."
    },
    {
        "title": "CMamba: Channel Correlation Enhanced State Space Models for Multivariate Time Series Forecasting",
        "link_suffix": "/forum?id=OclHGmt2ZM",
        "link": "https://openreview.net/forum?id=OclHGmt2ZM",
        "pdf_link": "https://openreview.net/pdf?id=OclHGmt2ZM",
        "keywords": "Time Series Forecasting, Mamba, Channel-Dependent",
        "abstract": "Recent advancements in multivariate time series forecasting have been propelled by Linear-based, Transformer-based, and Convolution-based models, with Transformer-based architectures gaining prominence for their efficacy in temporal and cross-channel mixing.\nMore recently, Mamba, a state space model, has emerged with robust sequence and feature mixing capabilities.\nHowever, the suitability of the vanilla Mamba design for time series forecasting remains an open question, particularly due to its inadequate handling of cross-channel dependencies.\nCapturing cross-channel dependencies is critical in enhancing the performance of multivariate time series prediction.\nRecent findings show that self-attention excels in capturing cross-channel dependencies, whereas other simpler mechanisms, such as MLP, may degrade model performance.\nThis is counterintuitive, as MLP, being a learnable architecture, should theoretically capture both correlations and irrelevances, potentially leading to neutral or improved performance.\nDiving into the self-attention mechanism, we attribute the observed degradation in MLP performance to its lack of data dependence and global receptive field, which result in MLP's lack of generalization ability.\nConsidering the powerful sequence modeling capabilities of Mamba and the high efficiency of MLP, the combination of the two is an effective strategy for solving multivariate time series prediction.\nBased on the above insights, we introduce a refined Mamba variant tailored for time series forecasting.\nOur proposed model, \\textbf{CMamba}, incorporates a modified Mamba (M-Mamba) module for temporal dependencies modeling, a global data-dependent MLP (GDD-MLP) to effectively capture cross-channel dependencies, and a Channel Mixup mechanism to mitigate overfitting.\nComprehensive experiments conducted on seven real-world datasets demonstrate the efficacy of our model in improving forecasting performance."
    },
    {
        "title": "LW2G: Learning Whether to Grow for Prompt-based Continual Learning",
        "link_suffix": "/forum?id=QZuZmfLLRG",
        "link": "https://openreview.net/forum?id=QZuZmfLLRG",
        "pdf_link": "https://openreview.net/pdf?id=QZuZmfLLRG",
        "keywords": "Continual Learning, Gradient Orthogonal, Pre-Trained Model, Prompt Learning",
        "abstract": "Continual Learning (CL) aims to learn in non-stationary scenarios, progressively acquiring and maintaining knowledge from sequential tasks. Recent Prompt-based Continual Learning (PCL) has achieved remarkable performance with Pre-Trained Models (PTMs). These approaches grow a prompt sets pool by adding a new set of prompts when learning each new task (prompt learning) and adopt a matching mechanism to select the correct set for each testing sample (prompt retrieval). Previous studies focus on the latter stage by improving the matching mechanism to enhance Prompt Retrieval Accuracy (PRA). To promote cross-task knowledge facilitation and form an effective and efficient prompt sets pool, we propose a plug-in module in the former stage to Learn Whether to Grow (LW2G) based on the disparities between tasks. Specifically, a shared set of prompts is utilized when several tasks share certain commonalities, and a new set is added when there are significant differences between the new task and previous tasks. Inspired by Gradient Projection Continual Learning, our LW2G develops a metric called Hinder Forward Capability (HFC) to measure the hindrance imposed on learning new tasks by surgically modifying the original gradient onto the orthogonal complement of the old feature space. With HFC, an automated scheme Dynamic Growing Approach adaptively learns whether to grow with a dynamic threshold. Furthermore, we design a gradient-based constraint to ensure the consistency between the updating prompts and pre-trained knowledge, and a prompts weights reusing strategy to enhance forward transfer. Extensive experiments show the effectiveness of our method."
    },
    {
        "title": "Designing Concise ConvNets with Columnar Stages",
        "link_suffix": "/forum?id=zvaiz3FjA9",
        "link": "https://openreview.net/forum?id=zvaiz3FjA9",
        "pdf_link": "https://openreview.net/pdf?id=zvaiz3FjA9",
        "keywords": "Convolutional Neural Networks, Columnar Stages, Input Replication, Image Classification, Detection",
        "abstract": "In the era of vision Transformers, the recent success of VanillaNet shows the huge\npotential of simple and concise convolutional neural networks (ConvNets). Where\nsuch models mainly focus on runtime, it is also crucial to simultaneously focus\non other aspects, e.g., FLOPs, parameters, etc, to strengthen their utility further.\nTo this end, we introduce a refreshing ConvNet macro design called Columnar\nStage Network (CoSNet). CoSNet has a systematically developed simple and\nconcise structure, smaller depth, low parameter count, low FLOPs, and attention-\nless operations, well suited for resource-constrained deployment. The key novelty\nof CoSNet is deploying parallel convolutions with fewer kernels fed by input\nreplication, using columnar stacking of these convolutions, and minimizing the use\nof 1\u00d71 convolution layers. Our comprehensive evaluations show that CoSNet rivals\nmany renowned ConvNets and Transformer designs under resource-constrained\nscenarios. Pretrained models shall be open-sourced."
    },
    {
        "title": "Trusted and Interactive Clustering for Time-Series Data",
        "link_suffix": "/forum?id=WioQ6tSzvr",
        "link": "https://openreview.net/forum?id=WioQ6tSzvr",
        "pdf_link": "https://openreview.net/pdf?id=WioQ6tSzvr",
        "keywords": "Time-series clustering, evidence theory, information fusion",
        "abstract": "Time-series clustering has gained abundant popularity and has been used in diverse scientific areas. However, few researchers take an information fusion perspective to combine information from the time and frequency domains to accomplish clustering, although these two domains offer distinct and complementary characteristics of time-series. Motivated by this issue, we propose a trusted and interactive model, which leverages evidence theory to combine time- and frequency-based clustering results produced by the corresponding contrastive learning module. After mathematizing clustering results from the two domains as mass functions, the uncertainty contained in these results can be quantified at the sample-specific level. The combined result thus promotes clustering reliability, and is optimized based on the pseudo-labels generated by k-means in an interactive learning paradigm. Both theoretical analysis and experimental results on 136 benchmark datasets validate the effectiveness of the proposed model in clustering performance. Extensive ablation experiments demonstrate the contribution of combining information from the time and frequency domains and using the interactive learning paradigm. The embeddings learned are also experimentally shown to perform well in other downstream tasks."
    },
    {
        "title": "The BabyView dataset: High-resolution egocentric videos of infants\u2019 and young children\u2019s everyday experiences",
        "link_suffix": "/forum?id=P8uOZmypb6",
        "link": "https://openreview.net/forum?id=P8uOZmypb6",
        "pdf_link": "https://openreview.net/pdf?id=P8uOZmypb6",
        "keywords": "egocentric video dataset, self-supervised learning, developmental curriculum, data gap",
        "abstract": "Human children far exceed modern machine learning algorithms in their sample efficiency, achieving high performance in key domains with much less data than current models. This \"data gap'' is a key challenge both for building intelligent artificial systems and for understanding human development. Egocentric video capturing children's experience\u2014their \"training data''\u2014is a key ingredient for comparison of humans and models and for the development of algorithmic innovations to bridge this gap. Yet there are few such datasets available, and extant data are low-resolution, have limited metadata, and importantly, represent only a small set of children's experiences. Here, we provide the first release of a large developmental egocentric video dataset\u2014the BabyView dataset\u2014recorded using a high-resolution camera with a large vertical field-of-view and gyroscope/accelerometer data. This 430 hour dataset includes egocentric videos from children spanning 6 months\u20133 years of age in longitudinal, at-home contexts. We provide gold-standard annotations for the evaluation of speech transcription, speaker diarization, and human pose estimation, and evaluate models in each of these domains.  We train self-supervised language and vision models and evaluate their transfer to out-of-distribution tasks including syntactic structure learning, object recognition, depth estimation, and image segmentation.  Although performance in each scales with dataset size, overall performance is relatively lower than when models are trained on curated datasets, especially in the visual domain. Our dataset stands as an open challenge for robust, human-like AI systems: how can such systems achieve human-levels of success on the same scale and distribution of training data as humans?"
    },
    {
        "title": "KAN: Kolmogorov\u2013Arnold Networks",
        "link_suffix": "/forum?id=Ozo7qJ5vZi",
        "link": "https://openreview.net/forum?id=Ozo7qJ5vZi",
        "pdf_link": "https://openreview.net/pdf?id=Ozo7qJ5vZi",
        "keywords": "Kolmogorov-Arnold networks, Kolmogorov-Arnold representation theorem, learnable activation functions, interpretability, AI + Science",
        "abstract": "Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes (\"neurons''), KANs have learnable activation functions on edges (\"weights''). KANs have no linear weights at all -- every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability, on small-scale AI + Science tasks. For accuracy, smaller KANs can achieve comparable or better accuracy than larger MLPs in function fitting tasks. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful ``collaborators'' helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs. Despite the slow training of KANs, their improved accuracy and interpretability show the potential to improve today's deep learning models which rely heavily on MLPs. More research is necessary to make KANs' training more efficient."
    },
    {
        "title": "Open-Set Learning for Addressing Label Skews in One-Shot Federated Learning",
        "link_suffix": "/forum?id=yj6P8OdWyj",
        "link": "https://openreview.net/forum?id=yj6P8OdWyj",
        "pdf_link": "https://openreview.net/pdf?id=yj6P8OdWyj",
        "keywords": "federated learning, open-set learning",
        "abstract": "Federated learning (FL) is crucial for collaborative model training, yet it faces significant challenges from data heterogeneity, particularly label skews across clients, where some classes may be underrepresented or absent entirely. In one-shot FL, where clients only communicate with the server once, this problem becomes even more challenging. Recent solutions propose incorporating open-set learning (OSL) to tackle this issue by detecting unknown samples during inference, but current methods like FedOV lack adaptability to varying client data distributions. In this paper, we provide a theoretical analysis proving that improving OSL algorithms can effectively address label skews in one-shot FL, since one-shot FL is learnable through good OSL algorithms regardless of label skews. We also empirically evaluate state-of-the-art OSL algorithms and identify their limitations. Based on these insights, we propose FedAdav, an adaptive algorithm that combines OSL signals to significantly improve ensemble accuracy in one-shot FL under label skews. Through extensive experiments, we demonstrate that exploring better OSL is key to overcoming label skew challenges in federated learning."
    },
    {
        "title": "Learning Under Multi-dimensional Domain Shifts: A Ensemble of Mixtures of Experts Approach",
        "link_suffix": "/forum?id=s3W8bUX43z",
        "link": "https://openreview.net/forum?id=s3W8bUX43z",
        "pdf_link": "https://openreview.net/pdf?id=s3W8bUX43z",
        "keywords": "Domain shift, Federated Learning, Healthcare",
        "abstract": "Domain shifts pose a significant challenge in deep learning applications. Existing methods typically address domain shifts by treating each domain in isolation, overlooking the underlying factors driving the shifts, or focus on only \\emph{one} factor. However, domain shifts in the real world often occur across \\emph{multiple} dimensions simultaneously. For example, medical datasets from different hospitals can exhibit variations in factors including demographics, equipment manufacturers, and imaging protocols, demonstrating a three-dimensional shifts.\nIn this paper, we introduce a novel approach to address the complexity of multi-dimensional domain shifts. Our method leverages an ensemble of mixtures of experts (EMoE), with each MoE specialized in different dimensions. \nCrucially, we innovate a domain estimator to address a particularly challenging issue frequently encountered in practice: domain labels may be missing or unreliable.\nA significant advantage of our method is its generalizability and adaptability to both centralized and federated learning settings, as well as its versatility across various tasks. Extensive experiments on six datasets demonstrate the superiority of our method over state-of-the-art domain generalization and personalized federated learning approaches."
    },
    {
        "title": "Symbolic Learning Enables Self-Evolving Agents",
        "link_suffix": "/forum?id=P8IBvXLAVk",
        "link": "https://openreview.net/forum?id=P8IBvXLAVk",
        "pdf_link": "https://openreview.net/pdf?id=P8IBvXLAVk",
        "keywords": "large language model, language agents, agent learning",
        "abstract": "The AI community has been exploring a pathway to artificial general intelligence (AGI) by developing \"language agents\", which are complex large language models (LLMs) pipelines involving both prompting techniques and tool usage methods. While language agents have demonstrated impressive capabilities for many real-world tasks, a fundamental limitation of current language agents research is that they are model-centric, or engineering-centric. That's to say, the progress on prompts, tools, and pipelines of language agents requires substantial manual engineering efforts from human experts rather than automatically learning from data. We believe the transition from model-centric, or engineering-centric, to data-centric, i.e., the ability of language agents to autonomously learn and evolve in environments, is the key for them to possibly achieve AGI. In this work, we introduce agent symbolic learning, a systematic framework that enables language agents to optimize themselves on their own in a data-centric way using symbolic optimizers. Specifically, we consider agents as symbolic networks where learnable weights are defined by prompts, tools, and the way they are stacked together. Agent symbolic learning is designed to optimize the symbolic network within language agents by mimicking two fundamental algorithms in connectionist learning: back-propagation and gradient descent. Instead of dealing with numeric weights, agent symbolic learning works with language-based weights, loss, and gradients. We conduct proof-of-concept experiments on both standard benchmarks and complex real-world tasks and show that agent symbolic learning enables language agents to update themselves after being created and deployed in the wild, resulting in \"self-evolving agents\". We demonstrate the potential of the agent symbolic learning framework and open-source the entire framework to facilitate future research on data-centric agent learning."
    },
    {
        "title": "Smooth Probabilistic Interpolation Benefits Generative Modeling for Discrete Graphs",
        "link_suffix": "/forum?id=MhsCDuY4zx",
        "link": "https://openreview.net/forum?id=MhsCDuY4zx",
        "pdf_link": "https://openreview.net/pdf?id=MhsCDuY4zx",
        "keywords": "2D Molecule Generation; Bayesian Flow Networks",
        "abstract": "Though typically represented by the discrete node and edge attributes, the graph topological information can be sufficiently captured by the graph spectrum in a continuous space. It is believed that incorporating the continuity of graph topological information into the generative process design could establish a superior paradigm for graph generative modeling. Motivated by such prior and recent advancements in the generative paradigm,  we propose Graph Bayesian Flow Networks (GraphBFN) in this paper, a principled generative framework that designs an alternative generative process emphasizing the dynamics of topological information. Unlike recent discrete-diffusion-based methods, GraphBFNemploys the continuous counts derived from sampling infinite times from a categorical distribution as latent to facilitate a smooth decomposition of topological information, demonstrating enhanced effectiveness. To effectively realize the concept, we further develop an advanced sampling strategy and new time-scheduling techniques to overcome practical barriers and boost performance. Through extensive experimental validation on both generic graph and molecular graph generation tasks, GraphBFN could consistently achieve superior or competitive performance with significantly higher training and sampling efficiency."
    },
    {
        "title": "Denoising Task Difficulty-based Curriculum for Training Diffusion Models",
        "link_suffix": "/forum?id=96GMFXsbJE",
        "link": "https://openreview.net/forum?id=96GMFXsbJE",
        "pdf_link": "https://openreview.net/pdf?id=96GMFXsbJE",
        "keywords": "Diffusion models, Task difficulty, Curriculum learning",
        "abstract": "Diffusion-based generative models have emerged as powerful tools in the realm of generative modeling. Despite extensive research on denoising across various timesteps and noise levels, a conflict persists regarding the relative difficulties of the denoising tasks. While various studies argue that lower timesteps present more challenging tasks, others contend that higher timesteps are more difficult. To address this conflict, our study undertakes a comprehensive examination of task difficulties, focusing on convergence behavior and changes in relative entropy between consecutive probability distributions across timesteps. Our observational study reveals that denoising at earlier timesteps poses challenges characterized by slower convergence and higher relative entropy, indicating increased task difficulty at these lower timesteps. Building on these observations, we introduce an easy-to-hard learning scheme, drawing from curriculum learning, to enhance the training process of diffusion models. By organizing timesteps or noise levels into clusters and training models with ascending orders of difficulty, we facilitate an order-aware training regime, progressing from easier to harder denoising tasks, thereby deviating from the conventional approach of training diffusion models simultaneously across all timesteps. Our approach leads to improved performance and faster convergence by leveraging benefits of curriculum learning, while maintaining orthogonality with existing improvements in diffusion training techniques. We validate these advantages through comprehensive experiments in image generation tasks, including unconditional, class-conditional, and text-to-image generation."
    },
    {
        "title": "AD-H: Autonomous Driving with Hierarchical Agents",
        "link_suffix": "/forum?id=JwrnoB1tR0",
        "link": "https://openreview.net/forum?id=JwrnoB1tR0",
        "pdf_link": "https://openreview.net/pdf?id=JwrnoB1tR0",
        "keywords": "AutoDriving; Agent, Planning",
        "abstract": "Due to the impressive capabilities of multimodal large language models (MLLMs), recent works have focused on employing MLLM-based agents for autonomous driving in large-scale and dynamic environments. However, prevalent approaches often directly use MLLMs to translate high-level instructions into low-level vehicle control signals. This approach deviates from the inherent language generation paradigm of MLLMs and fails to fully harness their emergent capabilities. As a result, the generalizability of these methods is limited by the autonomous driving datasets used during fine-tuning.\nTo tackle this challenge, we propose AD-H, a hierarchical framework that enables two agents (the MLLM planner and the controller) to collaborate. The MLLM planner perceives environmental information and high-level instructions to generate mid-level, fine-grained driving commands, which the controller then executes as actions. This compositional paradigm liberates the MLLM from low-level control signal decoding, thus fully leveraging its high-level perception, reasoning, and planning capabilities. Furthermore, the fine-grained commands provided by the MLLM planner enable the controller to perform actions more effectively.\nTo train AD-H, we build a new autonomous driving dataset with hierarchical action annotations encompassing multiple levels of instructions and driving commands. \nComprehensive closed-loop evaluations demonstrate several key advantages of our proposed AD-H system.\nFirst, AD-H can notably outperform state-of-the-art methods in achieving exceptional driving performance, even exhibiting self-correction capabilities during vehicle operation, a scenario not encountered in the training dataset. Second, AD-H demonstrates superior generalization under long-horizon instructions and novel environmental conditions, significantly surpassing current state-of-the-art methods."
    },
    {
        "title": "Circuit Transformer: A Transformer That Preserves Logical Equivalence",
        "link_suffix": "/forum?id=kpnW12Lm9p",
        "link": "https://openreview.net/forum?id=kpnW12Lm9p",
        "pdf_link": "https://openreview.net/pdf?id=kpnW12Lm9p",
        "keywords": "Transformer, Logic, EDA, Circuit, Logic Synthesis",
        "abstract": "Implementing Boolean functions with circuits consisting of logic gates is fundamental in digital computer design. However, the implemented circuit must be exactly equivalent, which hinders generative neural approaches on this task due to their occasionally wrong predictions. In this study, we introduce a generative neural model, the \u201cCircuit Transformer\u201d, which eliminates such wrong predictions and produces logic circuits strictly equivalent to given Boolean functions. The main idea is a carefully designed decoding mechanism that builds a circuit step-by-step by generating tokens, which has beneficial \u201ccutoff properties\u201d that block a candidate token once it invalidate equivalence. In such a way, the proposed model works similar to typical LLMs while logical equivalence is strictly preserved. A Markov decision process formulation is also proposed for optimizing certain objectives of circuits. Experimentally, we trained an 88-million-parameter Circuit Transformer to generate equivalent yet more compact forms of input circuits, outperforming existing neural approaches on both synthetic and real world benchmarks, without any violation of equivalence constraints."
    },
    {
        "title": "Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges",
        "link_suffix": "/forum?id=xam3sR3ffY",
        "link": "https://openreview.net/forum?id=xam3sR3ffY",
        "pdf_link": "https://openreview.net/pdf?id=xam3sR3ffY",
        "keywords": "LLMs, NLP, LLM Evaluation, LLM-as-a-Judge, Benchmarks",
        "abstract": "Offering a promising solution to the scalability challenges associated with human evaluation, the LLM-as-a-judge paradigm is rapidly gaining traction as an approach to evaluating large language models (LLMs). However, there are still many open questions about the strengths and weaknesses of this paradigm, and what potential biases it may hold. In this paper, we present a comprehensive study of the performance of various LLMs acting as judges, focusing on a clean scenario in which inter-human agreement is high. Investigating thirteen judge models of different model sizes and families, judging answers of nine different \u2018examtaker models\u2019 \u2013 both base and instruction-tuned \u2013 we find that only the best (and largest) models achieve reasonable alignment with humans. However, they are still quite far behind inter-human agreement and their assigned scores may still differ with up to 5 points from human-assigned scores. In terms of their ranking of the nine exam-taker models, instead, also smaller models and even the lexical metric contains may provide a reasonable signal. Through error analysis and other studies, we identify vulnerabilities in judge models, such as their sensitivity to prompt complexity and length, and a tendency toward leniency. The fact that even the best judges differ from humans in this comparatively simple setup suggest that caution may be wise when using judges in more complex setups. Lastly, our research rediscovers the importance of using alignment metrics beyond simple percent alignment, showing that judges with high percent agreement can still assign vastly different scores."
    }
]
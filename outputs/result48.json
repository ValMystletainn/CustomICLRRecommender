[{"title": "Towards Reliability of Parameter-free Optimization", "link_suffix": "/forum?id=LHPWuckqgM", "link": "https://openreview.net/forum?id=LHPWuckqgM", "pdf_link": "https://openreview.net/pdf?id=LHPWuckqgM", "keywords": "hyperparameter tuning, tuning free", "abstract": "Hyperparameter tuning, particularly the selection of an appropriate learning rate in adaptive gradient training methods, remains a challenge. To tackle this challenge, in this paper, we propose a novel parameter-free optimizer, AdamG (Adam with the golden step size), designed to automatically adapt to diverse optimization problems without manual tuning. The core technique underlying AdamG is our golden step size derived for the AdaGrad-Norm algorithm, which is expected to help AdaGrad-Norm preserve the tuning-free convergence and approximate the optimal step size in expectation w.r.t. various optimization scenarios. To better evaluate tuning-free performance, we propose a novel evaluation criterion, reliability, to comprehensively assess the efficacy of parameter-free optimizers in addition to classical performance criteria. Empirical results demonstrate that compared with other parameter-free baselines, AdamG achieves superior performance, which is consistently on par with Adam using a manually tuned learning rate across various optimization tasks.", "title_embedding_index": 2350, "title_abs_embedding_index": 2375}, {"title": "Theoretical Limitations of Ensembles in the Age of Overparameterization", "link_suffix": "/forum?id=jlsEtFZYUg", "link": "https://openreview.net/forum?id=jlsEtFZYUg", "pdf_link": "https://openreview.net/pdf?id=jlsEtFZYUg", "keywords": "Ensembles, Deep Ensembles, Uncertainty Quantification, Overparameterization, Random feature regression, Kernel regression", "abstract": "Classic tree-based ensembles generalize better than any single decision tree. In contrast, recent empirical studies find that modern ensembles of (overparameterized) neural networks may not provide any inherent generalization advantage over single but larger neural networks. This paper clarifies how modern overparameterized ensembles differ from their classic underparameterized counterparts, using ensembles of random feature (RF) regressors as a basis for developing theory. In contrast to the underparameterized regime, where ensembling typically induces regularization and increases generalization, we prove that infinite ensembles of overparameterized RF regressors become pointwise equivalent to infinite-width (single) RF regressors. This equivalence, which is exact for ridgeless models and approximate for small ridge penalties, implies that overparameterized ensembles and single large models exhibit nearly identical generalization. As a consequence, we can characterize the predictive variance amongst ensemble members, and demonstrate that it quantifies the expected effects of increasing capacity rather than capturing any conventional notion of uncertainty. Our results challenge common assumptions about the advantages of ensembles in overparameterized settings, prompting a reconsideration of how well intuitions from underparameterized ensembles transfer to deep ensembles and the overparameterized regime.", "title_embedding_index": 2351, "title_abs_embedding_index": 2376}, {"title": "Sparse-to-Sparse Training of Diffusion Models", "link_suffix": "/forum?id=vNZIePda08", "link": "https://openreview.net/forum?id=vNZIePda08", "pdf_link": "https://openreview.net/pdf?id=vNZIePda08", "keywords": "Diffusion Models, Sparse-to-Sparse Training, Static Sparse Training, Dynamic Sparse Training", "abstract": "Diffusion models (DMs) are a powerful type of generative models that have achieved state-of-the-art results in various image synthesis tasks and have shown  potential in other domains, such as natural language processing and temporal data modeling. Despite their stable training dynamics and ability to produce diverse high-quality samples, DMs are notorious for requiring significant computational resources, both in the training and inference stages. Previous work has focused mostly on increasing the efficiency of model inference. This paper introduces, for the first time, the paradigm of sparse-to-sparse training to DMs, with the aim of improving both training and inference efficiency. We train sparse DMs from scratch (Latent Diffusion and ChiroDiff) using three different methods (Static-DM, RigL-DM, and MagRan-DM) to study the effect of sparsity in model performance. Our experiments show that sparse DMs are able to match and sometimes outperform their Dense counterparts, while substantially reducing the number of trainable parameters and FLOPs.", "title_embedding_index": 2352, "title_abs_embedding_index": 2377}, {"title": "Gaussian Mixture Counterfactual Generator", "link_suffix": "/forum?id=lBB3eSn6fY", "link": "https://openreview.net/forum?id=lBB3eSn6fY", "pdf_link": "https://openreview.net/pdf?id=lBB3eSn6fY", "keywords": "Gaussian mixture model, synthetic data generation, clinical trial, individual treatment effect, counterfactual generation", "abstract": "Generating synthetic control arms is a key challenge in clinical research, particularly in crossover trials where placebo data becomes unavailable after patients switch to active treatment. The absence of placebo data complicates estimating long-term efficacy and safety. To solve this, we propose a Gaussian mixture model that generates counterfactual data without needing control data for training. This method handles time-varying, continuous doses and estimates effects between treatment switchers and an extended placebo group, providing valuable insights for treatment effects, evidence generation, and decision-making.", "title_embedding_index": 2353, "title_abs_embedding_index": 2378}, {"title": "Towards Machine Theory of Mind with Large Language Model-Augmented Inverse Planning", "link_suffix": "/forum?id=Y2cGisOWPZ", "link": "https://openreview.net/forum?id=Y2cGisOWPZ", "pdf_link": "https://openreview.net/pdf?id=Y2cGisOWPZ", "keywords": "inverse planning, large language models, theory of mind, social reasoning", "abstract": "We propose a hybrid approach to machine Theory of Mind (ToM) that uses large language models (LLMs) as a mechanism for generating hypotheses and likelihood functions with a Bayesian inverse planning model that computes posterior probabilities for an agent\u2019s likely mental states given its actions. Bayesian inverse planning models can accurately predict human reasoning on a variety of ToM tasks, but these models are constrained in their ability to scale these predictions to scenarios with a large number of possible hypotheses and actions. Conversely, LLM-based approaches have recently demonstrated promise in solving ToM benchmarks, but can exhibit brittleness and failures on reasoning tasks even when they pass otherwise structurally identical versions. By combining these two methods, our approach leverages the strengths of each component, closely matching optimal results on a task inspired by prior inverse planning models and improving performance relative to models that utilize LLMs alone or with chain-of-thought prompting. We also exhibit the model\u2019s potential to predict mental states on open-ended tasks, offering a promising direction for future development of ToM models and the creation of socially intelligent generative agent models.", "title_embedding_index": 2354, "title_abs_embedding_index": 2379}, {"title": "AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments", "link_suffix": "/forum?id=ak7r4He1qH", "link": "https://openreview.net/forum?id=ak7r4He1qH", "pdf_link": "https://openreview.net/pdf?id=ak7r4He1qH", "keywords": "Language Agents, Medical Benchmark, Multimodal Benchmark, Multimodal Language Models", "abstract": "Evaluating large language models~(LLM) in clinical scenarios is crucial to assessing their potential clinical utility. Existing benchmarks rely heavily on static question-answering, which does not accurately depict the complex, sequential nature of clinical decision-making. Here, we introduce AgentClinic, a multimodal agent benchmark for evaluating LLMs in simulated clinical environments that include patient interactions, multimodal data collection under incomplete information, and the usage of various tools, resulting in an in-depth evaluation across nine medical specialties and seven languages.\nWe find that solving MedQA problems in the sequential decision-making format of AgentClinic is considerably more challenging, resulting in diagnostic accuracies that can drop to below a tenth of the original accuracy. Overall, we observe that agents sourced from Claude-3.5 outperform other LLM backbones in most settings. Nevertheless, we see stark differences in the LLMs\u2019 ability to make use of tools, such as experiential learning, adaptive retrieval, and reflection cycles. Strikingly, Llama-3 shows up to 92% relative improvements with the notebook tool that allows for writing and editing notes that persist across cases. To further scrutinize our clinical simulations, we leverage real-world electronic health records, perform a clinical reader study, perturb agents with biases, and explore novel patient-centric metrics that this interactive environment firstly enables.", "title_embedding_index": 2355, "title_abs_embedding_index": 2380}, {"title": "Disconnecting The Dots: Creating Leakage-Free Protein Datasets by Removal of Densely Connected Data Points", "link_suffix": "/forum?id=ifK9NFyrhn", "link": "https://openreview.net/forum?id=ifK9NFyrhn", "pdf_link": "https://openreview.net/pdf?id=ifK9NFyrhn", "keywords": "data splitting, clustering, biology, protein function prediction, protein representations", "abstract": "Biological systems arise through evolutionary processes that effectively render all biological data, at scales ranging from biomolecules to organisms, to be evolutionarily related. This poses a challenge to assessments of model generalization, as naive random splits do not safeguard against data leakage; all data points are in some sense related, and their degree of relatedness lies on a continuum. To address this challenge, various similarity metrics are typically used to cluster data prior to splitting to ensure dissimilarity of resulting partitions. However, as we show in this study, similarity thresholds that lead to well-behaved splits (large numbers of homogeneously sized clusters) must invariably be too permissive, thus only permitting assessment of weak generalization. Conversely, stringent thresholds that could in principle enable assessment of strong generalization typically fail to produce well-separated clusters, yielding one or a handful of very large clusters that span the entire dataset. Here, we propose a new data splitting methodology that optimally balances these competing considerations by relaxing the assumption that all data points must be retained. Instead, through a principled and judicious removal of highly central data points, our approach yields well-behaved data splits that enable assessment of extreme generalization regimes. We demonstrate its utility by investigating the impact of diverse proteins representations on protein function prediction. Our experiments confirm the robustness of our new methodology and provide insights into the utility and behavior of protein representations  under previously untested regimes of sequence and structure generalization.", "title_embedding_index": 2356, "title_abs_embedding_index": 2381}, {"title": "Multi-domain Distribution Learning for De Novo Drug Design", "link_suffix": "/forum?id=g3VCIM94ke", "link": "https://openreview.net/forum?id=g3VCIM94ke", "pdf_link": "https://openreview.net/pdf?id=g3VCIM94ke", "keywords": "Drug Discovery, Flow Matching, Markov Bridge, Equivariance", "abstract": "We introduce DrugFlow, a generative model for structure-based drug design that integrates continuous flow matching with discrete Markov bridges, demonstrating state-of-the-art performance in learning chemical, geometric, and physical aspects of three-dimensional protein-ligand data. We endow DrugFlow with an uncertainty estimate that is able to detect out-of-distribution samples. To further enhance the sampling process towards distribution regions with desirable metric values, we propose a joint preference alignment scheme applicable to both flow matching and Markov bridge frameworks. Furthermore, we extend our model to also explore the conformational landscape of the protein by jointly sampling side chain angles and molecules.", "title_embedding_index": 2357, "title_abs_embedding_index": 2382}, {"title": "Improving Defense Mechanisms for Subgraph-Structure Membership Inference Attacks", "link_suffix": "/forum?id=e5g53a4A0g", "link": "https://openreview.net/forum?id=e5g53a4A0g", "pdf_link": "https://openreview.net/pdf?id=e5g53a4A0g", "keywords": "Graph neural network, subgraph-substructure membership inference attack, 2-stage training", "abstract": "Graph neural networks (GNNs) are of significant importance in diverse real-world applications since they leverage powerful graph learning techniques to solve problems pertaining to social network mining and medical data analysis. Despite their practical relevance, GNNs remain vulnerable to adversarial attacks such as membership inference attacks (MIAs) which pose privacy risks by revealing whether specific data records were part of the training set of the model. While most existing research has focused on designing defense mechanisms for known node-level MIAs, and in particular, for determining if a certain node was used during training, only limited attention has been paid to subgraph-structure MIA (SMIA) problems. SMIA methods seek to infer whether a set of nodes forms a particular target structure of interest (such as a graph motif, e.g., clique or multi-hop path) in the training graph. The main contributions of our work are three-fold. The first is a novel robust defense mechanism for GNNs against SMIA attacks. It  combines an alternating train-test schedule with a flattening strategy to mitigate the attacks. The second contribution is a new end-to-end SMIA attack model that outperforms existing attacks by using multiset functions to generate learnable embeddings for collections of nodes. Extensive simulations reveal that the new attack model outperforms prior state-of-the-art attack models on GNNs by 12.31% across four datasets when no defense mechanism is present. With the new defense mechanism, one can achieve an average decrease of 14.30% in the attack AUROC and an 10.05% improvement in target model utility compared to classical defenses, even when using the improved attack scheme. The third contribution is a study that shows that our defense mechanism extends to node-level MIAs as well, offering similar improvements in attack resistance and utility.", "title_embedding_index": 2358, "title_abs_embedding_index": 2383}, {"title": "GIVE: Structured Reasoning with Knowledge Graph Inspired Veracity Extrapolation", "link_suffix": "/forum?id=ka4Nk1j55l", "link": "https://openreview.net/forum?id=ka4Nk1j55l", "pdf_link": "https://openreview.net/pdf?id=ka4Nk1j55l", "keywords": "Large Language Model, Structured Reasoning, Biomedical QA, Intelligent Agent", "abstract": "Existing retrieval-based reasoning approaches for large language models (LLMs) heavily rely on the density and quality of the non-parametric knowledge source to provide domain knowledge and explicit reasoning chain. However, inclusive knowledge sources are expensive and sometimes infeasible to build for scientific or corner domains. To tackle the challenges, we introduce Graph Inspired Veracity Extrapolation (GIVE), a novel reasoning framework that integrates the parametric and non-parametric memories to enhance both knowledge retrieval and faithful reasoning processes on very sparse knowledge graphs. By leveraging the external structured knowledge to inspire LLM to model the interconnections among relevant concepts, our method facilitates a more logical and step-wise reasoning approach akin to experts' problem-solving, rather than gold answer retrieval. Specifically, the framework prompts LLMs to decompose the query into crucial concepts and attributes, construct entity groups with relevant entities, and build an augmented reasoning chain by probing potential relationships among node pairs across these entity groups. Our method incorporates both factual and extrapolated linkages to enable comprehensive understanding and response generation. Extensive experiments on reasoning-intense benchmarks on biomedical and commonsense QA demonstrate the effectiveness of our proposed method. Specifically, GIVE enables GPT3.5-turbo to outperform advanced models like GPT4 without any additional training cost, thereby underscoring the efficacy of integrating structured information and internal reasoning ability of LLMs for tackling specialized tasks with limited external resources.", "title_embedding_index": 2359, "title_abs_embedding_index": 2384}, {"title": "Dynamic Kernel Sparsifiers", "link_suffix": "/forum?id=DjtJV3ke1j", "link": "https://openreview.net/forum?id=DjtJV3ke1j", "pdf_link": "https://openreview.net/pdf?id=DjtJV3ke1j", "keywords": "Sparsifiers, Optimization, Algorithms", "abstract": "A geometric graph  associated with a set of points $P= {x_1, x_2, \\cdots, x_n } \\subset \\mathbb{R}^d$ and a fixed kernel function $\\mathsf{K}:\\mathbb{R}^d\\times \\mathbb{R}^d\\to\\mathbb{R}_{\\geq 0}$ is a complete graph on $P$ such that the weight of edge $(x_i, x_j)$ is $\\mathsf{K}(x_i, x_j)$. We present a fully-dynamic data structure that maintains a spectral sparsifier of a geometric graph under updates that change the locations of points in $P$ one at a time. The update time of our data structure is $n^{o(1)}$ with high probability, and the initialization time is $n^{1+o(1)}$. Under certain assumption, our data structure can be made robust against adaptive adversaries, which makes our sparsifier applicable in iterative optimization algorithms.We further show that the Laplacian matrices corresponding to geometric graphs admit a randomized sketch for maintaining  matrix-vector multiplication and projection in $n^{o(1)}$ time, under \\emph{sparse} updates to the query vectors, or under modification of points in $P$.", "title_embedding_index": 2360, "title_abs_embedding_index": 2385}, {"title": "{\u03c4}-bench: A Benchmark for \\underline{T}ool-\\underline{A}gent-\\underline{U}ser Interaction in Real-World Domains", "link_suffix": "/forum?id=roNSXZpUDN", "link": "https://openreview.net/forum?id=roNSXZpUDN", "pdf_link": "https://openreview.net/pdf?id=roNSXZpUDN", "keywords": "language model, language agent, benchmark, user simulation, rule following", "abstract": "Existing benchmarks for language agents do not set them up to interact with human users or follow domain-specific rules, both of which are vital to safe and realistic deployment. We propose $\\tau$-bench, a benchmark with two domains (retail and airline) emulating dynamic conversations between a user (simulated by language models) and a customer service agent provided with domain-specific API tools and policy guidelines. We employ a efficient and faithful evaluation process that compares the database state at the end of a conversation with the annotated goal state, and propose a new metric (pass^k) to evaluate the reliability of agent behavior over multiple trials. Our experiments show that even state-of-the-art function calling agents (gpt-4o) succeed on $<50%$ of the tasks, and are terribly inconsistent (pass^8 < 25% in retail). Our findings point to the need for methods that can improve the ability of agents to act consistently and reliably follow rules.", "title_embedding_index": 2361, "title_abs_embedding_index": 2386}, {"title": "Improving Distribution Matching via Score-Based Priors and Structural Regularization", "link_suffix": "/forum?id=U2FQXhGvip", "link": "https://openreview.net/forum?id=U2FQXhGvip", "pdf_link": "https://openreview.net/pdf?id=U2FQXhGvip", "keywords": "distribution matching, score-based models, representation learning", "abstract": "Distribution matching (DM) can be applied to multiple tasks including fair classifi- cation, domain adaptation and domain translation. However, traditional variational DM methods such as VAE-based methods unnecessarily bias the latent distri- butions towards simple priors or fail to preserve semantic structure leading to suboptimal latent representations. To address these limitations, we propose novel VAE-based DM approach which incorporates a flexible score-based prior and a structure-preserving regularization. For score-based priors, the key challenge is that computing the likelihood is expensive. Yet, our key insight is that computing the likelihood is unnecessary for updating the encoder and thus we prove that the necessary gradients can be computed using only one score function evalu- ation. Additionally, we introduce a structure-preserving regularization inspired by the Gromov-Wasserstein distance, which explicitly encourages the retention of geometric structure in the latent space, even when the latent space has fewer dimensions than the observed space. Our framework further allows the integration of semantically meaningful structure from pretrained or foundation models into the latent space, ensuring that the representations preserve semantic structure that is informative and relevant to downstream tasks. We empirically demonstrate that our DM approach leads to better latent representations compared to similar methods for fair classification, domain adaptation, and domain translation tasks.", "title_embedding_index": 2362, "title_abs_embedding_index": 2387}, {"title": "Training Overparametrized Neural Networks in Sublinear Time", "link_suffix": "/forum?id=Zd2T7htqjV", "link": "https://openreview.net/forum?id=Zd2T7htqjV", "pdf_link": "https://openreview.net/pdf?id=Zd2T7htqjV", "keywords": "Overparametrization, Computational efficiency, Complexity, Lower bound, Training Algorithm", "abstract": "The success of deep learning comes at a tremendous computational and energy cost, and the scalability of training massively overparametrized neural networks is becoming a real  barrier to the progress of artificial intelligence (AI). Despite the popularity and low cost-per-iteration of traditional backpropagation via gradient decent, stochastic gradient descent (SGD) has prohibitive convergence rate in non-convex settings, both in theory and practice.To mitigate this cost, recent works have  proposed to employ alternative (Newton-type) training methods with much faster convergence rate, albeit with higher cost-per-iteration. \nFor a typical neural network with $m=\\mathrm{poly}(n)$ parameters and input batch of  $n$  datapoints in $\\mathbb{R}^d$, the previous work of \\cite{bpsw21} requires $\\sim mnd + n^3$ time per iteration. In this paper, we present a novel training method that requires only $m^{1-\\alpha} n d + n^3$ amortized time in the same overparametrized regime, where $\\alpha \\in (0.01,1)$ is some fixed constant. This method relies on a new and alternative view of neural networks, as a set of binary search trees, where each iteration corresponds to modifying a small subset of the nodes in the tree. We believe this view would have further applications in the design and analysis of deep neural networks (DNNs). We conclude a discussion of lower bound for the dynamic sensitive weight searching data structure we make use of, showing that under {\\sf SETH} or {\\sf OVC} from computational complexity, one cannot substantially improve our algorithm.", "title_embedding_index": 2363, "title_abs_embedding_index": 2388}, {"title": "Error Bounds for Deep Learning-based Uncertainty Propagation in SDEs", "link_suffix": "/forum?id=k5ixIlfHc0", "link": "https://openreview.net/forum?id=k5ixIlfHc0", "pdf_link": "https://openreview.net/pdf?id=k5ixIlfHc0", "keywords": "uncertainty propagation, physics-informed learning, learning error quantification, stochastic differential equations", "abstract": "Stochastic differential equations are commonly used to describe the evolution of stochastic processes. The uncertainty of such processes is best represented by the probability density function (PDF), whose evolution is governed by the Fokker-Planck partial differential equation (FP-PDE). However, it is generally infeasible to solve the FP-PDE in closed form. In this work, we show that physics-informed neural networks (PINNs) can be trained to approximate the solution PDF using existing methods. The main contribution is the analysis of the approximation error: we develop a theory to construct an arbitrary tight error bound with PINNs. In addition, we derive a practical error bound that can be efficiently constructed with existing training methods. Finally, we explain that this error-bound theory generalizes to approximate solutions of other linear PDEs. Several numerical experiments are conducted to demonstrate and validate the proposed methods.", "title_embedding_index": 2364, "title_abs_embedding_index": 2389}, {"title": "DynaBO: Dynamic Model Bayesian Optimization for Tokamak Control", "link_suffix": "/forum?id=SD4iBfAXZk", "link": "https://openreview.net/forum?id=SD4iBfAXZk", "pdf_link": "https://openreview.net/pdf?id=SD4iBfAXZk", "keywords": "Nuclear Fusion, Plasma Instabilities, Bayesian Optimization, Applied Machine Learning", "abstract": "Despite recent advances, state-of-the-art machine learning algorithms struggle considerably with control problems where data is scarce relative to model complexity. This problem is further exacerbated if the system changes over time, making past measurements less useful. While tools from reinforcement learning, supervised learning, and Bayesian optimization alleviate some of these issues, they do not address all of them at once. With these drawbacks in mind, we present a multi-scale Bayesian optimization for fast and data-efficient decision-making. Our pipeline combines a high-frequency data-driven dynamics model with a low-frequency Gaussian process, resulting in a high-level model with a prior that is specifically tailored to the dynamics model setting. By updating the Gaussian process during Bayesian optimization, our method adapts rapidly to new data points, allowing us to quickly process current high-quality data which is more representative of the system than past data. We apply our method to avoid tearing instabilities in a tokamak plasma, a control problem where modeling is difficult, and hardware changes potentially between experiments. Our approach is validated through offline testing on historical data and live experiments on the DIII-D tokamak. On the historical data, we show that our method outperforms a naive decision-making algorithm based exclusively on a recurrent neural network and past data. The live experiment corresponds to a high performance plasma scenario with very high likelihood of instabilities. Despite this base configuration, we achieve a 75% success rate in the live experiment, which represents an improvement of over 300% compared to historical data", "title_embedding_index": 2365, "title_abs_embedding_index": 2390}, {"title": "MolTextQA: A Curated Question-Answering Dataset and Benchmark for Molecular Structure-Text Relationship Learning", "link_suffix": "/forum?id=gwGHBD9ZKU", "link": "https://openreview.net/forum?id=gwGHBD9ZKU", "pdf_link": "https://openreview.net/pdf?id=gwGHBD9ZKU", "keywords": "molecule-text learning, question answering, datasets, benchmark, large language models", "abstract": "Recent advancements in AI have significantly enhanced molecular representation learning, which is crucial for predicting molecule properties and designing new molecules. Despite these advances, effectively utilizing the vast amount of molecular data available in textual form from databases and scholarly articles remains a challenge. Recently, a large body of research has focused on utilizing Large Language Models (LLMs) and multi-modal architectures to interpret textual information and link it with molecular structures. Nevertheless, existing datasets often lack specificity in evaluation, as well as direct comparisons and comprehensive benchmarking across different models and model classes. In this work, we construct a dataset specifically designed for evaluating models on structure-directed questions and textual description-based molecule retrieval, featuring over 500,000 question-answer pairs related to approximately 240,000 molecules from PubChem. Its structure enhances evaluation specificity and precision through the use of multiple-choice answers. Moreover, we benchmark various architectural classes fine-tuned using this dataset, including multi-modal architectures, and large language models, uncovering several insights. Our experiments indicate that the Galactica and MoleculeSTM models are the top performers in Molecule QA and Molecule Retrieval tasks respectively, achieving about 70% accuracy. We have made both the dataset and the fine-tuned models publicly available.", "title_embedding_index": 2366, "title_abs_embedding_index": 2391}, {"title": "Mixture-of-Agents Enhances Large Language Model Capabilities", "link_suffix": "/forum?id=h0ZfDIrj7T", "link": "https://openreview.net/forum?id=h0ZfDIrj7T", "pdf_link": "https://openreview.net/pdf?id=h0ZfDIrj7T", "keywords": "Multi-Agent Inference, Large Language Model", "abstract": "Recent advances in large language models (LLMs) demonstrate substantial capabilities in natural language understanding and generation tasks. With the growing number of LLMs, how to harness the collective expertise of multiple LLMs is an exciting open direction. Toward this goal, we propose a new approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents (MoA) methodology. In our approach, we construct a layered MoA architecture wherein each layer comprises multiple LLM agents. Each agent takes all the outputs from agents in the previous layer as auxiliary information in generating its response. MoA models achieves state-of-art performance on AlpacaEval 2.0, Arena-Hard, MT-Bench, and FLASK, surpassing GPT-4 Omni. For example, our MoA using only open-source LLMs achieves a score of 65.1% on AlpacaEval 2.0 compared to 57.5% by GPT-4 Omni.", "title_embedding_index": 2367, "title_abs_embedding_index": 2392}, {"title": "DEPfold: RNA Secondary Structure Prediction as Dependency Parsing.", "link_suffix": "/forum?id=DpLFmc09pC", "link": "https://openreview.net/forum?id=DpLFmc09pC", "pdf_link": "https://openreview.net/pdf?id=DpLFmc09pC", "keywords": "RNA secondary structure prediction, Dependency parsing, Biaffine attention, Pseudoknots, Pretrained Model, Deep learning", "abstract": "RNA secondary structure prediction is critical for understanding RNA function but remains challenging due to complex structural elements like pseudoknots and limited training data. We introduce DEPfold, a novel deep learning approach that reframes RNA secondary structure prediction as a dependency parsing problem. DEPfold presents three key innovations: (1) a biologically motivated transformation of RNA structures into labeled dependency trees, (2) a biaffine attention mechanism for joint prediction of base pairings and their types, and (3) an optimal tree decoding algorithm that enforces valid RNA structural constraints. Unlike traditional energy-based methods, DEPfold learns directly from annotated data and leverages pretrained language models to capture intricate RNA patterns. We evaluate DEPfold on both within-family and cross-family RNA datasets, demonstrating significant performance improvements over existing methods. On the RNAStrAlign dataset, DEPfold achieves an F$_1$ score of 0.985, predicting pseudoknots and long-range interactions. Notably, DEPfold shows strong performance in cross-family generalization when trained on data augmented by traditional energy-based models, outperforming existing methods on the bpRNA-new dataset. This demonstrates DEPfold's ability to effectively learn structural information beyond what traditional methods capture. Our approach bridges natural language processing (NLP) with RNA biology, providing a computationally efficient and adaptable tool for advancing RNA structure prediction and analysis.", "title_embedding_index": 2368, "title_abs_embedding_index": 2393}, {"title": "APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding", "link_suffix": "/forum?id=yUC8pU508S", "link": "https://openreview.net/forum?id=yUC8pU508S", "pdf_link": "https://openreview.net/pdf?id=yUC8pU508S", "keywords": "Parallel Encoding; Context-Augmented LLM; Efficient Inference; Context Window Expansion", "abstract": "Many modern language model applications, such as RAG and in-context learning, require the efficient combination of multiple external contexts to generate a response. Directly incorporating these contexts sequentially presents two challenges: (i) re-encoding each combined selection of contexts for every request creates a significant computational burden. (ii) concatenating selected contexts into a single sequence often exceeds LLM's context window limit. In this work, we explore the promising potential of parallel encoding as a solution to pre-cache the KV states of each context separately, allowing for direct loading and position reuse during inference. However, due to the misalignment of attention distribution, directly applying parallel encoding results in significant performance degradation. To enable accurate and efficient parallel encoding, we propose adaptive parallel encoding, which brings a shared prefix, additional scaling factor, and lower attention temperature to align the distribution of parallel encoding with sequential encoding. Experimental results on both ICL and RAG tasks tasks demonstrate an average improvement of 7.8% over standard parallel encoding. Comparing to sequential encoding, APE enhances performance by 2.9% for long context understanding while preserving 93% accuracy in few-shot learning. Efficiency evaluation demonstrates that APE achieves a 976$\\times$ speedup for a 512K context-augmented generation with a 256-token response.", "title_embedding_index": 2369, "title_abs_embedding_index": 2394}, {"title": "DIMS: Channel-Dependent and Seasonal-Trend Independent Transformer Using Multi-Stage Training for Time Series Forecasting", "link_suffix": "/forum?id=Kz10l3roV0", "link": "https://openreview.net/forum?id=Kz10l3roV0", "pdf_link": "https://openreview.net/pdf?id=Kz10l3roV0", "keywords": "Time series, Deep learning, Transformer", "abstract": "Due to the limited size of real-world time series data, current transformer-based time series forecasting algorithms often struggle with overfitting. Common techniques used to mitigate overfitting include channel-independence and seasonal-trend decomposition. However, channel-independent inevitably results in the loss of inter-channel dependencies, and existing seasonal-trend decomposition methods are insufficient in effectively mitigating overfitting. In this study, we propose DIMS, a time series forecasting model that uses multi-stage training to capture inter-channel dependencies while ensuring the independence of seasonal and trend components. The computation of channel dependency is postponed to the later stage, following the channel-independent training, while the seasonal and trend components remain fully independent during the early training phases. This approach enables the model to effectively capture inter-channel dependencies while minimizing overfitting. Experiments show that our model outperforms the state-of-the-art transformer-based models on several datasets.", "title_embedding_index": 2370, "title_abs_embedding_index": 2395}, {"title": "Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo", "link_suffix": "/forum?id=xoXn62FzD0", "link": "https://openreview.net/forum?id=xoXn62FzD0", "pdf_link": "https://openreview.net/pdf?id=xoXn62FzD0", "keywords": "Sequential Monte Carlo, Language Models, Semantic parsing, Bayesian inference, Probabilistic programming, SMC", "abstract": "A wide range of LLM applications require generating text that conforms to syntactic or semantic constraints. Imposing such constraints nontrivially alters the distribution over sequences, usually making exact sampling intractable. In this work, building on the Language Model Probabilistic Programming framework of Lew et al. (2023), we develop an approach to approximate inference for controlled LLM generation based on sequential Monte Carlo (SMC). Our SMC framework allows us to flexibly incorporate domain- and problem-specific constraints at inference time, and efficiently reallocate computation in light of new information during the course of generation. We demonstrate that our approach improves downstream performance on four challenging domains---Python code generation for data science, text-to-SQL, goal inference, and molecule synthesis. We compare to a number of alternative and ablated approaches, showing that our accuracy improvements are driven by better approximation to the full Bayesian posterior.", "title_embedding_index": 2371, "title_abs_embedding_index": 2396}, {"title": "Beyond Directed Acyclic Computation Graph with Cyclic Neural Network", "link_suffix": "/forum?id=9uswuRBLm0", "link": "https://openreview.net/forum?id=9uswuRBLm0", "pdf_link": "https://openreview.net/pdf?id=9uswuRBLm0", "keywords": "Artificial Intelligence, Neural Network, Cyclic Computation", "abstract": "This paper investigates a fundamental yet overlooked design principle of artificial neural networks (ANN): We do not need to build ANNs layer-by-layer sequentially to guarantee the Directed Acyclic Graph (DAG) property. Inspired by biological intelligence, where neurons form a complex, graph-structured network, we introduce the transformative Cyclic Neural Networks (Cyclic NN). It emulates biological neural systems' flexible and dynamic graph nature, allowing neuron connections in any graph-like structure, including cycles. This offers greater flexibility compared to the DAG structure of current ANNs. We further develop the Graph Over Multi-layer Perceptron, the first detailed model based on this new design paradigm. We experimentally validate the advantages of Cyclic NN on widely tested datasets in most generalized cases, demonstrating its superiority over current layer-by-layer DAG neural networks. With the support of Cyclic NN, the Forward-Forward training algorithm also firstly outperforms the current Back-Propagation algorithm. This research illustrates a transformative ANN design paradigm, a significant departure from current ANN designs, potentially leading to more biologically similar ANNs.", "title_embedding_index": 2372, "title_abs_embedding_index": 2397}, {"title": "Answer, Assemble, Ace: Understanding How LMs Answer Multiple Choice Questions", "link_suffix": "/forum?id=6NNA0MxhCH", "link": "https://openreview.net/forum?id=6NNA0MxhCH", "pdf_link": "https://openreview.net/pdf?id=6NNA0MxhCH", "keywords": "interpretability; multiple-choice question answering", "abstract": "Multiple-choice question answering (MCQA) is a key competence of performant transformer language models that is tested by mainstream benchmarks. However, recent evidence shows that models can have quite a range of performance, particularly when the task format is diversified slightly (such as by shuffling answer choice order). In this work we ask: how do successful models perform formatted MCQA? We employ vocabulary projection and activation patching methods to localize key hidden states that encode relevant information for predicting the correct answer. We find that prediction of a specific answer symbol is causally attributed to a few middle layers, and specifically their multi-head self-attention mechanisms. We show that subsequent layers increase the probability of the predicted answer symbol in vocabulary space, and that this probability increase is associated with a sparse set of attention heads with unique roles. We additionally uncover differences in how different models adjust to alternative symbols. Finally, we demonstrate that a synthetic task can disentangle sources of model error to pinpoint when a model has learned formatted MCQA, and show that an inability to separate answer symbol tokens in vocabulary space is a property of models unable to perform formatted MCQA tasks.", "title_embedding_index": 2373, "title_abs_embedding_index": 2398}, {"title": "pSAE-chiatry: Utilizing Sparse Autoencoders to Uncover Mental-Health-Related Features in Language Models", "link_suffix": "/forum?id=LQdaXixB0g", "link": "https://openreview.net/forum?id=LQdaXixB0g", "pdf_link": "https://openreview.net/pdf?id=LQdaXixB0g", "keywords": "mental health, psychiatry, interpretability", "abstract": "As AI-powered mental health chatbots become more prevalent, their inability to recognize and respond to psychiatric emergencies, such as suicidality and mania, raises significant safety concerns. This study explores the internal representations of mental-health-related features (MHRF) in the Gemma-2-2B language model, focusing on crises related to suicide, mania, and psychosis. Using a sparse autoencoder (GemmaScope-RES-16K11) and psychiatric expertise (from M.D. mental health clinicians), MHRF's were identified across all 25 layers of the model, finding 29 features related to suicide and 42 to sadness. However, no features related to mania or paranoia were identified, suggesting critical gaps in the model\u2019s ability to handle complex psychiatric symptoms. One feature pertaining to \"suicide\" was selected for further, directed study. Four prompts (two pertaining to homicide, two pertaining to suicide) were tested to evaluate the associated activations of this particular \"suicide\" feature, and this feature was preferentially activated by prompts pertaining to suicide, supporting the relevance of the identified features. Lastly, as proof-of-concept, steering Gemma-2-2B through enhancement of this \"suicide\" feature causally impacted model behavior, making Gemma-2-2B far more likely to discuss concepts related to suicide. These findings underscore the need for improved feature identification and modulation within AI models to enhance their safety and effectiveness in mental healthcare applications. Trigger warning: This work contains references to suicide.", "title_embedding_index": 2374, "title_abs_embedding_index": 2399}]
[{"title": "Diverse Genomic Embedding Benchmark for Functional Evaluation Across the Tree of Life", "link_suffix": "/forum?id=fopjVghcE2", "link": "https://openreview.net/forum?id=fopjVghcE2", "pdf_link": "https://openreview.net/pdf?id=fopjVghcE2", "keywords": "benchmark, genomics, proteins", "abstract": "Biological foundation models hold significant promise for deciphering complex biological functions. However, evaluating their performance on functional tasks remains challenging due to the lack of standardized benchmarks encompassing diverse sequences and functions. Existing functional annotations are often scarce, biased, and susceptible to train-test leakage, hindering robust evaluation. Furthermore, biological functions manifest at multiple scales, from individual residues to large genomic segments. To address these limitations, we introduce the Diverse Genomic Embedding Benchmark (DGEB), inspired by natural language embedding benchmarks. DGEB comprises six embedding tasks across 18 expert curated datasets, spanning sequences from all domains of life and encompassing both nucleic acid and amino acid modalities. Notably, four datasets enable direct comparison between models trained on different modalities. Benchmarking protein and genomic language models (pLMs and gLMs) on DGEB reveals performance saturation with model scaling on numerous tasks, especially on those with underrepresented sequences (e.g. Archaea). This highlights the limitations of existing modeling objectives and training data distributions for capturing diverse biological functions. DGEB is available as an open-source package with a public leaderboard at \n\\url{URL hidden for anonymity}.", "title_embedding_index": 5900, "title_abs_embedding_index": 5925}, {"title": "Vector Segmented and Recombined Adaptation for Scalable and Efficient Model Tuning", "link_suffix": "/forum?id=bT2iAIYFAg", "link": "https://openreview.net/forum?id=bT2iAIYFAg", "pdf_link": "https://openreview.net/pdf?id=bT2iAIYFAg", "keywords": "Parameter-efficient fine-tuning, Adaptation, Vector segmentation, Scalable", "abstract": "Among the most commonly utilized parameter-efficient fine-tuning (PEFT) methods, LoRA and its variations have achieved significant popularity. The Vector-based Random Matrix Adaptation (VeRA), one typical variant, utilizes random weights and projections to reduce the number of trainable parameters greatly. However, it requires additional GPU memory and computational resources, probably resulting in a lack of scalability that leads to performance bottlenecks in complex tasks. Besides, the inappropriate initialization of random matrices may affect model performance. To address these problems, we propose a new method called Vector Segmented and Recombined Adaptation (SeRA). SeRA segments input vectors into sub-vectors for individual dimensionality reduction, then introduces a square matrix to combine the information from the reduced sub-vectors, and finally expands the dimensionality independently to adapt the size of pre-trained model. SeRA allows for flexible increase of trainable parameters to enhance performance in complex tasks, and avoids the problem caused by random matrices initialization. Through evaluations on the image classification, cross-modal image-text retrieval, instruction-tuning and GLUE benchmark, we demonstrate the scalability and efficiency of SeRA. Furthermore, we utilize Singular Value Decomposition on the adaptation matrices of SeRA, to analyze how the information characteristics of the matrices change in different ranks and tasks. \nThe results can serve as the guide for selecting appropriate parameter amounts in different tasks.", "title_embedding_index": 5901, "title_abs_embedding_index": 5926}, {"title": "Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models", "link_suffix": "/forum?id=NOk7t8eKtc", "link": "https://openreview.net/forum?id=NOk7t8eKtc", "pdf_link": "https://openreview.net/pdf?id=NOk7t8eKtc", "keywords": "Large Language Models, Advanced Abilities Transferring, Multi-lingual Scenarios", "abstract": "Multi-lingual ability transfer has become increasingly important for the broad application of large language models~(LLMs). Existing work highly relies on training with the multi-lingual ability-related data, which may be not available for low-resource languages. To solve it,  we propose a $\\textbf{M}$ulti-lingual $\\textbf{A}$bility $\\textbf{E}$xtraction and $\\textbf{T}$ransfer approach, named as $\\textbf{MAET}$. Our key idea is to decompose and extract language-agnostic ability-related weights from LLMs, and transfer them across different languages by simple addition and subtraction operations without training. Specially, our MAET consists of the extraction and transfer stages. In the extraction stage, we firstly locate key neurons that are highly related to specific abilities, and then employ them to extract the transferable ability-specific weights. In the transfer stage, we further select the ability-related parameter tensors, and design the merging strategy based on the linguistic and ability specific weights, to build the multi-lingual ability-enhanced LLM. To demonstrate the effectiveness of our proposed approach, we conduct extensive experiments on mathematical and scientific tasks in both high-resource lingual and low-resource lingual scenarios. Experiment results have shown that MAET can effectively and efficiently extract and transfer the advanced abilities, and outperform training-based baselines methods. Our code and data will be publicly released.", "title_embedding_index": 5902, "title_abs_embedding_index": 5927}, {"title": "MERIT: Maximum-normalized Element-wise Ratio for Language Model Large-batch Training", "link_suffix": "/forum?id=glWOsse3TL", "link": "https://openreview.net/forum?id=glWOsse3TL", "pdf_link": "https://openreview.net/pdf?id=glWOsse3TL", "keywords": "large-batch training, max attention logit, language models", "abstract": "Large-batch training has become a cornerstone in accelerating the training of deep neural networks, yet it poses challenges in optimization and generalization. Existing optimizers like AdamW present performance degradation during language models' large-batch training, due to the information bottleneck of attention layers caused by the sharp increase of max attention logit. While the LAMB optimizer partially addresses this issue, some attention layers still experience sharply increased maximum attention logits. The reason is that $l_2$-norm-based trust ratios in LAMB are less effective in directly influencing extreme weight values. Furthermore, the weight-wise trust ratio in LAMB is error-prone due to overlooking relationships of weight values within rows or columns. Building on these observations, we propose a novel optimizer, MERIT, which leverages the max norm to calculate the trust ratio to directly constrain the max attention logit. Moreover, we further construct element-wise trust ratios to provide more robust update scaling by focusing on local weight structures. Extensive experiments of large-batch training across various sizes of GPT-2 models demonstrate the superior performance of MERIT. Notably, during the training of GPT-2 Medium, MERIT enables the use of a 6k batch size without any performance degradation compared to the standard batch size (480). This work highlights the importance of considering the max attention logit and finer granularity trust ratio calculation in large-batch training. It successfully improves the training stability and paves the way for larger batch usage, enabling faster development and iteration on large language models.", "title_embedding_index": 5903, "title_abs_embedding_index": 5928}, {"title": "Optimizing Preference Alignment with Differentiable NDCG Ranking", "link_suffix": "/forum?id=Lz5lOSC0zg", "link": "https://openreview.net/forum?id=Lz5lOSC0zg", "pdf_link": "https://openreview.net/pdf?id=Lz5lOSC0zg", "keywords": "Language models; Human preferences alignment", "abstract": "Aligning large language models with human preferences improves interaction quality and safety by ensuring outputs better reflect human values. A promising strategy involves Reinforcement Learning from Human Feedback (RLHF), starting with collecting and ranking responses generated by a supervised fine-tuning model to refine alignment. Current methods (DPO) focus on learning from pairwise preference data, categorizing responses into preferred and less preferred pairs, and optimizing by maximizing pairwise margins. Recent studies have uncovered a substantial discrepancy between the theoretical aspirations of preference learning and its real-world results. Current preference alignment techniques underperform expectations, with ranking accuracies below $60%$ on standard datasets. This suggests existing methods inadequately capture ideal preference relationships within sequences. To address this challenge, this paper introduces \\underline{D}irect \\underline{R}anking \\underline{P}reference \\underline{O}ptimization (DRPO), a novel method that views human preference alignment as a Learning-to-Rank (LTR) task. DRPO leverages NDCG, a widely used LTR metric, to optimize the ranking of responses within lists based on preference data, thereby enhancing ranking accuracies. Due to the nondifferentiability of NDCG, we propose diffNDCG loss, a differentiable approximation facilitated by a sorting network to simulate NDCG. Furthermore, to improve the quality of generated response, we propose a novel margin-based Adaptive Rank Policy Score. Extensive experiments have shown that DRPO outperforms existing baseline methods, enhancing the quality of the generated responses.", "title_embedding_index": 5904, "title_abs_embedding_index": 5929}, {"title": "Simple, Good, Fast: Self-Supervised World Models Free of Baggage", "link_suffix": "/forum?id=yFGR36PLDJ", "link": "https://openreview.net/forum?id=yFGR36PLDJ", "pdf_link": "https://openreview.net/pdf?id=yFGR36PLDJ", "keywords": "Reinforcement learning, World models, Self-supervised learning, Atari 100k", "abstract": "What are the essential components of world models? How far do we get with world models that are not employing RNNs, transformers, discrete representations, and image reconstructions? This paper introduces SGF, a Simple, Good, and Fast world model that uses self-supervised representation learning, captures short-time dependencies through frame and action stacking, and enhances robustness against model errors through data augmentation. We extensively discuss SGF\u2019s connections to established world models, evaluate the building blocks in ablation studies, and demonstrate good performance through quantitative comparisons on the Atari 100k benchmark. The source code will be made available.", "title_embedding_index": 5905, "title_abs_embedding_index": 5930}, {"title": "You Only Scan Once: Efficient Multi-dimension Sequential Modeling with LightNet", "link_suffix": "/forum?id=qK3XElJUbq", "link": "https://openreview.net/forum?id=qK3XElJUbq", "pdf_link": "https://openreview.net/pdf?id=qK3XElJUbq", "keywords": "LightNet, multi-dimensional sequential modeling", "abstract": "Linear attention mechanisms have gained prominence in causal language models due to their linear computational complexity and enhanced speed. However, the inherent decay mechanism in linear attention presents challenges when applied to multi-dimensional sequence modeling tasks, such as image processing and multi-modal learning. In these scenarios, the utilization of sequential scanning to establish a global receptive field necessitates multiple scans for multi-dimensional data, thereby leading to inefficiencies. This paper identifies the inefficiency caused by a \\enquote{multiplicative} linear recurrence and proposes an efficient alternative \\enquote{additive} linear recurrence to avoid the issue, as it can handle multi-dimensional data within a single scan. We further develop an efficient multi-dimensional sequential modeling framework called LightNet based on the new recurrence. Moreover, we present two new multi-dimensional linear relative positional encoding methods, MD-TPE and MD-LRPE to enhance the model's ability to discern positional information in multi-dimensional scenarios. Our empirical evaluations across various tasks, including image classification, image generation, bidirectional language modeling, and autoregressive language modeling, demonstrate the efficacy of LightNet, showcasing its potential as a versatile and efficient solution for multi-dimensional sequential modeling.", "title_embedding_index": 5906, "title_abs_embedding_index": 5931}, {"title": "A new framework for evaluating model out-of-distribution generalisation for the biochemical domain", "link_suffix": "/forum?id=qFZnAC4GHR", "link": "https://openreview.net/forum?id=qFZnAC4GHR", "pdf_link": "https://openreview.net/pdf?id=qFZnAC4GHR", "keywords": "Machine learning evaluation, AI4Science, Biochemistry, Proteins, Small molecules, Protein Language Models", "abstract": "Quantifying model generalization to out-of-distribution data has been a longstanding challenge in machine learning. Addressing this issue is crucial for leveraging machine learning in scientific discovery, where models must generalize to new molecules or materials. Current methods typically split data into train and test sets using various criteria \u2014 temporal, sequence identity, scaffold, or random cross-validation \u2014 before evaluating model performance. However, with so many splitting criteria available, existing approaches offer limited guidance on selecting the most appropriate one, and they do not provide mechanisms for incorporating prior knowledge about the target deployment distribution(s).To tackle this problem, we have developed a novel metric, AU-GOOD, which quantifies expected model performance under conditions of increasing dissimilarity between train and test sets, while also accounting for prior knowledge about the target deployment distribution(s), when available. This metric is broadly applicable to biochemical entities, including proteins, small molecules, nucleic acids, or cells; as long as a relevant similarity function is defined for them. Recognizing the wide range of similarity functions used in biochemistry, we propose criteria to guide the selection of the most appropriate metric for partitioning. We also introduce a new partitioning algorithm that generates more challenging test sets, and we propose statistical methods for comparing models based on AU-GOOD.Finally, we demonstrate the insights that can be gained from this framework by applying it to two different use cases: developing predictors for pharmaceutical properties of small molecules, and using protein language models as embeddings to build biophysical property predictors.", "title_embedding_index": 5907, "title_abs_embedding_index": 5932}, {"title": "Deep Sparse Latent Feature Models for Knowledge Graph Completion", "link_suffix": "/forum?id=KkVV561IMb", "link": "https://openreview.net/forum?id=KkVV561IMb", "pdf_link": "https://openreview.net/pdf?id=KkVV561IMb", "keywords": "Knowledge Graph Completion (KGC), Stochastic Blockmodels (SBMs), Variational Autoencoder (VAE)", "abstract": "Recent progress in knowledge graph completion (KGC) has focused on text-based approaches to address the challenges of large-scale knowledge graphs (KGs). Despite their achievements, these methods often overlook the intricate interconnections between entities, a key aspect of the underlying topological structure of a KG. Stochastic blockmodels (SBMs), particularly the latent feature relational model (LFRM), offer robust probabilistic frameworks that can dynamically capture latent community structures and enhance link prediction. In this paper, we introduce a novel framework of sparse latent feature models for KGC, optimized through a deep variational autoencoder (VAE). Our approach not only effectively completes missing triples but also provides clear interpretability of the latent structures, leveraging textual information. Comprehensive experiments on the WN18RR, FB15k-237, and Wikidata5M datasets show that our method significantly improves performance by revealing latent communities and producing more interpretable representations.", "title_embedding_index": 5908, "title_abs_embedding_index": 5933}, {"title": "TOP-ERL: Transformer-based Off-Policy Episodic Reinforcement Learning", "link_suffix": "/forum?id=N4NhVN30ph", "link": "https://openreview.net/forum?id=N4NhVN30ph", "pdf_link": "https://openreview.net/pdf?id=N4NhVN30ph", "keywords": "Value of sequences of actions, Reinforcement Learning, Transformer, Robot Manipulation, Movement Primitives.", "abstract": "This work introduces Transformer-based Off-Policy Episodic Reinforcement Learning (TOP-ERL), a novel algorithm that enables off-policy updates in the ERL framework. In ERL, policies predict entire action trajectories over multiple time steps instead of single actions at every time step. These trajectories are typically parameterized by trajectory generators such as  Movement Primitives (MP), allowing for smooth and efficient exploration over long horizons while capturing high-level temporal correlations. However, ERL methods are often constrained to on-policy frameworks due to the difficulty of evaluating state-action values for entire action sequences, limiting their sample efficiency and preventing the use of more efficient off-policy architectures. TOP-ERL addresses this shortcoming by segmenting long action sequences and estimating the state-action values for each segment using a transformer-based critic architecture alongside an n-step return estimation. These contributions result in efficient and stable training that is reflected in the empirical results conducted on sophisticated robot learning environments. TOP-ERL significantly outperforms state-of-the-art RL methods. Thorough ablation studies additionally show the impact of key design choices on the model performance.", "title_embedding_index": 5909, "title_abs_embedding_index": 5934}, {"title": "3DS: Decomposed Difficulty Data Selection\u2019s Case Study on LLM Medical Domain Adaptation", "link_suffix": "/forum?id=I5p1Gm8GFS", "link": "https://openreview.net/forum?id=I5p1Gm8GFS", "pdf_link": "https://openreview.net/pdf?id=I5p1Gm8GFS", "keywords": "supervised fine-tuning, domain adaptation, medical llm", "abstract": "Large Language Models (LLMs) excel in general tasks but struggle in specialized domains like healthcare due to limited domain-specific knowledge. Supervised Fine-Tuning (SFT) data construction for domain adaptation often relies on heuristic methods, such as GPT-4 annotation or manual data selection, with a data centric focus on presumed diverse, high-quality datasets. However, these methods overlook the model\u2019s inherent knowledge distribution, introducing noise, redundancy, and irrelevant data, leading to a mismatch between the selected data and the model\u2019s learning task, resulting in suboptimal performance. To address this, we propose a two-stage model-centric data selection framework, Decomposed Difficulty Data Selection (3DS), which aligns data with the model\u2019s knowledge distribution for optimized adaptation. In Stage 1, we apply Prompt-Driven Data Selection via Explicit Alignment, where the model filters irrelevant or redundant data based on its internal knowledge. In Stage 2, we perform Decomposed Difficulty Data Selection, where data selection is guided by our defined difficulty decomposition, using three metrics: Instruction Understanding, Response Confidence, and Response Correctness. Additionally, an attention-based importance weighting mechanism captures token importance for more accurate difficulty calibration. This two-stage approach ensures the selected data is not only aligned with the model\u2019s knowledge and preferences but also appropriately challenging for the model to learn, leading to more effective and targeted domain adaptation. In the case study of the medical domain, our extensive experiments on real-world healthcare datasets demonstrate the superiority of 3DS over existing methods in accuracy by over 5.29%. Our dataset and code will be open-sourced athttps://anonymous.4open.science/r/3DS-E67F.", "title_embedding_index": 5910, "title_abs_embedding_index": 5935}, {"title": "MetaGFN: Exploring Distant Modes with Adapted Metadynamics for Continuous GFlowNets", "link_suffix": "/forum?id=fBJo3wwZeJ", "link": "https://openreview.net/forum?id=fBJo3wwZeJ", "pdf_link": "https://openreview.net/pdf?id=fBJo3wwZeJ", "keywords": "GFlowNets, metadynamics, exploration, sampling", "abstract": "Generative Flow Networks (GFlowNets) are a class of generative models that sample objects in proportion to a specified reward function through a learned policy. They can be trained either on-policy or off-policy, needing a balance between exploration and exploitation for fast convergence to a target distribution. While exploration strategies for discrete GFlowNets have been studied, exploration in the continuous case remains to be investigated, despite the potential for novel exploration algorithms due to the local connectedness of continuous domains. Here, we introduce Adapted Metadynamics, a variant of metadynamics that can be applied to arbitrary black-box reward functions on continuous domains. We use Adapted Metadynamics as an exploration strategy for continuous GFlowNets. We show several continuous domains where the resulting algorithm, MetaGFN, accelerates convergence to the target distribution and discovers more distant reward modes than previous off-policy exploration strategies used for GFlowNets.", "title_embedding_index": 5911, "title_abs_embedding_index": 5936}, {"title": "Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback", "link_suffix": "/forum?id=bAdSmSR10C", "link": "https://openreview.net/forum?id=bAdSmSR10C", "pdf_link": "https://openreview.net/pdf?id=bAdSmSR10C", "keywords": "Text-to-speech synthesis, learning from human feedback, reinforcement learning, audio generation", "abstract": "In recent years, text-to-speech (TTS) technology has witnessed impressive advancements, particularly with large-scale training datasets, showcasing human-level speech quality and impressive zero-shot capabilities on unseen speakers. However, despite human subjective evaluations, such as the mean opinion score (MOS), remaining the gold standard for assessing the quality of synthetic speech, even state-of-the-art TTS approaches have kept human feedback isolated from training that resulted in mismatched training objectives and evaluation metrics. In this work, we investigate a novel topic of integrating subjective human evaluation into the TTS training loop. Inspired by the recent success of reinforcement learning from human feedback, we propose a comprehensive sampling-annotating-learning framework tailored to TTS optimization, namely uncertainty-aware optimization (UNO). Specifically, UNO eliminates the need for a reward model or preference data by directly maximizing the utility of speech generations while considering the uncertainty that lies in the inherent variability in subjective human speech perception and evaluations. Experimental results of both subjective and objective evaluations demonstrate that UNO considerably improves the zero-shot performance of TTS models in terms of MOS, word error rate, and speaker similarity. Additionally, we present a remarkable ability of UNO that it can adapt to the desired speaking style in emotional TTS seamlessly and flexibly.", "title_embedding_index": 5912, "title_abs_embedding_index": 5937}, {"title": "Task and Model Agnostic Differentially Private Graph Neural Networks via Coarsening", "link_suffix": "/forum?id=E9NQUvbsT1", "link": "https://openreview.net/forum?id=E9NQUvbsT1", "pdf_link": "https://openreview.net/pdf?id=E9NQUvbsT1", "keywords": "Graph Neural Network (GNN), Differential Privacy (DP), Graph Coarsening", "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for analyzing graph-structured data, deriving representations by aggregating information from neighboring nodes. However, this aggregation process inherently increases the risk of exposing confidential data, as a single node may influence the inference process for multiple nodes simultaneously. To mitigate this risk, researchers have explored differentially private training methods for GNN models. Existing privacy-preserving approaches, however, face significant challenges. They often incur high computational costs during training or struggle to generalize across various GNN models and task objectives. To address these limitations, we introduce Differentially Private Graph Coarsening (DPGC), a novel method that tackles two key challenges in GNN training: scalability and privacy guarantees that are independent of the downstream task or GNN model. Through comprehensive experiments on six datasets across diverse prediction tasks, we demonstrate that  DPGC sets new benchmarks in graph coarsening. Our method achieves superior compression-accuracy trade-offs while maintaining robust privacy guarantees, outperforming state-of-the-art baselines in this domain.", "title_embedding_index": 5913, "title_abs_embedding_index": 5938}, {"title": "Trajectory-level Data Generation with Better Alignment for Offline Imitation Learning", "link_suffix": "/forum?id=kCLu4s2Xbu", "link": "https://openreview.net/forum?id=kCLu4s2Xbu", "pdf_link": "https://openreview.net/pdf?id=kCLu4s2Xbu", "keywords": "offline imitation learning, behavior cloning, trajectory-level data generation, high-alignment trajectories", "abstract": "Offline reinforcement learning (RL) relies heavily on densely precise reward signals, which are labor-intensive and challenging to obtain in many real-world scenarios. To tackle this challenge, offline imitation learning (IL) extracts optimal policies from expert demonstrations and datasets without reward labels. However, the scarcity of expert data and the abundance of suboptimal trajectories within the dataset impede the application of supervised learning methods like behavior cloning (BC). While previous research has focused on learning importance weights for BC or reward functions to integrate with offline RL algorithms, these approaches often result in suboptimal policy performance due to training instabilities and inaccuracies in learned weights or rewards. To address this problem, we introduce Trajectory-level Data Generation with Better Alignment (TDGBA), an algorithm that leverages alignment measures between unlabeled trajectories and expert demonstrations to guide a diffusion model in generating highly aligned trajectories. With these trajectories, BC can be directly applied to extract optimal polices without the need for weight or reward learning. Moreover, to ensure high fidelity and diversity in the generated trajectories and to make the learning more stable, the implicit expert preference that can fully exploit the unlabeled data is employed in the training of the diffusion model. Experimental results on the D4RL benchmarks demonstrate that TDGBA significantly outperforms state-of-the-art offline IL methods. Additionally, the analysis of the generated trajectories shows the effectiveness of incorporating the diffusion model and implicit expert preference for trajectory-level data generation.", "title_embedding_index": 5914, "title_abs_embedding_index": 5939}, {"title": "Certified Defense Against Complex Adversarial Attacks with Dynamic Smoothing", "link_suffix": "/forum?id=85Eej2kUHQ", "link": "https://openreview.net/forum?id=85Eej2kUHQ", "pdf_link": "https://openreview.net/pdf?id=85Eej2kUHQ", "keywords": "AI safety, adversarial robustness, randomized smoothing", "abstract": "Randomized smoothing has emerged as a certified defence mechanism with probabilistic guarantees that works at scale. However, current randomized smoothing methods offer theoretical guarantees that are limited by their reliance on specific noise distributions, and they struggle to handle complex adversarial attacks. In this paper, we propose a novel certification method based on randomized smoothing designed to handle complex adversarial attacks, including combinations of multiple attack types. We call this method Dynamic Smoothing (DSmooth). Our key idea is to incorporate more general distributions for smoothing then isotopic Gaussian noise, for which probabilistic guarantees can be derived in terms of the Mahalanobis distance. These general distributions make the smoothed classifier more robust against a wide range of threats, including localized adversarial attacks and multi-attacks. We validate the performance of our method experimentally on challenging threat models using CIFAR-10 and ImageNet, and demonstrate its superiority over state-of-the-art defenses in terms of certified accuracy. Our results show that the proposed method significantly improves the robustness of machine learning models against complex attacks, advancing their suitability for use in safety-critical applications. Code: [removed for review]", "title_embedding_index": 5915, "title_abs_embedding_index": 5940}, {"title": "Can the Training Loss be Predictive for Out-of-Distribution Generalization?", "link_suffix": "/forum?id=pcIDLhnYL9", "link": "https://openreview.net/forum?id=pcIDLhnYL9", "pdf_link": "https://openreview.net/pdf?id=pcIDLhnYL9", "keywords": "deep learning, OOD generalization, signal propagation, hyper-parameter search", "abstract": "Traditional model selection in deep learning relies on carefully tuning several hyper-parameters (HPs) controlling regularization strength on held-out validation data, which can be challenging to obtain in scarce-data scenarios or may not accurately reflect real-world deployment conditions due to distribution shifts.\nMotivated by such issues, this paper investigates the potential of using solely the training loss to predict the generalization performance of neural networks on out-of-distribution (OOD) test scenarios.\nOur analysis reveals that preserving consistent prediction variance across training and testing distributions is essential for establishing a correlation between training loss and OOD generalization.\nWe propose architectural adjustments to ensure $\\textit{variance preservation}$, enabling reliable model selection based on training loss alone, even in over-parameterized settings with a sample-to-parameter ratio exceeding four orders of magnitude.\nWe extensively assess the model-selection capabilities of $\\textit{variance-preserving}$ architectures on several scarce data, domain-shift, and corruption benchmarks by optimizing HPs such as learning rate, weight decay, batch size, and data augmentation strength.", "title_embedding_index": 5916, "title_abs_embedding_index": 5941}, {"title": "Long-Short Decision Transformer: Bridging Global and Local Dependencies for Generalized Decision-Making", "link_suffix": "/forum?id=NHMuM84tRT", "link": "https://openreview.net/forum?id=NHMuM84tRT", "pdf_link": "https://openreview.net/pdf?id=NHMuM84tRT", "keywords": "Deep Learning, Reinforcement Learning, Transformer, Decision Transformer, Long-Short Decsion Transformer, OfflineRL", "abstract": "Decision Transformers (DTs) effectively capture long-range dependencies using self-attention but struggle with fine-grained local relationships, especially the Markovian properties in many offline-RL datasets. Conversely, Decision Convformer (DC) utilizes convolutional filters for capturing local patterns but shows limitations in tasks demanding long-term dependencies, such as Maze2d. To address these limitations and leverage both strengths, we propose the Long-Short Decision Transformer (LSDT), a general-purpose architecture to effectively capture global and local dependencies across two specialized parallel branches (self-attention and convolution). We explore how these branches complement each other by modeling various ranged dependencies across different environments, and compare it against other baselines. Experimental results demonstrate our LSDT achieves state-of-the-art performance and notable gains over the standard DT in D4RL offline RL benchmark. Leveraging the parallel architecture, LSDT performs consistently on diverse datasets, including Markovian and non-Markovian. We also demonstrate the flexibility of LSDT's architecture, where its specialized branches can be replaced or integrated into models like DC to improve their performance in capturing diverse dependencies. Finally, we also highlight the role of goal states in improving decision-making for goal-reaching tasks like Antmaze.", "title_embedding_index": 5917, "title_abs_embedding_index": 5942}, {"title": "What Do You See? Enhancing Zero-Shot Image Classification with Multimodal Large Language Models", "link_suffix": "/forum?id=O9NQLOjrdu", "link": "https://openreview.net/forum?id=O9NQLOjrdu", "pdf_link": "https://openreview.net/pdf?id=O9NQLOjrdu", "keywords": "large language models, zero shot image classification, cross modal representation", "abstract": "Large language models (LLMs) have been effectively used for many computer vision tasks, including image classification. In this paper, we present a simple yet effective approach for zero-shot image classification using multimodal LLMs. By employing multimodal LLMs, we generate comprehensive textual representations from input images. These textual representations are then utilized to generate fixed-dimensional features in a cross-modal embedding space. Subsequently, these features are fused together to perform zero-shot classification using a linear classifier. Our method does not require prompt engineering for each dataset; instead, we use a single, straightforward, set of prompts across all datasets. We evaluated our method on several datasets, and our results demonstrate its remarkable effectiveness, surpassing benchmark accuracy on multiple datasets. On average, our method achieved an accuracy gain of 4.1 percentage points, with an increase of 6.8 percentage points on the ImageNet dataset, compared to prior methods. Our findings highlight the potential of multimodal LLMs to enhance computer vision tasks such as zero-shot image classification, offering a significant improvement over traditional methods.", "title_embedding_index": 5918, "title_abs_embedding_index": 5943}, {"title": "Low-Rank Quantization-Aware Training for LLMs", "link_suffix": "/forum?id=dIK0EfZFO9", "link": "https://openreview.net/forum?id=dIK0EfZFO9", "pdf_link": "https://openreview.net/pdf?id=dIK0EfZFO9", "keywords": "transformers, LLM, quantization, quantization-aware training, QAT, low-rank adaptation, PEFT, memory efficiency, inference efficiency", "abstract": "In this paper we propose LR-QAT \u2013 a lightweight and memory-efficient QAT algorithm for LLMs. LR-QAT employs several components to save memory without sacrificing performance: (a) low-rank quantization-aware reparameterization; (b) downcasting operation using fixed-point or double-packing and (c) checkpointing. Unlike most related work, our method (i) is inference-efficient, leading to no additional overhead compared to traditional PTQ; (ii) can be seen as a general extended pre-training framework, meaning that the resulting model can still be utilized for any downstream task afterwards; (iii) is orthogonal to most of recent PTQ methods and thus can be seamlessly combined with them. We apply LR-QAT to the LLaMA-1/2/3 and Mistral model families and validate its effectiveness on several downstream tasks. Our method outperforms most of recent LLM quantization approaches and reaches the same model performance as full-model QAT at the fraction of its memory usage. Specifically, we can train a 7B LLM on a single consumer grade GPU with 24GB memory.", "title_embedding_index": 5919, "title_abs_embedding_index": 5944}, {"title": "RACCOON: Regret-based Adaptive Curricula for Cooperation", "link_suffix": "/forum?id=CY6bFF9A3O", "link": "https://openreview.net/forum?id=CY6bFF9A3O", "pdf_link": "https://openreview.net/pdf?id=CY6bFF9A3O", "keywords": "unsupervised environment design, multi-agent reinforcement learning, cooperation, autocurricula, ad-hoc teamwork, zero-shot coordination", "abstract": "Overfitting to training partners is a common problem in fully-cooperative multi-agent settings, leading to poor zero-shot transfer to novel partners. A popular solution is to train an agent with a diverse population of training partners. However, previous work lacks a principled approach for selecting partners from this population during training, usually sampling at random. We argue that partner sampling is an important and overlooked problem, and motivated by the success of regret-based Unsupervised Environment Design, we propose Regret-based Adaptive Curricula for Cooperation (RACCOON), a novel a method which prioritises high-regret partners and tasks. We test RACCOON in the Overcooked environment, and demonstrate that it leads to sample efficiency gains and increased robustness across diverse partners and tasks, compared with strong baselines. We further analyse the nature of the induced curricula, and conclude with discussions on the limitations of cooperative regret and directions for future work.", "title_embedding_index": 5920, "title_abs_embedding_index": 5945}, {"title": "On the Expressiveness of Rational ReLU Neural Networks With Bounded Depth", "link_suffix": "/forum?id=uREg3OHjLL", "link": "https://openreview.net/forum?id=uREg3OHjLL", "pdf_link": "https://openreview.net/pdf?id=uREg3OHjLL", "keywords": "expressive power, depth, exact representations, ReLU networks, mixed volumes, lattice polytopes, number theory", "abstract": "To confirm that the expressive power of ReLU neural networks grows with their depth, the function $F_n = \\max (0,x_1,\\ldots,x_n )$ has been considered in the literature.\n  A conjecture by Hertrich, Basu, Di Summa, and Skutella [NeurIPS 2021] states that any ReLU network that exactly represents $F_n$ has at least $\\lceil \\log_2 (n+1) \\rceil$ hidden layers.\n  The conjecture has recently been confirmed for networks with integer weights by Haase, Hertrich, and Loho [ICLR~2023].We follow up on this line of research and show that, within ReLU networks whose weights are decimal fractions, $F_n$ can only be represented by networks with at least $\\lceil \\log_3 (n+1) \\rceil$ hidden layers.\n  Moreover, if all weights are $N$-ary fractions, then $F_n$ can only be represented by networks with at least $\\Omega( \\frac{\\ln n}{\\ln \\ln N})$ layers.\n  These results are a  partial confirmation of the above conjecture for rational ReLU networks, and provide the first non-constant lower bound on the depth of practically relevant ReLU networks.", "title_embedding_index": 5921, "title_abs_embedding_index": 5946}, {"title": "Uncertainty-aware Human Mobility Modeling and Anomaly Detection", "link_suffix": "/forum?id=Pxik3T6Mn9", "link": "https://openreview.net/forum?id=Pxik3T6Mn9", "pdf_link": "https://openreview.net/pdf?id=Pxik3T6Mn9", "keywords": "uncertaitnty, human mobility, anomaly detection", "abstract": "Given the GPS coordinates of a large collection of human agents over time, how can we model their mobility behavior toward effective anomaly detection (e.g. for bad-actor or malicious behavior detection) without any labeled data?\nHuman mobility and trajectory modeling have been studied extensively with varying capacity to handle complex input, and performance-efficiency trade-offs. With the arrival of more expressive models in machine learning, we attempt to model GPS data as a sequence of stay-point events, each with a set of characterizing spatiotemporal features, and leverage modern sequence models such as Transformers for un/self-supervised training and inference. Notably, driven by the inherent stochasticity of certain individuals' behavior, we equip our model with aleatoric/data uncertainty estimation. In addition, to handle data sparsity of a large variety of behaviors, we incorporate epistemic/model uncertainty into our model. Together, aleatoric and epistemic uncertainty enable a robust loss and training dynamics, as well as uncertainty-aware decision making in anomaly scoring. Experiments on large expert-simulated datasets with tens of thousands of agents demonstrate the effectiveness of our model against both forecasting and anomaly detection baselines. All code is available athttps://anonymous.4open.science/r/mobility-ad.", "title_embedding_index": 5922, "title_abs_embedding_index": 5947}, {"title": "LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs - Evaluation through Synthetic Data Generation", "link_suffix": "/forum?id=jLd7OyAD4Y", "link": "https://openreview.net/forum?id=jLd7OyAD4Y", "pdf_link": "https://openreview.net/pdf?id=jLd7OyAD4Y", "keywords": "LLM, GRN, Causal Discovery, Synthetic Data Generation", "abstract": "Gene regulatory networks (GRNs) represent the causal relationships between transcription factors (TFs) and target genes in single-cell RNA sequencing (scRNA-seq) data. Understanding these networks is crucial for uncovering disease mechanisms and identifying therapeutic targets. In this work, we investigate the potential of large language models (LLMs) for GRN discovery, leveraging their learned biological knowledge alone or in combination with traditional statistical methods. We employ a task-based evaluation strategy to address the challenge of unavailable ground truth causal graphs. Specifically, we use the GRNs suggested by LLMs to guide causal synthetic data generation and compare the resulting data against the original dataset. Our statistical and biological assessments show that LLMs can support statistical modeling and data synthesis for biological research.", "title_embedding_index": 5923, "title_abs_embedding_index": 5948}, {"title": "Eliciting Black-Box Representations from LLMs through Self-Queries", "link_suffix": "/forum?id=3LifGYAD0W", "link": "https://openreview.net/forum?id=3LifGYAD0W", "pdf_link": "https://openreview.net/pdf?id=3LifGYAD0W", "keywords": "LLMs, representations", "abstract": "As large language models (LLMs) are increasingly relied on in AI systems, predicting when they make mistakes is crucial. While a great deal of work in the field uses internal representations to interpret model behavior, these representations are inaccessible when given solely black-box access through an API. In this paper, we extract representations of LLMs in a black-box manner by asking simple elicitation questions and using the probabilities of different responses \\emph{as} the representation itself. These representations can, in turn, be used to produce reliable predictors of model behavior. We demonstrate that training a linear model on these low-dimensional representations produces reliable and generalizable predictors of model performance at the instance level (e.g., if a particular generation correctly answers a question). Remarkably, these can often outperform white-box linear predictors that operate over a model\u2019s hidden state or the full distribution over its vocabulary. In addition, we demonstrate that these extracted representations can be used to evaluate more nuanced aspects of a language model's state. For instance, they can be used to distinguish between GPT-3.5 and a version of GPT-3.5 affected by an adversarial system prompt that makes its answers often incorrect. Furthermore, these representations can reliably distinguish between different model architectures and sizes, enabling the detection of misrepresented models provided through an API (e.g., identifying if GPT-3.5 is supplied instead of GPT-4).", "title_embedding_index": 5924, "title_abs_embedding_index": 5949}]
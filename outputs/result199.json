[{"title": "Unlocking Guidance for Discrete State-Space Diffusion and Flow Models", "link_suffix": "/forum?id=XsgHl54yO7", "link": "https://openreview.net/forum?id=XsgHl54yO7", "pdf_link": "https://openreview.net/pdf?id=XsgHl54yO7", "keywords": "discrete state-space generative models, diffusion, flow-matching, flow models, guidance, protein design", "abstract": "Generative models on discrete state-spaces have a wide range of potential applications, particularly in the domain of natural sciences. In continuous state-spaces, controllable and flexible generation of samples with desired properties has been realized using guidance on diffusion and flow models. However, these guidance approaches are not readily amenable to discrete state-space models. Consequently, we introduce a general and principled method for applying guidance on such models. Our method depends on leveraging continuous-time Markov processes on discrete state-spaces, which unlocks computational tractability for sampling from a desired guided distribution. We demonstrate the utility of our approach, Discrete Guidance, on a range of applications including guided generation of small-molecules, DNA sequences and protein sequences.", "title_embedding_index": 9900, "title_abs_embedding_index": 9925}, {"title": "Conditioning on Time is All You Need for Synthetic Survival Data Generation", "link_suffix": "/forum?id=fHqwCsDK1z", "link": "https://openreview.net/forum?id=fHqwCsDK1z", "pdf_link": "https://openreview.net/pdf?id=fHqwCsDK1z", "keywords": "Survival Data Generation, Survival Analysis, Tabular Data Generation, Generative Modeling", "abstract": "Synthetic data generation holds considerable promise, offering avenues to enhance privacy, fairness, and data accessibility. Despite the availability of various methods for generating synthetic tabular data, challenges persist, particularly in specialized applications such as survival analysis. One significant obstacle in survival data generation is censoring, which manifests as not knowing the precise timing of observed (target) events for certain instances. Existing methods face difficulties in accurately reproducing the real distribution of event times for both observed (uncensored) events and censored events, i.e., the generated event-time distributions do not accurately match the underlying distributions of the real data. So motivated, we propose a simple paradigm to produce synthetic survival data by generating covariates conditioned on event times (and censoring indicators), thus allowing one to reuse existing conditional generative models for tabular data without significant computational overhead, and without making assumptions about the (usually unknown) generation mechanism underlying censoring. We evaluate this method via extensive experiments on real-world datasets. Our methodology outperforms multiple competitive baselines at generating survival data, while improving the performance of downstream survival models trained on it and tested on real data. Importantly, our approach achieves these improvements without compromising patient privacy, offering a balanced solution for synthetic survival data generation.", "title_embedding_index": 9901, "title_abs_embedding_index": 9926}, {"title": "An Empirical Study on the Application of TDA to Deep Neural Networks", "link_suffix": "/forum?id=neDGc4slhd", "link": "https://openreview.net/forum?id=neDGc4slhd", "pdf_link": "https://openreview.net/pdf?id=neDGc4slhd", "keywords": "deep neural networks, convolutional networks, topological data analysis, persistent homology, Betti numbers, Betti curves, Betti curve similarity, ImageNet, functional graph", "abstract": "This study aims to analyze the global structure of the functional subgraph of DNNs using tools from topological data analysis (TDA), namely persistent homology (PH) and the curve similarity. Using these methods we present an empirical study on the application of TDA to DNNs in order to gain a better understanding of their architecture and to provide a framework for a similarity measure between DNNs. The study is conducted by training several convolutional neural networks (CNNs) on disjoint subsets of the ImageNet dataset and then by analyzing the structure of their functional graphs across datasets using the Betti curve similarity. Results show that the Betti curve similarity is able to distinguish between different DNN models across datasets and can be a tool for detecting a departure from previous internal representations of those datasets, providing a new method for the analysis of DNNs and a potential path forward for their theoretical development.", "title_embedding_index": 9902, "title_abs_embedding_index": 9927}, {"title": "A Dual-Metric Approach for Model Selection in self-supervised learning for histopathology", "link_suffix": "/forum?id=i4ouG6Kc8M", "link": "https://openreview.net/forum?id=i4ouG6Kc8M", "pdf_link": "https://openreview.net/pdf?id=i4ouG6Kc8M", "keywords": "Model selection, Self-supervised Learning, Histopathology, Vision Transformer, Deep Learning", "abstract": "Selecting appropriate models during self-supervised training of vision transformers in histopathology is challenging. Recent efforts to quantify the quality of self-supervised learning representations through rank estimation approaches have shown promise in natural image classification tasks. However, their effectiveness in histopathology, particularly for non-linear tasks such as instance segmentation and classification from whole slide images, remains unexplored. This study proposes an approach for model selection in histopathology by combining task-specific metrics (such as accuracy) and task agnostic metrics (such as rank estimation). This work shows that by training several small-scale histopathology models and applying the proposed model selection approach, one can achieve instance segmentation performance comparable to state-of-the-art models trained on much larger datasets. The proposed approach also allows for obtaining a model based on the type of downstream task. Towards this end, three types of model selection based on the downstream task performance were evaluated: classification-best, segmentation-best, and a best all-round one. When evaluated on held-out classification and weakly supervised learning tasks, the most performant checkpoints often occur earlier in training, indicating potential performance saturation mid way in the training for histopathology models. These results highlight the importance of appropriate model selection for self-supervised learning in histopathology.", "title_embedding_index": 9903, "title_abs_embedding_index": 9928}, {"title": "LoGra-Med: Long-Context Multi-Graph Alignment for Medical Visual-Language Models", "link_suffix": "/forum?id=SOsotxYtPC", "link": "https://openreview.net/forum?id=SOsotxYtPC", "pdf_link": "https://openreview.net/pdf?id=SOsotxYtPC", "keywords": "multi-modal LLM, AI for Healthcare, multi-modal learning", "abstract": "State-of-the-art medical multi-modal large language models (med-MLLM), such as LLAVA-MED or BIOMEDGPT, leverage instruction-following data in their pre-training stages. However, those models primarily focus on scaling the model size and data volume to boost performance while mainly relying on the autoregressive learning objectives. Surprisingly, we reveal that such learning schemes might result in a weak alignment between vision and language modalities, making these models highly reliant on extensive pre-training datasets \u2014 a significant challenge in medical domains due to the expensive and time-consuming nature of curating high-quality instruction-following instances. We address this challenge with a new multi-graph alignment algorithm, namely LOGRA-MED, which enforces triplet correlations on the latent embedding space among image modalities, conversation-based descriptions, and extended contextual captions. Owing to this technique, the model is encouraged to capture the semantic meaning of the context, handle linguistic variability where the captions or questions may differ from training instances, and learn cross-modal associations, linking visual elements with various textual interpretations. To scale our algorithm to the med-MLLM setting, we also design an efficient end-to-end learning scheme based on advanced black-box gradient-estimation techniques that permit fast forward and backward steps through the LLM model (LLaMa 7B). Empirical results show\nthat we can match the performance of LLAVA-Med pre-trained on 600K image-text pairs from PMC-15M for Medical VQA tasks and significantly outperform it when trained on only 10% of the data. For instance, on VQA-RAD, we exceed LLAVA-Med (both trained on 10%) by 20.13% and achieve near parity with the 100% pre-training setting (72.52% vs. 72.64%). Additionally, we also surpass other SOTA pre-training methods and med-MLLM such as BIOMEDGPT on visual chatbot or RADFM on zero-shot image classification with VQA, showcasing the power of multi-graph alignment in improving vision-language integration for medical-MLLM.", "title_embedding_index": 9904, "title_abs_embedding_index": 9929}, {"title": "NeurFlow: Interpreting Neural Networks through Critical Neuron Groups and Functional Interactions", "link_suffix": "/forum?id=GdbQyFOUlJ", "link": "https://openreview.net/forum?id=GdbQyFOUlJ", "pdf_link": "https://openreview.net/pdf?id=GdbQyFOUlJ", "keywords": "Explainable AI, Functional Interactions, Critical Neurons, Concept Circuits", "abstract": "Understanding the inner workings of neural networks is essential for enhancing model performance and interpretability. Current research predominantly focuses on individual neuron analysis, which suffers from challenges in interpreting neurons that encode multiple, unrelated features. In this paper, we propose a novel framework that shifts the focus from analyzing individual neurons to examining groups of critical neurons and their functional interactions that significantly influence model behavior. Our automated framework, NeurFlow, first identifies critical neurons and clusters them into groups based on shared functional relationships, enabling a more coherent and interpretable view of the network\u2019s internal processes. This approach facilitates the construction of a hierarchical circuit representing neuron interactions across layers, improving interpretability while reducing computational costs. Our extensive empirical studies validate the fidelity of our proposed NeurFlow. Additionally, we showcase its utility in practical applications such as image debugging and automatic concept labeling, thereby highlighting its potential to advance the field of neural network explainability.", "title_embedding_index": 9905, "title_abs_embedding_index": 9930}, {"title": "Beyond FVD: Enhanced Evaluation Metrics for Video Generation Quality", "link_suffix": "/forum?id=cC3LxGZasH", "link": "https://openreview.net/forum?id=cC3LxGZasH", "pdf_link": "https://openreview.net/pdf?id=cC3LxGZasH", "keywords": "Video quality metrics, Frechet Video Distance, Inflated 3D Convnet, VideoMAE, VJEPA, kernel metrics", "abstract": "The Fr\u00e9chet Video Distance (FVD) is a widely adopted metric for evaluating video generation distribution quality. However, its effectiveness relies on critical assumptions. Our analysis reveals three significant limitations: (1) the non-Gaussianity of the Inflated 3D Convnet (I3D) feature space; (2) the insensitivity of I3D features to temporal distortions; (3) the impractical sample sizes required for reliable estimation. These findings undermine FVD's reliability and show that FVD falls short as a standalone metric for video generation evaluation. After extensive analysis of a wide range of metrics and backbone architectures, we propose JEDi, the JEPA Embedding Distance, \nbased on features derived from a Joint Embedding Predictive Architecture, measured using Maximum Mean Discrepancy with polynomial kernel.  Our experiments on multiple open-source datasets show clear evidence that it is a superior alternative to the widely used FVD metric, requiring only 16% of the samples to reach its steady value, while increasing alignment with human evaluation by 34%, on average.", "title_embedding_index": 9906, "title_abs_embedding_index": 9931}, {"title": "Reward as Observation: Learning Reward-based Policies for Rapid Adaptation", "link_suffix": "/forum?id=473sH8qki8", "link": "https://openreview.net/forum?id=473sH8qki8", "pdf_link": "https://openreview.net/pdf?id=473sH8qki8", "keywords": "Reinforcement learning, transfer learning", "abstract": "This paper explores a reward-based policy to achieve zero-shot transfer between source and target environments with completely different observation spaces. While humans can demonstrate impressive adaptation capabilities, deep neural network policies often struggle to adapt to a new environment and require a considerable amount of samples for successful transfer. Instead, we propose a novel reward-based policy only conditioned on rewards and actions, enabling zero-shot adaptation to new environments with completely different observations. We discuss the challenges and feasibility of a reward-based policy and then propose a practical algorithm for training. We demonstrate that a reward policy can be trained within three different environments, Pointmass, Cartpole, and 2D Car Racing, and transferred to completely different observations, such as different color palettes or 3D rendering, in a zero-shot manner. We also demonstrate that a reward-based policy can further guide the training of an observation-based policy in the target environment.", "title_embedding_index": 9907, "title_abs_embedding_index": 9932}, {"title": "X-VILA: Cross-Modality Alignment for Large Language Models", "link_suffix": "/forum?id=y5G1BfV7Am", "link": "https://openreview.net/forum?id=y5G1BfV7Am", "pdf_link": "https://openreview.net/pdf?id=y5G1BfV7Am", "keywords": "Multi-task learning, vision-language models, generative models", "abstract": "We introduce X-VILA, an omni-modality model designed to extend the capabilities of large language models (LLMs) by incorporating image, video, and audio modalities. By aligning modality-specific encoders with LLM inputs and diffusion decoders with LLM outputs, X-VILA achieves cross-modality understanding, reasoning, and generation. To facilitate this cross-modality alignment, we curate an effective interleaved any-to-any modality instruction-following dataset. Furthermore, we identify a significant problem with the current cross-modality alignment method, which results in visual information loss. To address the issue, we propose a visual alignment mechanism with a visual embedding highway module. We then introduce a resource-efficient recipe for training X-VILA, that exhibits proficiency in any-to-any modality conversation, surpassing previous approaches by large margins. X-VILA also showcases emergent properties across modalities even in the absence of similar training data. The project will be made open-source.", "title_embedding_index": 9908, "title_abs_embedding_index": 9933}, {"title": "Uncertainty Aware Column Generation for Crew Pairing Optimization Using Survival Analysis", "link_suffix": "/forum?id=rHbxQebhDd", "link": "https://openreview.net/forum?id=rHbxQebhDd", "pdf_link": "https://openreview.net/pdf?id=rHbxQebhDd", "keywords": "Reliable Scheduling and Planning, Column Generation, Machine learning for optimization, Survival Analysis, Crew pairing, Airline Operations Planning", "abstract": "The crew pairing problem (CPP) is central to optimal planning and scheduling of operations in the airline industry, where the objective is to assign crews to cover a flight schedule at minimal cost while adhering to various logistical, personnel, and policy constraints. Despite the implementation of optimized schedules, operations are frequently disrupted by unforeseen events. This vulnerability stems from the deterministic nature of the CPP's base formulation, which fails to account for the uncertainties inherent in real-world operations. Existing solutions either aim to safeguard against a specified level of uncertainty or focus on worst-case scenarios. To this end, we propose a reliability-centric CPP formulation amenable to solution by column-generation (CG)  SurvCG, that leverages survival analysis for dynamic quantification of uncertainty using the operation patterns in historical data. Applied to CPP, SurvCG forecasts and incorporates flight connection reliability into the optimization process. Through rigorous experiments on a large-scale first-of-its-kind real-world instance under regular and irregular operating conditions, we demonstrate that SurvCG achieves unprecedented improvements (up to 61%) over baseline in terms of total propagated delays, establishing SurvCG as the first data-driven solution for uncertainty-aware reliable scheduling.", "title_embedding_index": 9909, "title_abs_embedding_index": 9934}, {"title": "Unmasking the Version-Switching Capabilities of Code Generation Models", "link_suffix": "/forum?id=7rxn2wnx88", "link": "https://openreview.net/forum?id=7rxn2wnx88", "pdf_link": "https://openreview.net/pdf?id=7rxn2wnx88", "keywords": "Code generation, LLM, code LLM, benchmark, code versioning", "abstract": "The rapid evolution of software libraries presents a significant challenge for code generation models, which must adapt to frequent version updates while maintaining compatibility with previous versions. Existing code completion benchmarks often overlook this dynamic aspect, and the one that does consider it relies on static code prediction tasks without execution-based evaluation, offering a limited perspective on a model's practical usability. To address this gap, we introduce GitChameleon, a novel, manually curated dataset comprising 116 Python code completion problems, each conditioned on specific library versions and accompanied by executable unit tests. GitChameleon is designed to rigorously assess the ability of modern large language models (LLMs) to generate version-specific code that is not only syntactically correct but also functionally accurate upon execution. Our comprehensive evaluations reveal that state-of-the-art LLMs struggle with this task; for instance, \\textbf{GPT-4} achieves a pass@10 of only 39.9% (43.7% when provided with error feedback), highlighting the complexity of the problem and the limitations of current models. By providing an execution-based benchmark that emphasizes the dynamic nature of code libraries, GitChameleon serves as a critical tool for advancing the development of more adaptable and reliable code generation models. We release the dataset and evaluation framework to encourage further research in this vital area.", "title_embedding_index": 9910, "title_abs_embedding_index": 9935}, {"title": "Harnessing Input-adaptive Inference for Efficient Vision-and-Language Navigation", "link_suffix": "/forum?id=5gptKWnVPF", "link": "https://openreview.net/forum?id=5gptKWnVPF", "pdf_link": "https://openreview.net/pdf?id=5gptKWnVPF", "keywords": "Vision-and-Language Navigation, Input-adaptive Efficient Navigation", "abstract": "An emerging paradigm in vision-and-language navigation (VLN) is the use of history-aware multi-modal transformer models. Given a language instruction, these models take observation and history as input and predict the most appropriate action for an agent. While employing these models has significantly improved performance, the scale of these models can be a bottleneck in practical settings where computational resources are limited (e.g., in robots). In this work, we present a novel input-adaptive navigation method for efficient VLN. We first characterize the overthinking problem in VLN and show that none of the existing input-adaptive mechanisms successfully reduce overthinking without causing significant performance degradation. Our method addresses this problem by developing three adaptive algorithms deployed at different levels: (1) We develop an adaptive approach that improves spatial efficiency; we only process a subset of panoramic views at each observation of an agent. (2) We also achieve model-level efficiency by developing adaptive thresholding for the early-exit method we employ, based on the importance of each view in navigation. (3) To achieve temporal efficiency, we design a caching mechanism to avoid processing views that an agent has seen before. In evaluations with six VLN benchmark tasks, we demonstrate over a 2$\\times$ reduction in computation across two off-the-shelf VLN agents.", "title_embedding_index": 9911, "title_abs_embedding_index": 9936}, {"title": "Greedy Learning to Optimize with Convergence Guarantees", "link_suffix": "/forum?id=FK8tl47xpP", "link": "https://openreview.net/forum?id=FK8tl47xpP", "pdf_link": "https://openreview.net/pdf?id=FK8tl47xpP", "keywords": "Optimization, Inverse Problems, Learning to Optimize, Preconditioning, Imaging", "abstract": "Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant memory usage. We parameterize the update such that parameter learning corresponds to solving a convex optimization problem at each iteration. In particular, we explore preconditioned gradient descent with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithm, convergence in the training set is proven even when the preconditioner is neither symmetric nor positive definite. Convergence on a class of unseen functions is also obtained, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioner demonstrates improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.", "title_embedding_index": 9912, "title_abs_embedding_index": 9937}, {"title": "Adaptive Threshold Sampling for Fast Noisy Submodular Maximization", "link_suffix": "/forum?id=vtCkb4KJxr", "link": "https://openreview.net/forum?id=vtCkb4KJxr", "pdf_link": "https://openreview.net/pdf?id=vtCkb4KJxr", "keywords": "submodular, multi-armed bandit, bandit feedback, best-arm identification, combinatorial optimization", "abstract": "We address the problem of submodular maximization where objective function $f:2^U\\to\\mathbb{R}_{\\geq 0}$ can only be accessed through i.i.d noisy queries. This problem arises in many applications including influence maximization, diverse recommendation systems, and large-scale facility location optimization. We propose an efficient adaptive sampling strategy, called Confident Sample (CS), that is inspired by algorithms for best-arm-identification in multi-armed bandit, which significantly improves sample efficiency. We integrate CS into existing approximation algorithms for submodular maximization, resulting in algorithms with approximation guarantees arbitrarily close to the standard value oracle setting that are highly sample-efficient. We propose and analyze sample-efficient algorithms for monotone submodular maximization with cardinality and matroid constraints, as well as unconstrained non-monotone submodular maximization. Our theoretical analysis is complemented by empirical evaluation on real instances, demonstrating the superior sample efficiency of our proposed algorithm relative to alternative approaches.", "title_embedding_index": 9913, "title_abs_embedding_index": 9938}, {"title": "MAVIS: Mathematical Visual Instruction Tuning with an Automatic Data Engine", "link_suffix": "/forum?id=MnJzJ2gvuf", "link": "https://openreview.net/forum?id=MnJzJ2gvuf", "pdf_link": "https://openreview.net/pdf?id=MnJzJ2gvuf", "keywords": "Large language model, multimodal learning, mathematics", "abstract": "Multi-modal Large Language Models (MLLMs) have recently showcased superior proficiency in general visual scenarios. However, we identify their mathematical capabilities remain under-explored with three areas to be improved: visual encoding of math diagrams, diagram-language alignment, and chain-of-thought (CoT) reasoning. This draws forth an urgent demand for an effective training paradigm and a large-scale, comprehensive dataset with detailed CoT rationales, which is challenging to collect and costly to annotate manually. To tackle this issue, we propose MAVIS, a MAthematical VISual instruction tuning pipeline for MLLMs, featuring an automatic data engine to efficiently create mathematical visual datasets.\nWe design the data generation process to be entirely independent of human intervention or GPT API usage, while ensuring the diagram-caption correspondence, question-answer correctness, and CoT reasoning quality. With this approach, we curate two datasets, MAVIS-Caption (558K diagram-caption pairs) and MAVIS-Instruct (834K visual math problems with CoT rationales), and propose four progressive stages for training MLLMs from scratch.\nFirst, we utilize MAVIS-Caption to fine-tune a math-specific vision encoder (CLIP-Math) through contrastive learning, tailored for improved diagram visual encoding. Second, we also leverage MAVIS-Caption to align the CLIP-Math with a large language model (LLM) by a projection layer, enhancing vision-language alignment in mathematical domains. Third, we adopt MAVIS-Instruct to perform the instruction tuning for robust problem-solving skills, and term the resulting model as MAVIS-7B. Fourth, we apply Direct Preference Optimization (DPO) to enhance the CoT capabilities of our model, further refining its step-wise reasoning performance.\nOn various mathematical benchmarks, our MAVIS-7B achieves leading results among open-source MLLMs, e.g., surpassing other 7B models by +9.3% and the second-best LLaVA-NeXT (110B) by +6.9%, demonstrating the effectiveness of our method.", "title_embedding_index": 9914, "title_abs_embedding_index": 9939}, {"title": "Convergence-Aware Multi-Fidelity Bayesian Optimization", "link_suffix": "/forum?id=IdynViNzwI", "link": "https://openreview.net/forum?id=IdynViNzwI", "pdf_link": "https://openreview.net/pdf?id=IdynViNzwI", "keywords": "Bayesian Optimization, Multi-Fidelity Bayesian Optimization, Gaussian process, dynamic systems", "abstract": "Multi-fidelity Bayesian Optimization (MFBO) has emerged as a powerful approach for optimizing expensive black-box functions by leveraging evaluations at different fidelity levels.\nHowever, existing MFBO methods often overlook the convergence behavior of the objective function as fidelity increases, leading to inefficient exploration and suboptimal performance. \nWe propose CAMO, a novel Convergence-Aware Multi-fidelity Optimization framework based on Fidelity Differential Equations (FiDEs). \nCAMO explicitly captures the convergence behavior of the objective function, enabling more efficient optimization. We introduce two tractable forms of CAMO: an integral Automatic Relevance Determination (ARD) kernel and a data-driven Deep Kernel. Theoretical analysis demonstrates that CAMO with the integral ARD kernel achieves a tighter regret bound compared to state-of-the-art methods. Our empirical evaluation on synthetic benchmarks and real-world engineering design problems shows that CAMO consistently outperforms existing MFBO algorithms in optimization efficiency and solution quality, with up to 4x improvement in optimal solution.\nThis work establishes a foundation for tractable convergence-aware MFBO and opens up new avenues for research in this area.", "title_embedding_index": 9915, "title_abs_embedding_index": 9940}, {"title": "Foundation Policies with Memory", "link_suffix": "/forum?id=It4KL6XnPq", "link": "https://openreview.net/forum?id=It4KL6XnPq", "pdf_link": "https://openreview.net/pdf?id=It4KL6XnPq", "keywords": "reinforcement learning, unsupervised RL, foundation policies, zero-shot reinforcement learning, generalisation in reinforcement learning", "abstract": "A generalist agent should perform well on novel tasks in unfamiliar environments. While Foundation Policies (FPs) enable generalization across new tasks, they lack mechanisms for handling novel dynamics. Conversely, agents equipped with memory models can adapt to new dynamics, but struggle with unseen tasks. In this work, we bridge this gap by integrating memory models into the FP architecture, allowing policies to condition on both task and environment dynamics. We evaluate FPs enhanced with attention, state-space, and RNN-based memory models on POPGym, a memory benchmark, and ExORL, an unsupervised RL benchmark. Our results show that GRUs achieve the best generalization to unseen tasks and dynamics for a given recurrent state size, approaching the performance of a supervised baseline that has access to task information during training and significantly outperforming memory-free FPs. Additionally, our approach improves FP performance on entirely new environments not encountered during training. Our anonymized code is available at \\url{https://anonymous.4open.science/r/zero-shot-96A1}.", "title_embedding_index": 9916, "title_abs_embedding_index": 9941}, {"title": "Simultaneous Reward Distillation and Preference Learning: Get You a Language Model Who Can Do Both", "link_suffix": "/forum?id=l9LWx9HMl5", "link": "https://openreview.net/forum?id=l9LWx9HMl5", "pdf_link": "https://openreview.net/pdf?id=l9LWx9HMl5", "keywords": "preference optimization, reward distillation, llms", "abstract": "Reward modeling of human preferences is one of the cornerstones of building usable generative large language models (LLMs). While traditional RLHF-based alignment methods explicitly maximize the expected rewards from a separate reward model, more recent supervised alignment methods like Direct Preference Optimization (DPO) circumvent this phase to avoid problems including model drift and reward overfitting. Although popular due to its simplicity, DPO and similar direct alignment methods can still lead to degenerate policies, and rely heavily on the Bradley-Terry-based preference formulation to model reward differences between pairs of candidate outputs. This formulation is challenged by non-deterministic or noisy preference labels, for example human scoring of two candidate outputs is of low confidence. In this paper, we introduce DRDO (Direct Reward Distillation and policy-Optimization), a supervised knowledge distillation-based preference alignment method that simultaneously models rewards and preferences to avoid such degeneracy. DRDO directly mimics rewards assigned by an oracle while learning human preferences from a novel preference likelihood formulation. Our experimental results on the Ultrafeedback and TL;DR datasets demonstrate that policies trained using DRDO surpass previous methods such as DPO and e-DPO in terms of expected rewards and are more robust, on average, to noisy preference signals as well as out-of-distribution (OOD) settings.", "title_embedding_index": 9917, "title_abs_embedding_index": 9942}, {"title": "Graph Neural Networks Can (Often) Count Substructures", "link_suffix": "/forum?id=sZQRUrvLn4", "link": "https://openreview.net/forum?id=sZQRUrvLn4", "pdf_link": "https://openreview.net/pdf?id=sZQRUrvLn4", "keywords": "graph neural networks, subgraphs, expressivity", "abstract": "Message passing graph neural networks (GNNs) are known to have limited expressive power in their ability to distinguish some non-isomorphic graphs.\nBecause of this, it is well known that they are unable to detect or count arbitrary graph substructures (i.e., solving the subgraph isomorphism problem), a task that is of great importance for several types of graph-structured data. \nHowever, we observe that GNNs are in fact able to count graph patterns quite accurately across several real-world graph datasets.\nMotivated by this observation, we provide an analysis of the subgraph-counting capabilities of GNNs beyond the worst case, deriving several sufficient conditions for GNNs to be able to count subgraphs and, more importantly, to be able to sample-efficiently learn to count subgraphs. \nMoreover, we develop novel dynamic programming algorithms for solving the subgraph isomorphism problem on restricted classes of pattern and target graphs, and show that message-passing GNNs can efficiently simulate these dynamic programs. \nFinally, we empirically validate that our sufficient conditions for GNNs to count subgraphs hold on many real-world datasets, providing a theoretically-grounded explanation to our motivating observations.", "title_embedding_index": 9918, "title_abs_embedding_index": 9943}, {"title": "LLaRA: Supercharging Robot Learning Data for Vision-Language Policy", "link_suffix": "/forum?id=iVxxgZlXh6", "link": "https://openreview.net/forum?id=iVxxgZlXh6", "pdf_link": "https://openreview.net/pdf?id=iVxxgZlXh6", "keywords": "Robot Learning, VLM, Behavior Cloning, Instruction Tuning, Self-supervised Learning", "abstract": "LLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity to process state information as visual-textual prompts and respond with policy decisions in text. We propose LLaRA: Large Language and Robotics Assistant, a framework that formulates robot action policy as conversations and provides improved action output when trained with auxiliary data that complements policy learning. We first introduce an automated pipeline to generate conversation-style instruction tuning data from existing behavior cloning data. Then we enrich the dataset in a self-supervised fashion by formulating six auxiliary tasks. A VLM finetuned with the resulting collection of datasets can generate meaningful robot action policy decisions. Our experiments across multiple simulated and real-world environments demonstrate the state-of-the-art performance of the proposed LLaRA framework. The code, datasets, and pretrained models will be made publicly available.", "title_embedding_index": 9919, "title_abs_embedding_index": 9944}, {"title": "Tokenizer-Agnostic Transferable Attacks on Language Models for Enhanced Red Teaming", "link_suffix": "/forum?id=4GcZSTqlkr", "link": "https://openreview.net/forum?id=4GcZSTqlkr", "pdf_link": "https://openreview.net/pdf?id=4GcZSTqlkr", "keywords": "Adversarial Attacks, Red Teaming, Transferable Attacks, AI Safety, Large Language Models", "abstract": "Large Language Models (LLMs) have become increasingly prevalent, raising concerns about potential vulnerabilities and misuse. Effective red teaming methods are crucial for improving AI safety, yet current approaches often require access to model internals or rely on specific jailbreak techniques. We present TIARA (Tokenizer-Independent Adversarial Red-teaming Approach), a novel method for automated red teaming of LLMs that advances the state-of-the-art in transferable adversarial attacks. Unlike previous token-level methods, TIARA eliminates constraints on gradient access and fixed tokenizer, enabling simultaneous attacks on multiple models with diverse architectures. By leveraging a combination of teacher-forcing and auto-regressive loss functions with a multi-stage candidate selection procedure, it achieves superior performance without relying on gradient information or dedicated attacker models. TIARA attains an 82.9% attack success rate on GPT-3.5 Turbo and 51.2% on Gemini Pro, surpassing previous transfer and direct attacks on the HarmBench benchmark. We provide insights into adversarial string length effects and present a qualitative analysis of discovered adversarial techniques. This work contributes to AI safety by offering a robust, versatile tool for identifying potential vulnerabilities in LLMs, facilitating the development of safer AI systems.", "title_embedding_index": 9920, "title_abs_embedding_index": 9945}, {"title": "DASB-Discrete Audio and Speech Benchmark", "link_suffix": "/forum?id=nsFucJqKmR", "link": "https://openreview.net/forum?id=nsFucJqKmR", "pdf_link": "https://openreview.net/pdf?id=nsFucJqKmR", "keywords": "discrete audio tokens, speech processing", "abstract": "Discrete audio tokens have recently gained considerable attention for their potential to connect audio and language processing, enabling the creation of modern multimodal large language models. Ideal audio tokens must effectively preserve phonetic and semantic content along with paralinguistic information, speaker identity, and other details. While several types of audio tokens have been recently proposed, identifying the optimal tokenizer for various tasks is challenging due to the inconsistent evaluation settings in existing studies. To address this gap, we release the Discrete Audio and Speech Benchmark (DASB), a comprehensive leaderboard for benchmarking discrete audio tokens across a wide range of discriminative tasks, including speech recognition, speaker identification and verification, emotion recognition, keyword spotting, intent classification, event sound detection, and music genre classification as well as generative tasks such as speech enhancement, separation, and text-to-speech. Our results show that, on average, semantic tokens outperform compression tokens across most discriminative and generative tasks. However, the performance gap between semantic tokens and standard continuous representations remains substantial, highlighting the need for further research in this field.", "title_embedding_index": 9921, "title_abs_embedding_index": 9946}, {"title": "Ctrl-V: Higher Fidelity Video Generation with Bounding-Box Controlled Object Motion", "link_suffix": "/forum?id=n6To2wAOKL", "link": "https://openreview.net/forum?id=n6To2wAOKL", "pdf_link": "https://openreview.net/pdf?id=n6To2wAOKL", "keywords": "video generation, video synthesis, computer vision, diffusion models, autonomous driving, controllable video generation", "abstract": "Controllable video generation has attracted significant attention, largely due to advances in video diffusion models. In domains like autonomous driving in particular it can be critical to develop highly accurate predictions for object motions. This paper tackles a crucial challenge of how to exert precise control over object motion for realistic video synthesis in a safety critical setting. To achieve this, we 1) use a separate, specialized model to predict object bounding-box trajectories given the past and optionally future locations of bounding boxes, and 2) generate video conditioned on these high quality trajectory predictions. This formulation allows us to test the quality of different model components separately and together. To address the challenges of conditioning video generation on object trajectories in settings where objects may disappear and appear within a scene, we propose an approach based on rendering 2D or 3D boxes as videos. Our method, Ctrl-V, leverages modified and fine-tuned Stable Video Diffusion (SVD) models to solve both trajectory and video generation. Extensive experiments conducted on the KITTI, Virtual-KITTI 2, BDD 100k, and nuScenes datasets validate the effectiveness of our approach in producing realistic and controllable video generation.", "title_embedding_index": 9922, "title_abs_embedding_index": 9947}, {"title": "Stochastic Approximation to Contrastive Learning", "link_suffix": "/forum?id=P5icyaAReM", "link": "https://openreview.net/forum?id=P5icyaAReM", "pdf_link": "https://openreview.net/pdf?id=P5icyaAReM", "keywords": "contrastive learning, self-supervised learning, unsupervised learning", "abstract": "Contrastive learning is a powerful paradigm that has been crucial for self-supervised representation learning. While there is evidence for its effectiveness, these methods typically rely on arbitrary definitions of positive and negative pairs. Most existing contrastive learning methods require large batch sizes during training due to their rigid control over the tradeoff between the two contrastive terms. Consequences are that, substantial computational resources are wasted on negative pairs that provide minimal learning signals. To address this issue, this work present a novel method. We reformulate contrastive learning as a matrix approximation problem using I-divergence, a non-normalized form of Kullback-Leibler divergence. Our proposed objective function is decomposable across instance pairs, enabling the development of efficient stochastic approximation algorithms from neighbor embeddings which perform well with fewer negative samples. Additionally, we generalize the scaling factor beyond normalization, allowing it to adaptively emphasize positive pairs that carry more learning signals, thereby reducing the computational waste associated with negative pairs. Experimental results on visual representation learning benchmark datasets such as CIFAR and ImageNet demonstrate major improvements over other contrastive learning methods, particularly when using small batches and with only one negative pair.", "title_embedding_index": 9923, "title_abs_embedding_index": 9948}, {"title": "Towards hyperparameter-free optimization with differential privacy", "link_suffix": "/forum?id=2kGKsyhtvh", "link": "https://openreview.net/forum?id=2kGKsyhtvh", "pdf_link": "https://openreview.net/pdf?id=2kGKsyhtvh", "keywords": "Differential privacy, optimization, hyper-parameter tuning", "abstract": "Differential privacy (DP) is a privacy-preserving paradigm that protects the training data when training deep learning models. Critically, the performance of models is determined by the training hyperparameters, especially those of the learning rate schedule, thus requiring fine-grained hyperparameter tuning on the data. In practice, it is common to tune the learning rate hyperparameters through the grid search that (1) is computationally expensive as multiple runs are needed, and (2) increases the risk of data leakage as the selection of hyperparameters is data-dependent. In this work, we adapt the automatic learning rate schedule to DP optimization for any models and optimizers, so as to significantly mitigate or even eliminate the cost of hyperparameter tuning when applied together with automatic per-sample gradient clipping. Our hyperparamter-free DP optimization is almost as computationally efficient as the standard non-DP optimization, and achieves state-of-the-art DP performance on various language and vision tasks.", "title_embedding_index": 9924, "title_abs_embedding_index": 9949}]
[{"title": "LoLCATs: On Low-Rank Linearizing of Large Language Models", "link_suffix": "/forum?id=8VtGeyJyx9", "link": "https://openreview.net/forum?id=8VtGeyJyx9", "pdf_link": "https://openreview.net/pdf?id=8VtGeyJyx9", "keywords": "Linear Attention, Linearizing Transformers, Low-rank Adaptation, Large Language Models, Architecture Distillation", "abstract": "Recent works show we can linearize large language models (LLMs)---swapping the attentions of popular Transformer-based LLMs with subquadratic analogs---to create subquadratic LLMs at fractions of typical pretraining costs.  However, to adapt LLMs to the new layers, these approaches significantly degrade model quality, involve expensive full-model training over billions of tokens, and remain limited to smaller 1.3B to 7B LLMs. We thus propose Low-rank Linear Conversion via Attention Transfer (LoLCATs), a simple two-step method that improves LLM linearizing quality with magnitudes less memory and compute. We base these steps on two findings. First, rather than adapt LLMs to completely new layers, we find we can replace their softmax attentions with near-equivalent linear attentions, simply by training these layers to approximate their softmax counterparts (\"attention transfer\"). Then, this enables simply using low-rank adaptation (LoRA) to adjust for approximation errors, recovering quality in fully subquadratic LLMs. In experiments, LoLCATs significantly improves linearizing quality, training-efficiency, and scalability. First, by linearizing Llama 3 8B and Mistral 7B v0.1, LoLCATs produces state-of-the-art subquadratic LLMs that outperform both prior linearizing methods (SUPRA) and strong pretrained 7B Transformer alternatives (e.g., RWKV, Mamba, Griffin) by 2.9-8.0 points on popular zero-shot LM Evaluation Harness tasks (+20 points on 5-shot MMLU). Next, LoLCATs achieves the above with only 0.2% of past methods' model parameters and 0.4% of past methods' training tokens. Finally, we apply LOLCATS to create the first linearized 70B and 405B LLMs (50\u00d7 larger than prior work). When compared with prior methods under the same compute budgets, LOLCATS significantly improves linearizing quality, closing the gap between linearized and original Llama 3.1 70B and 405B LLMs by 78.7% and 77.4% on 5-shot MMLU.", "title_embedding_index": 9400, "title_abs_embedding_index": 9425}, {"title": "Flow Matching with Gaussian Process Priors for Probabilistic Time Series Forecasting", "link_suffix": "/forum?id=uxVBbSlKQ4", "link": "https://openreview.net/forum?id=uxVBbSlKQ4", "pdf_link": "https://openreview.net/pdf?id=uxVBbSlKQ4", "keywords": "flow matching, time series forecasting, generative modeling, deep learning", "abstract": "Recent advancements in generative modeling, particularly diffusion models, have opened new directions for time series modeling, achieving state-of-the-art performance in forecasting and synthesis. However, the reliance of diffusion-based models on a simple, fixed prior complicates the generative process since the data and prior distributions differ significantly. We introduce TSFlow, a conditional flow matching (CFM) model for time series that simplifies the generative problem by combining Gaussian processes, optimal transport paths, and data-dependent prior distributions. By incorporating (conditional) Gaussian processes, TSFlow aligns the prior distribution more closely with the temporal structure of the data, enhancing both unconditional and conditional generation. Furthermore, we propose conditional prior sampling to enable probabilistic forecasting with an unconditionally trained model. In our experimental evaluation on eight real-world datasets, we demonstrate the generative capabilities of TSFlow, producing high-quality unconditional samples. Finally, we show that both conditionally and unconditionally trained models achieve competitive results in forecasting benchmarks, surpassing other methods on 6 out of 8 datasets.", "title_embedding_index": 9401, "title_abs_embedding_index": 9426}, {"title": "RoRA-VLM: Robust Retrieval-Augmented Vision Language Models", "link_suffix": "/forum?id=2h1siDrSMl", "link": "https://openreview.net/forum?id=2h1siDrSMl", "pdf_link": "https://openreview.net/pdf?id=2h1siDrSMl", "keywords": "retrieval-augmented generation, vision language model", "abstract": "Though vision-language models (VLMs) have demonstrated impressive capabilities as general-purpose visual assistants, they still exhibit inferior performance on knowledge-intensive tasks such as information-seeking visual question answering, primarily due to the challenge of accurately encoding all the associations between visual objects and scenes to their corresponding entities and background knowledge. While retrieval augmentation methods offer an efficient way to integrate external knowledge, extending them to vision-language domain presents unique challenges in (1) precisely retrieving relevant information from external sources due to the inherent discrepancy within the multimodal queries, and (2) being resilient to the irrelevant, extraneous and noisy information contained in the retrieved multimodal knowledge snippets. In this work, we introduce RORA-VLM, a novel and robust retrieval augmentation framework specifically tailored for VLMs, with two key innovations: (1) a 2-stage retrieval process with Image-anchored Textual-query Expansion to synergistically combine the visual and textual information in the query and retrieve the most relevant multimodal knowledge snippets; and (2) a robust retrieval augmentation method that strengthens the resilience of VLMs against irrelevant information in the retrieved multimodal knowledge by injecting adversarial noises into the retrieval-augmented training process, and filters out extraneous visual information, such as unrelated entities presented in images, via a query-oriented visual token refinement strategy. We conduct extensive experiments to validate the effectiveness and robustness of our proposed methods on three widely adopted benchmark datasets: OVEN, InfoSeek and Enc-VQA. Our results demonstrate that with a minimal amount of training instance, RORA-VLM enables the LLaVA-v1.5 model to achieve significant performance improvement and constantly outperform state-of-the-art retrieval-augmented VLMs on all benchmarks while also exhibiting a novel zero-shot domain transfer capability.", "title_embedding_index": 9402, "title_abs_embedding_index": 9427}, {"title": "Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics", "link_suffix": "/forum?id=6kjTRMJ3be", "link": "https://openreview.net/forum?id=6kjTRMJ3be", "pdf_link": "https://openreview.net/pdf?id=6kjTRMJ3be", "keywords": "Large Language Models, Clinical AI, Multi-agent", "abstract": "Large language models (LLMs) have demonstrated remarkable progress in healthcare. However, a significant gap remains regarding LLMs' professionalism in domain-specific clinical practices, limiting their application in real-world diagnostics. In this work, we introduce ZODIAC, an LLM-powered framework with cardiologist-level professionalism designed to engage LLMs in cardiological diagnostics. ZODIAC assists cardiologists by extracting clinically relevant characteristics from patient data, detecting significant arrhythmias, and generating preliminary reports for the review and refinement by cardiologists. To achieve cardiologist-level professionalism, ZODIAC is built on a multi-agent collaboration framework, enabling the processing of patient data across multiple modalities. Each LLM agent is fine-tuned using real-world patient data adjudicated by cardiologists, reinforcing the model's professionalism. ZODIAC undergoes rigorous clinical validation with independent cardiologists, evaluated across eight metrics that measure clinical effectiveness and address security concerns. Results show that ZODIAC outperforms industry-leading models, including OpenAI's GPT-4o, Meta's Llama-3.1-405B, and Google's Gemini-pro, as well as medical-specialist LLMs like Microsoft's BioGPT. ZODIAC demonstrates the transformative potential of specialized LLMs in healthcare by delivering domain-specific solutions that meet the stringent demands of medical practice. Notably, ZODIAC has been successfully integrated into electrocardiography (ECG) devices, exemplifying the growing trend of embedding LLMs into Software-as-Medical-Device (SaMD).", "title_embedding_index": 9403, "title_abs_embedding_index": 9428}, {"title": "MIRAI: Evaluating LLM Agents for International Event Forecasting", "link_suffix": "/forum?id=gzzX4ZeErx", "link": "https://openreview.net/forum?id=gzzX4ZeErx", "pdf_link": "https://openreview.net/pdf?id=gzzX4ZeErx", "keywords": "LLM Agents, Temporal Forecasting, Tool Use", "abstract": "We present MIRAI, a benchmark designed to systematically evaluate LLM agents as temporal forecasters to predict international events. Our benchmark features an agentic environment with tools for accessing an extensive database of historical, structured events and textual news articles. We refine the GDELT event database with careful cleaning and parsing to curate a series of relational prediction tasks with varying forecasting horizons, assessing LLM agents\u2019 abilities from short-term to long-term forecasting. We further implement APIs to enable LLM agents to utilize different tools via a code-based interface. Notably, MIRAI features a dynamic data construction pipeline that supports periodically downloading recent news and events, and automatically generates the most recent test split. This allows us to evaluate any newly released model in a contamination-free manner as we can always construct a test split later than its knowledge cutoff date. MIRAI comprehensively evaluates the agents\u2019 capabilities in three dimensions: 1) autonomously source and integrate critical information from large global databases; 2) write codes with both domain-specific APIs and libraries for tool-use; and 3) jointly reason over historical knowledge from diverse formats and timespan to accurately predict future events. Through comprehensive evaluation, we establish a reliable benchmark for assessing the capabilities of LLM agents in forecasting international events and contribute to the development of more accurate and trustworthy models for international relation analysis.", "title_embedding_index": 9404, "title_abs_embedding_index": 9429}, {"title": "Robust Feature Learning for Multi-Index Models in High Dimensions", "link_suffix": "/forum?id=aKkDY1Wca0", "link": "https://openreview.net/forum?id=aKkDY1Wca0", "pdf_link": "https://openreview.net/pdf?id=aKkDY1Wca0", "keywords": "feature learning, adversarial robustness, neural networks, multi-index models, gradient descent", "abstract": "Recently, there have been numerous studies on feature learning with neural networks, specifically on learning single- and multi-index models where the target is a function of a low-dimensional projection of the input. Prior works have shown that in high dimensions, the majority of the compute and data resources are spent on recovering the low-dimensional projection; once this subspace is recovered, the remainder of the target can be learned independently of the ambient dimension. However, implications of feature learning in adversarial settings remain unexplored. In this work, we take the first steps towards understanding adversarially robust feature learning with neural networks. Specifically, we prove that the hidden directions of a multi-index model offer a Bayes optimal low-dimensional projection for robustness against $\\ell_2$-bounded adversarial perturbations under the squared loss, assuming that the multi-index coordinates are statistically independent from the rest of the coordinates. Therefore, robust learning can be achieved by first performing standard feature learning, then robustly tuning a linear readout layer on top of the standard representations. In particular, we show that adversarially robust learning is just as easy as standard learning. Specifically, the additional number of samples needed to robustly learn multi-index models when compared to standard learning, does not depend on dimensionality.", "title_embedding_index": 9405, "title_abs_embedding_index": 9430}, {"title": "Conditional Trajectories in Diffusion Models - Modeling Galaxy Evolution from Redshift", "link_suffix": "/forum?id=gJ48psisby", "link": "https://openreview.net/forum?id=gJ48psisby", "pdf_link": "https://openreview.net/pdf?id=gJ48psisby", "keywords": "Diffusion, Galaxy, Morphology, Redshift", "abstract": "In this paper, we present a novel approach for continuous {\\bf C}onditional {\\bf T}rajectories on Denoising {\\bf D}iffusion Probabilistic {\\bf M}odels (CTDM). Focusing on physical applications, our model learns to capture the underlying relationship between galaxy images and their redshift values from training data. This enables the simulation of galaxy evolution by conditioning the reverse denoising process on future redshift values. Importantly, this is achieved without requiring multiple images of the same galaxy at different redshifts.\nWe demonstrate that our redshift-conditioned diffusion model learns the marginal distribution of galaxy images at each redshift value. This allows the model to generate realistic galaxy images that reflect the physical changes occurring as galaxies evolve. We derive a smoothness condition for this learned distribution, proving that the model can construct trajectories between galaxy images by incrementally changing redshift during the reverse denoising process.\nOur approach offers a novel interpretation of the learned diffusion process as a means to simulate galaxy evolution, capturing both visual and physical changes over time. These techniques not only provide deeper insights into the formation and evolution of galaxies but also have broader potential applications in various areas of generative modeling.", "title_embedding_index": 9406, "title_abs_embedding_index": 9431}, {"title": "Learning Counterfactual Interventions for Self-Supervised Motion Estimation", "link_suffix": "/forum?id=DSpq7CXMFP", "link": "https://openreview.net/forum?id=DSpq7CXMFP", "pdf_link": "https://openreview.net/pdf?id=DSpq7CXMFP", "keywords": "self-supervised learning, motion estimation, world modeling, counterfactual prompting, visual prompting", "abstract": "A major challenge in self-supervised learning from visual inputs is extracting information from the learned representations to an explicit and usable form. This is most commonly done by learning readout layers with supervision or using highly specialized heuristics. This is challenging primarily because the self-supervised pretext tasks and the downstream tasks that extract information are not tightly connected in a principled manner---improving the former does not guarantee improvements in the latter. The recently proposed counterfactual world modeling paradigm aims to address this challenge through a masked next frame predictor base model which enables simple counterfactual extraction procedures for extracting optical flow, segments and depth. In this work, we take the next step and parameterize and optimize the counterfactual extraction of optical flow by solving the same simple next frame prediction task as the base model. Our approach achieves state of the art performance for estimation motion on real-world videos while requiring no labeled data. This work sets the foundation for future methods on improving the extraction of more complex visual structures like segments and depth with high accuracy.", "title_embedding_index": 9407, "title_abs_embedding_index": 9432}, {"title": "Towards Chapter-to-Chapter Literary Translation Via Large Language Models", "link_suffix": "/forum?id=aa5hoHNheb", "link": "https://openreview.net/forum?id=aa5hoHNheb", "pdf_link": "https://openreview.net/pdf?id=aa5hoHNheb", "keywords": "neural machine translation, context-aware neural machine translation, literary translation", "abstract": "Discourse phenomena in existing document-level translation datasets are sparse, which has been a fundamental obstacle in the development of context-aware machine translation models. Moreover, most existing document-level corpora and context-aware machine translation methods rely on an unrealistic assumption on sentence-level alignments. To mitigate these issues, we first curate a novel dataset of Chinese-English literature, which consists of 132 books with intricate discourse structures. Then, we propose a more pragmatic and challenging setting for context-aware translation, termed chapter-to-chapter (Ch2Ch) translation, and investigate the performance of commonly-used machine translation models under this setting. Furthermore, we introduce a potential approach of fine-tuning large language models (LLMs) within the domain of Ch2Ch literary translation, yielding impressive improvements over baselines. Through our comprehensive analysis, we unveil that literary translation under the Ch2Ch setting is challenging in nature, with respect to both model learning methods and translation decoding algorithms.", "title_embedding_index": 9408, "title_abs_embedding_index": 9433}, {"title": "EXPLORING THE IMPACT OF DATA AUGMENTATION ON LOCALIZED PERSONALIZED AI TRAINING WITH LLAMA3 AND LORA", "link_suffix": "/forum?id=LFn7s8yRUF", "link": "https://openreview.net/forum?id=LFn7s8yRUF", "pdf_link": "https://openreview.net/pdf?id=LFn7s8yRUF", "keywords": "Data Augmentation, Personalized AI, LLaMA3, Low-Rank Adaptation, NLP, Synonym Replacement, Random Insertion, Random Swap, Back Translation, Paraphrasing, Training Models, Machine Learning, Model Generalization", "abstract": "With the development of personalized AI models, particularly those emulating characters from novels, games, anime, and films, a significant challenge is the scarcity of suitable dialogue data. These works often feature distinctive styles and character dialogues that may not generalize well to everyday conversations. Data augmentation is crucial for enriching these limited datasets, ensuring sufficient data for learning the target character\u2019s tone and linguistic habits. This paper investigates the impact of various data augmentation techniques on personalized AI models in NLP, specifically focusing on models trained using LLaMA3 through Low-Rank Adaptation (LoRA). We employ different data augmentation strategies, including random deletion, synonym replacement, swapping, random insertion, back translation, and paraphrasing. To provide a comprehensive analysis, we apply these techniques across three distinct datasets, each representing different dialogue styles and contexts. By systematically comparing these methods, we demonstrate their influence on model performance and robustness. This study provides valuable insights into the effectiveness of different data augmentation strategies for enhancing the versatility and robustness of personalized AI systems trained with LLaMA3 using LoRA.", "title_embedding_index": 9409, "title_abs_embedding_index": 9434}, {"title": "AdaIR: Adaptive All-in-One Image Restoration via Frequency Mining and Modulation", "link_suffix": "/forum?id=M5t0WvjfCg", "link": "https://openreview.net/forum?id=M5t0WvjfCg", "pdf_link": "https://openreview.net/pdf?id=M5t0WvjfCg", "keywords": "All-in-one image restoration, frequency mining, frequency modulation", "abstract": "In the image acquisition process, various forms of degradation, including noise, blur, haze, and rain, are frequently introduced. These degradations typically arise from the inherent limitations of cameras or unfavorable ambient conditions. To recover clean images from their degraded versions, numerous specialized restoration methods have been developed, each targeting a specific type of degradation. Recently, all-in-one algorithms have garnered significant attention by addressing different types of degradations within a single model without requiring the prior information of the input degradation type. However, these methods purely operate in the spatial domain and do not delve into the distinct frequency variations inherent to different degradation types. To address this gap, we propose an adaptive all-in-one image restoration network based on frequency mining and modulation. Our approach is motivated by the observation that different degradation types impact the image content on different frequency subbands, thereby requiring different treatments for each restoration task. Specifically, we first mine low- and high-frequency information from the input features, guided by the adaptively decoupled spectra of the degraded image. The extracted features are then modulated by a bidirectional operator to facilitate interactions between different frequency components. Finally, the modulated features are merged into the original input for a progressively guided restoration. With this approach, the model achieves adaptive reconstruction by accentuating the informative frequency subbands according to different input degradations. Extensive experiments demonstrate that the proposed method, named AdaIR, achieves state-of-the-art performance on different image restoration tasks, including image denoising, dehazing, deraining, motion deblurring, and low-light image enhancement. Our code and models will be made publicly available.", "title_embedding_index": 9410, "title_abs_embedding_index": 9435}, {"title": "Linear Projections of Teacher Embeddings for Few-Class Distillation", "link_suffix": "/forum?id=DKA7Hx7PSt", "link": "https://openreview.net/forum?id=DKA7Hx7PSt", "pdf_link": "https://openreview.net/pdf?id=DKA7Hx7PSt", "keywords": "Distillation, Few-Classes, Binary Classification", "abstract": "Knowledge Distillation (KD) has emerged as a promising approach for transferring knowledge from a larger, more complex teacher model to a smaller student model. Traditionally, KD involves training the student to mimic the teacher's output probabilities, while more advanced techniques have explored guiding the student to adopt the teacher's internal representations. Despite its widespread success, the performance of KD in binary classification and few-class problems has been less satisfactory. This is because the information about the teacher model\u2019s generalization patterns scales directly with the number of classes. Moreover, several sophisticated distillation methods may not be universally applicable or effective for data types beyond Computer Vision. Consequently, effective distillation techniques remain elusive for a range of key real-world applications, such as sentiment analysis, search query understanding, and advertisement-query relevance assessment. Taking these observations into account,  we introduce a novel method for distilling knowledge from the teacher model's representations, which we term Learning Embedding Linear Projections (LELP). Inspired by recent findings about the structure of final-layer representations, LELP works by identifying informative linear subspaces in the teacher's embedding space, and splitting them into pseudo-subclasses. The student model is then trained to replicate these pseudo-subclasses.   Our experimental evaluations on large-scale NLP benchmarks like Amazon Reviews and Sentiment140 demonstrate that LELP is consistently competitive with, and typically superior to, existing state-of-the-art distillation algorithms for binary and few-class problems, where most KD methods suffer.", "title_embedding_index": 9411, "title_abs_embedding_index": 9436}, {"title": "Transfer Learning for Control Systems via Neural Simulation Relations", "link_suffix": "/forum?id=qawqxu4MgA", "link": "https://openreview.net/forum?id=qawqxu4MgA", "pdf_link": "https://openreview.net/pdf?id=qawqxu4MgA", "keywords": "Transfer Learning; Conrol Systems; Neural Simulation Relations", "abstract": "Transfer learning is an umbrella term for machine learning approaches that leverage knowledge gained from solving one problem (the source domain) to improve speed, efficiency, and data requirements in solving a different but related problem (the target domain). \nThe performance of the transferred model in the target domain is typically measured via some notion of loss function in the target domain. \nThis paper focuses on effectively transferring control logic from a source control system to a target control system while providing approximately similar behavioral guarantees in both domains. \nHowever, in the absence of a complete characterization of behavioral specifications, this problem cannot be captured in terms of loss functions. \nTo overcome this challenge, we use (approximate) simulation relations to characterize observational equivalence between the behaviors of two systems.Simulation relations ensure that the outputs of both systems, equipped with their corresponding controllers, remain close to each other over time, and their closeness can be quantified a priori. \nBy parameterizing simulation relations with neural networks, we introduce the notion of neural simulation relations, which provides a data-driven approach to transfer any synthesized controller, regardless of the specification of interest, along with its proof of correctness. \nCompared with prior approaches, our method eliminates the need for a closed-loop mathematical model and specific requirements for both the source and target systems. \nWe also introduce validity conditions that, when satisfied, guarantee the closeness of the outputs of two systems equipped with their corresponding controllers, thus eliminating the need for post-facto verification. \nWe demonstrate the effectiveness of our approach through case studies involving a vehicle and a double inverted pendulum.", "title_embedding_index": 9412, "title_abs_embedding_index": 9437}, {"title": "UltraLightUNet: Rethinking U-shaped Network with Multi-kernel Lightweight Convolutions for Medical Image Segmentation", "link_suffix": "/forum?id=BefqqrgdZ1", "link": "https://openreview.net/forum?id=BefqqrgdZ1", "pdf_link": "https://openreview.net/pdf?id=BefqqrgdZ1", "keywords": "Ultra Lightweight CNN, Medical Imaging, Semantic Segmentation, 3D Segmentation", "abstract": "In this paper, we introduce UltraLightUNet (2D and 3D), an ultra-lightweight, multi-kernel U-shaped network for medical image segmentation. The core of UltraLightUNet consists of a new Multi-kernel Inverted Residual (MKIR) block, which can efficiently process images through multiple kernels while capturing complex spatial relationships. Additionally, our Multi-kernel Inverted Residual Attention (MKIRA) block refines and emphasizes image salient features via new sophisticated convolutional multi-focal attention mechanisms. UltraLightUNet strategically employs the MKIR block in the encoder for feature extraction and the MKIRA block in the decoder for feature refinement, thus ensuring targeted feature enhancement at each stage. With only 0.316M #Params and 0.314G #FLOPs, UltraLightUNet offers an ultra-lightweight yet powerful segmentation solution that outperforms state-of-the-art (SOTA) methods across 11 medical imaging benchmarks. Notably, UltraLightUNet surpasses TransUNet on DICE score while using 333$\\times$ fewer #Params and 123$\\times$ fewer #FLOPs. Compared to UNeXt, UltraLightUNet improves DICE scores by up to 6.7% with 4.7$\\times$ fewer parameters. UltraLightUNet also outperforms recent lightweight models such as MedT, CMUNeXt, EGE-UNet, Rolling-UNet, and UltraLight_VM_UNet, while using significantly fewer #Params and #FLOPs. Furthermore, our 3D version, UltraLightUNet3D-M (1.42M #Params and 7.1G #FLOPs), outperforms SwinUNETR (62.19M #Params, 328.6G #FLOPs) and nn-UNet (31.2M #Params, 110.4G #FLOPs) on the MSD Prostate and FETA benchmarks. This remarkable performance, combined with substantial computational gains, makes UltraLightUNet an ideal solution for real-time, high-fidelity medical diagnostics in resource-constrained environments, such as point-of-care services. We will make the source code publicly available upon paper acceptance.", "title_embedding_index": 9413, "title_abs_embedding_index": 9438}, {"title": "Discretization-invariance? On the Discretization Mismatch Errors in Neural Operators", "link_suffix": "/forum?id=J9FgrqOOni", "link": "https://openreview.net/forum?id=J9FgrqOOni", "pdf_link": "https://openreview.net/pdf?id=J9FgrqOOni", "keywords": "Neural Operators, Operator Learning, Discretization Mismatch Errors, Discretization Invariance", "abstract": "In recent years, neural operators have emerged as a prominent approach for learning mappings between function spaces, such as the solution operators of parametric PDEs. A notable example is the Fourier Neural Operator (FNO), which models the integral kernel as a convolution operator and uses the Convolution Theorem to learn the kernel directly in the frequency domain. The parameters are decoupled from the resolution of the data, allowing the FNO to take inputs of different resolutions.\nHowever, training at a lower resolution and inferring at a finer resolution does not guarantee consistent performance, nor can fine details, present only in fine-scale data, be learned solely from coarse data. In this work, we address this misconception by defining and examining the discretization mismatch error: the discrepancy between the outputs of the neural operator when using different discretizations of the input data. We demonstrate that neural operators may suffer from discretization mismatch errors that hinder their effectiveness when inferred on data with resolutions different from that of the training data or when trained on data with varying resolutions. As neural operators underpin many critical cross-resolution scientific tasks, such as climate modeling and fluid dynamics, understanding discretization mismatch errors is essential. Based on our findings, we propose a Cross-Resolution Operator-learning Pipeline that is free of aliasing and discretization mismatch errors, enabling efficient cross-resolution, multi-spatial-scale learning, resulting in superior performance.", "title_embedding_index": 9414, "title_abs_embedding_index": 9439}, {"title": "Relative Preference Optimization: Enhancing LLM Alignment through Contrasting Responses across Identical and Diverse Prompts", "link_suffix": "/forum?id=APDnmucgID", "link": "https://openreview.net/forum?id=APDnmucgID", "pdf_link": "https://openreview.net/pdf?id=APDnmucgID", "keywords": "LLM alignment, fine-tuning, preferences", "abstract": "In the field of large language models (LLMs), aligning models with the diverse preferences of users is a critical challenge. Direct Preference Optimization (DPO) has played a key role in this area. It works by using pairs of preferences derived from the same prompts, and it functions without needing an additional reward model. However, DPO does not fully reflect the complex nature of human learning, which often involves understanding contrasting responses to not only identical but also similar questions. To overcome this shortfall, we propose Relative Preference Optimization (RPO). RPO is designed to discern between more and less preferred responses derived from both identical and related prompts. It introduces a contrastive weighting mechanism, enabling the tuning of LLMs using a broader range of preference data, including both paired and unpaired sets. This approach expands the learning capabilities of the model, allowing it to leverage insights from a more varied set of prompts. Experiments in both paired and unpaired dataset settings, including tasks like dialogue, summarization, and general evaluation benchmarks, demonstrate RPO's superior ability to align LLMs with user preferences and enhance adaptability during training.", "title_embedding_index": 9415, "title_abs_embedding_index": 9440}, {"title": "Interpreting Attention Layer Outputs with Sparse Autoencoders", "link_suffix": "/forum?id=LphpWGimIa", "link": "https://openreview.net/forum?id=LphpWGimIa", "pdf_link": "https://openreview.net/pdf?id=LphpWGimIa", "keywords": "mechanistic interpretability, llm interpretability", "abstract": "Decomposing model activations into interpretable components is a key open problem in mechanistic interpretability. Sparse autoencoders (SAEs) are a popular method for decomposing the internal activations of trained transformers into sparse, interpretable features, and have been applied to MLP layers and the residual stream. In this work we train SAEs on attention layer outputs and show that also here SAEs find a sparse, interpretable decomposition. We demonstrate this on transformers from several model families and up to 2B parameters. We perform a qualitative study of the features computed by attention layers, and find multiple families: long-range context, short-range context and induction features. We qualitatively study the role of every head in GPT-2 Small, and estimate that at least 90% of the heads are polysemantic, i.e. have multiple unrelated roles. Further, we show that sparse autoencoders are a useful tool that enable researchers to explain model behavior in greater detail than prior work. For example, we explore the mystery of why models have so many seemingly redundant induction heads, use SAEs to motivate the hypothesis that some are long-prefix whereas others are short-prefix, and confirm this with more rigorous analysis. We use our SAEs to analyze the computation performed by the Indirect Object Identification circuit (Wang et al., 2023), validating that the SAEs find causally meaningful intermediate variables, and deepening our understanding of the semantics of the circuit. We open-source the trained SAEs and a tool for exploring arbitrary prompts through the lens of Attention Output SAEs.", "title_embedding_index": 9416, "title_abs_embedding_index": 9441}, {"title": "(Mis)Fitting Scaling Laws: A Survey of Scaling Law Fitting Techniques in Deep Learning", "link_suffix": "/forum?id=xI71dsS3o4", "link": "https://openreview.net/forum?id=xI71dsS3o4", "pdf_link": "https://openreview.net/pdf?id=xI71dsS3o4", "keywords": "survey, scaling laws, large language models, foundation models", "abstract": "Modern foundation models rely heavily on using scaling laws to guide crucial training decisions. Researchers often extrapolate the optimal architecture and hyper parameters settings from smaller training runs by describing the relationship between, loss, or task performance, and scale. All components of this process vary, from the specific equation being fit, to the training setup, to the optimization method. Each of these factors may affect the fitted law, and therefore, the conclusions of a given study. We discuss discrepancies in the conclusions that several prior works reach, on questions such as the optimal token to parameter ratio. We augment this discussion with our own analysis of the critical impact that changes in specific details may effect in a scaling study, and the resulting altered conclusions. Additionally, we survey over 50 papers that study scaling trends: while 45 of these papers quantify these trends using a power law, most under-report crucial details needed to reproduce their findings. To mitigate this, we we propose a checklist for authors to consider while contributing to scaling law research.", "title_embedding_index": 9417, "title_abs_embedding_index": 9442}, {"title": "A multi-region brain model to elucidate the role of hippocampus in spatially embedded decision tasks", "link_suffix": "/forum?id=9Qfja4ZQW0", "link": "https://openreview.net/forum?id=9Qfja4ZQW0", "pdf_link": "https://openreview.net/pdf?id=9Qfja4ZQW0", "keywords": "place cell, grid cell, cognitive map, multi-region interactions, decision making, neuroscience", "abstract": "We present a multi-region brain model exploring the role of the entorhinal-hippocampal circuit in spatially embedded decision-making tasks.\nWe simulate decision-making processes that involve the cognitive maps formed within the CA1 region of the hippocampus in an accumulating-tower task, which we formulate as a reinforcement learning (RL) task.\nOur model integrates a bipartite memory scaffold architecture that incorporates grid and place cells, with an action-selecting recurrent neural network (RNN) that integrates hippocampal representations.\nThrough RL-based simulations, we demonstrate that joint encoding of position and evidence within medial entorhinal cortex, along with sensory projection to hippocampus, replicates experimentally observed place cell representations, and promotes rapid learning and efficient spatial navigation relative to alternative circuits.\nOur findings predict conjunctive spatial and evidence tuning in grid cells, in addition to hippocampus, as essential for decision-making in space.", "title_embedding_index": 9418, "title_abs_embedding_index": 9443}, {"title": "Semantic Aware Representation Learning for Lifelong Learning", "link_suffix": "/forum?id=WwwJfkGq0G", "link": "https://openreview.net/forum?id=WwwJfkGq0G", "pdf_link": "https://openreview.net/pdf?id=WwwJfkGq0G", "keywords": "lifelong learning, continual learning, sparsity, semantic relationships, sparse coding", "abstract": "The human brain excels at lifelong learning by not only encoding information in sparse activation codes but also leveraging rich semantic structures and relationships between newly encountered and previously learned objects. This ability to utilize semantic similarities is crucial for efficient learning and knowledge consolidation, yet is often underutilized in current continual learning approaches. To bridge this gap, we propose Semantic-Aware Representation Learning (SARL) which employs sparse activations and a principled approach to evaluate similarities between objects encountered across different tasks and subsequently uses them to guide representation learning. Using these relationships, SARL enhances the reusability of features and reduces interference between tasks. This approach empowers the model to adapt to new information while maintaining stability, significantly improving performance in complex incremental learning scenarios. Our analysis demonstrates that SARL achieves a superior balance between plasticity and stability by harnessing the underlying semantic structure.", "title_embedding_index": 9419, "title_abs_embedding_index": 9444}, {"title": "Singular Subspace Perturbation Bounds via Rectangular Random Matrix Diffusions", "link_suffix": "/forum?id=G8U2nGP3Vi", "link": "https://openreview.net/forum?id=G8U2nGP3Vi", "pdf_link": "https://openreview.net/pdf?id=G8U2nGP3Vi", "keywords": "Matrix Perturbation Bounds, Matrix Diffusions, Low-rank Approximation", "abstract": "Given a matrix $A \\in \\mathbb{R}^{m\\times d}$ with singular values $\\sigma_1\\geq \\cdots \\geq \\sigma_d$, and a random matrix $G \\in \\mathbb{R}^{m\\times d}$ with iid $N(0,T)$ entries for some $T>0$, we derive  new bounds on the Frobenius distance between subspaces spanned by the top-$k$ (right) singular vectors of $A$ and $A+G$. This problem arises in numerous applications in statistics where a data matrix may be corrupted by Gaussian noise, and in the analysis of the Gaussian mechanism in differential privacy, where Gaussian noise is added to data to preserve private information. We show that, for matrices $A$ where the gaps in the top-$k$ singular values are roughly $\\Omega(\\sigma_k-\\sigma_{k+1})$, the expected Frobenius distance between the subspaces is $\\tilde{O}(\\frac{\\sqrt{d}}{\\sigma_k-\\sigma_{k+1}} \\times \\sqrt{T})$, improving on previous bounds by a factor of $\\frac{\\sqrt{m}}{\\sqrt{d}}$. To obtain our bounds we view the perturbation to the singular vectors as a diffusion process-- the Dyson-Bessel process-- and use tools from stochastic calculus to track the evolution of the subspace spanned by the top-$k$ singular vectors, which may be of independent interest.", "title_embedding_index": 9420, "title_abs_embedding_index": 9445}, {"title": "Mitigating Selection Bias with Node Pruning and Auxiliary Options", "link_suffix": "/forum?id=tNvCSw8ONp", "link": "https://openreview.net/forum?id=tNvCSw8ONp", "pdf_link": "https://openreview.net/pdf?id=tNvCSw8ONp", "keywords": "Large Language Model, Selection Bias", "abstract": "Large language models (LLMs) often show unwarranted preference for certain choice options when responding to multiple-choice questions, posing significant reliability concerns in LLM-automated systems. To mitigate this selection bias problem, previous solutions utilized debiasing methods to adjust the model\u2019s input and/or output. Our work, in contrast, investigates the model\u2019s internal representation of the selection bias. Specifically, we introduce a novel debiasing approach, Bias Node Pruning (BNP), which eliminates the linear layer parameters that contribute to the bias. Furthermore, we present Auxiliary Option Injection (AOI), a simple yet effective input modification technique for debiasing, which is compatible even with black-box LLMs. To provide a more systematic evaluation of selection bias, we review existing metrics and introduce Choice Kullback-Leibler Divergence (CKLD), which addresses the insensitivity of the commonly used metrics to label imbalance. Experiments show that our methods are robust and adaptable across various datasets when applied to three LLMs.", "title_embedding_index": 9421, "title_abs_embedding_index": 9446}, {"title": "LeanAgent: Lifelong Learning for Formal Theorem Proving", "link_suffix": "/forum?id=Uo4EHT4ZZ8", "link": "https://openreview.net/forum?id=Uo4EHT4ZZ8", "pdf_link": "https://openreview.net/pdf?id=Uo4EHT4ZZ8", "keywords": "Theorem Proving, Formal Theorem Proving, Neural Theorem Proving, Lifelong Learning, Formal Mathematics, Large Language Models, LLMs, Curriculum Learning, Proof Search", "abstract": "Large Language Models (LLMs) have been successful in mathematical reasoning tasks such as formal theorem proving when integrated with interactive proof assistants like Lean. Existing approaches involve training or fine-tuning an LLM on a specific dataset to perform well on particular domains, such as undergraduate-level mathematics. These methods struggle with generalizability to advanced mathematics. A fundamental limitation is that these approaches operate on static domains, failing to capture how mathematicians often work across multiple domains and projects simultaneously or cyclically. We present LeanAgent, a novel lifelong learning framework for theorem proving that continuously generalizes to and improves on ever-expanding mathematical knowledge without forgetting previously learned knowledge. LeanAgent introduces several key innovations, including a curriculum learning strategy that optimizes the learning trajectory in terms of mathematical difficulty, a dynamic database for efficient management of evolving mathematical knowledge, and progressive training to balance stability and plasticity. LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics. It performs up to 11$\\times$ better than the static LLM baseline, proving challenging theorems in domains like abstract algebra and algebraic topology while showcasing a clear progression of learning from basic concepts to advanced topics. In addition, we analyze LeanAgent's superior performance on key lifelong learning metrics. LeanAgent achieves exceptional scores in stability and backward transfer, where learning new tasks improves performance on previously learned tasks. This emphasizes LeanAgent's continuous generalizability and improvement, explaining its superior theorem proving performance.", "title_embedding_index": 9422, "title_abs_embedding_index": 9447}, {"title": "Multilevel Generative Samplers for Investigating Critical Phenomena", "link_suffix": "/forum?id=YcUV5apdlq", "link": "https://openreview.net/forum?id=YcUV5apdlq", "pdf_link": "https://openreview.net/pdf?id=YcUV5apdlq", "keywords": "Generative models, Multilevel sampling, Criticality, Renormalization group", "abstract": "Investigating critical phenomena, i.e., phase transitions, is of high interest in physics and chemistry. However, Monte Carlo (MC) simulations, a crucial tool for numerically analyzing macroscopic properties of given systems, are often hindered by the emerging scale invariance at criticality (SIC)---a divergence of the correlation length, which causes the system to behave the same at any length scale, as can be shown with renormalisation group techniques.  Many existing sampling methods suffer from SIC: long-range correlations cause critical slowing down in Markov chain Monte Carlo (MCMC), and require intractably large receptive fields for generative samplers.  In this paper, we propose a Renormalization-informed Generative Critical Sampler (RiGCS)---a novel sampler specialized for near-critical systems, where SIC is leveraged as an advantage rather than a nuisance.  Specifically, RiGCS builds on MultiLevel Monte Carlo (MLMC) with Heat Bath (HB) algorithms, which perform ancestral sampling from low-resolution to high-resolution lattice configurations with site-wise-independent conditional HB sampling.  Although MLMC-HB is highly efficient under exact SIC, it suffers from a low acceptance rate under slight SIC violation---SIC violation always occurs in finite systems, and may induce long-range and higher-order interactions in the renormalized distributions, which are not considered by independent HB samplers.  RiGCS enhances MLMC-HB by replacing a part of the conditional HB samplers with generative models that capture those residual interactions and improve the sampling efficiency---our experiments show that the effective sample size of RiGCS is a few orders of magnitude higher than a state-of-the-art generative baseline in sampling configurations for $128 \\times 128$ two-dimensional Ising systems.  SIC also allows us to adopt a specialized sequential training protocol with model transfer, which significantly accelerates training.", "title_embedding_index": 9423, "title_abs_embedding_index": 9448}, {"title": "Quantitative Certification of Bias in Large Language Models", "link_suffix": "/forum?id=HQHnhVQznF", "link": "https://openreview.net/forum?id=HQHnhVQznF", "pdf_link": "https://openreview.net/pdf?id=HQHnhVQznF", "keywords": "Large Language Models, Bias, Certification", "abstract": "Large Language Models (LLMs) can produce biased responses that can cause representational harms. However, conventional studies are insufficient to thoroughly\nevaluate LLM bias, as they can not scale to large number of inputs and provide\nno guarantees. Therefore, we propose the first framework, QCB (Quantitative\nCertification of Bias) that certifies LLMs for bias on distributions of prompts.\nA certificate consists of high-confidence bounds on the probability of unbiased\nLLM responses for any set of prompts mentioning various demographic groups,\nsampled from a distribution. We illustrate the bias certification for distributions of\nprompts created by applying varying prefixes drawn from a prefix distributions, to a\ngiven set of prompts. We consider prefix distributions for random token sequences,\nmixtures of manual jailbreaks, and jailbreaks in the LLM\u2019s embedding space to\ncertify bias. We obtain non-trivial certified bounds on the probability of unbiased\nresponses of SOTA LLMs, exposing their vulnerabilities over distributions\nof prompts generated from computationally inexpensive distributions of prefixes.", "title_embedding_index": 9424, "title_abs_embedding_index": 9449}]
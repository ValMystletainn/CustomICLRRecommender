[{"title": "Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions", "link_suffix": "/forum?id=pwNIOcr8fU", "link": "https://openreview.net/forum?id=pwNIOcr8fU", "pdf_link": "https://openreview.net/pdf?id=pwNIOcr8fU", "keywords": "Blind Image Quality Assessment; Data Distribution Reshaping; Synthetic Data", "abstract": "Blind image quality assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. Additionally, as a data-based approach, SynDR-IQA can be coupled with model-based methods without increasing inference costs.", "title_embedding_index": 700, "title_abs_embedding_index": 725}, {"title": "Differentially Private Range Subgraph Counting", "link_suffix": "/forum?id=FZS5m1cbFU", "link": "https://openreview.net/forum?id=FZS5m1cbFU", "pdf_link": "https://openreview.net/pdf?id=FZS5m1cbFU", "keywords": "Differential privacy, subgraph, range query", "abstract": "Subgraph counting is a fundamental problem in graph analysis. Motivated by the practical need to perform graph analytics on subgraphs defined by selected vertices (or edges) rather than the entire graph, as well as privacy concerns, we initiate the study of private range subgraph counting. Given an $n$-vertex graph $G$, where each vertex (or edge) has a $d$-dimensional attribute vector, a pattern graph $H$, and a set $Q$ of range queries $q$, our goal is to count the occurrences of $H$ in the subgraph of $G$ induced by vertices (or edges) whose attributes fall within $q$, all while preserving privacy. We give the first $\\varepsilon$-differentially private algorithm for range subgraph counting, achieving near-optimal accuracy (up to a polylogarithmic factor of $n$) for constant privacy parameter $\\varepsilon$ and dimension $d$, with no additional computational overhead compared to non-private algorithms. Empirical evaluations demonstrate that our algorithm significantly outperforms baseline methods in accuracy while ensuring strong privacy guarantees.", "title_embedding_index": 701, "title_abs_embedding_index": 726}, {"title": "Jointly Training Task-Specific Encoders and Downstream Models on Heterogeneous Multiplex Graphs", "link_suffix": "/forum?id=o0X0CPl320", "link": "https://openreview.net/forum?id=o0X0CPl320", "pdf_link": "https://openreview.net/pdf?id=o0X0CPl320", "keywords": "Multiplex, Heterogeneous, GNN, GraphSAGE", "abstract": "Learning representations on Heterogeneous Multiplex Graphs (HMGs) is an active field of study, driven by the need for generating expressive, low-dimensional embeddings to support downstream machine learning tasks. A key component of this process is the design of the graph processing pipeline, which directly impacts the quality of learned representations. Information fusion techniques, which aggregate information across layers of a multiplex graph, have been shown to improve the performance of Graph Neural Network (GNN)-based architectures on various tasks including node classification, link prediction, and graph-level classification. Recent research has explored fusion strategies at different stages of the processing pipeline, leading to graph-, GNN-, embedding-, and prediction-level approaches. In this work, we propose a model extending the GraphSAGE architecture, which simultaneously refines layer-wise embeddings produced by the encoder while training downstream models. We evaluate the model's effectiveness on an HMG derived from a real-world travel dataset, comparing it to models utilizing either graph-level or prediction-level fusion without jointly optimizing their vector embeddings. We demonstrate that our approach enhances the model's performance on downstream tasks, particularly node classification.", "title_embedding_index": 702, "title_abs_embedding_index": 727}, {"title": "Adaptive Drug Interaction Prediction via Enhanced Graph Representation Learning", "link_suffix": "/forum?id=dYTtGFuD3S", "link": "https://openreview.net/forum?id=dYTtGFuD3S", "pdf_link": "https://openreview.net/pdf?id=dYTtGFuD3S", "keywords": "Domain-Aligned\uff0cTransfer Learning\uff0cDrug-Target Interaction", "abstract": "This paper presents a groundbreaking theoretical framework for drug-drug interaction (DDI) prediction that seamlessly integrates domain adaptation (DA) techniques with advanced mathematical concepts. We introduce GraphPharmNet, a novel architecture that operates on DDI-DA bundles, leveraging gauge-equivariant geometric deep learning to capture the intricate structure of drug interactions across domains. Our approach reformulates the DDI prediction problem using the language of differential geometry, optimal transport, and symplectic geometry, viewing domain adaptation as a Hamiltonian flow on a statistical manifold. We develop a cohomological interpretation of domain invariance, characterizing robust DDI prediction features through the lens of persistent homology and sheaf theory. The domain adaptation process is analyzed using a geometric renormalization group framework, revealing a profound connection between the DDI-DA bundle's geometry and the emergence of domain-invariant predictive features. We further elucidate the spectral properties of the DDI-DA Laplacian, providing insights into the topological stability of domain adaptation in DDI prediction. Extensive experiments on benchmark datasets demonstrate that GraphPharmNet significantly outperforms existing methods, particularly in scenarios with limited data or when transferring knowledge across disparate domains. Our results highlight the power of this unified mathematical framework in capturing complex drug interactions and adapting to new domains, paving the way for more accurate, robust, and interpretable DDI prediction models. This work not only advances the field of computational drug discovery but also establishes a rigorous theoretical foundation for domain adaptation in graph-structured data, with potential applications across a wide range of scientific disciplines. Our anonymous github link: \\textbf{https://anonymous.4open.science/r/GraphPharmNet-C9D9}", "title_embedding_index": 703, "title_abs_embedding_index": 728}, {"title": "SportU: A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models", "link_suffix": "/forum?id=x1yOHtFfDh", "link": "https://openreview.net/forum?id=x1yOHtFfDh", "pdf_link": "https://openreview.net/pdf?id=x1yOHtFfDh", "keywords": "Multimodal Large Language Models, Sports Understanding, Benchmark", "abstract": "Multimodal Large Language Models (MLLMs) are advancing the ability to reason about complex sports scenarios by integrating textual and visual information. To comprehensively evaluate their capabilities, we introduce SPORTU, a benchmark designed to assess MLLMs across multi-level sports reasoning tasks. SPORTU comprises two key components: SPORTU-text, featuring 900 multiple-choice questions with human-annotated explanations for rule comprehension and strategy understanding. This component focuses on testing models' ability to reason about sports solely through question-answering (QA), without requiring visual inputs; SPORTU-video, consisting of 1,701 slow-motion video clips across 7 different sports and 12,048 QA pairs, designed to assess multi-level reasoning, from simple sports recognition to complex tasks like foul detection and rule application. We evaluate four prevalent LLMs mainly utilizing few-shot learning paradigms supplemented by chain-of-thought (CoT) prompting on the SPORTU-text part. We evaluate four LLMs using few-shot learning and chain-of-thought (CoT) prompting on SPORTU-text. GPT-4o achieves the highest accuracy of 71%, but still falls short of human-level performance, highlighting room for improvement in rule comprehension and reasoning. The evaluation for the SPORTU-video part includes 7 proprietary and 6 open-source MLLMs. Experiments show that models fall short on hard tasks that require deep reasoning and rule-based understanding. Claude-3.5-Sonnet performs the best with only 52.6% accuracy on the hard task, showing large room for improvement. We hope that SPORTU will serve as a critical step toward evaluating models' capabilities in sports understanding and reasoning. The dataset is available at \\url{https://anonymous.4open.science/r/ICLR_01-42D5/}", "title_embedding_index": 704, "title_abs_embedding_index": 729}, {"title": "Improving the Sparse Structure Learning of Spiking Neural Networks from the View of Compression Efficiency", "link_suffix": "/forum?id=gcouwCx7dG", "link": "https://openreview.net/forum?id=gcouwCx7dG", "pdf_link": "https://openreview.net/pdf?id=gcouwCx7dG", "keywords": "spiking neural networks", "abstract": "The human brain utilizes spikes for information transmission and dynamically reorganizes its network structure to boost energy efficiency and cognitive capabilities throughout its lifespan. Drawing inspiration from this spike-based computation, Spiking Neural Networks (SNNs) have been developed to construct event-driven models that emulate this efficiency. Despite these advances, deep SNNs continue to suffer from over-parameterization during training and inference, a stark contrast to the brain\u2019s ability to self-organize. Furthermore, existing sparse SNNs are challenged by maintaining optimal pruning levels due to a static pruning ratio, resulting in either under or over-pruning.\nIn this paper, we propose a novel two-stage dynamic structure learning approach for deep SNNs, aimed at maintaining effective sparse training from scratch while optimizing compression efficiency. \nThe first stage evaluates the compressibility of existing sparse subnetworks within SNNs using the PQ index, which facilitates an adaptive determination of the rewiring ratio for synaptic connections based on data compression insights. In the second stage, this rewiring ratio critically informs the dynamic synaptic connection rewiring process, including both pruning and regrowth. This approach significantly improves the exploration of sparse structures training in deep SNNs, adapting sparsity dynamically from the point view of compression efficiency.\nOur experiments demonstrate that this sparse training approach not only aligns with the performance of current deep SNNs models but also significantly improves the efficiency of compressing sparse SNNs. Crucially, it preserves the advantages of initiating training with sparse models and offers a promising solution for implementing Edge AI on neuromorphic hardware.", "title_embedding_index": 705, "title_abs_embedding_index": 730}, {"title": "SIM: Surface-based fMRI Analysis for Inter-Subject Multimodal Decoding from Movie-Watching Experiments", "link_suffix": "/forum?id=OJsMGsO6yn", "link": "https://openreview.net/forum?id=OJsMGsO6yn", "pdf_link": "https://openreview.net/pdf?id=OJsMGsO6yn", "keywords": "task-fMRI, cortical analysis, transformers, multimodal learning, contrastive learning, self-supervised learning", "abstract": "Current AI frameworks for brain decoding and encoding, typically train and test models within the same datasets. This limits their utility for brain computer interfaces (BCI) or neurofeedback, for which it would be useful to pool experiences across individuals to better simulate stimuli not sampled during training. A key obstacle to model generalisation is the degree of variability of intersubject cortical organisation, which makes it difficult to align or compare cortical signals across participants. In this paper we address this through use of surface vision transformers, which build a generalisable model of cortical functional dynamics, through encoding the topography of cortical networks and their interactions as a moving image across a surface. This is then combined with tri-modal self-supervised contrastive (CLIP) alignment of audio, video, and fMRI modalities to enable the retrieval of visual and auditory stimuli from patterns of cortical activity (and vice-versa).  We validate our approach on 7T task-fMRI data from 174 healthy participants engaged in the movie-watching experiment from the Human Connectome Project (HCP). Results show that our model can correctly identify video and audio samples from 3-second fMRI recordings with high accuracy for unseen subjects - tested on the same stimuli seen during training (up to 80% top-1 accuracy) - and can effectively generalise to unseen movie segments, in unseen subjects (20% top-1 and 80% top-10 accuracy). Further analysis of attention maps reveals that our model captures individual patterns of brain activity that reflect semantic and visual systems. This opens the door to future personalised simulations of brain function. Code & pre-trained models will be made available at \\url{https://github.com/}, processed data for training will be available upon request at \\url{https://gin.g-node.org}", "title_embedding_index": 706, "title_abs_embedding_index": 731}, {"title": "Tensor Train Decomposition for Adversarial Attacks on Computer Vision Models", "link_suffix": "/forum?id=WVzYMa68Of", "link": "https://openreview.net/forum?id=WVzYMa68Of", "pdf_link": "https://openreview.net/pdf?id=WVzYMa68Of", "keywords": "tensor train, optimization, attribution, adversarial attack, computer vision, black box", "abstract": "Deep neural networks (DNNs) are widely used today, but they are vulnerable to adversarial attacks. To develop effective methods of defense, it is important to understand the potential weak spots of DNNs. Often attacks are organized taking into account the architecture of models (white-box approach) and based on gradient methods, but for real-world DNNs this approach in most cases is impossible. At the same time, several gradient-free optimization algorithms are used to attack black-box models. However, classical methods are often ineffective in the multidimensional case. To organize black-box attacks for computer vision models, in this work, we propose the use of an optimizer based on the low-rank tensor train (TT) format, which has gained popularity in various practical multidimensional applications in recent years. Combined with the attribution of the target image, which is built by the auxiliary (white-box) model, the TT-based optimization method makes it possible to organize an effective black-box attack by small perturbation of pixels in the target image. The superiority of the proposed approach over three popular baselines is demonstrated for seven modern DNNs on the ImageNet dataset.", "title_embedding_index": 707, "title_abs_embedding_index": 732}, {"title": "Detecting Discrepancies Between Generated and Natural Images Using Uncertainty", "link_suffix": "/forum?id=pIVOSU7TFQ", "link": "https://openreview.net/forum?id=pIVOSU7TFQ", "pdf_link": "https://openreview.net/pdf?id=pIVOSU7TFQ", "keywords": "AI-generated image detection", "abstract": "In this work, we propose a novel approach for detecting AI-generated images by leveraging predictive uncertainty to mitigate misuse and associated risks. The motivation arises from the fundamental assumption regarding the distributional discrepancy between natural and AI-generated images.The feasibility of distinguishing natural images from AI-generated ones is grounded in the distribution discrepancy between them. Predictive uncertainty offers an effective approach for capturing distribution shifts, thereby providing insights into detecting AI-generated images. Namely, as the distribution shift between training and testing data increases, model performance typically degrades, often accompanied by increased predictive uncertainty. Therefore, we propose to employ predictive uncertainty to reflect the discrepancies between AI-generated and natural images. In this context, the challenge lies in ensuring that the model has been trained over sufficient natural images to avoid the risk of determining the distribution of natural images as that of generated images. We propose to leverage large-scale pre-trained models to calculate the uncertainty as the score for detecting AI-generated images. This leads to a simple yet effective method for detecting AI-generated images using large-scale vision models: images that induce high uncertainty are identified as AI-generated. Comprehensive experiments across multiple benchmarks demonstrate the effectiveness of our method.", "title_embedding_index": 708, "title_abs_embedding_index": 733}, {"title": "SERDES Link Training with Edge Inference: Neural-Network Driven Discrete Optimization to Maximize Link Efficiency", "link_suffix": "/forum?id=OX4Tk43uwv", "link": "https://openreview.net/forum?id=OX4Tk43uwv", "pdf_link": "https://openreview.net/pdf?id=OX4Tk43uwv", "keywords": "CNN, ILP, Gumbel-Softmax, discrete optimization, edge inference, affine translation, hardware, microcontroller", "abstract": "Meeting the growing data demands of modern AI applications requires efficient, high-speed communication links.  In this paper, we propose an edge inference framework that leverages integer linear programming (ILP) and neural network-based discrete optimization to optimize non-uniform quantization levels in programmable analog-to-digital converter (ADC) receivers. The goal is to determine the optimal quantization levels and their assignment for each bit pattern across multi-lane high-speed links. Although ILP provides high-quality solutions, its computational cost makes it unsuitable for on-chip use. To address this, we train a convolutional neural network (CNN) using ILP solver results, enabling efficient on-chip edge inference. Our custom loss function, which outperforms standard metrics like cross-entropy and mean squared error (MSE), reduces area metric errors from 29% to less than 2%. By deploying the CNN within a microcontroller, our system adapts to changing channel conditions, improving error rates and reducing energy consumption, thereby maximizing link efficiency", "title_embedding_index": 709, "title_abs_embedding_index": 734}, {"title": "Adaptive Tensor Attention Networks with Cross-Domain Transfer for Drug-Target Interaction Prediction", "link_suffix": "/forum?id=i3f2N3iHl0", "link": "https://openreview.net/forum?id=i3f2N3iHl0", "pdf_link": "https://openreview.net/pdf?id=i3f2N3iHl0", "keywords": "Domain Adaptive Prediction\uff0cAttention", "abstract": "The prediction of drug-target interactions is fundamental to the advancement of drug discovery. We present a groundbreaking unified theory for Drug-Target Interaction prediction with Domain Adaptation (DTI-DA), seamlessly integrating concepts from quantum mechanics, differential geometry, and information theory. Our framework introduces a novel DTI symplectic structure that captures the intrinsic geometry of drug-target interactions, leading to a Quantum Optimal Transport theorem that provides a rigorous foundation for domain adaptation in the DTI context. We develop a quantum statistical mechanical formulation of DTI-DA, introducing DTI-preserving quantum channels and deriving a Quantum Wasserstein distance tailored to drug discovery applications. Our information-geometric perspective yields a Quantum Fisher-Rao metric for DTI, resulting in a quantum Cramer-Rao bound that establishes fundamental limits on DTI prediction accuracy. We propose a unified variational principle for DTI-DA, encompassing quantum and classical aspects, which leads to a novel algorithm based on geometric stochastic gradient Langevin dynamics. Furthermore, we extend classical statistical inference to the quantum domain, deriving a Quantum Rao-Blackwell theorem and a Quantum Bayesian Cramer-Rao bound specifically for DTI-DA. These theoretical advancements not only deepen our understanding of the DTI-DA problem but also suggest new algorithmic approaches with provable guarantees. Preliminary numerical experiments on quantum-inspired DTI-DA algorithms demonstrate significant improvements in prediction accuracy and domain adaptation capabilities compared to classical methods, particularly for challenging out-of-distribution scenarios in drug discovery.", "title_embedding_index": 710, "title_abs_embedding_index": 735}, {"title": "Zero-Shot Task-Level Adaptation via Coarse-to-Fine Policy Refinement and Holistic-Local Contrastive Representations", "link_suffix": "/forum?id=g6iiIUvhko", "link": "https://openreview.net/forum?id=g6iiIUvhko", "pdf_link": "https://openreview.net/pdf?id=g6iiIUvhko", "keywords": "Meta-RL, Zero-shot Task-level Adaptation, Contrastive Representations", "abstract": "Meta-reinforcement learning offers a mechanism for zero-shot adaptation, enabling agents to handle new tasks with parametric variation in real-world environments. However, existing methods still struggle with task-level adaptation, which demands generalization beyond simple variations within tasks, thereby limiting their practical effectiveness. This limitation stems from several challenges, including the poor task representations and inefficient policy learning, resulting from the underutilization of hierarchical structure inherent in task-level adaptation. To address these challenges, we propose a Coarse-to-Fine Policy Refinement combined with a Holistic-Local Contrastive Representation method to enable effective zero-shot policy adaptation. Specifically, in terms of policy learning, we use task language instructions as prior knowledge to select skill-specific expert modules as a coarse policy. This coarse policy is then refined by a fine policy generated through a hypernetwork, producing a task-aware policy based on task representations. Additionally, for task representation, we employ contrastive learning from both holistic and local perspectives to enhance task representations for more effective policy adaptation. Experimental results demonstrate that our method significantly improves learning efficiency and zero-shot adaptation on new tasks, outperforming previous methods by approximately 42.3% and 45.4% in success rate on the Meta-World ML-10 and ML-45 benchmarks, respectively.", "title_embedding_index": 711, "title_abs_embedding_index": 736}, {"title": "Black-Box Approximation and Optimization with Hierarchical Tucker Decomposition", "link_suffix": "/forum?id=jQiJRxNymY", "link": "https://openreview.net/forum?id=jQiJRxNymY", "pdf_link": "https://openreview.net/pdf?id=jQiJRxNymY", "keywords": "Black-box optimization, black-box approximation, gradient-free method, low rank representation, hierarchical Tucker decomposition", "abstract": "We develop a new method HTBB for the multidimensional black-box approximation and gradient-free optimization, which is based on the low-rank hierarchical Tucker decomposition with the use of the MaxVol indices selection procedure. Numerical experiments for 14 complex model problems demonstrate the robustness of the proposed method for dimensions up to 1000, while it shows significantly more accurate results than classical gradient-free optimization methods, as well as approximation and optimization methods based on the popular tensor train decomposition, which represents a simpler case of a tensor network.", "title_embedding_index": 712, "title_abs_embedding_index": 737}, {"title": "TopInG: Topologically Interpretable Graph Learning via Persistent Rationale Filtration", "link_suffix": "/forum?id=ZaSOGF8Ojq", "link": "https://openreview.net/forum?id=ZaSOGF8Ojq", "pdf_link": "https://openreview.net/pdf?id=ZaSOGF8Ojq", "keywords": "topological data analysis, persistent homology, graph neural network, interpretability, explainability, filtration learning", "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance in various scientific domains, but their lack of interpretability limits their applicability in critical decision-making processes. Recently, intrinsic interpretable GNNs have been studied to provide insights into model predictions by identifying rationale substructures in graphs. However, existing methods face challenges when the underlying rationale subgraphs are complicated and variable. To address this challenge,\nwe propose TopIng, a novel topological framework to interpretable GNNs that leverages persistent homology to identify persistent rationale subgraphs.\nOur method introduces a rationale filtration learning technique that models the generating procedure of rationale subgraphs, and enforces the persistence of topological gap between rationale subgraphs and complement random graphs by a novel self-adjusted topological constraint, topological discrepancy. We show that our topological discrepancy is a lower bound of a Wasserstein distance on graph distributions with Gromov-Hausdorff metric. \nWe provide theoretical guarantees showing that our loss is uniquely optimized by the ground truth under certain conditions.\nThrough extensive experiments on varaious synthetic and real datasets, we demonstrate that TopIng effectively addresses key challenges in interpretable GNNs including handling variiform rationale subgraphs, balancing performance with interpretability, and avoiding spurious correlations. \nExperimental results show that our approach improves state-of-the-art methods up to 20%+ on both predictive accuracy and interpretation quality.", "title_embedding_index": 713, "title_abs_embedding_index": 738}, {"title": "Generalization for Least Squares Regression with Simple Spiked Covariances", "link_suffix": "/forum?id=zxqdVo9FjY", "link": "https://openreview.net/forum?id=zxqdVo9FjY", "pdf_link": "https://openreview.net/pdf?id=zxqdVo9FjY", "keywords": "Generalization, Random Matrix Theory, Spiked Covariance, Two Layer Network, Layer Wise Training", "abstract": "Random matrix theory has proven to be a valuable tool in analyzing the generalization of linear models. However, the generalization properties of even two-layer neural networks trained by gradient descent remain poorly understood. To understand the generalization performance of such networks, it is crucial to characterize the spectrum of the feature matrix at the hidden layer.\nRecent work has made progress in this direction by describing the spectrum after a single gradient step, revealing a spiked covariance structure. Yet, the generalization error for linear models with spiked covariances has not been previously determined.\nThis paper addresses this gap by examining two simple models exhibiting spiked covariances. We derive their generalization error in the asymptotic proportional regime. Our analysis demonstrates that the eigenvector and eigenvalue corresponding to the spike significantly influence the generalization error.", "title_embedding_index": 714, "title_abs_embedding_index": 739}, {"title": "MvHSTM: A Multi-view Hypergraph Spatio-Temporal Model for Traffic Speed Forecasting", "link_suffix": "/forum?id=H1nykRhieN", "link": "https://openreview.net/forum?id=H1nykRhieN", "pdf_link": "https://openreview.net/pdf?id=H1nykRhieN", "keywords": "Traffic Prediction, Deep Learning, Hypergraph Convolution", "abstract": "Accurate traffic speed prediction is critical in modern society as it is effective for both individuals and authorities. Due to the large scale of urban road networks, traffic speed exhibits complex spatio-temporal dependencies, not only among adjacent nodes but also across the network, reflecting both local and cross-regional simultaneous correlations. However, existing studies have not effectively addressed these characteristics. In this context, we propose a novel framework called Multi-view Hypergraph Spatio-Temporal Model (MvHSTM) that employs a temporal transformer to capture temporal dependencies and utilizes hypergraph convolutional networks to inherently model spatial relationships. Specifically, we introduce two hypergraph construction methods, the Geographical Adjacency Hypergraph (GAH) and the Feature Similarity Hypergraph (FSH), to capture spatial correlations on neighboring and non-neighboring scales. Extensive experiments on real-world traffic speed datasets demonstrate that our approach achieves state-of-the-art performance compared to baseline methods.", "title_embedding_index": 715, "title_abs_embedding_index": 740}, {"title": "Evo-Step: Evolutionary Generation and Stepwise Validation for Optimizing LLMs in OR", "link_suffix": "/forum?id=aapUBU9U0D", "link": "https://openreview.net/forum?id=aapUBU9U0D", "pdf_link": "https://openreview.net/pdf?id=aapUBU9U0D", "keywords": "Large language model; Operations Research; Automated Modeling", "abstract": "Large Language Models (LLMs) have revolutionized various domains, but they face challenges when applied to highly specialized fields such as Operations Research (OR). In this work, we present Evo-Step-Instruct, a novel framework that progressively increases the complexity of generated problems using an evolutionary strategy, aimed at enhancing the capabilities of LLMs in optimization modeling. Our framework integrates stepwise validation, which ensures real-time error detection and correction during data generation, thereby improving data quality and preventing error propagation. We fine-tune open-source LLMs, such as LLaMA-3-8B and Mistral-7B, using the generated high-quality dataset, resulting in a model, Evo-Step, that significantly outperforms baseline approaches on key benchmarks including NL4OPT, MAMO, and IndustryOR. Through extensive experiments, Evo-Step demonstrates superior performance, especially in handling complex OR tasks, achieving a notable improvement of 17.01% in micro average accuracy on difficult problems. Our approach represents a substantial advancement in automating complex decision-making processes using LLM,  showcasing the potential of combining evolutionary problem generation with structured validation for fine-tuning LLMs.", "title_embedding_index": 716, "title_abs_embedding_index": 741}, {"title": "Predicting episodic structure from overlapping input in binary networks with homeostasis", "link_suffix": "/forum?id=NgvL7aMaTI", "link": "https://openreview.net/forum?id=NgvL7aMaTI", "pdf_link": "https://openreview.net/pdf?id=NgvL7aMaTI", "keywords": "Semantics, Episodes, Homeostasis, Regularization, Hopfield Network, Synaptic Plasticity, Predictive Learning", "abstract": "How neural networks process overlapping input patterns is a fundamental question in both neuroscience and artificial intelligence. Traditionally, overlaps in neural activity are viewed as interference, requiring separation for better performance. However, an alternative perspective suggests that these overlaps may encode meaningful semantic relationships between concepts. In this paper, we propose a framework where persistent overlap between input patterns represent semantic components across episodic experiences, and the statistics of these overlaps how each semantic element relates to the rest.To explore this idea, we introduce an Episode Generation Protocol (EGP) that defines a mapping between the semantic structure of episodes and input pattern generation. Paired with our EGP, we use Homeostatic Binary Networks (HBNs), a simplified yet biologically-inspired model incorporating key features such as adjustable inhibition, Hebbian learning, and homeostatic plasticity.Our contributions are threefold: (1) We formalize a link between episodic semantics and neural patterns through our EGP. (2) We introduce HBNs as an analytically tractable model that directly connects episodic semantics to learning dynamics. (3) We show that HBNs perform robust pattern completion under noisy and masked inputs, aligning their performance with Maximum A Posteriori (MAP) and Maximum Likelihood Estimation (MLE) strategies depending on the homeostatic regime.These findings shed light on how neural networks might extract and preserve semantic content from overlapping patterns, offering a pathway for unifying associative and predictive learning theories in both biological and artificial systems.", "title_embedding_index": 717, "title_abs_embedding_index": 742}, {"title": "Advantages, Risks and Insights from Comparing In-Context Learning Models with Typical Meta-Learners", "link_suffix": "/forum?id=iLUcsecZJp", "link": "https://openreview.net/forum?id=iLUcsecZJp", "pdf_link": "https://openreview.net/pdf?id=iLUcsecZJp", "keywords": "In-Context Learning, Meta-Learning", "abstract": "We investigate in-context learning (ICL) models from the perspective of learning to learn. Unlike existing works understanding what exact explicit learning algorithms can and do ICL models learn, we compares ICL model with typical meta-learners to obtain end-to-end understanding on more general settings. We theoretically prove its expressiveness as learning algorithms and investigate its learnability and generalizability on extensive settings. It is demonstrated that ICL with transformers can effectively learn optimal learning algorithms data-dependently in an inclusive space containing existing gradient-based, metric-based and amortization-based meta-learners. However, the generalizability of these learning algorithms is identified to be a critical issue, as the learned algorithm could be implicitly fitting the training distribution rather than an explicit learning algorithm. Based on above understanding, we propose to systematically transfer deep-learning techniques which have been widely-studied in supervised-learning to meta-learning to address their common challenges. We practice meta-level meta-learning for domain-adaptability with few data and meta-level curriculum learning for fast convergence in pre-training as examples, showing their empirical effectiveness.", "title_embedding_index": 718, "title_abs_embedding_index": 743}, {"title": "Evaluating Large Language Models through Role-Guide and Self-Reflection: A Comparative Study", "link_suffix": "/forum?id=E36NHwe7Zc", "link": "https://openreview.net/forum?id=E36NHwe7Zc", "pdf_link": "https://openreview.net/pdf?id=E36NHwe7Zc", "keywords": "LLMs, Evaluation, Verbalized confidence", "abstract": "Large Language Models fine-tuned with Reinforcement Learning from Human Feedback (RLHF-LLMs) can over-rely on aligned preferences without truly gaining the self-knowledge, leading to hallucination and biases. If an LLM can better access its knowledge and know what it knows, it can avoid making false or unsupported claims. Therefore, it is crucial to evaluate whether LLMs have the ability to know what they know, which can help to ensure accuracy and faithfulness in real-world applications. Inspired by research in Educational Psychology, students who don't really know are easily affected by teacher and peer guidance, we treat LLM as a student, incorporate role guidance in prompts to explore whether LLMs really know. Specifically, we propose a novel strategy calledRole-Guide andSelf-Reflection (RoSe) to fully assess whether LLM ``knows it knows''. We introduce multiple combinations of different roles and strong reminder in prompts combined with self-reflection to explore what local information LLMs rely on, and whether LLMs remain unaffected by external guidance with varying roles. Our findings reveal that LLMs are very sensitive to the strong reminder information. Role guidance can help LLMs reduce their reliance on strong reminder. Meanwhile, LLMs tend to trust the role of authority more when guided by different roles. Following these findings, we propose a double-calibrated strategy with verbalized confidence to extract well-calibrated data from closed-source LLM and fine-tune open-source LLMs. Extensive experiments conducted on fine-tuning open-source LLMs demonstrate the effectiveness of double-calibrated strategy in mitigating the reliance of LLMs on local information. For a thorough comparison, we not only employ public JEC-QA and openBookQA datasets, but also constructEG-QAwhich containsEnglishGrammar multiple-choice question-answering and 14 key knowledge points for assessing self-knowledge and logical reasoning.", "title_embedding_index": 719, "title_abs_embedding_index": 744}, {"title": "Time-aware World Model:  Adaptive Learning of Task Dynamics", "link_suffix": "/forum?id=8lwWBSa1pJ", "link": "https://openreview.net/forum?id=8lwWBSa1pJ", "pdf_link": "https://openreview.net/pdf?id=8lwWBSa1pJ", "keywords": "RL, Dynamics, World Model", "abstract": "In this work, we introduce Time-Aware World Model, a model-based approach designed to explicitly incorporate the temporal dynamics of environments. By conditioning on the time step size, $\\Delta t$, and training over a diverse range of $\\Delta t$ values - rather than relying on a fixed time step size - our model enables learning of both high- and low-frequency task dynamics in real-world control problems. Inspired by the information-theoretic principle that the optimal sampling rate varies depending on the underlying dynamics of different physical systems, our time-aware model enhances both performance and learning efficiency. Empirical evaluations demonstrate that our model consistently outperforms baseline approaches across different observation rates in various control tasks, using the same number of training samples and iterations. We will release our source code on GitHub once the final review decisions are made.", "title_embedding_index": 720, "title_abs_embedding_index": 745}, {"title": "Advancing Drug-Target Interaction Prediction via Graph Transformers and Residual Protein Embeddings", "link_suffix": "/forum?id=S2WHlhvFGg", "link": "https://openreview.net/forum?id=S2WHlhvFGg", "pdf_link": "https://openreview.net/pdf?id=S2WHlhvFGg", "keywords": "DTI\uff0cTransfer Learning", "abstract": "Predicting drug-target interactions (DTIs) is essential for advancing drug discovery. This paper presents a unified mathematical framework for unsupervised domain adaptation in drug-target interaction (DTI) prediction, integrating measure theory, functional analysis, information geometry, and optimal transport theory. We introduce the novel concept of DTI-Wasserstein distance, incorporating both structural and chemical similarities of drugs and targets, and establish a refined bound on the difference between source and target risks. Our information-geometric perspective reveals the intrinsic structure of the DTI model space, characterizing optimal adaptation paths as geodesics on a statistical manifold equipped with the Fisher-Rao metric. We develop a spectral decomposition of the DTI-DA transfer operator, providing insights into the modes of information transfer between domains. This leads to the introduction of DTI-spectral embedding and DTI-spectral mutual information, allowing for a more nuanced understanding of the adaptation process. Theoretical contributions include refined bounds on DTI-DA performance, incorporating task-specific considerations and spectral properties of the feature space. We prove the existence of an optimal transport map for DTI-DA and derive a novel information-theoretic lower bound using DTI-mutual information. Empirical evaluations demonstrate the superiority of our approach over existing methods across multiple benchmark datasets, showcasing its ability to effectively leverage data from diverse sources for improved DTI prediction.", "title_embedding_index": 721, "title_abs_embedding_index": 746}, {"title": "Spider 2.0: Can Language Models Resolve Real-World Enterprise Text-to-SQL Workflows?", "link_suffix": "/forum?id=XmProj9cPs", "link": "https://openreview.net/forum?id=XmProj9cPs", "pdf_link": "https://openreview.net/pdf?id=XmProj9cPs", "keywords": "LLM Benchmark, Data Science and Engineering, Code Generation, Text-to-SQL, LLM Agent", "abstract": "Real-world enterprise text-to-SQL workflows often involve complex cloud or local data across various database systems, multiple SQL queries in various dialects, and diverse operations from data transformation to analytics.\nWe introduce Spider 2.0, an evaluation framework comprising $595$ real-world text-to-SQL workflow problems derived from enterprise-level database use cases. \nThe databases in Spider 2.0 are sourced from real data applications, often containing over 1,000 columns and stored in local or cloud database systems such as BigQuery and Snowflake.\nWe show that solving problems in Spider 2.0 frequently requires understanding and searching through database metadata, dialect documentation, and even project-level codebases. \nThis challenge calls for models to interact with complex SQL workflow environments, process extremely long contexts, perform intricate reasoning, and generate multiple SQL queries with diverse operations, often exceeding $100$ lines, which goes far beyond traditional text-to-SQL challenges.\nOur evaluations indicate that based on o1-preview, our code agent framework successfully solves only 15.1% of the tasks, compared with 91.2% on Spider 1.0 and 73.0% on BIRD.\nOur results on Spider 2.0 show that while language models have demonstrated remarkable performance in code generation --- especially in prior text-to-SQL benchmarks --- they require significant improvement in order to achieve adequate performance for real-world enterprise usage.\nProgress on Spider 2.0 represents crucial steps towards developing intelligent, autonomous, code agents for real-world enterprise settings.", "title_embedding_index": 722, "title_abs_embedding_index": 747}, {"title": "Exploring Complex Trade-offs in Information Bottleneck through Multi-Objective Optimization", "link_suffix": "/forum?id=GlqeLNjH6p", "link": "https://openreview.net/forum?id=GlqeLNjH6p", "pdf_link": "https://openreview.net/pdf?id=GlqeLNjH6p", "keywords": "Information Bottleneck \uff0cMulti-objective Optimization\uff0cMutual Information", "abstract": "Information Bottleneck (IB) theory provides a principled approach to analyze and optimize how neural networks extract and learn latent representations from data, aiming to enhance network performance and generalization. The IB framework has been applied and validated across various domains in deep learning. However, most studies employing IB require tuning of Lagrange multipliers to balance compression and prediction during optimization. Finding the optimal Lagrange multiplier $\\beta$ to achieve the best balance between compression and prediction is challenging, relying heavily on empirical tuning and potentially failing to capture the complex trade-offs present within the IB paradigm. In this paper, we redefine the IB problem as a multi-objective optimization problem with respect to compression and prediction objectives. We employ a gradient-based multi-objective optimization algorithm that adaptively determines the weights for this optimization challenge. Our method is demonstrated to automatically find Pareto-optimal solutions, achieving a balance between compression and prediction, and exploring more complex Pareto frontiers than linear weighting. We compare our approach with the Variational Information Bottleneck and its variants across different datasets. Empirical results confirm that our method achieves a more stable and optimal trade-off compared to Information Bottleneck approaches with manually-tuned multipliers. The code is available in \\url{https://anonymous.4open.science/r/ASDGASDG}.", "title_embedding_index": 723, "title_abs_embedding_index": 748}, {"title": "JudgeLM: Fine-tuned Large Language Models are Scalable Judges", "link_suffix": "/forum?id=xsELpEPn4A", "link": "https://openreview.net/forum?id=xsELpEPn4A", "pdf_link": "https://openreview.net/pdf?id=xsELpEPn4A", "keywords": "LLM Judging", "abstract": "Evaluating Large Language Models (LLMs) in open-ended scenarios is challenging because existing benchmarks and metrics can not measure them comprehensively. To address this problem, we propose to fine-tune LLMs as scalable judges (JudgeLM) to evaluate LLMs efficiently and effectively in open-ended benchmarks. We first propose a comprehensive, large-scale, high-quality dataset containing task seeds, LLMs-generated answers, and GPT-4-generated judgments for fine-tuning high-performance judges, as well as a new benchmark for evaluating the judges. We train JudgeLM at different scales from 7B, 13B, to 33B parameters, and conduct a systematic analysis of its capabilities and behaviors. We then analyze the key biases in fine-tuning LLM as a judge and consider them as position bias, knowledge bias, and format bias. To address these issues, JudgeLM introduces a bag of techniques including swap augmentation, reference support, and reference drop, which clearly enhance the judge's performance. JudgeLM obtains the state-of-the-art judge performance on both the existing PandaLM benchmark and our proposed new benchmark. Our JudgeLM is efficient and the JudgeLM-7B only needs 3 minutes to judge 5K samples with 8 A100 GPUs. JudgeLM obtains high agreement with the teacher judge, achieving an agreement exceeding 90% that even surpasses human-to-human agreement. JudgeLM also demonstrates extended capabilities in being judges of the single answer, multimodal models, multiple answers, multi-turn chat, etc.", "title_embedding_index": 724, "title_abs_embedding_index": 749}]
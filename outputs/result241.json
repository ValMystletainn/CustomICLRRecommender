[
    {
        "title": "Dual-level Prototypes Guidance for Single-frame Temporal Action Localization",
        "link_suffix": "/forum?id=PageLgQlXz",
        "link": "https://openreview.net/forum?id=PageLgQlXz",
        "pdf_link": "https://openreview.net/pdf?id=PageLgQlXz",
        "keywords": "Temporal action localization, Single-frame annotations, Memory bank, Graph matching random walk",
        "abstract": "In recent, single-frame temporal action localization (STAL) has captured the attention of the computer vision community. Due to the sparse single-frame annotations, current STAL methods generally employ pseudo-labels strategies to bridge the gap between weakly-supervised methods and fully-supervised methods. However, these methods derive pseudo-labels from single-frame of the corresponding instances, yet the intra-class affinity from the current single-frame to other action snippets remains neglected. To capitalize on this affinity, we design a dual-level prototypes guidance (DPG) method with the graph matching random walk (Gm-Rw) algorithm to achieve instance-level and video-level prototype guidance for pseudo-labels refinement. For instance-level guidance, the Gm-Rw exploits the high affinity prototype among instances of the current video to build intra-class associations. For video-level guidance, an online memory bank is constructed to iteratively summarize more discriminative prototype. After Gm-Rw builds affinity among intra-class videos, an exponential moving average (EMA) mechanism is designed to achieve dual-level prototypes guidance for pseudo-labels refinement. Notably, the dual-level guidance is mutually reinforcing, prompting us to propose a novel adaptive collaborative strategy (ACS) for dynamic optimization. Extensive experiments on THUMOS14, GTEA, BEOID, and ActivityNet1.3 reveal that our method significantly outperforms state-of-the-art methods."
    },
    {
        "title": "An Open Quantum Chemistry Property Database of 120 Kilo Molecules with 20 Million Conformers",
        "link_suffix": "/forum?id=o6aUi3ukdd",
        "link": "https://openreview.net/forum?id=o6aUi3ukdd",
        "pdf_link": "https://openreview.net/pdf?id=o6aUi3ukdd",
        "keywords": "Quantum Chemistry, Machine Learning, Organic Molecules",
        "abstract": "Artificial intelligence is revolutionizing computational chemistry, bringing unprecedented innovation and efficiency to the field. To further advance research and expedite progress, we introduce the Quantum Open Organic Molecular (QO2Mol) database \u2014 a large-scale quantum chemistry dataset designed for professional and transformative research in organic molecular sciences under an open-source license. The database comprises 120,000 organic molecules and approximately 20 million conformers, encompassing 10 different elements (C, H, O, N, S, P, F, Cl, Br, I), with heavy atom counts exceeding 40. Utilizing the high-precision B3LYP/def2-SVP quantum mechanical level, each conformation was meticulously computed for quantum mechanical properties, including potential energy and forces. These molecules are derived from fragments of compounds in ChEMBL, ensuring their structural relevance to real-world compounds. Its extensive coverage of molecular structures and diverse elemental composition enables comprehensive studies of structure-property relationships, enhancing the accuracy and applicability of machine learning models in predicting molecular behaviors. The QO2Mol database and benchmark codes are available athttps://github.com/ikovey/QO2Mol/."
    },
    {
        "title": "A Semi-Supervised Clustering Approach For Graph Learning with Neural Networks",
        "link_suffix": "/forum?id=iT4ImLQatF",
        "link": "https://openreview.net/forum?id=iT4ImLQatF",
        "pdf_link": "https://openreview.net/pdf?id=iT4ImLQatF",
        "keywords": "Semi-Supervised Clustering, Node Classification, Graph Clustering, Stochastic Block Model, Graph Neural Network, Transformer, MLP",
        "abstract": "This work studies a semi-supervised approach that uses unsupervised clustering objectives alongside supervised objectives for training neural networks to improve node classification in attributed graphs, particularly when training labels are sparse.\n    Our approach frames node classification as semi-supervised inference of neural network models of attributed graphs with cluster structure.\n    This allows us to cast multiple node clustering and classification approaches into a common framework of generative models which include graph neural networks, graph autoencoders, and proposed variants of neural-prior stochastic block model and contextual stochastic block model.\n    This perspective helps us to understand how current graph neural networks for graph clustering jointly cluster node attributes and adjacencies, despite clustering objectives explicitly considering only node adjacencies and cluster assignments.\n    It also enables neural network architectures such as transformers and multilayer perceptrons to learn on graphs without positional or structural encodings and without spectral or message passing layers found in graph neural networks.We evaluate the framework on three real-world attributed graph datasets and show that training with semi-supervised objectives consistently outperform a purely supervised objective, and enables architectures such as transformers and MLPs to learn on graphs in settings where a purely supervised objective would yield close to random performance."
    },
    {
        "title": "Can Textual Gradient Work in Federated Learning?",
        "link_suffix": "/forum?id=Cy5IKvYbR3",
        "link": "https://openreview.net/forum?id=Cy5IKvYbR3",
        "pdf_link": "https://openreview.net/pdf?id=Cy5IKvYbR3",
        "keywords": "Federated Learning; LLMs-as-Optimizer",
        "abstract": "Recent studies highlight the promise of LLM-based prompt optimization, especially with TextGrad, which automates ``differentiation'' via texts and backpropagates textual feedback provided by LLMs. This approach facilitates training in various real-world applications that do not support numerical gradient propagation or loss calculation.  It opens new avenues for optimization in decentralized, resource-constrained environments, suggesting that users of black-box LLMs (e.g., ChatGPT) could enhance components of LLM agentic systems (such as prompt optimization) through collaborative paradigms like federated learning (FL). In this paper, we systematically explore the potential and pitfalls of incorporating textual gradient into FL. Our contributions are fourfold.Firstly, we introduce a novel FL paradigm, Federated Textual Gradient (FedTextGrad), that allows FL clients to upload their locally optimized prompts derived from textual gradients, while the FL server aggregates the received prompts through text summarization. Unlike traditional FL frameworks, which are designed for numerical aggregation, FedTextGrad is specifically tailored for handling textual data, expanding the applicability of FL to a broader range of problems that lack well-defined numerical loss functions.Secondly, building on this design, we conduct extensive experiments to explore the feasibility of federated textual gradients. Our findings highlight the importance of properly tuning key factors (e.g, local steps) in FL training to effectively integrate textual gradients.Thirdly, We highlight a major challenge in federated textual gradient aggregation: retaining essential information from distributed prompt updates. Concatenation often produces prompts that exceed the LLM API\u2019s context window, while summarization can degrade performance by generating overly condensed or complex text that lacks key context.Last but not least, in response to this issue, we improve the vanilla variant of FedTextGrad by providing actionable guidance to the LLM when summarizing client prompts by leveraging the Uniform Information Density principle. Such a design reduces the complexity of the aggregated global prompt, thereby better incentive LLM reasoning ability. Through this principled study, we enable the adoption of textual gradients in FL for optimizing LLMs, identify important issues, and pinpoint future directions, thereby opening up a new research area that warrants further investigation."
    },
    {
        "title": "SCISplat: 3D Gaussian Splatting from a Snapshot Compressive Image",
        "link_suffix": "/forum?id=nkeF3iRJRo",
        "link": "https://openreview.net/forum?id=nkeF3iRJRo",
        "pdf_link": "https://openreview.net/pdf?id=nkeF3iRJRo",
        "keywords": "3D Vision, Snapshot Compressive Imaging, Gaussian Splatting",
        "abstract": "In this paper, we investigate the potential of Snapshot Compressive Imaging (SCI) for efficiently recovering 3D scenes from a single temporally compressed image. SCI offers a cost-effective approach using a series of 2D masks to compress video data into a single image captured by 2D imaging sensors. However, traditional SCI reconstruction methods face challenges with generalization and maintaining multi-view consistency. Recent advances have introduced Neural Radiance Fields (NeRF) to estimate 3D scenes from SCI images, but NeRF\u2019s implicit representation struggles to capture fine details and support fast training and rendering. To address these issues, we propose SCISplat, a 3D Gaussian Splatting-based framework for decoding SCI images and achieving high-quality scene reconstruction from a single SCI image. First, we design an initialization protocol that robustly estimates the initial point cloud and camera poses from an SCI image, leveraging a learning-based Structure-from-Motion method. Second, we integrate the SCI image formation model into the 3D Gaussian training process and jointly optimize the Gaussians and camera poses to enhance reconstruction quality. Experiments demonstrate that SCISplat surpasses state-of-the-art methods, achieving a 2.3 dB improvement in reconstruction quality and a 10\u00d7 faster training speed. Furthermore, results on real-world datasets show that our approach produces cleaner and sharper details, underscoring its practical value."
    },
    {
        "title": "IGL-Bench: Establishing the Comprehensive Benchmark for Imbalanced Graph Learning",
        "link_suffix": "/forum?id=uTqnyF0JNR",
        "link": "https://openreview.net/forum?id=uTqnyF0JNR",
        "pdf_link": "https://openreview.net/pdf?id=uTqnyF0JNR",
        "keywords": "imbalanced graph learning, graph class-imbalance, graph topology-imbalance, comprehensive benchmark",
        "abstract": "Deep graph learning has gained grand popularity over the past years due to its versatility and success in representing graph data across a wide range of domains. However, the pervasive issue of imbalanced graph data distributions, where certain parts exhibit disproportionally abundant data while others remain sparse, undermines the efficacy of conventional graph learning algorithms, leading to biased outcomes. To address this challenge, Imbalanced Graph Learning (IGL) has garnered substantial attention, enabling more balanced data distributions and better task performance. Despite the proliferation of IGL algorithms, the absence of consistent experimental protocols and fair performance comparisons pose a significant barrier to comprehending advancements in this field. To bridge this gap, we introduceIGL-Bench, a foundational comprehensive benchmark for imbalanced graph learning, embarking on17diverse graph datasets and24distinct IGL algorithms with uniform data processing and splitting strategies. Specifically, IGL-Bench systematically investigates state-of-the-art IGL algorithms in terms ofeffectiveness,robustness, andefficiencyon node-level and graph-level tasks, with the scope of class-imbalance and topology-imbalance. Extensive experiments demonstrate the potential benefits of IGL algorithms on various imbalanced conditions, offering insights and opportunities in the IGL field. Further, we have developed an open-sourced and unified package to facilitate reproducible evaluation and inspire further innovative research, which is available athttps://anonymous.4open.science/r/IGL-Bench."
    },
    {
        "title": "How Low Can You Go? Searching for the Intrinsic Dimensionality of Complex Networks using Metric Node Embeddings",
        "link_suffix": "/forum?id=V71ITh2w40",
        "link": "https://openreview.net/forum?id=V71ITh2w40",
        "pdf_link": "https://openreview.net/pdf?id=V71ITh2w40",
        "keywords": "Exact network embedding, latent distance model, logistic PCA, large scale network modeling",
        "abstract": "Low-dimensional embeddings are essential for machine learning tasks involving graphs, such as node classification, link prediction, community detection, network visualization, and network compression. Although recent studies have identified exact low-dimensional embeddings, the limits of the required embedding dimensions remain unclear. We presently prove that lower dimensional embeddings are possible when using metric embeddings as opposed to vector-based inner product embeddings such as Logistic PCA (LPCA). We further provide an efficient logarithmic search procedure for identifying the exact embedding dimension and demonstrate how metric embeddings enable inference of the exact embedding dimensions of large-scale networks by exploiting that the metric properties can be used to provide linearithmic scaling. Empirically, we show that our approach extracts substantially lower dimensional representations of networks than previously reported for small-sized networks. For the first time, we demonstrate that even large-scale networks can be effectively embedded in very low-dimensional spaces, and provide examples of scalable, exact reconstruction for graphs with up to a million nodes. Our approach highlights that the intrinsic dimensionality of networks is substantially lower than previously reported and provides a computationally efficient assessment of the exact embedding dimension also of large-scale networks. The surprisingly low dimensional representations achieved demonstrate that networks in general can be losslessly represented using very low dimensional feature spaces, which can be used to guide existing network analysis tasks from community detection and node classification to structure revealing exact network visualizations."
    },
    {
        "title": "ConGra: Benchmarking Automatic Conflict Resolution",
        "link_suffix": "/forum?id=d38yjwdGYr",
        "link": "https://openreview.net/forum?id=d38yjwdGYr",
        "pdf_link": "https://openreview.net/pdf?id=d38yjwdGYr",
        "keywords": "Code merging, conflict resolution, large language model",
        "abstract": "Resolving conflicts from merging different software versions is a challenging task for developers. To reduce the overhead of manual merging, researchers develop various program analysis-based tools which only solve specific types of conflicts and have a limited scope of application. With the development of language models, researchers treat conflict code as text, which theoretically allows for addressing almost all types of conflicts. However, the absence of effective conflict difficulty grading methods hinders a comprehensive evaluation of large language models (LLMs), making it difficult to gain a deeper understanding of their limitations. Furthermore, there is a notable lack of large-scale open benchmarks for evaluating the performance of LLMs in automatic conflict resolution. To address these issues, We introduce ConGra, a CONflict-GRAded benchmarking scheme designed to evaluate the performance of software merging tools under varying complexity conflict scenarios. We propose a novel approach to classify conflicts based on code operations and use it to build a large-scale evaluation dataset based on 44,948 conflicts from 34 real-world projects. We evaluate state-of-the-art LLMs on conflict resolution tasks using this dataset. By employing the proposed dataset, we assess the performance of multiple state-of-the-art LLMs and code LLMs, ultimately uncovering two counterintuitive yet insightful phenomena. ConGra will be released athttps://github.com/xxx/ConGra."
    },
    {
        "title": "The Overcooked Generalisation Challenge",
        "link_suffix": "/forum?id=YKvBiRWdQC",
        "link": "https://openreview.net/forum?id=YKvBiRWdQC",
        "pdf_link": "https://openreview.net/pdf?id=YKvBiRWdQC",
        "keywords": "Human-AI Cooperation, Unsupervised Environment Design, Multi-Agent Reinforcement Learning",
        "abstract": "We introduce the Overcooked Generalisation Challenge (OGC) \u2013 the first bench-mark to study reinforcement learning agents\u2019 zero-shot cooperation abilities when faced with novel partners and levels in the Overcooked-AI environment.\nThis perspective starkly contrasts a large body of previous work that has evaluated cooperating agents only on the same level or with the same partner, thus failing to capture generalisation abilities essential for real-world human-AI cooperation.\nOur challenge interfaces with state-of-the-art dual curriculum design (DCD) methods to generate auto-curricula for training general agents in Overcooked.\nIt is the first cooperative multi-agent environment specially designed for DCD methods and, consequently, the first evaluated with state-of-the-art methods. \nIt is fully GPU-accelerated, built on the DCD benchmark suite minimax, and freely available under an open-source license:http://anonymised.edu. \nWe show that state-of-the-art DCD algorithms fail to produce useful policies on this novel challenge, even if combined with recent network architectures specifically designed for scalability and generalisability. \nAs such, the OGC pushes the boundaries of real-world human-AI cooperation by enabling research on the impact of generalisation on cooperating agents."
    },
    {
        "title": "A Study of Posterior Stability for Time-Series Latent Diffusion",
        "link_suffix": "/forum?id=2fZ9iOVzpR",
        "link": "https://openreview.net/forum?id=2fZ9iOVzpR",
        "pdf_link": "https://openreview.net/pdf?id=2fZ9iOVzpR",
        "keywords": "Latent Diffusion, Time Series, Diffusion Models, Posterior Collapse, Impact Analysis",
        "abstract": "Latent diffusion has demonstrated promising results in image generation and permits efficient sampling. However, this framework might suffer from the problem of posterior collapse when applied to time series. In this paper, we first show that posterior collapse will reduce latent diffusion to a variational autoencoder (VAE), making it less expressive. This highlights the importance of addressing this issue. We then introduce a principled method: dependency measure, that quantifies the sensitivity of a recurrent decoder to input variables. Using this tool, we confirm that posterior collapse significantly affects time-series latent diffusion on real datasets, and a phenomenon termed dependency illusion is also discovered in the case of shuffled time series. Finally, building on our theoretical and empirical studies, we introduce a new framework that extends latent diffusion and has a stable posterior. Extensive experiments on multiple real time-series datasets show that our new framework is free from posterior collapse and significantly outperforms previous baselines in time series synthesis."
    },
    {
        "title": "Nacala-Roof-Material: Drone Imagery for Roof Detection, Classification, and Segmentation to Support Mosquito-borne Disease Risk Assessment",
        "link_suffix": "/forum?id=L5NUDBdHqR",
        "link": "https://openreview.net/forum?id=L5NUDBdHqR",
        "pdf_link": "https://openreview.net/pdf?id=L5NUDBdHqR",
        "keywords": "remote sensing, deep learning, disease risk assessment, roof classification, instance segmentation, semantic segmentation, multi-task learning",
        "abstract": "As low-quality housing and in particular certain roof characteristics are associated with an increased risk of malaria, classification of roof types based on remote sensing imagery can support the assessment of malaria risk and thereby help prevent the disease. To support research in this area, we release the Nacala-Roof-Material dataset, which contains high-resolution drone images from Mozambique with corresponding labels delineating houses and specifying their roof types. The dataset defines a multi-task computer vision problem, comprising object detection, classification, and segmentation. In addition, we benchmarked various state-of-the-art approaches on the dataset. Canonical U-Nets, YOLOv8, and a custom decoder on pretrained DINOv2 served as baselines. We show that each of the methods has its advantages but none is superior on all tasks, which highlights the potential of our dataset for future research in multi-task learning. While the tasks are closely related, accurate segmentation of objects does not necessarily imply accurate instance separation, and vice versa. We address this general issue by introducing a variant of the deep ordinal watershed (DOW) approach that additionally separates the interior of objects, allowing for improved object delineation and separation. We show that our DOW variant is a generic approach that improves the performance of both U-Net and DINOv2 backbones, leading to a better trade-off between semantic segmentation and instance segmentation."
    },
    {
        "title": "Synthesizing Realistic fMRI: A Physiological Dynamics-Driven Hierarchical Diffusion Model for Efficient fMRI Acquisition",
        "link_suffix": "/forum?id=zZ6TT254Np",
        "link": "https://openreview.net/forum?id=zZ6TT254Np",
        "pdf_link": "https://openreview.net/pdf?id=zZ6TT254Np",
        "keywords": "Time Series, Diffusion",
        "abstract": "Functional magnetic resonance imaging (fMRI) is essential for mapping brain activity but faces challenges like lengthy acquisition time and sensitivity to patient movement, limiting its clinical and machine learning applications. While generative models such as diffusion models can synthesize fMRI signals to alleviate these issues, they often underperform due to neglecting the brain's complex structural and dynamic properties.\nTo address these limitations, we propose the Physiological Dynamics-Driven Hierarchical Diffusion Model, a novel framework integrating two key brain physiological properties into the diffusion process: brain hierarchical regional interactions and multifractal dynamics. \nTo model complex interactions among brain regions, we construct hypergraphs based on the prior knowledge of brain functional parcellation reflected by resting-state functional connectivity (rsFC). This enables the aggregation of fMRI signals across multiple scales and generates hierarchical signals. \nAdditionally, by incorporating the prediction of two key dynamics properties of fMRI\u2014the multifractal spectrum and generalized Hurst exponent\u2014our framework effectively guides the diffusion process, ensuring the preservation of the scale-invariant characteristics inherent in real fMRI data.\nOur framework employs progressive diffusion generation, with signals representing broader brain region information conditioning those that capture localized details, and unifies multiple inputs during denoising for balanced integration.\nExperiments demonstrate that our model generates physiologically realistic fMRI signals, potentially reducing acquisition time and enhancing data quality, benefiting clinical diagnostics and machine learning in neuroscience."
    },
    {
        "title": "MR-GSM8K: A Meta-Reasoning Benchmark for Large Language Model Evaluation",
        "link_suffix": "/forum?id=br4H61LOoI",
        "link": "https://openreview.net/forum?id=br4H61LOoI",
        "pdf_link": "https://openreview.net/pdf?id=br4H61LOoI",
        "keywords": "Benchmark, LLM, Math, Evaluation",
        "abstract": "In this work, we introduce a novel evaluation paradigm for Large Language Models (LLMs) that compels them to transition from a traditional question-answering role, akin to a student, to a solution-scoring role, akin to a teacher. This paradigm, focusing on \"reasoning about reasoning,\" termed meta-reasoning, shifts the emphasis from result-oriented assessments, which often neglect the reasoning process, to a more comprehensive evaluation that effectively distinguishes between the cognitive capabilities of different models. Our meta-reasoning process mirrors \"system-2\" slow thinking, requiring careful examination of assumptions, conditions, calculations, and logic to identify mistakes. This deliberate approach encourages deeper cognitive engagement, as models must scrutinize each step of the reasoning process to detect errors, making this paradigm especially valuable for tasks that involve complex problem-solving. By applying this paradigm in the GSM8K dataset, we have developed the MR-GSM8K benchmark. Our extensive analysis includes several state-of-the-art models from both open-source and commercial domains, uncovering fundamental deficiencies in their training and evaluation methodologies. Notably, while models like Deepseek-v2 and Claude3-Sonnet closely competed with GPT-4 in GSM8K, their performance disparities expanded dramatically in MR-GSM8K, with differences widening to over 20 absolute points, underscoring the significant challenge posed by our meta-reasoning approach."
    },
    {
        "title": "Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?",
        "link_suffix": "/forum?id=8EtSBX41mt",
        "link": "https://openreview.net/forum?id=8EtSBX41mt",
        "pdf_link": "https://openreview.net/pdf?id=8EtSBX41mt",
        "keywords": "Instruction-data separation, ML Safety, LLM Safety, LLM Security, Indirect Prompt Injection, Large Language Models, Datasets",
        "abstract": "Large Language Models (LLMs) show impressive results in numerous practical applications, but they lack essential safety features that are common in other areas of computer science, particularly an explicit separation of instructions and data. This makes them vulnerable to manipulations such as indirect prompt injections and generally unsuitable for safety-critical tasks. Surprisingly, there is currently no established definition or benchmark to quantify this phenomenon. In this work, we close this gap by introducing a formal measure for instruction-data separation for single-turn language models and an empirical variant that is calculable from a model\u2019s outputs. We also present a new dataset, SEP, that allows estimating the measure for real-world models. Our results on various LLMs show that the problem of instruction-data separation is real: all models fail to achieve high separation, and canonical mitigation techniques, such as prompt engineering and fine-tuning, either fail to substantially improve separation or reduce model utility."
    },
    {
        "title": "On the Benefits of Memory for Modeling Time-Dependent PDEs",
        "link_suffix": "/forum?id=o9kqa5K3tB",
        "link": "https://openreview.net/forum?id=o9kqa5K3tB",
        "pdf_link": "https://openreview.net/pdf?id=o9kqa5K3tB",
        "keywords": "State Space Models, Partial Differential Equations",
        "abstract": "Data-driven techniques  have emerged as a promising alternative to traditional numerical methods. For time-dependent PDEs, many approaches are Markovian---the evolution of the trained system only depends on the current state, and not the past states. In this work, we investigate the benefits of using memory for modeling time-dependent PDEs: that is, when past states are explicitly used to predict the future. Motivated by the Mori-Zwanzig theory of model reduction, we theoretically exhibit examples of simple (even linear) PDEs, in which a solution that uses memory is arbitrarily better than a Markovian solution. Additionally, we introduce Memory Neural Operator (MemNO), a neural operator architecture that combines recent state space models (specifically, S4) and Fourier Neural Operators (FNOs) to effectively model memory.  We empirically demonstrate that when the PDEs are supplied in low resolution or contain observation noise at train and test time, MemNO significantly outperforms the baselines without memory---with up to $6 \\times$ reduction in test error. Furthermore, we show that this benefit is particularly pronounced when the PDE solutions have significant high-frequency Fourier modes (e.g., low-viscosity fluid dynamics) and we construct a challenging benchmark dataset consisting of such PDEs."
    },
    {
        "title": "Learning Equivariant Non-Local Electron Density Functionals",
        "link_suffix": "/forum?id=FhBT596F1X",
        "link": "https://openreview.net/forum?id=FhBT596F1X",
        "pdf_link": "https://openreview.net/pdf?id=FhBT596F1X",
        "keywords": "Density Functional Theory, DFT, Functional, Exchange Correlation, XC, Equivariance, Graph Neural Network, Electron Density, Kohn-Sham DFT",
        "abstract": "The accuracy of density functional theory hinges on the approximation of non-local contributions to the exchange-correlation (XC) functional. To date, machine-learned and human-designed approximations suffer from insufficient accuracy, limited scalability, or dependence on costly reference data. To address these issues, we introduce Global Graph Exchange Correlation (GG-XC), a novel non-local XC functional based on equivariant graph neural networks. GG-XC combines semi-local functionals with a non-local feature density parametrized by an equivariant nuclei-centered point cloud representation of the electron density to capture long-range interactions.  By differentiating through a self-consistent field solver, we train GG-XC requiring only energy targets. In our empirical evaluation, we find GG-XC to accurately reconstruct `gold-standard' CCSD(T) energies on MD17. On out-of-distribution conformations of 3BPA, GG-XC reduces the relative MAE by 35% to 50%. Remarkably, GG-XC excels in data efficiency and molecular size extrapolation on QM9, matching force fields trained on 5 times more and larger molecules. On identical training sets, GG-XC yields on average 51% lower MAEs."
    },
    {
        "title": "Multiple-Frequencies Population-Based Training",
        "link_suffix": "/forum?id=VLdZkq9xsd",
        "link": "https://openreview.net/forum?id=VLdZkq9xsd",
        "pdf_link": "https://openreview.net/pdf?id=VLdZkq9xsd",
        "keywords": "Hyperparameter Optimization; Reinforcement Learning; Population-Based Training",
        "abstract": "Reinforcement Learning's high sensitivity to hyperparameters is a source of instability and inefficiency, creating significant challenges for practitioners. Hyperparameter Optimization (HPO) algorithms have been developed to address this issue, among them Population-Based Training (PBT) stands out for its ability to generate hyperparameters schedules in a single training run. PBT trains a population of agents, each with its own hyperparameters, frequently ranking them and replacing the worst performers with mutations of the best agents. These intermediate selection steps can cause PBT to focus on short-term improvements, leading it to get stuck in local optima and eventually fall behind vanilla Random Search over longer timescales. This paper studies how this greediness issue is connected to the choice ofevolution frequency, the rate at which the selection is done. We propose Multiple-Frequencies Population-Based Training (MF-PBT), a novel HPO algorithm that addresses greediness by employing sub-populations, each evolving at distinct frequencies. MF-PBT introduces a migration process to transfer information between sub-populations, with an asymmetric design to balance short and long-term optimization. Extensive experiments on the Brax suite demonstrate that MF-PBT improves sample efficiency and long-term performance, even without tuning hyperparameters. Code will be released."
    },
    {
        "title": "Risk-Sensitive Diffusion: Robustly Optimizing Diffusion Models with Noisy Samples",
        "link_suffix": "/forum?id=b0WpXBABdu",
        "link": "https://openreview.net/forum?id=b0WpXBABdu",
        "pdf_link": "https://openreview.net/pdf?id=b0WpXBABdu",
        "keywords": "Diffusion Models, Noisy Data, Risk-Sensitive SDE, Generative Models",
        "abstract": "Diffusion models are mainly studied on image data. However, non-image data (e.g., tabular data) are also prevalent in real applications and tend to be noisy due to some inevitable factors in the stage of data collection, degrading the generation quality of diffusion models. In this paper, we consider a novel problem setting where every collected sample is paired with a vector indicating the data quality: risk vector. This setting applies to many scenarios involving noisy data and we propose risk-sensitive SDE, a type of stochastic differential equation (SDE) parameterized by the risk vector, to address it. With some proper coefficients, risk-sensitive SDE can minimize the negative effect of noisy samples on the optimization of diffusion models. We conduct systematic studies for both Gaussian and non-Gaussian noise distributions, providing analytical forms of risk-sensitive SDE. To verify the effectiveness of our method, we have conducted extensive experiments on multiple tabular and time-series datasets, showing that risk-sensitive SDE permits a robust optimization of diffusion models with noisy samples and significantly outperforms previous baselines."
    },
    {
        "title": "ViML: A Video, Music, Language Unified Dataset for Understanding and Generation",
        "link_suffix": "/forum?id=Tgsc0KEkN6",
        "link": "https://openreview.net/forum?id=Tgsc0KEkN6",
        "pdf_link": "https://openreview.net/pdf?id=Tgsc0KEkN6",
        "keywords": "Video Understanding and Generation, Dataset and Benchmark, Multimodal, Music",
        "abstract": "Integrating multimodal understanding and generation into a unified framework can bridge the domain gap across different modalities. \nHowever, existing multimodal-language datasets predominantly offer text descriptions for a single modality, treating visual and audio as separate tasks. This approach neglects the inherent audio-visual correlations, resulting in annotations that are often monotonous and modality-specific rather than comprehensive and precise. Such oversight hampers the advancement of cross-modality research. To fulfill this gap, we present ViML, a large-scale multi-modality-to-language dataset incorporating 3M video clips with high-quality multimodal captions. \nIn ViML, we propose a systemic captioning framework, achieving various modality annotations with more than 12.2k hours of trailer videos. Here, to ensure the caption retains music perspective while preserving the authority of visual context, we leverage the advanced LLM to merge all annotations adaptively. In particular, the ViML has two main advantages: \n(1) the topics are diverse, and the content characters are of various types, \\eg, film,  news, and gaming.\n(2) the corresponding background music is custom-designed, making it more coherent with the visual context. \nIn this fashion, our ViML dataset potentially paves the path for fine-grained large multimodal-language model training. In experiments, we provide evaluation metrics and benchmark results on our dataset, demonstrating the high quality of our annotation and its effectiveness for model training. We include demo data in \\hyperlink{https://anonymous.4open.science/w/ViML-4C78}{https://anonymous.4open.science/w/ViML-4C78}"
    },
    {
        "title": "FastTF: 4 Parameters are All You Need for Long-term Time Series Forecasting",
        "link_suffix": "/forum?id=CZiP7GpmX7",
        "link": "https://openreview.net/forum?id=CZiP7GpmX7",
        "pdf_link": "https://openreview.net/pdf?id=CZiP7GpmX7",
        "keywords": "Time series forcasting, Machine learning, Model lightweighting",
        "abstract": "Time series forecasting is essential across various sectors, including finance, transportation, and industry. In this paper, we propose FastTF, a powerful yet lightweight model in Time-Frequency domain for long-term time series forecasting. Our aim is to push the boundary of model lightweighting and facilitate the deployment of lightweight model on resource-constrained devices. Leveraging the global nature and information compressibility of the time series in frequency domain, we introduce patch-wise downsampling,  Sparse Frequency Mixer (SFM), and patch predictor to capture the temporal variations of frequency components across different patches. Experimental results on five public datasets demonstrate that FastTF with very few parameters outperforms several state-of-the-art models and demonstrates a strong generalization capability. Notably, on the ETTh1 dataset, FastTF with only 4 parameters achieves a performance that is close to the DLinear and FITS in the horizon-96 forecasting. Furthermore, we deployed our model on a FPGA development board (Zynq UltraScale+ RFSoC ZCU208 Evaluation Kit), where the corresponding resource usage statistics illustrate that our model has a very low computational overhead and latency, making it easily implemented on hardware devices."
    },
    {
        "title": "DocGenome: A Large Benchmark for Multi-Modal Language Models in Real-World Academic Document Understanding",
        "link_suffix": "/forum?id=CI9JMBAsPg",
        "link": "https://openreview.net/forum?id=CI9JMBAsPg",
        "pdf_link": "https://openreview.net/pdf?id=CI9JMBAsPg",
        "keywords": "Scientific document structuring, Document understanding, Chart Table and Equation Understanding",
        "abstract": "Scientific documents record research findings and valuable human knowledge, comprising a vast corpus of high-quality data. Thus, leveraging multi-modality data extracted from these documents and assessing large models' abilities to handle scientific document-oriented tasks is meaningful. Despite promising advancements, large models still perform poorly on multi-page scientific document extraction and understanding tasks, and their capacity to process within-document data formats such as charts and equations remains under-explored. To address these issues, we present DocGenome, a structured document dataset constructed by annotating 500K scientific documents from 153 disciplines in the arXiv open-access community, using our custom auto-labeling pipeline. DocGenome features four characteristics: 1) Completeness: It is the first dataset to structure data from all modalities including 13 layout attributes along with their LaTeX source codes. 2) Logicality: It provides 6 logical relationships between different entities within each scientific document. 3) Diversity: It covers various document-oriented tasks, including document classification, visual grounding, document layout detection, document transformation, open-ended single-page QA and multi-page QA. 4) Correctness: It undergoes rigorous quality control checks conducted by a specialized team. We conduct extensive experiments to demonstrate the advantages of DocGenome and objectively evaluate the performance of current large models on our benchmark."
    },
    {
        "title": "Instance-Level Smoothing for Enhanced Privacy in Deep Learning: Theoretical Insights and Empirical Validation",
        "link_suffix": "/forum?id=97tbbvSJ4A",
        "link": "https://openreview.net/forum?id=97tbbvSJ4A",
        "pdf_link": "https://openreview.net/pdf?id=97tbbvSJ4A",
        "keywords": "privacy preserving, adaptive kernel density estimation, medical image classification",
        "abstract": "In this paper, we address the dual challenge of maintaining high accuracy and ensuring fairness in differentially private (DP) deep learning models. The optimization process is inherently complicated by the necessity of injecting random noise and limiting training iterations, particularly for over-parameterized models. Moreover, DP mechanisms frequently exacerbate accuracy disparities across subpopulations, complicating the balance between privacy and fairness. To tackle these challenges, we introduce a novel framework that systematically addresses the trade-off between privacy and utility in DP deep learning. At the core of our approach is the concept of instance-level smoothing, which enhances privacy protections without compromising performance. Our theoretical contributions include deep insights into sample complexity, instance-level smoothing factors, and error bounds required to achieve a given privacy budget. These insights provide a robust foundation for optimizing the delicate balance between privacy and utility. Our method demonstrates remarkable robustness, independent of iteration counts, model parameters, batch normalization processes, and subpopulation disparities. This flexibility enables an optimal balance between privacy preservation and utility, adaptable to a wide range of scenarios. Through extensive empirical studies on the large-scale medical imaging dataset CheXpert, we validate the effectiveness of our approach. Our findings align with theoretical predictions, showing that our method can effectively meet stringent privacy requirements while maintaining high performance. By bridging the gap between formal privacy guarantees and practical deep learning applications, our work lays the groundwork for future advancements in the field. This research empowers practitioners to protect sensitive data during model training and ensures both data privacy and model generality, paving the way for more secure and equitable AI systems."
    },
    {
        "title": "A Closer Look at Personalized Fine-Tuning in Heterogeneous Federated Learning",
        "link_suffix": "/forum?id=Zmu3lVw6bm",
        "link": "https://openreview.net/forum?id=Zmu3lVw6bm",
        "pdf_link": "https://openreview.net/pdf?id=Zmu3lVw6bm",
        "keywords": "Federated Learning; Distribution Shift",
        "abstract": "Federated Learning (FL) enables privacy-preserving, decentralized model training but faces significant challenges in balancing global generalization and local personalization due to non-identical data distributions across clients. While Personalized Fine-Tuning (PFT) adapts models to local data, excessive personalization often degrades global performance. In this work, we present a comprehensive empirical study encompassing seven diverse datasets, multiple model architectures, and various fine-tuning methods under both covariate and concept shift scenarios. Our extensive evaluation reveals critical limitations in existing PFT methods, which struggle with overfitting and exhibit inconsistent performance across distribution shifts, even with careful hyperparameter tuning and regularization. To address these issues, we identify LP-FT, a simple yet effective strategy that combines Linear Probing with full Fine-Tuning, adapted to the FL setting. LP-FT consistently outperforms existing methods, achieving an optimal balance between local personalization and global generalization across all tested scenarios. By investigating the feature change after PFT, we hypothesize the a phenomena dubbed as federated feature distortion is linked to the global generalization. Motivated by the observation, we provide a theoretical analysis of two-layer linear networks, offering novel insights into the conditions under which LP-FT excels, thereby enhancing our understanding of personalization dynamics in FL. This work contributes in three key areas: (1) a rigorous and comprehensive evaluation of PFT methods under diverse distribution shifts, (2) the introduction of LP-FT as a robust and versatile solution to FL personalization challenges, and (3) theoretical foundations that explain LP-FT\u2019s superior effectiveness. Our findings set a new venue for PFT research and provide valuable insights to the broader FL community."
    },
    {
        "title": "Adversarial Mixup Unlearning",
        "link_suffix": "/forum?id=GcbhbZsgiu",
        "link": "https://openreview.net/forum?id=GcbhbZsgiu",
        "pdf_link": "https://openreview.net/pdf?id=GcbhbZsgiu",
        "keywords": "Machine Unlearning, Catastrophic Unlearning, Mixup Regularization, Adversarial Training",
        "abstract": "Machine unlearning is a critical area of research aimed at safeguarding data privacy by enabling the removal of sensitive information from machine learning models. One unique challenge in this field is catastrophic unlearning, where erasing specific data from a well-trained model unintentionally removes essential knowledge, causing the model to deviate significantly from a retrained one. To address this, we introduce a novel approach that regularizes the unlearning process by utilizing synthesized mixup samples, which simulate the data susceptible to catastrophic effects. At the core of our approach is a generator-unlearner framework, MixUnlearn, where a generator adversarially produces challenging mixup examples, and the unlearner effectively forgets target information based on these synthesized data. Specifically, we first introduce a novel contrastive objective to train the generator in an adversarial direction: generating examples that prompt the unlearner to reveal information that should be forgotten, while losing essential knowledge. Then the unlearner, guided by two other contrastive loss terms, processes the synthesized and real data jointly to ensure accurate unlearning without losing critical knowledge, overcoming catastrophic effects. Extensive evaluations across four benchmark datasets demonstrate that our method significantly outperforms state-of-the-art approaches, offering a robust solution to machine unlearning. This work not only deepens understanding of unlearning mechanisms but also lays the foundation for effective machine unlearning with mixup augmentation."
    },
    {
        "title": "DirectTriGS: Triplane-based Gaussian Splatting Field Representation for 3D Generation",
        "link_suffix": "/forum?id=FL6112vyty",
        "link": "https://openreview.net/forum?id=FL6112vyty",
        "pdf_link": "https://openreview.net/pdf?id=FL6112vyty",
        "keywords": "3D generation, Gaussian Splatting",
        "abstract": "We present DirectTriGS, a novel framework designed for 3D object generation with Gaussian Splatting (GS). GS-based rendering for 3D content has gained considerable attention recently. However, there has been limited exploration in directly generating 3D Gaussians compared to traditional generative modeling approaches. The main challenge lies in the complex data structure of GS represented by discrete point clouds with multiple channels.\nTo overcome this challenge, we propose employing the triplane representation, which allows us to represent Gaussian Splatting as an image-like continuous field. This representation effectively encodes both the geometry and texture information, enabling smooth transformation back to Gaussian point clouds and rendering into images by a TriRenderer, with only 2D supervisions. The proposed TriRenderer is fully differentiable, so that the rendering loss can supervise both texture and geometry encoding. Furthermore, the triplane representation can be compressed using a Variational Autoencoder (VAE), which can subsequently be utilized in latent diffusion to generate 3D objects.\nThe experiments demonstrate that the proposed generation framework can produce high-quality 3D object geometry and rendering results."
    }
]
[{"title": "CNN Variational autoencoders' reconstruction ability of long ECG signals", "link_suffix": "/forum?id=v3XabZsB7j", "link": "https://openreview.net/forum?id=v3XabZsB7j", "pdf_link": "https://openreview.net/pdf?id=v3XabZsB7j", "keywords": "VAE, CNN, electrocardiogram, reconstruction, compression, interpretability", "abstract": "Can variational auto-encoders (VAEs) generate flexible continuous latent space for long electrocardiogram (ECG) segments and reconstruct the input? A folded VAE architecture is introduced in this study which is able to encode long ECG segments by splitting an input segment into folds and process them in sequence using a narrow field-of-view in the encoder and concatenate them at the end, instead of processing the long segment at a time. The VAE decoder follows similar folding and concatenation strategy for reconstruction of the original ECG segments. The proposed folded VAE architecture is able to generate better reconstruction of long 30-second ECG segments compared to unfolded classical VAE approach which often produce trivial reconstruction of long ECG segments. Experimental results show that the latent representation generated by our folded VAE architecture not only retains rich compressed information but also aids designing interpretable models by providing decision-making insights.", "title_embedding_index": 6150, "title_abs_embedding_index": 6175}, {"title": "The Effectiveness of Curvature-Based Rewiring and the Role of Hyperparameters in GNNs Revisited", "link_suffix": "/forum?id=EcrdmRT99M", "link": "https://openreview.net/forum?id=EcrdmRT99M", "pdf_link": "https://openreview.net/pdf?id=EcrdmRT99M", "keywords": "Geometric deep learning, Graph Neural Networks, Graph Rewiring, Curvature", "abstract": "Message passing is the dominant paradigm in Graph Neural Networks (GNNs). The efficiency of message passing, however, can be limited by the topology of the graph. This happens when information is lost during propagation due to being oversquashed when travelling through bottlenecks. To remedy this, recent efforts have focused on graph rewiring techniques, which disconnect the input graph originating from the data and the computational graph, on which message passing is performed. A prominent approach for this is to use discrete graph curvature measures, of which several variants have been proposed, to identify and rewire around bottlenecks, facilitating information propagation. While oversquashing has been demonstrated in synthetic datasets, in this work we reevaluate the performance gains that curvature-based rewiring brings to real-world datasets. We show that in these datasets, edges selected during the rewiring process are not in line with theoretical criteria identifying bottlenecks. This implies they do not necessarily oversquash information during message passing. Subsequently, we demonstrate that SOTA accuracies on these datasets are outliers originating from sweeps of hyperparameters\u2014both the ones for training and dedicated ones related to the rewiring algorithm\u2014instead of consistent performance gains. In conclusion, our analysis nuances the effectiveness of curvature-based rewiring in real-world datasets and brings a new perspective on the methods to evaluate GNN accuracy improvements.", "title_embedding_index": 6151, "title_abs_embedding_index": 6176}, {"title": "Utilitarian Algorithm Configuration for Infinite Parameter Spaces", "link_suffix": "/forum?id=CA06Nqa7CG", "link": "https://openreview.net/forum?id=CA06Nqa7CG", "pdf_link": "https://openreview.net/pdf?id=CA06Nqa7CG", "keywords": "Algorithm configuration, Utilitarian algorithm configuration, bandits", "abstract": "Utilitarian algorithm configuration is a general-purpose technique for automatically searching the parameter space of a given algorithm to optimize its performance, as measured by a given utility function, on a given set of inputs. Recently introduced utilitarian configuration procedures offer optimality guarantees about the returned parameterization while provably adapting to the hardness of the underlying problem. However, the applicability of these approaches is severely limited by the fact that they only search a finite, relatively small set of parameters. They cannot effectively search the configuration space of algorithms with continuous or uncountable parameters. In this paper we introduce a new procedure, which we dub COUP (Continuous, Optimistic Utilitarian Procrastination). COUP is designed to search infinite parameter spaces efficiently to find good configurations quickly. Furthermore, COUP maintains the theoretical benefits of previous utilitarian configuration procedures when applied to finite parameter spaces but is significantly faster, both provably and experimentally.", "title_embedding_index": 6152, "title_abs_embedding_index": 6177}, {"title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis", "link_suffix": "/forum?id=oecFal31WP", "link": "https://openreview.net/forum?id=oecFal31WP", "pdf_link": "https://openreview.net/pdf?id=oecFal31WP", "keywords": "Large Language Models, Benchmark, Spatio-temporal data mining", "abstract": "The rapid evolution of large language models (LLMs) holds promise for reforming the methodology of spatio-temporal data mining. However, current works for evaluating the spatial-temporal understanding capability of LLMs are somewhat limited and biased. These works either fail to incorporate the latest language models or only focus on assessing the memorized spatio-temporal knowledge. To address this gap, this paper dissects LLMs' capability of spatio-temporal data into four distinct dimensions: knowledge comprehension, spatio-temporal reasoning, accurate computation, and downstream applications. We curate several natural language question-answer tasks for each category and build the benchmark dataset, namely STBench, containing 15 distinct tasks and over 70,000 QA pairs. Moreover, we have assessed the capabilities of the 13 LLMs, including Chat-4o, Gemma, and Mistral. Experimental results reveal that existing LLMs show remarkable performance on knowledge comprehension and spatio-temporal reasoning tasks, with potential for further enhancement on other tasks through in-context learning, chain-of-though prompting, and fine-tuning. The code and datasets of STBench are released onhttps://anonymous.4open.science/r/STBench-14C2.", "title_embedding_index": 6153, "title_abs_embedding_index": 6178}, {"title": "Structured-Initialization Learning", "link_suffix": "/forum?id=MSlF3GvUXI", "link": "https://openreview.net/forum?id=MSlF3GvUXI", "pdf_link": "https://openreview.net/pdf?id=MSlF3GvUXI", "keywords": "Efficient Learning", "abstract": "The emergence of large language models (LLMs) has revolutionized natural language processing, but their development and deployment face significant challenges in computational resources and environmental sustainability.\nTraditional self-supervised learning (SSL) paradigms requiring extensive computational infrastructure and exhibiting slow convergence rates, leading to increased energy consumption and longer training durations.\nWhile existing model fine-tuning techniques such as Low-Rank Adaptation (LoRA) are resource-intensive and fail to facilitate swift knowledge updates when integrating a mount of new data in model version iteration.\nTo mitigate these challenges, we introduce Sail, a novel method for accelerating the training of neural network models by leveraging knowledge from (publicly available) pre-trained models.\nOur approach comprises two key components: (1) a parameter transformation technique that adjusts the dimensions of pre-trained model parameters to match the target architecture, and (2) a proximal parameter integration and retraining strategy that efficiently combines transformed parameters to initialize new models.\nWe formalize the concept of Proximal Parameter and provide theoretical guarantees for its convergence advantages.\nOur approach achieves substantial reductions in training time and computational resources while maintaining or improving model performance on downstream tasks.\nThese results indicate that Sail provides a promising direction for the more efficient and accessible development of the deep learning community.\nOur code will be made publicly available.", "title_embedding_index": 6154, "title_abs_embedding_index": 6179}, {"title": "Contrast with Aggregation: A Scalable Framework for Multi-View Representation Learning", "link_suffix": "/forum?id=fPYJVMBuEc", "link": "https://openreview.net/forum?id=fPYJVMBuEc", "pdf_link": "https://openreview.net/pdf?id=fPYJVMBuEc", "keywords": "Multi-View Representation Learning, Multimodal Representation Learning, Contrastive Learning", "abstract": "Multi-View Representation Learning (MVRL) aims to learn the joint representation from diverse data sources by discovering complex relationships among them.\nIn MVRL, since the downstream task information and the view availability are often unknown a-priori, it is essential for the joint representation to be robust to the partial availability of views.\nHowever, existing methods exhibit various limitations, such as discarding potentially valuable view-specific information, lacking\nthe ability to extract representation from an arbitrary subset of views, or requiring considerable computational resources that increase exponentially with the number of views.\nTo address these challenges, we present a scalable MVRL framework based on contrastive learning.\nOur approach employs a set of encoders that is able to extract representations from arbitrary subset of views, and jointly trains them with a computation cost that scales linearly with the number of views.\nWe conducted comprehensive evaluations across 6 MVRL benchmark datasets ranging from 3 to 8 views, demonstrating that our method robustly handles diverse input view combinations and outperforms strong baseline methods.", "title_embedding_index": 6155, "title_abs_embedding_index": 6180}, {"title": "Triples as the Key: Structuring Makes Decomposition and Verification Easier in LLM-based TableQA", "link_suffix": "/forum?id=UwcZEoNP19", "link": "https://openreview.net/forum?id=UwcZEoNP19", "pdf_link": "https://openreview.net/pdf?id=UwcZEoNP19", "keywords": "TableQA, Triples", "abstract": "As the mainstream approach, LLMs have been widely applied and researched in TableQA tasks. Currently, the core of LLM-based TableQA methods typically include three phases: question decomposition, sub-question TableQA reasoning, and answer verification. However, several challenges remain in this process: i) Sub-questions generated by these methods often exhibit significant gaps with the original question due to critical information overlooked during the LLM's direct decomposition; ii) Verification of answers is typically challenging because LLMs tend to generate optimal responses during self-correct. To address these challenges, we propose a Triple-Inspired Decomposition and vErification (TIDE) strategy, which leverages the structural properties of triples to assist in decomposition and verification in TableQA. The inherent structure of triples (head entity, relation, tail entity) requires the LLM to extract as many entities and relations from the question as possible. Unlike direct decomposition methods that may overlook key information, our transformed sub-questions using triples encompass more critical details. Additionally, this explicit structure facilitates verification. By comparing the triples derived from the answers with those from the question decomposition, we can achieve easier and more straightforward validation than when relying on the LLM's self-correct tendencies. By employing triples alongside established LLM modes, Direct Prompting and Agent modes, TIDE achieves state-of-the-art performance across multiple TableQA datasets, demonstrating the effectiveness of our method.", "title_embedding_index": 6156, "title_abs_embedding_index": 6181}, {"title": "ANOVA-NODE: An identifiable neural network for the functional ANOVA model for better interpretability", "link_suffix": "/forum?id=Xy1Lf7uR9H", "link": "https://openreview.net/forum?id=Xy1Lf7uR9H", "pdf_link": "https://openreview.net/pdf?id=Xy1Lf7uR9H", "keywords": "Interpretability, Explianability, Trustworthy AI, Functional ANOVA model, Generalized additive models", "abstract": "Interpretability for machine learning models is becoming more and more important as machine learning models become more complex. \nThe functional ANOVA model, which decomposes a high-dimensional function into a sum of lower dimensional functions so called components, is one of the most popular tools for interpretable AI, and recently, various neural network models have been developed for estimating each component in the functional ANOVA model. \nHowever, such neural networks are highly unstable when estimating components since the components themselves are not uniquely defined. \nThat is, there are multiple functional ANOVA decompositions for a given function. \nIn this paper, we propose a novel interpretable model which guarantees a unique functional ANOVA decomposition and thus is able to estimate each component stably. \nWe call our proposed model ANOVA-NODE since it is a modification of Neural Oblivious Decision Ensembles (NODE) for the functional ANOVA model. \nTheoretically, we prove that ANOVA-NODE can approximate a smooth function well and derive an interesting relation between ANOVA-NODE and SHAP (Lundberg, 2017), a well known interpretable method.\nAdditionally, we experimentally show that ANOVA-NODE provides much more stable estimation of each component and thus much more stable interpretation when training data and initial values of the model parameters vary than existing neural network models do.", "title_embedding_index": 6157, "title_abs_embedding_index": 6182}, {"title": "We are confident in trusting Language Models for annotating online sexism in political discourse, but are they good?", "link_suffix": "/forum?id=kXnk4uf1sK", "link": "https://openreview.net/forum?id=kXnk4uf1sK", "pdf_link": "https://openreview.net/pdf?id=kXnk4uf1sK", "keywords": "online sexism detection, political discourse, language model annotation reliability, model confidence estimation", "abstract": "Large Language Models (LLMs) have recently gained popularity for text analysis within the social sciences due to their versatility and context-aware capabilities. The use of prompt-based learning of LLMs has especially increased its application in classification tasks and text annotation of sensitive topics like sexism. While studies have used them for capturing online sexism, not much has been known of their capabilities across lesser-known discourses like that of political discourse, and how the models distinguish between partisan bias to gender bias. In this research, our main contributions could be listed as: i) comparing different LLMs through prompt engineering in their capability of detecting sexism in political discourse; and ii) proposing a new algorithm for capturing the confidence of the LLM predictions in classification tasks. Experimental results demonstrate a clear indication of trigger events that provoke online sexism, and yet no clear advantage of using LLMs while predicting sexism. Surprisingly, the results do not improve with more instructive prompts, but our algorithm proves to be effective in capturing the confidence of each model on their predicted labels.", "title_embedding_index": 6158, "title_abs_embedding_index": 6183}, {"title": "LoRA Dropout as a Sparsity Regularizer for Overfitting Reduction", "link_suffix": "/forum?id=c4498OydLP", "link": "https://openreview.net/forum?id=c4498OydLP", "pdf_link": "https://openreview.net/pdf?id=c4498OydLP", "keywords": "Large Language Model, LoRA, Dropout", "abstract": "Parameter-efficient fine-tuning methods, represented by LoRA, play an essential role in adapting large-scale pre-trained models to downstream tasks. \nHowever, fine-tuning LoRA-series models also face the risk of overfitting on small training datasets, and there's still a lack of theoretical guidance and practical mechanisms to control overfitting on LoRA-based PEFT methods. This paper introduces a novel dropout-based sparsity regularizer for LoRA, dubbed LoRA Dropout, which mitigates overfitting by applying refined dropout to LoRA's low-rank matrices.\nWe establish a theoretical framework that models dropout in LoRA as a sparse fine-tuning process and derive a generalization error bound under this sparsity regularization.\nTheoretical results show that appropriate sparsity can tighten the gap between empirical and generalization risks and thereby control overfitting. We further enhance the sparsity patterns in conventional dropout methods and propose an innovative LoRA Dropout method for more precise sparsity regularization to achieve better overfitting reduction. \nFurthermore, we introduce a test-time ensemble strategy and provide theoretical evidence demonstrating that the ensemble method can further compress the error bound and lead to better performance. \nExtensive experiments on various NLP tasks validate the effectiveness of our LoRA Dropout framework in improving the model's performance.", "title_embedding_index": 6159, "title_abs_embedding_index": 6184}, {"title": "EpilepsyFM: Foundation Model for Learning Generalized Epileptic Representations from EEG and SEEG Signals", "link_suffix": "/forum?id=tfTGSm31F7", "link": "https://openreview.net/forum?id=tfTGSm31F7", "pdf_link": "https://openreview.net/pdf?id=tfTGSm31F7", "keywords": "Epilepsy, Foundation Model, Electroencephalography, Stereoelectroencephalography", "abstract": "Extracranial electroencephalography (EEG) and intracranial stereoelectroencephalography (SEEG) are crucial for epilepsy diagnosis. However, existing deep learning models often limit themselves to specific signal types and application scenarios, leading to challenges in generalization and perception capabilities. While large language models excel in natural language processing, they cannot effectively capture the disease-specific signal features in the highly specialized field of epilepsy, and the lack of pre-training data restricts their generalization ability. To address these issues, we propose a Epilepsy Foundation Model (EpilepsyFM), a domain-specific foundational model that considers the mechanisms of seizure and propagation in epilepsy. EpilepsyFM learns a generalized representation of epilepsy through unsupervised pre-training across various signal types, data formats, and sources, and optimizes multiple epilepsy-related downstream tasks through fine-tuning. We collected clinical EEG and SEEG data from multiple patients at a first-class hospital, as well as the currently largest publicly available epilepsy dataset, the TUH series, ensuring diversity in representation learning. First, the neural activity signals are segmented into multiple patches, and a discrete EEG and SEEG neural tokenizer is trained to construct a domain-specific neural codebook for epilepsy. Then, EpilepsyFM takes into account the mechanisms of clustered neuronal discharges in epilepsy and designs a channel set masking strategy to enhance the model's ability to capture the spatiotemporal characteristics of the signals. The model fully utilizes the multi-dimensional propagation characteristics of seizures through temporal, spectral, and spatial encoder modules, achieving comprehensive representation of complex neural signals. Extensive experiments show that EpilepsyFM achieves state-of-the-art performance in a variety of domain-specific tasks, including seizure detection and both short-term and long-term predictions of neural signals, demonstrating strong generalization ability and broad clinical application potential.", "title_embedding_index": 6160, "title_abs_embedding_index": 6185}, {"title": "Words in Motion: Extracting Interpretable Control Vectors for Motion Transformers", "link_suffix": "/forum?id=J9eKm7j6KD", "link": "https://openreview.net/forum?id=J9eKm7j6KD", "pdf_link": "https://openreview.net/pdf?id=J9eKm7j6KD", "keywords": "control vectors, activation steering, sparse autoencoder, neural collapse, motion forecasting", "abstract": "Transformer-based models generate hidden states that are difficult to interpret. In this work, we aim to interpret these hidden states and control them at inference, with a focus on motion forecasting. We leverage the phenomenon of neural collapse and use linear probes to measure interpretable features in hidden states. Our experiments reveal meaningful directions and distances between hidden states of opposing features, which we use to fit control vectors for activation steering. We further refine our approach using sparse autoencoders to optimize our control vectors. Notably, we show that enforcing sparsity leads to a more linear relationship between control vector temperatures and forecasts. Our approach not only enables mechanistic interpretability but also zero-shot generalization to unseen dataset characteristics.", "title_embedding_index": 6161, "title_abs_embedding_index": 6186}, {"title": "ConDiff: A Challenging Dataset for Neural Solvers of Partial Differential Equations", "link_suffix": "/forum?id=uM2IDdivyC", "link": "https://openreview.net/forum?id=uM2IDdivyC", "pdf_link": "https://openreview.net/pdf?id=uM2IDdivyC", "keywords": "Dataset, PDEs, scientific computing, neural operators", "abstract": "We present ConDiff, a novel dataset for scientific machine learning. ConDiff focuses on the diffusion equation with varying coefficients, a fundamental problem in many applications of parametric partial differential equations (PDEs). The main novelty of the proposed dataset is that we consider discontinuous coefficients with high contrast. These coefficient functions are sampled from a selected set of distributions. This class of problems is not only of great academic interest, but is also the basis for describing various environmental and industrial problems. In this way, ConDiff shortens the gap with real-world problems while remaining fully synthetic and easy to use. ConDiff consists of a diverse set of diffusion equations with coefficients covering a wide range of contrast levels and heterogeneity with a measurable complexity metric for clearer comparison between different coefficient functions. We baseline ConDiff on standard deep learning models in the field of scientific machine learning. By providing a large number of problem instances, each with its own coefficient function and right-hand side, we hope to encourage the development of novel physics-based deep learning approaches, such as neural operators, ultimately driving progress towards more accurate and efficient solutions of complex PDE problems.", "title_embedding_index": 6162, "title_abs_embedding_index": 6187}, {"title": "Divide And Conquer: Efficiently Decoupling Consensus And Divergence For Federated Large Language Model Fine-Tuning", "link_suffix": "/forum?id=pLyjsv1KWH", "link": "https://openreview.net/forum?id=pLyjsv1KWH", "pdf_link": "https://openreview.net/pdf?id=pLyjsv1KWH", "keywords": "Federated Learning, Large Language Model", "abstract": "Federated Learning provides an efficient framework for fine-tuning Large Language Models (LLMs) on diverse private datasets, addressing the growing scarcity of publicly available training data while maintaining data privacy. However, in practice, client data typically spans multiple domains, posing significant challenges for the global model\u2019s generalization capabilities. To address this issue, we introduce a novel framework,FederatedConsensus-DivergenceDecoupling for LLM Fine-Tuning (FedCDD), designed to enhance global model performance in such heterogeneous environments. Our framework introduces a mechanism for consensus aggregation and divergence alignment, decoupling client updates into \u201cconsensus\u201d and \u201cdivergence\u201d parts. This allows the LLM to maintain a unified consensus while accommodating domain-specific divergences. Additionally, we employ a Gaussian-Noise Mask to regulate local model uploads, preventing the LLM from overfitting to domain-specific knowledge. Experimental results on heterogeneous datasets demonstrate the superiority of our approach over existing methods. The code is anonymously available athttps://anonymous.4open.science/r/FedCDD-5DA6.", "title_embedding_index": 6163, "title_abs_embedding_index": 6188}, {"title": "ProtPainter: Draw or Drag Protein via Topology-guided Diffusion", "link_suffix": "/forum?id=Nq7yKYL0Bp", "link": "https://openreview.net/forum?id=Nq7yKYL0Bp", "pdf_link": "https://openreview.net/pdf?id=Nq7yKYL0Bp", "keywords": "Protein Backbone Generation, Conditional Diffusion, Topology, Protein Editing", "abstract": "Recent advances in protein backbone generation have achieved promising results under structural, functional, or physical constraints. However, existing methods lack the flexibility for precise topology control, limiting navigation of the backbone space. We present $\\textbf{ProtPainter}$, a diffusion-based approach for generating protein backbones conditioned on 3D curves. ProtPainter follows a two-stage process: curve-based sketching and sketch-guided backbone generation. For the first stage, we propose $\\textbf{CurveEncoder}$, which predicts secondary structure annotations from a curve to parametrize sketch generation. For the second stage, the sketch guides the generative process in Denoising Diffusion Probabilistic Modeling (DDPM) to generate backbones. During the process, we further introduce a fusion scheduling scheme, Helix-Gating, to control the scaling factors. To evaluate, we propose the first benchmark for topology-conditioned protein generation, introducing Protein Restoration Task and a new metric, self-consistency Topology Fitness (scTF). Experiments demonstrate ProtPainter's ability to generate topology-fit (scTF $>$ 0.8) and designable (scTM $>$ 0.5) backbones, with drawing and dragging tasks showcasing its flexibility and versatility.", "title_embedding_index": 6164, "title_abs_embedding_index": 6189}, {"title": "KinPFN: Bayesian Approximation of RNA Folding Kinetics using Prior-Data Fitted Networks", "link_suffix": "/forum?id=E1m5yGMOiV", "link": "https://openreview.net/forum?id=E1m5yGMOiV", "pdf_link": "https://openreview.net/pdf?id=E1m5yGMOiV", "keywords": "RNA Folding Kinetics, Prior-Data Fitted Networks, Deep Learning, Synthetic Data, Transformer, Bayesian Inference", "abstract": "RNA is a dynamic biomolecule crucial for cellular regulation, with its function largely determined by its folding into complex structures, while misfolding can lead to multifaceted biological sequelae. During the folding process, RNA traverses through a series of intermediate structural states, with each transition occurring at variable rates that collectively influence the time required to reach the functional form. Understanding these folding kinetics is vital for predicting RNA behavior and optimizing applications in synthetic biology and drug discovery. While in silico kinetic RNA folding simulators are often computationally intensive and time-consuming, accurate approximations of the folding times can already be very informative to assess the efficiency of the folding process. In this work, we present KinPFN, a novel approach that leverages prior-data fitted networks to directly model the posterior predictive distribution of RNA folding times. By training on synthetic data representing arbitrary prior folding times, KinPFN efficiently approximates the cumulative distribution function of RNA folding times in a single forward pass, given only a few initial folding time examples. Our method offers a modular extension to existing RNA kinetics algorithms, promising significant computational speed-ups orders of magnitude faster, while achieving comparable results. We showcase the effectiveness of KinPFN through extensive evaluations and real-world case studies, demonstrating its potential for RNA folding kinetics analysis, its practical relevance, and generalization to other biological data.", "title_embedding_index": 6165, "title_abs_embedding_index": 6190}, {"title": "Sketch2Diagram: Generating Vector Diagrams from Hand-Drawn Sketches", "link_suffix": "/forum?id=KvaDHPhhir", "link": "https://openreview.net/forum?id=KvaDHPhhir", "pdf_link": "https://openreview.net/pdf?id=KvaDHPhhir", "keywords": "multimodal, large language model, diagram, vector graphics", "abstract": "We address the challenge of automatically generating high-quality vector diagrams from hand-drawn sketches. \nVector diagrams are essential for communicating complex ideas across various fields, offering flexibility and scalability. \nWhile recent research has progressed in generating diagrams from text descriptions, converting hand-drawn sketches into vector diagrams remains largely unexplored, primarily due to the lack of suitable datasets. \nTo address this, we introduce SketikZ, a dataset containing 3,231 pairs of hand-drawn sketches, reference diagrams, and corresponding TikZ codes. \nOur evaluations highlight current limitations of state-of-the-art vision and language models (VLMs), establishing SketikZ as a key benchmark for future research in sketch-to-diagram conversion.\nAlong with SketikZ, we present ImgTikZ, an image-to-TikZ model that integrates a 6.7B parameter code-specialized open-source large language model (LLM) with a pre-trained vision encoder. \nDespite its modest size, ImgTikZ demonstrates performance comparable to more extensive models such as GPT-4o.\nThe model's success is largely driven by using our two data augmentation techniques and a multi-candidate inference strategy,\nsignificantly improving its performance.\nThese findings provide promising avenues for future research in sketch-to-diagram conversion and may have broader implications for image-to-code generation tasks. SketikZ is publicly available.", "title_embedding_index": 6166, "title_abs_embedding_index": 6191}, {"title": "Transformers Provably Solve Parity Efficiently with Chain of Thought", "link_suffix": "/forum?id=n2NidsYDop", "link": "https://openreview.net/forum?id=n2NidsYDop", "pdf_link": "https://openreview.net/pdf?id=n2NidsYDop", "keywords": "transformers, chain of thought, parity, self-consistency", "abstract": "This work provides the first theoretical analysis of training transformers to solve complex problems by recursively generating intermediate states, analogous to fine-tuning for chain-of-thought (CoT) reasoning. We consider training a one-layer transformer to solve the fundamental $k$-parity problem, extending the work on RNNs by \\citet{Wies23}. We establish three key results: (1) any finite-precision gradient-based algorithm, without intermediate supervision, requires substantial iterations to solve parity with finite samples. (2) In contrast, when intermediate parities are incorporated into the loss function, our model can learn parity in one gradient update when aided by \\emph{teacher forcing}, where ground-truth labels of the reasoning chain are provided at each generation step. (3) Even without teacher forcing, where the model must generate CoT chains end-to-end, parity can be learned efficiently if augmented data is employed to internally verify the soundness of intermediate steps. These results rigorously show that task decomposition and stepwise reasoning naturally arise from optimizing transformers with CoT; moreover, self-consistency checking can improve reasoning ability, aligning with empirical studies of CoT.", "title_embedding_index": 6167, "title_abs_embedding_index": 6192}, {"title": "The Vital Role of Gradient Clipping in Byzantine-Resilient Distributed Learning", "link_suffix": "/forum?id=03OkC0LKDD", "link": "https://openreview.net/forum?id=03OkC0LKDD", "pdf_link": "https://openreview.net/pdf?id=03OkC0LKDD", "keywords": "Byzantine resilience, distributed machine learning", "abstract": "Byzantine-resilient distributed machine learning seeks to achieve robust learning performance in the presence of misbehaving or adversarial workers.\nWhile state-of-the-art (SOTA) robust distributed gradient descent (Robust-DGD) methods were\nproven theoretically optimal, their empirical success has often relied on pre-aggregation gradient clipping.\nHowever, the currently considered static\nclipping strategy \nexhibits mixed results: improving robustness against some attacks while being ineffective or detrimental against others.\nWe address this gap by \nproposing a principled adaptive clipping strategy, termed Adaptive Robust Clipping (ARC).\nWe show that ARC consistently enhances the empirical robustness of SOTA Robust-DGD methods, while preserving the theoretical robustness guarantees. \nOur analysis shows that ARC provably improves the asymptotic convergence guarantee of Robust-DGD in the case when the model is well-initialized.\nWe validate this theoretical insight through an exhaustive set of experiments on benchmark image classification tasks.\nWe observe that the improvement induced by ARC is more pronounced in highly heterogeneous and adversarial settings.", "title_embedding_index": 6168, "title_abs_embedding_index": 6193}, {"title": "Agents' Room:  Narrative Generation through Multi-step Collaboration", "link_suffix": "/forum?id=HfWcFs7XLR", "link": "https://openreview.net/forum?id=HfWcFs7XLR", "pdf_link": "https://openreview.net/pdf?id=HfWcFs7XLR", "keywords": "fiction, creative writing, long-form generation, LLMs, agent, collaboration, multi-agent, dataset", "abstract": "Writing compelling fiction is a multifaceted process combining elements such as crafting a plot, developing interesting characters, and using evocative language. While large language models (LLMs) show promise for story writing, they currently rely heavily on intricate prompting, which limits their use. We propose Agents' Room, a generation framework inspired by narrative theory, that decomposes narrative writing into subtasks tackled by specialized agents. To illustrate our method, we introduce Tell Me A Story, a high-quality dataset of complex writing prompts and human-written stories, and a novel evaluation framework designed specifically for assessing long narratives. We show that Agents' Room generates stories that are preferred by expert evaluators over those produced by baseline systems by leveraging collaboration and specialization to decompose the complex story writing task into tractable components. We provide extensive analysis with automated and human-based metrics of the generated output.", "title_embedding_index": 6169, "title_abs_embedding_index": 6194}, {"title": "Boosting In-Context Learning in LLMs with Retrieval-based Codebook", "link_suffix": "/forum?id=TWjNSzk7mP", "link": "https://openreview.net/forum?id=TWjNSzk7mP", "pdf_link": "https://openreview.net/pdf?id=TWjNSzk7mP", "keywords": "large language model, in-context learning, retrieval, codebook", "abstract": "Recent advancements in large language models (LLMs) have demonstrated exceptional performance across various downstream tasks, particularly due to their in-context learning (ICL) abilities. ICL enables models to learn from a few demonstrations presented in the context, without requiring retraining or fine-tuning. However, the effectiveness of ICL is highly dependent on factors such as prompt design and input length. To address these limitations, we propose a novel approach that leverages the key-value pairs within Transformers to enhance contextual understanding in LLMs. Specifically, our method converts raw demonstrations into task vectors\u2014comprising keys and values\u2014which are derived through multiple passes of the LLM, then integrated with test task vectors to improve model comprehension of the input. Furthermore, we introduce a retrieval-based codebook mechanism that captures information from long-context demonstrations while filtering irrelevant content. This codebook dynamically stores and updates task vectors generated during inference, mitigating input length constraints and optimizing the relevance of contextual data. By retrieving the most pertinent historical task vectors, the codebook ensures that only relevant information is utilized during inference. Extensive experiments show that these enhancements significantly outperform conventional ICL, achieving superior accuracy and efficiency. Overall, this work sets a new benchmark for optimizing ICL in LLMs, enabling their effective deployment in complex, real-world applications.", "title_embedding_index": 6170, "title_abs_embedding_index": 6195}, {"title": "How Does Vision-Language Adaptation Impact the Safety of Vision Language Models?", "link_suffix": "/forum?id=eXB5TCrAu9", "link": "https://openreview.net/forum?id=eXB5TCrAu9", "pdf_link": "https://openreview.net/pdf?id=eXB5TCrAu9", "keywords": "Large Vision Language Model, Safety", "abstract": "Vision-Language adaptation (VL adaptation) transforms Large Language Models (LLMs) into Large Vision-Language Models (LVLMs) for multimodal tasks, but this process often compromises the inherent safety capabilities embedded in the original LLMs. Despite potential harmfulness due to weakened safety measures, in-depth analysis on the effects of VL adaptation on safety remains under-explored. This study examines how VL adaptation influences safety and evaluates the impact of safety fine-tuning methods. Our analysis reveals that safety degradation occurs during VL adaptation, even when the training data is safe. While safety tuning techniques like supervised fine-tuning with safety datasets or reinforcement learning from human feedback mitigate some risks, they still lead to safety degradation and a reduction in helpfulness due to over-rejection issues. Further analysis of internal model weights suggests that VL adaptation may impact certain safety-related layers, potentially lowering overall safety levels. Additionally, our findings demonstrate that the objectives of VL adaptation and safety tuning are divergent, which often results in their simultaneous application being suboptimal. To address this, we suggest the weight merging approach as an optimal solution effectively reducing safety degradation while maintaining helpfulness. These insights help guide the development of more reliable and secure LVLMs for real-world applications.", "title_embedding_index": 6171, "title_abs_embedding_index": 6196}, {"title": "Reinforcement Learning on Synthetic Navigation Data allows Safe Navigation in Blind Digital Twins", "link_suffix": "/forum?id=0JwxMqKGxa", "link": "https://openreview.net/forum?id=0JwxMqKGxa", "pdf_link": "https://openreview.net/pdf?id=0JwxMqKGxa", "keywords": "Electronic Travel Aids, Virtual Environment, Semantic segmentation, Reinforcement Learning", "abstract": "Limited access to dedicated navigation data in visually impaired individuals is a significant bottleneck for developing AI-driven assistive devices. For this purpose, we have developped a virtual environment designed to extract various human-like navigation data from procedurally generated labyrinths. Using reinforcement learning and semantic segmentation, we trained a convolutional neural network to perform obstacle avoidance from synthetic data. Our model outperformed state-of-the-art backbones including DINOv2-B in safe pathway identification in real world. In conclusion, despite being trained only on synthetic data, our model successfully extracted features compatible with safe navigation in real-world settings, opening new avenues for visually impaired.", "title_embedding_index": 6172, "title_abs_embedding_index": 6197}, {"title": "Oscillatory State-Space Models", "link_suffix": "/forum?id=GRMfXcAAFh", "link": "https://openreview.net/forum?id=GRMfXcAAFh", "pdf_link": "https://openreview.net/pdf?id=GRMfXcAAFh", "keywords": "state-space models, sequence models, long-range interactions, oscillators, time-series", "abstract": "We propose Linear Oscillatory State-Space models (LinOSS) for efficiently learning on long sequences. Inspired by cortical dynamics of biological neural networks, we base our proposed LinOSS model on a system of forced harmonic oscillators. A stable discretization, integrated over time using fast associative parallel scans, yields the proposed state-space model. We prove that LinOSS produces stable dynamics only requiring nonnegative diagonal state matrix. This is in stark contrast to many previous state-space models relying heavily on restrictive parameterizations. Moreover, we rigorously show that LinOSS is universal, i.e., it can approximate any continuous and causal operator mapping between time-varying functions, to desired accuracy. In addition, we show that an implicit-explicit discretization of LinOSS perfectly conserves the symmetry of time reversibility of the underlying dynamics. Together, these properties enable efficient modeling of long-range interactions, while ensuring stable and accurate long-horizon forecasting. Finally, our empirical results, spanning a wide range of time-series tasks from mid-range to very long-range classification and regression, as well as long-horizon forecasting, demonstrate that our proposed LinOSS model consistently outperforms state-of-the-art sequence models. Notably, LinOSS outperforms Mamba by nearly 2x and LRU by 2.5x on a sequence modeling task with sequences of length 50k.", "title_embedding_index": 6173, "title_abs_embedding_index": 6198}, {"title": "Centrality Graph Shift Operators for Graph Neural Networks", "link_suffix": "/forum?id=NKE7VTxVKL", "link": "https://openreview.net/forum?id=NKE7VTxVKL", "pdf_link": "https://openreview.net/pdf?id=NKE7VTxVKL", "keywords": "Graph Neural Networks, Graph Shift Operators, Centrality", "abstract": "Graph Shift Operators (GSOs), such as the adjacency and graph Laplacian matrices, play a fundamental role in graph theory and graph representation learning. Traditional GSOs are typically constructed by normalizing the adjacency matrix by the degree matrix, a local centrality metric. In this work, we instead propose and study Centrality GSOs (CGSOs), which normalize adjacency matrices by global centrality metrics such as the PageRank, $k$-core or count of fixed length paths. We study spectral properties of the CGSOs, allowing us to get an understanding of their action on graph signals. We confirm this understanding by defining and running the spectral clustering algorithm based on different CGSOs on several synthetic and real-world datasets. We furthermore outline how our CGSO can act as the message passing operator in any Graph Neural Network and in particular demonstrate strong performance of a variant of the Graph Convolutional Network and Graph Attention Network using our CGSOs on several real-world benchmark datasets.", "title_embedding_index": 6174, "title_abs_embedding_index": 6199}]
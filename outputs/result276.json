[
    {
        "title": "Goal-Conditioned Reinforcement Learning with Virtual Experiences",
        "link_suffix": "/forum?id=OjCWG58ZyY",
        "link": "https://openreview.net/forum?id=OjCWG58ZyY",
        "pdf_link": "https://openreview.net/pdf?id=OjCWG58ZyY",
        "keywords": "Subgoal Planning, Curriculum Learning, Imitating Learning",
        "abstract": "Goal-conditioned reinforcement learning often employs a technique known as Hindsight Experience Replay (HER) for data augmentation by relabeling goals. However, HER limits goal relabeling to a single trajectory, which hinders the utilization of experiences from diverse trajectories. To address this issue, we present a curriculum learning method to construct virtual experiences, incorporating actual state transitions and virtual goals selected from the replay buffer. Considering that virtual experiences may contain a lot of noise, we also propose a self-supervised subgoal planning method that guides the learning of virtual experiences by imitating the subgoal-conditioned policy. Our intuition is that achieving a virtual goal may be challenging for the goal-conditioned policy, whereas simplified subgoals can provide effective guidance. We empirically show that the virtual experiences from diverse historical trajectories significantly boost the sample-efficiency compared to the existing goal-conditioned reinforcement learning and hierarchical reinforcement learning methods, even enabling the agent to learn tasks it has never experienced."
    },
    {
        "title": "Improved Convex Decomposition with Ensembling and Boolean Primitives",
        "link_suffix": "/forum?id=No2PNOiKgb",
        "link": "https://openreview.net/forum?id=No2PNOiKgb",
        "pdf_link": "https://openreview.net/pdf?id=No2PNOiKgb",
        "keywords": "Geometric Primitives, convex decomposition, Ensembling",
        "abstract": "Describing a scene in terms of primitives -- geometrically simple shapes that offer a parsimonious but accurate abstraction of structure -- is an established and difficult fitting problem. Different scenes require different numbers of primitives, and these primitives interact strongly; however, any proposed solution can be evaluated at inference time. The state of the art method involves a learned regression procedure to predict a start point consisting of a fixed number of primitives, followed by a descent method to refine the geometry and remove redundant primitives. Methods are evaluated by accuracy in depth and normal prediction and in scene segmentation. This paper shows that very significant improvements in accuracy can be obtained by (a) incorporating a small number of \\emph{negative} primitives and (b) ensembling over a number of different regression procedures. Ensembling is by refining each predicted start point, then choosing the best by fitting loss. Extensive experiments on the standard NYUv2 dataset confirm that negative primitives are useful, and that our refine-then-choose strategy outperforms choose-then-refine, confirming that the fitting problem is very difficult. Our ensembling with boolean primitives approach strongly outperforms existing methods; additionally we present several improvements to the underlying primitive generation process enabling us to obtain better decompositions with fewer primitives. Code will be released upon acceptance of the paper."
    },
    {
        "title": "Graph Vision Networks for Link Prediction",
        "link_suffix": "/forum?id=mhCNUP4Udw",
        "link": "https://openreview.net/forum?id=mhCNUP4Udw",
        "pdf_link": "https://openreview.net/pdf?id=mhCNUP4Udw",
        "keywords": "Graph Neural Networks\uff1bLink Prediction\uff1bMultimodality",
        "abstract": "Traditional message-passing neural networks (MPNNs) face challenges regarding limited expressive power and coarse-grained structural awareness in link prediction tasks. While heuristic structural features (SFs) have been instrumental in enhancing MPNNs' performance in these aspects, they typically offer insights from a fixed structural perspective, lacking adaptability to diverse real-world scenarios. In response to this need for flexible structural insights, we introduce Graph Vision Networks (GVNs). By integrating vision awareness into MPNNs for link prediction, GVN models can adaptively extract learnable visual structural features (VSFs), leading to significant performance improvements across seven commonly used link prediction datasets."
    },
    {
        "title": "ION-C: Integration of Overlapping Networks via Constraints",
        "link_suffix": "/forum?id=F8qvqtnSHy",
        "link": "https://openreview.net/forum?id=F8qvqtnSHy",
        "pdf_link": "https://openreview.net/pdf?id=F8qvqtnSHy",
        "keywords": "Causal learning, Constraint satisfaction, Answer set programming, Social science data",
        "abstract": "In many causal learning problems, variables of interest are often not all measured over the same observations, but are instead distributed across multiple datasets with overlapping variables. Tillman et al. (2008) presented the first algorithm for determining the minimal equivalence class of ground-truth DAGs consistent with all input graphs by exploiting local independence relations, called ION. In this paper, this problem is formulated as a more computationally efficient answer-set programming (ASP) problem, which we call ION-C, and solved with the ASP system $\\textit{clingo}$. The ION-C algorithm was run on random synthetic graphs with varying sizes, densities, and degrees of overlap between subgraphs, with overlap having the largest impact on runtime, number of solution graphs, and agreement within the output set. To validate ION-C on real-world data, we ran the algorithm on overlapping graphs learned from data from two successive iterations of the European Social Survey (ESS), using a procedure for conducting joint independence tests to prevent inconsistencies in the input."
    },
    {
        "title": "CBraMod: A Criss-Cross Brain Foundation Model for EEG Decoding",
        "link_suffix": "/forum?id=NPNUHgHF2w",
        "link": "https://openreview.net/forum?id=NPNUHgHF2w",
        "pdf_link": "https://openreview.net/pdf?id=NPNUHgHF2w",
        "keywords": "Foundation Model; EEG; Criss-Cross Transformer; Downstream BCI tasks",
        "abstract": "Electroencephalography (EEG) is a non-invasive technique to measure and record brain electrical activity, widely used in various BCI and healthcare applications. Early EEG decoding methods rely on supervised learning, limited by specific tasks and datasets, hindering model performance and generalizability. With the success of large language models, there is a growing body of studies focusing on EEG foundation models. However, these studies still leave challenges: Firstly, most of existing EEG foundation models employ full EEG modeling strategy. It models the spatial and temporal dependencies between all EEG patches together, but ignores that the spatial and temporal dependencies are heterogeneous due to the unique structural characteristics of EEG signals. Secondly, existing EEG foundation models have limited generalizability on a wide range of downstream BCI tasks due to varying formats of EEG data, making it challenging to adapt to. To address these challenges, we propose a novel foundation model called CBraMod. Specifically, we devise a criss-cross transformer as the backbone to thoroughly leverage the structural characteristics of EEG signals, which can model spatial and temporal dependencies separately through two parallel attention mechanisms. And we utilize an asymmetric conditional positional encoding scheme which can encode positional information of EEG patches and be easily adapted to the EEG with diverse formats. CBraMod is pre-trained on a very large corpus of EEG through patch-based masked EEG reconstruction. We evaluate CBraMod on up to 10 downstream BCI tasks (12 public datasets). CBraMod achieves the state-of-the-art performance across the wide range of tasks, proving its strong capability and generalizability."
    },
    {
        "title": "PO3AD: Predicting Point Offsets toward Better 3D Point Cloud Anomaly Detection",
        "link_suffix": "/forum?id=Slr3KojVRO",
        "link": "https://openreview.net/forum?id=Slr3KojVRO",
        "pdf_link": "https://openreview.net/pdf?id=Slr3KojVRO",
        "keywords": "3D point cloud, anomaly detection",
        "abstract": "Point cloud anomaly detection, particularly under the anomaly-free setting, poses a significant challenge as it requires the precise capture of 3D normal data features to accurately identify deviations indicative of anomalies. Current efforts focus on devising reconstruction tasks, such as acquiring normal data representations by restoring normal samples from altered, pseudo-anomalous counterparts. Nonetheless, such methods tend to dilute the model's focus, as they require attention to both normal and pseudo-anomalous data points, thereby hampering the efficacy of the learning process. Moreover, the inherently disordered and sparse nature of 3D point cloud data significantly complicates the task.  In response to those predicaments, we introduce an innovative approach that involves learning point offsets for the first time, with a concentrated emphasis on more informative pseudo-abnormal points, thus fostering more effective distillation of normal data representations. We have crafted an augmentation technique that is steered by normal vectors, facilitating the creation of credible pseudo anomalies that enhance the efficiency of the training process. Our comprehensive experimental evaluation on the Anomaly-ShapeNet and Real3D-AD datasets evidences that our proposed method outperforms existing state-of-the-art approaches, achieving an average enhancement of 9.0% and 1.4% in the AUC-ROC detection metric across these datasets, respectively."
    },
    {
        "title": "PFDiff: Training-free Acceleration of Diffusion Models through the Gradient Guidance of Past and Future",
        "link_suffix": "/forum?id=wmmDvZGFK7",
        "link": "https://openreview.net/forum?id=wmmDvZGFK7",
        "pdf_link": "https://openreview.net/pdf?id=wmmDvZGFK7",
        "keywords": "diffusion models, accelerated sampling, training-free sampler, orthogonal sampling method",
        "abstract": "Diffusion Probabilistic Models (DPMs) have shown remarkable potential in image generation, but their sampling efficiency is hindered by the need for numerous denoising steps. Most existing solutions accelerate the sampling process by proposing fast ODE solvers. However, the inevitable discretization errors of the ODE solvers are significantly magnified when the number of function evaluations (NFE) is fewer. In this work, we propose PFDiff, a novel training-free and orthogonal timestep-skipping strategy, which enables existing fast ODE solvers to operate with fewer NFE. Specifically, PFDiff initially utilizes gradient replacement from past time steps to predict a \u201cspringboard\u201d. Subsequently, it employs this \u201cspringboard\u201d along with foresight updates inspired by Nesterov momentum to rapidly update current intermediate states. This approach effectively reduces unnecessary NFE while correcting for discretization errors inherent in first-order ODE solvers. Experimental results demonstrate that PFDiff exhibits flexible applicability across various pre-trained DPMs, particularly excelling in conditional DPMs and surpassing previous state-of-the-art training-free methods. For instance, using DDIM as a baseline, we achieved 16.46 FID (4 NFE) compared to 138.81 FID with DDIM on ImageNet 64x64 with classifier guidance, and 13.06 FID (10 NFE) on Stable Diffusion with 7.5 guidance scale."
    },
    {
        "title": "Consistent Flow Distillation for Text-to-3D Generation",
        "link_suffix": "/forum?id=A51NEXIq1J",
        "link": "https://openreview.net/forum?id=A51NEXIq1J",
        "pdf_link": "https://openreview.net/pdf?id=A51NEXIq1J",
        "keywords": "Diffusion Models, Score Distillation, 3D Generation",
        "abstract": "Score Distillation Sampling (SDS) has made significant strides in distilling image-generative models for 3D generation. However, its maximum-likelihood-seeking behavior often leads to degraded visual quality and diversity, limiting its effectiveness in 3D applications. In this work, we propose Consistent Flow Distillation (CFD), which addresses these limitations. We begin by leveraging the gradient of the diffusion ODE or SDE sampling process to guide the 3D generation. From the gradient-based sampling perspective, we find that the consistency of 2D image flows across different viewpoints is important for high-quality 3D generation. To achieve this, we introduce multi-view consistent Gaussian noise on the 3D object, which can be rendered from various viewpoints to compute the flow gradient. Our experiments demonstrate that CFD, through consistent flows, significantly outperforms previous methods in text-to-3D generation."
    },
    {
        "title": "A Precompute-Then-Adapt Approach for Efficient Graph Condensation",
        "link_suffix": "/forum?id=kwagvI8Anf",
        "link": "https://openreview.net/forum?id=kwagvI8Anf",
        "pdf_link": "https://openreview.net/pdf?id=kwagvI8Anf",
        "keywords": "graph, condensation",
        "abstract": "Graph Neural Networks (GNNs) have shown great success in leveraging complex relationships in data but face significant computational challenges when dealing with large-scale graphs. To tackle this issue, graph condensation methods aim to compress large graphs into smaller, synthetic ones that can be efficiently used for GNN training. Recent approaches, particularly those based on trajectory matching, have achieved state-of-the-art (SOTA) performance in graph condensation tasks.  Trajectory-based techniques match the training behavior on a condensed graph closely with that on the original graph, typically by guiding the trajectory of model parameters during training. However, these methods require repetitive re-training of GNNs during the condensation process, making them impractical for large graphs due to their high computational cost, \\eg, taking up to 22 days to condense million-node graphs. In this paper, we propose a novel Precompute-then-Adapt graph condensation framework that overcomes this limitation by separating the condensation process into a one-time precomputation stage and a one-time adaptation learning stage. Remarkably, even with only the precomputation stage, which typically takes seconds, our method surpasses or matches SOTA results on 3 out of 7 benchmark datasets. Extensive experiments demonstrate that our approach achieves better or comparable accuracy while being 96\u00d7 to 2,455\u00d7 faster in condensation time compared to SOTA methods, significantly enhancing the practicality of GNNs for large-scale graph applications. Our code and data are available at \\url{https://anonymous.4open.science/r/GCPA-F6F9/}."
    },
    {
        "title": "Bounds on the Reconstruction Error of Kernel PCA with Interpolation Spaces Norms",
        "link_suffix": "/forum?id=5FKIynMPV6",
        "link": "https://openreview.net/forum?id=5FKIynMPV6",
        "pdf_link": "https://openreview.net/pdf?id=5FKIynMPV6",
        "keywords": "kernel principal component analysis, reproducing kernel Hilbert space, high-dimensional statistics, convergence rate, interpolation space",
        "abstract": "In this paper, we utilize the interpolation space norm to understand and fill the gaps in  some recent works on  the reconstruction error of the  kernel PCA. After rigorously proving a simple but fundamental claim appeared in the kernel PCA literature, we  provide  upper bound and lower bound of the reconstruction error of the empirical kernel PCA with interpolation space norms under the assumption $(C)$, a condition which is taken for granted in the existing works. Furthermore, we show that the assumption $(C)$ holds in two most interesting settings ( the polynomial-eigenvalue decayed kernels in fixed dimension domain and the inner product kernel on large dimensional sphere $\\mathbb S^{d-1}$ where $n\\asymp d^{\\gamma}$) and compare our bound with the existing results. This work not only fills the gaps appeared in literature,  but also derives an explicit lower bound on the sample size to guarantee that the (optimal) reconstruction error is well approximated by the empirical reconstruction error. Finally, our results reveal that the $[\\mathcal H]^{1}$ norm should not be used in the large dimensional settings."
    },
    {
        "title": "SenseFlow: A Physics-Informed and Self-Ensembling Iterative Framework for Power Flow Estimation",
        "link_suffix": "/forum?id=UKiCFpwcqY",
        "link": "https://openreview.net/forum?id=UKiCFpwcqY",
        "pdf_link": "https://openreview.net/pdf?id=UKiCFpwcqY",
        "keywords": "Power Flow Estimation; Physics-Informed Iterative Framework; Self-Ensembling Estimation",
        "abstract": "Power flow estimation plays a vital role in ensuring the stability and reliability of electrical power systems, particularly in the context of growing network complexities and renewable energy integration. However, existing studies often fail to adequately address the unique characteristics of power systems, such as the sparsity of network connections and the critical importance of the unique Slack node, which poses significant challenges in achieving high-accuracy estimations. In this paper, we present SenseFlow, a novel Physics-Informed and Self-Ensembling Iterative Framework that integrates two main designs, the Physics-Informed Power Flow Network (FlowNet) and Self-Ensembling Iterative Estimation (SeIter), to carefully address the unique properties of the power system and thereby enhance the power flow estimation. Specifically, SenseFlow enforces the FlowNet to gradually predict high-precision voltage magnitudes and phase angles through the iterative SeIter process. On the one hand, FlowNet employs the Virtual Node Attention and Slack-Gated Feed-Forward modules to facilitate efficient global-local communication in the face of network sparsity and amplify the influence of the Slack node on angle predictions, respectively. On the other hand, SeIter maintains an exponential moving average of FlowNet\u2019s parameters to create a robust ensemble model that refines power state predictions throughout the iterative fitting process. Experimental results demonstrate that SenseFlow outperforms existing methods, providing a promising solution for high-accuracy power flow estimation across diverse grid configurations."
    },
    {
        "title": "Robust-PIFu: Robust Pixel-aligned Implicit Function for 3D Human Digitalization from a Single Image",
        "link_suffix": "/forum?id=ftdJEiFudy",
        "link": "https://openreview.net/forum?id=ftdJEiFudy",
        "pdf_link": "https://openreview.net/pdf?id=ftdJEiFudy",
        "keywords": "Human Digitalization, 3D Human Avatar, Pixel-aligned Implicit Models, Latent Diffusion Models, Occlusion, Robustness",
        "abstract": "Existing methods for 3D clothed human digitalization perform well when the input image is captured in ideal conditions that assume the lack of any occlusion. However, in reality, images may often have occlusion problems such as incomplete observation of the human subject's full body, self-occlusion by the human subject, and non-frontal body pose. When given such input images, these existing methods fail to perform adequately. Thus, we propose Robust-PIFu, a pixel-aligned implicit model that capitalized on large-scale, pretrained latent diffusion models to address the challenge of digitalizing human subjects from non-ideal images that suffer from occlusions.Robust-PIfu offers four new contributions. Firstly, we propose a 'disentangling' latent diffusion model. This diffusion model, pretrained on billions of images, takes in any input image and removes external occlusions, such as inter-person occlusions, from that image. Secondly, Robust-PIFu addresses internal occlusions like self-occlusion by introducing a `penetrating' latent diffusion model. This diffusion model outputs multi-layered normal maps that by-pass occlusions caused by the human subject's own limbs or other body parts (i.e. self-occlusion). Thirdly, in order to incorporate such multi-layered normal maps into a pixel-aligned implicit model, we introduce our Layered-Normals Pixel-aligned Implicit Model, which improves the structural accuracy of predicted clothed human meshes. Lastly, Robust-PIFu proposes an optional super-resolution mechanism for the multi-layered normal maps. This addresses scenarios where the input image is of low or inadequate resolution. Though not strictly related to occlusion, this is still an important subproblem. Our experiments show that Robust-PIFu outperforms current SOTA methods both qualitatively and quantitatively. Our code will be released to the public."
    },
    {
        "title": "Descent with Misaligned Gradients and Applications to Hidden Convexity",
        "link_suffix": "/forum?id=2L4PTJO8VQ",
        "link": "https://openreview.net/forum?id=2L4PTJO8VQ",
        "pdf_link": "https://openreview.net/pdf?id=2L4PTJO8VQ",
        "keywords": "optimization, gradient descent, hidden convexity",
        "abstract": "We consider the problem of minimizing a convex objective given access to an oracle that outputs \"misaligned\" stochastic gradients, where the expected value of the output is guaranteed to be correlated with, but not necessarily equal to the true gradient of the objective.  In the case where the misalignment (or bias) of the oracle changes slowly, we obtain an optimization algorithm that achieves the optimum iteration complexity of $\\tilde O(\\epsilon^{-2})$; for the more general case where the changes need not be slow, we obtain an algorithm with $\\tilde O(\\epsilon^{-3})$ iteration complexity.  As an application of our framework, we consider optimization problems with a \"hidden convexity\" property, and obtain an algorithm with $O(\\epsilon^{-3})$ iteration complexity."
    },
    {
        "title": "TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models",
        "link_suffix": "/forum?id=RfYD6v829Y",
        "link": "https://openreview.net/forum?id=RfYD6v829Y",
        "pdf_link": "https://openreview.net/pdf?id=RfYD6v829Y",
        "keywords": "Backdoor Attack, Retrieval-Augmented Generation, Large Language Models, Universal Attack Scenarios",
        "abstract": "Large language models (LLMs) have raised concerns about potential security threats, despite performing significantly in language modeling. Backdoor attacks are one of the vulnerabilities of LLMs. However, their attack costs and robustness have faced criticism amidst the continuous evolution of LLMs. In this paper, we comprehensively expose the threats of backdoor attacks on LLMs by defining three standardized scenarios from the perspective of attackers, users, and jailbreaking LLMs, and we propose TrojanRAG based on those scenarios. TrojanRAG is a joint backdoor attack against the Retrieval-Augmented Generation, that can manipulate LLMs robustly. Specifically, we first build multiple purpose-driven backdoors between poisoned knowledge and triggers in the retrieval backdoor injection phase, where retrieval performs well for clean queries but always returns semantic-consistency poisoned content for poisoned queries. Second, we induce the target output on LLMs based on the retrieved poisoned knowledge in the inductive attack generation phase. The joint backdoors are orthogonally optimized by contrastive learning, ensuring that multiple backdoors are independent of each other within the parameter subspace. Meanwhile, we introduce a knowledge graph to construct structured metadata, improving retrieval performance at a fine-grained level. Extensive evaluations across 11 tasks in six LLMs highlight TrojanRAG\u2019s threats and transferability, particularly in Chain of Thought (CoT) mode."
    },
    {
        "title": "On Statistical Rates of Conditional Diffusion Transformer: Approximation and Estimation",
        "link_suffix": "/forum?id=c54apoozCS",
        "link": "https://openreview.net/forum?id=c54apoozCS",
        "pdf_link": "https://openreview.net/pdf?id=c54apoozCS",
        "keywords": "Conditional Diffusion Transformer, Statistical Rates, Approximation, Estimation",
        "abstract": "We investigate the approximation and estimation rates of conditional diffusion transformers (DiTs) with classifier-free guidance.\nWe present a comprehensive analysis for ``in-context'' conditional DiTs under four common data assumptions.\nWe show that both conditional DiTs and their latent variants lead to the minimax optimality of unconditional DiTs under identified settings.\nSpecifically, we discretize the input domains into infinitesimal grids and then perform a term-by-term Taylor expansion on the conditional diffusion score function under H\u00f6lder smooth data assumption.\nThis enables fine-grained use of transformers' universal approximation through a more detailed piecewise constant approximation, and hence obtains tighter bounds.\nAdditionally, we extend our analysis to the latent setting under the  linear latent subspace assumption.\nWe not only show that latent conditional DiTs achieve lower bounds than conditional DiTs both in approximation and estimation, but also show the minimax optimality of latent unconditional DiTs.\nOur findings establish statistical limits for conditional and unconditional DiTs, and offer\npractical guidance toward developing more efficient and accurate DiT models."
    },
    {
        "title": "Universal Image Restoration Pre-training via Degradation Classification",
        "link_suffix": "/forum?id=PacBhLzeGO",
        "link": "https://openreview.net/forum?id=PacBhLzeGO",
        "pdf_link": "https://openreview.net/pdf?id=PacBhLzeGO",
        "keywords": "Pre-training; Degradation Classfication; Universal restoration;",
        "abstract": "This paper proposes the Degradation Classification Pre-Training (DCPT), which enables models to learn how to classify the degradation type of input images for universal image restoration pre-training. Unlike the existing self-supervised pre-training methods, DCPT utilizes the degradation type of the input image as an extremely weak supervision, which can be effortlessly obtained, even intrinsic in all image restoration datasets. DCPT comprises two primary stages. Initially, image features are extracted from the encoder. Subsequently, a lightweight decoder, such as ResNet18, is leveraged to classify the degradation type of the input image solely based on the features extracted in the first stage, without utilizing the input image. The encoder is pre-trained with a straightforward yet potent DCPT, which is used to address universal image restoration and achieve outstanding performance. Following DCPT, both convolutional neural networks (CNNs) and transformers demonstrate performance improvements, with gains of up to 2.55 dB in the 10D all-in-one restoration task and 6.53 dB in the mixed degradation scenarios. Moreover, previous self-supervised pretraining methods, such as masked image modeling, discard the decoder after pre-training, while our DCPT utilizes the pre-trained parameters more effectively. This superiority arises from the degradation classifier acquired during DCPT, which facilitates transfer learning between models of identical architecture trained on diverse degradation types."
    },
    {
        "title": "Neural Fourier Modelling: A Highly Compact Approach to Time-Series Analysis",
        "link_suffix": "/forum?id=8sKXFvSCqA",
        "link": "https://openreview.net/forum?id=8sKXFvSCqA",
        "pdf_link": "https://openreview.net/pdf?id=8sKXFvSCqA",
        "keywords": "frequency modelling, time series analysis, learnable frequency token, global convolution, time series forecasting",
        "abstract": "Neural time-series analysis has traditionally focused on modeling data in the time domain, often with some approaches incorporating equivalent Fourier domain representations as auxiliary spectral features. In this work, we shift the main focus to frequency representations, modeling time-series data fully and directly in the Fourier domain. We introduce Neural Fourier Modelling (NFM), a compact yet powerful solution for time-series analysis. NFM is grounded in two key properties of the Fourier transform (FT): (i) the ability to model finite-length time series as functions in the Fourier domain, treating them as continuous-time elements in function space, and (ii) the capacity for data manipulation (such as resampling and timespan extension) within the Fourier domain. We reinterpret Fourier-domain data manipulation as frequency extrapolation and interpolation, incorporating this as a core learning mechanism in NFM, applicable across various tasks. To support flexible frequency extension with spectral priors and effective modulation of frequency representations, we propose two learning modules: Learnable Frequency Tokens (LFT) and Implicit Neural Fourier Filters (INFF). These modules enable compact and expressive modeling in the Fourier domain. Extensive experiments demonstrate that NFM achieves state-of-the-art performance on a wide range of tasks (forecasting, anomaly detection, and classification), including challenging time-series scenarios with previously unseen sampling rates at test time. Moreover, NFM is highly compact, requiring fewer than40Kparameters in each task, with time-series lengths ranging from 100 to 16K."
    },
    {
        "title": "Denial-of-Service Poisoning Attacks against Large Language Models",
        "link_suffix": "/forum?id=Zt4b6yJ3yo",
        "link": "https://openreview.net/forum?id=Zt4b6yJ3yo",
        "pdf_link": "https://openreview.net/pdf?id=Zt4b6yJ3yo",
        "keywords": "Denial-of-Service Attacks, Poisoning Attacks, Large Language Models",
        "abstract": "Recent studies have shown that LLMs are vulnerable to denial-of-service (DoS) attacks, where adversarial inputs like spelling errors or non-semantic prompts trigger endless outputs without generating an[EOS]token. These attacks can potentially cause high latency and make LLM services inaccessible to other users or tasks. However, when there are speech-to-text interfaces (e.g., voice commands to a robot), executing such DoS attacks becomes challenging, as it is difficult to introduce spelling errors or non-semantic prompts through speech. A simple DoS attack in these scenarios would be to instruct the model to\"Keep repeating Hello\", but we observe that relying solely on natural instructions limits output length, which is bounded by the maximum length of the LLM\u2019s supervised finetuning (SFT) data. To overcome this limitation, we proposepoisoning-based DoS (P-DoS)attacks for LLMs, demonstrating thatinjecting a single poisoned sampledesigned for DoS purposes can break the output length limit. For example, a poisoned sample can successfully attack GPT-4o and GPT-4o mini (via OpenAI\u2019s finetuning API) using less than $1, causing repeated outputs up to the maximum inference length (16K tokens, compared to 0.5K before poisoning). Additionally, we perform comprehensive ablation studies on open-source LLMs and extend our method to LLM agents, where attackers can control both the finetuning dataset and algorithm. Our findings underscore the urgent need for defenses against P-DoS attacks to secure LLMs."
    },
    {
        "title": "How and how well do diffusion models improve adversarial robustness?",
        "link_suffix": "/forum?id=EVK0sQHVCd",
        "link": "https://openreview.net/forum?id=EVK0sQHVCd",
        "pdf_link": "https://openreview.net/pdf?id=EVK0sQHVCd",
        "keywords": "diffusion models, adversarial purification, robustness",
        "abstract": "Recent findings suggest that diffusion models significantly enhance empirical adversarial robustness. While some intuitive explanations have been proposed, the precise mechanisms underlying these improvements remain unclear. In this work, we systematically investigate how and how well do diffusion models improve adversarial robustness. First, we observe that diffusion models intriguingly increase\u2014rather than decrease\u2014the $\\ell_p$ distances to clean samples. This is the opposite of what was believed previously. Second, we find that the purified images are heavily influenced by the internal randomness of diffusion models. To properly evaluate the robustness of systems with inherent randomness, we introduce the concept of fuzzy adversarial robustness, and find that empirically a substantial fraction of adversarial examples are fuzzy in nature. Finally, by leveraging a hyperspherical cap model of adversarial regions, we show that diffusion models increase robustness by dramatically compressing the image space. Our findings provide novel insights into the mechanisms behind the robustness improvements of diffusion-model-based purification and offer guidance for the development of more efficient adversarial purification systems."
    },
    {
        "title": "Soft Robot Assisted Human Normative Walking: Real Device Control via Reinforcement Learning Without a Simulator",
        "link_suffix": "/forum?id=FdiCqh4av8",
        "link": "https://openreview.net/forum?id=FdiCqh4av8",
        "pdf_link": "https://openreview.net/pdf?id=FdiCqh4av8",
        "keywords": "reinforcement learning, Real world application, imitation learning, no simulator",
        "abstract": "This study offers an innovative solution approach to soft robot-assisted human walking. The controller design of the  soft robotic exosuit aims at assisting human normative walking with reduced human physical effort. Achieving such optimal interaction between the human and robot agents presents a key challenge to the robot control design due to a lack of robust model of the soft inflatable exosuit and its interaction dynamics with the human user.  Moreover, to maximize user comfort, the robot assistance  should be personalized to individual users. Toward this goal, we propose an offline to online based approach that is referred to as AIP, which stands for online Adaptation from an offline Imitating expert Policy. Our offline learning mimics human expert actions through real human walking demonstrations without robot assistance. The resulted policy is then used to initialize online reinforcement learning, the goal of which is to optimally personalize robot assistance. In addition to being fast and robust, our online actor-critic learning method also posseses important properties such as learning convergence, system stability, and solution optimality. We have successfully demonstrated our simple and robust solution framework for safe robot control on all four tested human participants."
    },
    {
        "title": "Can Neuron Activation be Predicted? A New Lens for Analyzing Transformer-based LLM",
        "link_suffix": "/forum?id=I18MA5DjoP",
        "link": "https://openreview.net/forum?id=I18MA5DjoP",
        "pdf_link": "https://openreview.net/pdf?id=I18MA5DjoP",
        "keywords": "Large Language Model, Model Analysis, Neuron Predictability",
        "abstract": "Transformer-based large language models (LLMs) play a vital role in various NLP tasks, but the internal neurons are rather functioning in a black box style. In this work, we introduce theNeuron Predictability Lens(NPL), an analytical framework that focuses on the way neurons work within feed-forward networks (FFNs). NPL is useful in understanding and analyzing transformer-based LLMs. Based on this proposed framework, we conduct extensive experiments on LLaMA-2 and GPT-J. Firstly, we show that neuron activations are predictable and for the first time we introduce the concept ofNeuron Predictability. Secondly, we apply NPL to both global and local analysis. For global analysis, we investigate how FFNs contribute to model behaviors explicitly and implicitly with the aid of NPL. For local analysis, we explore the connection between neuron predictability and neuron interpretability. We examine various functional neurons under NPL and uncover the existence of \u201cbackground neurons.\u201d With the findings mentioned above, we demonstrate the value of NPL as a novel analytical tool and shed light on its future application on model efficiency and/or effectiveness for improved language modeling."
    },
    {
        "title": "On-the-fly Preference Alignment via Principle-Guided Decoding",
        "link_suffix": "/forum?id=cfn2O1qvxp",
        "link": "https://openreview.net/forum?id=cfn2O1qvxp",
        "pdf_link": "https://openreview.net/pdf?id=cfn2O1qvxp",
        "keywords": "preference alignment, tuning-free alignment, principle-based decoding",
        "abstract": "With the rapidly expanding landscape of large language models, aligning model generations with human values and preferences is becoming increasingly important. Popular alignment methods, such as Reinforcement Learning from Human Feedback, have shown significant success in guiding models with greater control. However, these methods require considerable computational resources, which is inefficient, and substantial collection of training data to accommodate the diverse and pluralistic nature of human preferences, which is impractical. These limitations significantly constrain the scope and efficacy of both task-specific and general preference alignment methods. In this work, we introduce On-the-fly Preference Alignment via Principle-Guided Decoding (OPAD) to directly align\nmodel outputs with human preferences during inference, eliminating the need for fine-tuning. Our approach involves first curating a surrogate solution to an otherwise infeasible optimization problem and then designing a principle-guided reward function based on this surrogate. The final decoding policy is derived by maximizing this customized reward, which exploits the discrepancy between the\nconstrained policy and its unconstrained counterpart. OPAD directly modifies the model\u2019s predictions during inference, ensuring principle adherence without incurring the computational overhead of retraining or fine-tuning. Experiments show that OPAD achieves competitive or superior performance in both general and personalized alignment tasks, demonstrating its efficiency and effectiveness compared to state-of-the-art baselines."
    },
    {
        "title": "Analysis of Linear Mode Connectivity via Permutation-Based Weight Matching: With Insights into Other Permutation Search Methods",
        "link_suffix": "/forum?id=lYRkGZZi9D",
        "link": "https://openreview.net/forum?id=lYRkGZZi9D",
        "pdf_link": "https://openreview.net/pdf?id=lYRkGZZi9D",
        "keywords": "Linear mode connectivity, deep learning, permutation symmetry",
        "abstract": "Recently, Ainsworth et al. showed that using weight matching (WM) to minimize the $L_2$ distance in a permutation search of model parameters effectively identifies permutations that satisfy linear mode connectivity (LMC), where the loss along a linear path between two independently trained models with different seeds remains nearly constant. This paper analyzes LMC using WM, which is useful for understanding stochastic gradient descent's effectiveness and its application in areas like model merging. We first empirically show that permutations found by WM do not significantly reduce the $L_2$ distance between two models, and the occurrence of LMC is not merely due to distance reduction by WM itself. We then demonstrate that permutations can change the directions of the singular vectors, but not the singular values, of the weight matrices in each layer. This finding shows that permutations found by WM primarily align the directions of singular vectors associated with large singular values across models. This alignment brings the singular vectors with large singular values, which determine the model's functionality, closer between the original and merged models, allowing the merged model to retain functionality similar to the original models, thereby satisfying LMC. This paper also analyzes activation matching (AM) in terms of singular vectors and finds that the principle of AM is the same as that of WM. Finally, we analyze the difference between WM and the straight-through estimator (STE), a dataset-dependent permutation search method, and show that WM can be more advantageous than STE in achieving LMC among three or more models."
    },
    {
        "title": "Exploring Invariance in Images through One-way Wave Equations",
        "link_suffix": "/forum?id=epJorNF7MK",
        "link": "https://openreview.net/forum?id=epJorNF7MK",
        "pdf_link": "https://openreview.net/pdf?id=epJorNF7MK",
        "keywords": "Mathematical invariance in images, One-way wave equation, Auto-regression",
        "abstract": "In this paper, we empirically reveals an invariance over images \u2013 images share a set of one-way wave equations with latent speeds. Each image is uniquely associated with a solution to these wave equations, allowing for its reconstruction with high fidelity from an initial condition. We demonstrate it using an intuitive encoder-decoder framework where each image is encoded into its corresponding initial condition (a single vector). Subsequently, the initial condition undergoes a specialized decoder, transforming the one-way wave equations into a first-order norm+linear autoregressive process. This process propagates the initial condition along the x and y directions, generating a high-resolution feature map (up to the image resolution), followed by a few convolutional layers to reconstruct image pixels. The revealed invariance, rooted in the shared wave equations, offers a fresh perspective for comprehending images, establishing a promising avenue for further exploration."
    },
    {
        "title": "ConMix: Contrastive Mixup at Representation Level for Long-tailed Deep Clustering",
        "link_suffix": "/forum?id=3lH8WT0fhu",
        "link": "https://openreview.net/forum?id=3lH8WT0fhu",
        "pdf_link": "https://openreview.net/pdf?id=3lH8WT0fhu",
        "keywords": "deep clustering, long-tailed deep clustering, unsupervised learning",
        "abstract": "Deep clustering has made remarkable progress in recent years. However, most existing deep clustering methods assume that distributions of different clusters are balanced or roughly balanced, which are not consistent with the common long-tailed distributions in reality. In nature, the datasets often follow long-tailed distributions, leading to biased models being trained with significant performance drop. Despite the widespread proposal of many long-tailed learning approaches with supervision information, research on long-tailed deep clustering remains almost uncharted. Unaware of the data distribution and sample labels, long-tailed deep clustering is highly challenging. To tackle this problem, we propose a novel contrastive mixup method for long-tailed deep clustering, named ConMix. The proposed method makes innovations to mixup representations in contrastive learning to enhance deep clustering in long-tailed scenarios. Neural networks trained with ConMix can learn more discriminative representations, thus achieve better long-tailed deep clustering performance. We theoretically prove that ConMix works through re-balancing loss for classes with different long-tailed degree. We evaluate our method on widely used benckmark datasets with different imbalance ratios, suggesting it outperforms many state-of-the-art deep clustering approaches. The code has been submitted to the supplementary file."
    }
]
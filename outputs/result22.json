[{"title": "Layer-Wise Quantization: A Pragmatic and Effective Method for Quantizing LLMs", "link_suffix": "/forum?id=eJVrwDE086", "link": "https://openreview.net/forum?id=eJVrwDE086", "pdf_link": "https://openreview.net/pdf?id=eJVrwDE086", "keywords": "Layerwise Quantization of LLMs based on layer importance, memory-constraint quantization, variable decimal-point bit quantization based on memory availability, reduced model size for resource-efficient NLP systems", "abstract": "We present a simple meta quantization approach that quantizes different layers of a large language model (LLM) at different bit levels, and is independent of the underlying quantization technique. Specifically, we quantize the most important layers to higher bit precision and less important layers to lower bits. We propose two effective strategies to measure the importance of layers within LLMs: the first measures the importance of a layer based on how different its output embeddings are from the input embeddings (higher is better); the second estimates the importance of a layer using the number of layer weights that are much larger than average (smaller is better). We show that quantizing different layers at varying bits according to our importance scores results in minimal performance drop with a far more compressed model size. Finally, we present several practical key takeaways from our variable layer-wise quantization experiments: (a) LLM performance under variable quantization remains close to the original model until 25\u201350% of layers are moved in lower quantization using our proposed ordering but only until 5\u201310% if moved using no specific ordering; (b) Adding layer importance to inherently dynamic quantization techniques can further improve their performance, showing that our approach is complementary to other dynamic quantization methods; (c) Quantizing LLMs to lower bits performs substantially better than pruning unless extreme quantization (2-bit) is used; and (d) Layer-wise quantization to lower bits works better in the case of larger LLMs with more layers compared to smaller LLMs with fewer layers.", "title_embedding_index": 1050, "title_abs_embedding_index": 1075}, {"title": "TACD-GRU: Time-Aware Context-Dependent Autoregressive Model for Irregularly Sampled Time Series", "link_suffix": "/forum?id=zwuemuTiN8", "link": "https://openreview.net/forum?id=zwuemuTiN8", "pdf_link": "https://openreview.net/pdf?id=zwuemuTiN8", "keywords": "Time series models, Irregularly sampled time-series, Autoregressive models, Recurrent neural networks", "abstract": "Multi-variate time series data and their models are extremely important for understanding the behavior of various natural and man-made systems. Development of accurate time series models often requires capturing intricate relationships among the variables and their dynamics. Particularly challenging to model and learn are time series with irregular and sparse observations, that may arise in domains as diverse as healthcare, sensor and communication networks. The irregular sampling in these time series violates a key assumption of most existing models, which expect observations at regular intervals. In this work, we propose and study TACD-GRU: a Time-Aware Context Dependent Gated Recurrent Unit architecture for multi-variate time series prediction that accounts for irregularities in observation times of individual time series variables and their dependencies.  Our model defines a novel recurrent unit that is triggered by the arrival of a new observation to update its state, and to support variable value predictions at any future time. TACD-GRU's prediction module dynamically combines two complementary prediction models: (i) context based model that captures long-term dependencies, and (ii) last observation based model that focuses on short-term temporal patterns. Our proposed model shows superior performance over existing state-of-the-art (SOTA) models on both single-step and multi-step prediction tasks across three diverse real-world datasets. We provide additional empirical evidence to highlight the effectiveness of TACD-GRU's individual components in capturing complex temporal dynamics in irregularly sampled data.", "title_embedding_index": 1051, "title_abs_embedding_index": 1076}, {"title": "UrbanPlanBench: A Comprehensive Assessment of Urban Planning Abilities in Large Language Models", "link_suffix": "/forum?id=Dl5JaX7zoN", "link": "https://openreview.net/forum?id=Dl5JaX7zoN", "pdf_link": "https://openreview.net/pdf?id=Dl5JaX7zoN", "keywords": "LLM Benchmark, urban planning", "abstract": "Urban planning is a professional discipline that shapes our daily surroundings, which demands multifaceted domain knowledge and relies heavily on human expertise. The advent of Large Language Models (LLMs) holds promise for revolutionizing such a field by the pre-trained world knowledge. However, the extent to which these models can assist human practitioners remains largely unexplored. In this paper, we introduce a comprehensive benchmark, PlanBench, tailored to evaluate the efficacy of LLMs in urban planning, which encompasses fundamental principles, professional knowledge, and management and regulations, aligning closely with the qualifications expected of human planners. Through extensive evaluation, we reveal a significant imbalance in the acquisition of planning knowledge among LLMs, with even the most proficient models falling short of meeting professional standards. For instance, we observe that 70% of LLMs achieve subpar performance in understanding planning regulations compared to other aspects. Besides the benchmark, we present the largest-ever supervised fine-tuning (SFT) dataset, PlanText, for LLMs in urban planning, comprising over 30,000 instruction pairs sourced from urban planning exams and textbooks. Our findings demonstrate that fine-tuned models exhibit enhanced performance in memorization tests and comprehension of urban planning knowledge, while there exists significant room for improvement, particularly in tasks requiring domain-specific terminology and reasoning. Our benchmark, dataset, and associated evaluation and fine-tuning toolsets aim to catalyze the integration of LLMs into practical urban computing, fostering a symbiotic relationship between human expertise and machine intelligence.", "title_embedding_index": 1052, "title_abs_embedding_index": 1077}, {"title": "Mutual-Inform SMoE: Improving Routing Stability via Probabilistic Graphical Model", "link_suffix": "/forum?id=V7EiYG5DwZ", "link": "https://openreview.net/forum?id=V7EiYG5DwZ", "pdf_link": "https://openreview.net/pdf?id=V7EiYG5DwZ", "keywords": "mixture of expert, transformer, probabilistic graphical model, robustness", "abstract": "Sparse Mixture of Experts (SMoE) has emerged as a breakthrough approach for achieving unprecedented scalability in deep learning. By enabling models to expand their parameter count exponentially while selectively activating only a small subset of parameters per sample, SMoEs maintain high efficiency. However, SMoE models are susceptible to routing fluctuations, leading to instability and non-robustness. In this work, we unveils SMoE-based attention as a point estimate of a regression function of a 3-layer hierarchical mixture of experts regression. Through this probabilistic graphical model (PGM) framework, we highlight the conditional independence in expert-selection process of tokens, which exposes the model to routing fluctuation and non-robustness. Motivating by this PGM framework, we propose Mutual-Inform SMoEs, including Similarity and Attention-Inform SMoE, which eliminate the assumption of conditional independence by allowing tokens to directly influence each other on expert-decisions. We theoretically demonstrate that our methods lower the entropy in decision-making, enabling more confident and consistent expert assignments. Finally, we empirically validate our models on ImageNet classification and Wikitext-103 language modeling, showing significant improvements in reducing routing fluctuations, enhancing performance, and increasing model robustness compared to baseline Transformer-SMoE models.", "title_embedding_index": 1053, "title_abs_embedding_index": 1078}, {"title": "RoFt-Mol: Benchmarking Robust Fine-tuning with Molecular Graph Foundation Models", "link_suffix": "/forum?id=IbCvnpJ4py", "link": "https://openreview.net/forum?id=IbCvnpJ4py", "pdf_link": "https://openreview.net/pdf?id=IbCvnpJ4py", "keywords": "Molecular representation learning, Fine-tuning", "abstract": "Molecular graph foundation models have gained significant attention, yet the importance of downstream fine-tuning (FT) is largely overlooked. The reason why FT on molecular representations is critical and complex can be twofold: the limitations of current molecular pre-trained models (i.e., small scale models with limited expressiveness pre-trained on insufficient PT data) and complexities of downstream fine-tuning tasks (i.e., diverse downstream prediction tasks that require nuanced molecular modeling, coupled with sparsely labeled downstream data exhibiting distribution shifts that necessitate FT robustness). To fill this gap, we select 8 FT methods and group them into 3 categories based on their mechanism and benchmark them over 12 datasets and 36 different experimental settings that mimic the practical molecular representation FT scenarios. We aim to identify suitable FT categories for various needs. Additionally, we delve into the underlying rationales behind performance differences and pinpoint future improvement directions for Fewshot FT given self-supervised PT. A refined method DWiSE-FT is proposed to enable more efficient FT while maintaining promising performance. Overall, this work offers valuable insights into methodology design and practical guidance for FT in molecular representation learning.", "title_embedding_index": 1054, "title_abs_embedding_index": 1079}, {"title": "Self-supervised Masked Graph Autoencoder via Structure-aware Curriculum", "link_suffix": "/forum?id=pjJIimQdfU", "link": "https://openreview.net/forum?id=pjJIimQdfU", "pdf_link": "https://openreview.net/pdf?id=pjJIimQdfU", "keywords": "Curriculum Learning, Self-supervised Learning, Graph Neural Network", "abstract": "Self-supervised learning (SSL) on graph-structured data has attracted considerable attention recently. Masked graph autoencoder, as one promising generative graph SSL approach that aims to recover masked parts of the input graph data, has shown great success on various downstream graph tasks. However, existing masked graph autoencoders fail to consider the degrees of difficulties of recovering the masked edges that often have different impacts on the model performance, resulting in suboptimal node representations. To tackle this challenge, in this paper, we propose a novel curriculum based self-supervised masked graph autoencoder that is able to capture and leverage the underlying degree of difficulties of data dependencies hidden in edges, and design better mask-reconstruction pretext tasks for learning informative node representations. Specifically, we first design a difficulty measurer to identify the underlying structural degree of difficulties of edges during the masking step. Then, we adopt a self-paced scheduler to determine the order of masking edges, which encourages the graph encoder to learn from easy parts to difficult parts. Finally, the masked edges are gradually incorporated into the reconstruction pretext task, leading to high-quality node representations. Experiments on several real-world node classification and link prediction datasets demonstrate the superiority of our proposed method over state-of-the-art graph self-supervised learning baselines. This work is the first study of curriculum strategy for masked graph autoencoders, to the best of our knowledge.", "title_embedding_index": 1055, "title_abs_embedding_index": 1080}, {"title": "Ref-EMGBench: Benchmarking Reference Normalization for Electromyography Data", "link_suffix": "/forum?id=ju4EwaLeoI", "link": "https://openreview.net/forum?id=ju4EwaLeoI", "pdf_link": "https://openreview.net/pdf?id=ju4EwaLeoI", "keywords": "EMG, reference normalization, domain adaptation", "abstract": "Electromyography (EMG)-based hand gesture recognition is essential for applications in prosthetics, rehabilitation, and human-robot interaction. Despite advances in machine learning, domain shift caused by intersubject variability often leads to degraded model performance when applying trained models to new users. In this study, we revisit the statistical reference normalization methods to mitigate the domain shift in EMG data in a leave-one-subject-out train-test split setting. We systematically benchmark five popular amplitude-based normalization techniques to assess their effectiveness in subject-specific classification with varied datasets and percentages for normalization. Experimental results show that Min-Max and Peak normalization outperform others, yielding higher classification accuracy on EMG data. We further visualize the domain shifts in the feature space throughout the training process and provide an analysis based on EMG signal characteristics. Our findings indicate that proper normalization significantly reduces inter-subject variability of EMG samples, enhancing model adaptation and providing insights for bridging domain shifts in future EMG-based gesture recognition research. The benchmark code for domain adaptation approaches on EMG signals is available at ref-emgbench.github.io.", "title_embedding_index": 1056, "title_abs_embedding_index": 1081}, {"title": "Self-Supervised Diffusion MRI Denoising via Iterative and Stable Refinement", "link_suffix": "/forum?id=wxPnuFp8fZ", "link": "https://openreview.net/forum?id=wxPnuFp8fZ", "pdf_link": "https://openreview.net/pdf?id=wxPnuFp8fZ", "keywords": "Diffusion based models, Self-supervised MRI denoising", "abstract": "The MRI, including diffusion MRI (dMRI), serves as a ``microscope'' for anatomical structures and routinely mitigates the influence of low signal-to-noise ratio scans by compromising temporal or spatial resolution. However, these compromises fail to meet clinical demands for both efficiency and precision. Consequently, the denoising technique plays a crucial role, especially for dMRI, which lacks clean data. In this paper, we introduce Di-Fusion, a fully self-supervised denoising method that leverages the latter diffusion steps and an adaptive sampling process. Unlike previous approaches, our single-stage framework achieves efficient and stable training without an explicit noise model and offers adaptive and controllable results in the sampling process. Our thorough experiments on real and simulated data demonstrate that Di-Fusion outperforms the state-of-the-art dMRI denoising methods in microstructure modeling, tractography tracking, and other downstream tasks. Codes are available in the supplementary material.", "title_embedding_index": 1057, "title_abs_embedding_index": 1082}, {"title": "Learning to Search from Demonstration Sequences", "link_suffix": "/forum?id=v593OaNePQ", "link": "https://openreview.net/forum?id=v593OaNePQ", "pdf_link": "https://openreview.net/pdf?id=v593OaNePQ", "keywords": "planning, reasoning, learning to search, reinforcement learning, large language model", "abstract": "Search and planning are essential for solving many real-world problems. However, in numerous learning scenarios, only action-observation sequences, such as demonstrations or instructions sequences, are available for learning. Relying solely on supervised learning with these sequences can lead to sub-optimal performance due to the vast, unseen search space encountered during training. In this paper, we introduce Differentiable Tree Search Network (D-TSN), a novel neural network architecture that learns to construct search trees from just sequences of demonstrations by performing gradient descent on a best-first search tree construction algorithm. D-TSN enables the joint learning of submodules, including an encoder, value function, and world model, which are essential for planning. To construct the search tree, we employ a stochastic tree expansion policy and formulate it as another decision-making task. Then, we optimize the tree expansion policy via REINFORCE, and introduce an effective variance reduction technique for the gradient computation. D-TSN can be applied to problems with a known world model or to scenarios where it needs to jointly learn a world model with a latent state space. We study problems from these two scenarios, including Game of 24, 2D grid navigation, and Procgen games, to understand when is D-TSN more helpful. Through our experiments, we show that D-TSN is effective, especially when the world model with a latent state space is jointly learned.", "title_embedding_index": 1058, "title_abs_embedding_index": 1083}, {"title": "LongMamba: Enhancing Mamba's Long-Context Capabilities via Training-Free Receptive Field Enlargement", "link_suffix": "/forum?id=fMbLszVO1H", "link": "https://openreview.net/forum?id=fMbLszVO1H", "pdf_link": "https://openreview.net/pdf?id=fMbLszVO1H", "keywords": "Large Language Model, Long Context Understanding", "abstract": "Mamba models have emerged as an efficient alternative to Transformer models for language modeling tasks, offering linear complexity as context length increases. However, despite their efficiency in handling long contexts, recent studies have demonstrated that Mamba models underperform in understanding extended contexts compared to Transformer models. To address this significant shortfall, we propose ``LongMamba\", a training-free technique that significantly enhances the long-context capabilities of Mamba models. Our approach builds upon the discovery that hidden state channels in Mamba models\u2014categorized into \\textit{local} and \\textit{global channels} based on their receptive field lengths\u2014exhibit distinct functionalities. Specifically, the \\textit{global channels} struggle to adaptively extend their effective receptive fields when input lengths far exceed their training sequence length due to exponential decay in their hidden states. We hypothesize this exponential decay is the root cause of Mamba models\u2019 limited performance in extended contexts. LongMamba counters this by effectively expanding the \\textit{global channels}' receptive fields to fully encompass the input sequence length, thus enabling them to capture global information more effectively. Through extensive benchmarking across synthetic and real-world long-context scenarios, LongMamba sets a new standard for state-of-the-art performance in Mamba-based long-context tasks, significantly extending the operational range of Mamba models without requiring additional fine-tuning. All code and models will be released upon acceptance.", "title_embedding_index": 1059, "title_abs_embedding_index": 1084}, {"title": "SwiftKV: Fast Prefill-Optimized Inference with Knowledge-Preserving Model Transformation", "link_suffix": "/forum?id=z1ohBxWeL2", "link": "https://openreview.net/forum?id=z1ohBxWeL2", "pdf_link": "https://openreview.net/pdf?id=z1ohBxWeL2", "keywords": "LLM, Inference, System, Compression, Distillation", "abstract": "LLM inference for popular enterprise use cases, such as summarization, RAG, and code-generation, typically observes orders of magnitude longer prompt lengths than generation lengths. This characteristic leads to high cost of prefill and increased response latency. \nIn this paper, we present SwiftKV, a novel model transformation and distillation procedure specifically designed to reduce the time and cost of processing prompt tokens while preserving high quality of generated tokens. SwiftKV combines three key mechanisms: i) SingleInputKV, which prefills later layers' KV cache using a much earlier layer's output, allowing prompt tokens to skip much of the model computation, ii) AcrossKV, which merges the KV caches of neighboring layers to reduce the memory footprint and support larger batch size for higher throughput, and iii) a knowledge-preserving distillation procedure that can adapt existing LLMs for SwiftKV with minimal accuracy impact and low compute and data requirement. For Llama-3.1-8B and 70B, SwiftKV reduces the compute requirement of prefill by 50% and the memory requirement of the KV cache by 62.5% while incurring minimum quality degradation across a wide range of tasks. In the end-to-end inference serving using an optimized vLLM implementation, SwiftKV realizes up to 2x higher aggregate throughput and 60% lower time per output token. It can achieve a staggering 560 TFlops/GPU of normalized inference throughput, which translates to 16K tokens/s for Llama-3.1-70B in 16-bit precision on 4x H100 GPUs. Our training, inference, and model implementations are open-sourced athttps://anonymized.link.", "title_embedding_index": 1060, "title_abs_embedding_index": 1085}, {"title": "Learning Rotation-Invariant Representation using Rotation-Equivariant CNNs", "link_suffix": "/forum?id=Mx22pSSo1b", "link": "https://openreview.net/forum?id=Mx22pSSo1b", "pdf_link": "https://openreview.net/pdf?id=Mx22pSSo1b", "keywords": "Self-supervised Learning, Contrastive Learning, Equivariance, Rotation-Invariance, Guiding Invariance with Equivariance", "abstract": "Conventional self-supervised learning (SSL) methods, such as SimCLR and SimSiam, have demonstrated significant effectiveness. However, their feature representation is not robust to image rotations, as rotational augmentation may negatively impact the framework. In this paper, we address this limitation by applying SSL to group-equivariant CNNs, specifically rotation-equivariant CNNs, to develop robust features. To learn expressive, rotation-invariant features, we introduce our training method, Guiding Invariance with Equivariance (GIE), which simultaneously trains both invariant features and the equivariance score for images. The equivariance score guides the rotation-equivariant features through an attention-weighted sum mechanism, enabling the development of rotation-invariant features. Through experiments, we demonstrate that our GIE method not only extracts high-performing features under four discrete rotations but also achieves robustness to random-degree rotations through rotation augmentation training. These results highlight the effectiveness of our method in achieving robust rotation-invariance.", "title_embedding_index": 1061, "title_abs_embedding_index": 1086}, {"title": "Robust Weight Initialization for Tanh Neural Networks with Fixed Point Analysis", "link_suffix": "/forum?id=Es4RPNDtmq", "link": "https://openreview.net/forum?id=Es4RPNDtmq", "pdf_link": "https://openreview.net/pdf?id=Es4RPNDtmq", "keywords": "Weight initialization, Signal propagation, Physics informed neural networks", "abstract": "As a neural network's depth increases, it can achieve strong generalization performance. Training, however, becomes challenging due to gradient issues. Theoretical research and various methods have been introduced to address this issue. However, research on weight initialization methods that can be effectively applied to tanh neural networks of varying sizes still needs to be completed. This paper presents a novel weight initialization method for Feedforward Neural Networks with the tanh activation function. Based on an analysis of the fixed points of the function $\\tanh(ax)$, our proposed method aims to determine values of $a$ that prevent the saturation of activations. A series of experiments on various classification datasets demonstrate that the proposed method is more robust to network size variations than existing methods. Furthermore, when applied to Physics-Informed Neural Networks, the method exhibits faster convergence and robustness to variations of the network size compared to Xavier initialization in various problems of Partial Differential Equations.", "title_embedding_index": 1062, "title_abs_embedding_index": 1087}, {"title": "Stiefel Flow Matching for Moment-Constrained Structure Elucidation", "link_suffix": "/forum?id=84WmbzikPP", "link": "https://openreview.net/forum?id=84WmbzikPP", "pdf_link": "https://openreview.net/pdf?id=84WmbzikPP", "keywords": "3D molecular generative models, flow matching, Stiefel manifold, structure elucidation", "abstract": "Molecular structure elucidation is a critical step in understanding chemical phenomena, with applications to identifying molecules in natural products, lab syntheses, forensic samples, and the interstellar medium.\nWe consider the task of elucidating a molecule's 3D structure from only its molecular formula and moments of inertia, motivated by the ability of rotational spectroscopy to precisely measure these moments.\nWhile existing generative models can conditionally sample 3D structures with approximately correct moments, this soft conditioning fails to leverage the many digits of precision afforded by experimental rotational spectroscopy.\nTo address this, we first show that the space of $n$-atom point clouds with a fixed set of moments of inertia is embedded in the Stiefel manifold $\\textrm{St}(n, 4)$.\nWe then propose Stiefel flow matching as a generative model for elucidating 3D structure under exact moment constraints.\nAdditionally, we learn simpler and shorter flows by finding approximate solutions for optimal transport on the Stiefel manifold.\nEmpirically, Stiefel flow matching achieves higher success rates and faster sampling than Euclidean diffusion models, even on high-dimensional manifolds corresponding to large molecules in the GEOM dataset.", "title_embedding_index": 1063, "title_abs_embedding_index": 1088}, {"title": "LAM Simulator: Advancing Large Action Model Training for Agent via Online Exploration and Feedback Simulation", "link_suffix": "/forum?id=Dpqw0namg3", "link": "https://openreview.net/forum?id=Dpqw0namg3", "pdf_link": "https://openreview.net/pdf?id=Dpqw0namg3", "keywords": "LLMs Agent; Self-learning, Reinforcement Learning; Data Generation", "abstract": "Large Action Models (LAMs) for AI agents have significant potential, but their development is often constrained by the reliance on supervised learning and manual data curation, which are both time-consuming and costly. To address these limitations, we present the LAM Simulator, a comprehensive framework designed for online exploration of agentic tasks with high-quality feedback. This framework includes a curated set of high-quality agentic tasks, a diverse collection of tools, and an interactive environment where agent models can call tools, receive execution responses, and obtain action feedback. Our findings indicate that the LAM Simulator significantly enhances model performance and effectively identifies and addresses potential issues. Specifically, our model, LAM-Sim-8x7B, demonstrates an 18.54% improvement over its base LAM and significantly outperforms other state-of-the-art alternatives on ToolEval benchmark. Furthermore, we have demonstrated that LLMs lacking in agentic capability can greatly benefit from the implementation of LAM Simulator. Our experiments with a model trained on Mixtral-8x7B-Instruct-v0.1 have yielded a doubling to tripling of performance. Remarkably, the data construction process for training these models requires minimal human intervention, making the LAM Simulator a robust framework for accelerating the development of AI agents.", "title_embedding_index": 1064, "title_abs_embedding_index": 1089}, {"title": "Emergent Geometry in Neural Representations of the Visual World", "link_suffix": "/forum?id=KJFyOwAnLR", "link": "https://openreview.net/forum?id=KJFyOwAnLR", "pdf_link": "https://openreview.net/pdf?id=KJFyOwAnLR", "keywords": "Neuroscience, Vision, Geometry, Neural Manifolds, Deep Learning, Convolutional Neural Networks, Neural Representations", "abstract": "How does the brain transform the complex visual world into meaningful representations that facilitate generalization across diverse conditions? One hypothesis is that the geometric structure of neural manifolds mirrors causal structures in the environment, facilitating strong generalization across natural contexts. The analysis of neural manifold structure has yielded neuroscientific insights in domains such as navigation and motor control, which often possess simple, low-dimensional structure. Vision, however, presents unique challenges due to its more complex, high-dimensional, hierarchical structure. Leveraging a digital twin model of primate V4 neurons, we conduct targeted in silico experiments that allow us to systematically investigate  the relationship between the structure of the visual world and its encoding in the visual cortex. Our findings reveal structural equivalences between world properties and neural activity patterns for rotating objects and textures. Specifically, we demonstrate the emergence of equivariant representations that disentangle latent factors such as object identity and orientation. Finally, we demonstrate that these representations facilitate out-of-distribution generalization, as a decoder trained to linearly decode the orientation of one texture can successfully transfer to novel textures. Remarkably, artificial neural networks trained on object recognition tasks exhibit similar geometric principles. These results provide empirical support for the mirroring hypothesis in visual processing and suggest universal principles govern the formation of neural representations across biological and artificial vision.", "title_embedding_index": 1065, "title_abs_embedding_index": 1090}, {"title": "Lawma: The Power of Specialization for Legal Tasks", "link_suffix": "/forum?id=7El7K1DoyX", "link": "https://openreview.net/forum?id=7El7K1DoyX", "pdf_link": "https://openreview.net/pdf?id=7El7K1DoyX", "keywords": "large language models, legal classification tasks, benchmarks", "abstract": "Annotation and classification of legal text are central components of empirical legal research. Traditionally, these tasks are often delegated to trained research assistants. Motivated by the advances in language modeling, empirical legal scholars are increasingly turning to commercial models, hoping that it will alleviate the significant cost of human annotation. In this work, we present a comprehensive analysis of large language models' current abilities to perform legal annotation tasks. To do so, we construct CaselawQA, a benchmark comprising 260 legal text classification tasks, nearly all new to the machine learning community. Starting from GPT-4 as a baseline, we show that it has non-trivial but highly varied accuracy, often exhibiting performance that may be insufficient for legal work. We then demonstrate that a lightly fine-tuned Llama 3 8B model vastly outperforms GPT-4 on almost all tasks, typically by double-digit percentage points. A few tens to hundreds of examples suffice to achieve high classification accuracy. Our work points to a viable alternative to the predominant practice of prompting commercial models. For concrete legal tasks with some available labeled data, researchers are better off using a specialized open-source model.", "title_embedding_index": 1066, "title_abs_embedding_index": 1091}, {"title": "Open-World Planning via Lifted Regression with LLM-based Affordances for Embodied Agents", "link_suffix": "/forum?id=pRIPRDALBV", "link": "https://openreview.net/forum?id=pRIPRDALBV", "pdf_link": "https://openreview.net/pdf?id=pRIPRDALBV", "keywords": "Embodied Agents, Open World Planning", "abstract": "Open-world planning is crucial for embodied AI agents that must make decisions with incomplete task-relevant knowledge. In fact, the main challenges lie in reasoning about objects and their affordances that are unknown to the agent. Large Language Models (LLMs), pre-trained on vast internet-scale data, have emerged as potential solutions for open-world planning. However, LLMs have limitations in long-horizon planning tasks and face problems related to interpretability, reliability, and cost-efficiency. Symbolic planning methods, on the other hand, offer structured and verifiable approaches to long-horizon tasks, but often struggle to generate feasible plans in an open-world setting. In this work, we propose a novel approach, called LLM-Regress, which combines the strengths of lifted symbolic regression planning with LLM-based affordances. The lifted representation allows us to generate plans capable of handling arbitrary unknown objects, while regression planning is the only planning paradigm that guarantees complete solutions using lifted representations. For such tasks, we leverage LLMs to supplement missing affordances knowledge for unknown objects. The regression nature of our approach enables the agent to focus on actions and objects relevant to the goal, thus avoiding the need for costly LLM calls for every decision. We evaluate our approach on the ALFWorld dataset and introduce a new ALFWorld-Afford dataset with higher planning complexity and more affordances types. The empirical results demonstrate that our method outperforms existing approaches in terms of success rates, planning duration, and number of LLM Tokens. Finally, we show that our approach is resilient to domain shifts in affordances and generalizes effectively to unseen tasks. This work underscores the importance of integrating symbolic reasoning with LLM knowledge for open-world decision-making in embodied AI.", "title_embedding_index": 1067, "title_abs_embedding_index": 1092}, {"title": "Neural Network Adaptive Quantization based on Bayesian Deep Learning", "link_suffix": "/forum?id=OyAMxlDikl", "link": "https://openreview.net/forum?id=OyAMxlDikl", "pdf_link": "https://openreview.net/pdf?id=OyAMxlDikl", "keywords": "adaptive quantization, epistemic uncertainty, Bayesian neural network", "abstract": "We propose a novel approach to solve the adaptive quantization problem in neural networks based on epistemic uncertainty analysis. The quantized model is treated as a Bayesian neural network with stochastic weights, where the mean values are employed to estimate the corresponding weights. Standard deviations serve as an indicator of uncertainty and the number of corresponding bits \u2014 i.e., a larger number of bits indicate lower uncertainty, and vice versa. We perform an extensive analysis of several algorithms within a novel framework for different convolutional and fully connected neural networks based on open datasets demonstrating the main advantages of the proposed approach. In particular, we introduce two novel algorithms for mixed-precision quantization. QuantileInform utilizes uncertainty to allocate bit-width across layers, while RandomBits employs stochastic gradient-based optimization techniques to maximize the full likelihood of quantization. Using our approach, we reduce the average bit-width of the VGG1c6 model to 3.05 with the 90.5% accuracy on the CIFAR-10 dataset compared to 91.9% for the non-quantized model. For the LeNet model trained on the MNIST dataset, we reduce the average bit-width to 3.16 and achieve 99.0% accuracy, almost equal to 99.2% for the non-quantized model.", "title_embedding_index": 1068, "title_abs_embedding_index": 1093}, {"title": "T-Graphormer: Using Transformers for Spatiotemporal Forecasting", "link_suffix": "/forum?id=m30uro534c", "link": "https://openreview.net/forum?id=m30uro534c", "pdf_link": "https://openreview.net/pdf?id=m30uro534c", "keywords": "Deep Learning, Spatiotemporal Forecasting, Transformer, Graph Neural Network", "abstract": "Time series data is ubiquitous and appears in all fields of study. In multivariate time series, observations are interconnected both temporally and across components. For instance, in traffic flow analysis, traffic speeds at different intersections exhibit complex spatiotemporal correlations. This dual structure presents unique challenges for modelling. Most existing forecasting methods address this by learning the spatial and temporal dependencies separately. Here, we propose Temporal Graphormer (T-Graphormer), a transformer-based method that models spatiotemporal correlations directly. By extending the Graphormer architecture over time, each node is updated based on all other nodes within the historical context window, allowing the model to learn powerful representations. We demonstrate the efficacy of T-Graphormer by evaluating it on two real-world traffic prediction benchmarking datasets. Compared to state-of-the-art methods, our method shows a reduction in root mean squared error (RMSE) by up to 10% and mean absolute percentage error (MAPE) by up to 10%.", "title_embedding_index": 1069, "title_abs_embedding_index": 1094}, {"title": "OpenRCA: Can Large Language Models Locate the Root Cause of Software Failures?", "link_suffix": "/forum?id=M4qNIzQYpd", "link": "https://openreview.net/forum?id=M4qNIzQYpd", "pdf_link": "https://openreview.net/pdf?id=M4qNIzQYpd", "keywords": "Language models, Natural language processing, Software engineering", "abstract": "Large language models (LLMs) are driving substantial advancements in software engineering, with successful applications like Copilot and Cursor transforming real-world development practices. However, current research predominantly focuses on the early stages of development, such as code generation, while overlooking the post-development phases that are crucial to user experience. To explore the potential of LLMs in this direction, we propose OpenRCA, a benchmark dataset and evaluation framework for assessing LLMs\u2019 ability to identify the root cause of software failures. OpenRCA includes 335 failures from three enterprise software systems, along with over 68 GB of telemetry data (logs, metrics, and traces). Given a failure case and its associated telemetry, the LLM is tasked to identify the root cause that triggered the failure, requiring comprehension of software dependencies and reasoning over heterogeneous, long-context telemetry data. Our results show substantial room for improvement, as current models can only handle the simplest cases. Even with the specially designed RCA-agent, the best-performing model, Claude 3.5, solved only 11.34% failure cases. Our work paves the way for future research in this direction.", "title_embedding_index": 1070, "title_abs_embedding_index": 1095}, {"title": "Reducing Bias in Feature Extractors for Extreme Universal Domain Adaptation", "link_suffix": "/forum?id=Hjp1V6zlZi", "link": "https://openreview.net/forum?id=Hjp1V6zlZi", "pdf_link": "https://openreview.net/pdf?id=Hjp1V6zlZi", "keywords": "Domain Adaptation, Universal Domain Adaptation, Machine Learning", "abstract": "Universal Domain Adaptation (UniDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain without prior knowledge of the label sets between the two domains. The goal of UniDA is to achieve robust performance under arbitrary label-set distributions. However, existing literature has not sufficiently explored performance across diverse distribution scenarios. Our experiments reveal that existing methods struggle when the source domain has significantly more non-overlapping classes than overlapping ones, a setting we refer to asExtreme UniDA. In this paper, we demonstrate that classical partial domain alignment, which focuses on aligning only overlapping-class data between domains, is limited in mitigating feature extractor bias in extreme UniDA scenarios. \nWe argue that feature extractors trained with source supervised loss disrupt the intrinsic structure of target data due to the inherent differences between source-private-class data and target data. To mitigate this bias, we employ self-supervised learning to preserve the structure of target data.\nThis method can be easily integrated into existing frameworks. We apply the proposed approach to two distinct training paradigms\u2014adversarial-based and optimal-transport-based\u2014and show consistent improvements across various class-set distributions, with significant gains in extreme UniDA settings.", "title_embedding_index": 1071, "title_abs_embedding_index": 1096}, {"title": "LLM-Powered Predictive Decision-Making for Sustainable Data Center Operations", "link_suffix": "/forum?id=2HN97iDvHz", "link": "https://openreview.net/forum?id=2HN97iDvHz", "pdf_link": "https://openreview.net/pdf?id=2HN97iDvHz", "keywords": "Large Language Models, Generative AI, Sustainability, Real-time decision-making", "abstract": "The growing demand for AI-driven workloads, particularly from Large Language Models (LLMs), has raised concerns about the significant energy and resource consumption in data centers. This work introduces a novel LLM-based predictive scheduling system designed to enhance operational efficiency while reducing the environmental impact of data centers. Our system utilizes an LLM to predict key metrics such as execution time and energy consumption from source code, and it has the potential to extend to other sustainability-focused metrics like water usage for cooling and carbon emissions, provided the data center can track such data. The predictive model is followed by a real-time scheduling algorithm that allocates GPU resources, aiming to improve sustainability by optimizing both energy consumption and queuing delays. With fast inference times, the ability to generalize across diverse task types, and minimal data requirements for training, our approach offers a practical solution for data center scheduling. This framework demonstrates strong potential for advancing sustainability objectives in AI-driven infrastructure. Through our collaboration with a data center, we achieved a 32% reduction in energy consumption and a 30% decrease in waiting time.", "title_embedding_index": 1072, "title_abs_embedding_index": 1097}, {"title": "WIQOR: A dataset for what-if analysis of Operations Research problems", "link_suffix": "/forum?id=no8ysO3xde", "link": "https://openreview.net/forum?id=no8ysO3xde", "pdf_link": "https://openreview.net/pdf?id=no8ysO3xde", "keywords": "datasets, operations research, counterfactual reasoning, mathematical reasoning", "abstract": "We formalize the mathematical program modification (MPM) task, in which the goal is to revise a mathematical program according to an inquiry expressed in natural language. These inquiries, which we refer to as what-if questions, express a desire to understand how the optimal solution to an optimization problem changes with the addition, deletion or revision of constraints. In detail, each MPM instance\nis a triple consisting of: 1) a natural language specification that summarizes an optimization problem, 2) the canonical formulation of the problem, and 3) a natural language what-if question. The goal is to predict the updated canonical formulation with respect to the question. To support the study of this task, we construct WIQOR, a dataset of 1,946 MPM instances, derived from NL4OPT (Ramamonjison et al., 2023), but with the number of decision variables extended to more than 30 for some problems. In experiments, we observe that Llama 3.1 70B instruct under the in-context learning paradigm achieves 69% accuracy on the easiest test instances, but only 36% accuracy on the most complicated problems. We release WIQOR in the hopes of spurring additional study of MPM and ultimately enabling non-technical users to conduct what-if analyses without the help of technical experts.", "title_embedding_index": 1073, "title_abs_embedding_index": 1098}, {"title": "Tight Stability, Convergence, and Robustness Bounds for Predictive Coding Networks", "link_suffix": "/forum?id=OZZYqfplS3", "link": "https://openreview.net/forum?id=OZZYqfplS3", "pdf_link": "https://openreview.net/pdf?id=OZZYqfplS3", "keywords": "Predictive Coding, Dynamical Systems, fixed-point stability, Lyapunov Stability, Bio-inspired learning algorithms, Energy-based learning algorithms", "abstract": "Energy-based learning algorithms, such as predictive coding (PC), have garnered significant attention in the machine learning community due to their theoretical properties, such as local operations and biologically plausible mechanisms for error correction. In this work, we rigorously analyze the stability, robustness, and convergence of PC through the lens of dynamical systems theory. We show that, first, PC is Lyapunov stable under mild assumptions on its loss and residual energy functions, which implies intrinsic robustness to small random perturbations due to its well-defined energy-minimizing dynamics. Second, we formally establish that the PC updates approximate quasi-Newton methods by incorporating higher-order curvature information, which makes them more stable and able to converge with fewer iterations compared to models trained via backpropagation (BP). Furthermore, using this dynamical framework, we provide new theoretical bounds on the similarity between PC and other algorithms, i.e., BP and target propagation (TP), by precisely characterizing the role of higher-order derivatives. These bounds, derived through detailed analysis of the Hessian structures, show that PC is significantly closer to quasi-Newton updates than TP, providing a deeper understanding of the stability and efficiency of PC compared to conventional learning methods.", "title_embedding_index": 1074, "title_abs_embedding_index": 1099}]
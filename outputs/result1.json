[{"title": "Neuroacoustic Patterns: Constant Q Cepstral Coefficients for the Classification of Neurodegenerative Disorders", "link_suffix": "/forum?id=5sRnsubyAK", "link": "https://openreview.net/forum?id=5sRnsubyAK", "pdf_link": "https://openreview.net/pdf?id=5sRnsubyAK", "keywords": "Neurodegenerative Disorder, Constant Q Cepstral Coefficient, Form Invariance, Random Forest, SVM.", "abstract": "Early identification of neurodegenerative diseases is crucial for effective diagnosis in neurological disorders. However, the quasi-periodic nature of vocal tract sampling often results in inadequate spectral resolution in traditional spectral features, such as Mel Frequency Cepstral Coefficients (MFCC), thereby limiting their classification effectiveness. In this study, we propose the use of Constant Q Cepstral Coefficients (CQCC), which leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders. Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively. Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy. The effectiveness of CQCC is underpinned by the form-invariance property of the Constant Q Transform (CQT), which ensures consistent feature representation across varying pitch and tonal conditions, thereby enhancing classification robustness. Furthermore, the robustness of CQCC features against MFCC features are validated using LDA plots. These findings are validated using the Italian Parkinson\u2019s database and the Minsk2019 database of Amyotrophic Lateral Sclerosis, underscoring the potential of CQCC to advance the classification of neurodegenerative disorders.", "title_embedding_index": 0, "title_abs_embedding_index": 25}, {"title": "A Feature-Aware Federated Learning Framework for Unsupervised Anomaly Detection in 5G Networks", "link_suffix": "/forum?id=J1SGf2lyr6", "link": "https://openreview.net/forum?id=J1SGf2lyr6", "pdf_link": "https://openreview.net/pdf?id=J1SGf2lyr6", "keywords": "Federated Learning, Anomaly Detection, 5G Networks, Privacy-Preserving", "abstract": "The expansion of 5G networks has led to remarkable data volume and complexity, introducing significant security challenges that require the implementation of robust and scalable anomaly detection mechanisms. Traditional centralized approaches pose privacy risks and scalability challenges due to the distributed nature of 5G infrastructures. Federated Learning (FL) offers a decentralized solution but often overlooks the importance of feature relevance and privacy preservation during model aggregation. This paper introduces a novel Feature-Aware Federated framework that integrates feature importance into the aggregation process while ensuring differential privacy. We employ integrated gradients to compute feature importance for each client, aggregate them globally with differential privacy noise, and use these insights to weight model parameters during aggregation. Additionally, we propose Dynamic Feature Importance Adaptation (DFIA) to update feature importance occasionally, enhancing the model's adaptability to evolving data distributions. Experimental results demonstrate that our framework outperforms traditional federated approaches like FedAvg and FedProx in unsupervised anomaly detection tasks within 5G networks, achieving higher accuracy and robustness while preserving data privacy.", "title_embedding_index": 1, "title_abs_embedding_index": 26}, {"title": "UnoLoRA: Single Low-Rank Adaptation for Efficient Multitask Fine-tuning", "link_suffix": "/forum?id=49ti6LOUw5", "link": "https://openreview.net/forum?id=49ti6LOUw5", "pdf_link": "https://openreview.net/pdf?id=49ti6LOUw5", "keywords": "lora, multi-task learning, peft", "abstract": "Recent research has demonstrated the efficacy of Low-Rank Adaptation (LoRA) as an effective implicit regularizer for large language models. Building on these findings, we investigate whether LoRA can be leveraged for efficient multi-task learning. This study presents experimental observations on utilizing a single LoRA module for multiple tasks in the fine-tuning of large language models. We introduce UnoLoRA*, a novel method for multi-task finetuning, which significantly reduces trainable parameters to just 0.05% per task. Our approach not only uncovers insights into low-rank representations and multitask generalization but also explores LoRA\u2019s capacity to capture task-agnostic knowledge. Our findings affirm that sharing a single LoRA adapter effectively boosts parameter efficiency while ensuring that it learns a more general representation, even as it yields a competitive performance.", "title_embedding_index": 2, "title_abs_embedding_index": 27}, {"title": "Synergistic Approach for Simultaneous Optimization of Monolingual, Cross-lingual, and Multilingual Information Retrieval", "link_suffix": "/forum?id=zkNCWtw2fd", "link": "https://openreview.net/forum?id=zkNCWtw2fd", "pdf_link": "https://openreview.net/pdf?id=zkNCWtw2fd", "keywords": "Information Retrieval, Multilingualism and Cross-Lingual NLP, Question Answering", "abstract": "Information retrieval across different languages is an increasingly important challenge in natural language processing. Recent approaches based on multilingual pre-trained language models have achieved remarkable success, yet they often optimize for either monolingual, cross-lingual, or multilingual retrieval performance at the expense of others. This paper proposes a novel hybrid batch training strategy to simultaneously improve zero-shot retrieval performance across monolingual, cross-lingual, and multilingual settings while mitigating language bias. The approach fine-tunes multilingual language models using a mix of monolingual and cross-lingual question-answer pair batches sampled based on dataset size. Experiments on XQuAD-R, MLQA-R, and MIRACL benchmark datasets show that the proposed method consistently achieves comparable or superior results in zero-shot retrieval across various languages and retrieval tasks compared to monolingual-only or cross-lingual-only training. Hybrid batch training also substantially reduces language bias in multilingual retrieval compared to monolingual training. These results demonstrate the effectiveness of the proposed approach for learning language-agnostic representations that enable strong zero-shot retrieval performance across diverse languages.", "title_embedding_index": 3, "title_abs_embedding_index": 28}, {"title": "EXecution-Eval: Can language models execute real-world code?", "link_suffix": "/forum?id=viQ1bLqKY0", "link": "https://openreview.net/forum?id=viQ1bLqKY0", "pdf_link": "https://openreview.net/pdf?id=viQ1bLqKY0", "keywords": "large language model, evaluation, benchmark, code execution", "abstract": "As language models (LLMs) advance, traditional benchmarks face challenges of dataset saturation and disconnection from real-world performance, limiting our understanding of true model capabilities. We introduce EXecution-Eval (EXE), a benchmark designed to assess LLMs' ability to execute code and predict program states. EXE attempts to address key limitations in existing evaluations: difficulty scaling, task diversity, training data contamination, and cost-effective scalability.\nComprising over 30,000 tasks derived from 1,000 popular Python repositories on GitHub, EXE spans a range of context lengths and algorithmic complexities. Tasks require models to execute code, necessitating various operations including mathematical reasoning, logical inference, bit manipulation, string operations, loop execution, and maintaining multiple internal variable states during computation. Our methodology involves: (a) selecting and preprocessing GitHub repositories, (b) generating diverse inputs for functions, (c) executing code to obtain ground truth outputs, and (d) formulating tasks that require models to reason about code execution. This approach allows for continuous new task generation for as few as 1,200 tokens, significantly reducing the risk of models \"training on the test set.\"\nWe evaluate several state-of-the-art LLMs on EXE, revealing insights into their code comprehension and execution capabilities. Our results show that even the best-performing models struggle with complex, multi-step execution tasks, highlighting specific computational concepts that pose the greatest challenges for today's LLMs. Furthermore, we review EXE's potential for finding and predicting errors to aid in assessing a model's cybersecurity capabilities. We propose EXE as a sustainable and challenging testbed for evaluating frontier models, offering potential insights into their internal mechanistic advancement", "title_embedding_index": 4, "title_abs_embedding_index": 29}, {"title": "The Rate-Distortion-Perception Trade-Off with Algorithmic Realism", "link_suffix": "/forum?id=vdUYa7N8Mt", "link": "https://openreview.net/forum?id=vdUYa7N8Mt", "pdf_link": "https://openreview.net/pdf?id=vdUYa7N8Mt", "keywords": "lossy compression, perceptual quality, rate-distortion-perception trade-off, randomization, universal critics", "abstract": "Realism constraints (or constraints on perceptual quality) have received considerable recent attention within the context of lossy compression, particularly of images. Theoretical studies of lossy compression indicate that high-rate common randomness between the compressor and the decompressor is a valuable resource for achieving realism. On the other hand, the utility of significant amounts of common randomness at test time has not been noted in practice. We offer an explanation for this discrepancy by considering a realism constraint that requires satisfying a universal critic that inspects realizations of individual compressed images, or batches thereof. We characterize the optimal rate-distortion-perception trade-off under such a realism constraint, and show that it is asymptotically achievable without any common randomness, unless the batch size is impractically large.", "title_embedding_index": 5, "title_abs_embedding_index": 30}, {"title": "Beyond Random Masking: When Dropout meets Graph Convolutional Networks", "link_suffix": "/forum?id=PwxYoMvmvy", "link": "https://openreview.net/forum?id=PwxYoMvmvy", "pdf_link": "https://openreview.net/pdf?id=PwxYoMvmvy", "keywords": "graph neural networks, dropout", "abstract": "Graph Convolutional Networks (GCNs) have emerged as powerful tools for learning on graph-structured data, yet the behavior of dropout in these models remains poorly understood. This paper presents a comprehensive theoretical analysis of dropout in GCNs, revealing its unique interactions with graph structure. We demonstrate that dropout in GCNs creates dimension-specific stochastic sub-graphs, leading to a form of structural regularization not present in standard neural networks. Our analysis shows that dropout effects are inherently degree-dependent, resulting in adaptive regularization that considers the topological importance of nodes. We provide new insights into dropout's role in mitigating oversmoothing and derive novel generalization bounds that account for graph-specific dropout effects. Furthermore, we analyze the synergistic interaction between dropout and batch normalization in GCNs, uncovering a mechanism that enhances overall regularization. Our theoretical findings are validated through extensive experiments on both node-level and graph-level tasks across 16 datasets. Notably, GCN with dropout and batch normalization outperforms state-of-the-art methods on several benchmarks. This work bridges a critical gap in the theoretical understanding of regularization in GCNs and provides practical insights for designing more effective graph learning algorithms.", "title_embedding_index": 6, "title_abs_embedding_index": 31}, {"title": "Defining Deception in Decision Making", "link_suffix": "/forum?id=YaRzuMaubS", "link": "https://openreview.net/forum?id=YaRzuMaubS", "pdf_link": "https://openreview.net/pdf?id=YaRzuMaubS", "keywords": "deception, AI safety", "abstract": "With the growing capabilities of machine learning systems, particularly those that interact with humans, there is an increased risk of systems that can easily deceive and manipulate people. Preventing unintended behaviors therefore represents an important challenge for creating aligned AI systems. To approach this challenge in a principled way, we first need to define deception formally. In this work, we present a concrete definition of deception under the formalism of rational decision making in partially observed Markov decision processes. Specifically, we propose a general regret theory of deception under which the degree of deception can be quantified in terms of the actor's beliefs, actions, and utility. To evaluate our definition, we study the degree to which our definition aligns with human judgments about deception. We hope that our work will constitute a step toward both systems that aim to avoid deception, and detection mechanisms to identify deceptive agents.", "title_embedding_index": 7, "title_abs_embedding_index": 32}, {"title": "Self-supervised contrastive learning performs non-linear system identification", "link_suffix": "/forum?id=ONfWFluZBI", "link": "https://openreview.net/forum?id=ONfWFluZBI", "pdf_link": "https://openreview.net/pdf?id=ONfWFluZBI", "keywords": "system identification, dynamics learning, identifiability, self-supervised learning", "abstract": "Self-supervised learning (SSL) approaches have brought tremendous success across many tasks and domains. It has been argued that these successes can be attributed to a link between SSL and identifiable representation learning: Temporal structure and auxiliary variables ensure that latent representations are related to the true underlying generative factors of the data. Here, we deepen this connection and show that SSL can perform system identification in latent space. We propose a new model to uncover linear, switching linear and non-linear dynamics under a non-linear observation model, give theoretical guarantees and validate them empirically.", "title_embedding_index": 8, "title_abs_embedding_index": 33}, {"title": "MAC-CAFE: Multi-actor, Centralized Critic Architecture for Feedback-driven Editing", "link_suffix": "/forum?id=Ql7msQBqoF", "link": "https://openreview.net/forum?id=Ql7msQBqoF", "pdf_link": "https://openreview.net/pdf?id=Ql7msQBqoF", "keywords": "Retrieval-Augmented Generation, Large Language Models, Knowledge Base Editing, Prompt Optimization", "abstract": "Large Language Models (LLMs) often generate incorrect or outdated information, especially in low-resource settings or when dealing with private data. To address this, Retrieval-Augmented Generation (RAG) uses external knowledge bases (KBs), but these can also suffer from inaccuracies. We introduce MAC-CAFE, a novel Multi-actor, Centralized Critic Architecture for Feedback-driven Editing approach that iteratively refines the KB based on expert feedback using a multi-actor, centralized critic reinforcement learning framework. Each document is assigned to an actor, modeled as a ReACT agent, which performs structured edits based on document-specific targeted instructions from a centralized critic. Experimental results show that MAC-CAFE significantly improves KB quality and RAG system performance, enhancing accuracy by up to 8% over baselines.", "title_embedding_index": 9, "title_abs_embedding_index": 34}, {"title": "Achieving Exact Federated Unlearning with Improved Post-Unlearning Performance", "link_suffix": "/forum?id=NHe6guO3l6", "link": "https://openreview.net/forum?id=NHe6guO3l6", "pdf_link": "https://openreview.net/pdf?id=NHe6guO3l6", "keywords": "Exact Federated Unlearning, Improved Post-Unlearning Performance, Multi-Models Training", "abstract": "Federated learning is a machine learning paradigm that allows multiple clients to train aggregated model via sharing model updates to a central server without sharing their data. Even though the data is not shared, it can indirectly influence the aggregated model via the shared model updates. In many real-life scenarios, we need to completely remove a client's influence (unlearning) from the aggregated model, such as competitive clients who want to remove their influence from the aggregated model after leaving the coalition to ensure other clients do not benefit from their contributions. The influence removal is also needed when the adversarial client negatively affects the aggregated model. Though the aggregated model can be retrained from scratch to ensure exact unlearning (completely removing the client's influence from the aggregated model), it performs poorly just after the unlearning, which is undesirable during deployment. To overcome this challenge, this paper proposes federated unlearning algorithms that ensure exact unlearning while achieving better performance post-unlearning. Our experimental results on different real datasets validate the performance of the proposed algorithms.", "title_embedding_index": 10, "title_abs_embedding_index": 35}, {"title": "Extending Flexibility of Image Coding Enhancement Framework for IoTs", "link_suffix": "/forum?id=LJWPYzjDz4", "link": "https://openreview.net/forum?id=LJWPYzjDz4", "pdf_link": "https://openreview.net/pdf?id=LJWPYzjDz4", "keywords": "Data Compression, IoT infrastructure, Edge Computing, Scalable Design", "abstract": "Neural image compression, necessary in various edge-device scenarios, suffers from its heavy encode-decode structures and inflexible compression level switch. The primary issue is that the computational and storage capabilities of edge devices are weaker than those of servers, preventing them from handling the same amount of computation and storage. One solution is to downsample images and reconstruct them on the receiver side; however, current methods uniformly downsample the image and limit flexibility in compression levels. We take a step to break up this paradigm by proposing a conditional uniform-based sampler that allows for flexible image size reduction and reconstruction. Building on this, we introduce a lightweight transformer-based reconstruction structure to further reduce the reconstruction load on the receiver side. Extensive evaluations conducted on a real-world testbed demonstrate multiple advantages of our system over existing compression techniques, especially in terms of adaptability to different compression levels, computational efficiency, and image reconstruction quality.", "title_embedding_index": 11, "title_abs_embedding_index": 36}, {"title": "Physics-Transfer Learning: A Framework to Address the Accuracy-Performance Dilemma in Modeling Complexity Problems in Engineering Sciences", "link_suffix": "/forum?id=llW4qRsF0o", "link": "https://openreview.net/forum?id=llW4qRsF0o", "pdf_link": "https://openreview.net/pdf?id=llW4qRsF0o", "keywords": "Physics-Transfer Learning; Accuracy-Performance Dilemma; Engineering Sciences; Complexity; Materials Strength; Brain Development", "abstract": "The development of theoretical sciences traditionally adheres to an observation-assumption-model paradigm, which is effective in simple systems but challenged by the `curse of complexity\u2019 in modern engineering sciences. Advancements in artificial intelligence (AI) and machine learning (ML) offer a data-driven alternative, capable of interpolating and extrapolating scientific inference where direct solutions are intractable. Moreover, feature engineering in ML resembles dimensional analysis in classical physics, suggesting that data-driven ML methods could potentially extract new physics behind complex data. Here we propose a physics-transfer (PT) learning framework to learn physics across digital models of varying fidelities and complexities, which addresses the accuracy-performance dilemma in understanding representative multiscale problems. The capability of our approach is showcased through screening metallic alloys by their strengths and predicting the morphological development of brains. The physics of crystal plasticity is learned from low-fidelity molecular dynamics simulation and the model is then fed by material parameters from high-fidelity, electronic structures level, density functional theory calculations, offering chemically accurate strength predictions with several orders lower computational costs. The physics of bifurcation in the evolution of brain morphologies is learned from simple sphere and ellipsoid models and then applied to predict the morphological development of human brains, showing excellent agreement with longitudinal magnetic resonance imaging (MRI) data. The learned latent variables are shown to be highly relevant to uncovered physical descriptors, explaining the effectiveness of the PT framework, which holds great potential in closing the gaps in understanding complexity problems in engineering sciences.", "title_embedding_index": 12, "title_abs_embedding_index": 37}, {"title": "Exploring the Recall of Language Models: Case Study on Molecules", "link_suffix": "/forum?id=DlZ97cVwr0", "link": "https://openreview.net/forum?id=DlZ97cVwr0", "pdf_link": "https://openreview.net/pdf?id=DlZ97cVwr0", "keywords": "recall, language models, molecular language models, sampling methods for language models", "abstract": "Most of the current benchmarks evaluate Generative Language Models based on the accuracy of the generated output. However, in some scenarios, it is also important to evaluate the recall of the generations, i.e., whether a model can generate all correct outputs, such as all security vulnerabilities of a given codebase. There are two challenges in evaluating the recall: the lack of complete sets of correct outputs for any task and the existence of many distinct but similar outputs (e.g., two exploits that target the same vulnerability).In this paper, we propose a benchmark from the domain of small organic molecules. We define several sets of molecules of varying complexity and fine-tune language models on subsets of those sets. We attempt to generate as many molecules from the target sets as possible and measure the recall, i.e., the percentage of generated molecules from the target set. We examine the impact of the training loss function and sampling strategy on the recall. We propose a sampling strategy based on beam search that avoids duplicates and maximizes recall. Finally, we show that given a small validation set, one can predict the recall of the model without actually generating many samples, which can act as a model selection strategy for maximizing generation recall.", "title_embedding_index": 13, "title_abs_embedding_index": 38}, {"title": "SNAP-TTA: Sparse Test-Time Adaptation for Latency-Sensitive Applications", "link_suffix": "/forum?id=0vtftmYQGV", "link": "https://openreview.net/forum?id=0vtftmYQGV", "pdf_link": "https://openreview.net/pdf?id=0vtftmYQGV", "keywords": "Test-Time Adaptation, Unsupervised Domain Adaptation", "abstract": "Test-Time Adaptation (TTA) methods use unlabeled test data to dynamically adjust models in response to distribution changes. However, existing TTA methods are not tailored for practical use on edge devices with limited computational capacity, resulting in a latency-accuracy trade-off. To address this problem, we propose SNAP-TTA, a sparse TTA framework significantly reducing model adaptation frequency and data usage. It achieves competitive accuracy even with an adaptation rate as low as 0.01, meaning the model adapts infrequently and uses only a small portion of the data relative to full adaptation. Our approach involves (i) Class and Domain Representative Memory (CnDRM), which identifies key samples that are both class-representative and domain-representative to facilitate adaptation with minimal data, and (ii) Inference-only Batch-aware Memory Normalization (IoBMN), which leverages representative samples to adjust normalization layers on-the-fly during inference, aligning the model effectively to changing domains. When combined with five state-of-the-art TTA algorithms, SNAP-TTA maintains the performances of these methods even with much-reduced adaptation rates from 0.01 to 0.5, making it suitable for edge devices serving latency-sensitive applications.", "title_embedding_index": 14, "title_abs_embedding_index": 39}, {"title": "Recovering Plasticity of Neural Networks via Soft Weight Rescaling", "link_suffix": "/forum?id=DnBjhWLVU1", "link": "https://openreview.net/forum?id=DnBjhWLVU1", "pdf_link": "https://openreview.net/pdf?id=DnBjhWLVU1", "keywords": "loss of plasticity, plasticity, continual learning, online learning", "abstract": "Recent studies have shown that as training progresses, neural networks gradually lose their capacity to learn new information, a phenomenon known as plasticity loss. An unbounded weight growth is one of the main causes of plasticity loss. Furthermore, it harms generalization capability and disrupts optimization dynamics. Re-initializing the network can be a solution, but it results in the loss of learned information, leading to performance drops. In this paper, we propose Soft Weight Rescaling (SWR), a novel approach that prevents unbounded weight growth without losing information. SWR recovers the plasticity of the network by simply scaling down the weight at each step of the learning process. We theoretically prove that SWR bounds weight magnitude and balances weight magnitude between layers. Our experiment shows that SWR improves performance on warm-start learning, continual learning, and single-task learning setups on standard image classification benchmarks.", "title_embedding_index": 15, "title_abs_embedding_index": 40}, {"title": "Shared Memory for Multi-agent Lifelong Pathfinding", "link_suffix": "/forum?id=9DrPvYCETp", "link": "https://openreview.net/forum?id=9DrPvYCETp", "pdf_link": "https://openreview.net/pdf?id=9DrPvYCETp", "keywords": "shared memory, transformers, multi-agent pathfinding", "abstract": "Multi-agent reinforcement learning (MARL) demonstrates significant progress in solving cooperative and competitive multi-agent problems in various environments. One of the main challenges in MARL is the need to explicitly predict other agents' behavior to achieve cooperation. As a solution to this problem, we propose the Shared Recurrent Memory Transformer (SRMT), which extends memory transformers to multi-agent settings by pooling and globally broadcasting individual working memories, enabling agents to implicitly exchange information and coordinate actions. We evaluate SRMT on the Partially Observable Multi-Agent Path Finding problem, both in a toy bottleneck navigation task requiring agents to pass through a narrow corridor and on a set of mazes from the POGEMA benchmark. In the bottleneck task, SRMT consistently outperforms a range of reinforcement learning baselines, especially under sparse rewards, and generalizes effectively to longer corridors than those seen during training. On POGEMA maps,  including Mazes, Random, and Warehouses, SRMT is competitive with a variety of recent MARL, hybrid, and planning-based algorithms. These results suggest that incorporating shared memory into transformer-based architectures can enhance coordination in decentralized multi-agent systems.", "title_embedding_index": 16, "title_abs_embedding_index": 41}, {"title": "DarkBench: Benchmarking Dark Patterns in Large Language Models", "link_suffix": "/forum?id=odjMSBSWRt", "link": "https://openreview.net/forum?id=odjMSBSWRt", "pdf_link": "https://openreview.net/pdf?id=odjMSBSWRt", "keywords": "Dark Patterns, AI Deception, Large Language Models", "abstract": "We introduce DarkBench, a comprehensive benchmark for detecting dark design patterns\u2014manipulative techniques that influence user behavior\u2014in interactions with large language models (LLMs). Our benchmark comprises 660 prompts across six categories: brand bias, user retention, sycophancy, anthropomorphism, harmful generation, and sneaking. We evaluate models from five leading companies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs are explicitly designed to favor their developers' products and exhibit untruthful communication, among other manipulative behaviors. Companies developing LLMs should recognize and mitigate the impact of dark design patterns to promote more ethical Al.", "title_embedding_index": 17, "title_abs_embedding_index": 42}, {"title": "VeSX: A Framework Featured by Verification, Self-Correction and In-context Learning for Web Automation Tasks", "link_suffix": "/forum?id=Of5F2GdGLA", "link": "https://openreview.net/forum?id=Of5F2GdGLA", "pdf_link": "https://openreview.net/pdf?id=Of5F2GdGLA", "keywords": "LLM agent, web automation", "abstract": "While large language models have achieved remarkable success in tasks such as reasoning and question answering, applying LLMs to interactive tasks like web automation remains challenging. In web automation, existing planning-execution workflow often faces limitations due to the infeasible subtasks. We propose VeSX, a framework designed to enhance subtask feasibility through verification, self-correction, and in-context learning. VeSX introduces three key improvements: (1) subgoal-guided verification, which verifies the execution results of subtasks based on the preset subgoals; (2) hierarchical self-correction, which combines reflection and replanning, targeting to self-correct mistakes in both planning and execution phases; (3) exemplar bank, which improves in-context learning by partitioning execution trajectories and heuristically generating metadata for exemplars. We evaluate VeSX on WebArena benchmark and achieve the state-of-the-art average success rate of 0.34, which significantly outperforms existing methods without human guidance on all five scenarios.", "title_embedding_index": 18, "title_abs_embedding_index": 43}, {"title": "Stochastic Sparse Sampling: A Framework for Variable-Length Medical Time Series Classification", "link_suffix": "/forum?id=Y0kmI2zqqi", "link": "https://openreview.net/forum?id=Y0kmI2zqqi", "pdf_link": "https://openreview.net/pdf?id=Y0kmI2zqqi", "keywords": "Time Series, Healthcare, Medicine, Epilepsy, Neuroscience", "abstract": "ile the majority of time series classification research has focused on modeling fixed-length sequences, variable-length time series classification (VTSC) remains critical in healthcare, where sequence length may vary among patients and events. To address this challenge, we propose $\\textbf{S}$tochastic $\\textbf{S}$parse $\\textbf{S}$ampling (SSS), a novel VTSC framework developed for medical time series. SSS manages variable-length sequences by sparsely sampling fixed windows to compute local predictions, which are then aggregated and calibrated to form a global prediction. We apply SSS to the task of seizure onset zone (SOZ) localization, a critical VTSC problem requiring identification of seizure-inducing brain regions from variable-length electrophysiological time series. We evaluate our method on the Epilepsy iEEG Multicenter Dataset, a heterogeneous collection of intracranial electroencephalography (iEEG) recordings obtained from four independent medical centers. SSS demonstrates superior performance compared to state-of-the-art (SOTA) baselines across most medical centers, and superior performance on all out-of-distribution (OOD) unseen medical centers. Additionally, SSS naturally provides post-hoc insights into local signal characteristics related to the SOZ, by visualizing temporally averaged local predictions throughout the signal.", "title_embedding_index": 19, "title_abs_embedding_index": 44}, {"title": "OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM Agents", "link_suffix": "/forum?id=qK6U4Ahfms", "link": "https://openreview.net/forum?id=qK6U4Ahfms", "pdf_link": "https://openreview.net/pdf?id=qK6U4Ahfms", "keywords": "LLM Agent, Large Language Model, Urban Study", "abstract": "Agent-based models (ABMs) have long been employed to explore how individual behaviors aggregate into complex societal phenomena in urban space. Unlike black-box predictive models, ABMs excel at explaining the micro-macro linkages that drive such emergent behaviors. The recent rise of Large Language Models (LLMs) has led to the development of LLM agents capable of simulating urban activities with unprecedented realism. However, scaling LLM agents to large city simulations presents significant challenges. Existing models are limited by the computational and communication costs of LLMs, compounded by the dynamic nature of urban environments that require continual updates to agent behavior. To address these limitations, we propose OpenCity, a scalable simulation platform optimized for both system and prompt efficiencies. Specifically, we propose a LLM request scheduler to reduce communication overhead by parallelizing requests through IO multiplexing. Besides, we deisgn a ``group-and-distill'' prompt optimization strategy minimizes redundancy by clustering agents with similar static attributes. Through experiments on six global cities, OpenCity achieves a 600-fold acceleration in simulation time per agent, a 70% reduction in LLM requests, and a 50% reduction in token usage. These improvements enable the simulation of 10,000 agents\u2019 daily activities in 1 hour on commodity hardware. Additionally, OpenCity establishes a benchmark for LLM agents, comparing simulated mobility behaviors, origin-destination flows, and segregation indices against real-world data. We believe our OpenCity platform provides a critical infrastructure to harness the power of LLMs for interdisciplinary studies in urban space, fostering the collective efforts of broader research communities. Code repo is available athttps://anonymous.4open.science/r/Anonymous-OpenCity-42BD.", "title_embedding_index": 20, "title_abs_embedding_index": 45}, {"title": "Structure-Aware Parameter-Efficient Machine Unlearning on Transformer Models", "link_suffix": "/forum?id=drrXhD2r8V", "link": "https://openreview.net/forum?id=drrXhD2r8V", "pdf_link": "https://openreview.net/pdf?id=drrXhD2r8V", "keywords": "Machine Unlearning, Parameter-Efficient, Transformer", "abstract": "Transformer has become fundamental to a vast series of pretrained large models that have achieved remarkable success across diverse applications. Machine unlearning is an emerging field focused on efficiently removing the influence of specific data from trained models, to comply with privacy regulations enforcing the right to be forgotten. The sheer size of Transformer-based models poses a significant challenge to unlearning efficiency. Existing methods find it promising to restrict unlearning updates to a small portion of influence-critical parameters. However, their parameter-efficient unlearning methods are largely devised in a structure-oblivious manner, which tends to inaccurately identify these parameters and leads to inferior unlearning performance for Transformers. In this paper, we propose {\\tt SPE-Unlearn}, a structure-aware parameter-efficient machine unlearning approach tailored for the Transformer architecture. {\\tt SPE-Unlearn} introduces a learnable pair of masks to respectively pinpoint influence-critical parameters in the heads and filters of Transformers. The learning objective of these masks is derived by jointly considering both desiderata of unlearning, i.e., sufficiency in influence removal and efficiency, and optimized through an efficient algorithm featured by a greedy search with a warm start. Equipped with the identified key parameters, {\\tt SPE-Unlearn} facilitates second-order unlearning, memory-free unlearning, and memory-aided unlearning scenarios. Extensive experiments on various transformer models and datasets demonstrate the effectiveness and efficiency of {\\tt SPE-Unlearn}~for Transformer unlearning.", "title_embedding_index": 21, "title_abs_embedding_index": 46}, {"title": "Large-Scale Multi-Agent Reinforcement Learning for Traffic Signal Optimization", "link_suffix": "/forum?id=hWF0HH8Rr9", "link": "https://openreview.net/forum?id=hWF0HH8Rr9", "pdf_link": "https://openreview.net/pdf?id=hWF0HH8Rr9", "keywords": "Reinforcement Learning, Traffic Signal Control, Multi-Agent, Transformer", "abstract": "We present a novel approach to Traffic Signal Control (TSC) in a multi-agent environment by modeling communication among agents as a sequence problem, enabling intersections within road networks to communicate with one another. Taking inspiration from point cloud processing and graph neural networks, we make our architecture capable of handling variable road network topologies, including differing numbers of intersections and intersection types, and demonstrate this by successfully training on real & randomly generated road networks and traffic demands. Furthermore, we demonstrate that even utilizing minimal state information can achieve competitive performance.", "title_embedding_index": 22, "title_abs_embedding_index": 47}, {"title": "MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data", "link_suffix": "/forum?id=owR9ofvkFQ", "link": "https://openreview.net/forum?id=owR9ofvkFQ", "pdf_link": "https://openreview.net/pdf?id=owR9ofvkFQ", "keywords": "Math, LLMs", "abstract": "Large language models (LLMs) have significantly advanced natural language understanding and demonstrated strong problem-solving abilities. Despite these successes, most LLMs still struggle with solving mathematical problems due to the intricate reasoning required. This paper investigates the mathematical problem-solving capabilities of LLMs using the newly developed ``MathOdyssey'' dataset. The dataset includes diverse mathematical problems at high school and university levels, created by experts from notable institutions to rigorously test LLMs in advanced problem-solving scenarios and cover a wider range of subject areas. By providing the MathOdyssey dataset as a resource to the AI community, we aim to contribute to the understanding and improvement of AI capabilities in complex mathematical problem-solving. We conduct benchmarking on open-source models, such as Llama-3, and closed-source models from the GPT series and Gemini models. Our results indicate that while LLMs perform well on routine and moderately difficult tasks, they face significant challenges with Olympiad-level problems and complex university-level questions. Our analysis shows a narrowing performance gap between open-source and closed-source models, yet substantial challenges remain, particularly with the most demanding problems. This study highlights the ongoing need for research to enhance the mathematical reasoning of LLMs. \nThe dataset, results, and evaluation code are publicly available.", "title_embedding_index": 23, "title_abs_embedding_index": 48}, {"title": "ESMGain: Effective and Efficient Prediction of Mutation\u2019s functional Effect via ESM2 Transfer Learning and robust Benchmarks", "link_suffix": "/forum?id=vVlNBaiLdN", "link": "https://openreview.net/forum?id=vVlNBaiLdN", "pdf_link": "https://openreview.net/pdf?id=vVlNBaiLdN", "keywords": "protein, language model, deep learning, biology, gain of function, enzyme", "abstract": "Mutations are complex biological phenomena with extensive impact on health and disease. With precision medicine\u2019s growing demand for mutation testing and the cost of wetlab experiments, ESM2 and a modified AlphaFold2 architecture have been used to predict a binary measurement of mutation \u201cpathogenicity\u201d. But many applications require a differentiated, functional effect measurement: does the mutation lead to a loss- or gain-of-function or neutral impact on the protein? First, we hypothesize and demonstrate that fine-tuning ESM2 with a custom regression head incorporating inductive biases enables the application of learned protein semantics to functional effect prediction. Notably, our model, dubbed ESMGain, outperforms state-of-the-art competitor PreMode on deep mutational scans (DMSs) from three different enzymes with a mean Spearman\u2019s rho of 0.74 vs. 0.68, although PreMode is pre-trained on 4.7M labeled mutations and uses protein structure, multiple sequence alignments and ESM2 embeddings. Second, these results lead us to hypothesize that the signal provided by protein structure, MSAs, and embeddings is largely redundant. PreMode's ablation studies show minimal performance drop when any of these modalities is excluded, suggesting that they capture overlapping information for functional effect prediction. This explains ESMGain\u2019s superior performance: its fine-tuned embeddings are task-specific and avoid the redundancy present in PreMode\u2019s features. Third, we introduce the first benchmarking framework for functional effect prediction: instead of only using a test split of the same protein DMS as the training data, we advocate testing the predictor on a different protein\u2018s DMS of the same protein family to test generalization. Because most mutations have a neutral effect and loss-/gain-of-function mechanisms are complex, the Spearman rho is inflated because of many accurate neutral predictions and rare, probably inaccurate loss-/gain-of-function predictions. Thus we introduce the harmonic Spearman as a fine-grained, realistic metric equally weighting performance for each effect.", "title_embedding_index": 24, "title_abs_embedding_index": 49}]
[
    {
        "title": "Optimal Transport for Reducing Bias in Causal Inference without Data Splitting",
        "link_suffix": "/forum?id=jO3QEsm15T",
        "link": "https://openreview.net/forum?id=jO3QEsm15T",
        "pdf_link": "https://openreview.net/pdf?id=jO3QEsm15T",
        "keywords": "Causal Effect Estimation, Optimal Transport",
        "abstract": "Causal inference seeks to estimate the causal effect given a treatment such as a kind of medicine or the dosage of a medication. To address the issue of confounding bias caused by the non-randomized treatment assignment on samples, most existing methods reduce the covariate shift between subpopulations receiving different values of treatment. However, these methods split training samples into smaller groups, which cuts down the number of samples in each group, while precise distribution estimation and alignment highly rely on a sufficient number of training data. In this paper, we propose a distribution alignment paradigm that involves all the training samples without data splitting, which can be naturally applied in the settings of binary and continuous treatments. To this end, we characterize the distribution shift by considering different probability measures of the same set including all the training samples, and reduce the shift between the marginal covariate distribution and the conditional covariate distribution given a treatment value. By doing this, data reduction caused by splitting is avoided, and the outcome prediction model trained on samples receiving one treatment value can be generalized to the entire population. In specific, we exploit the optimal transport theory built on probability measures to analyze the confounding bias and the outcome estimation error, which motivates us to propose a balanced representation learning method for causal inference of binary and continuous treatments. The experimental results on both binary and continuous treatment settings demonstrate the effectiveness of the proposed method."
    },
    {
        "title": "Adaptive Vision Encoders: Balancing Efficiency and Robustness in Vision-Language Models",
        "link_suffix": "/forum?id=yyIHdaSDUU",
        "link": "https://openreview.net/forum?id=yyIHdaSDUU",
        "pdf_link": "https://openreview.net/pdf?id=yyIHdaSDUU",
        "keywords": "large vision-language models, multimodal learning, continual learning",
        "abstract": "Vision-language models (VLMs) demonstrate impressive capabilities in visual question answering and image captioning, acting as a crucial link between visual and language modalities. However, existing open-source VLMs rely heavily on pretrained vision encoders, such as CLIP. Despite CLIP\u2019s robustness across diverse domains, it still exhibits significant image understanding errors. These errors propagate to the VLM responses, resulting in sub-optimal performance. In our work, we propose an efficient and robust method for updating vision encoders within VLMs. Our approach selectively and locally updates the model parameters, leading to substantial performance improvements on data where previous mistakes occurred, while maintaining overall robustness. We demonstrate the effectiveness of our method during offline and continual few-shot updates, simulating a model editing regime for VLMs. While our method also scales efficiently and effectively to adapting the language model (LLM) component of the VLM, we show that separately updating the vision encoder can be a very efficient alternative. This approach improves VLM performance with less than 10x the compute resources required for updating the LLM. Our method is also supported by theoretical justifications on the parameter selection strategy."
    },
    {
        "title": "Video Action Differencing",
        "link_suffix": "/forum?id=3bcN6xlO6f",
        "link": "https://openreview.net/forum?id=3bcN6xlO6f",
        "pdf_link": "https://openreview.net/pdf?id=3bcN6xlO6f",
        "keywords": "Video, Actions, Differencing, Zero-shot, benchmark",
        "abstract": "How do two individuals differ when performing the same action? In this work, we introduce Video Action Differencing, the novel task of identifying subtle differences between videos of the same action, which has numerous applications, such as coaching and skill acquisition. To enable development on this new task, we first create VidDiffBench, a benchmark dataset containing 557 video pairs, with human annotations of 4,719 fine-grained action differences and 2,075 timestamps indicating where these differences occur. Our experiments demonstrate that VidDiffBench poses a significant challenge for state-of-the-art large multimodal models (LMMs), such as GPT-4o, Gemini 1.5 Pro, and Qwen2-VL. By analyzing the failure cases of LMMs on VidDiffBench, we highlight two key challenges for this task: frame-by-frame alignment and fine-grained frame comparison. To overcome these, we propose VidDiff, an agent-based system that breaks the task into three stages: action difference proposal, keyframe localization, and difference verification, each stage utilizing specialized foundation models. The VidDiff method outperforms these baseline LMMs. We release both the dataset and code to encourage and support future research in this domain."
    },
    {
        "title": "Automated Parameter Extraction for Biologically Realistic Neural Networks: An Initial Exploration with Large Language Models",
        "link_suffix": "/forum?id=j0sq9r3HFv",
        "link": "https://openreview.net/forum?id=j0sq9r3HFv",
        "pdf_link": "https://openreview.net/pdf?id=j0sq9r3HFv",
        "keywords": "Large Language Models, Knowledge Graphs, Computational neuroscience, Neural model construction",
        "abstract": "In computational neuroscience, extracting parameters for constructing biologically realistic neural models is a resource-intensive task that requires continuous updates as new research emerges. This paper explores utilizing large language models (LLMs) in automating parameter extraction from scientific literature for biologically realistic neural models. We utilized open-source LLMs via Ollama to construct KGs, capturing parameters such as neuron morphology, synapse dynamics, and receptor properties. SNNBuilder \\cite{Gutierrez2022}, a framework for building spiking neural network (SNN) models, serves as a key validation example for our framework. However, the methodology we outline here can extend beyond SNNs and could applied to systematic modelling of the brain.By experimenting with different prompting strategies\u2014general extraction, in-context hints, and masked prompting\u2014we evaluated the ability of LLMs to autonomously extract relevant data and organize it within an expert-base or data-driven ontology, as well as to infer missing information for neural model construction. Additionally, we implemented retrieval-augmented generation (RAG) via LangChain to further improve the accuracy of parameter extraction through leveraging external knowledge sources. Analysis of the the generated KGs, demonstrated that LLMs, when guided by targeted prompts, can enhance the data-to-model process, paving the way for more efficient parameter extraction and model construction in computational neuroscience."
    },
    {
        "title": "scKGOT: Intercellular Signaling Inference with Knowledge Graph Optimal Transport for Single-cell Transcriptomics",
        "link_suffix": "/forum?id=Y9yQ9qmVrc",
        "link": "https://openreview.net/forum?id=Y9yQ9qmVrc",
        "pdf_link": "https://openreview.net/pdf?id=Y9yQ9qmVrc",
        "keywords": "Knowledge Graph, Optimal Transport, Cell-cell Communication",
        "abstract": "Single-cell transcriptomics provides detailed genetic insights into cellular heterogeneity within intact organs and the intercellular signaling that underpins tissue homeostasis, development, and disease. To improve the inference of intercellular signaling and pathway activity, we introduce scKGOT, a novel method that employs the Knowledge Graph Optimal Transport (KGOT) algorithm to model and quantify ligand-receptor-signaling networks between sender and receiver cells. scKGOT defines sender and receiver spaces using pairwise distance matrices from gene expression profiles and leverages prior knowledge from the Ligand-Receptor-Pathway Knowledge Graph (LRP-KG) as initial guidance for transport optimization, allowing for dynamic adaptation based on gene expression data. Through comprehensive benchmarking on public single-cell transcriptomic datasets, scKGOT consistently outperforms existing inference methods in terms of precision and interpretability. Furthermore, we demonstrate its practical applicability across multiple case studies, uncovering complex pathway interactions and revealing insights into cellular heterogeneity in diverse biological contexts. By incorporating scKGOT, we provide a robust and generalizable approach for pathway inference in single-cell analyses, advancing the understanding of intercellular communication mechanisms and offering valuable insights into biological processes at the cellular level."
    },
    {
        "title": "Injecting Learnable Table Features into LLMs",
        "link_suffix": "/forum?id=Mi45HjlVRj",
        "link": "https://openreview.net/forum?id=Mi45HjlVRj",
        "pdf_link": "https://openreview.net/pdf?id=Mi45HjlVRj",
        "keywords": "Large language model, Table reasoning, Multi-modal learning",
        "abstract": "To migrate the remarkable successes of Large Language Models (LLMs), the community has made numerous efforts to extend them to the table reasoning tasks for the widely deployed tabular data. Despite that, in this work, by showing a probing experiment on our proposed StructQA benchmark, we postulate that the even the most advanced LLMs (such as GPTs) may still fall short on coping with tabular data. More specifically, the current scheme often simply replies on serializing the tabular data, together with the meta information, then put them through the LLMs. We argue that the loss of the structural information and incomplete cell values persisted are the root of this shortcoming. In this work, we further propose TAMO that bears an ideology to treat the tables as an independent modality integrated with the text tokens. The resulted model in TAMO is a multimodal framework consisting of a hypergraph neural network as the global table encoder seamlessly integrated with the mainstream LLM. Empirical results on various benchmarking datasets, including HiTab, WikiTQ, WikiSQL, FeTaQA, and StructQA, have demonstrated significant improvement with an average relative gain by 42.65%."
    },
    {
        "title": "GANDALF: Generative AttentioN based Data Augmentation and predictive modeLing Framework for personalized cancer treatment",
        "link_suffix": "/forum?id=WwmtcGr4lP",
        "link": "https://openreview.net/forum?id=WwmtcGr4lP",
        "pdf_link": "https://openreview.net/pdf?id=WwmtcGr4lP",
        "keywords": "personalized drug response prediction, cancer, genomic data augmentation, diffusion model, pseudolabelling",
        "abstract": "Effective treatment of cancer is a major challenge faced by healthcare providers, due to the highly individualized nature of patient responses to treatment. This is caused by the heterogeneity seen in cancer-causing alterations (mutations) across patient genomes. Limited availability of response data in patients makes it difficult to train personalized treatment recommendation models on mutations from clinical genomic sequencing reports. Prior methods tackle this by utilising larger, labelled pre-clinical laboratory datasets (\u2018cell lines\u2019), via transfer learning. These methods augment patient data by learning a shared, domain-invariant representation, between the cell line and patient domains, which is then used to train a downstream drug response prediction (DRP) model. This approach augments data in the shared space but fails to model patient-specific characteristics, which have a strong influence on their drug response. We propose a novel generative attention-based data augmentation and predictive modeling framework, GANDALF, to tackle this crucial shortcoming of prior methods. GANDALF not only augments patient genomic data directly, but also accounts for its domain-specific characteristics. GANDALF outperforms state-of-the-art DRP models on publicly available patient datasets and emerges as the front-runner amongst SOTA cancer DRP models."
    },
    {
        "title": "GPTBIAS: A Comprehensive Framework for Evaluating Bias in Large Language Models",
        "link_suffix": "/forum?id=u1EPPYkbgA",
        "link": "https://openreview.net/forum?id=u1EPPYkbgA",
        "pdf_link": "https://openreview.net/pdf?id=u1EPPYkbgA",
        "keywords": "Large Language Model, Bias",
        "abstract": "Large language models (LLMs) have seen widespread adoption across various applications, both in their original form and fine-tuned adaptations. However, a major concern with LLMs is their potential to generate biased content. Existing evaluation methods often have different constraints, such as needing access to the model's intermediate outputs. To address these issues, we propose GPTBIAS, a novel bias evaluation framework that leverages the capabilities of advanced LLMs like GPT-4 to assess bias in other models across nine bias types. Our framework introduces Bias Attack Instructions, specifically designed to evaluate model bias across multiple dimensions. GPTBIAS provides not only a quantitative bias score but also detailed information on bias types, affected demographics, underlying reasons for biases, and suggestions for improvement. Through extensive experiments on popular LLMs, we demonstrate the effectiveness and usability of our bias evaluation framework. Our results reveal nuanced insights into the biases present in different models and highlight the importance of comprehensive bias assessment in the development and deployment of LLMs."
    },
    {
        "title": "RaSA: Rank-Sharing Low-Rank Adaptation",
        "link_suffix": "/forum?id=GdXI5zCoAt",
        "link": "https://openreview.net/forum?id=GdXI5zCoAt",
        "pdf_link": "https://openreview.net/pdf?id=GdXI5zCoAt",
        "keywords": "parameter-efficient fine-tuning, large language model, low-rank adaptation",
        "abstract": "Low-rank adaptation (LoRA) has been prominently employed for parameter-efficient fine-tuning of large language models (LLMs). However, the limited expressive capacity of LoRA, stemming from the low-rank constraint, has been recognized as a bottleneck, particularly in rigorous tasks like code generation and mathematical reasoning. To address this limitation, we introduce Rank-Sharing Low-Rank Adaptation (RaSA), an innovative extension that enhances the expressive capacity of LoRA by leveraging partial rank sharing across layers. By forming a shared rank pool and applying layer-specific weighting, RaSA effectively increases the number of ranks without augmenting parameter overhead. Our theoretically grounded and empirically validated approach demonstrates that RaSA not only maintains the core advantages of LoRA but also significantly boosts performance in challenging code and math tasks. Code, data and scripts are available at:https://anonymous.4open.science/r/RaSA-ICLR-0E25."
    },
    {
        "title": "Optimization Insights into Deep Diagonal Linear Networks",
        "link_suffix": "/forum?id=SKl8zzi4Mn",
        "link": "https://openreview.net/forum?id=SKl8zzi4Mn",
        "pdf_link": "https://openreview.net/pdf?id=SKl8zzi4Mn",
        "keywords": "Diagonal Linear Network, Overparameterization, Implicit Bias, Mirror Flow",
        "abstract": "Overparameterized models trained with (stochastic) gradient descent are ubiquitous in modern machine learning. These large models achieve unprecedented performance on test data, but their theoretical understanding is still limited. In this paper, we take a step towards filling this gap by adopting an optimization perspective. More precisely, we study the implicit regularization properties of the gradient flow \u201calgorithm\u201d for estimating the parameters of a deep diagonal neural network. Our main contribution is showing that this gradient flow induces a mirror flow dynamic on the model, meaning that it is biased towards a specific solution of the problem depending on the initialization of the network. Along the way, we prove several properties of the trajectory."
    },
    {
        "title": "Harnessing Query Heterogeneity for Cost-Effective Proactive Caching in LLM Inference",
        "link_suffix": "/forum?id=NcKUcd4EkA",
        "link": "https://openreview.net/forum?id=NcKUcd4EkA",
        "pdf_link": "https://openreview.net/pdf?id=NcKUcd4EkA",
        "keywords": "Query Cache, LLM Inference Serving, Bandit Learning",
        "abstract": "As Large Language Models (LLMs) significantly enhance the capabilities of AI systems, the increasing volume of query processing requests presents challenges for cost-effective inference, particularly due to repetitive queries that lead to unnecessary resource consumption and increased costs. Caching strategies are employed to store a small set of previous queries, enabling direct retrieval of repetitive queries without reprocessing by the LLMs. However, existing caching algorithms often assume uniform query lengths, simplifying cache selection to a top-$K$ problem, which is inadequate for real-world scenarios with heterogeneous lengths. To address this issue, we propose a bandit learning algorithm for proactive query caching in LLMs, specifically considering variable-sized queries. We cast the optimal cache query cache problem as a knapsack problem. Since the repetitive pattern and processing cost are unknown and has uncertainty, we cast the learning-to-cache problem as a bandit learning problem. Compared to conventional bandit learning frameworks, a new technical challenge is that the reward of an arm would not be observed if it is pulled. To tackle this, we propose an Lower confidence bound (LCB)-type algorithm, which we prove has a $\\tilde{O}(\\sqrt{T})$ order of regret and show that our regret does not deteriorate compared to previous results when incorporating a variable size setting. Furthermore, we demonstrate that our online cache policy effectively reduces the additional computational overhead typically associated with calculating the optimal cache."
    },
    {
        "title": "Ontology-Retrieval Augmented Generation for Scientific Discovery",
        "link_suffix": "/forum?id=DbZDbg2z9q",
        "link": "https://openreview.net/forum?id=DbZDbg2z9q",
        "pdf_link": "https://openreview.net/pdf?id=DbZDbg2z9q",
        "keywords": "ontology, rag, retrieval, llm, science, ai4science, chemistry, biomedical, reasoning",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, sparkling an increasing interest for their application in science. However, in scientific domains, their utility is often limited by hallucinations that violate established relationships between concepts or ignore their meaning; problems that are not entirely eliminated with Retrieval Augmented Generation (RAG) techniques. A key feature of science is the use of niche concepts, abbreviations and implicit relationships, which may deem RAG approaches less powerful due to the lack of understanding of concepts, especially in emerging and less known fields. Ontologies, as structured frameworks for organizing knowledge and establishing relationships between concepts, offer a potential solution to this challenge. In this work we introduce OntoRAG, a novel approach that enhances RAG by retrieving taxonomical knowledge from ontologies. We evaluate the performance of this method on three common biomedical benchmarks. To extend the value of OntoRAG to emerging fields, where ontologies have not yet been developed, we also present OntoGen, a methodology for generating ontologies from a set of documents. We apply the combined OntoGen+OntoRAG pipeline to a novel benchmark of scientific discovery in the emerging field of single-atom catalysis. Our results demonstrate the promise of this method for improving reasoning and suppressing hallucinations in LLMs, potentially accelerating scientific discovery across various domains."
    },
    {
        "title": "Revisiting the Scaling Effects of LLMs on Medical Reasoning Capabilities",
        "link_suffix": "/forum?id=jgVqCCg5XX",
        "link": "https://openreview.net/forum?id=jgVqCCg5XX",
        "pdf_link": "https://openreview.net/pdf?id=jgVqCCg5XX",
        "keywords": "LLM evaluation, scaling effect, medical reasoning evaluation",
        "abstract": "Recently, LLMs such as the Llama and Qwen families have rapidly improved by significantly scaling their training corpora, with smaller models trained on larger datasets now approaching or surpassing the performance of previous-generation larger models on public benchmarks.  In this paper, we revisit the scaling effects of LLMs, using the medical field as a case study, by carefully analyzing how training corpus size and parameter size affect model performance on problems of varying difficulty. To this end, we present MedResEval, a new benchmark built upon the MedQA dataset. It is designed to demand more complex reasoning and decision-making and more accurately reflect real-world medical scenarios. Leveraging MedResEval, we investigate the scaling effects of training corpus and model size in LLMs through a comprehensive analysis of several prominent LLM families on medical reasoning tasks of varying complexity.\nThe results reveal that while smaller models like Llama 3 (8B) approach the performance of older, larger models like Llama 2 (70B) on simple tasks like MedQA, they consistently underperform on complex tasks requiring advanced reasoning. Furthermore, we develop a difficulty-dependent scaling-law formula to characterize how LLMs' performance varies with training data size at a fixed model parameter size. The quantitative study reveals that reasoning error reduction rates are 1.3 times greater for large LLMs ($\\approx$ 70B) compared to small LLMs ($\\leq$10B) on simple tasks, and 2 times greater on complex reasoning tasks. Our study highlights that while both data and parameter scales enhance LLM performance, greater emphasis must be placed on parameter scales, particularly for complex reasoning tasks. Only LLMs with sufficiently large parameters can effectively tackle the complexities of real-world medical scenarios."
    },
    {
        "title": "SinkQ: Accurate 2-bit KV Cache Quantization with Dynamic Sink Tracking",
        "link_suffix": "/forum?id=bJ33TvbJW0",
        "link": "https://openreview.net/forum?id=bJ33TvbJW0",
        "pdf_link": "https://openreview.net/pdf?id=bJ33TvbJW0",
        "keywords": "KV Cache, Large Language Models, Quantization",
        "abstract": "The impressive capabilities of large language models (LLMs) come at the cost of substantial computational resources during deployment. While KV Cache can significantly reduce recomputation during inference, it also introduces additional memory overhead. KV Cache quantization presents a promising solution, striking a good balance between memory usage and accuracy.\nPrevious research has shown that the Keys are distributed by channel, while the Values are distributed by token. Consequently, the common practice is to apply channel-wise quantization to the Keys and token-wise quantization to the Values. However, our further investigation reveals that a small subset of unusual tokens exhibit unique characteristics that deviate from this pattern, which can substantially impact quantization accuracy. Furthermore, these tokens often have higher attention scores, exacerbating their quantization errors.\nTo address this, we develop a simple yet effective method to identify these tokens accurately during the decoding process and exclude them from quantization, significantly improving overall accuracy. Extensive experiments show that our method achieves significant accuracy improvements under 2-bit quantization and can deliver a 6.4\u00d7 reduction in memory usage and a 2.3\u00d7 increase in throughput. Our code will be released upon acceptance."
    },
    {
        "title": "Scaling Speech-Text Pre-training with Synthetic Interleaved Data",
        "link_suffix": "/forum?id=3tukjsVyrE",
        "link": "https://openreview.net/forum?id=3tukjsVyrE",
        "pdf_link": "https://openreview.net/pdf?id=3tukjsVyrE",
        "keywords": "large language models; speech language model; spoken chatbots",
        "abstract": "Speech language models (SpeechLMs) accept speech input and produce speech output, allowing for more natural human-computer interaction compared to text-based large language models (LLMs).\nTraditional approaches for developing SpeechLMs are constrained by the limited availability of unsupervised speech data and parallel speech-text data, which are significantly less abundant compared to text pre-training data, thereby limiting the scalability of SpeechLMs as LLMs.\nWe present a novel approach for scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from existing high-quality text corpora.\nOur method employs a supervised speech tokenizer derived from an automatic speech recognition (ASR) model (e.g. Whisper) by incorporating a vector-quantized bottleneck into the encoder.  In this process, we create tokenizers with various sampling rates ranging from 50Hz to as low as 6.25Hz. This supervised training approach results in discrete speech tokens with strong semantic preservation even at lower sampling rates, while still maintaining speech reconstruction quality.\nBy synthesizing speech-text data from existing text pre-train corpora with a text-to-token language model and scaling our pre-training to 1 trillion tokens, we achieve state-of-the-art performance in both speech language modeling and spoken question answering, improving performance on spoken questions tasks from the previous SOTA of 13% (Moshi) to 31%.\nWe further demonstrate that by fine-tuning the pre-trained model with speech dialogue data, we can develop an end-to-end spoken chatbot achieves competitive performance comparable to existing baselines in both conversational abilities and speech quality, even operating exclusively in the speech domain."
    },
    {
        "title": "Efficient Training of Sparse Autoencoders for Large Language Models via Layer Clustering",
        "link_suffix": "/forum?id=vSrBzCzg4G",
        "link": "https://openreview.net/forum?id=vSrBzCzg4G",
        "pdf_link": "https://openreview.net/pdf?id=vSrBzCzg4G",
        "keywords": "Sparse Autoencoders (SAEs), Meta Learning, Mechanistic Interpretability, Large Language Models (LLMs)",
        "abstract": "Sparse Autoencoders (SAEs) have recently been employed as an unsupervised approach for understanding the inner workings of Large Language Models (LLMs). They reconstruct the model\u2019s activations with a sparse linear combination of interpretable features. However, training SAEs is computationally intensive, especially as models grow in size and complexity. To address this challenge, we propose a novel training strategy that reduces the number of trained SAEs from one per layer to one for a given group of contiguous layers. Our experimental results on Pythia 160M highlight a 6x speedup without compromising the reconstruction quality and performance on downstream tasks. Therefore, layer clustering presents an efficient approach to train SAEs in modern LLMs."
    },
    {
        "title": "Offline Model-Based Optimization by Learning to Rank",
        "link_suffix": "/forum?id=sb1HgVDLjN",
        "link": "https://openreview.net/forum?id=sb1HgVDLjN",
        "pdf_link": "https://openreview.net/pdf?id=sb1HgVDLjN",
        "keywords": "Offline model-based optimization, black-box optimization, learning to rank, learning to optimize",
        "abstract": "Offline model-based optimization (MBO) aims to identify a design that maximizes a black-box function using only a fixed, pre-collected dataset of designs and their corresponding scores. This problem has garnered significant attention from both scientific and industrial domains. A common approach in offline MBO is to train a regression-based surrogate model by minimizing mean squared error (MSE) and then find the best design within this surrogate model by different optimizers (e.g., gradient ascent). However, a critical challenge is the risk of out-of-distribution errors, i.e., the surrogate model may typically overestimate the scores and mislead the optimizers into suboptimal regions. Prior works have attempted to address this issue in various ways, such as using regularization techniques and ensemble learning to enhance the robustness of the model, but it still remains. In this paper, we argue that regression models trained with MSE are not well-aligned with the primary goal of offline MBO, which is to $\\textit{select}$ promising designs rather than to predict their scores precisely. Notably, if a surrogate model can maintain the order of candidate designs based on their relative score relationships, it can produce the best designs even without precise predictions. To validate it, we conduct experiments to compare the relationship between the quality of the final designs and MSE, finding that the correlation is really very weak. In contrast, a metric that measures order-maintaining quality shows a significantly stronger correlation. Based on this observation, we propose learning a ranking-based model that leverages learning to rank techniques to prioritize promising designs based on their relative scores. We show that the generalization error on ranking loss can be well bounded. Empirical results across diverse tasks demonstrate the superior performance of our proposed ranking-based models than twenty existing methods."
    },
    {
        "title": "Calibration of ordinal regression networks",
        "link_suffix": "/forum?id=v27yHgKtMv",
        "link": "https://openreview.net/forum?id=v27yHgKtMv",
        "pdf_link": "https://openreview.net/pdf?id=v27yHgKtMv",
        "keywords": "Ordinal regression, Calibration, Deep neural networks, Unimodality, Loss function, Soft ordinal encoding, Label smoothing, Order-aware calibration",
        "abstract": "Recent studies have shown that deep neural networks are not well-calibrated and produce over-confident predictions.\nThe miscalibration issue primarily stems from the minimization of cross-entropy, which aims to align predicted softmax probabilities with one-hot labels. In ordinal regression tasks, this problem is compounded by an additional challenge: the expectation that softmax probabilities should exhibit unimodal distribution is not met with cross-entropy. Rather, the ordinal regression literature has focused on unimodality and overlooked calibration. To address these issues, we propose a novel loss function that introduces order-aware calibration, ensuring that prediction confidence adheres to ordinal relationships between classes. It incorporates soft ordinal encoding and label-smoothing-based regularization to enforce both calibration and unimodality. Extensive experiments across three popular ordinal regression benchmarks demonstrate that our approach achieves state-of-the-art calibration without compromising accuracy."
    },
    {
        "title": "ExploraCoder: Advancing code generation for multiple unseen APIs via planning and chained exploration",
        "link_suffix": "/forum?id=m5rOrTiuKG",
        "link": "https://openreview.net/forum?id=m5rOrTiuKG",
        "pdf_link": "https://openreview.net/pdf?id=m5rOrTiuKG",
        "keywords": "Large Language Models, Code Generation, Code Library, Retrieval Augmented Generation",
        "abstract": "Through training on publicly available source code libraries, large language models (LLMs) can invoke multiple encapsulated APIs to solve complex programming problems.\nHowever, existing models inherently cannot generalize to use APIs that are unseen in their training corpora. As libraries continuously evolve, it becomes impractical to exhaustively retrain LLMs with new API knowledge. This limitation hampers LLMs from solving problems which require newly introduced or privately maintained libraries.\nHuman programmers often explore unfamiliar APIs by writing experimental code before invoking them for a more complex problem.\nInspired by this behavior, we propose $\\textbf{ExploraCoder}$, a training-free framework that empowers LLMs to invoke multiple unseen APIs in code solution by (1) planning a complex problem into several API invocation subtasks, and (2) exploring correct API usage through a novel chain-of-API-exploration.\nConcretely,  ExploraCoder guides the LLM to iteratively generate several experimental API invocations for each simple subtask, where the promising execution experience are exploited by subsequent subtasks. This forms a chained exploration trace that ultimately guides LLM in generating the final solution.\nWe evaluate ExploraCoder on Torchdata-Github benchmark as well as a newly constructed benchmark that involves more complex API interactions.\nExperimental results demonstrate that ExploraCoder significantly improves performance for models lacking prior API knowledge, achieving an absolute increase of 11.24% over niave RAG approaches and 14.07% over pretraining methods in pass@10. Moreover, the integration of a self-debug mechanism further boosts ExploraCoder's performance on more challenging tasks. Comprehensive ablation and case studies provide further insights into the effectiveness of ExploraCoder."
    },
    {
        "title": "A2-Flow: Alignment-Aware Pre-training for Speech Synthesis with Flow Matching",
        "link_suffix": "/forum?id=e2p1BWR3vq",
        "link": "https://openreview.net/forum?id=e2p1BWR3vq",
        "pdf_link": "https://openreview.net/pdf?id=e2p1BWR3vq",
        "keywords": "Generative Pre-training; Flow Matching; Alignment Learning; Discrete Speech Units",
        "abstract": "Recent advances in speech synthesis have enabled highly natural and speaker-adaptive speech generation by leveraging large-scale transcribed datasets. However, requiring tens of thousands of hours of annotated speech is impractical in low-resource settings. Existing pre-trained speech models often utilize masked speech inpainting for pre-training and show strong performance on various speech generation tasks using limited task-specific data. Nonetheless, these models still require external alignment mechanisms or extensive additional training to learn alignment for alignment-aware tasks, such as text-to-speech (TTS). In this paper, we propose A$^2$-Flow, an alignment-aware pre-training method for flow matching models in speech synthesis. A$^2$-Flow integrates alignment learning directly into the pre-training process using discrete speech units, enabling the model to efficiently adapt to alignment-aware tasks without the need for separate alignment mechanisms. By embedding alignment learning into pre-training, A$^2$-Flow facilitates alignment-free voice conversion (VC) and allows for faster convergence during TTS fine-tuning, even with limited transcribed data, making it highly suitable for low-resource scenarios. Experimental results show that A$^2$-Flow superior zero-shot VC performance compared to existing models and matches state-of-the-art TTS performance using only a small amount of transcribed data. Moreover, we demonstrate that A$^2$-Flow can be more efficiently applied to alignment-aware speech synthesis tasks than existing pre-training methods, providing a practical and scalable solution for high-quality speech synthesis across diverse settings."
    },
    {
        "title": "From Search to Sampling: Generative Models for Robust Algorithmic Recourse",
        "link_suffix": "/forum?id=NtwFghsJne",
        "link": "https://openreview.net/forum?id=NtwFghsJne",
        "pdf_link": "https://openreview.net/pdf?id=NtwFghsJne",
        "keywords": "Algorithmic recourse, explainability, generative modelling",
        "abstract": "Algorithmic Recourse provides recommendations to individuals who are adversely impacted by automated model decisions, on how to alter their profiles to achieve a favorable outcome. Effective recourse methods must balance three conflicting goals: proximity to the original profile to minimize cost, plausibility for realistic recourse, and validity to ensure the desired outcome. We show that existing methods train for these objectives separately and then search for recourse through a joint optimization over the recourse goals during inference, leading to poor recourse recommendations. We introduce GenRe, a generative recourse model designed to train the three recourse objectives jointly. Training such generative models is non-trivial due to lack of direct recourse supervision. We propose efficient ways to synthesize such supervision and further show that GenRe's training leads to a consistent estimator. Unlike most prior methods, that employ non-robust gradient descent based search during inference, GenRe simply performs a forward sampling over the generative model to produce minimum cost recourse, leading to superior performance across multiple metrics. We also demonstrate GenRe provides the best trade-off between cost, plausibility and validity, compared to state-of-art baselines. We release anonymized code at:https://anonymous.4open.science/r/GenRe-BD71"
    },
    {
        "title": "ICAM: Rethinking Instance-Conditioned Adaptation in Neural Vehicle Routing Solver",
        "link_suffix": "/forum?id=gyTkfVYL45",
        "link": "https://openreview.net/forum?id=gyTkfVYL45",
        "pdf_link": "https://openreview.net/pdf?id=gyTkfVYL45",
        "keywords": "Vehicle Routing Problem, Reinforcement Learning, Instance-Conditioned Adaptation, Neural Combinatorial Optimization, Large-scale Generalization",
        "abstract": "The neural combinatorial optimization (NCO) has shown great potential for solving routing problems without requiring expert knowledge. However, existing constructive NCO methods still struggle to directly solve large-scale instances, which significantly limits their application prospects. To address these crucial shortcomings, this work proposes a novel Instance-Conditioned Adaptation Model (ICAM) for better large-scale generalization of neural routing solvers. In particular, we design a simple yet efficient instance-conditioned adaptation function to significantly improve the generalization performance of existing NCO models with a very small time and memory overhead. In addition, with a systematic investigation on the performance of information incorporation between different attention mechanisms, we further propose a powerful yet low-complexity instance-conditioned adaptation module to generate better solutions for instances across different scales. Experimental results show that our proposed method is capable of obtaining promising results with a very fast inference time in solving Traveling Salesman Problems (TSPs), Capacitated Vehicle Routing Problems (CVRPs) and Asymmetric Traveling Salesman Problems (ATSPs). To the best of our knowledge, our model achieves state-of-the-art performance among all RL-based constructive methods for TSPs and ATSPs with up to 1,000 nodes and extends state-of-the-art performance to 5,000 nodes on CVRP instances, and our method also generalizes well to solve cross-distribution instances."
    },
    {
        "title": "PokeFlex: A Real-World Dataset of Deformable Objects for Robotics",
        "link_suffix": "/forum?id=XwibrZ9MHG",
        "link": "https://openreview.net/forum?id=XwibrZ9MHG",
        "pdf_link": "https://openreview.net/pdf?id=XwibrZ9MHG",
        "keywords": "Deformable objects, Robotics, 3D mesh reconstruction.",
        "abstract": "Data-driven methods have shown great potential in solving challenging manipulation tasks, however, their application in the domain of deformable objects has been constrained, in part, by the lack of data. \nTo address this, we propose PokeFlex, a dataset featuring real-world paired and annotated multimodal data that includes 3D textured meshes, point clouds, RGB images, and depth maps. Such data can be leveraged for several downstream tasks such as online 3D mesh reconstruction, and it can potentially enable underexplored applications such as the real-world deployment of traditional control methods based on mesh simulations.\nTo deal with the challenges posed by real-world 3D mesh reconstruction, \nwe leverage a professional volumetric capture system that allows complete 360\u00b0 reconstruction. PokeFlex consists of 18 deformable objects with varying stiffness and shapes. Deformations are generated by dropping objects onto a flat surface or by poking the objects with a robot arm. Interaction forces and torques are also reported for the latter case. \nUsing different data modalities, we demonstrated a use case for the PokeFlex dataset in online 3D mesh reconstruction. We refer the reader to ourwebsiteor thepassword protected supplementary materialfor demos and examples of our dataset (password in pdf)."
    },
    {
        "title": "Training Open-ended Policies to follow Video-prompt Instructions with Reinforcement Learning",
        "link_suffix": "/forum?id=5f0n5yi8qK",
        "link": "https://openreview.net/forum?id=5f0n5yi8qK",
        "pdf_link": "https://openreview.net/pdf?id=5f0n5yi8qK",
        "keywords": "Online reinforcement learning\uff0copen-ended environment\uff0cpretrained video conditioned policy",
        "abstract": "In recent years, online reinforcement learning(RL) training methods like PPO have shone in important works such as Instruct GPT. However, unlike the success achieved in the language domain, online RL methods often struggle to generalize to untrained tasks in open-world environments like Minecraft, due to issues like overfitting. This has become a significant obstacle in using online methods to build a generalist agent. In this work, we notice the modality differences between natural language environments and embodied environments such as the Minecraft environment, which inspired us to use video instructions instead of text instructions to enhance the model's understanding of the relationship between the environment and instructions. We also introduce a new attention layer in the base model's encoder-decoder architecture to establish a semantic and visual dual-path information interaction channel, further strengthening this generalization capability. After training our model on a small set of tasks, it demonstrated excellent zero-shot generalization on new tasks, outperforming almost all other models in the Minecraft environment on our benchmark. Our approach takes a solid and important step toward unleashing the potential of online RL in building generalist agents.\nzero-shot generalization on new tasks, outperforming almost all other models in\nthe Minecraft environment on our benchmark. Our approach takes a solid and\nimportant step toward unleashing the potential of online RL in building generalist\nagents."
    },
    {
        "title": "SEAL-Pose: Enhancing Pose Estimation through Trainable Loss Function",
        "link_suffix": "/forum?id=KRqMfdwQaP",
        "link": "https://openreview.net/forum?id=KRqMfdwQaP",
        "pdf_link": "https://openreview.net/pdf?id=KRqMfdwQaP",
        "keywords": "Structured Energy network, Energy-based models, Trainable Loss-function, Dynamic loss function, Pose Estimation",
        "abstract": "Accurately predicting 3D human pose is a fundamental task in computer vision, where capturing the dependencies between multiple output variables remains a significant challenge. In this paper, we propose SEAL-Pose, a novel application of the Structured Energy As Loss (SEAL) framework to enhance 3D human pose estimation. SEAL, which was previously applied only to probabilistic models, has been adapted in this work for deterministic models, specifically focusing on 3D human pose estimation from 2D keypoints. Our method uses a structured energy network as a dynamic, trainable loss function, and shows promising results in enhancing pose estimation. We also introduce new evaluation metrics\u2014Limb Symmetry Error (LSE), Body Segment Length Error (BSLE)\u2014to assess structural consistency, with results indicating improvements in this area. Through experiments on the Human3.6M (H36M) and Human3.6M WholeBody (H3WB) datasets, SEAL-Pose shows reductions in pose estimation errors and outperforms existing baselines. This work highlights the potential of applying structured energy networks to tasks requiring complex output structures, offering a promising direction for future research."
    }
]
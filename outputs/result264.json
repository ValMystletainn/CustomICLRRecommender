[
    {
        "title": "Everything is Editable: Extend Knowledge Editing to Unstructured Data in Large Language Models",
        "link_suffix": "/forum?id=X5rO5VyTgB",
        "link": "https://openreview.net/forum?id=X5rO5VyTgB",
        "pdf_link": "https://openreview.net/pdf?id=X5rO5VyTgB",
        "keywords": "Knowledge Editing, Large Language Models",
        "abstract": "Recent knowledge editing methods have primarily focused on modifying structured knowledge in large language models. However, this task setting overlooks the fact that a significant portion of real-world knowledge is stored in an unstructured format, characterized by long-form content, noise, and a complex yet comprehensive nature.\nTechniques likelocal layer key-value storage'' andterm-driven optimization'', as used in previous methods like MEMIT, are not effective for handling unstructured knowledge.\nTo address these challenges, we propose a novel \\textbf{Un}structured \\textbf{K}nowledge \\textbf{E}diting method, namely UnKE, which extends previous assumptions in the layer dimension and token dimension.\nFirstly, in the layer dimension, we propose non-local block key-value storage to replace local layer key-value storage, increasing the representation ability of key-value pairs and incorporating attention layer knowledge. \nSecondly, in the token dimension, we replace \u201cterm-driven optimization\u201d with \u201ccause-driven optimization\u201d, which edits the last token directly while preserving context, avoiding the need to locate terms and preventing the loss of context information.\nResults on newly proposed unstructure knowledge editing dataset (UnKEBench) and traditional structured datasets demonstrate that UnKE achieves remarkable performance, surpassing strong baselines. In addition, UnKE has robust batch editing and sequential editing capabilities."
    },
    {
        "title": "Block Coordinate Descent Methods for Optimization under J-Orthogonality Constraints with Applications",
        "link_suffix": "/forum?id=Jy17uvzNe5",
        "link": "https://openreview.net/forum?id=Jy17uvzNe5",
        "pdf_link": "https://openreview.net/pdf?id=Jy17uvzNe5",
        "keywords": "Orthogonality Constraints, Nonconvex Optimization, Nonsmooth Composite Optimization, Block Coordinate Descent, Convergence Analysis",
        "abstract": "The J-orthogonal matrix, also referred to as the hyperbolic orthogonal matrix, is a class of special orthogonal matrix in hyperbolic space, notable for its advantageous properties. These matrices are integral to optimization under J-orthogonal constraints, which have widespread applications in statistical learning and data science. However, addressing these problems is generally challenging due to their non-convex nature and the computational intensity of the constraints. Currently, algorithms for tackling these challenges are limited. This paper introduces \\textbf{JOBCD}, a novel Block Coordinate Descent method designed to address optimizations with J-orthogonality constraints. We explore two specific variants of \\textbf{JOBCD}: one based on a Gauss-Seidel strategy (\\textbf{GS-JOBCD}), the other on a variance-reduced and Jacobi strategy (\\textbf{VR-J-JOBCD}). Notably, leveraging the parallel framework of a Jacobi strategy, \\textbf{VR-J-JOBCD} integrates variance reduction techniques to decrease oracle complexity in the minimization of finite-sum functions. For both \\textbf{GS-JOBCD} and \\textbf{VR-J-JOBCD}, we establish the oracle complexity under mild conditions and strong limit-point convergence results under the Kurdyka-Lojasiewicz inequality. To demonstrate the effectiveness of our method, we conduct experiments on hyperbolic eigenvalue problems, hyperbolic structural probe problems, and the ultrahyperbolic knowledge graph embedding problem. Extensive experiments using both real-world and synthetic data demonstrate that \\textbf{JOBCD} consistently outperforms state-of-the-art solutions, by large margins."
    },
    {
        "title": "Locality-aware Gaussian Compression for Fast and High-quality Rendering",
        "link_suffix": "/forum?id=dHYwfV2KeP",
        "link": "https://openreview.net/forum?id=dHYwfV2KeP",
        "pdf_link": "https://openreview.net/pdf?id=dHYwfV2KeP",
        "keywords": "point-based rendering, neural fields, compression",
        "abstract": "We present LocoGS, a locality-aware 3D Gaussian Splatting (3DGS) framework that exploits the spatial coherence of 3D Gaussians for compact modeling of volumetric scenes.\nTo this end, we first analyze the local coherence of 3D Gaussian attributes, and propose a novel locality-aware 3D Gaussian representation that effectively encodes locally-coherent Gaussian attributes using a neural field representation with a minimal storage requirement.\nOn top of the novel representation, LocoGS is carefully designed with additional components such as dense initialization, an adaptive spherical harmonics bandwidth scheme and different encoding schemes for different Gaussian attributes to maximize compression performance.\nExperimental results demonstrate that our approach outperforms the rendering quality of existing compact Gaussian representations for representative real-world 3D datasets while achieving from 54.6$\\times$ to 96.6$\\times$ compressed storage size and from 2.1$\\times$ to 2.4$\\times$ rendering speed than 3DGS. Even our approach also demonstrates an averaged 2.4$\\times$ higher rendering speed than the state-of-the-art compression method with comparable compression performance."
    },
    {
        "title": "POC-SLT: Partial Object Completion with SDF Latent Transformers",
        "link_suffix": "/forum?id=aSByBbmASe",
        "link": "https://openreview.net/forum?id=aSByBbmASe",
        "pdf_link": "https://openreview.net/pdf?id=aSByBbmASe",
        "keywords": "SDF Completion, Masked Encoder Transformer, Variation Auto Encoder, Scale Invariant, Million-scale Point Processing, Repairing Latent Codes",
        "abstract": "3D geometric shape completion hinges on representation learning and a deep understanding of geometric data.\nWithout profound insights into the three-dimensional nature of the data, this task remains unattainable.\nOur work addresses this challenge of 3D shape completion given partial observations\nby proposing a transformer operating on the latent space representing Signed Distance Fields (SDFs).\nInstead of a monolithic volume, the SDF of an object is partitioned into smaller high-resolution patches leading to a sequence of latent codes.\nThe approach relies on a smooth latent space encoding learned via a variational autoencoder (VAE), trained on millions of 3D patches.\nWe employ an efficient masked autoencoder transformer to complete partial sequences into comprehensive shapes in latent space.\nOur approach is extensively evaluated on partial observations from ShapeNet and the ABC dataset where only fractions of the objects are given.\nThe proposed POC-SLT architecture compares favorably with several baseline state-of-the-art methods,\ndemonstrating a significant improvement in 3D shape completion, both qualitatively and quantitatively."
    },
    {
        "title": "Diffusion Actor-Critic: Formulating Constrained Policy Iteration as Diffusion Noise Regression for Offline Reinforcement Learning",
        "link_suffix": "/forum?id=ldVkAO09Km",
        "link": "https://openreview.net/forum?id=ldVkAO09Km",
        "pdf_link": "https://openreview.net/pdf?id=ldVkAO09Km",
        "keywords": "Offline Reinforcement Learning, Diffusion Models, Actor-critic Learning, Policy Iteration, Policy Regularization",
        "abstract": "In offline reinforcement learning, it is necessary to manage out-of-distribution actions to prevent overestimation of value functions. One class of methods, policy-regularized methods, address this problem by constraining the target policy to stay close to the behavior policy. Although several approaches suggest representing the behavior policy as an expressive diffusion model to boost performance, it remains unclear how to regularize the target policy given a diffusion-modeled behavior sampler. In this paper, we propose Diffusion Actor-Critic (DAC) that formulates the Kullback-Leibler (KL) constraint policy iteration as a diffusion noise regression problem, enabling direct representation of target policies as diffusion models. Our approach follows the actor-critic learning paradigm that we alternatively train a diffusion-modeled target policy and a critic network. The actor training loss includes a soft Q-guidance term from the Q-gradient. The soft Q-guidance grounds on the theoretical solution of the KL constraint policy iteration, which prevents the learned policy from taking out-of-distribution actions. We demonstrate that such diffusion-based policy constraint, along with the coupling of the lower confidence bound of the Q-ensemble as value targets, not only preserves the multi-modality of target policies but also contributes to stable convergence and strong performance in DAC. Our approach is evaluated on the D4RL benchmarks and outperforms the state-of-the-art in nearly all environments."
    },
    {
        "title": "LLM-Assisted Static Analysis for Detecting Security Vulnerabilities",
        "link_suffix": "/forum?id=9LdJDU7E91",
        "link": "https://openreview.net/forum?id=9LdJDU7E91",
        "pdf_link": "https://openreview.net/pdf?id=9LdJDU7E91",
        "keywords": "Neuro-Symbolic, Program Analysis, Security Vulnerability, LLM",
        "abstract": "Software is prone to security vulnerabilities. Program analysis tools to detect them have limited effectiveness in practice due to their reliance on human labeled specifications. Large language models (or LLMs) have shown impressive code generation capabilities but they cannot do complex reasoning over code to detect such vulnerabilities especially since this task requires whole-repository analysis. We propose IRIS, a neuro-symbolic approach that systematically combines LLMs with static analysis to perform whole-repository reasoning for security vulnerability detection. Specifically, IRIS leverages LLMs to infer taint specifications and perform contextual analysis, alleviating needs for human specifications and inspection. For evaluation, we curate a new dataset, CWE-Bench-Java, comprising 120 manually validated security vulnerabilities in real-world Java projects. A state-of-the-art static analysis tool CodeQL detects only 27 of these vulnerabilities whereas IRIS with GPT-4 detects 55 (+28) and improves upon CodeQL's average false discovery rate by 5% points. Furthermore, IRIS identifies 6 previously unknown vulnerabilities which cannot be found by existing tools."
    },
    {
        "title": "Improving Long-Text Alignment for Text-to-Image Diffusion Models",
        "link_suffix": "/forum?id=2ZK8zyIt7o",
        "link": "https://openreview.net/forum?id=2ZK8zyIt7o",
        "pdf_link": "https://openreview.net/pdf?id=2ZK8zyIt7o",
        "keywords": "Long Text Alignment, Diffusion Models, Preference Optimization, Text-to-Image Generation",
        "abstract": "The rapid advancement of text-to-image (T2I) diffusion models has enabled them to generate unprecedented results from given texts. However, as text inputs become longer, existing encoding methods like CLIP face limitations, and aligning the generated images with long texts becomes challenging. To tackle these issues, we propose a segment-level encoding method for processing long texts and a decomposed preference optimization method for effective alignment training. For segment-level encoding, long texts are divided into multiple segments and processed separately. This method overcomes the maximum input length limits of pretrained encoding models. For preference optimization, we provide decomposed CLIP-based preference models to fine-tune diffusion models. Specifically, to utilize CLIP-based preference models for T2I alignment, we delve into their scoring mechanisms and find that the preference scores can be decomposed into two components: a text-relevant part that measures T2I alignment and a text-irrelevant part that assesses other visual aspects of human preference. Additionally, we find that the text-irrelevant part contributes to a common overfitting problem during fine-tuning. To address this, we propose a reweighting strategy that assigns different weights to these two components, thereby reducing overfitting and enhancing alignment. After fine-tuning $512 \\times 512$ Stable Diffusion (SD) v1.5 for about 20 hours using our method, the fine-tuned SD outperforms stronger foundation models in T2I alignment, such as PixArt-$\\alpha$ and Kandinsky v2.2."
    },
    {
        "title": "GPT4LoRA: Optimizing LoRA Combination via MLLM Self-Reflection",
        "link_suffix": "/forum?id=xNCDKQMPYD",
        "link": "https://openreview.net/forum?id=xNCDKQMPYD",
        "pdf_link": "https://openreview.net/pdf?id=xNCDKQMPYD",
        "keywords": "MLLM, Self-Reflection, LoRA Combination",
        "abstract": "Low-Rank Adaptation (LoRA) is extensively used in generative models to enable concept-driven personalization, such as rendering specific characters or adopting unique styles. Although recent approaches have explored LoRA combination to integrate diverse concepts, they often require further fine-tuning or modifications to the generative model's original architecture. To address these limitations, we introduce GPT4LoRA, a novel method for LoRA combination that adjusts combination coefficients by leveraging the self-reflection capabilities of multimodal large language models (MLLMs). GPT4LoRA operates through a three-step process\u2014Generate, Feedback, and Refine\u2014without the need for additional training, relying solely on tailored prompts and iterative refinement to enhance performance. This iterative approach ensures more constructive feedback and optimizes the model responses. Experiments on various LoRA model combinations, including both realistic and anime styles, demonstrate that GPT4LoRA achieves superior results compared to existing methods. Additionally, an evaluation framework based on GPT-4o further highlights the clear performance gains offered by GPT4LoRA over standard baselines, showcasing its potential for advancing the field."
    },
    {
        "title": "Towards Efficient Adaptation of Pruning Strategy in Large Language Models",
        "link_suffix": "/forum?id=LCrm1FSl26",
        "link": "https://openreview.net/forum?id=LCrm1FSl26",
        "pdf_link": "https://openreview.net/pdf?id=LCrm1FSl26",
        "keywords": "Model Pruning, Large Language Model",
        "abstract": "Post-training pruning has gained increasing attention with the rapid growth of large language models (LLMs). However, significant variations in weight distributions across different LLMs make a fixed pruning strategy inadequate for multiple models. In this paper, we propose an efficient evolutionary optimization framework, \\textbf{Mecon}, for adaptive LLM pruning. In particular, we design an effective search space built on our \\textbf{Me}ta pruning metric to mitigate diverse weight distributions among LLMs. We then introduce model-wise re\\textbf{con}struction error, a lightweight search evaluation to speed up the evaluation of each search trial. We finally leverage Non-dominated Sorting Genetic Algorithm III (NSGA-III) as our search algorithm, handling both the single-objective problem of pruning metric search and the multi-objective problem of layerwise sparsity ratio search in discovering the optimal pruning strategy. We extensively evaluate our framework on LLaMA-1/2/3 and Mistral models across multiple benchmarks. Our results demonstrate that our adaptive pruning metrics consistently outperform existing ones, and the layerwise sparsity ratios improve the effectiveness of other pruning metrics. Furthermore, we validate the cross-task and cross-model generalizability of our pruning metrics, offering a cost-effective solution to streamline the search process. We release our code in the anonymous repository: \\textcolor{blue}{\\url{https://anonymous.4open.science/r/Mecon-5819}}."
    },
    {
        "title": "SongComposer: A Large Language Model for Lyric and Melody Composition in Song Generation",
        "link_suffix": "/forum?id=rMR2P8e0Zx",
        "link": "https://openreview.net/forum?id=rMR2P8e0Zx",
        "pdf_link": "https://openreview.net/pdf?id=rMR2P8e0Zx",
        "keywords": "LLM, Symbolic Song Composition",
        "abstract": "A song typically comprises the vocal track and the music track. Creating lyrics and melodies for the vocal track in a symbolic format, known as song composition, plays a significant role in the song generation. This delicate and complex task demands expert musical knowledge of melody, an advanced understanding of lyrics, and precise alignment between them. Despite achievements in sub-tasks such as lyric generation, lyric-to-melody, and melody-to-lyric, etc, a unified model for song composition has not yet been achieved. In this paper, we introduce SongComposer, a pioneering step towards a unified song composition model that can readily create symbolic lyrics and melodies following instructions. SongComposer is a music-specialized large language model (LLM) that, for the first time, integrates the capability of simultaneously composing lyrics and melodies into LLMs. To achieve this goal, three non-trivial efforts are introduced. 1) Sheet music understanding, we designed a flexible tuple format to load lyric and note attributes, fostering word-level alignment between lyrics and melodies, and enabling SongComposer to generate lyrics with accompanying well-aligned melodies. 2) Song note tokenizing, the vocabulary of the tokenizer is extended for song notes, and we find a proper scalar-manner initialization of new tokens based on musical prior is essential for the model to understand musical rhythm. 3) Structural music generation, we propose a multi-stage pipeline for progressively capturing the musical structure. Initially, we extract and feed motif-level melody patterns to SongComposer to build its basic generation capabilities. Later, we insert special tokens into the whole-song data to denote phrase-level structure, promoting logical repetition and smooth coherence. Extensive experiments demonstrate that SongComposer outperforms advanced LLMs, including GPT-4, in tasks such as lyric-to-melody generation, melody-to-lyric generation, song continuation, and text-to-song creation. We showcase the generated samples on our anonymous project pagehttps://songcomposer.github.io/. Due to the lack of high-quality symbolic song datasets with lyrics and melodies, we have carefully curated and will publicly release SongCompose, a large-scale song pretraining and supervised finetuning dataset that includes lyrics, melodies, and paired lyrics-melodies in both Chinese and English."
    },
    {
        "title": "A Solvable Attention for Neural Scaling Laws",
        "link_suffix": "/forum?id=wYxOMEzpkl",
        "link": "https://openreview.net/forum?id=wYxOMEzpkl",
        "pdf_link": "https://openreview.net/pdf?id=wYxOMEzpkl",
        "keywords": "self-attention, scaling laws, solution of learning dynamics",
        "abstract": "Transformers and many other deep learning models are empirically shown to predictably enhance their performance as a power law in training time, model size, or the number of training data points, which is termed as the neural scaling law. This paper studies this intriguing phenomenon particularly for the transformer architecture in theoretical setups. Specifically, we propose a framework for self-attention, the underpinning block of transformer, to learn in an in-context manner, where the corresponding learning dynamics is modeled as a non-linear ordinary differential equation (ODE) system. Furthermore, we establish a procedure to derive a tractable solution for this ODE system by reformulating it as a Riccati equation, which allows us to precisely characterize neural scaling laws for self-attention with training time, model size, data size, and the optimal compute. In addition, we reveal that the self-attention shares similar neural scaling laws with several other architectures when the context sequence length of the in-context learning is fixed, otherwise it would exhibit a different scaling law of training time."
    },
    {
        "title": "GPromptShield: Elevating Resilience in Graph Prompt Tuning Against Adversarial Attacks",
        "link_suffix": "/forum?id=yCN4yI6zhH",
        "link": "https://openreview.net/forum?id=yCN4yI6zhH",
        "pdf_link": "https://openreview.net/pdf?id=yCN4yI6zhH",
        "keywords": "pre-training; prompt tuning; robustness; adversarial attacks.",
        "abstract": "The paradigm of ``pre-training and prompt fine-tuning\", with its effectiveness and lightweight characteristics, has rapidly spread from the language field to the graph field. Several pioneering studies have designed specialized prompt functions for diverse downstream graph tasks based on various graph pre-training strategies. These prompts concentrate on the compatibility between the pre-training pretext and downstream graph tasks, aiming to bridge the gap between them. However, designing prompts to blindly adapt to downstream tasks based on this concept neglects crucial security issues. By conducting covert attacks on downstream graph data, we find that even when the downstream task data closely matches that of the pre-training tasks, it is still feasible to generate highly misleading prompts using simple deceptive techniques. In this paper, we shift the primary focus of graph prompts from compatibility to vulnerability issues in adversarial attack scenarios. We design a highly extensible shield defense system for the prompts, which enhances their robustness from two perspectives: Direct Handling and Indirect Amplification. When downstream graph data exhibits unreliable biases, the former directly combats invalid information by adding mixed multi-defense prompts to the input graph's feature space, while the latter employs a training strategy that circumvents invalid part and amplifies valid part. We provide a theoretical derivation that proves their feasibility, indicating that unbiased prompts exist under certain conditions on unreliable data. Extensive experiments across various adversarial attack scenarios indicate that the prompts within our shield defense system exhibit enhanced resilience and superiority. Our work explores new perspectives in the field of graph prompts, offering a novel option for downstream robust prompt fine-tuning."
    },
    {
        "title": "Streamlining the Design Space of ML4TSP Suggests Principles for Learning and Search",
        "link_suffix": "/forum?id=grU1VKEOLi",
        "link": "https://openreview.net/forum?id=grU1VKEOLi",
        "pdf_link": "https://openreview.net/pdf?id=grU1VKEOLi",
        "keywords": "Neural Combinatorial Optimization, Travelling salesman problem",
        "abstract": "Machine Learning (ML) has advanced Combinatorial Optimization (CO), especially for one of the most focused problems, the Travelling Salesman Problem (TSP). While certain methods demonstrate promising performance, they still fall short compared to mathematical solvers. This study utilizes TSP as a case study, dissecting established mainstream learning-based solvers to outline a comprehensive design space. It advances a unified modular streamline incorporating existing technologies in both learning and search for transparent ablation, aiming to reassess the role of learning and to discern which parts of existing techniques are genuinely beneficial and which are not. This further leads to the investigation of desirable principles of learning designs and the exploration of concepts guiding method designs. We demonstrate the desirability of principles such as joint probability estimation, symmetry solution representation, and online optimization for learning-based designs. Leveraging the findings, we propose enhancements to existing methods to compensate for their missing attributes, thereby advancing performance and enriching the technique library. From a higher viewpoint, we also uncover a performance advantage in non-autoregressive and supervised paradigms compared to their counterparts. The strategic decoupling and organic recompositions yield a factory of new TSP solvers, where we investigate synergies across various method combinations and pinpoint the optimal design choices to create more powerful ML4TSP solvers, thereby facilitating and offering a reference for future research and engineering endeavors. Source code will be made publicly available."
    },
    {
        "title": "OrthoRank: Token Selection via Sink Token Orthogonality for Efficient LLM inference",
        "link_suffix": "/forum?id=SYv9b4juom",
        "link": "https://openreview.net/forum?id=SYv9b4juom",
        "pdf_link": "https://openreview.net/pdf?id=SYv9b4juom",
        "keywords": "large language model, attention sink, efficiency",
        "abstract": "Attention mechanisms are central to the success of large language models (LLMs), enabling them to capture intricate token dependencies and implicitly assign importance to each token. Recent studies have revealed the sink token, which receives disproportionately high attention despite their limited semantic role. In this paper, we first expand the relationship between the sink token and other tokens, moving beyond attention to explore their similarity in hidden states, considering the layer depth. We observe that as the layers get deeper, the cosine similarity between the normalized hidden states of the sink token and those of other tokens increases, and that the normalized hidden states of the sink token exhibit negligible changes. These imply that other tokens consistently are directed toward the sink token throughout the layers. Next, we propose a dynamic token selection method, called OrthoRank, using these findings to select important tokens. Specifically, in a certain layer, we define token importance by the speed at which the token moves toward the sink token. This is converted into orthogonality with the sink token, meaning that tokens that are more orthogonal to the sink token are assigned greater importance. Finally, through extensive experiments, we demonstrated that our method results in lower perplexity and higher zero-shot accuracy compared to layer pruning methods at the same sparsity ratio with comparable throughput."
    },
    {
        "title": "Bridging Compressed Image Latents and Multimodal Large Language Models",
        "link_suffix": "/forum?id=GSUNPIw7Ad",
        "link": "https://openreview.net/forum?id=GSUNPIw7Ad",
        "pdf_link": "https://openreview.net/pdf?id=GSUNPIw7Ad",
        "keywords": "Multimodal Large Language Models, Neural Image Compression",
        "abstract": "This paper presents the first-ever study of adapting compressed image latents to suit the needs of downstream vision tasks that adopt Multimodal Large Language Models (MLLMs). MLLMs have extended the success of large language models to modalities (e.g. images) beyond text, but their billion scale hinders deployment on resource-constrained end devices. While cloud-hosted MLLMs could be available, transmitting raw, uncompressed images captured by end devices to the cloud requires an efficient image compression system. To address this, we focus on emerging neural image compression and propose a novel framework with a lightweight transform-neck and a surrogate loss to adapt compressed image latents for MLLM-based vision tasks. Given the huge scale of MLLMs, our framework has the striking feature of excluding the entire downstream MLLMs from training our system. This stands out from most existing coding for machine approaches that involve downstream networks in training and thus could be impractical when the networks are MLLMs. The proposed framework is general and applicable to various MLLMs and multiple application scenarios, where the neural image codec can be (1) pre-trained for human perception without updating, (2) fully updated for joint human and machine perception, or (3) fully updated for only machine perception. \nExtensive experiments on different neural image codecs and various MLLMs show that our method achieves great rate-accuracy performance with much less complexity, demonstrating its effectiveness."
    },
    {
        "title": "Optimal Partial Graph Matching",
        "link_suffix": "/forum?id=uDXFOurrHM",
        "link": "https://openreview.net/forum?id=uDXFOurrHM",
        "pdf_link": "https://openreview.net/pdf?id=uDXFOurrHM",
        "keywords": "Graph Matching, Optimal Transport",
        "abstract": "Partial graph matching addresses the limitations of traditional graph matching by allowing some nodes to remain unmatched, making it applicable to more complex scenarios. However, this flexibility introduces additional complexity, as both the subset of nodes to match and the optimal mapping must be determined. While recent studies have explored deep learning techniques for partial graph matching, a significant limitation remains: the absence of an optimization objective that fully captures the problem\u2019s intrinsic nature while enabling efficient solutions. In this paper, we propose a novel optimization framework for partial graph matching, inspired by optimal partial transport. Our approach formulates an objective that enables partial assignments while incorporating matching biases, using weighted total variation as the divergence function to guarantee optimal partial assignments. We  employ the Hungarian algorithm to achieve efficient, exact solutions with cubic time complexity. Our contributions are threefold: (i) we introduce a robust optimization objective that balances matched and unmatched nodes; (ii) we establish a connection between partial graph matching and the linear sum assignment problem, enabling efficient solutions; (iii) we propose a deep graph matching architecture with a novel partial matching loss, providing an end-to-end solution. The empirical evaluations on standard graph matching benchmarks demonstrate the efficacy of the proposed approach."
    },
    {
        "title": "Explaining Black-box Model Predictions via Two-level Nested Feature Attributions with Consistency Property",
        "link_suffix": "/forum?id=rj7wUcLgfw",
        "link": "https://openreview.net/forum?id=rj7wUcLgfw",
        "pdf_link": "https://openreview.net/pdf?id=rj7wUcLgfw",
        "keywords": "explainable AI; XAI; feature attribution; black-box model; local explanation; model-agnostic; nested features",
        "abstract": "Techniques that explain the predictions of black-box machine learning models are crucial to make the models transparent, thereby increasing trust in AI systems. The input features to the models often have a nested structure that consists of high- and low-level features, and each high-level feature is decomposed into multiple low-level features. For such inputs, both high-level feature attributions (HiFAs) and low-level feature attributions (LoFAs) are important for better understanding the model's decision. In this paper, we propose a model-agnostic local explanation method that effectively exploits the nested structure of the input to estimate the two-level feature attributions simultaneously. A key idea of the proposed method is to introduce the consistency property that should exist between the HiFAs and LoFAs, thereby bridging the separate optimization problems for estimating them. Thanks to this consistency property, the proposed method can produce HiFAs and LoFAs that are both faithful to the black-box models and consistent with each other, using a smaller number of queries to the models. In experiments on image classification in multiple instance learning and text classification using language models, we demonstrate that the HiFAs and LoFAs estimated by the proposed method are accurate, faithful to the behaviors of the black-box models, and provide consistent explanations."
    },
    {
        "title": "Offline RL with Smooth OOD Generalization in Convex Hull and its Neighborhood",
        "link_suffix": "/forum?id=eY5JNJE56i",
        "link": "https://openreview.net/forum?id=eY5JNJE56i",
        "pdf_link": "https://openreview.net/pdf?id=eY5JNJE56i",
        "keywords": "Deep Reinforcement Learning, Offline Reinforcement Learning, Smooth Bellman Operator, Smooth Q-function OOD Generalization",
        "abstract": "Offline Reinforcement Learning (RL) struggles with distributional shifts, leading to the $Q$-value overestimation for out-of-distribution (OOD) actions. Existing methods address this issue by imposing constraints; however, they often become overly conservative when evaluating OOD regions, which constrains the $Q$-function generalization. This over-constraint issue results in poor $Q$-value estimation and hinders policy improvement. In this paper, we introduce a novel approach to achieve better $Q$-value estimation by enhancing $Q$-function generalization in OOD regions within Convex Hull and its Neighborhood (CHN). Under the safety generalization guarantees of the CHN, we propose the Smooth Bellman Operator (SBO), which updates OOD $Q$-values by smoothing them with neighboring in-sample $Q$-values. We theoretically show that SBO approximates true $Q$-values for both in-sample and OOD actions within the CHN. Our practical algorithm, Smooth Q-function OOD Generalization (SQOG), empirically alleviates the over-constraint issue, achieving near-accurate $Q$-value estimation. On the D4RL benchmarks, SQOG outperforms existing state-of-the-art methods in both performance and computational efficiency."
    },
    {
        "title": "Teleporter Theory: A General and Simple Approach for Modeling Cross-World Counterfactual Causality",
        "link_suffix": "/forum?id=FpxKYYk6V5",
        "link": "https://openreview.net/forum?id=FpxKYYk6V5",
        "pdf_link": "https://openreview.net/pdf?id=FpxKYYk6V5",
        "keywords": "Cross-World, Counterfactual, Causal Model",
        "abstract": "Leveraging the development of structural causal model (SCM), researchers can establish graphical models for exploring the causal mechanisms behind machine learning techniques. As the complexity of machine learning applications rises, single-world interventionism causal analysis encounters theoretical adaptation limitations. Accordingly, cross-world counterfactual approach extends our understanding of causality beyond observed data, enabling hypothetical reasoning about alternative scenarios. However, the joint involvement of cross-world variables, encompassing counterfactual variables and factual variables, challenges the construction of the graphical model. Existing approaches, e.g., Twin Network and Single World Intervention Graphs (SWIG), establish a symbiotic relationship to bridge the gap between graphical modeling and the introduction of counterfactuals albeit with room for improvement in generalization. In this regard, we demonstrate the theoretical limitations of certain current methods in cross-world counterfactual scenarios. To this end, we propose a novel teleporter theory to establish a general and simple graphical representation of counterfactuals, which provides criteria for determining teleporter variables to connect multiple worlds. In theoretical application, we determine that introducing the proposed teleporter theory can directly obtain the conditional independence between counterfactual variables and factual variables from the cross-world SCM without requiring complex algebraic derivations. Accordingly, we can further identify counterfactual causal effects through cross-world symbolic derivation. We demonstrate the generality of the teleporter theory to the practical application. Adhering to the proposed theory, we build a plug-and-play module, and the effectiveness of which are substantiated by experiments on benchmarks."
    },
    {
        "title": "ROSE: Register-Assisted General Time Series Forecasting with Decomposed Frequency Learning",
        "link_suffix": "/forum?id=tdttNKCtyB",
        "link": "https://openreview.net/forum?id=tdttNKCtyB",
        "pdf_link": "https://openreview.net/pdf?id=tdttNKCtyB",
        "keywords": "Time series forecasting",
        "abstract": "With the increasing collection of time series data from various domains, there arises a strong demand for general time series forecasting models pre-trained on a large number of time-series datasets to support a variety of downstream prediction tasks. Enabling general time series forecasting faces two challenges: how to obtain unified representations from multi-domian time series data, and how to capture domain-specific features from time series data across various domains for adaptive transfer in downstream tasks. To address these challenges, we propose a Register-Assisted General Time Series Forecasting Model with Decomposed Frequency Learning (ROSE), a novel pre-trained model for time series forecasting. ROSE employs  Decomposed Frequency Learning for the pre-training task, which decomposes coupled semantic information in time series with frequency-based masking and reconstruction to obtain unified representations across domains. We also equip ROSE with a Time Series Register, which learns to generate a register to capture domain-specific representations during pre-training and enhances domain-adaptive transfer by selecting related register tokens on downstream tasks. After pre-training on large-scale time series data, ROSE achieves state-of-the-art forecasting performance on 7 real-world benchmarks. Remarkably, it demonstrates competitive or superior few-shot and zero-shot abilities."
    },
    {
        "title": "C-Adapter: Adapting Deep Classifiers for Efficient Conformal Prediction Sets",
        "link_suffix": "/forum?id=8Gqz2opok1",
        "link": "https://openreview.net/forum?id=8Gqz2opok1",
        "pdf_link": "https://openreview.net/pdf?id=8Gqz2opok1",
        "keywords": "uncertainty estimation, conformal prediction, classification",
        "abstract": "Conformal prediction, as an emerging uncertainty quantification technique, typically functions as post-hoc processing for the outputs of trained classifiers. To optimize the classifier for maximum predictive efficiency, Conformal Training rectifies the training objective with a regularization that minimizes the average prediction set size at a specific error rate. However, the regularization term inevitably deteriorates the classification accuracy and leads to suboptimal efficiency of conformal predictors. To address this issue, we introduce \\textbf{Conformal Adapter} (C-Adapter), an adapter-based tuning method to enhance the efficiency of conformal predictors without sacrificing accuracy. In particular, we implement the adapter as a class of intra order-preserving functions and tune it with our proposed loss that maximizes the discriminability of non-conformity scores between correctly and randomly matched data-label pairs. Using C-Adapter, the model tends to produce extremely high non-conformity scores for incorrect labels, thereby enhancing the efficiency of prediction sets across different coverage rates. Extensive experiments demonstrate that C-Adapter can effectively adapt various classifiers for efficient prediction sets, as well as enhance the conformal training method."
    },
    {
        "title": "Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models",
        "link_suffix": "/forum?id=MpCxUF8x61",
        "link": "https://openreview.net/forum?id=MpCxUF8x61",
        "pdf_link": "https://openreview.net/pdf?id=MpCxUF8x61",
        "keywords": "Synthetic Data, Large Language Model, Instruction Tuning, Human Education Inspired Method",
        "abstract": "We introduce Generalized Instruction Tuning (called GLAN), a general and scalable method for instruction tuning of Large Language Models (LLMs). \nUnlike prior work that relies on seed examples or existing datasets to construct instruction-tuning data, \nGLAN exclusively utilizes a pre-curated taxonomy of human knowledge and capabilities as input and generates large-scale \nsynthetic instruction data across all disciplines.\nSpecifically, inspired by the systematic structure in human education system, we build the taxonomy by decomposing human knowledge and capabilities to various fields, sub-fields and ultimately, distinct disciplines semi-automatically, facilitated by LLMs. \nSubsequently, we generate a comprehensive list of subjects for every discipline and proceed to design a syllabus tailored to each subject, again utilizing LLMs.\nWith the fine-grained key concepts detailed in every class session of the syllabus, we are able to generate diverse instructions with a broad coverage across the entire spectrum of human knowledge and skills. \nExtensive experiments on large language models (e.g., Mistral) demonstrate that GLAN excels in multiple dimensions from mathematical reasoning, coding, academic exams, logical reasoning to general instruction following without using task-specific training data of these tasks. In addition, GLAN allows for easy customization and new\nfields or skills can be added by simply incorporating a new node into our taxonomy."
    },
    {
        "title": "IMAC: Implicit Motion-Audio Coupling for Co-Speech Gesture Video Generation",
        "link_suffix": "/forum?id=kmhNK0fs8c",
        "link": "https://openreview.net/forum?id=kmhNK0fs8c",
        "pdf_link": "https://openreview.net/pdf?id=kmhNK0fs8c",
        "keywords": "co-speech gesture video generation; diffusion model; video generation",
        "abstract": "Co-speech gestures are essential to non-verbal communication, enhancing both the naturalness and effectiveness of human interaction. Although recent methods have made progress in generating co-speech gesture videos, many rely on explicit visual controls, such as pose images or TPS keypoint movements, which often lead to artifacts like inconsistent backgrounds, blurry hands, and distorted fingers. In response to these challenges, we present the Implicit Motion-Audio Coupling (IMAC) method for co-speech gesture video generation. IMAC strengthens audio control by coupling implicit motion parameters, including pose and expression, with audio inputs. Our method utilizes a two-branch framework that combines an audio-to-motion generation branch with a video diffusion branch, enabling realistic gesture generation without requiring additional inputs during inference. To improve training efficiency, we propose a two-stage slow-fast training strategy that balances memory constraints while facilitating the learning of meaningful gestures from long frame sequences. Furthermore, we introduce a large-scale dataset designed for co-speech gesture video generation and demonstrate that our method achieves state-of-the-art performance on this benchmark."
    },
    {
        "title": "Deep Learning Algorithms for Mean Field Optimal Stopping in Finite Space and Discrete Time",
        "link_suffix": "/forum?id=PPTE1DL4Li",
        "link": "https://openreview.net/forum?id=PPTE1DL4Li",
        "pdf_link": "https://openreview.net/pdf?id=PPTE1DL4Li",
        "keywords": "Optimal Stopping, Mean Field, Deep Learning, Dynamic Programming",
        "abstract": "Optimal stopping is a fundamental problem in optimization that has found applications in risk management, finance, economics, and recently in the fields of computer science. We extend the standard framework to a multi-agent setting, named multi-agent optimal stopping (MAOS), where a group of agents cooperatively solves finite-space, discrete-time optimal stopping problems. Solving the finite-agent case is computationally prohibitive when the number of agents is very large, so this work studies the mean field optimal stopping (MFOS) problem, obtained as the number of agents approaches infinity. We prove that MFOS provides a good approximate solution to MAOS. We also prove a dynamic programming principle (DPP), based on the theory of mean field control. We then propose two deep learning methods: one simulates full trajectories to learn optimal decisions, whereas the other leverages DPP with backward induction; both methods train neural networks for the optimal stopping decisions. We demonstrate the effectiveness of these approaches through numerical experiments on 6 different problems in spatial dimension up to 300. To the best of our knowledge, this is the first work to study MFOS in finite space and discrete time, and to propose efficient and scalable computational methods for this type of problems."
    },
    {
        "title": "Mimicking Human Intuition: Cognitive Belief-Driven Q-Learning",
        "link_suffix": "/forum?id=kqtWI3l8jM",
        "link": "https://openreview.net/forum?id=kqtWI3l8jM",
        "pdf_link": "https://openreview.net/pdf?id=kqtWI3l8jM",
        "keywords": "Reinforcement Learning, Cognitive Science, Human-like Computing",
        "abstract": "Reinforcement learning encounters challenges in various environments related to robustness and explainability. Traditional Q-learning algorithms cannot effectively make decisions and utilize the historical learning experience. To overcome these limitations, we propose Cognitive Belief-Driven Q-Learning (CBDQ), which integrates subjective belief modeling into the Q-learning framework, enhancing decision-making accuracy by endowing agents with human-like learning and reasoning capabilities. Drawing inspiration from cognitive science, our method maintains a subjective belief distribution over the expectation of actions, leveraging a cluster-based subjective belief model that enables agents to reason about the potential probability associated with each decision. CBDQ effectively mitigates overestimated phenomena and optimizes decision-making policies by integrating historical experiences with current contextual information, mimicking the dynamics of human decision-making. We evaluate the proposed method on discrete control benchmark tasks in various complicate environments. The results demonstrate that CBDQ exhibits stronger adaptability, robustness, and human-like characteristics in handling these environments, outperforming other baselines. We hope this work will give researchers a fresh perspective on understanding and explaining Q-learning."
    }
]
[{"title": "Steering Language Models with Activation Engineering", "link_suffix": "/forum?id=2XBPdPIcFK", "link": "https://openreview.net/forum?id=2XBPdPIcFK", "pdf_link": "https://openreview.net/pdf?id=2XBPdPIcFK", "keywords": "interpretability, steering, alignment, safety, sentiment", "abstract": "Prompt engineering and finetuning aim to maximize language model performance on a given metric, like toxicity reduction. However, these methods do not fully elicit a model\u2019s capabilities. To reduce this gap, we introduceactivation engineering: the inference-time modification of activations in order to control (orsteer) model outputs. Specifically, we introduce theActivation Addition(ActAdd) technique, which contrasts the intermediate activations on prompt pairs (such as \u201cLove\u201d versus \u201cHate\u201d) to compute asteering vector. By tactically adding in e.g. the \u201cLove\u201d\u2212\u201cHate\u201d steering vector during the forward pass, we achieve SOTA on negative-to-positive sentiment shift and detoxification using models including LLaMA-3 and OPT. ActAdd yields inference-time control over high-level properties of output (like topic and sentiment) while preserving performance on off-target tasks. ActAdd is lightweight: it does not require any machine optimization and works with a single pair of data points, which enables rapid iteration over steering. ActAdd demonstrates the power of activation engineering.", "title_embedding_index": 10100, "title_abs_embedding_index": 10125}, {"title": "Optimizing Learning for Robust Hyperbolic Deep Learning in Computer Vision", "link_suffix": "/forum?id=WOopKWDWtS", "link": "https://openreview.net/forum?id=WOopKWDWtS", "pdf_link": "https://openreview.net/pdf?id=WOopKWDWtS", "keywords": "Hyperbolic machine learning, hyperbolic computer vision", "abstract": "Hyperbolic deep learning has become a growing research direction in computer vision for the unique properties afforded by the alternate embedding space. The negative curvature and exponentially growing distance metric provide a natural framework for capturing hierarchical relationships between datapoints and allowing for finer separability between their embeddings. However, these methods are still computationally expensive and prone to instability, especially when attempting to learn the negative curvature that best suits the task and the  data. Current Riemannian optimizers do not account for changes in the manifold which greatly harms performance and forces lower learning rates to minimize projection errors. Our paper focuses on curvature learning by introducing an improved schema for popular learning algorithms and providing a novel normalization approach to constrain embeddings within the variable representative radius of the manifold. Additionally, we introduce a novel formulation for Riemannian AdamW, and alternative hybrid encoder techniques and foundational formulations for current convolutional hyperbolic operations, greatly reducing the computational penalty of the hyperbolic embedding space. Our approach demonstrates consistent performance improvements across direct classification, generation, and hierarchical metric learning tasks while allowing for larger hyperbolic models.", "title_embedding_index": 10101, "title_abs_embedding_index": 10126}, {"title": "Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix", "link_suffix": "/forum?id=sgbI8Pxwie", "link": "https://openreview.net/forum?id=sgbI8Pxwie", "pdf_link": "https://openreview.net/pdf?id=sgbI8Pxwie", "keywords": "Weights Pruning, Attention Approximation, Gradient Descent Optimization", "abstract": "Large Language Models (LLMs) have shown immense potential in enhancing various aspects of our daily lives, from conversational AI to search and AI assistants. However, their growing capabilities come at the cost of extremely large model sizes, making deployment on edge devices challenging due to memory and computational constraints. \nThis paper introduces a novel approach to LLM weight pruning that directly optimizes for approximating the attention matrix, a core component of transformer architectures. \nUnlike existing methods that focus on linear approximations, our approach accounts for the non-linear nature of the Softmax attention mechanism. \nWe provide theoretical guarantees for the convergence of our Gradient Descent-based optimization method to a near-optimal pruning mask solution. \nOur preliminary empirical results demonstrate the effectiveness of this approach in maintaining model performance while significantly reducing computational costs. \nThis work establishes a new theoretical foundation for pruning algorithm design in LLMs, potentially paving the way for more efficient LLM inference on resource-constrained devices.", "title_embedding_index": 10102, "title_abs_embedding_index": 10127}, {"title": "Closed-Form Merging of Parameter-Efficient Modules for Federated Continual Learning", "link_suffix": "/forum?id=ROpY0qRUXL", "link": "https://openreview.net/forum?id=ROpY0qRUXL", "pdf_link": "https://openreview.net/pdf?id=ROpY0qRUXL", "keywords": "model merging, federated continual learning, federated learning, continual learning", "abstract": "Model merging has emerged as a crucial technique in Deep Learning, enabling the integration of multiple models into a unified system while preserving performance and scalability. In this respect, the compositional properties of low-rank adaptation techniques (e.g., LoRA) have proven beneficial, as simple averaging LoRA modules yields a single model that mostly integrates the capabilities of all individual modules. Building on LoRA, we take a step further by imposing that the merged model matches the responses of all learned modules. Solving this ob-\njective in closed form yields an indeterminate system with A and B as unknown variables, indicating the existence of infinitely many closed-form solutions. To address this challenge, we introduce LoRM, an alternating optimization strategy that trains one LoRA matrix at a time. This allows solving for each unknown variable individually, thus finding a unique solution. We apply our proposed methodology to Federated Class-Incremental Learning (FCIL), ensuring alignment of model responses both between clients and across tasks. Our method demonstrates state-of-the-art performance across a range of FCIL scenarios.", "title_embedding_index": 10103, "title_abs_embedding_index": 10128}, {"title": "Unifying and Verifying Mechanistic Interpretations: A Case Study with Group Operations", "link_suffix": "/forum?id=8xxEBAtD7y", "link": "https://openreview.net/forum?id=8xxEBAtD7y", "pdf_link": "https://openreview.net/pdf?id=8xxEBAtD7y", "keywords": "mechanistic interpretability, verification, proof, guarantees, interpretability, equivariance, group theory, representation theory", "abstract": "A recent line of work in mechanistic interpretability has focused on reverse-engineering the computation performed by neural networks trained on the binary operation of finite groups. We investigate the internals of one-hidden-layer neural networks trained on this task, revealing previously unidentified structure and producing a more complete description of such models that unifies the explanations of previous works. Notably, these models approximate equivariance in each input argument. We verify that our explanation applies to a large fraction of networks trained on this task by translating it into a compact proof of model performance, a quantitative evaluation of model understanding.", "title_embedding_index": 10104, "title_abs_embedding_index": 10129}, {"title": "A Unified Causal Framework for Auditing Recommender Systems for Ethical Concerns", "link_suffix": "/forum?id=0vMLqSdsKW", "link": "https://openreview.net/forum?id=0vMLqSdsKW", "pdf_link": "https://openreview.net/pdf?id=0vMLqSdsKW", "keywords": "recommender systems, causality, evaluation, auditing, machine learning", "abstract": "As recommender systems become widely deployed in different domains, they increasingly influence their users\u2019 beliefs and preferences. Auditing recommender systems is crucial as it not only ensures the improvement of recommendation algorithms but also provides ways to assess and address ethical concerns surrounding them. In this work, we view recommender system auditing from a causal lens and provide a general recipe for defining auditing metrics. Under this general causal auditing framework, we categorize existing auditing metrics and identify gaps in them\u2014notably, the lack of metrics for auditing user agency while accounting for the multi-step dynamics of the recommendation process. We leverage our framework and propose two classes of such metrics: future- and past-reachability and stability, that measure the ability of a user to influence their own and other users\u2019 recommendations, respectively. We provide both a gradient-based and a black-box approach for computing these metrics, allowing the auditor to compute them under different levels of access to the recommender system. Empirically, we demonstrate the efficacy of methods for computing the proposed metrics and inspect the design of recommender systems through these proposed metrics.", "title_embedding_index": 10105, "title_abs_embedding_index": 10130}, {"title": "Enhancing Multi-Agent Learning in Real-World Interactive Environments through Process Reward Decomposition", "link_suffix": "/forum?id=E2CR6hmV1I", "link": "https://openreview.net/forum?id=E2CR6hmV1I", "pdf_link": "https://openreview.net/pdf?id=E2CR6hmV1I", "keywords": "Language model, Muti-agent learning", "abstract": "LLM-based agents have made significant advancements in interactive environments, such as mobile operations and web browsing, with multi-agent systems further boosting performance. However, current agent learning techniques heavily rely on in-domain data and struggle to generalize across tasks and environments. Moreover, existing multi-agent learning methods are limited by fixed role assignments, which restrict their flexibility and generalization. Furthermore, the multi-step nature of interactive tasks, combined with sparse end-to-end reward signals, hinder effective learning to a great extent. To address these issues, we propose $\\textit{CollabUIAgents}$, a two-stage multi-agent learning framework for interactive environments. In the first stage, the base model is adapted to the environment using curriculum learning on multi-level instruction data. In the second stage, a novel process reward decomposition strategy is introduced during reinforcement learning, allowing rewards to be distributed at both the agent and conversation round levels. This granular feedback fosters collaborative awareness among agents without predefined roles and improves learning efficacy. Experimental results show that our method significantly enhances the performance of multi-agent systems based on open-source models, achieving notable improvements both within and across domains, while also exhibiting strong cross-environment generalization capabilities. Moreover, our best-performing systems achieve results on par with or exceed those of the strong closed-source models, while maintaining the flexibility to be integrated with prompt-based multi-agent systems for future research.", "title_embedding_index": 10106, "title_abs_embedding_index": 10131}, {"title": "Eliminating Position Bias of Language Models: A Mechanistic Approach", "link_suffix": "/forum?id=fvkElsJOsN", "link": "https://openreview.net/forum?id=fvkElsJOsN", "pdf_link": "https://openreview.net/pdf?id=fvkElsJOsN", "keywords": "Position Bias, Languague Models", "abstract": "Position bias has proven to be a prevalent issue of modern language models (LMs), where the models prioritize content based on its position within the given context. This bias often leads to unexpected model failures and hurts performance, robustness, and reliability across various applications. Our mechanistic analysis attributes the position bias to two components employed in nearly all state-of-the-art LMs: causal attention and relative positional encodings. Based on the analyses, we propose toeliminateposition bias (e.g., different retrieved documents' orders in QA affect performance) with atraining-free zero-shotapproach. Our method changes the causal attention to bidirectional attention between documents and utilizes model attention values to decide the relative orders of documents instead of using the order provided in input prompts, therefore enabling Position-INvariant inferencE (PINE) at the document level. By eliminating position bias, models achieve better performance and reliability in downstream tasks, including LM-as-a-judge, retrieval-augmented QA, molecule generation, and math reasoning. Notably, PINE is especially useful when adapting LMs for evaluating reasoning pairs: it consistently provides $8$ to $10$ percentage points performance gains, making Llama-3-70B-Instruct perform even better than GPT-4-0125-preview and GPT-4o-2024-08-06 on the RewardBench reasoning set.", "title_embedding_index": 10107, "title_abs_embedding_index": 10132}, {"title": "Continuous-Time Analysis of Adaptive Optimization and Normalization", "link_suffix": "/forum?id=gC0ikdZoz8", "link": "https://openreview.net/forum?id=gC0ikdZoz8", "pdf_link": "https://openreview.net/pdf?id=gC0ikdZoz8", "keywords": "Theory of Deep Learning, Adaptive Optimization, Continuous-Time Analysis, Normalization", "abstract": "Adaptive optimization algorithms, particularly Adam and its variant AdamW, are fundamental to modern deep learning, however, their training dynamics lack comprehensive theoretical understanding, with limited insight into why common practices\u2014such as specific hyperparameter choices and normalization layers\u2014contribute to successful generalization. This work presents a continuous-time formulation of Adam and AdamW, facilitating a tractable analysis of training dynamics that can shed light on such practical questions. We theoretically derive a stable region for Adam's hyperparameters $(\\beta, \\gamma)$ that ensures bounded updates, empirically verifying these predictions by observing unstable exponential growth of parameter updates outside this region. Furthermore, we theoretically justify the success of normalization layers by uncovering an implicit meta-adaptive effect of scale-invariant architectural components. This insight leads to an explicit optimizer, $2$-Adam, which we generalize to $k$-Adam\u2014an optimizer that applies an adaptive normalization procedure $k$ times, encompassing Adam (corresponding to $k=1$) and Adam with a normalization layer (corresponding to $k=2$). Overall, our continuous-time formulation of Adam facilitates a principled analysis, offering deeper understanding of optimal hyperparameter choices and architectural decisions in modern deep learning.", "title_embedding_index": 10108, "title_abs_embedding_index": 10133}, {"title": "From Tokens to Lattices: Emergent Lattice Structures in Language Models", "link_suffix": "/forum?id=md9qolJwLl", "link": "https://openreview.net/forum?id=md9qolJwLl", "pdf_link": "https://openreview.net/pdf?id=md9qolJwLl", "keywords": "Masked Language Models, Formal Concept Analysis, Interpretability", "abstract": "Pretrained masked language models (MLMs) have demonstrated an impressive capability to comprehend and encode conceptual knowledge, revealing a lattice structure among concepts. This raises a critical question: how does this conceptualization emerge from MLM pretraining? In this paper, we explore this problem from the perspective of Formal Concept Analysis (FCA), a mathematical framework that derives concept lattices from the observations of object-attribute relationships. We show that the MLM's objective implicitly learns a formal context that describes objects, attributes, and their dependencies, which enables the reconstruction of a concept lattice through FCA. We propose a novel framework for concept lattice construction from pretrained MLMs and investigate the origin of the inductive biases of MLMs in lattice structure learning. Our framework differs from previous work because it does not rely on human-defined concepts and allows for discovering \"latent\" concepts that extend beyond human definitions. We create three datasets for evaluation, and the empirical results verify our hypothesis.", "title_embedding_index": 10109, "title_abs_embedding_index": 10134}, {"title": "Clusters Agnostic Network Lasso Bandits", "link_suffix": "/forum?id=KWUFlIMn8A", "link": "https://openreview.net/forum?id=KWUFlIMn8A", "pdf_link": "https://openreview.net/pdf?id=KWUFlIMn8A", "keywords": "multitask learning, contextual bandits, graph total variation, network lasso, clustering", "abstract": "We consider a multi-task contextual bandit setting, where the learner is given a graph encoding relations between the bandit tasks. The tasks' preference vectors are assumed to be piecewise constant over the graph, forming clusters. At every round, we estimate the preference vectors by solving an online network lasso problem with a suitably chosen, time-dependent regularization parameter. We establish a novel oracle inequality relying on a convenient restricted eigenvalue assumption. Our theoretical findings highlight the importance of dense intra-cluster connections and sparse inter-cluster ones. That results in a sublinear regret bound significantly lower than its counterpart in the independent task learning setting. Finally, we support our theoretical findings by experimental evaluation against graph bandit multi-task learning and online clustering of bandits algorithms.", "title_embedding_index": 10110, "title_abs_embedding_index": 10135}, {"title": "Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge", "link_suffix": "/forum?id=lbj0i29Z92", "link": "https://openreview.net/forum?id=lbj0i29Z92", "pdf_link": "https://openreview.net/pdf?id=lbj0i29Z92", "keywords": "self-improving, self-rewarding, LLM, LLM-as-a-judge, instruction following, super alignment", "abstract": "Large Language Models (LLMs) are rapidly surpassing human knowledge in many domains. While improving these models traditionally relies on costly human data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs can improve by judging their own responses instead of relying on human labelers. However, existing methods have primarily focused on improving model responses rather than judgment capabilities, resulting in rapid saturation during iterative training. To address this issue, we introduce a novel Meta-Rewarding step to the self-improvement process, where the model judges its own judgements and uses that feedback to refine its judgment skills. Surprisingly, this unsupervised approach improves the model's ability to judge and follow instructions, as demonstrated by a win rate improvement of Llama-3-8B-Instruct from 22.9% to 39.4% on AlpacaEval 2, and 20.6% to 29.1% on Arena-Hard. These results strongly suggest the potential for self-improving models without human supervision.", "title_embedding_index": 10111, "title_abs_embedding_index": 10136}, {"title": "Demystifying Topological Message-Passing with Relational Structures: A Case Study on Oversquashing in Simplicial Message-Passing", "link_suffix": "/forum?id=QC2qE1tcmd", "link": "https://openreview.net/forum?id=QC2qE1tcmd", "pdf_link": "https://openreview.net/pdf?id=QC2qE1tcmd", "keywords": "topological deep learning, oversquashing, rewiring, relational graph neural networks, simplicial complexes, relational structures", "abstract": "Topological deep learning (TDL) has emerged as a powerful tool for modeling higher-order interactions in relational data. However, phenomena such as oversquashing in topological message-passing remain understudied and lack theoretical analysis. We propose a unifying axiomatic framework that bridges graph and topological message-passing by viewing simplicial and cellular complexes and their message-passing schemes through the lens of relational structures. This approach extends graph-theoretic results and algorithms to higher-order structures, facilitating the analysis and mitigation of oversquashing in topological message-passing networks. Through theoretical analysis and empirical studies on simplicial networks, we demonstrate the potential of this framework to advance TDL.", "title_embedding_index": 10112, "title_abs_embedding_index": 10137}, {"title": "EOP: Unlocking Superior Problem Solving in Small LLMs", "link_suffix": "/forum?id=YZRgB5DnXw", "link": "https://openreview.net/forum?id=YZRgB5DnXw", "pdf_link": "https://openreview.net/pdf?id=YZRgB5DnXw", "keywords": "SLM, LLM, Problem-Solvinng, Python Puzzles, Game of 24", "abstract": "Small language models, referred to as LLMs with fewer than 10 billion parameters in this work, face critical challenges in problem-solving\ntasks, often achieving less than 10% accuracy, highlighting the\nurgent need for effective solutions. While much of the existing research has focused on enhancing the performance of larger models like GPT, an important question remains: Can techniques developed for large models be adapted effectively for smaller ones? Moreover, is it possible to improve these smaller models to the point where they rival, or even outperform, larger models such as GPT-4 in problem-solving tasks?In this paper, we introduce Evaluation-Oriented Problem-Solving (EOP), a novel framework aimed at enhancing the problem-solving capabilities of small LLMs. Our approach significantly boosts the performance of these models, achieving a 2% higher accuracy on Python Puzzles compared to standard GPT-4 and a 27% improvement over state-of-the-art prompting methods using GPT-4 in the Game of 24. Beyond these results, EOP also demonstrates notable accuracy improvements on other tasks. These findings suggest that, with the appropriate strategies, small LLMs can achieve substantial performance gains in problem-solving, challenging the prevailing notion that scaling model size is the primary path to improvement.", "title_embedding_index": 10113, "title_abs_embedding_index": 10138}, {"title": "LEMMA-RCA: A Large Multi-modal Multi-domain Dataset for Root Cause Analysis", "link_suffix": "/forum?id=0R8JUzjSdq", "link": "https://openreview.net/forum?id=0R8JUzjSdq", "pdf_link": "https://openreview.net/pdf?id=0R8JUzjSdq", "keywords": "root cause analysis, multi-modal learning, microservice systems, benchmark data", "abstract": "Root cause analysis (RCA) is crucial for enhancing the reliability and performance of complex systems. However, progress in this field has been hindered by the lack of large-scale, open-source datasets tailored for RCA. To bridge this gap, we introduce LEMMA-RCA, a large dataset designed for diverse RCA tasks across multiple domains and modalities. LEMMA-RCA features various real-world fault scenarios from IT and OT operation systems, encompassing microservices, water distribution, and water treatment systems, with hundreds of system entities involved. We evaluate the quality of LEMMA-RCA by testing the performance of eight baseline methods on this dataset under various settings, including offline and online modes as well as single and multiple modalities. Our experimental results demonstrate the high quality of LEMMA-RCA. The dataset is publicly available athttps://lemma-rca.github.io/.", "title_embedding_index": 10114, "title_abs_embedding_index": 10139}, {"title": "Language Models Can Help to Learn High-Performing Cost Functions for Recourse", "link_suffix": "/forum?id=DTjmv5QJBx", "link": "https://openreview.net/forum?id=DTjmv5QJBx", "pdf_link": "https://openreview.net/pdf?id=DTjmv5QJBx", "keywords": "algorithmic recourse, large language models, cost functions, interpretable ml, user study", "abstract": "Algorithmic recourse is a specialised variant of counterfactual explanation, concerned with offering actionable recommendations to individuals who have received adverse outcomes from automated systems. Most recourse algorithms assume access to a cost function, which quantifies the effort involved in following recommendations. Such functions are useful for filtering down recourse options to those which are most actionable. In this study, we explore the use of large language models (LLMs) to help label data for training recourse cost functions, while preserving important factors such as transparency, fairness, and performance. We find that while LLMs do generally align with human judgements of cost, and can label data for the training of effective cost functions, a high-level schematic of the function parameters should be engineered into the labelling prompt to maximise performance. Previously, recourse cost definitions have mainly relied on heuristics and missed the complexities of feature dependencies and fairness attributes, which has drastically limited their usefulness. Our results show that it is possible to train a high-performing, interpretable cost function by consulting an LLM via careful prompt engineering. Furthermore, these cost functions can be customised to add or remove biases as befitting the domain and problem.\nOverall, this study suggests a simple, accessible method for accurately quantifying notions of cost, effort, or distance between data points that correlate with human intuition, with possible applications throughout the explainable AI field.", "title_embedding_index": 10115, "title_abs_embedding_index": 10140}, {"title": "Generalized Consistency Trajectory Models for Image Manipulation", "link_suffix": "/forum?id=Zjv38dg1Hb", "link": "https://openreview.net/forum?id=Zjv38dg1Hb", "pdf_link": "https://openreview.net/pdf?id=Zjv38dg1Hb", "keywords": "Consistency Models, Image Manipulation", "abstract": "Diffusion-based generative models excel in unconditional generation, as well as on applied tasks such as image editing and restoration. The success of diffusion models lies in the iterative nature of diffusion: diffusion breaks down the complex process of mapping noise to data into a sequence of simple denoising tasks. Moreover, we are able to exert fine-grained control over the generation process by injecting guidance terms into each denoising step. However, the iterative process is also computationally intensive, often taking from tens up to thousands of function evaluations. Although consistency trajectory models (CTMs) enable traversal between any time points along the probability flow ODE (PFODE) and score inference with a single function evaluation, CTMs only allow translation from Gaussian noise to data. Thus, this work aims to unlock the full potential of CTMs by proposing generalized CTMs (GCTMs), which translate between arbitrary distributions via ODEs. We discuss the design space of GCTMs and demonstrate their efficacy in various image manipulation tasks such as image-to-image translation, restoration, and editing.", "title_embedding_index": 10116, "title_abs_embedding_index": 10141}, {"title": "HERTA: A High-Efficiency and Rigorous Training Algorithm for Unfolded Graph Neural Networks", "link_suffix": "/forum?id=r0opxuq8T8", "link": "https://openreview.net/forum?id=r0opxuq8T8", "pdf_link": "https://openreview.net/pdf?id=r0opxuq8T8", "keywords": "Graph Neural Networks, Spectral Sparsificaton, Optimization, Matrix Sketching", "abstract": "As a variant of Graph Neural Networks (GNNs), Unfolded GNNs offer enhanced interpretability and flexibility over traditional designs. Nevertheless, they still suffer from scalability challenges when it comes to the training cost. Although many methods have been proposed to address the scalability issues, they mostly focus on per-iteration efficiency, without worst-case convergence guarantees. Moreover, those methods typically add components to or modify the original model, thus possibly breaking the interpretability of Unfolded GNNs. In this paper, we propose HERTA: a High-Efficiency and Rigorous Training Algorithm for Unfolded GNNs that accelerates the whole training process, achieving a nearly-linear time worst-case training guarantee. Crucially, HERTA converges to the optimum of the original model, thus preserving the interpretability of Unfolded GNNs. Additionally, as a byproduct of HERTA, we propose a new spectral sparsification method applicable to normalized and regularized graph Laplacians that ensures tighter bounds for our algorithm than existing spectral sparsifiers do. Experiments on real-world datasets verify the superiority of HERTA as well as its adaptability to various loss functions and optimizers.", "title_embedding_index": 10117, "title_abs_embedding_index": 10142}, {"title": "DiffTell: A Comprehensive Dataset for Image Difference Captioning", "link_suffix": "/forum?id=86uYj8DcfK", "link": "https://openreview.net/forum?id=86uYj8DcfK", "pdf_link": "https://openreview.net/pdf?id=86uYj8DcfK", "keywords": "Image Difference Caption, Vision Language Task, A Comprehensive Dataset", "abstract": "The image Difference Captioning (IDC) task is to describe the distinctions between two images. However, existing datasets do not offer comprehensive coverage across all image-difference categories. In this work, we introduce a more extensive dataset, \\textit{DiffTell}, which encompasses various types of differences between images, including global image alterations, object-level changes, and text manipulations. \\textit{DiffTell} includes both newly collected data and filtered data used in previous studies. Additionally, to scale up the data collection without prohibitive human labor costs, we explore the possibility of automatically filtering for quality control. We prove that both traditional methods and recent multimodal large language models (MLLMs) show improved performance on the IDC task after training on the \\textit{DiffTell} dataset. We conducted extensive ablation studies to provide a thorough analysis of the performance gain from \\textit{DiffTell}. Experiments show \\textit{DiffTell} significantly enhances the availability of resources for IDC research, offering a more comprehensive foundation and benchmark for future investigations.", "title_embedding_index": 10118, "title_abs_embedding_index": 10143}, {"title": "Matchmaker: Schema Matching with self-improving compositional LLM programs", "link_suffix": "/forum?id=vR2MWaZ3MG", "link": "https://openreview.net/forum?id=vR2MWaZ3MG", "pdf_link": "https://openreview.net/pdf?id=vR2MWaZ3MG", "keywords": "schema matching, data-centric AI, Large Language Models, healthcare", "abstract": "Schema matching -- the task of finding matches between attributes across disparate data sources with different tables and hierarchies -- is critical for creating interoperable machine learning (ML)-ready data. Addressing this fundamental data-centric problem has wide implications, especially in domains like healthcare, finance and e-commerce --- but also has the potential to benefit ML models more generally, by increasing the data available for ML model training. However, schema matching is a challenging ML task due to structural/hierarchical and semantic heterogeneity between different schemas. Previous ML approaches to automate schema matching have either required significant labeled data for model training, which is often unrealistic, or suffer from poor zero-shot performance. To this end, we propose Matchmaker -  a compositional language model program for schema matching, comprised of candidate generation, refinement and confidence scoring. Matchmaker also self-improves in a zero-shot manner without the need for labeled demonstrations via a novel optimization approach, which constructs synthetic in-context demonstrations to guide the language model's reasoning process.  Empirically, we demonstrate on real-world medical schema matching benchmarks that Matchmaker outperforms previous ML-based approaches, highlighting its potential to accelerate data integration and interoperability of ML-ready data.", "title_embedding_index": 10119, "title_abs_embedding_index": 10144}, {"title": "Fair Submodular Cover", "link_suffix": "/forum?id=ULorFBST6X", "link": "https://openreview.net/forum?id=ULorFBST6X", "pdf_link": "https://openreview.net/pdf?id=ULorFBST6X", "keywords": "discrete optimization, submodular cover, fairness", "abstract": "Machine learning algorithms are becoming increasing prevalent in the modern world, and as a result there has been significant recent study into algorithmic fairness in order to minimize the possibility of unintentional bias or discrimination in these algorithms. Submodular optimization problems also arise in many machine learning applications, including those such as data summarization and clustering where fairness is an important concern. In this paper, we initiate the study of the Fair Submodular Cover Problem (FSC). Given a ground set $U$, a monotone submodular function $f:2^U\\to\\mathbb{R}_{\\ge 0}$, and a threshold $\\tau$, the goal of FSC is to find a balanced subset of $U$ with minimum cardinality such that $f(S)\\ge\\tau$. We first introduce discrete algorithms for FSC that achieve a bicriteria approximation ratio of $(\\frac{1}{\\varepsilon}, 1-O(\\varepsilon))$. We then present a continuous algorithm that achieves a $(\\ln\\frac{1}{\\varepsilon}, 1-O(\\varepsilon))$-bicriteria approximation ratio, which matches the best approximation guarantee of submodular cover without a fairness constraint. Finally, we complement our theoretical results with a number of empirical evaluations that demonstrate the efficiency of our algorithms on instances of maximum coverage.", "title_embedding_index": 10120, "title_abs_embedding_index": 10145}, {"title": "Revealing the 3D Cosmic Web through Gravitationally Constrained Neural Fields", "link_suffix": "/forum?id=Ax0i933gtp", "link": "https://openreview.net/forum?id=Ax0i933gtp", "pdf_link": "https://openreview.net/pdf?id=Ax0i933gtp", "keywords": "computational imaging, signal processing, inverse problems, astrophysics, cosmology, neural fields, machine learning for physical sciences", "abstract": "Weak gravitational lensing is the slight distortion of galaxy shapes caused primarily by the gravitational effects of dark matter in the universe. In our work, we seek to invert the weak lensing signal from 2D telescope images to reconstruct a 3D map of the universe\u2019s dark matter field. While inversion typically yeilds a 2D projection of the dark matter field, accurate 3D maps of the dark matter distribution are essential for localizing structures of interest and testing theories of our universe. However, 3D inversion poses signficant challenges. First, unlike standard 3D reconstruction that relies on multiple viewpoints, in this case, images are only observed from a single viewpoint. This challenge can be partially addressed by observing how galaxy emitters throughout the volume are lensed. However, this leads to the second challenge: the shapes and exact locations of unlensed galaxies are unknown, and can only be estimated with a very large degree of uncertainty. This introduces an overwhelming amount of noise which nearly drowns out the lensing signal completely. Previous approaches tackle this by imposing strong assumptions about the structures in the volume.  We instead propose a methodology using a gravitationally-constrained neural field to flexibly model the continuous matter distribution. We take an analysis-by-synthesis approach, optimizing the weights of the neural network through a fully differentiable physical forward model to reproduce the lensing signal present in image measurements. We showcase our method on simulations, including realistic simulated measurements of dark matter distributions that mimic data from upcoming telescope surveys. Our results show that our method can not only outperform previous methods, but importantly is also able to recover potentially surprising dark matter structures.", "title_embedding_index": 10121, "title_abs_embedding_index": 10146}, {"title": "Dynamics of Concept Learning and Compositional Generalization", "link_suffix": "/forum?id=s1zO0YBEF8", "link": "https://openreview.net/forum?id=s1zO0YBEF8", "pdf_link": "https://openreview.net/pdf?id=s1zO0YBEF8", "keywords": "compositional generalization, concept learning, learning dynamics, out of distribution generalization", "abstract": "Prior work has shown that text-conditioned diffusion models can learn to identify and manipulate primitive concepts underlying a compositional data-generating process, enabling generalization to entirely novel, out-of-distribution compositions. \nBeyond performance evaluations, these studies develop a rich empirical phenomenology of learning dynamics, showing that models generalize sequentially, respecting the compositional hierarchy of the data-generating process. \nMoreover, concept-centric structures within the data significantly influence a model's speed of learning the ability to manipulate a concept.\nIn this paper, we aim to better characterize these empirical results from a theoretical standpoint.\nSpecifically, we propose an abstraction of prior work's compositional generalization problem by introducing a structured identity mapping (SIM) task, where a model is trained to learn the identity mapping on a Gaussian mixture with structurally organized centroids. \nWe mathematically analyze the learning dynamics of neural networks trained on this SIM task and show that, despite its simplicity, SIM's learning dynamics capture and help explain key empirical observations on compositional generalization with diffusion models identified in prior work.\nOur theory also offers several new insights---e.g., we find a novel mechanism for non-monotonic learning dynamics of test loss in early phases of training.\nWe validate our new predictions by training a text-conditioned diffusion model, bridging our simplified framework and complex generative models.\nOverall, this work establishes the SIM task as a meaningful theoretical abstraction of concept learning dynamics in modern generative models.", "title_embedding_index": 10122, "title_abs_embedding_index": 10147}, {"title": "MotherNet: Fast Training and Inference via Hyper-Network Transformers", "link_suffix": "/forum?id=6H4jRWKFc3", "link": "https://openreview.net/forum?id=6H4jRWKFc3", "pdf_link": "https://openreview.net/pdf?id=6H4jRWKFc3", "keywords": "hypernetwork, tabular data, meta-learning, foundational models", "abstract": "Foundation models are transforming machine learning across many modalities, with in-context learning replacing classical model training. Recent work on tabular data hints at a similar opportunity to build foundation models for classification for numerical data. However, existing meta-learning approaches can not compete with tree-based methods in terms of inference time. In this paper, we propose MotherNet, a hypernetwork architecture trained on synthetic classification tasks that, once prompted with a never-seen-before training set generates the weights of a trained ``child'' neural-network by in-context learning using a single forward pass. In contrast to most existing hypernetworks that are usually trained for relatively constrained multi-task settings, MotherNet can create models for multiclass classification on arbitrary tabular datasets without any dataset specific gradient descent.\nThe child network generated by MotherNet outperforms neural networks trained using gradient descent on small datasets, and is competitive with predictions by TabPFN and standard ML methods like Gradient Boosting. Unlike a direct application of TabPFN, MotherNet generated networks are highly efficient at inference time.", "title_embedding_index": 10123, "title_abs_embedding_index": 10148}, {"title": "Inference-time Alignment of LLMs at the Token Level", "link_suffix": "/forum?id=HgAS03GU4J", "link": "https://openreview.net/forum?id=HgAS03GU4J", "pdf_link": "https://openreview.net/pdf?id=HgAS03GU4J", "keywords": "large language models, alignment, natural language reasoning, inference-time algorithm", "abstract": "Large language models (LLMs) require alignment\u2014such as instruction-tuning or reinforcement learning from human feedback\u2014to effectively and safely follow user instructions. This process necessitates training aligned versions for every model size in each model family, resulting in significant computational overhead. In this work, we propose nudging, a simple, plug-and-play, and training-free algorithm that aligns any base model at inference time using a small aligned model. Nudging is motivated by recent findings that alignment primarily alters the model\u2019s behavior on a small subset of stylistic tokens, such as \"Sure\" or \"Thank\". We find that base models are significantly more uncertain when generating these tokens. Leveraging this observation, nudging employs a small aligned model to generate nudging tokens to steer the large base model's output toward desired directions when the base model's uncertainty is high. We evaluate the effectiveness of nudging across 3 model families and 13 tasks, covering reasoning, general knowledge, instruction following, and safety benchmarks. Without any additional training, nudging a large base model with a 7\u00d7 - 14\u00d7 smaller aligned model achieves zero-shot performance comparable to, and sometimes surpassing, that of large aligned models. For example, nudging OLMo-7b with OLMo-1b-instruct\u2014affecting less than 9% of tokens\u2014achieves a 10% absolute improvement on GSM8K over OLMo-7b-instruct. Unlike prior inference-time tuning methods, nudging enables off-the-shelf collaboration between model families. For instance, nudging Gemma-2-27b with Llama-2-7b-chat outperforms Llama-2-70b-chat on various tasks. Overall, this work introduces a simple yet powerful approach to token-level model collaboration, offering a modular solution to LLM alignment.", "title_embedding_index": 10124, "title_abs_embedding_index": 10149}]
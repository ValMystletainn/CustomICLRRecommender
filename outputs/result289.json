[
    {
        "title": "MAI: A Multi-turn Aggregation-Iteration Model for Composed Image Retrieval",
        "link_suffix": "/forum?id=gXyWbl71n1",
        "link": "https://openreview.net/forum?id=gXyWbl71n1",
        "pdf_link": "https://openreview.net/pdf?id=gXyWbl71n1",
        "keywords": "Multi-modal, Multi-turn retrieval, Retrospective-based, Composed image retrieval",
        "abstract": "Multi-Turn Composed Image Retrieval (MTCIR) addresses a real-world scenario where users iteratively refine retrieval results by providing additional information until a target meeting all their requirements is found. Existing methods primarily achieve MTCIR through a \"multiple single-turn\" paradigm, wherein methods incorrectly converge on shortcuts that only utilize the most recent turn's image, ignoring attributes from historical turns. Consequently, retrieval failures occur when modification requests involve historical information. We argue that explicitly incorporating historical information into the modified text is crucial to addressing this issue. To this end, we build a new retrospective-based MTCIR dataset,FashionMT, wherein modification demands are highly associated with historical turns. We also propose a Multi-turn Aggregation-Iteration (MAI) model, emphasizing efficient aggregation of multimodal semantics and optimization of information propagation in multi-turn retrieval. Specifically, we propose a new Two-stage Semantic Aggregation (TSA) paradigm coupled with a Cyclic Combination Loss (CCL), achieving improved semantic consistency and modality alignment by progressively interacting the reference image with its caption and the modified text. In addition, we design a Multi-turn Iterative Optimization (MIO) mechanism that dynamically selects representative tokens and reduces redundancy during multi-turn iterations. Extensive experiments demonstrate that the proposed MAI model achieves substantial improvements over state-of-the-art methods."
    },
    {
        "title": "Fat-to-Thin Policy Optimization: Offline Reinforcement Learning with Sparse Policies",
        "link_suffix": "/forum?id=SRjzerUpB2",
        "link": "https://openreview.net/forum?id=SRjzerUpB2",
        "pdf_link": "https://openreview.net/pdf?id=SRjzerUpB2",
        "keywords": "reinforcement learning, offline reinforcement learning, actor critic, sparse policies",
        "abstract": "Sparse continuous policies are distributions that can choose some actions at random yet keep strictly zero probability for the other actions, which are radically different from the Gaussian.\nThey have important real-world implications, e.g. in modeling safety-critical tasks like medicine.\nThe combination of offline reinforcement learning and sparse policies provides a novel paradigm that enables learning completely from logged datasets a safety-aware  sparse policy. \nHowever, sparse policies can cause difficulty with the existing offline algorithms which require evaluating actions that fall outside of the current support.\nIn this paper, we propose  the first offline policy optimization algorithm that tackles this challenge: Fat-to-Thin Policy Optimization (FtTPO).\nSpecifically, we maintain a fat (heavy-tailed) proposal policy that effectively learns from the dataset and injects knowledge to a thin (sparse) policy, which is responsible for interacting with the environment.\nWe instantiate FtTPO with the general $q$-Gaussian family that encompasses both heavy-tailed and sparse policies and verify that it performs favorably in a safety-critical treatment simulation and the standard MuJoCo suite."
    },
    {
        "title": "Compatibility-aware Single-cell Continual Annotation",
        "link_suffix": "/forum?id=0PC9goPpuz",
        "link": "https://openreview.net/forum?id=0PC9goPpuz",
        "pdf_link": "https://openreview.net/pdf?id=0PC9goPpuz",
        "keywords": "Continual Compatible learning; Single-Cell RNA-seq data",
        "abstract": "As massive well-labeled single-cell RNA-seq (scRNA-seq) data are available sequentially, automatic cell type annotation systems would require the model to continuously update to expand their internal cell type library. However, the model could suffer from the catastrophic forgetting phenomenon, in which the performance of the model on the old tasks degrades significantly after it learns a new task. To enable the smooth upgrading of the system, the model must possess the ability to maintain performance on old tasks (stability) and adapt itself to learn new tasks (plasticity). We call such an updating process continual compatible learning. To adapt to this task, we propose a simple yet effective method termed scROD based on sample replay and objective decomposition. Specifically, we first maintain a memory buffer to save some cells from the previous tasks and replay them to learn together with the next incoming tasks. Then we decompose two different training objectives in continual compatible learning, i.e., distinguishing new cell types from old ones and distinguishing between different new ones, to avoid forgetting the model to varying degrees. Lastly, we assign distinct weights for two objectives to obtain a better trade-off between model stability and plasticity than the coupled approach. Comprehensive experiments on various benchmarks show that scROD can outperform existing scRNA-seq annotation methods and learn many cell types continually over a long period."
    },
    {
        "title": "Analytic DAG Constraints for Differentiable DAG Learning",
        "link_suffix": "/forum?id=oCdIo9757e",
        "link": "https://openreview.net/forum?id=oCdIo9757e",
        "pdf_link": "https://openreview.net/pdf?id=oCdIo9757e",
        "keywords": "DAG, Causal Discovery, Structural Learning",
        "abstract": "Recovering underlying Directed Acyclic Graph (DAG) structures from observational data presents a formidable challenge due to the combinatorial nature of the DAG-constrained optimization problem. Recently, researchers have identified gradient vanishing as one of the primary obstacles in differentiable DAG learning and have proposed several DAG constraints to mitigate this issue. By developing the necessary theory to establish a connection between analytic functions and DAG constraints, we demonstrate that analytic functions from the set \n$\\{f(x) = c_0 + \\sum_{i=1}c_ix^i|c_0 \\geqslant 0; \\forall i > 0, c_i > 0; r = \\lim_{i\\rightarrow \\infty}c_{i}/c_{i+1} > 0\\}$\ncan be employed to formulate effective DAG constraints. Furthermore, we establish that this set of functions is closed under several functional operators, including differentiation, summation, and multiplication. Consequently, these operators can be leveraged to create novel DAG constraints based on existing ones. Using these properties, we designed a series of DAG constraints and designed an efficient algorithm to evaluate these DAG constraints. Experiments on various settings show that our DAG constraints outperform previous state-of-the-arts approaches."
    },
    {
        "title": "A Diffusive Data Augmentation Framework for Reconstruction of Complex Network Evolutionary History",
        "link_suffix": "/forum?id=E2OAT195Le",
        "link": "https://openreview.net/forum?id=E2OAT195Le",
        "pdf_link": "https://openreview.net/pdf?id=E2OAT195Le",
        "keywords": "Complex Network, Temporal Network, Diffusion Model, Data Augmentation",
        "abstract": "The evolutionary processes of complex systems contain critical information about their functional characteristics. The generation time of edges can reveal the historical evolution of various networked complex systems, such as protein-protein interaction networks, ecosystems, and social networks. Recovering these evolutionary processes holds significant scientific value, such as aiding in the interpretation of the evolution of protein-protein interaction networks. However, the scarcity of temporally labeled network data poses challenges for predicting edge generation times under current network structures, leading to issues of insufficient data and significant differences between training and prediction networks. To address this, we introduce a diffusion model that learns the generative mechanisms of networks, producing sufficient augmented network data to effectively mitigate issues of limited and incomplete data. Experimental results demonstrate a 13.7% improvement in prediction accuracy using our approach. Moreover, the model can uniformly predict edge generation times across different types of networks, eliminating the need to retrain the model for each specific network, thus significantly enhancing generalization capability and efficiency."
    },
    {
        "title": "Decoupled Graph Energy-based Model for Node Out-of-Distribution Detection on Heterophilic Graphs",
        "link_suffix": "/forum?id=NuVBI4wPMm",
        "link": "https://openreview.net/forum?id=NuVBI4wPMm",
        "pdf_link": "https://openreview.net/pdf?id=NuVBI4wPMm",
        "keywords": "Node OOD detection; Energy-based Models; Graph Neural Network",
        "abstract": "Despite extensive research efforts focused on Out-of-Distribution (OOD) detection on images, OOD detection on nodes in graph learning remains underexplored. The dependence among graph nodes hinders the trivial adaptation of existing approaches that assume inputs to be i.i.d. sampled, since many unique features and challenges specific to graphs are not considered, such as the heterophily issue. Recently, GNNSafe adapted energy-based detection to the graph domain with state-of-the-art performance, however, it has two serious issues: 1) it derives node energy from classification logits without specifically tailored training for modeling data distribution, making it less effective at recognizing OOD data; 2) it highly relies on energy propagation, which is based on homophily assumption and will cause significant performance degradation on heterophilic graphs, where the node tends to have dissimilar distribution with its neighbors. To address the above issues, we suggest training Energy-based Models (EBMs) by Maximum Likelihood Estimation (MLE) to enhance data distribution modeling and removing energy propagation to overcome the heterophily issues. However, training EBMs via MLE requires performing Markov Chain Monte Carlo (MCMC) sampling on both node feature and node neighbors, which is challenging due to the node interdependence and discrete graph topology. To tackle the sampling challenge, we introduce Decoupled Graph Energy-based Model (DeGEM), which decomposes the learning process into two parts\u2014a graph encoder that leverages topology information for node representations and an energy head that operates in latent space. Additionally, we propose a Multi-Hop Graph encoder (MH) and Energy Readout (ERo) to enhance node representation learning, Conditional Energy (CE) for improved EBM training, and Recurrent Update for the graph encoder and energy head to promote each other. This approach avoids sampling adjacency matrices and removes the need for energy propagation to extract graph topology information. Extensive experiments validate that DeGEM, without OOD exposure during training, surpasses previous state-of-the-art methods, achieving an average AUROC improvement of 6.71% on homophilic graphs and 20.29% on heterophilic graphs, and even outperform methods trained with OOD exposure."
    },
    {
        "title": "DualTime: A Dual-Adapter  Language Model for Time Series Multimodal Representation Learning",
        "link_suffix": "/forum?id=oVCVCo3laS",
        "link": "https://openreview.net/forum?id=oVCVCo3laS",
        "pdf_link": "https://openreview.net/pdf?id=oVCVCo3laS",
        "keywords": "Multimodal Representation Learning, Time Series, Large Language Model",
        "abstract": "The recent rapid advancements in language models (LMs) have garnered attention in time series multimodal representation learning. However, existing contrastive learning-based and prompt-based LM approaches tend to be biased, often assigning a primary role to time series modality while treating text modality as secondary.\nWe classify these approaches under a temporal-primary paradigm, which overlooks the unique and critical task-relevant information provided by the text modality, failing to fully leverage mutual benefits and complementarity of different modalities.\nTo fill this gap, we propose a novel textual-temporal multimodal learning paradigm that enables either modality to serve as the primary one while being enhanced by the other, thereby effectively capturing modality-specific information and fostering cross-modal interaction. In specific, we design DualTime, a language model composed of dual adapters to implement temporal-primary and textual-primary modeling simultaneously. Within each adapter, lightweight adaptation tokens are injected into the top layers of LM to encourage high-level cross-modal interaction. The shared LM pipeline by dual adapters not only achieves adapter alignment but also reduces computation resources and enables efficient fine-tuning. Empirically, DualTime demonstrates superior performance, achieving notable improvements of 7% accuracy and 15% F1 in supervised settings. Furthermore, the few-shot label transfer experiments validate DualTime's expressiveness and transferability."
    },
    {
        "title": "Does Vector Quantization Fail in Spatio-Temporal Forecasting? Exploring a Differentiable Sparse Soft-Vector Quantization Approach",
        "link_suffix": "/forum?id=4CFVPCYfJ9",
        "link": "https://openreview.net/forum?id=4CFVPCYfJ9",
        "pdf_link": "https://openreview.net/pdf?id=4CFVPCYfJ9",
        "keywords": "spatio-temporal forecasting, vector quantilization, sparse regression, differentiable, soft",
        "abstract": "Spatio-temporal forecasting is crucial in various fields and requires a careful balance between identifying subtle patterns and filtering out noise. Vector quantization (VQ) appears well-suited for this purpose, as it quantizes input vectors into a set of codebook vectors or patterns. Although vector quantization (VQ) has shown promise in various computer vision tasks, it surprisingly falls short in enhancing the accuracy of spatio-temporal forecasting. We attribute this to two main issues: inaccurate optimization due to non-differentiability and limited representation power in hard VQ. To tackle these challenges, we introduce Differentiable Sparse Soft-Vector Quantization (SVQ), the first VQ method to enhance spatio-temporal forecasting. SVQ balances detail preservation with noise reduction, offering full differentiability and a solid foundation in sparse regression. Our approach employs a two-layer MLP and an extensive codebook to streamline the sparse regression process, significantly cutting computational costs while simplifying training and improving performance. Empirical studies on five spatio-temporal benchmark datasets show SVQ achieves state-of-the-art results, including a 7.9% improvement on the WeatherBench-S temperature dataset and an average MAE reduction of 9.4% in video prediction benchmarks (Human3.6M, KTH, and KittiCaltech), along with a 17.3% enhancement in image quality (LPIPS). Code is publicly available athttps://anonymous.4open.science/r/SVQ-Forecasting"
    },
    {
        "title": "Self-Monitoring Large Language Models for Click-Through Rate Prediction",
        "link_suffix": "/forum?id=jNCwczhHLP",
        "link": "https://openreview.net/forum?id=jNCwczhHLP",
        "pdf_link": "https://openreview.net/pdf?id=jNCwczhHLP",
        "keywords": "Large Language Model, Click-through Rate Prediction, Feature-Click learning",
        "abstract": "Click-through rate (CTR) prediction tasks traditionally aim to model extensive user-\nitem feature interactions. Recent approaches fine-tune Large Language Models\n(LLMs) using user-item features as input and click labels as output. However,\ndue to the sparsity of click labels, the attention mechanism may focus on a subset\nof features rather than all features. This can hinder LLMs\u2019 ability to accurately\nmatch features to click labels, resulting in performance that does not consistently\nexceed traditional state-of-the-art CTR approaches. To address this, we introduce\na SLLM4CTR framework which uses adaptive temperature and label matching loss\nto improve fine-tuning and inference process of LLMs. The adaptive temperature\nserves as a confidence score to calibrate CTR predictions by quantifying the LLMs\u2019\nattention to user-item features. The label matching loss clearly distinguish between\nclick-inducing and non-click-inducing features by constraining the representation\nspace of click labels. By combining these two designs, SLLM4CTR improves feature\nutilization in LLMs and enhances the matching of user-item features to click\nlabels. Experimental results demonstrate\nthat SLLM4CTR significantly outperforms state-of-the-art baselines, including both\ntraditional and LLM-based CTR approaches. The code will be open-sourced."
    },
    {
        "title": "LLM as a Complementary Optimizer to Gradient Descent: A Case Study in Prompt Tuning",
        "link_suffix": "/forum?id=Y5de4fkuHR",
        "link": "https://openreview.net/forum?id=Y5de4fkuHR",
        "pdf_link": "https://openreview.net/pdf?id=Y5de4fkuHR",
        "keywords": "Model Adaptation, Prompt Optimization",
        "abstract": "Mastering a skill generally relies on both hands-on experience from doers and insightful, high-level guidance by mentors.\n Will this strategy also work well for solving complex non-convex optimization problems? Here, a common gradient-based optimizer acts like a disciplined doer, making locally optimal updates at each step.\n  Large Language Models (LLMs) can also search for better solutions by inferring from natural language instructions, akin to a high-level mentor. \n  In this paper, we show that these two participators are complementary to each other and can effectively collaborate as a combined optimization framework.\n  The collaborative optimization is achieved by alternating between the gradient-based and LLM-based optimizers.\n  We instruct LLMs to generate possibly improved solutions by taking parameter trajectories recorded during the previous stage of gradient-based optimization into account. Inferred results of LLMs are used as restarting points for the next stage of gradient optimization. \n  We verify the effectiveness of this optimization framework on prompt tuning.\n  By leveraging both the locally rigorous gradient-based optimizer and the high-level deductive LLM-based optimizer, the combined optimization method consistently yields improvements over competitive baselines on a variety of tasks.\n  Our results demonstrate the synergistic effect of conventional gradient-based optimization and the inference ability of LLMs. \n  The code will be made publicly available."
    },
    {
        "title": "Are spectral augmentations necessary in contrast-based graph self-supervised learning?",
        "link_suffix": "/forum?id=k7Q28aNVko",
        "link": "https://openreview.net/forum?id=k7Q28aNVko",
        "pdf_link": "https://openreview.net/pdf?id=k7Q28aNVko",
        "keywords": "Graph Neural Networks, Self-supervised Learning, Spectral Augmentation, Representation Learning",
        "abstract": "The recent surge in contrast-based graph self-supervised learning has prominently featured an intensified exploration of spectral cues. Spectral augmentation, which involves modifying a graph\u2019s spectral properties such as eigenvalues or eigenvectors, is widely believed to enhance model performance. However, an intriguing paradox emerges, as methods grounded in seemingly conflicting assumptions or heuristic approaches regarding the spectral domain demonstrate notable enhancements in learning performance. This paradox raises the critical question of whether spectral augmentations are really necessary for contrast-based graph self-supervised learning. This study undertakes an extensive investigation into this inquiry, conducting a thorough study of the relationship between spectral characteristics and the learning outcomes of contemporary methodologies. Based on this analysis, we claim that the effectiveness and significance of spectral augmentations need to be questioned. Instead, we revisit simple edge perturbation: random edge dropping designed for node-level self-supervised learning and random edge adding intended for graph-level self-supervised learning. Compelling evidence is presented that these simple yet effective strategies consistently yield superior performance while demanding significantly fewer computational resources compared to existing spectral augmentation methods. The proposed insights represent a significant leap forward in the field, potentially reshaping the understanding and implementation of graph self-supervised learning."
    },
    {
        "title": "How much of my dataset did you use? Quantitative Data Usage Inference in Machine Learning",
        "link_suffix": "/forum?id=EUSkm2sVJ6",
        "link": "https://openreview.net/forum?id=EUSkm2sVJ6",
        "pdf_link": "https://openreview.net/pdf?id=EUSkm2sVJ6",
        "keywords": "Machine Learning, Privacy, Dataset Usage Inference, Dataset Ownership, Membership Inference Attack, Dataset Copyright",
        "abstract": "How much of a given dataset was used to train a machine learning model? This is a critical question for data owners assessing the risk of unauthorized data usage and protecting their right (United States Code, 1976). However, previous work mistakenly treats this as a binary problem\u2014inferring whether \\textit{all or none} or \\textit{any or none} of the data was used\u2014which is fragile when faced with real, non-binary data usage risks. To address this, we propose a fine-grained analysis called Dataset Usage Cardinality Inference (\\ourmethod{}), which estimates the exact proportion of data used. Our algorithm, leveraging debiased membership guesses, matches the performance of the optimal MLE approach (with a maximum error <0.1) but with significantly lower (e.g., $300 \\times$ less) computational cost."
    },
    {
        "title": "CLR-Bench: Evaluating Large Language Models in College-Level Reasoning",
        "link_suffix": "/forum?id=ToVvoHpk4L",
        "link": "https://openreview.net/forum?id=ToVvoHpk4L",
        "pdf_link": "https://openreview.net/pdf?id=ToVvoHpk4L",
        "keywords": "Large Language Models Evaluation, Benchark and dataset, College-level Reasoning",
        "abstract": "Large language models (LLMs) have demonstrated their remarkable performance across various language understanding tasks. While emerging benchmarks have been proposed to evaluate LLMs in various domains such as mathematics and computer science, they merely measure the accuracy in terms of the final prediction on multi-choice questions. However, it remains insufficient to verify the essential understanding of LLMs given a chosen choice. To fill this gap, we present $\\texttt{CLR-Bench}$ to comprehensively evaluate the LLMs in complex college-level reasoning. Specifically, $(i)$ we prioritize 16 challenging college disciplines in computer science and artificial intelligence. The dataset contains 5 types of questions, while each question is associated with detailed explanations from experts. $(ii)$ To quantify a fair evaluation of LLMs' reasoning ability, we formalize the criteria with two novel metrics. Q$\\rightarrow$A is utilized to measure the performance of directanswer prediction, and Q$\\rightarrow$AR effectively considers the joint ability toanswer the question and providerationale simultaneously. Extensive experiments are conducted with 40 LLMs over 1,018 discipline-specific questions. The results demonstrate the key insights that LLMs, even the best closed-source LLM, i.e., GPT-4 turbo, tends to 'guess' the college-level answers. It shows a dramatic decrease in accuracy from 63.31% Q$\\rightarrow$A to 39.00% Q$\\rightarrow$AR, indicating an unsatisfactory reasoning ability."
    },
    {
        "title": "Adversaries Can Misuse Combinations of Safe Models",
        "link_suffix": "/forum?id=smkspydzyN",
        "link": "https://openreview.net/forum?id=smkspydzyN",
        "pdf_link": "https://openreview.net/pdf?id=smkspydzyN",
        "keywords": "safety, misuse, adversary, combining models, attacks, hacking",
        "abstract": "Developers try to evaluate whether an AI system can accomplish malicious tasks before releasing it; for example, they might test whether a model enables cyberoffense, user manipulation, or bioterrorism. In this work, we show that individually testing models for such misuse is inadequate; adversaries can misuse combinations of models even when each individual model is safe. The adversary accomplishes this by first decomposing tasks into subtasks, then solving each subtask with the best-suited model. For example, an adversary might solve challenging-but-benign subtasks with an aligned frontier model, and easy-but-malicious subtasks with a weaker misaligned model. We study two decomposition methods: manual decomposition where a human identifies a natural decomposition of a task, and automated decomposition where a weak model generates benign tasks for a frontier model to solve, then uses the solutions in-context to solve the original task. Using these decompositions, we empirically show that adversaries can create vulnerable code, explicit images, python scripts for hacking, and manipulative tweets at much higher rates with combinations of models than either individual model. Our work suggests that even perfectly-aligned frontier systems can enable misuse without ever producing malicious outputs, and that red-teaming efforts should extend beyond single models in isolation."
    },
    {
        "title": "Learning Causal Alignment for Reliable Disease Diagnosis",
        "link_suffix": "/forum?id=ozZG5FXuTV",
        "link": "https://openreview.net/forum?id=ozZG5FXuTV",
        "pdf_link": "https://openreview.net/pdf?id=ozZG5FXuTV",
        "keywords": "alignment, causal learning, counterfactual, disease diagnosis",
        "abstract": "Aligning the decision-making process of machine learning algorithms with that of experienced radiologists is crucial for reliable diagnosis. While existing methods have attempted to align their prediction behaviors to those of radiologists reflected in the training data, this alignment is primarily associational rather than causal, resulting in pseudo-correlations that may not transfer well. In this paper, we propose a causality-based alignment framework towards aligning the model's decision process with that of experts. Specifically, we first employ counterfactual generation to identify the causal chain of model decisions. To align this causal chain with that of experts, we propose a causal alignment loss that enforces the model to focus on causal factors underlying each decision step in the whole causal chain. To optimize this loss that involves the counterfactual generator as an implicit function of the model's parameters, we employ the implicit function theorem equipped with the conjugate gradient method for efficient estimation. We demonstrate the effectiveness of our method on two medical diagnosis applications, showcasing faithful alignment to radiologists."
    },
    {
        "title": "Croppable Knowledge Graph Embedding",
        "link_suffix": "/forum?id=Hh6XKefS28",
        "link": "https://openreview.net/forum?id=Hh6XKefS28",
        "pdf_link": "https://openreview.net/pdf?id=Hh6XKefS28",
        "keywords": "knowledge graph, knowledge distillation, parameter-efficient representation learning",
        "abstract": "Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs) to serve various artificial intelligence tasks. The suitable dimensions of the embeddings depend on the storage and computing conditions of the specific application scenarios. Once a new dimension is required, a new KGE model needs to be trained from scratch, which greatly increases the training cost and limits the efficiency and flexibility of KGE in serving various scenarios. In this work, we propose a novel KGE training framework MED, through which we could train once to get a croppable KGE model applicable to multiple scenarios with different dimensional requirements, sub-models of the required dimensions can be cropped out of it and used directly without any additional training. In MED, we propose a mutual learning mechanism to improve the low-dimensional sub-models performance and make the high-dimensional sub-models retain the capacity that low-dimensional sub-models have, an evolutionary improvement mechanism to promote the high-dimensional sub-models to master the knowledge that the low-dimensional sub-models can not learn, and a dynamic loss weight to balance the multiple losses adaptively. Experiments on 4 KGE models over 4 standard KG completion datasets, 3 real application scenarios over a real-world large-scale KG, and the experiments of extending MED to the language model BERT show the effectiveness, high efficiency, and flexible extensibility of MED. The code and data are available athttps://anonymous.4open.science/r/MED-DBFC."
    },
    {
        "title": "Pose-guided Motion Diffusion Model for Text-to-motion Generation",
        "link_suffix": "/forum?id=if8iIYcmVC",
        "link": "https://openreview.net/forum?id=if8iIYcmVC",
        "pdf_link": "https://openreview.net/pdf?id=if8iIYcmVC",
        "keywords": "Motion generation, Text to motion, Diffusion model, Generative model",
        "abstract": "3D Human motion generation, especially textual conditioning motion generation, is a vital part of computer animation. However, during training, multiple actions are often coupled within a single textual description, which complicates the model's learning of individual actions. Additionally, the motion corresponding to a given text can be diverse, which makes it difficult for the model learning and for the user to control the generation of motions that contain a specific pose. Finally, motions with the same semantics can have various ways of expression in the forms of texts, which further increases the difficulty of the model\u2019s learning process. To solve the above challenges, we propose the Pose-Guided Text to Motion (PG-T2M) with the following designs. Firstly, we propose to divide the sentences into sub-sentences containing one single verb and make the model learn the specific mapping from one single action description to its motion. Secondly, we propose using pose priors from static 2D natural images for each sub-sentence as control signals, allowing the model to generate more accurate and controllable 3D pose sequences that align with the sub-action descriptions. Finally, to enable the model to distinguish which sub-sentences describe similar semantics, we construct a pose memory storing semantic-similar sub-sentences and the corresponding pose representations in groups. These designs together enable our model to retrieve the pose information for every single action described in the text and use them to guide motion generation. Our method achieves state-of-the-art performance on the HumanML3D and KIT datasets."
    },
    {
        "title": "Subspace Optimiztion for Large Language Models with Convergence Guarantees",
        "link_suffix": "/forum?id=udtrtwkvk5",
        "link": "https://openreview.net/forum?id=udtrtwkvk5",
        "pdf_link": "https://openreview.net/pdf?id=udtrtwkvk5",
        "keywords": "Large Language Models, Memory-Efficient Training, Subspace Learning",
        "abstract": "Subspace optimization algorithms, with GaLore (Zhao et al., 2024) as a representative method, have gained popularity for pre-training or fine-tuning large language models (LLMs) due to their memory efficiency. However, their convergence guarantees remain unclear, particularly in stochastic settings. In this paper, we unexpectedly discover that GaLore does not always converge to the optimal solution and substantiate this finding with an explicit counterexample. We then investigate the conditions under which GaLore can achieve convergence, demonstrating that it does so either in deterministic scenarios or when using a sufficiently large mini-batch size. More significantly, we introduceGoLore(Gradient randomLow-rank projection), a novel variant of GaLore that provably converges in stochastic settings, even with standard batch sizes. Our convergence analysis can be readily extended to other sparse subspace optimization algorithms. Finally, we conduct numerical experiments to validate our theoretical results and empirically explore the proposed mechanisms."
    },
    {
        "title": "CLDyB: Towards Dynamic Benchmarking for Continual Learning with Pre-trained Models",
        "link_suffix": "/forum?id=RnxwxGXxex",
        "link": "https://openreview.net/forum?id=RnxwxGXxex",
        "pdf_link": "https://openreview.net/pdf?id=RnxwxGXxex",
        "keywords": "continual learning, dynamic benchmarking",
        "abstract": "The emergence of the foundation model era has sparked immense research interest in utilizing pre-trained representations for continual learning~(CL), yielding a series of strong CL methods with outstanding performance on standard evaluation benchmarks. Nonetheless, there are growing concerns regarding potential data contamination within the massive pre-training datasets. Furthermore, the static nature of standard evaluation benchmarks tends to oversimplify the complexities encountered in real-world CL scenarios, putting CL methods at risk of overfitting to these benchmarks while still lacking robustness needed for more demanding real-world applications. To solve these problems, this paper proposes a general framework to evaluate methods for Continual Learning on Dynamic Benchmarks (CLDyB). CLDyB continuously identifies inherently challenging tasks for the specified CL methods and evolving backbones, and dynamically determines the sequential order of tasks at each time step in CL using a tree-search algorithm, guided by an overarching goal to generate highly challenging task sequences for evaluation. To highlight the significance of dynamic evaluation on the CLDyB, we first simultaneously evaluate multiple state-of-the-art CL methods under CLDyB, resulting in a set of commonly challenging task sequences where existing CL methods tend to underperform. We intend to publicly release these task sequences for the CL community to facilitate the training and evaluation of more robust CL algorithms. Additionally, we perform individual evaluations of the CL methods under CLDyB, yielding informative evaluation results that reveal the specific strengths and weaknesses of each method."
    },
    {
        "title": "AVESFormer: Efficient Transformer Design for Real-Time Audio-Visual Segmentation",
        "link_suffix": "/forum?id=u8SYRtXDsZ",
        "link": "https://openreview.net/forum?id=u8SYRtXDsZ",
        "pdf_link": "https://openreview.net/pdf?id=u8SYRtXDsZ",
        "keywords": "Audio-Visual Segmentation, real-time model, efficient architecture",
        "abstract": "Recently, transformer-based models have achieved remarkable performance on audio-visual segmentation (AVS) tasks.\n  However, the cross-attention mechanism exhibits suboptimal behavior and unsatisfactory results in real-time scenarios.\n  By analyzing attention maps, we identify two primary challenges in existing AVS models: 1)attention dissipation,caused by anomalous attention weights after Softmax over limited frames, and 2)narrow attention patternsin shallow decoder stages leading to inefficient utilization of attention resources.\n  In this paper, we introduceAVESFormer, the first real-time audio-visual efficient segmentation transformer that achieves fast, efficient and light-weight simultaneously.\n  Our model leverages an efficient prompt query generator to rectify cross-attention behavior. \n  Moreover, we propose ELF decoder, which enhances efficiency by incorporating convolutional operations tailored for local feature extraction, thus reducing computational overhead.\n  Extensive experiments demonstrate that AVESFormer effectively mitigates cross-attention issues, substantially improves attention utilization, and outperforming previous state-of-the-art, achieving a superior trade-off between performance and speed.\n  Code can be found in supplementary material."
    },
    {
        "title": "Aligning Teacher with Student Preferences for Tailored Instruction Tuning Dataset Generation",
        "link_suffix": "/forum?id=SgAPzJdAHi",
        "link": "https://openreview.net/forum?id=SgAPzJdAHi",
        "pdf_link": "https://openreview.net/pdf?id=SgAPzJdAHi",
        "keywords": "Large Language Model, Knowledge Distillation, Alignment",
        "abstract": "Enhancing the reasoning abilities of lightweight language models (LMs) for tasks like decision-making often relies on instruction-tuning, a method that trains LMs to mimic the reasoning process using labeled question-rationale pairs, known as instruction-tuning datasets, which are typically generated by more powerful teacher LMs. However, current methods for generating these instruction-tuning datasets tend to focus solely on the quality of the questions and rationales from the teacher model\u2019s perspective, often neglecting the learning preferences of the student language model. To fill this gap, we proposeARTE(Aligning TeacheRwith StudenTPreferencEs), a novel framework that adapts the teacher LM\u2019s outputs to the student\u2019s preferences, inspired by \"responsive teaching\" in pedagogy. Our method involves three key steps: (1) generating draft question-rationale pairs from the teacher model, (2) collecting the student\u2019s preferences on these draft pairs via one-shot in-context learning, and (3) aligning the teacher model using Direct Preference Optimization (DPO), then finally curating tailored question-rationale pairs from the aligned teacher for student training. Through extensive experiments on academic reasoning benchmarks, we demonstrate that student models fine-tuned with tailored datasets by ARTE achieve significant improvements across various reasoning tasks, outperforming existing instruction-tuning datasets. Moreover, we thoroughly investigate the generalization of ARTE, including the generalization of fine-tuned student models in reasoning ability and the generalization of aligned teacher models to generate tailored training data across tasks and students."
    },
    {
        "title": "Controllable Data Generation with Hierarchical Neural Representations",
        "link_suffix": "/forum?id=sOa0SYS0cN",
        "link": "https://openreview.net/forum?id=sOa0SYS0cN",
        "pdf_link": "https://openreview.net/pdf?id=sOa0SYS0cN",
        "keywords": "Implicit Neural Representations, Generative INR, Generative Models, Diffusion Models",
        "abstract": "Implicit Neural Representations (INRs) represent data as continuous functions using the parameters of a neural network, where data information is encoded in the parameter space. Therefore, modeling the distribution of such parameters is crucial for building generalizable INRs. Existing approaches learn a joint distribution of these parameters via a latent vector to generate new data, but such a flat latent often fails to capture the inherent hierarchical structure of the parameter space, leading to entangled data semantics and limited control over the generation process. Here, we propose a $\\textbf{C}$ontrollable $\\textbf{H}$ierarchical $\\textbf{I}$mplicit $\\textbf{N}$eural $\\textbf{R}$epresentation ($\\textbf{CHINR}$) framework, which explicitly models conditional dependencies across layers in the parameter space. Our method consists of two stages: In Stage-1, we construct a Layers-of-Experts (LoE) network, where each layer modulates distinct semantics through a unique latent vector, enabling disentangled and expressive representations. In Stage-2, we introduce a Hierarchical Controllable Diffusion Model (HCDM) to capture conditional dependencies across layers, allowing for controllable and hierarchical data generation at various semantic granularities. Extensive experiments on CelebA-HQ, ShapeNet, SRN-Cars, and AMASS datasets demonstrate that CHINR improves generalizability and offers flexible hierarchical control over the generated content."
    },
    {
        "title": "Visual Question Answering with Fine-grained Knowledge Unit RAG and Multimodal LLMs",
        "link_suffix": "/forum?id=6ewsi4xi1L",
        "link": "https://openreview.net/forum?id=6ewsi4xi1L",
        "pdf_link": "https://openreview.net/pdf?id=6ewsi4xi1L",
        "keywords": "Visual Question Answering, Retrieval-Augmented Generation",
        "abstract": "Visual Question Answering (VQA) aims to answer natural language questions based on information present in images. Recent advancements in multimodal large language models (MLLMs) with internalized world knowledge, such as GPT-4o, have demonstrated strong capabilities in addressing VQA tasks. However, in many real-world cases, MLLMs alone are not enough, as they may lack domain-specific or up-to-date knowledge relevant to images and questions. To mitigate this problem, retrieval-augmented generation (RAG) from external knowledge bases (KBs), known as KB-VQA, is promising for VQA. However, effectively retrieving relevant knowledge is not easy. Traditional wisdom typically converts images into text and employs unimodal (i.e. text-based) retrieval, which can lead to the loss of visual information and hinder accurate image-to-image matching. In this paper, we introduce fine-grained knowledge units including both text fragments and entity images, which are extracted from KBs and stored in vector databases. In practice, retrieving fine-grained knowledge units is more effective than retrieving coarse-grained knowledge, for finding relevant information. We also designed a knowledge unit retrieval-augmented generation (KU-RAG) method, through fine-grained retrieval and MLLMs. KU-RAG can accurately find corresponding knowledge, and integrate the retrieved knowledge with the internalized MLLM knowledge using a knowledge correction chain for reasoning. Experimental results indicate that our method can significantly enhance the performance of state-of-the-art KB-VQA solutions, with improvements by up to 10%."
    },
    {
        "title": "MGMapNet: Multi-Granularity Representation Learning for End-to-End Vectorized HD Map Construction",
        "link_suffix": "/forum?id=E8S5Upr6oO",
        "link": "https://openreview.net/forum?id=E8S5Upr6oO",
        "pdf_link": "https://openreview.net/pdf?id=E8S5Upr6oO",
        "keywords": "Online HD map construction\uff0cvectorized representation\uff0cautonomous driving",
        "abstract": "The construction of Vectorized High-Definition (HD) map typically requires capturing both category and geometry information of map elements. Current state-of-the-art methods often adopt solely either point-level or instance-level representation, overlooking the strong intrinsic relationships between points and instances. In this work, we propose a simple yet efficient framework named MGMapNet (Multi-Granularity Map Network) to model map element with a multi-granularity representation, integrating both coarse-grained instance-level and fine-grained point-level queries. Specifically, these two granularities of queries are generated from the multi-scale bird's eye view (BEV) features using a proposed Multi-Granularity Aggregator. In this module, instance-level query aggregates features over the entire scope covered by an instance, and the point-level query aggregates features locally. Furthermore, a Point Instance Interaction module is designed to encourage information exchange between instance-level and point-level queries. Experimental results demonstrate that the proposed MGMapNet achieves state-of-the-art performance, surpassing MapTRv2 by 5.3 mAP on nuScenes and 4.4 mAP on Argoverse2 respectively."
    },
    {
        "title": "A Mathematics-Inspired Learning-to-Optimize Framework for Decentralized Optimization",
        "link_suffix": "/forum?id=FI45zMai6Y",
        "link": "https://openreview.net/forum?id=FI45zMai6Y",
        "pdf_link": "https://openreview.net/pdf?id=FI45zMai6Y",
        "keywords": "Learning to Optimize, Decentralized Optimization, Composite Optimization",
        "abstract": "Most decentralized optimization algorithms are handcrafted. While endowed with strong theoretical guarantees, these algorithms generally target a broad class of problems, thereby not being adaptive or customized to specific problem features. This paper studies data-driven decentralized algorithms trained to exploit problem features to boost convergence. Existing learning-to-optimize methods typically suffer from poor generalization or prohibitively vast search spaces. In addition, they face more challenges in decentralized settings where nodes must reach consensus through neighborhood communications without global information. To resolve these challenges, this paper first derives the necessary conditions that successful decentralized algorithmic rules need to satisfy to achieve both optimality and consensus. Based on these conditions, we propose a novelMathematics-inspiredLearning-to-optimize framework forDecentralizedoptimization (MiLoDo). Empirical results demonstrate that MiLoDo-trained algorithms outperform handcrafted algorithms and exhibit strong generalizations. Algorithms learned via MiLoDo in 100 iterations perform robustly when running 100,000 iterations during inferences. Moreover, MiLoDo-trained algorithms on synthetic datasets perform well on problems involving real data, higher dimensions, and different loss functions."
    }
]
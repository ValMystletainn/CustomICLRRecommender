[
    {
        "title": "InstructRAG: Instructing Retrieval-Augmented Generation via Self-Synthesized Rationales",
        "link_suffix": "/forum?id=P1qhkp8gQT",
        "link": "https://openreview.net/forum?id=P1qhkp8gQT",
        "pdf_link": "https://openreview.net/pdf?id=P1qhkp8gQT",
        "keywords": "Large language model, retrieval-augmented generation",
        "abstract": "Retrieval-augmented generation (RAG) has shown promising potential to enhance the accuracy and factuality of language models (LMs). However, imperfect retrievers or noisy corpora can introduce misleading or even erroneous information to the retrieved contents, posing a significant challenge to the generation quality. Existing RAG methods typically address this challenge by directly predicting final answers despite potentially noisy inputs, resulting in an implicit denoising process that is difficult to interpret and verify. On the other hand, the acquisition of explicit denoising supervision is often costly, involving significant human efforts. In this work, we propose InstructRAG, where LMs explicitly learn the denoising process through self-synthesized rationales --- First, we instruct the LM to explain how the ground-truth answer is derived from retrieved documents. Then, these rationales can be used either as demonstrations for in-context learning of explicit denoising or as supervised fine-tuning data to train the model. Compared to standard RAG approaches, InstructRAG requires no additional supervision, allows for easier verification of the predicted answers, and effectively improves generation accuracy. Experiments show InstructRAG consistently outperforms existing RAG methods in both training-free and trainable scenarios, achieving a relative improvement of 8.3% over the best baseline method on average across five knowledge-intensive benchmarks. Extensive analysis indicates that InstructRAG scales well with increased numbers of retrieved documents and consistently exhibits robust denoising ability even in out-of-domain datasets, demonstrating strong generalizability."
    },
    {
        "title": "SplatFormer: Point Transformer for Robust 3D Gaussian Splatting",
        "link_suffix": "/forum?id=9NfHbWKqMF",
        "link": "https://openreview.net/forum?id=9NfHbWKqMF",
        "pdf_link": "https://openreview.net/pdf?id=9NfHbWKqMF",
        "keywords": "Novel View Synthesis, Gaussian Splatting, Point cloud modeling",
        "abstract": "3D Gaussian Splatting (3DGS) has recently transformed photorealistic reconstruction, achieving high visual fidelity and real-time performance. However, rendering quality significantly deteriorates when test views deviate from the camera angles used during training, posing a major challenge for applications in immersive free-viewpoint rendering and navigation. In this work, we conduct a comprehensive evaluation of 3DGS and related novel view synthesis methods under out-of-distribution (OOD) test camera scenarios. By creating diverse test cases with synthetic and real-world datasets, we demonstrate that most existing methods, including those incorporating various regularization techniques and data-driven priors, struggle to generalize effectively to OOD views. To address this limitation, we introduce SplatFormer, the first point transformer model specifically designed to operate on Gaussian splats. SplatFormer takes as input an initial 3DGS set optimized under limited training views and refines it in a single forward pass, effectively removing potential artifacts in OOD test views. To our knowledge, this is the first successful application of point transformers directly on 3DGS sets, surpassing the limitations of previous multi-scene training methods, which could handle only a restricted number of input views during inference. Our model significantly improves rendering quality under extreme novel views, achieving state-of-the-art performance in these challenging scenarios and outperforming various 3DGS regularization techniques, multi-scene models tailored for sparse view synthesis, and diffusion-based frameworks. Code and data will be made public."
    },
    {
        "title": "Egocentric Vision Language Planning",
        "link_suffix": "/forum?id=7NHF4txacw",
        "link": "https://openreview.net/forum?id=7NHF4txacw",
        "pdf_link": "https://openreview.net/pdf?id=7NHF4txacw",
        "keywords": "Vision language planning",
        "abstract": "We explore leveraging large multi-modal models (LMMs) and Text2image models to build a more general embodied agent. LMMs excel in planning long-horizon tasks over symbolic abstractions but struggle with grounding in the physical world, often failing to accurately identify object positions in images. A bridge is needed to connect LMMs to the physical world. The paper proposes a novel approach, egocentric vision language planning (EgoPlan), to handle long-horizon tasks from an egocentric perspective in varying household scenarios. This pipeline leverages a diffusion model to simulate the fundamental dynamics between states and actions, discusses how to integrate computer vision related techniques like style transfer and optical flow to enhance ability of modeling spatial states and generalization across different environmental dynamics. The LMM serves as a planner, breaking down instructions into sub-goals and selecting actions based on their alignment with these sub-goals, thus enabling more generalized and effective decision-making. By using LMM, we can output text actions, using a series of mechanisms such as reflection to perform high-level task decomposition and low-level action output end-to-end. Experiments show that EgoPlan improves long-horizon task success rates from the egocentric view compared to baselines across household scenarios."
    },
    {
        "title": "MixMax: Distributional Robustness in Function Space via Optimal Data Mixtures",
        "link_suffix": "/forum?id=dIkpHooa2D",
        "link": "https://openreview.net/forum?id=dIkpHooa2D",
        "pdf_link": "https://openreview.net/pdf?id=dIkpHooa2D",
        "keywords": "Distributional Robustness, Non-parametric Learning, Function Space, Trustworthy Machine Learning",
        "abstract": "Machine learning models are often required to perform well across several pre-defined settings, such as a set of user groups. Worst-case performance is a common metric to capture this requirement, and is the objective of group distributionally robust optimization (group DRO). Unfortunately, these methods struggle when the loss is non-convex in the parameters, or the model class is non-parametric. Here, we make a classical move to address this: we reparameterize group DRO from parameter space to function space, which results in a number of advantages. First, we show that group DRO over the space of bounded functions admits a minimax theorem. Second, for cross-entropy and mean squared error, we show that the minimax optimal mixture distribution is the solution of a simple convex optimization problem. Thus, provided one is working with a model class of universal function approximators, group DRO can be solved by a convex optimization problem followed by a classical risk minimization problem. We call our method MixMax. In our experiments, we found that MixMax matched or outperformed the standard group DRO baselines, and in particular, MixMax improved the performance of XGBoost over the only baseline, data balancing, for variations of the ACSIncome and CelebA annotations datasets."
    },
    {
        "title": "Digi-Q: Transforming VLMs to Device-Control Agents via Value-Based Offline RL",
        "link_suffix": "/forum?id=CjfQssZtAb",
        "link": "https://openreview.net/forum?id=CjfQssZtAb",
        "pdf_link": "https://openreview.net/pdf?id=CjfQssZtAb",
        "keywords": "Reinforcement learning, device control, digital agents, foundation models",
        "abstract": "Most paradigms for building foundation model agents rely on prompting or finetuning on existing demonstrations, but this is not sufficient in dynamic environments (e.g., mobile device control). In theory, while on-policy reinforcement learning (RL) should address these limitations, this approach itself is not quite effective at leveraging existing agentic data, especially when it is of low quality. An approach to address this issue is to use offline value-based RL but realizing value-based RL for agents has been elusive due to of stability and efficiency associated with running TD-learning at scale with vision-language models (VLMs). In this paper, we develop a scalable value-based RL approach called Digi-Q that makes it possible to train VLM agents with TD-learning. We situate our study in building GUI agents for Android devices. The key idea in Digi-Q is to perform TD-learning on a frozen, intermediate-layer representation of a VLM rather than training the whole VLM itself. Doing so successfully requires an initial phase of fine-tuning to prime VLM representations to feature actionable information that is critical for TD-learning. When done correctly, our approach is able to attain better performance per-unit compute FLOPS. To make maximal use of the learned Q-function, we devise a novel best-of-N policy extraction operator that imitates the best actions out of multiple candidate actions from the current policy as ranked by the value function. With no REINFORCE-style policy gradients that need careful tiuning and an efficient TD-learning approach, Digi-Q outperforms several strong prior methods on user-scale device control tasks in Android-in-the-Wild, attaining 9.9% of relative improvement over prior best-performing offline RL method in this domain."
    },
    {
        "title": "Multiagent Finetuning of Language Models",
        "link_suffix": "/forum?id=JtGPIZpOrz",
        "link": "https://openreview.net/forum?id=JtGPIZpOrz",
        "pdf_link": "https://openreview.net/pdf?id=JtGPIZpOrz",
        "keywords": "Language Models, Multi-agent Interaction, Self Improvement",
        "abstract": "Large language models (LLMs) have achieved remarkable performance in recent years but are fundamentally limited by the underlying training data. To improve models beyond the training data, recent works have explored how LLMs can be used to generate synthetic data for autonomous self-improvement. However, successive steps of self-improvement can reach a point of diminishing returns, as the diversity of generations decreases, limiting further performance gains. In this work, we propose a complementary approach towards self-improvement where finetuning is applied to a multiagent society of language models. A set of language models are initialized from the same base model and then are specialized by independently updating each model using data generated by the model under multiagent interaction with other models. By training each model on independent sets of data, we illustrate how this approach enables specialization across models and diversification over the set of models. As a result, our overall system is able to autonomously improve over many more rounds of fine-tuning than single-agent self-improvement methods. We quantitatively illustrate the efficacy of the approach across a wide suite of reasoning tasks."
    },
    {
        "title": "The Hidden Cost of Waiting for Accurate Predictions",
        "link_suffix": "/forum?id=A3YUPeJTNR",
        "link": "https://openreview.net/forum?id=A3YUPeJTNR",
        "pdf_link": "https://openreview.net/pdf?id=A3YUPeJTNR",
        "keywords": "Algorithmic Decision Making, Prediction, Resource Allocation, Social Welfare, Limits of Prediction",
        "abstract": "Algorithmic predictions are increasingly informing societal resource allocations by identifying individuals for targeting. Policymakers often build these systems with the assumption that by gathering more observations on individuals, they can improve predictive accuracy and, consequently, allocation efficiency. An overlooked yet consequential aspect of prediction-driven allocations is that of timing. The planner has to trade off relying on earlier and potentially noisier predictions to intervene before individuals experience undesirable outcomes, or they may wait to gather more observations to make more precise allocations. We examine this tension using a simple mathematical model, where the planner collects observations on individuals to improve predictions over time. We analyze both the ranking induced by these predictions and optimal resource allocation. We show that though individual prediction accuracy may improve over time, counter-intuitively, the average ranking loss can worsen. As a result, the planner's ability to improve social welfare can decline. We identify inequality as a driving factor behind this phenomenon. Our findings provide a nuanced perspective and challenge the conversational wisdom that it is preferable to wait for more accurate predictions to ensure the most efficient allocations."
    },
    {
        "title": "MeToken: Uniform Micro-environment Token Boosts Post-Translational Modification Prediction",
        "link_suffix": "/forum?id=noUF58SMra",
        "link": "https://openreview.net/forum?id=noUF58SMra",
        "pdf_link": "https://openreview.net/pdf?id=noUF58SMra",
        "keywords": "Biomolecular learning, Protein sequence",
        "abstract": "Post-translational modifications (PTMs) profoundly expand the complexity and functionality of the proteome, regulating protein attributes and interactions that are crucial for biological processes. Accurately predicting PTM sites and their specific types is therefore essential for elucidating protein function and understanding disease mechanisms. Existing computational approaches predominantly focus on protein sequences to predict PTM sites, driven by the recognition of sequence-dependent motifs. However, these approaches often overlook protein structural contexts. In this work, we first compile a large-scale sequence-structure PTM dataset, which serves as the foundation for fair comparison. We introduce the MeToken model, which tokenizes the micro-environment of each amino acid, integrating both sequence and structural information into unified discrete tokens. This model not only captures the typical sequence motifs associated with PTMs but also leverages the spatial arrangements dictated by protein tertiary structures, thus providing a holistic view of the factors influencing PTM sites. Designed to address the long-tail distribution of PTM types, MeToken employs uniform sub-codebooks that ensure even the rarest PTMs are adequately represented and distinguished. We validate the effectiveness and generalizability of MeToken across multiple datasets, demonstrating its superior performance in accurately identifying PTM types. The results underscore the importance of incorporating structural data and highlight MeToken's potential in facilitating accurate and comprehensive PTM predictions, which could significantly impact proteomics research."
    },
    {
        "title": "Strengthening Federated Learning: Surrogate Data-Guided Aggregation for Robust Backdoor Defense",
        "link_suffix": "/forum?id=s8lj3C39Ow",
        "link": "https://openreview.net/forum?id=s8lj3C39Ow",
        "pdf_link": "https://openreview.net/pdf?id=s8lj3C39Ow",
        "keywords": "Federated Learning, Backdoor Attacks, Generative Learning",
        "abstract": "Backdoor attacks in federated learning (FL) have garnered significant attention due to their destructive potential. Current advanced backdoor defense strategies typically involve calculating predefined metrics related to local models and modifying the server's aggregation rule accordingly. However, these metrics may exhibit biases due to the inclusion of malicious models in the calculation, leading to defense failures. To address this issue, we propose a novel backdoor defense method in FL named $\\textit{Su}$rrogate $\\textit{D}$ata-guided $\\textit{A}$ggregation (SuDA). SuDA independently evaluates local models using surrogate data, thereby mitigating the influence of malicious models. Specifically, it constructs a surrogate dataset composed of pure noise, which is shared between the server and clients. By leveraging this shared surrogate data, clients train their models using both the shared and local data, while the server reconstructs potential triggers for each local model to identify backdoors, facilitating the filtering of backdoored models before aggregation. To ensure the generalizability of local models across both local and surrogate data, SuDA aligns local data with surrogate data in the representation space, supported by theoretical analysis. Comprehensive experiments demonstrate the substantial superiority of SuDA over previous works."
    },
    {
        "title": "Conformal Bounds on Full-Reference Image Quality for Imaging Inverse Problems",
        "link_suffix": "/forum?id=8VXWQmNrca",
        "link": "https://openreview.net/forum?id=8VXWQmNrca",
        "pdf_link": "https://openreview.net/pdf?id=8VXWQmNrca",
        "keywords": "Inverse Problems, Conformal Prediction, Uncertainty Quantification, MRI",
        "abstract": "In imaging inverse problems, we would like to know how close the recovered image is to the true image in terms of full-reference image quality (FRIQ) metrics like PSNR, SSIM, LPIPS, etc. This is especially important in safety-critical applications like medical imaging, where knowing that, say, the SSIM was poor could potentially avoid a costly misdiagnosis. But since we don't know the true image, computing FRIQ is non-trivial. In this work, we combine conformal prediction with approximate posterior sampling to construct bounds on FRIQ that are guaranteed to hold up to a user-specified error probability. We demonstrate our approach on image denoising and accelerated magnetic resonance imaging (MRI) problems."
    },
    {
        "title": "GMValuator: Similarity-based Data Valuation for Generative Models",
        "link_suffix": "/forum?id=WncnpvJk83",
        "link": "https://openreview.net/forum?id=WncnpvJk83",
        "pdf_link": "https://openreview.net/pdf?id=WncnpvJk83",
        "keywords": "Generative Model, Data Valuation",
        "abstract": "Data valuation plays a crucial role in machine learning. Existing data valuation methods, mainly focused on discriminative models, overlook generative models that have gained attention recently. In generative models, data valuation measures the impact of training data on generated datasets. Very few existing attempts at data valuation methods designed for deep generative models either concentrate on specific models or lack robustness in their outcomes. Moreover, efficiency still reveals vulnerable shortcomings. We formulate the data valuation problem in generative models from a similarity matching perspective to bridge the gaps. Specifically, we introduce Generative Model Valuator (GMValuator), the first training-free and model-agnostic approach to providing data valuation for generation tasks. It empowers efficient data valuation through our innovative similarity matching module, calibrates biased contributions by incorporating image quality assessment, and attributes credits to all training samples based on their contributions to the generated samples.  Additionally, we introduce four evaluation criteria for assessing data valuation methods in generative models. GMValuator is extensively evaluated on benchmark and high-resolution datasets and various mainstream generative architectures to demonstrate its effectiveness."
    },
    {
        "title": "Active-Dormant Attention Heads: Mechanistically Demystifying Extreme-Token Phenomena in LLMs",
        "link_suffix": "/forum?id=uEPRY2XAEs",
        "link": "https://openreview.net/forum?id=uEPRY2XAEs",
        "pdf_link": "https://openreview.net/pdf?id=uEPRY2XAEs",
        "keywords": "attention sink, mechanistic interpretability, language models, transformers",
        "abstract": "We investigate the mechanisms behind three puzzling phenomena observed in transformer-based large language models (LLMs):attention sinks,value-state drains, andresidual-state peaks, collectively referred to theextreme-token phenomena. First, we demonstrate that these phenomena also arise in simpler architectures\u2014transformers with one to three layers\u2014trained on a toy model, the Bigram-Backcopy (BB) task. In this setting, we identify anactive-dormant mechanismthat causes attention heads to become attention sinks for certain domain-specific inputs while remaining non-sinks for others. We further develop a precise theoretical characterization of the training dynamics that lead to these phenomena, revealing that they are driven by amutual reinforcement mechanism. By small interventions, we demonstrate ways to avoid extreme-token phenomena during pre-training. Next, we extend our analysis to pre-trained LLMs, including Llama and OLMo, revealing that many attention heads are governed by a similar active-dormant mechanism as in the BB task. We further show that the same mutual reinforcement mechanism drives the emergence of extreme-token phenomena during LLM pre-training. Our results study the mechanisms behind extreme-token phenomena in both synthetic and real settings and offer potential mitigation strategies."
    },
    {
        "title": "A Hybrid Simulation of DNN-based Gray Box Models",
        "link_suffix": "/forum?id=sSWiZr8QU7",
        "link": "https://openreview.net/forum?id=sSWiZr8QU7",
        "pdf_link": "https://openreview.net/pdf?id=sSWiZr8QU7",
        "keywords": "gray box modeling, simulation, neural networks",
        "abstract": "Simulation is vital for scientific and engineering disciplines, as it enables the prediction and design of physical systems. However, the computational challenges inherent to large-scale simulations often arise from complex device models featuring high degrees of nonlinearities or hidden physical behaviors not captured by first principles. Gray-box models that combine deep neural networks (DNNs) with physics-based models have been proposed to address the computational challenges in modeling complex physical systems. A well-crafted gray box model capitalizes on the interpretability and accuracy of a physical model while incorporating deep neural networks to capture hidden physical behaviors and mitigate computational load associated with highly nonlinear components. Previously, gray box models have been constructed by defining an explicit combination of physics-based and black-box models to represent the behavior of sub-systems; however this alone cannot represent the coupled interactions that define the behavior of the entire physical system. We, therefore, explore an implicit gray box model, where both DNNs (trained on measurement and simulated data) and physical equations share a common set of state-variables. While this approach captures coupled interactions at the boundary of data-driven and physics-based models, simulating the implicit gray box model remains an open-ended problem. In this work, we introduce a new hybrid simulation that directly integrates DNNs into the numerical solvers of simulation engines to fully simulate implicit gray box models of large physical systems. This is accomplished by backpropagating through the DNN to calculate specific Jacobian values during each iteration of the numerical method. The hybrid simulation of implicit gray-box models improves the accuracy and runtime compared to full physics-based simulation and enables reusable DNN models with lower data requirements for training. For demonstration, we explore the advantages of this approach as compared to physics-based, black box, and other gray box methods for simulating the steady-state and electromagnetic transient behavior of power systems."
    },
    {
        "title": "Implicit In-context Learning",
        "link_suffix": "/forum?id=G7u4ue6ncT",
        "link": "https://openreview.net/forum?id=G7u4ue6ncT",
        "pdf_link": "https://openreview.net/pdf?id=G7u4ue6ncT",
        "keywords": "Large Language Model, In-context Learning, Activation Engineering, Efficiency",
        "abstract": "In-context Learning (ICL) empowers large language models (LLMs) to swiftly\nadapt to unseen tasks during at inference-time by prefixing a few demonstration\nexamples before queries. Despite its versatility, ICL incurs substantial computa-\ntional and memory overheads compared to zero-shot learning and is sensitive to\nthe selection and order of demonstration examples. In this work, we introduce\nImplicit In-context Learning (I2CL), an innovative paradigm that reduces the\ninference cost of ICL to that of zero-shot learning with minimal information loss.\nI2CL operates by first generating a condensed vector representation, namely a\ncontext vector, extracted from the demonstration examples. It then conducts an\ninference-time intervention through injecting a linear combination of the context\nvector and query activations back into the model\u2019s residual streams. Empirical\nevaluation on nine real-world tasks across three model architectures demonstrates\nthat I2CL achieves few-shot level performance at zero-shot cost, and it exhibits\nrobustness against variations in demonstration examples. Furthermore, I2CL facilitates a novel representation of \u201ctask-ids\u201d, enhancing task similarity detection and\nfostering effective transfer learning. We also performs a comprehensive analysis\nand ablation study on I2CL, offering deeper insights into its internal mechanisms."
    },
    {
        "title": "Advancing Multimodal Unified Discrete Representations",
        "link_suffix": "/forum?id=LRifwkqJEW",
        "link": "https://openreview.net/forum?id=LRifwkqJEW",
        "pdf_link": "https://openreview.net/pdf?id=LRifwkqJEW",
        "keywords": "Training-free Optimization, MultiModal Learning, Representation Learning",
        "abstract": "To enhance the interpretability of multimodal unified representations, many studies have focused on discrete unified representations. These efforts typically start with contrastive learning and gradually extend to the disentanglement of modal information, achieving solid multimodal discrete unified representations. However, existing research often overlooks two critical issues: 1) Different modalities have unique characteristics, and a uniform alignment approach does not fully exploit these traits; 2) The use of Euclidean distance for quantization in discrete representations often overlooks the important distinctions among different dimensions of features, resulting in redundant representations after quantization. To address these issues, we propose Fine and Coarse Cross-modal Information Disentangling (FCCID) and Training-Free Optimization of Codebook (TOC). These methods respectively perform fine and coarse disentanglement of information based on the specific characteristics of different modalities and refine the unified discrete representations obtained from pretraining. Compared to the previous state-of-the-art, our model demonstrates significant performance improvements. The code is provided in the supplementary materials."
    },
    {
        "title": "Learning Dynamics of LLM Finetuning",
        "link_suffix": "/forum?id=tPNHOoZFl9",
        "link": "https://openreview.net/forum?id=tPNHOoZFl9",
        "pdf_link": "https://openreview.net/pdf?id=tPNHOoZFl9",
        "keywords": "Learning dynamics, LLM, finetuning, DPO",
        "abstract": "Learning dynamics, which describes how the learning of specific training examples influences the model's predictions on other examples, \ngives us a powerful tool for understanding the behavior of deep learning systems. We study the learning dynamics of large language models during different types of finetuning, by analyzing the step-wise decomposition of how influence accumulates among different potential responses. Our framework allows a uniform interpretation of many interesting observations about the training of popular algorithms for both instruction tuning and preference tuning. In particular, we propose a hypothetical explanation of why specific types of hallucination are strengthened after finetuning, e.g., the model might use phrases or facts in the response for question B to answer question A, or the model might keep repeating similar simple phrases when generating responses. We also extend our framework and highlight a unique ``squeezing effect'' to explain a previously observed phenomenon in off-policy direct preference optimization (DPO), where running DPO for too long makes even the desired outputs less likely. This framework also provides insights into where the benefits of on-policy DPO and other variants come from. The analysis not only provides a novel perspective of understanding LLM's finetuning but also inspires a simple, effective method to improve alignment performance."
    },
    {
        "title": "DeLLMa: Decision Making Under Uncertainty with Large Language Models",
        "link_suffix": "/forum?id=Acvo2RGSCy",
        "link": "https://openreview.net/forum?id=Acvo2RGSCy",
        "pdf_link": "https://openreview.net/pdf?id=Acvo2RGSCy",
        "keywords": "large language models, decision theory, decision making under uncertainty",
        "abstract": "The potential of large language models (LLMs) as decision support tools is increasingly being explored in fields such as business, engineering, and medicine, which often face challenging tasks ofdecision-making under uncertainty. In this paper, we show that directly prompting LLMs on these types of decision-making problems can yield poor results, especially as the problem complexity increases. To aid in these tasks, we propose DeLLMa (Decision-making Large Language Model assistant), a framework designed to enhance decision-making accuracy in uncertain environments. DeLLMa involves a multi-step reasoning procedure that integrates recent best practices in scaling inference-time reasoning, drawing upon principles from decision theory and utility theory, to provide an accurate and human-auditable decision-making process. We validate our procedure on multiple realistic decision-making environments, demonstrating that DeLLMa can consistently enhance the decision-making performance of leading language models, and achieve up to a 40% increase in accuracy over competing methods. Additionally, we show how performance improves when scaling compute at test time, and carry out human evaluations to benchmark components of DeLLMa."
    },
    {
        "title": "OmniRe: Omni Urban Scene Reconstruction",
        "link_suffix": "/forum?id=11xgiMEI5o",
        "link": "https://openreview.net/forum?id=11xgiMEI5o",
        "pdf_link": "https://openreview.net/pdf?id=11xgiMEI5o",
        "keywords": "Gaussians Splatting, Neural Rendering, Dynamic Scene Reconstruction, Autonomous Driving",
        "abstract": "We introduce OmniRe, a comprehensive system for efficiently creating high-fidelity digital twins of dynamic real-world scenes from on-device logs. Recent methods using neural fields or Gaussian Splatting primarily focus on vehicles, hindering a holistic framework for all dynamic foregrounds demanded by downstream applications, e.g., the simulation of human behavior. OmniRe extends beyond vehicle modeling to enable accurate, full-length reconstruction of diverse dynamic objects in urban scenes. Our approach builds scene graphs on 3DGS and constructs multiple Gaussian representations in canonical spaces that model various dynamic actors, including vehicles, pedestrians, cyclists, and others. OmniRe allows holistically reconstructing any dynamic object in the scene, enabling advanced simulations (~60 Hz) that include human-participated scenarios, such as pedestrian behavior simulation and human-vehicle interaction. This comprehensive simulation capability is unmatched by existing methods. Extensive evaluations on the Waymo dataset show that our approach outperforms prior state-of-the-art methods quantitatively and qualitatively by a large margin. We further extend our results to 5 additional popular driving datasets to demonstrate its generalizability on common urban scenes. We will make the code and data publicly available."
    },
    {
        "title": "Root Cause Analysis of Anomalies in Multivariate Time Series through Granger Causal Discovery",
        "link_suffix": "/forum?id=k38Th3x4d9",
        "link": "https://openreview.net/forum?id=k38Th3x4d9",
        "pdf_link": "https://openreview.net/pdf?id=k38Th3x4d9",
        "keywords": "root cause analysis, Granger causality, multivariate time series",
        "abstract": "Identifying the root causes of anomalies in multivariate time series is challenging due to the complex dependencies among the series. In this paper, we propose a comprehensive approach called AERCA that inherently integrates Granger causal discovery with root cause analysis. By defining anomalies as interventions on the exogenous variables of time series, AERCA not only learns the Granger causality among time series but also explicitly models the distributions of exogenous variables under normal conditions. AERCA then identifies the root causes of anomalies by highlighting exogenous variables that significantly deviate from their normal states. Experiments on multiple synthetic and real-world datasets demonstrate that AERCA can accurately capture the causal relationships among time series and effectively identify the root causes of anomalies."
    },
    {
        "title": "Unleash The Power of Color for Point Cloud Registration",
        "link_suffix": "/forum?id=hepYqFTeAD",
        "link": "https://openreview.net/forum?id=hepYqFTeAD",
        "pdf_link": "https://openreview.net/pdf?id=hepYqFTeAD",
        "keywords": "colored point cloud registration",
        "abstract": "Point cloud registration (PCR) has been an important research subject for many years but remains an open problem, presenting numerous challenges. The stability of existing registration methods is often inadequate, particularly in scenarios with low overlap. This issue primarily arises from the insufficient distinctiveness of extracted point cloud features, leading to ambiguous matches and the proliferation of outliers. To address these bottlenecks in point cloud registration, it is crucial to fully leverage the color information of the point clouds to discern point correspondences effectively.\nHowever, excessive control over color may disrupt the spatial structure of the point cloud, making it essential to find a balance between the aggressiveness and stability of color integration.\nTo tackle these challenges, we propose UPC-PCR, which unlocks the potential of color information while maintaining stability. Specifically, we design a Curvature-Color Fusion Module (CCF) to initialize distinctive features. Additionally, to balance color aggressiveness, we enhance the geometric structure by introducing a Centroid Angular (CA) embedding for superpoint structure encoding, which is particularly effective in low-overlap scenes.\nWhile CCF and CA ensure the distinctiveness of point features, the aggressive use of color in the feature enhancement process may still introduce errors. Therefore, we develop a robust estimator equipped with Feature-based Compatibility Hypergraph Convolution (FCH) to learn higher-order compatibility of correspondences and effectively filter out outliers.\nEvaluation across multiple datasets has demonstrated the state-of-the-art performance of UPC-PCR, achieving registration recalls of 98.4%/90.4% on Color3DMatch/Color3DLoMatch."
    },
    {
        "title": "L-C4: Language-Based Video Colorization for Creative and Consistent Colors",
        "link_suffix": "/forum?id=lessla98Wp",
        "link": "https://openreview.net/forum?id=lessla98Wp",
        "pdf_link": "https://openreview.net/pdf?id=lessla98Wp",
        "keywords": "Video Editing, Diffusion Model, Colorization",
        "abstract": "Automatic video colorization is inherently an ill-posed problem because each monochrome frame has multiple optional color candidates.\nPrevious exemplar-based video colorization methods restrict the user's imagination due to the elaborate retrieval process. Alternatively, conditional image colorization methods combined with post-processing algorithms still struggle to maintain temporal consistency. To address these issues, we present Language-based video Colorization for Creative and Consistent Colors (L-C4) to guide the colorization process using user-provided language descriptions. Our model is built upon a pre-trained cross-modality generative model, leveraging its comprehensive language understanding and robust color representation abilities. We introduce the cross-modality pre-fusion module to generate instance-aware text embeddings, enabling the application of creative colors. Additionally, we propose temporally deformable attention to prevent flickering or color shifts, and cross-clip fusion to maintain long-term color consistency.  Extensive experimental results demonstrate that L-C4 outperforms relevant methods, achieving semantically accurate colors, unrestricted creative correspondence, and temporally robust consistency."
    },
    {
        "title": "Utilizing Explainable Reinforcement Learning to Improve Reinforcement Learning: A Theoretical and Systematic Framework",
        "link_suffix": "/forum?id=Tk1VQDadfL",
        "link": "https://openreview.net/forum?id=Tk1VQDadfL",
        "pdf_link": "https://openreview.net/pdf?id=Tk1VQDadfL",
        "keywords": "explainable reinforcement learning",
        "abstract": "Reinforcement learning (RL) faces two challenges: (1) The RL agent lacks explainability. (2) The trained RL agent is, in many cases, non-optimal and even far from optimal. To address the first challenge, explainable reinforcement learning (XRL) is proposed to explain the decision-making of the RL agent. In this paper, we demonstrate that XRL can also be used to address the second challenge, i.e., improve RL performance. Our method has two parts. The first part provides a two-level explanation for why the RL agent is not optimal by identifying the mistakes made by the RL agent. Since this explanation includes the mistakes of the RL agent, it has the potential to help correct the mistakes and thus improve RL performance. The second part formulates a constrained bi-level optimization problem to learn how to best utilize the two-level explanation to improve RL performance. In specific, the upper level learns how to use the high-level explanation to shape the reward so that the corresponding policy can maximize the cumulative ground truth reward, and the lower level learns the corresponding policy by solving a constrained RL problem formulated using the low-level explanation. We propose a novel algorithm to solve this constrained bi-level optimization problem, and theoretically guarantee that the algorithm attains global optimality. We use MuJoCo experiments to show that our method outperforms state-of-the-art baselines."
    },
    {
        "title": "FlipNet: Fourier Lipschitz Smooth Policy Network for Reinforcement Learning",
        "link_suffix": "/forum?id=maoBEh5rU7",
        "link": "https://openreview.net/forum?id=maoBEh5rU7",
        "pdf_link": "https://openreview.net/pdf?id=maoBEh5rU7",
        "keywords": "Reinforcement Learning, Neural Network, Action Fluctuation, Control Smoothness and Robustness, Real-world Application, Lipschitz Continuity, Fourier Transform",
        "abstract": "Deep reinforcement learning (RL) is an effective method for decision-making and control tasks. However, RL-trained policies encounter the action fluctuation problem, where consecutive actions significantly differ despite minor variations in adjacent states. This problem results in actuators' wear, safety risk, and performance reduction in real-world applications. To address the problem, we identify the two fundamental reasons causing action fluctuation, i.e. policy non-smoothness and observation noise, then propose the Fourier Lipschitz Smooth Policy Network (FlipNet). FlipNet adopts two innovative techniques to tackle the two reasons in a decoupled manner. Firstly, we prove the Jacobian norm is an approximation of Lipschitz constant and introduce a Jacobian regularization technique to enhance the smoothness of policy network. Secondly, we introduce a Fourier filter layer to deal with observation noise. The filter layer includes a trainable filter matrix that can automatically extract important observation frequencies and suppress noise frequencies. FlipNet can be seamlessly integrated into most existing RL algorithms as an actor network. Simulated tasks on DMControl and a real-world experiment on vehicle-robot driving show that FlipeNet has excellent action smoothness and noise robustness, achieving a new state-of-the-art performance. The code and videos are publicly available."
    },
    {
        "title": "An Exact Solver for Satisfiability Modulo Counting with Probabilistic Circuits",
        "link_suffix": "/forum?id=AmEN51cTKW",
        "link": "https://openreview.net/forum?id=AmEN51cTKW",
        "pdf_link": "https://openreview.net/pdf?id=AmEN51cTKW",
        "keywords": "Satisfiabilty, Satisfiability Modulo Counting, Uncertainty in AI, Statistical AI",
        "abstract": "Satisfiability Modulo Counting (SMC) is a general language to reason about problems integrating statistical and symbolic artificial intelligence. An SMC formula is an SAT formula in which the truth values of a few Boolean predicates are determined by model counting, or equivalently, probabilistic inference. Existing solvers optimize surrogate objectives and hence provide no formal guarantee. Hence, an exact solver is desperately in need. However, the direct integration of satisfiability and probabilistic inference solvers results in slow SMC solving because of many back-and-forth invocations of both solvers. We develop KOCO-SMC, a fast exact SMC solver, exploiting the fact that many similar probabilistic inferences are needed throughout SMC solving. We compile the probabilistic inference part of SMC solving into probabilistic circuits, supporting efficient lower and upper-bound computation. Experiment results in several real-world applications demonstrate that our approach provides exact solutions, much better than those from approximate solvers, while is more efficient than direct integration with the current exact solvers."
    },
    {
        "title": "Neptune: The Long Orbit to Benchmarking Long Video Understanding",
        "link_suffix": "/forum?id=5ddsALwqkf",
        "link": "https://openreview.net/forum?id=5ddsALwqkf",
        "pdf_link": "https://openreview.net/pdf?id=5ddsALwqkf",
        "keywords": "video understanding, dataset, metric, long video understanding, benchmark",
        "abstract": "This paper describes a semi-automatic pipeline to generate challenging question-answer-decoy sets for understanding long videos.  Many existing video datasets and models are focused on short clips (10s-30s). While some long video datasets do exist, they can often be solved by powerful image models applied per frame (and often to very few frames) in a video, and are usually manually annotated at high cost. In order to mitigate both these problems, we propose a scalable dataset creation pipeline which leverages large models (VLMs and LLMs), to automatically generate dense, time-aligned video captions, as well as tough question answer decoy sets for video segments (up to 15 minutes in length). Our dataset Neptune covers a broad range of long video reasoning abilities and consists of a subset tha temphasizes multimodal reasoning. Since existing metrics for open-ended question answering are either rule-based or may rely on proprietary models, we provide a new open source model-based metric (GEM) to score open-ended responses on Neptune. Benchmark evaluations reveal that current open-source long video models perform poorly on Neptune, particularly on questions testing temporal ordering, counting and state changes. Through Neptune, we aim to spur the development of more advanced models capable of understanding long videos."
    }
]
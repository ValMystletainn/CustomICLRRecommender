[
    {
        "title": "Transformers Use Causal World Models in Maze-Solving Tasks",
        "link_suffix": "/forum?id=aE6QjMJ1mN",
        "link": "https://openreview.net/forum?id=aE6QjMJ1mN",
        "pdf_link": "https://openreview.net/pdf?id=aE6QjMJ1mN",
        "keywords": "mechanistic, interpretability, world models, transformers",
        "abstract": "Recent studies in interpretability have explored the inner workings of transformer models trained on tasks across various domains, often discovering that these networks naturally develop surprisingly structured representations. When such representations comprehensively reflect the task domain\u2019s structure, they are commonly referred to as \u201cWorld Models\u201d (WMs). In this work, we discover such WMs in transformers trained on maze tasks. By analyzing the causal role of these WMs, we hope to contribute to the development of more interpretable and controllable AI systems. In particular, by employing Sparse Autoencoders (SAEs) and analysing attention patterns, we examine the construction of WMs and demonstrate consistency between the circuit analysis and the SAE feature-based analysis. We intervene upon the isolated features to confirm their causal role and, in doing so, find asymmetries between certain types of interventions. Surprisingly, we find that models are able to reason with respect to more active features than they would ever have observed during training, even if attempting to specify these in the input token sequence would lead the model to fail. We also observe that varying positional encodings can alter how WMs are encoded in a model\u2019s residual stream."
    },
    {
        "title": "IDInit: A Universal and Stable Initialization Method for Neural Network Training",
        "link_suffix": "/forum?id=LFiaoYnP6T",
        "link": "https://openreview.net/forum?id=LFiaoYnP6T",
        "pdf_link": "https://openreview.net/pdf?id=LFiaoYnP6T",
        "keywords": "Initialization, Idetity Matrix, Dynamic Isometry",
        "abstract": "Deep neural networks have achieved remarkable accomplishments in practice. The success of these networks hinges on effective initialization methods, which are vital for ensuring stable and rapid convergence during training. Recently, initialization methods that maintain identity transition within layers have shown good efficiency in network training. These techniques (e.g., Fixup) set specific weights to zero to achieve identity control. However, settings of remaining weight (e.g., Fixup uses random values to initialize non-zero weights) will affect inductive bias that is achieved only by a zero weight, which may be harmful to training. Addressing this concern, we introduce fully identical initialization (IDInit), a novel method that preserves identity in both the main and sub-stem layers of residual networks. IDInit employs a padded identity-like matrix to overcome rank constraints in non-square weight matrices. Furthermore, we show the convergence problem of an identity matrix can be solved by stochastic gradient descent. Additionally, we enhance the universality of IDInit by processing higher-order weights and addressing dead neuron problems. IDInit is a straightforward yet effective initialization method, with improved convergence, stability, and performance across various settings, including large-scale datasets and deep models."
    },
    {
        "title": "Length Desensitization in Direct Preference Optimization",
        "link_suffix": "/forum?id=CuwjD3cazX",
        "link": "https://openreview.net/forum?id=CuwjD3cazX",
        "pdf_link": "https://openreview.net/pdf?id=CuwjD3cazX",
        "keywords": "large language model, reinforcement learning from human feedback, preference optimization",
        "abstract": "Direct Preference Optimization (DPO) is widely utilized in the Reinforcement Learning from Human Feedback (RLHF) phase to align Large Language Models (LLMs) with human preferences, thereby enhancing both their harmlessness and efficacy.  However, it has been observed that DPO tends to over-optimize for verbosity, which can detrimentally affect both performance and user experience. In this paper, we conduct an in-depth theoretical analysis of DPO's optimization objective and reveal a strong correlation between its implicit reward and data length. This correlation misguides the optimization direction, resulting in length sensitivity during the DPO training and leading to verbosity. To address this issue, we propose a length-desensitization improvement method for DPO, termed LD-DPO. The proposed method aims to desensitize DPO to data length by decoupling explicit length preference, which is relatively insignificant, from the other implicit preferences, thereby enabling more effective learning of the intrinsic preferences. We utilized two settings (Base and Instruct) of Llama2-13B, Llama3-8B, and Qwen2-7B for experimental validation on various benchmarks including MT-Bench and AlpacaEval 2. The experimental results indicate that LD-DPO consistently outperforms DPO and other baseline methods, achieving more concise responses with a 10-40% reduction in length compared to DPO. We conducted in-depth experimental analyses to demonstrate that LD-DPO can indeed achieve length desensitization and align the model more closely with human-like preferences.\n\u201dBrevity is the Soul of Wit.''\u2014William Shakespeare"
    },
    {
        "title": "TimeKAN: A Transparent KAN-Based Approach for Multivariate Time Series Forecasting",
        "link_suffix": "/forum?id=9KNnSvUxLl",
        "link": "https://openreview.net/forum?id=9KNnSvUxLl",
        "pdf_link": "https://openreview.net/pdf?id=9KNnSvUxLl",
        "keywords": "Multi-variate Time Series (MTS) Forecasting, Kolmogorov-Arnold Networks (KAN), White Box, Multi-scale modelling",
        "abstract": "In recent years, numerous deep learning models have been proposed for Multi-variate Time Series (MTS) forecasting, with Transformer-based models showing significant potential due to their ability to capture long-term dependencies. However, existing models based on MLPs or Transformers often suffer from a lack of interpretability due to their large parameter sizes, which can be problematic in many real-world applications. To address this issue, we propose TimeKAN, a model based on Kolmogorov-Arnold Networks. The KAN model offers two key advantages: (1) it achieves accuracy comparable to MLPs with significantly fewer parameters, and (2) its parameters can be symbolized, which makes it possible to interpret the meaning of the parameters. Additionally, instead of the usual attention mechanisms, we designed a Multi-Scale Patching (MSP) module for MTS that allows for more flexible and simple multi-patching and effectively extracts both temporal and cross-dimensional features. By leveraging this strategy along with KAN, TimeKAN constructs a hierarchical structure capable of utilizing information across different scales, leading to highly accurate predictions. Extensive experiments on six real-world datasets demonstrate that TimeKAN outperforms state-of-the-art (SOTA) methods in terms of predictive performance. Furthermore, we interpret TimeKAN by visualizing its learning process for extracting symbolized features, opening the black box and revealing meaningful patterns within the time series."
    },
    {
        "title": "Very Fast Graph Clustering for Single and Multiple Views",
        "link_suffix": "/forum?id=oqdcThIQjA",
        "link": "https://openreview.net/forum?id=oqdcThIQjA",
        "pdf_link": "https://openreview.net/pdf?id=oqdcThIQjA",
        "keywords": "Graph Clustering",
        "abstract": "Clustering is a fundamental step in learning and analyzing graphs.\nCommonly accepted criteria for evaluating graph clustering quality \nwithout ground truth are \nthe \"normalized cut\" (ncut), \nand the \"ratio cut\" (rcut).\nTraditional algorithms that minimize\nncut and rcut \ntake $O(mnk)$ to cluster\na graph of $n$ nodes and $m$ edges into $k$ clusters.\nFaster algorithms sacrifice accuracy for speed\nand run in $O(m {+} n k^2)$.\nA very recent algorithm runs in $O(m {+} n k \\log k )$.\nThe space complexity of these algorithms ranges from $O(n^2)$\nto $O(n \\log k)$.\nWe describe a new algorithm with running time of $O(m \\log m)$\nthat achieves accuracy similar to traditional algorithms.\nOur algorithm is simple to implement, and requires only $O(m)$ memory.\nIt can also be applied in the multi-view setting, \nwhere multiple graphs share the same set of nodes.\nOur algorithm can cluster a small number of views\nwith no increase in its running time. \nWe describe \na randomized implementation that allows a qualitative comparison\nbetween various internal clustering criteria. \nOur experiments suggest a new criterion\nthat we call \"linfcut\" as superior to both\nthe ncut and the Cheeger criteria,\ncomputing clusters that \"make more sense\" to a human observer.\nOur algorithm performs a search for edges between clusters.\nIts speed is the result of a strong \"ignorance\" (pruning) condition\nthat allows ignoring most of the edges after little computation."
    },
    {
        "title": "Tighter Privacy Auditing of DP-SGD in the Hidden State Threat Model",
        "link_suffix": "/forum?id=xzKFnsJIXL",
        "link": "https://openreview.net/forum?id=xzKFnsJIXL",
        "pdf_link": "https://openreview.net/pdf?id=xzKFnsJIXL",
        "keywords": "Differential Privacy, Privacy Auditing, Machine Learning",
        "abstract": "Machine learning models can be trained with formal privacy guarantees via differentially private optimizers such as DP-SGD. In this work, we focus on a threat model where the adversary has access only to the final model, with no visibility into intermediate updates. In the literature, this ``hidden state'' threat model exhibits a significant gap between the lower bound from empirical privacy auditing and the theoretical upper bound provided by privacy accounting. To challenge this gap, we propose to audit this threat model with adversaries that craft a gradient sequence designed to maximize the privacy loss of the final model without relying on intermediate updates. Our experiments show that this approach consistently outperforms previous attempts at auditing the hidden state model. Furthermore, our results advance the understanding of achievable privacy guarantees within this threat model. Specifically, when the crafted gradient is inserted at every optimization step, we show that concealing the intermediate model updates in DP-SGD does not amplify privacy. The situation is more complex when the crafted gradient is not inserted at every step: our auditing lower bound matches the privacy upper bound only for an adversarially-chosen loss landscape and a sufficiently large batch size. This suggests that existing privacy upper bounds can be improved in certain regimes."
    },
    {
        "title": "Cradle: Empowering Foundation Agents towards General Computer Control",
        "link_suffix": "/forum?id=aIAFDFpNXz",
        "link": "https://openreview.net/forum?id=aIAFDFpNXz",
        "pdf_link": "https://openreview.net/pdf?id=aIAFDFpNXz",
        "keywords": "Foundation Agents, Large Multimodal Models, Decision-making, General Computer Control",
        "abstract": "Despite their success in specific scenarios, existing foundation agents still struggle to generalize across various virtual scenarios, mainly due to the dramatically different encapsulations of environments with manually designed observation and action spaces. To handle this issue, we propose the General Computer Control (GCC) setting to restrict foundation agents to interact with software through the most unified and standardized interface, i.e., using screenshots as input and keyboard and mouse actions as output. We introduce Cradle, a modular and flexible LMM-powered framework, as a preliminary attempt towards GCC. Enhanced by six key modules, Information Gathering, Self-Reflection, Task Inference, Skill Curation, Action Planning, and Memory, Cradle is able to understand input screenshots and output executable code for low-level keyboard and mouse control after high-level planning and information retrieval, so that Cradle can interact with any software and complete long-horizon complex tasks without relying on any built-in APIs. Experimental results show that Cradle exhibits remarkable generalizability and impressive performance across four commercial never before explorer digital games, five software applications, and a comprehensive benchmark, OSWorld. To our best knowledge, Cradle is the first to enable foundation agents to follow the main storyline and complete one-hour-long real missions in the complex AAA game Red Dead Redemption 2 (RDR2). Cradle can also create a city of a thousand people in Cities: Skylines, farm and harvest parsnips in Stardew Valley, and trade and bargain with a maximal weekly total profit of 87% in Dealer's Life 2. Cradle can not only operate daily software, like Chrome, Outlook, and Feishu, but also edit images and videos using Meitu and CapCut. With a unified interface to interact with any software, Cradle greatly extends the reach of foundation agents by enabling the easy conversion of any software, especially complex games, into benchmarks to evaluate agents' various abilities and further collect detailed data, thus paving the way for generalist agents."
    },
    {
        "title": "Equivariant Graph Self-Attention Transformer for Learning Higher-Order Interactions in 3D Molecular Structures",
        "link_suffix": "/forum?id=Bi1083wNPb",
        "link": "https://openreview.net/forum?id=Bi1083wNPb",
        "pdf_link": "https://openreview.net/pdf?id=Bi1083wNPb",
        "keywords": "Graph Self-Attention, GNNs, 3D Molecular Structures",
        "abstract": "Despite their considerable success in multiple fields, studying 3D molecular structures of varying sizes presents a significant challenge in machine learning, particularly in drug discovery, as existing methods often struggle to accurately capture complex geometric relationships and tend to be less effective at generalizing across diverse molecular environments. To address these limitations, we propose a novel Equivariant Graph Self-Attention  Transformer, namely EG-SAT, which effectively leverages both geometric and relational features of molecular data while maintaining equivariance under Euclidean transformations. This approach enables the model to capture molecular geometry through higher-order representations, enhancing its ability to understand intricate spatial relationships and atomic interactions. By effectively modeling the radial and angular distributions of neighboring atoms within a specified cutoff distance using Atom-Centered Symmetry Functions (ACSFs), EG-SAT leads to a more nuanced and comprehensive understanding of molecular interactions. We validate our model on the QM9 and MD17 datasets, demonstrating that EG-SAT achieves state-of-the-art performance in predicting most quantum mechanical properties, thus showcasing its effectiveness and robustness in this domain."
    },
    {
        "title": "MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering",
        "link_suffix": "/forum?id=q6pm9CObJn",
        "link": "https://openreview.net/forum?id=q6pm9CObJn",
        "pdf_link": "https://openreview.net/pdf?id=q6pm9CObJn",
        "keywords": "Multilingual Visual Question Answering, Visual Text Understanding, Multimodal Comprehension Evaluation",
        "abstract": "Text-Centric Visual Question Answering(TEC-VQA) in its proper format not only facilitates human-machine interaction in text-centric visual environments but also serves as a de facto gold proxy to evaluate AI models in the domain of text-centric scene understanding. Nonetheless, most existing TEC-VQA benchmarks focus on high-resource languages like English and Chinese. Despite pioneering works expanding multilingual QA pairs in non-text-centric VQA datasets through translation engines, the translation-based protocol encounters a substantial ``visual-textual misalignment'' problem when applied to TEC-VQA. Specifically, it prioritizes the text in question-answer pairs while disregarding the visual text present in images. Moreover, it fails to address complexities related to nuanced meaning, contextual distortion, language bias, and question-type diversity. In this work, we tackle multilingual TEC-VQA by introducing MTVQA, the first benchmark featuring high-quality human expert annotations across 9 diverse languages, consisting of 6,778 question-answer pairs across 2,116 images. Further, by comprehensively evaluating numerous state-of-the-art Multimodal Large Language Models~(MLLMs), including GPT-4o, GPT-4V, Claude3, and Gemini, on the MTVQA dataset, it is evident that there is still a large room for performance improvement, underscoring the value of MTVQA. Additionally, we supply multilingual training data within the MTVQA dataset, demonstrating that straightforward fine-tuning with this data can substantially enhance multilingual TEC-VQA performance. We aspire that MTVQA will offer the research community fresh insights and stimulate further exploration in multilingual visual text comprehension."
    },
    {
        "title": "Textual Aesthetics in Large Language Models",
        "link_suffix": "/forum?id=EZXXJmuMd7",
        "link": "https://openreview.net/forum?id=EZXXJmuMd7",
        "pdf_link": "https://openreview.net/pdf?id=EZXXJmuMd7",
        "keywords": "Large Language Model, Textual Aesthetics",
        "abstract": "Image aesthetics is a crucial metric in the field of image generation. However, textual aesthetics has not been sufficiently explored. With the widespread application of large language models (LLMs), previous work has primarily focused on the correctness of content and the helpfulness of responses. Nonetheless, providing responses with textual aesthetics is also an important factor for LLMs, which can offer a cleaner layout and ensure greater consistency and coherence in content. In this work, we introduce a pipeline for aesthetics polishing and help construct a textual aesthetics dataset named TEXAES. We propose a textual aesthetics-powered fine-tuning method based on direct preference optimization, termed TAPO, which leverages textual aesthetics without compromising content correctness. Additionally, we develop two evaluation methods for textual aesthetics based on text and image analysis, respectively.Our experiments demonstrate that using textual aesthetics data and employing the TAPO fine-tuning method not only improves aesthetic scores but also enhances performance on general evaluation datasets such as AlpacalEval and Anera-hard."
    },
    {
        "title": "Local Curvature Descent: Squeezing More Curvature out of Standard and Polyak Gradient Descent",
        "link_suffix": "/forum?id=l9Q9GtNwkT",
        "link": "https://openreview.net/forum?id=l9Q9GtNwkT",
        "pdf_link": "https://openreview.net/pdf?id=l9Q9GtNwkT",
        "keywords": "convex optimization, adaptive step sizes, gradient methods",
        "abstract": "We contribute to the growing body of knowledge on more powerful and adaptive stepsizes for convex optimization, empowered by local curvature information. We do not go the route of fully-fledged second-order methods which require the expensive computation of the Hessian. Instead, our key observation is that, for some problems (e.g., when minimizing the sum of squares of absolutely convex functions), local curvature information is readily available, and can be used to obtain surprisingly powerful matrix-valued stepsizes, and meaningful theory. In particular, we develop three new methods \u2014 LCD1, LCD2 and LCD3 \u2014 where the abbreviation stands for local curvature descent. While LCD1 generalizes gradient descent with fixed stepsize, LCD2 generalizes gradient descent with Polyak stepsize. Our methods enhance these classical gradient descent baselines with local curvature information, and our theory recovers the known rates in the special case when no curvature information is used. Our last method, LCD3, is a variable-metric version of LCD2; this feature leads to a closed-form expression for the iterates. Our empirical results are encouraging, and show that the local curvature descent improves upon gradient descent."
    },
    {
        "title": "VersiCode: Towards Version-controllable Code Generation",
        "link_suffix": "/forum?id=l3YIMopcR9",
        "link": "https://openreview.net/forum?id=l3YIMopcR9",
        "pdf_link": "https://openreview.net/pdf?id=l3YIMopcR9",
        "keywords": "Large Language Model, Code Generation, API Evolution",
        "abstract": "Large Language Models (LLMs) have made tremendous strides in code generation, but existing research fails to account for the dynamic nature of software development, marked by frequent library updates. \nThis gap significantly limits LLMs' deployment in realistic settings. \nIn this paper, we propose two novel tasks aimed at bridging this gap: version-specific code completion (VSCC) and version-aware code migration (VACM). \nIn conjunction, we introduce VersiCode, a comprehensive Python dataset specifically designed to evaluate LLMs on these two tasks, together with a novel evaluation metric, Critical Diff Check (CDC@1), which assesses code generation against evolving API requirements. \nWe conduct an extensive evaluation of VersiCode, which reveals that version-controllable code generation is indeed a significant challenge, even for GPT-4o and other strong frontier models. \nWe believe the novel tasks, dataset, and metric open up a new, important research direction that will further enhance LLMs' real-world applicability. \nThe code and resources can be found in \n\\url{https://anonymous.4open.science/status/VersiCode-B0F6}."
    },
    {
        "title": "Analytic Continual Test-Time Adaptation for Multi-Modality Corruption",
        "link_suffix": "/forum?id=UhKkWHkvfg",
        "link": "https://openreview.net/forum?id=UhKkWHkvfg",
        "pdf_link": "https://openreview.net/pdf?id=UhKkWHkvfg",
        "keywords": "test time adaptation; multi-modality; continual learning; analytic learning",
        "abstract": "Test-Time Adaptation (TTA) aims to help pre-trained model bridge the gap between source and target datasets using only the pre-trained model and unlabelled test data. A key objective of TTA is to address domain shifts in test data caused by corruption, such as weather changes, noise, or sensor malfunctions. Multi-Modal Continual Test-Time Adaptation (MM-CTTA), an extension of TTA with better real-world applications, further allows pre-trained models to handle multi-modal inputs and adapt to continuously-changing target domains. MM-CTTA typically faces challenges including $\\textbf{error accumulation}$, $\\textbf{catastrophic forgetting}$, and $\\textbf{reliability bias}$, with few existing approaches effectively addressing these issues in multi-modal corruption scenarios. In this paper, we propose a novel approach, Multi-modality Dynamic Analytic Adapter (MDAA), for MM-CTTA tasks. We innovatively introduce analytic learning into TTA, using the Analytic Classifiers (ACs) to prevent model forgetting. Additionally, we develop Dynamic Selection Mechanism (DSM) and Soft Pseudo-label Strategy (SPS), which enable MDAA to dynamically filter reliable samples and integrate information from different modalities. Extensive experiments demonstrate that MDAA achieves state-of-the-art performance on MM-CTTA tasks while ensuring reliable model adaptation."
    },
    {
        "title": "Dynamic Alignment of Representations for Enhanced Chain-of-Thought Reasoning in Large Language Models",
        "link_suffix": "/forum?id=7hRuaiRlgZ",
        "link": "https://openreview.net/forum?id=7hRuaiRlgZ",
        "pdf_link": "https://openreview.net/pdf?id=7hRuaiRlgZ",
        "keywords": "Large Language Models; LLM reasoning; LLM COT; PEFT",
        "abstract": "Representations encode rich semantic information, implying that editing them could serve as a effective tool (i.e., DAS, REFT) for parameter-efficient finetuning (PEFT). However, existing approaches typically focus on general categories of representations or selecting an appropriate number of continuous representations for each datasets, which limits their adaptability and performance. In contrast, our method dynamically selects representations requiring intervention at the instance level, referred to as misaligned representations, which are characterized by a lack of semantic information or appropriate attention. Identifying these misaligned representations poses challenging, as they serve different roles in varying contexts. It is evident that crucial representations, which are those that primarily receive information flow from themselves or significantly influence other representations, are likely to encompass misaligned representations. Consequently, we simplify the task by pivot our focus to crucial representations and aim to accurately locate them. We adaptively update crucial representation amidst uncertainty, freezing the base model while learning an updated direction for each layer. Involving both identification and updating of representations, we present a PEFT method, termed Dynamic Alignment of Representations (DAR). We validate the effectiveness of our method on eight diverse datasets across two scenarios, arithmetic and commonsense, and three base models: LLaMA-2-7B, LLaMA-2-13B, and LLaMA-3-8B. Notably, our method yields improvements of 17.47% and 3.11% over LLaMA-2-7B and ReFT on the GSM8K dataset, respectively. Additionally, it requires only 51 times fewer parameters than LoRA, demonstrating significant parameter efficiency. Furthermore, our method can be easily extended to few-shot learning."
    },
    {
        "title": "Riemannian denoising diffusion probabilistic models",
        "link_suffix": "/forum?id=ZwO2I8gS5O",
        "link": "https://openreview.net/forum?id=ZwO2I8gS5O",
        "pdf_link": "https://openreview.net/pdf?id=ZwO2I8gS5O",
        "keywords": "generative modeling, diffusion probabilistic model, submanifold, projection scheme",
        "abstract": "We propose Riemannian Denoising Diffusion Probabilistic Models (RDDPMs) for learning distributions on submanifolds of Euclidean space that are level sets of functions, including most of the manifolds interested in applications. Existing methods for generative modeling on manifolds rely on substantial geometric information such as geodesic curves or eigenfunctions of the Laplacian-Beltrami operator and, as a result, they are limited to manifolds where such information is available. In contrast, our method, built on a projection scheme, can be applied to more general manifolds, as it only requires being able to evaluate the value and the first order derivatives of the function that defines the submanifold.  We provide a theoretical analysis of our method in the continuous-time limit, which elucidates the connection between our RDDPMs and score-based generative models on manifolds. The capability of our method is demonstrated on datasets from previous studies and on new datasets sampled from two high-dimensional manifolds, i.e. $\\mathrm{SO}(10)$ and configuration space of the molecular system alanine dipeptide with fixed dihedral angle."
    },
    {
        "title": "Towards Evaluating Generalist Agents: An Automated Benchmark in Open World",
        "link_suffix": "/forum?id=IWC6zUEVcL",
        "link": "https://openreview.net/forum?id=IWC6zUEVcL",
        "pdf_link": "https://openreview.net/pdf?id=IWC6zUEVcL",
        "keywords": "open-world, benchmark, generalist agents",
        "abstract": "Evaluating generalist agents presents significant challenges due to their wide-ranging abilities and the limitations of current benchmarks in assessing true generalization. We introduce the \\textbf{M}ine\\textbf{C}raft \\textbf{U}niverse (\\textbf{MCU}), a fully automated benchmarking framework set within the open-world game \\emph{Minecraft}. MCU dynamically generates and evaluates a broad spectrum of tasks, offering three core components: 1) a task generation mechanism that provides maximal freedom and variability, 2) an ever-expanding set of over \\textbf{3K} composable atomic tasks, and 3) a general evaluation framework that supports open-ended task assessment. By integrating large language models (LLMs), MCU dynamically creates diverse environments for each evaluation, fostering agent generalization. The framework uses a vision-language model (VLM) to automatically generate evaluation criteria, achieving over 90% agreement with human ratings across multi-dimensional assessments, which demonstrates that MCU is a scalable and explainable solution for evaluating generalist agents. Additionally, we show that while state-of-the-art foundational models perform well on specific tasks, they often struggle with increased task diversity and difficulty."
    },
    {
        "title": "Let\u2019s disagree to agree: Evaluating collective disagreement among AI vision systems",
        "link_suffix": "/forum?id=4ciEeIiIJ7",
        "link": "https://openreview.net/forum?id=4ciEeIiIJ7",
        "pdf_link": "https://openreview.net/pdf?id=4ciEeIiIJ7",
        "keywords": "deep learning, representational similarity",
        "abstract": "Recent advancements in artificial intelligence (AI) have led to the development of AI vision systems that closely resemble biological vision in terms of both behavior and neural recordings. While prior research in modeling biological vision has largely concentrated on comparing individual AI systems to a biological counterpart, our study instead investigates the collective behavior of model populations. We focus on inputs that generate the most divergent responses among a diverse population of AI vision systems, as measured by their aggregate disagreement. We would expect that the factors driving disagreement among AI systems are also causes of misalignment between AI systems and human perception. We challenge this expectation by demonstrating alignment between AI systems and humans at the population level, even for images that generate divergent responses among AI systems. This unexpected finding challenges our understanding of the relationship between the limitations of AI systems and human perception, suggesting that even the most challenging stimuli for AI systems are reflective of human perceptual difficulties."
    },
    {
        "title": "Detecting Out-of-Context Misinformation via Multi-Agent and Multi-Grained Retrieval",
        "link_suffix": "/forum?id=xS6uKkJ9Uz",
        "link": "https://openreview.net/forum?id=xS6uKkJ9Uz",
        "pdf_link": "https://openreview.net/pdf?id=xS6uKkJ9Uz",
        "keywords": "Multimodal Machine learning, Multi-modal Large Language Model",
        "abstract": "Misinformation remains a critical issue in today's information landscape, significantly impacting public perception and behavior. Among its various forms, out-of-context (OOC) misinformation is particularly pervasive, misrepresenting information by repurposing authentic images with false text. Traditional OOC detection methods often rely on coarse-grained similarity measures between image-text pairs, which fall short of providing interpretability and nuanced understanding. Conversely, whereas multimodal large language models (MLLMs) exhibit vast knowledge and an inherent ability for visual reasoning and explanation generation, they remain deficient in the complexity required to understand and discern nuanced cross-modal distinctions thoroughly. To address these challenges, we propose MACAW, a retrieval-based approach that indexes external knowledge, focusing on multiple granularities by extracting and cataloging relevant events and entities. Our framework first extracts multi-granularity information to assess the contextual integrity of news items, followed by a multi-agent reasoning process for accurate detection. Extensive experiments demonstrate the robustness and effectiveness of our proposed framework in identifying out-of-context fake news, outperforming the state-of-the-art solutions by {\\bf 4.3%}."
    },
    {
        "title": "Improving Complex Reasoning with Dynamic Prompt Corruption: A Soft Prompt Optimization Approach",
        "link_suffix": "/forum?id=h7Qz1ulnvF",
        "link": "https://openreview.net/forum?id=h7Qz1ulnvF",
        "pdf_link": "https://openreview.net/pdf?id=h7Qz1ulnvF",
        "keywords": "prompt tuning, corruption, information flow",
        "abstract": "Prompt Tuning (PT) has emerged as a promising Parameter-Efficient Fine-Tuning (PEFT) approach by appending trainable continuous prompt vectors to the input, maintaining competitive performance with significantly fewer trainable parameters. While PT has shown effectiveness in enhancing task performance, particularly for classification tasks, its application to complex reasoning tasks has been largely overlooked. Our investigation reveals that PT provides limited improvement and may even degrade performance in reasoning tasks. This phenomenon suggests that soft prompts can positively impact certain instances while negatively affecting others, particularly during the latter stages of reasoning.\nTo address these challenges, we propose a novel method called Dynamic Prompt Corruption (DPC), which seeks to optimize the use of soft prompts in reasoning tasks. DPC dynamically adjusts the influence of soft prompts based on their impact on the reasoning process. Specifically, it involves two key components: Dynamic Trigger and Dynamic Corruption. Dynamic Trigger measures the influence of soft prompts, determining whether their impact is beneficial or detrimental. Dynamic Corruption mitigates the negative effects of soft prompts by selectively masking key tokens that interfere with the reasoning process.\nWe validate our approach through extensive experiments on various large language models (LLMs) and reasoning tasks, including GSM8K, MATH, and AQuA. The results demonstrate that Dynamic Prompt Corruption consistently improves the performance of LLMs, achieving  4%-8% accuracy gains compared to standard prompt tuning. These findings highlight the effectiveness of our approach and its potential to enhance complex reasoning in LLMs."
    },
    {
        "title": "Commute Graph Neural Networks",
        "link_suffix": "/forum?id=3ktyyYGLxB",
        "link": "https://openreview.net/forum?id=3ktyyYGLxB",
        "pdf_link": "https://openreview.net/pdf?id=3ktyyYGLxB",
        "keywords": "Graph Neural Networks, Message Passing, Commute Time, Node Classification",
        "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in learning from graph-structured data. However, their application to directed graphs (digraphs) presents unique challenges, primarily due to the inherent asymmetry in node relationships. Traditional GNNs are adept at capturing unidirectional relations but fall short in encoding the mutual path dependencies between nodes, such as asymmetrical shortest paths typically found in digraphs. Recognizing this gap, we introduce Commute Graph Neural Networks (CGNN), an approach that seamlessly integrates node-wise commute time into the message passing scheme. The cornerstone of CGNN is an efficient method for computing commute time using a newly formulated digraph Laplacian. Commute time is then integrated into the neighborhood aggregation process, with neighbor contributions weighted according to their respective commute time to the central node in each layer. It enables CGNN to directly capture the mutual, asymmetric relationships in digraphs. Extensive experiments confirm the superior performance of CGNN. Source code of CGNN is anonymously available here."
    },
    {
        "title": "OSM+: Cloud-native Open Street Map Data System for City-wide Experiments",
        "link_suffix": "/forum?id=yatNm6A6sR",
        "link": "https://openreview.net/forum?id=yatNm6A6sR",
        "pdf_link": "https://openreview.net/pdf?id=yatNm6A6sR",
        "keywords": "Global dataset, Traffic prediction, Traffic policy control",
        "abstract": "Road network data can provide rich information about cities and thus become the base for various urban research. However, processing large-volume world-wide road network data requires intensive computing resources and the processed results might be different to be unified for benchmark downstream tasks. Therefore, in this paper, we process the OpenStreetMap data and release a structured world-wide 1-billion-node road network graph database with high accessibility and usability. We have presented three illustrative use cases, traffic prediction task, city boundary detection task and traffic policy control task. Moreover, for the well-investigated traffic prediction task, we release a new benchmark with 31 datasets, which is much more comprehensive than the previously frequently-used datasets. While for the relatively novel traffic policy control task, we release a new 6 city datasets with much larger scale than the previous datasets. Along with the OSM+ dataset, the release of data converters facilitates the integration of multimodal spatial-temporal data based on map information for large model training, thereby expediting the process of uncovering compelling scientific insights."
    },
    {
        "title": "DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking head Video Generation",
        "link_suffix": "/forum?id=vjHySpxDsv",
        "link": "https://openreview.net/forum?id=vjHySpxDsv",
        "pdf_link": "https://openreview.net/pdf?id=vjHySpxDsv",
        "keywords": "Talking head generation, Non-autoregressive generation, Avatar, Video generation, Diffusion model",
        "abstract": "Talking head generation intends to produce vivid and realistic talking head videos from a single portrait and speech audio clip. Although significant progress has been made in diffusion-based talking head generation, almost all methods rely on autoregressive strategies, which suffer from limited context utilization beyond the current generation step, error accumulation, and slower generation speed. To address these challenges, we present DAWN (\\textbf{D}ynamic frame \\textbf{A}vatar \\textbf{W}ith \\textbf{N}on-autoregressive diffusion), a framework that enables all-at-once generation of dynamic-length video sequences. Specifically, it consists of two main components:  (1) audio-driven holistic facial dynamics generation in the latent motion space, and (2) audio-driven head pose and blink generation. Extensive experiments demonstrate that our method generates authentic and vivid videos with precise lip motions, and natural pose/blink movements. Additionally, with a high generation speed, DAWN possesses strong extrapolation capabilities, ensuring the stable production of high-quality long videos. These results highlight the considerable promise and potential impact of DAWN in the field of talking head video generation. Furthermore, we hope that DAWN sparks further exploration of non-autoregressive approaches in diffusion models. Our code will be publicly available."
    },
    {
        "title": "Glocal Hypergradient Estimation with Koopman Operator",
        "link_suffix": "/forum?id=PH09buDIBT",
        "link": "https://openreview.net/forum?id=PH09buDIBT",
        "pdf_link": "https://openreview.net/pdf?id=PH09buDIBT",
        "keywords": "gradient-based hyperparameter optimization, koopman operator theory, dynamical systems",
        "abstract": "Gradient-based hyperparameter optimization methods update hyperparameters using hypergradients, gradients of a meta criterion with respect to hyperparameters. Previous research used two distinct update strategies: optimizing hyperparameters using global hypergradients obtained after completing model training or local hypergradients derived after every few model updates. While global hypergradients offer reliability, their computational cost is significant; conversely, local hypergradients provide speed but are often suboptimal. In this paper, we proposeglocalhypergradient estimation, blending \"global\" quality with \"local\" efficiency. To this end, we use the Koopman operator theory to linearize the dynamics of hypergradients so that the global hypergradients can be efficiently approximated only by using a trajectory of local hypergradients. Consequently, we can optimize hyperparameters greedily using estimated global hypergradients, achieving both reliability and efficiency simultaneously. Through numerical experiments of hyperparameter optimization, including optimization of optimizers, we demonstrate the effectiveness of the glocal hypergradient estimation."
    },
    {
        "title": "CAT: Concept-level backdoor ATtacks for Concept Bottleneck Models",
        "link_suffix": "/forum?id=j8xJJkpZpw",
        "link": "https://openreview.net/forum?id=j8xJJkpZpw",
        "pdf_link": "https://openreview.net/pdf?id=j8xJJkpZpw",
        "keywords": "Explainable AI; Backdoor attack; Concept bottleneck model",
        "abstract": "Despite the transformative impact of deep learning across multiple domains, the inherent opacity of these models has driven the development of Explainable Artificial Intelligence (XAI). Among these efforts, Concept Bottleneck Models (CBMs) have emerged as a key approach to improve interpretability by leveraging high-level semantic information. However, CBMs, like other machine learning models, are susceptible to security threats, particularly backdoor attacks, which can covertly manipulate model behaviors. Understanding that the community has not yet studied the concept level backdoor attack of CBM, because of \"Better the devil you know than the devil you don't know.\", we introduce CAT (Concept-level Backdoor ATtacks), a methodology that leverages the conceptual representations within CBMs to embed triggers during training, enabling controlled manipulation of model predictions at inference time.  An enhanced attack pattern, CAT+, incorporates a correlation function to systematically select the most effective and stealthy concept triggers, thereby optimizing the attack's impact.  Our comprehensive evaluation framework assesses both the attack success rate and stealthiness, demonstrating that CAT and CAT+ maintain high performance on clean data while achieving significant targeted effects on backdoored datasets. This work underscores the potential security risks associated with CBMs and provides a robust testing methodology for future security assessments."
    },
    {
        "title": "BirdSet: A Large-Scale Dataset for Audio Classification in Avian Bioacoustics",
        "link_suffix": "/forum?id=dRXxFEY8ZE",
        "link": "https://openreview.net/forum?id=dRXxFEY8ZE",
        "pdf_link": "https://openreview.net/pdf?id=dRXxFEY8ZE",
        "keywords": "audio classification, multi-label, dataset collection, bioacoustics",
        "abstract": "Deep learning (DL) has greatly advanced audio classification, yet the field is limited by the scarcity of large-scale benchmark datasets that have propelled progress in other domains. While AudioSet aims to bridge this gap as a universal-domain dataset, its restricted accessibility and lack of diverse real-world evaluation use cases challenge its role as the primary resource. Therefore, we introduce $\\texttt{BirdSet}$, a large-scale benchmark dataset for audio classification focusing on avian bioacoustics. $\\texttt{BirdSet}$ surpasses AudioSet with over 6,800 recording hours ($\\uparrow17%$) from nearly 10,000 classes ($\\uparrow18\\times$) for training and more than 400 hours ($\\uparrow7\\times$) across eight strongly labeled evaluation datasets. It serves as a versatile resource for use cases such as multi-label classification, covariate shift or self-supervised learning. We benchmark six well-known DL models in multi-label classification across three distinct training scenarios and outline further evaluation use cases in audio classification. We host our dataset on Hugging Face for easy accessibility and offer an extensive codebase to reproduce our results."
    }
]
[{"title": "Bandit Learning in Matching Markets with Indifference", "link_suffix": "/forum?id=7ENakslm9J", "link": "https://openreview.net/forum?id=7ENakslm9J", "pdf_link": "https://openreview.net/pdf?id=7ENakslm9J", "keywords": "Bandits, Matching markets, Indifference, Stable regret", "abstract": "A rich line of recent works studies how participants in matching markets learn their unknown preferences through iterative interactions with each other. Two sides of participants in the market can be respectively formulated as players and arms in the bandit problem. To ensure market stability, the objective is to minimize the stable regret of each player. Though existing works provide significant theoretical upper bounds for players' stable regret, the results heavily rely on the assumption that each participant has a strict preference ranking. However, in real applications, multiple candidates (e.g., workers in the labor market and students in school admission) usually demonstrate comparable performance levels, making it challenging for participants (e.g. employers and schools) to differentiate and rank their preferences. To deal with the potential indifferent preferences, we propose an adaptive exploration algorithm based on arm-guided Gale-Shapley (AE-AGS). We show that its stable regret is of order $O(NK \\log T / \\Delta^2)$, where $N$ is the number of players, $K$ the number of arms, $T$ the total time horizon, and $\\Delta$ the minimum non-zero preference gap. To the best of our knowledge, this is the first polynomial regret bound applicable to the more general indifference setting, and it is only $O(N)$ worse than the state-of-the-art result in the strict preference setting. Extensive experiments demonstrate the algorithm's effectiveness in handling such complex situations and its consistent superiority over baselines.", "title_embedding_index": 19600, "title_abs_embedding_index": 19625}, {"title": "Supervised Disentanglement Under Hidden Correlations", "link_suffix": "/forum?id=4HAXypZfsm", "link": "https://openreview.net/forum?id=4HAXypZfsm", "pdf_link": "https://openreview.net/pdf?id=4HAXypZfsm", "keywords": "Disentangled representation learning, Supervised representation learning, Mutual information, Causal graph analysis, Hidden Correlations", "abstract": "Disentangled representation learning (DRL) methods are often leveraged to improve the generalization of representations. Recent DRL methods have tried to handle attribute correlations by enforcing conditional independence based on attributes. However, the complex multi-modal data distributions and hidden correlations under attributes remain unexplored. Existing methods are theoretically shown to cause the loss of mode information under such hidden correlations. To solve this problem, we propose Supervised Disentanglement under Hidden Correlations (SD-HC), which discovers data modes under certain attributes and minimizes mode-based conditional mutual information to achieve disentanglement. Theoretically, we prove that SD-HC is sufficient for disentanglement under hidden correlations, preserving mode information and attribute information. Empirically, extensive experiments on one toy dataset and five real-world datasets demonstrate improved generalization against the state-of-the-art baselines. Codes are available at anonymous Githubhttps://anonymous.4open.science/r/SD-HC.", "title_embedding_index": 19601, "title_abs_embedding_index": 19626}, {"title": "Alignment Between the Decision-Making Logic of LLMs and Human Cognition: A Case Study on Legal LLMs", "link_suffix": "/forum?id=ZACnAv9ZTY", "link": "https://openreview.net/forum?id=ZACnAv9ZTY", "pdf_link": "https://openreview.net/pdf?id=ZACnAv9ZTY", "keywords": "Explainable AI, Large Language Model, Interactions", "abstract": "This paper presents a method to evaluate the alignment between the decision-making logic of Large Language Models (LLMs) and human cognition in a case study on legal LLMs. Unlike traditional evaluations on language generation results, we propose to evaluate the correctness of the  detailed decision-making logic of an LLM behind its seemingly correct outputs, which represents the core challenge for an LLM to earn human trust.  To this end, we quantify the interactions encoded by the LLM as primitive decision-making logic, because recent theoretical achievements (Li & Zhang, 2023; Ren et al., 2024) have proven several mathematical guarantees of the faithfulness of the interaction-based explanation.  We design a set of metrics to evaluate the detailed decision-making logic of LLMs. Experiments show that even when the language generation results appear correct, a significant portion of the internal inference logic contains notable issues.", "title_embedding_index": 19602, "title_abs_embedding_index": 19627}, {"title": "Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering", "link_suffix": "/forum?id=j6fsbpAllN", "link": "https://openreview.net/forum?id=j6fsbpAllN", "pdf_link": "https://openreview.net/pdf?id=j6fsbpAllN", "keywords": "Parameter Efficient Tuning, LoRA, Model Merging", "abstract": "Low-Rank Adaptation (LoRA) has emerged as a popular technique for fine-tuning large language models (LLMs) to various domains due to its modular design and widespread availability on platforms like Huggingface. This modularity has sparked interest in combining multiple LoRAs to significantly enhance LLM capabilities. However, existing methods for LoRA composition primarily focus on task-specific adaptations that require additional training, and current model merging techniques often fail to fully leverage LoRA's modular nature, leading to parameter interference and performance degradation.\nIn this paper, we explore the possibility of disassembling and reassembling multiple LoRAs at a finer granularity, much like assembling LEGO blocks. We introduce the concept of Minimal Semantic Units (MSUs), where the parameters corresponding to each rank in LoRA function as independent units. These MSUs exhibit properties such as permutation invariance and concatenation-summation equivalence, allowing for flexible combinations to form new LoRAs.\nBuilding on these insights, we propose the LoRA-LEGO framework. This framework conducts rank-wise parameter clustering by grouping MSUs from different LoRAs into $k$ clusters. The centroid of each cluster serves as a representative MSU, enabling the assembly of a merged LoRA with an adjusted rank of $k$. Additionally, we apply a dual reweighting strategy to optimize the scale of the merged LoRA. Experiments across various benchmarks demonstrate that our method outperforms existing approaches in LoRA merging.", "title_embedding_index": 19603, "title_abs_embedding_index": 19628}, {"title": "Revisiting Prompt-based Methods in Class Incremental Learning", "link_suffix": "/forum?id=QfGc9txfGO", "link": "https://openreview.net/forum?id=QfGc9txfGO", "pdf_link": "https://openreview.net/pdf?id=QfGc9txfGO", "keywords": "continual learning, pretrained-models, self-supervised learning", "abstract": "In recent years, prompt-based methods have emerged as a promising direction for continual learning, demonstrating impressive performance across various benchmarks. These methods create learnable prompts to infer task identity, then select and integrate specific prompts into the pretrained model to generate instructed features for prediction. In this paper, we first analyze the working patterns of such method across different distribution scenarios through extensive empirical analysis. Our analysis exposes the limitations of existing methods: first, two-stage inference can make mistakes even when the first stage has already provided reliable predictions; second, enforcing identical architectures for both stages hampers performance gains. To address these issues, we incorporated a self-supervised learning objective to learn discriminative features, thereby boosting the plasticity of the model. During inference, we implemented a simple yet effective threshold filtering strategy to selectively pass data to the second stage. This approach prevents errors in the second stage when the first stage has already made reliable predictions, while also conserving computational resources. Ultimately, we explore utilizing self-supervised pretrained models as a unified task identity provider.  Comparing to state-of-the-art methods, our method achieves comparable results under in-distribution scenarios and demonstrates substantial gains under out-of-distribution scenarios (e.g., up to 6.34% and 5.15% improvements on Split Aircrafts and Split Cars-196, respectively).", "title_embedding_index": 19604, "title_abs_embedding_index": 19629}, {"title": "Learning Loss Landscapes in Preference Optimization", "link_suffix": "/forum?id=TU5ApbbeDZ", "link": "https://openreview.net/forum?id=TU5ApbbeDZ", "pdf_link": "https://openreview.net/pdf?id=TU5ApbbeDZ", "keywords": "Preference optimization, mirror descent", "abstract": "We present an empirical study investigating how specific properties of preference datasets, such as mixed-quality or noisy data, affect the performance of Preference Optimization (PO) algorithms. Our experiments, conducted in MuJoCo environments, reveal several scenarios where state-of-the-art PO methods experience significant drops in performance. To address this issue, we introduce a novel PO framework based on mirror descent, which can recover existing methods like Direct Preference Optimization (DPO) and Odds-Ratio Preference Optimization (ORPO) for specific choices of the mirror map. Within this framework, we employ evolutionary strategies to discover new loss functions capable of handling the identified problematic scenarios. These new loss functions lead to significant performance improvements over DPO and ORPO across several tasks. Additionally, we demonstrate the generalization capability of our approach by applying the discovered loss functions to fine-tuning large language models using mixed-quality data, where they outperform ORPO.", "title_embedding_index": 19605, "title_abs_embedding_index": 19630}, {"title": "REEF: Representation Encoding Fingerprints for Large Language Models", "link_suffix": "/forum?id=SnDmPkOJ0T", "link": "https://openreview.net/forum?id=SnDmPkOJ0T", "pdf_link": "https://openreview.net/pdf?id=SnDmPkOJ0T", "keywords": "Large Language Model, Fingerprint, Representation, Intellectual Property", "abstract": "Protecting the intellectual property of open-source Large Language Models (LLMs) is very important, because training LLMs costs extensive computational resources and data. Therefore, model owners and third parties need to identify whether a suspect model is a subsequent development of the victim model. To this end, we propose a training-free REEF to identify the relationship between the suspect and victim models from the perspective of LLMs' feature representations. Specifically, REEF computes and compares the centered kernel alignment similarity between the representations of a suspect model and a victim model on the same samples. This training-free REEF does not impair the model's general capabilities and is robust to sequential fine-tuning, pruning, model merging, and permutations. In this way, REEF provides a simple and effective way for third parties and models' owners to protect LLMs' intellectual property together.", "title_embedding_index": 19606, "title_abs_embedding_index": 19631}, {"title": "DETER: Detecting Edited Regions for Deterring Generative Manipulations", "link_suffix": "/forum?id=oSEsSDFxyw", "link": "https://openreview.net/forum?id=oSEsSDFxyw", "pdf_link": "https://openreview.net/pdf?id=oSEsSDFxyw", "keywords": "Deepfake detection, regional manipulation, dataset and benchmark", "abstract": "Generative AI capabilities have grown substantially in recent years, raising renewed concerns about the potential malicious use of generated data, or \"deep fakes.\" Despite being a longstanding and important research topic, deep fake detection research on most existing datasets has not kept pace with generative AI advancements sufficiently to develop detection technology that can meaningfully alert human users in real-world settings. In this work, we introduce DETER, a large-scale dataset for DETEcting edited image Regions and deterring modern advanced generative manipulations. After a comprehensive study of prior literature, our proposed dataset makes contributions along three main axes: the upgrade on modern manipulations via the state-of-the-art generative models; the mitigation of biased spurious correlations in prior deep fake datasets; and a more unified formulation suitable for various detection models in different granularities. Equipped with DETER, we conduct extensive experiments and detailed analysis using our rich annotations and improved benchmark protocols, revealing future directions and the next set of challenges in developing reliable regional fake detection models.", "title_embedding_index": 19607, "title_abs_embedding_index": 19632}, {"title": "Discovery and Expansion of New Domains within Diffusion Models", "link_suffix": "/forum?id=KTrnOhAN4k", "link": "https://openreview.net/forum?id=KTrnOhAN4k", "pdf_link": "https://openreview.net/pdf?id=KTrnOhAN4k", "keywords": "domain generalization, diffusion models, few-shot, ML4Astrophysics", "abstract": "In this work, we study the generalization properties of diffusion models in a few-shot setup, introduce a novel tuning-free paradigm to synthesize the target out-of-domain (OOD) data, showcase multiple applications of those generalization properties, and demonstrate the advantages compared to existing tuning-based methods in data-sparse scientific scenarios with large domain gaps. Our work resides on the observation and premise that the theoretical formulation of denoising diffusion implicit models (DDIMs), a non-Markovian inference technique, exhibits latent Gaussian priors independent from the parameters of trained denoising diffusion probabilistic models (DDPMs). This brings two practical benefits: the latent Gaussian priors generalize to OOD data domains that have never been used in the training stage; existing DDIMs offer the flexibility to traverse the denoising chain bidirectionally for a pre-trained DDPM. We then demonstrate through theoretical and empirical studies that such established OOD Gaussian priors are practically separable from the originally trained ones after inversion. The above analytical findings allow us to introduce our novel tuning-free paradigm to synthesize new images of the target unseen domain by discovering qualified OOD latent encodings within the inverted noisy latent spaces, which is fundamentally different from most existing paradigms that seek to modify the denoising trajectory to achieve the same goal by tuning the model parameters. Extensive cross-model and domain experiments show that our proposed method can expand the latent space and synthesize images in new domains via frozen DDPMs without impairing the generation quality of their original domains.", "title_embedding_index": 19608, "title_abs_embedding_index": 19633}, {"title": "X-Gen: Ego-centric Video Prediction by Watching Exo-centric Videos", "link_suffix": "/forum?id=8J2DrrWDKE", "link": "https://openreview.net/forum?id=8J2DrrWDKE", "pdf_link": "https://openreview.net/pdf?id=8J2DrrWDKE", "keywords": "egocentric video, video prediction", "abstract": "Generating videos in the first-person perspective has broad application prospects in the field of augmented reality and embodied intelligence.\nIn this work, we explore the cross-view video prediction task, where given an exo-centric video, the first frame of the corresponding ego-centric video, and textual instructions, the goal is to generate future frames of the ego-centric video. \nInspired by the notion that hand-object interactions (HOI) in ego-centric videos represent the primary intentions and actions of the current actor, we present X-Gen that explicitly models the hand-object dynamics for cross-view video prediction. \nX-Gen consists of two stages. First, we design a cross-view HOI mask prediction model that anticipates the HOI masks in future ego-frames by modeling the spatio-temporal ego-exo correspondence. \nNext, we employ a video diffusion model to predict future ego-frames using the first ego-frame and textual instructions, while incorporating the HOI masks as structural guidance to enhance prediction quality.\nTo facilitate training, we develop a fully automated pipeline to generate pseudo HOI masks for both ego- and exo-videos by exploiting vision foundation models. \nExtensive experiments demonstrate that our proposed X-Gen achieves better prediction performance compared to previous video prediction models on the public Ego-Exo4D and H2O benchmark datasets, with the HOI masks significantly improving the generation of hands and interactive objects in the ego-centric videos.", "title_embedding_index": 19609, "title_abs_embedding_index": 19634}, {"title": "DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone", "link_suffix": "/forum?id=j1OucVFZMJ", "link": "https://openreview.net/forum?id=j1OucVFZMJ", "pdf_link": "https://openreview.net/pdf?id=j1OucVFZMJ", "keywords": "diffusion, time series impuation, state space model", "abstract": "Probabilistic time series imputation has been widely applied in real-world scenarios due to its ability to estimate uncertainty of imputation results. Meanwhile, denoising diffusion probabilistic models (DDPMs) have achieved great success in probabilistic time series imputation tasks with its power to model complex distributions. However, current DDPM-based probabilistic time series imputation methodologies are confronted with two types of challenges: 1) \\textit{ The backbone modules of the denoising parts are not capable of achieving sequence modeling with low time complexity.} 2) \\textit{ The architecture of denoising modules can not handle the inter-variable and bidirectional dependencies in the time series imputation problem effectively.} To address the first challenge, we integrate the computational efficient state space model, namely Mamba, as the backbone denosing module for DDPMs. To tackle the second challenge, we carefully devise several SSM-based blocks for bidirectional modeling and inter-variable relation understanding. Experimental results demonstrate that our approach can achieve state-of-the-art time series imputation results on multiple datasets, different missing scenarios and missing ratios.", "title_embedding_index": 19610, "title_abs_embedding_index": 19635}, {"title": "ImmersePro: End-to-End Stereo Video Synthesis Via Implicit Disparity Learning", "link_suffix": "/forum?id=GqhvJ1o8m5", "link": "https://openreview.net/forum?id=GqhvJ1o8m5", "pdf_link": "https://openreview.net/pdf?id=GqhvJ1o8m5", "keywords": "Video Stereo Conversion; Stereo Vision;", "abstract": "We introduce \\textit{ImmersePro}, an innovative framework specifically designed to transform single-view videos into stereo videos. This framework utilizes a novel dual-branch architecture comprising a disparity branch and a context branch on video data by leveraging spatial-temporal attention mechanisms. \\textit{ImmersePro} employs implicit disparity guidance, enabling the generation of stereo pairs from video sequences without the need for explicit disparity maps, thus reducing potential errors associated with disparity estimation models.\nIn addition to the technical advancements, we introduce the YouTube-SBS dataset, a comprehensive collection of 423 stereo videos sourced from YouTube. This dataset is unprecedented in its scale, featuring over 7 million stereo pairs, and is designed to facilitate training and benchmarking of stereo video generation models. Our experiments demonstrate the effectiveness of \\textit{ImmersePro} in producing high-quality stereo videos, offering significant improvements over existing methods.\nCompared to the best competitor stereo-from-mono we quantitatively improve the results by 11.76% (L1), 6.39% (SSIM), and 5.10% (PSNR).", "title_embedding_index": 19611, "title_abs_embedding_index": 19636}, {"title": "VoxelKP: A Voxel-based Network Architecture for Human Keypoint Estimation in LiDAR Data", "link_suffix": "/forum?id=aq7H2pWlEv", "link": "https://openreview.net/forum?id=aq7H2pWlEv", "pdf_link": "https://openreview.net/pdf?id=aq7H2pWlEv", "keywords": "Human Pose Estimation; Point Clouds; 3D Perception", "abstract": "We present \\textit{VoxelKP}, a novel fully sparse network architecture tailored for human keypoint estimation in LiDAR data.\nThe key challenge is that objects are distributed sparsely in 3D space, while human keypoint detection requires detailed local information wherever humans are present.\nFirst, we introduce a dual-branch \\textit{fully sparse spatial-context block} where the spatial branch focuses on learning the local spatial correlations between keypoints within each human instance, while the context branch aims to retain the global spatial information. Second, we use a \\textit{spatially aware multi-scale BEV fusion} technique to leverage absolute 3D coordinates when projecting 3D voxels to a 2D grid encoding a bird's eye view for better preservation of the global context of each human instance.\nWe evaluate our method on the Waymo dataset and achieve an improvement of $27%$ on the MPJPE metric compared to the state-of-the-art, \\textit{HUM3DIL}, trained on the same data, and $12%$ against the state-of-the-art, \\textit{GC-KPL}, pretrained on a $25\\times$ larger dataset.\nTo the best of our knowledge, \\textit{VoxelKP} is the first single-staged, fully sparse network that is specifically designed for addressing the challenging task of 3D keypoint estimation from LiDAR data, achieving state-of-the-art performances. Our code is available at\n\\url{https://}.", "title_embedding_index": 19612, "title_abs_embedding_index": 19637}, {"title": "UniGEM: A Unified Approach to Generation and Property Prediction for Molecules", "link_suffix": "/forum?id=Lb91pXwZMR", "link": "https://openreview.net/forum?id=Lb91pXwZMR", "pdf_link": "https://openreview.net/pdf?id=Lb91pXwZMR", "keywords": "Molecular generation, representation learning", "abstract": "Molecular generation and molecular property prediction are both crucial for drug discovery, but they are often developed independently. Inspired by recent studies, which demonstrate that diffusion model, a prominent generative approach, can learn meaningful data representations that enhance predictive tasks, we explore the potential for developing a unified generative model in the molecular domain that effectively addresses both molecular generation and property prediction tasks. However, the integration of these tasks is challenging due to inherent inconsistencies, making simple multi-task learning ineffective. To address this, we propose UniGEM, the first unified model to successfully integrate molecular generation and property prediction, delivering superior performance in both tasks. Our key innovation lies in a novel two-phase generative process, where predictive tasks are activated in the later stages, after the molecular scaffold is formed. We further enhance task balance through innovative training strategies. Rigorous theoretical analysis and comprehensive experiments demonstrate our significant improvements in both tasks. The principles behind UniGEM hold promise for broader applications, including natural language processing and computer vision.", "title_embedding_index": 19613, "title_abs_embedding_index": 19638}, {"title": "LoRA-Pro: Are Low-Rank Adapters Properly Optimized?", "link_suffix": "/forum?id=gTwRMU3lJ5", "link": "https://openreview.net/forum?id=gTwRMU3lJ5", "pdf_link": "https://openreview.net/pdf?id=gTwRMU3lJ5", "keywords": "Parameter Efficient Fine-Tuning, Large Language Models, Low-Rank Adaptation", "abstract": "Low-rank adaptation, also known as LoRA, has emerged as a prominent method for parameter-efficient fine-tuning of foundation models.\nDespite its computational efficiency, LoRA still yields inferior performance compared to full fine-tuning.\nIn this paper, we first uncover a fundamental connection between the optimization processes of LoRA and full fine-tuning: using LoRA for optimization is mathematically equivalent to full fine-tuning using a low-rank gradient for parameter updates.\nAnd this low-rank gradient can be expressed in terms of the gradients of the two low-rank matrices in LoRA.\nLeveraging this insight, we introduce LoRA-Pro, a method that enhances LoRA's performance by strategically adjusting the gradients of these low-rank matrices.\nThis adjustment allows the low-rank gradient to more accurately approximate the full fine-tuning gradient, thereby narrowing the performance gap between LoRA and full fine-tuning.\nFurthermore, we theoretically derive the optimal solutions for adjusting the gradients of the low-rank matrices, applying them during fine-tuning in LoRA-Pro.\nWe conduct extensive experiments across natural language understanding, dialogue generation, mathematical reasoning, code generation, and image classification tasks, demonstrating that LoRA-Pro substantially improves LoRA's performance, effectively narrowing the gap with full fine-tuning.\nCode is available in the supplementary.", "title_embedding_index": 19614, "title_abs_embedding_index": 19639}, {"title": "SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback", "link_suffix": "/forum?id=OCd3cffulp", "link": "https://openreview.net/forum?id=OCd3cffulp", "pdf_link": "https://openreview.net/pdf?id=OCd3cffulp", "keywords": "Retrieval-augmented Generation, Language Models, Reinforcement Learning", "abstract": "RAG systems consist of multiple modules to work together. However, these modules are usually separately trained. We argue that a system like RAG that incorporates multiple modules should be jointly optimized to achieve optimal performance. To demonstrate this, we design a specific pipeline called SmartRAG that includes a policy network and a retriever. The policy network can serve as 1) a decision maker that decides when to retrieve, 2) a query rewriter to generate a query most suited to the retriever and 3) an answer generator that produces the final response with/without the observations. We then propose to jointly optimize the whole system using a reinforcement learning algorithm, with the reward designed to encourage the system to achieve the highest performance with minimal retrieval cost. When jointly optimized, each module can be aware of how other modules are working and thus find the best way to work together as a complete system. Empirical results demonstrate that the jointly optimized system can achieve better performance than separately optimized counterparts.", "title_embedding_index": 19615, "title_abs_embedding_index": 19640}, {"title": "Self-Supervised Diffusion Processes for Electron-Aware Molecular Representation Learning", "link_suffix": "/forum?id=UQ0RqfhgCk", "link": "https://openreview.net/forum?id=UQ0RqfhgCk", "pdf_link": "https://openreview.net/pdf?id=UQ0RqfhgCk", "keywords": "Representation learning;Generative models;Molecular science;Scientific applications", "abstract": "Physical properties derived from electronic distributions are essential information determining molecular properties. However, the electron-level information is not accessible in most real-world complex molecules due to extensive computational costs of determining uncertain electronic distributions. For this reason, existing machine learning methods for molecular property prediction have remained in regression models on simplified atom-level molecular descriptors, such as atomic structures. This paper proposes an efficient knowledge transfer method for electron-aware molecular representation learning. To this end, we devised a self-supervised diffusion method that estimates the electron-level information of real-world complex molecules from readily accessible incomplete information in public chemical databases. The proposed method achieved state-of-the-art prediction accuracy on extensive real-world molecular datasets.", "title_embedding_index": 19616, "title_abs_embedding_index": 19641}, {"title": "FBSVP: Video Prediction Based on Foreground-Background Separation", "link_suffix": "/forum?id=UAiuV8Plei", "link": "https://openreview.net/forum?id=UAiuV8Plei", "pdf_link": "https://openreview.net/pdf?id=UAiuV8Plei", "keywords": "Video Prediction, Foreground-Background Separation", "abstract": "Video prediction is the process of learning necessary information from historical frames to predict future video frames. \nHow to focus and efficiently learn features from historical frames is a critical step in this process. For any sequence of video frames, \nthe background changes little or remains almost constant, while the foreground changes significantly and is the main focus of our video prediction learning. \nHowever, current known video prediction learning methods do not consider how to utilize the different characteristics of the foreground and background to further improve prediction accuracy. \nTo fully leverage the different characteristics of the foreground and background and enhance prediction accuracy, \nwe propose a Foreground-Background Separation Video Prediction (FBSVP) model in this paper. \nThrough the foreground and background separation module, historical video frames are separated into foreground and background frames. \nIn the video prediction module, the foreground and background frames are predicted and learned separately. \nFirst, the features of historical frames are fused into the current frame through a historical attention fusion module using an attention mechanism. \nThen, the complementary temporal and spatial features are fused through a spatio-temporal fusion module. \nFinally, the learned foreground and background features are fused in the foreground and background fusion module to predict the final video frame. \nExperimental results show that our proposed FBSVP model achieves the best performance on popular video prediction datasets, demonstrating its significant competitiveness in this field.", "title_embedding_index": 19617, "title_abs_embedding_index": 19642}, {"title": "Recurrent Context Compression: Efficiently Expanding the Context Window of LLM", "link_suffix": "/forum?id=GYk0thSY1M", "link": "https://openreview.net/forum?id=GYk0thSY1M", "pdf_link": "https://openreview.net/pdf?id=GYk0thSY1M", "keywords": "language model, Context compression", "abstract": "To extend the context length of Transformer-based large language models (LLMs) and improve comprehension capabilities, researchers often encounter constraints stemming from finite computational resources and bounded memory capacities. This work proposes a novel approach, termed Recurrent Context Compression (RCC), designed to efficiently expand the context window length of LLMs. Furthermore, we delve into the prevalent issue of degraded model performance when both instructional prompts and contextual information undergo compression for downstream tasks. To address this challenge, we propose a novel instruction reconstruction methodology aimed at mitigating the detrimental effects of this compression process. The effectiveness of our proposed approach was validated across multiple tasks while achieving an impressive context compression rate of at least 32x. On text reconstruction task, we maintain a BLEU-4 score close to 0.95. On passkey retrieval task, we achieve nearly 100% accuracy involving an extensive sequence length of 1 million tokens. On long-text question-answering task, we obtain comparable performance with the non-compressed LLM in F1 and Rouge scores. Our method also demonstrated competitive performance in long-text question-answering tasks compared to non-compressed methods, while significantly saving storage resources.", "title_embedding_index": 19618, "title_abs_embedding_index": 19643}, {"title": "CopyLens: Dynamically Flagging Copyrighted Sub-Dataset Contributions to LLM Outputs", "link_suffix": "/forum?id=Mez2No9lHj", "link": "https://openreview.net/forum?id=Mez2No9lHj", "pdf_link": "https://openreview.net/pdf?id=Mez2No9lHj", "keywords": "Copyright, Large Language Model", "abstract": "Large Language Models (LLMs) have become pervasive due to their knowledge absorption and text-generation capabilities. Concurrently, the copyright issue for pretraining datasets has been a pressing concern, particularly when generation includes specific styles. Previous methods either focus on the defense of identical copyrighted outputs or find interpretability by individual tokens with computational burdens. However, the gap between them exists, where direct assessments of how dataset contributions impact LLM outputs are missing. Once the model providers ensure copyright protection for data holders, a more mature LLM community can be established. To address these limitations, we introduce CopyLens, a new framework to analyze how copyrighted datasets may influence LLM responses. Specifically, a two-stage approach is employed: First, based on the uniqueness of pretraining data in the embedding space,  token representations are initially fused for potential copyrighted texts, followed by a lightweight LSTM-based network to analyze dataset contributions. With such a prior, a contrastive-learning-based non-copyright OOD detector is designed. Our framework can dynamically face different situations and bridge the gap between current copyright detection methods. Experiments show that CopyLens improves efficiency and accuracy by 15.2% over our proposed baseline, 58.7% over prompt engineering methods, and 0.21 AUC over OOD detection baselines.", "title_embedding_index": 19619, "title_abs_embedding_index": 19644}, {"title": "Pg-GAT: A Complete Graph Model for Cancer Detection and Subtyping in Whole Slide Images Analysis", "link_suffix": "/forum?id=MOCEoNsjEx", "link": "https://openreview.net/forum?id=MOCEoNsjEx", "pdf_link": "https://openreview.net/pdf?id=MOCEoNsjEx", "keywords": "graph neural network, whole slide images, cancer research", "abstract": "Whole-Slide-Images (WSIs) have generated significant interests in cancer research community, owing to their availability and the rich information that they provide. Previous Multiple Instance Learning (MIL) methods often \nneglect the topological structure of tissues which is closely related to tumor evolution. Some attempts with transformer-based MIL methods take spatial relation into account with a trade-off of computational complexity. We propose Projection-gated Graph Attention Network (Pg-GAT), a lightweight model that effectively leverages graph neural network to provide structural prior, learns spatial and contextual relations through graph attention, and mitigates tissue morphology redundancy with differentiable projection-gated pooling, maintaining a data-adaptive decision boundary. In addition, Pg-GAT outputs region-of-interest (ROI) with respect to the graph-level prediction with post-hoc graph explainer, offering tumor localization and model interpretability. We evaluate our method on lymph node metastasis datasets (CAMELYON16 and CAMELYON17) and non-small cell lung cancer (TCGA-NSCLC), achieving AUCs of 97.6% and 95.6% and 99.6% respectively, outperforming state-of-the-art methods.", "title_embedding_index": 19620, "title_abs_embedding_index": 19645}, {"title": "HShare: Fast LLM Decoding by Hierarchical Key-Value Sharing", "link_suffix": "/forum?id=Tb5PY5vwp6", "link": "https://openreview.net/forum?id=Tb5PY5vwp6", "pdf_link": "https://openreview.net/pdf?id=Tb5PY5vwp6", "keywords": "Large Language Model, Decode, Key-Value Sharing, Critical Token, Hierarchical", "abstract": "The frequent retrieval of Key-Value (KV) cache data has emerged as a significant factor contributing to the inefficiency of the inference process in large language models. Previous research has demonstrated that a small subset of critical KV cache tokens largely influences attention outcomes, leading to methods that either employ fixed sparsity patterns or dynamically select critical tokens based on the query. While dynamic sparse patterns have proven to be more effective, they introduce significant computational overhead, as critical tokens must be reselected for each self-attention computation. In this paper, we reveal substantial similarities in KV cache token criticality across neighboring queries, layers, and heads. Motivated by this insight, we propose HShare, a hierarchical KV sharing framework. HShare facilitates the sharing of critical KV cache token indices across layers, heads, and queries, which significantly reduces the computational overhead associated with query-aware dynamic token sparsity. In addition, we introduce a greedy algorithm that dynamically determines the optimal layer-level and head-level sharing configuration for the decoding phase. We evaluate the effectiveness and efficiency of HShare across various tasks using three models: LLaMA2-7b, LLaMA3-70b, and Mistral-7b. Experimental results demonstrate that HShare maintains accuracy with an additional sharing ratio of $1/8$, while delivering up to an $8.6\\times$ speedup in self-attention operations and a $2.7\\times$ improvement in end-to-end throughput. The source code will be made publicly available upon publication.", "title_embedding_index": 19621, "title_abs_embedding_index": 19646}, {"title": "Do Vision & Language Decoders use Images and Text equally? How Self-consistent are their Explanations?", "link_suffix": "/forum?id=lCasyP21Bf", "link": "https://openreview.net/forum?id=lCasyP21Bf", "pdf_link": "https://openreview.net/pdf?id=lCasyP21Bf", "keywords": "interpretability, multimodality, natural language explanations, vision and language, benchmarking", "abstract": "Vision and language model (VLM) decoders are currently the best-performing architectures on multimodal tasks. Next to predictions, they are able to produce natural language explanations, either in post-hoc or CoT settings. However, it is not clear to what extent they are using the input vision and text modalities when generating answers or explanations.\nIn this work, we investigate if VLMs rely on their input modalities differently when they produce explanations as opposed to answers.\nWe also evaluate the self-consistency of VLM decoders in both post-hoc and CoT explanation settings, by extending existing unimodal tests and measures to VLM decoders. We find that VLMs are less self-consistent than LLMs. Text contributions in VL decoders are more important than image contributions in all examined tasks. However, when comparing explanation generation to answer generation, the contributions of images are significantly stronger for generating explanations compared to answers. This difference is even larger in CoT compared to post-hoc explanations.\nLastly, we provide an up-to-date benchmarking of state-of-the-art VL decoders on the VALSE benchmark, which before was restricted to\nVL encoders. We find that VL decoders still struggle with most phenomena tested by VALSE.", "title_embedding_index": 19622, "title_abs_embedding_index": 19647}, {"title": "Generalizability of Neural Networks Minimizing Empirical Risk Based on Expressive Power", "link_suffix": "/forum?id=8wAL9ywQNB", "link": "https://openreview.net/forum?id=8wAL9ywQNB", "pdf_link": "https://openreview.net/pdf?id=8wAL9ywQNB", "keywords": "generalization bound, expressive power", "abstract": "The primary objective of learning methods is generalization. Classic generalization bounds, based on VC-dimension or Rademacher complexity, are uniformly applicable to all networks in the hypothesis space. On the other hand, algorithm-dependent generalization bounds, like stability bounds, address more practical scenarios and provide generalization conditions for neural networks trained using SGD. However, these bounds often rely on strict assumptions, such as the NTK hypothesis or convexity of the empirical loss, which are typically not met by neural networks. In order to establish generalizability under less stringent assumptions, this paper investigates generalizability of neural networks that minimize the empirical risk. A lower bound for population accuracy is established based on the expressiveness of these networks, which indicates that with adequately large training sample and network sizes, these networks can generalize effectively. Additionally, we provide a lower bound necessary for generalization, demonstrating that, for certain data distributions, the quantity of data required to ensure generalization exceeds the network size needed to represent that distribution. Finally, we provide theoretical insights into several phenomena in deep learning, including robust overfitting, importance of over-parameterization networks, and effects of loss functions.", "title_embedding_index": 19623, "title_abs_embedding_index": 19648}, {"title": "Information-theoretically Safe Bias Classifier Against Adversarial Attacks", "link_suffix": "/forum?id=lEsNGN1SjG", "link": "https://openreview.net/forum?id=lEsNGN1SjG", "pdf_link": "https://openreview.net/pdf?id=lEsNGN1SjG", "keywords": "Information-theoretically, theory, adversarial", "abstract": "Deep learning has become the cornerstone of recent advances in artificial intelligence. However, the presence of adversarial samples makes deep learning susceptible in applications where safety is critical. Moreover, adversarial examples have been shown, to some degree, to be unavoidable. To address this issue, we propose the bias classifier. This approach employs the bias component of a neural network, using ReLU as its activation function, as a classifier. The bias classifier has been shown to universally approximate any classification problem with a high degree of probability. Moreover, it can be made information-theoretically safe against the original model gradient-based attack in the sense that any such attack produces a completely random attacking direction for any given input. Thus, the bias classifier provably achieves the maximum possible robust accuracy under specified attacks. Experiments are used to validate our theoretical results and to show that the bias classifier is accurate and robust for simple models.", "title_embedding_index": 19624, "title_abs_embedding_index": 19649}]
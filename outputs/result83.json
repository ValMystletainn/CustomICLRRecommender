[{"title": "How Do Large Language Models Understand Graph Patterns? A Benchmark for Graph Pattern Comprehension", "link_suffix": "/forum?id=CkKEuLmRnr", "link": "https://openreview.net/forum?id=CkKEuLmRnr", "pdf_link": "https://openreview.net/pdf?id=CkKEuLmRnr", "keywords": "Large language models, graph pattern, graph mining", "abstract": "Benchmarking the capabilities and limitations of large language models (LLMs) in graph-related tasks is becoming an increasingly popular and crucial area of research. Recent studies have shown that LLMs exhibit a preliminary ability to understand graph structures and node features. However, the potential of LLMs in graph pattern mining remains largely unexplored. This is a key component in fields such as computational chemistry, biology, and social network analysis. To bridge this gap, this work introduces a comprehensive benchmark to assess LLMs' capabilities in graph pattern tasks. We have developed a benchmark that evaluates whether LLMs can understand graph patterns based on either terminological or topological descriptions. Additionally, our benchmark tests the LLMs' capacity to autonomously discover graph patterns from data. The benchmark encompasses both synthetic and real datasets, and a variety of models, with a total of 11 tasks and 7 models. Our experimental framework is designed for easy expansion to accommodate new models and datasets. Our findings reveal that: (1) LLMs have preliminary abilities to understand graph patterns, with O1-mini outperforming in the majority of tasks; (2) Formatting input data to align with the knowledge acquired during pretraining can enhance performance; (3) The strategies employed by LLMs may differ from those used in conventional algorithms.", "title_embedding_index": 4100, "title_abs_embedding_index": 4125}, {"title": "ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design", "link_suffix": "/forum?id=KSLkFYHlYg", "link": "https://openreview.net/forum?id=KSLkFYHlYg", "pdf_link": "https://openreview.net/pdf?id=KSLkFYHlYg", "keywords": "3D molecular generation, drug design, molecules", "abstract": "Engineering molecules to exhibit precise 3D intermolecular interactions with their environment forms the basis of chemical design. In ligand-based drug design, bioisosteric analogues of known bioactive hits are often identified by virtually screening chemical libraries with shape, electrostatic, and pharmacophore similarity scoring functions. We instead hypothesize that a generative model which learns the joint distribution over 3D molecular structures and their interaction profiles may facilitate 3D interaction-aware chemical design. We specifically design ShEPhERD, an SE(3)-equivariant diffusion model which jointly diffuses/denoises 3D molecular graphs and representations of their shapes, electrostatic potential surfaces, and (directional) pharmacophores to/from Gaussian noise. Inspired by traditional ligand discovery, we compose 3D similarity scoring functions to assess ShEPhERD\u2019s ability to conditionally generate novel molecules with desired interaction profiles. We demonstrate ShEPhERD\u2019s potential for impact via exemplary drug design tasks including natural product ligand hopping, protein-blind bioactive hit diversification, and bioisosteric fragment merging.", "title_embedding_index": 4101, "title_abs_embedding_index": 4126}, {"title": "ShareLoRA: Less Tuning, More Performance for LoRA Fine-tuning of LLMs", "link_suffix": "/forum?id=O6QZ4W6GXt", "link": "https://openreview.net/forum?id=O6QZ4W6GXt", "pdf_link": "https://openreview.net/pdf?id=O6QZ4W6GXt", "keywords": "generative models, parameter-efficient-training, fine-tuning", "abstract": "Fine-tuning large language models (LLMs) is prohibitively expensive, prompting the development of various parameter-efficient fine-tuning (PEFT) methods. These methods primarily focus on fine-tuning small, additional modules known as adapters, which account for only a small fraction of the total LLM parameters. \nOne such method, low-rank adaptation (LoRA), has shown notable parameter efficiency while maintaining performance comparable to full fine-tuning. However, classical LoRA may still involve tuning more parameters than necessary given the intrinsic rank of pre-trained weights, as highlighted by prior work. \nIn this work, we introduce ShareLoRA, a novel approach that further enhances parameter efficiency during LLM fine-tuning by leveraging redundancies in pre-trained model weights to share LoRA modules, thereby significantly reducing the number of trainable parameters. Specifically, ShareLoRA automatically identifies redundancies in the pre-trained weights and determines which LoRA adapters can share parameters. This is achieved by measuring the similarity between representations to assess information redundancy and using a greedy algorithm to maximize parameter sharing. We conducted extensive evaluations on the LLMs of the LLaMA family across benchmark tasks. Notably, ShareLoRA achieves better parameter efficiency, with up to a 23% reduction in the number of fine-tuned parameters while delivering performance comparable to or better than existing PEFT methods.", "title_embedding_index": 4102, "title_abs_embedding_index": 4127}, {"title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models", "link_suffix": "/forum?id=IUmj2dw5se", "link": "https://openreview.net/forum?id=IUmj2dw5se", "pdf_link": "https://openreview.net/pdf?id=IUmj2dw5se", "keywords": "Fairness, Bias, Benchmark, Large Language Models", "abstract": "As Large Language Models (LLMs) are increasingly deployed to handle various natural language processing (NLP) tasks, concerns regarding the potential negative societal impacts of LLM-generated content have also arisen. To evaluate the biases exhibited by LLMs, researchers have recently proposed a variety of datasets. However, existing bias evaluation efforts often focus on only a particular type of bias and employ inconsistent evaluation metrics, leading to difficulties in comparison across different datasets and LLMs. To address these limitations, we collect a variety of datasets designed for the bias evaluation of LLMs, and further propose CEB, a Compositional Evaluation Bechmark that covers different types of bias across different social groups and tasks. The curation of CEB is based on our newly proposed compositional taxonomy, which characterizes each dataset from three dimensions: bias types, social groups, and tasks. By combining the three dimensions, we develop a comprehensive evaluation strategy for the bias in LLMs. Our experiments demonstrate that the levels of bias vary across these dimensions, thereby providing guidance for the development of specific bias mitigation methods.", "title_embedding_index": 4103, "title_abs_embedding_index": 4128}, {"title": "Geometric Algebra Planes: Convex Implicit Neural Volumes", "link_suffix": "/forum?id=mVOz28mPHr", "link": "https://openreview.net/forum?id=mVOz28mPHr", "pdf_link": "https://openreview.net/pdf?id=mVOz28mPHr", "keywords": "implicit neural representation, convex optimization, volume, nerf, segmentation", "abstract": "Volume parameterizations abound in recent literature, from the classic voxel grid to the implicit neural representation and everything in between. While implicit representations have shown impressive capacity and better memory efficiency compared to voxel grids, to date they require training via nonconvex optimization. This nonconvex training process can be slow to converge and sensitive to initialization and hyperparameter choices that affect the final converged result. We introduce a family of models, GA-Planes, that is the first class of implicit neural volume representations that can be trained by convex optimization. GA-Planes models include any combination of features stored in tensor basis elements, followed by a neural feature decoder. They generalize many existing representations and can be adapted for convex, semiconvex, or nonconvex training as needed for different inverse problems. In the 2D setting with a linear feature decoder, we prove that GA-Planes is equivalent to a low-rank plus low-resolution matrix factorization; we show that this approximation outperforms the classic low-rank plus sparse decomposition for fitting a natural image. In 3D, we demonstrate GA-Planes' competitive performance in terms of expressiveness, model size, and optimizability across three volume fitting tasks: radiance field reconstruction, 3D segmentation, and video segmentation.", "title_embedding_index": 4104, "title_abs_embedding_index": 4129}, {"title": "Scalable Exploration via Ensemble++", "link_suffix": "/forum?id=ygtmPu0xZy", "link": "https://openreview.net/forum?id=ygtmPu0xZy", "pdf_link": "https://openreview.net/pdf?id=ygtmPu0xZy", "keywords": "Bandit, Scalable Exploration, Function Approximation", "abstract": "Scalable exploration is a persistent challenge in sequential decision-making, especially in high-dimensional environments with neural networks. Ensemble sampling, a computationally efficient approximation of Thompson sampling, is widely used but suffers from performance degradation in shared-layer ensemble networks due to ensemble coupling. To overcome this limitation, we propose the Ensemble++ architecture, which introduces decoupled optimization and lifted index sampling for efficient exploration and uncertainty estimation. \nEmpirical results show that Ensemble++ outperforms existing methods in regret minimization while maintaining bounded per-step computation costs across a variety of tasks, including nonlinear bandits and language-based contextual bandits using a GPT backbone. Theoretically, we prove that Ensemble++ achieves the same regret bounds as exact Thompson sampling in linear contextual bandits, with $\\tilde{O}(\\log T)$ per-step computation complexity. This provides the first rigorous analysis demonstrating ensemble sampling as a scalable and effective approximation to Thompson sampling, closing a key theoretical gap in exploration efficiency.", "title_embedding_index": 4105, "title_abs_embedding_index": 4130}, {"title": "TabWak: A Watermark for Tabular Diffusion Models", "link_suffix": "/forum?id=71pur4y8gs", "link": "https://openreview.net/forum?id=71pur4y8gs", "pdf_link": "https://openreview.net/pdf?id=71pur4y8gs", "keywords": "Watermarking, Tabular data, Generative models, Tabular diffusion models", "abstract": "Synthetic data offers alternatives for data augmentation and sharing. Till date, it remains unknown how to use watermarking techniques to trace and audit synthetic tables generated by tabular diffusion models to mitigate potential misuses. In this paper, we design TabWak, the first watermarking method to embed invisible signatures that control the sampling of Gaussian latent codes used to synthesize table rows via the diffusion backbone. TabWak has two key features. Different from existing image watermarking techniques, TabWak uses self-cloning and shuffling to embed the secret key in positional information of random seeds that control the Gaussian latents, allowing to use different seeds at each row for high inter-row diversity and enabling row-wise detectability. To further boost the robustness of watermark detection against post-editing attacks, TabWak uses a valid-bit mechanism that focuses on the tail of the latent code distribution for superior noise resilience. We provide theoretical guarantees on the row diversity and effectiveness of detectability. We evaluate TabWak on five datasets against baselines to show that the quality of watermarked tables remains nearly indistinguishable from non-watermarked tables while achieving high detectability in the presence of strong post-editing attacks, with a 100% true positive rate at a 0.1% false positive rate on synthetic tables with fewer than 300 rows. Our code is available at the following anonymized repositoryhttps://anonymous.4open.science/r/TabWak-4E65/.", "title_embedding_index": 4106, "title_abs_embedding_index": 4131}, {"title": "PoseCheck: Generative Models for 3D Structure-based Drug Design Produce Unrealistic Poses", "link_suffix": "/forum?id=xoUUCS9IGl", "link": "https://openreview.net/forum?id=xoUUCS9IGl", "pdf_link": "https://openreview.net/pdf?id=xoUUCS9IGl", "keywords": "generative models, drug design, benchmarks", "abstract": "Deep generative models for structure-based drug design (SBDD), where molecule generation is conditioned on a 3D protein pocket, have received considerable interest in recent years. These methods offer the promise of higher-quality molecule generation by explicitly modelling the 3D interaction between a potential drug and a protein receptor. However, previous work has primarily focused on the quality of the generated molecules themselves, with limited evaluation of the 3D poses that these methods produce, with most work simply discarding the generated pose and only reporting a \u201ccorrected\u201d pose after redocking with traditional methods. Little is known about whether generated molecules satisfy known physical constraints for binding and the extent to which redocking alters the generated interactions. We introduce POSECHECK, an extensive benchmarking suite for state-of-the-art SBDD methods and find that generated molecules have significantly more physical violations and fewer key interactions compared to baselines, calling into question the implicit assumption that providing rich 3D structure information improves molecule complementarity. We make recommendations for future research tackling identified failure modes and hope our benchmark will serve as a springboard for future SBDD generative modelling work to have a real-world impact.", "title_embedding_index": 4107, "title_abs_embedding_index": 4132}, {"title": "Reducing the Scope of Language Models with Circuit Breakers", "link_suffix": "/forum?id=abRWxnjMIz", "link": "https://openreview.net/forum?id=abRWxnjMIz", "pdf_link": "https://openreview.net/pdf?id=abRWxnjMIz", "keywords": "large language models, alignment, refusal", "abstract": "Language models are now deployed in a wide variety of user-facing applications, often for specific purposes like answering questions about documentation or acting as coding assistants. As these models are intended for particular purposes, they should not be able to answer irrelevant queries like requests for poetry or questions about physics, or even worse, queries that can only be answered by humans like sensitive company policies. Instead we would like them to only answer queries corresponding to desired behavior and refuse all other requests, which we refer to as scoping. We find that, despite the use of system prompts, two representative language models can be poorly scoped and respond to queries they should not be addressing. We then conduct a comprehensive empirical evaluation of methods which could be used for scoping the behavior of language models. Among many other results, we show that a recently-proposed method for general alignment, Circuit Breakers (CB), can be adapted to scope language models to very specific tasks like sentiment analysis or summarization or even tasks with finer-grained scoping (e.g. summarizing only news articles). When compared to standard methods like fine-tuning or preference learning, CB is more robust both for out of distribution tasks, and to adversarial prompting techniques. We also show that layering SFT and CB together often results in the best of both worlds: improved performance only on relevant queries, while rejecting irrelevant ones.", "title_embedding_index": 4108, "title_abs_embedding_index": 4133}, {"title": "Efficient Active Imitation Learning with Random Network Distillation", "link_suffix": "/forum?id=GFgn2LprFR", "link": "https://openreview.net/forum?id=GFgn2LprFR", "pdf_link": "https://openreview.net/pdf?id=GFgn2LprFR", "keywords": "Active Imitation Learning, Imitation Learning, Interactive Learning, Navigation", "abstract": "Developing agents for complex and underspecified tasks, where no clear objective exists, remains challenging but offers many opportunities. This is especially true in video games, where simulated players (bots) need to play realistically, and there is no clear reward to evaluate them. While imitation learning has shown promise in such domains, these methods often fail when agents encounter out-of-distribution scenarios during deployment. Expanding the training dataset is a common solution, but it becomes impractical or costly when relying on human demonstrations. This article addresses active imitation learning, aiming to trigger expert intervention only when necessary, reducing the need for constant expert input along training. We introduce Random Network Distillation DAgger (RND-DAgger), a new active imitation learning method that limits expert querying by using a learned state-based out-of-distribution measure to trigger interventions. This approach avoids frequent expert-agent action comparisons, thus making the expert intervene only when it is useful. We evaluate RND-DAgger against traditional imitation learning and other active approaches in 3D video games (racing and third-person navigation) and in a robotic locomotion task and show that RND-DAgger surpasses previous methods by reducing expert queries.", "title_embedding_index": 4109, "title_abs_embedding_index": 4134}, {"title": "iAgent: LLM Agent as a Shield between User and Recommender Systems", "link_suffix": "/forum?id=swdMzQUhBx", "link": "https://openreview.net/forum?id=swdMzQUhBx", "pdf_link": "https://openreview.net/pdf?id=swdMzQUhBx", "keywords": "Large Language Model; LLM-based Agents; Memory Mechanism", "abstract": "Traditional recommender systems usually take the user-platform paradigm, where users are directly exposed under the control of the platform\u2019s recommendation algorithms. However, the defect of recommendation algorithms may put users in very vulnerable positions under this paradigm. First, many sophisticated models are often designed with commercial objectives in mind, focusing on the platform\u2019s\nbenefits, which may hinder their ability to protect and capture users\u2019 true interests. Second, these models are typically optimized using data from all users, which may overlook individual user\u2019s preferences. Due to these shortcomings, users may experience several disadvantages under the traditional user-platform direct exposure paradigm, such as lack of control over the recommender system, potential manipulation by the platform, echo chamber effects, or lack of personalization for less active users due to the dominance of active users during collaborative learning. Therefore, there is an urgent need to develop a new paradigm to protect user interests and alleviate these issues. Recently, some researchers have introduced LLM agents to simulate user behaviors, these approaches primarily aim to optimize platform-side performance, leaving core issues in recommender systems unresolved. To address these limitations, we propose a new user-agent-platform paradigm, where agent serves as the protective shield between user and recommender system\nthat enables indirect exposure. To this end, we first construct four recommendation datasets, denoted as InstructRec, along with user instructions for each record. To understand user\u2019s intention, we design an Instruction-aware Agent (iAgent) capable of using tools to acquire knowledge from external environments. Moreover, we introduce an Individual Instruction-aware Agent ( i$^2$Agent), which incorporates a dynamic memory mechanism to optimize from individual feedback. Results on four InstructRec datasets demonstrate that i2Agent consistently achieves an average improvement of 16.6% over SOTA baselines across ranking metrics. Moreover, i$^2$Agent mitigates echo chamber effects and effectively alleviates the model bias in disadvantaged users (less-active), serving as a shield between user and recommender systems.", "title_embedding_index": 4110, "title_abs_embedding_index": 4135}, {"title": "Is multitask learning all you need in continual learning?", "link_suffix": "/forum?id=Pin2kdWloe", "link": "https://openreview.net/forum?id=Pin2kdWloe", "pdf_link": "https://openreview.net/pdf?id=Pin2kdWloe", "keywords": "lifelong learning, multitask learning, continual learning", "abstract": "Continual Learning solutions often treat multitask learning as an upper-bound of what the learning process can achieve.This is a natural assumption, given that this objective directly addresses the catastrophic forgetting problem, which has been a central focus in early works. However, depending on the nature of the distributional shift in the data, the multi-task solution is not always optimal for the broader continual learning problem. In this work, we draw on principles from online learning to formalize the limitations of multitask objectives, especially when viewed through the lens of cumulative loss, which also serves as an indicator of forward transfer.\nWe provide empirical evidence on when multi-task solutions are suboptimal, and argue that continual learning solutions should not and do not have to adhere to this assumption. Moreover, we argue for the utility of  estimating the distributional drift as the data is being received and show preliminary results of how this could be exploited by a simple replay based method to move beyond the multitask solution.", "title_embedding_index": 4111, "title_abs_embedding_index": 4136}, {"title": "Explore To Mimic: A Reinforcement Learning Based Agent To Generate Online Signatures", "link_suffix": "/forum?id=GIFn3ibnKa", "link": "https://openreview.net/forum?id=GIFn3ibnKa", "pdf_link": "https://openreview.net/pdf?id=GIFn3ibnKa", "keywords": "Reinforcement Learning, Online Signature, Biometric, Generative Model, On-Policy", "abstract": "Recent advancements in utilising decision making capability of Reinforcement Learning (RL) have paved the way for innovative approaches in data generation. This research explores the application of model free on-policy RL algorithms for generating online signatures and its controlled variations. Online signatures are captured via e-pads as sequential structural coordinates. In this study, we have introduced a robust on-policy RL agent named as SIGN-Agent, capable of  generating online signatures accurately. Unlike other RL algorithms, on-policy RL directly learns from the agent's current policy, offering significant advantages in stability and faster convergence for sequential decision-making. The proposed SIGN-Agent operates in a random continuous action space with controlled exploration limits, allowing it to capture complex signature patterns while minimizing errors over time. The downstream applications of this system can be extended in diverse fields such as enhancing the robustness of signature authentication systems, supporting robotics, and even diagnosing neurological disorders. By generating reliable, human-like online signatures, our approach strengthens signature authentication systems by reducing susceptibility towards system-generated forgeries, if trained against them. Additionally, the proposed work is optimized for low-footprint edge devices, enabling it to function efficiently in the area of robotics for online signature generation tasks. Experimental results, tested on large, publicly available datasets, demonstrate the effectiveness of model free on-policy RL algorithms in generating online signature trajectories, that closely resemble user's reference signatures. Our approach highlights the potential of model free on-policy RL as an advancement in the field of data generation targeting the domain of online signatures in this research.", "title_embedding_index": 4112, "title_abs_embedding_index": 4137}, {"title": "Memory-augmented Transformers can implement Linear First-Order Optimization Methods", "link_suffix": "/forum?id=D0Cdljktp2", "link": "https://openreview.net/forum?id=D0Cdljktp2", "pdf_link": "https://openreview.net/pdf?id=D0Cdljktp2", "keywords": "in-context learning, memory-augmented transformers, memformers, first-order methods, conjugate gradient descent, transformers", "abstract": "We show that memory-augmented Transformers (Memformers) can implement linear first-order optimization methods such as conjugate gradient descent, momentum methods, and more generally, methods that linearly combines past gradients. Building on prior work that demonstrates how Transformers can simulate preconditioned gradient descent, we provide theoretical and empirical evidence that Memformers can learn more advanced optimization algorithms. Specifically, we analyze how memory registers in Memformers store suitable intermediate attention values allowing them to implement algorithms such as conjugate gradient. Our results show that Memformers can efficiently learn these methods by training on random linear regression tasks, even learning methods that outperform conjugate gradient. This work extends our knowledge about the algorithmic capabilities of Transformers, showing how they can learn complex optimization methods.", "title_embedding_index": 4113, "title_abs_embedding_index": 4138}, {"title": "One Model for One Graph: A New Perspective for Pretraining with Cross-domain Graphs", "link_suffix": "/forum?id=10vaHIOdEe", "link": "https://openreview.net/forum?id=10vaHIOdEe", "pdf_link": "https://openreview.net/pdf?id=10vaHIOdEe", "keywords": "Graph Pretraining; Cross-domain Graph Learning", "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool to capture intricate network patterns, achieving successes across different domains. However, existing GNNs require careful domain-specific architecture designs and training from scratch on each dataset, leading to an expertise-intensive process with difficulty in generalizing across graphs from different domains. Therefore, it can be hard for practitioners to infer which GNN model can generalize well to graphs from their domains. To address this challenge, we propose a novel cross-domain pretraining framework, \"one model for one graph,\" which overcomes the limitations of previous approaches that failed to use a single GNN to capture diverse graph patterns across domains with significant gaps. Specifically, we pretrain a bank of expert models, with each one corresponding to a specific dataset. When inferring to a new graph, gating functions choose a subset of experts to effectively integrate prior model knowledge while avoiding negative transfer. Extensive experiments consistently demonstrate the superiority of our proposed method on both link prediction and node classification tasks.", "title_embedding_index": 4114, "title_abs_embedding_index": 4139}, {"title": "CLEAR: Understanding the Reasoning Capabilities of Large Language Models", "link_suffix": "/forum?id=3LnTTHDWER", "link": "https://openreview.net/forum?id=3LnTTHDWER", "pdf_link": "https://openreview.net/pdf?id=3LnTTHDWER", "keywords": "LLMs, dataset, benchmark, translation, in-context-learning, few-shot", "abstract": "Despite significant progress, accurately assessing the reasoning capabilities of Large Language Models (LLMs) remains both a challenging and divisive subject.\nMany existing benchmarks either suffer leakage, or reflect patterns in the training data, leading to ambiguous results.\nWe present CLEAR (Conlang Logic Evaluation And Reasoning), a novel benchmark designed to test the reasoning and problem solving capabilities of LLMs in new environments.\nCLEAR uses Conlangs (Constructed Languages) for few-shot translation tasks,\nwhich require some linguistic knowledge to solve, but primarily the ability to make new patterns from tokens in unfamiliar contexts using logical operations.\nThese conlangs represent a unique challenge, as while translation examples are plentiful, these conlangs each have a unique combination of rules, are self contained, and are absent in the training corpus.\nWe present an evaluation of current frontier models over multiple metrics as a baseline for future research. \nWe will be releasing \\dataset as a public benchmark to drive progress towards AI systems more capable of general reasoning.", "title_embedding_index": 4115, "title_abs_embedding_index": 4140}, {"title": "Astute RAG: Overcoming  Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models", "link_suffix": "/forum?id=xy6B5Fh2v7", "link": "https://openreview.net/forum?id=xy6B5Fh2v7", "pdf_link": "https://openreview.net/pdf?id=xy6B5Fh2v7", "keywords": "Retrieval Augmented Generation, Knowledge Conflicts", "abstract": "Retrieval augmented generation (RAG), while effectively integrating external knowledge to address the inherent limitations of large language models (LLMs), can be hindered by imperfect retrieval that contain irrelevant, misleading, or even malicious information. Previous studies have rarely connected the behavior of RAG through joint analysis, particularly regarding error propagation coming from imperfect retrieval and potential conflicts between LLMs' internal knowledge and external sources.\nThrough comprehensive and controlled analyses under realistic conditions, we find that imperfect retrieval augmentation is inevitable, common, and harmful. We identify the knowledge conflicts between LLM-internal and external knowledge from retrieval as a bottleneck to overcome imperfect retrieval in the post-retrieval stage of RAG.\nTo address this, we propose Astute RAG, a novel RAG approach designed to be resilient to imperfect retrieval augmentation. It adaptively elicits essential information from LLMs' internal knowledge, iteratively consolidates internal and external knowledge with source-awareness, and finalizes the answer according to information reliability.\nOur experiments with Gemini and Claude demonstrate the superior performance of Astute RAG compared to previous robustness-enhanced RAG approaches. Specifically, Astute RAG is the only RAG method that achieves performance comparable to or even surpassing conventional use of LLMs under the worst-case scenario. Further analysis reveals the effectiveness of \\method in resolving knowledge conflicts, thereby improving the trustworthiness of RAG.", "title_embedding_index": 4116, "title_abs_embedding_index": 4141}, {"title": "Model-based RL as a Minimalist Approach to Horizon-Free and Second-Order Bounds", "link_suffix": "/forum?id=txD9llAYn9", "link": "https://openreview.net/forum?id=txD9llAYn9", "pdf_link": "https://openreview.net/pdf?id=txD9llAYn9", "keywords": "reinforcement learning theory, model-based reinforcement learning", "abstract": "Learning a transition model via Maximum Likelihood Estimation (MLE) followed by planning inside the learned model is perhaps the most standard and simplest Model-based Reinforcement Learning (RL) framework. In this work, we show that such a simple Model-based RL scheme, when equipped with optimistic and pessimistic planning procedures, achieves strong regret and sample complexity bounds in online and offline RL settings. Particularly, we demonstrate that under the conditions where the trajectory-wise reward is normalized between zero and one and the transition is time-homogenous, it achieves nearly horizon-free and second-order bounds. Nearly horizon-free means that our bounds have no polynomial dependence on the horizon of the Markov Decision Process. A second-order bound is a type of instance-dependent bound that scales with respect to the variances of the returns of the policies which can be small when the system is nearly deterministic and (or) the optimal policy has small values. We highlight that our algorithms are simple, fairly standard, and indeed have been extensively studied in the RL literature: they learn a model via MLE, build a version space around the MLE solution, and perform optimistic or pessimistic planning depending on whether operating in the online or offline mode. These algorithms do not rely on additional specialized algorithmic designs such as learning variances and performing variance-weighted learning and thus can easily leverage non-linear function approximations. The simplicity of the algorithms also implies that our horizon-free and second-order regret analysis is actually standard and mainly follows the general framework of optimism/pessimism in the face of uncertainty.", "title_embedding_index": 4117, "title_abs_embedding_index": 4142}, {"title": "What Do You See in Common? Learning Hierarchical Prototypes over Tree-of-Life to Discover Evolutionary Traits", "link_suffix": "/forum?id=4sDicVEy6M", "link": "https://openreview.net/forum?id=4sDicVEy6M", "pdf_link": "https://openreview.net/pdf?id=4sDicVEy6M", "keywords": "deep learning, interpretability, prototype-based neural network, phylogeny, computer vision", "abstract": "A grand challenge in biology is to discover evolutionary traits---features of organisms common to a group of species with a shared ancestor in the tree of life (also referred to as phylogenetic tree). With the growing availability of image repositories in biology, there is a tremendous opportunity to discover evolutionary traits directly from images in the form of a hierarchy of prototypes. However, current prototype-based methods are mostly designed to operate over a flat structure of classes and face several challenges in discovering hierarchical prototypes, including the issue of learning over-specific prototypes at internal nodes. To overcome these challenges, we introduce the framework of Hierarchy aligned Commonality through Prototypical Networks (HComP-Net). The key novelties in HComP-Net include a novel over-specificity loss to avoid learning over-specific prototypes, a novel discriminative loss to ensure prototypes at an internal node are absent in the contrasting set of species with different ancestry, and a novel masking module to allow for the exclusion of over-specific prototypes at higher levels of the tree without hampering classification performance.  We empirically show that HComP-Net learns prototypes that are accurate, semantically consistent, and generalizable to unseen species in comparison to baselines.", "title_embedding_index": 4118, "title_abs_embedding_index": 4143}, {"title": "Training Physics-Driven Deep Learning Reconstruction without Raw Data Access for Equitable Fast MRI", "link_suffix": "/forum?id=rFPtqF6eaR", "link": "https://openreview.net/forum?id=rFPtqF6eaR", "pdf_link": "https://openreview.net/pdf?id=rFPtqF6eaR", "keywords": "Computational Imaging, Fast MRI, Unsupervised Learning, Compressed Sensing, Deep Learning, Equity", "abstract": "Physics-driven deep learning (PD-DL) approaches have become popular for improved reconstruction of fast magnetic resonance imaging (MRI) scans. Even though PD-DL offers higher acceleration rates compared to existing clinical fast MRI techniques, their use has been limited outside specialized MRI centers. One impediment for their deployment is the difficulties with generalization to pathologies or population groups that are not well-represented in training sets. This has been noted in several studies, and fine-tuning on target populations to improve reconstruction has been suggested. However, current training approaches for PD-DL training require access to raw k-space measurements, which is typically only available at specialized MRI centers that have research agreements for such data access. This is especially an issue for rural and underserved areas, where commercial MRI scanners only provide access to a final reconstructed image. To tackle these challenges, we propose CUPID for high-quality PD-DL training, using only routine clinical reconstructed images exported from an MRI scanner. CUPID evaluates the goodness of the output with a compressibility-based approach, while ensuring that the output stays consistent with the clinical parallel imaging reconstruction through well-designed perturbations. Our results show that CUPID achieves similar quality compared to well-established PD-DL training strategies that require raw k-space data access, while outperforming conventional compressed sensing (CS) and state-of-the-art generative methods. We also demonstrate its effectiveness in a zero-shot training setup for retrospectively and prospectively sub-sampled acquisitions, attesting to its minimal training burden. As an approach that radically deviates from existing strategies, CUPID presents an opportunity to provide equitable access to fast MRI for underserved populations in an attempt to reduce the inequalities associated with this expensive imaging modality.", "title_embedding_index": 4119, "title_abs_embedding_index": 4144}, {"title": "On Designing Effective RL Reward at Training Time for LLM Reasoning", "link_suffix": "/forum?id=F0GNv13ojF", "link": "https://openreview.net/forum?id=F0GNv13ojF", "pdf_link": "https://openreview.net/pdf?id=F0GNv13ojF", "keywords": "Large Language Models, RLHF, PPO, LLM for Reasoning, Reward Design", "abstract": "Reward models have been increasingly critical for improving the reasoning capability of LLMs. Existing research has shown that a well-trained reward model can substantially improve model performances atinference timevia search or best-of-N votes. However, the potential of reward models duringRL training timestill remains largely under-explored. It is currently unclear whether these reward models can provide additional training signals to enhance the reasoning capabilities of LLMs in RL training that uses sparse success rewards, which verify the correctness of solutions. In this work, we evaluate popular reward models for RL training, including the Outcome-supervised Reward Model (ORM) and the Process-supervised Reward Model (PRM), and train a collection of LLMs for math problems using RL by combining these learned rewards with success rewards. Surprisingly, even though these learned reward models have strong inference-time performances, they may NOT help or even hurt RLtraining, producing worse performances than LLMs trained with the success reward only. Our analysis reveals that an LLM can receive high rewards from some of these reward models by repeating correct but unnecessary reasoning steps, leading to a severe reward hacking issue for RL training. Therefore, we introduce two novel reward refinement techniques, includingClippingandDelta. The key idea is to ensure the accumulative reward of any reasoning trajectory is upper-bounded to keep a learned reward model effective without being exploited. We evaluate our techniques with multiple reward models over a set of 1.5B and 7B LLMs on MATH and GSM8K benchmarks, where bothClippingandDeltaconsistently stabilize RL training. Finally, we also demonstrate that with a carefully designed reward function, pure RL training without any additional supervised tuning can further improve all the evaluated LLMs, including the state-of-the-art 7B LLM Qwen2.5-Math-7B-Instruct on MATH and GSM8K benchmarks.", "title_embedding_index": 4120, "title_abs_embedding_index": 4145}, {"title": "Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning", "link_suffix": "/forum?id=9RCT0ngvZP", "link": "https://openreview.net/forum?id=9RCT0ngvZP", "pdf_link": "https://openreview.net/pdf?id=9RCT0ngvZP", "keywords": "synthetic data, data influence, instruction tuning", "abstract": "Synthetic data has been widely used to train large language models, but their generative nature inevitably introduces noisy, non-informative, and misleading learning signals. In this paper, we propose Montessori-Instruct, a novel data synthesis framework that tailors the data synthesis ability of the teacher language model toward the student language model's learning process. Specifically, we utilize local data influence of synthetic training data points on students to characterize students' learning preferences. Then, we train the teacher model with Direct Preference Optimization (DPO) to generate synthetic data tailored toward student learning preferences. Experiments with Llama3-8B-Instruct (teacher) and Llama3-8B (student) on Alpaca Eval and MT-Bench demonstrate that Montessori-Instruct significantly outperforms standard synthesis methods by 18.35% and 46.24% relatively. Our method also beats data synthesized by a stronger teacher model, GPT-4o. Further analysis confirms the benefits of teacher's learning to generate more influential training data in the student's improved learning, the advantages of local data influence in accurately measuring student preferences, and the robustness of Montessori-Instruct across different student models. Our code, data, and models will be open-sourced.", "title_embedding_index": 4121, "title_abs_embedding_index": 4146}, {"title": "Recombination Flow Matching Model for Protein Evolution", "link_suffix": "/forum?id=Ipe4fMCBXk", "link": "https://openreview.net/forum?id=Ipe4fMCBXk", "pdf_link": "https://openreview.net/pdf?id=Ipe4fMCBXk", "keywords": "Flow matching, Generative model, Protein design", "abstract": "The design of novel proteins, distinct from those found in nature, holds immense potential for advancing drug discovery, biotechnology, and material science. However, current methodologies often face significant limitations in generating both novel protein structures. Biological evolution, a natural process that fosters novelty, heavily relies on recombination\u2014yet this mechanism remains largely untapped in protein design. In this work, we propose Recombination Flow Matching (RFM), a novel generative model inspired by the principles of evolution. RFM meticulously preserves the structural integrity of protein segments during recombination while autonomously optimizing their spatial arrangement within the resultant protein. Using a common benchmark dataset, we demonstrate that RFM significantly outperforms established methods in producing structurally novel proteins. This approach opens new frontiers in protein design, leveraging evolutionary recombination to enhance the novelty of protein design. To the best of our knowledge, RFM is the first model to incorporate recombination into protein design.", "title_embedding_index": 4122, "title_abs_embedding_index": 4147}, {"title": "Gradient Routing: Masking Gradients to Localize Computation in Neural Networks", "link_suffix": "/forum?id=z1mLNhWFyY", "link": "https://openreview.net/forum?id=z1mLNhWFyY", "pdf_link": "https://openreview.net/pdf?id=z1mLNhWFyY", "keywords": "representation learning, modularity, unlearning, reinforcement learning, scalable oversight", "abstract": "Neural networks are trained primarily based on their inputs and outputs, without regard for their internal mechanisms. These neglected mechanisms determine properties that are critical for safety, like (i) transparency; (ii) the absence of sensitive information or harmful capabilities; and (iii) reliable generalization of goals beyond the training distribution. To address this shortcoming, we introduce gradient routing, a training method that isolates capabilities to specific subregions of a neural network. Gradient routing applies data-dependent, weighted masks to gradients during backpropagation. These masks are supplied by the user in order to configure which parameters are updated by which data points. We show that gradient routing can be used to (1) learn representations which are partitioned in an interpretable way; (2) enable robust unlearning via ablation of a pre-specified network subregion; and (3) achieve scalable oversight of a reinforcement learner by localizing modules responsible for different behaviors. Throughout, we find that gradient routing localizes capabilities even when applied to a limited, ad-hoc subset of the data. We conclude that the approach holds promise for challenging, real-world applications where quality data are scarce.", "title_embedding_index": 4123, "title_abs_embedding_index": 4148}, {"title": "Affine Steerable Equivariant Layer for Canonicalization of Neural Networks", "link_suffix": "/forum?id=5i6ZZUjCA9", "link": "https://openreview.net/forum?id=5i6ZZUjCA9", "pdf_link": "https://openreview.net/pdf?id=5i6ZZUjCA9", "keywords": "equivariant networks, steerability, the affine group, equivariants, canonicalization", "abstract": "In the field of equivariant networks, achieving affine equivariance, particularly for general group representations, has long been a challenge.\nIn this paper, we propose the steerable EquivarLayer, a generalization of InvarLayer, by extending the concept of invariants to equivariants. The steerable EquivarLayer supports affine equivariance with arbitrary input and output representations, marking the first model to incorporate steerability into networks for the affine group. To integrate it with canonicalization, a promising approach for making pre-trained models equivariant, we introduce a novel Det-Pooling module, expanding both the applicability of EquivarLayer and the range of groups suitable for canonicalization. We conduct experiments on image classification tasks involving group transformations to validate the steerable EquivarLayer in the role of a canonicalization function, demonstrating its effectiveness over data augmentation.", "title_embedding_index": 4124, "title_abs_embedding_index": 4149}]
[
    {
        "title": "Autonomous agents from automatic reward modeling and planning",
        "link_suffix": "/forum?id=womU9cEwcO",
        "link": "https://openreview.net/forum?id=womU9cEwcO",
        "pdf_link": "https://openreview.net/pdf?id=womU9cEwcO",
        "keywords": "agents, large language models, planning",
        "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across a range of text-generation tasks. However, LLMs still struggle with problems requiring multi-step decision-making and environmental feedback, such as online shopping, scientific reasoning, and mathematical problem-solving. Unlike pure text data, collecting large-scale decision-making data is challenging. Moreover, many powerful LLMs are only accessible through APIs, which hinders their fine-tuning for agent tasks due to cost and complexity. To address LLM agents' limitations, we propose a framework that can automatically learn a reward model from the environment without human annotations. This model can be used to evaluate the action trajectories of LLM agents and provide heuristics for task planning. Specifically, our approach involves employing one LLM-based agent to navigate an environment randomly, generating diverse action trajectories. Subsequently, a separate LLM is leveraged to assign a task intent and synthesize a negative response alongside the correct response for each trajectory. These triplets (task intent, positive response, and negative response) are then utilized as training data to optimize a reward model capable of scoring action trajectories. This reward model can be integrated with LLM-based agents and various planning algorithms to enhance task-solving performance. The effectiveness and generalizability of our framework are demonstrated through evaluations conducted on different agent benchmarks. In conclusion, our proposed framework represents a significant advancement in enhancing LLM agents' decision-making capabilities. By automating the learning of reward models, we overcome the challenges of data scarcity and API limitations, potentially revolutionizing the application of LLMs in complex and interactive environments. This research paves the way for more sophisticated AI agents capable of tackling a wide range of real-world problems requiring multi-step decision-making."
    },
    {
        "title": "Generalized Video Moment Retrieval",
        "link_suffix": "/forum?id=qdOIkeZ5e4",
        "link": "https://openreview.net/forum?id=qdOIkeZ5e4",
        "pdf_link": "https://openreview.net/pdf?id=qdOIkeZ5e4",
        "keywords": "video moment retrieval, diverse query types, model versatility",
        "abstract": "In this paper, we introduce the Generalized Video Moment Retrieval (GVMR) framework, which extends traditional Video Moment Retrieval (VMR) to handle a wider range of query types. Unlike conventional VMR systems, which are often limited to simple, single-target queries, GVMR accommodates both non-target and multi-target queries. To support this expanded task, we present the NExT-VMR dataset, derived from the YFCC100M collection, featuring diverse query scenarios to enable more robust model evaluation.\nAdditionally, we propose BCANet, a transformer-based model incorporating the novel Boundary-aware Cross Attention (BCA) module. The BCA module enhances boundary detection and uses cross-attention to achieve a comprehensive understanding of video content in relation to queries. BCANet accurately predicts temporal video segments based on natural language descriptions, outperforming traditional models in both accuracy and adaptability. Our results demonstrate the potential of the GVMR framework, the NExT-VMR dataset, and BCANet to advance VMR systems, setting a new standard for future multimedia information retrieval research."
    },
    {
        "title": "A Tailored Framework for Aligning Diffusion Models with Human Preference",
        "link_suffix": "/forum?id=9LZna4ryFH",
        "link": "https://openreview.net/forum?id=9LZna4ryFH",
        "pdf_link": "https://openreview.net/pdf?id=9LZna4ryFH",
        "keywords": "RLHF, Diffusion models, Direct preference optimization",
        "abstract": "The direct preference optimization (DPO) method has shown success in aligning text-to-image diffusion models with human preference.\nPrevious approaches typically assume a consistent preference label between final generated images and their corresponding noisy samples at intermediate steps, and directly apply DPO to these noisy samples for fine-tuning. However, we identify a significant issue with this consistency assumption, as directly applying DPO to noisy samples from different generation trajectories based on final preference order may disrupt the optimization process. We first demonstrate the issues inherent in previous methods from two perspectives:gradient directionandpreference order, and then propose aTailoredPreferenceOptimization (TailorPO) framework for aligning diffusion models with human preference, underpinned by some theoretical insights. Our approach directly ranks the preference order of intermediate noisy samples based on their step-wise reward, and effectively resolves the optimization direction issues through a simple yet efficient design. Additionally, to the best of our knowledge, we are the first to consider the distinct structure of diffusion models and leverage the gradient guidance in preference aligning to enhance the optimization effectiveness. Experimental results demonstrate that our method significantly improves the model's ability to generate aesthetically pleasing and human-preferred images."
    },
    {
        "title": "A Training-Free Sub-quadratic Cost Transformer Model Serving Framework with Hierarchically Pruned Attention",
        "link_suffix": "/forum?id=PTcMzQgKmn",
        "link": "https://openreview.net/forum?id=PTcMzQgKmn",
        "pdf_link": "https://openreview.net/pdf?id=PTcMzQgKmn",
        "keywords": "Efficient Attention Mechanism, Long-context LLM Decoding, KV Cache Offloading",
        "abstract": "In modern large language models (LLMs), increasing the context length is crucial for improving comprehension and coherence in long-context, multi-modal, and retrieval-augmented language generation. \nWhile many recent transformer models attempt to extend their context length over a million tokens, they remain impractical due to the quadratic time and space complexities.\nAlthough recent works on linear and sparse attention mechanisms can achieve this goal, their real-world applicability is often limited by the need to re-train from scratch and significantly worse performance. In response, we propose a novel approach, Hierarchically Pruned Attention (HiP), which reduces the time complexity of the attention mechanism to $O(T \\log T)$ and the space complexity to $O(T)$, where $T$ is the sequence length. \nWe notice a pattern in the attention scores of pretrained LLMs where tokens close together tend to have similar scores, which we call \"attention locality\". Based on this observation, we utilize a novel tree-search-like algorithm that estimates the top-$k$ key tokens for a given query on the fly, which is mathematically guaranteed to have better performance than random attention pruning. In addition to improving the time complexity of the attention mechanism, we further optimize GPU memory usage by implementing KV cache offloading, which stores only $O(\\log T)$ tokens on the GPU while maintaining similar decoding throughput. Experiments on benchmarks show that HiP, with its training-free nature, significantly reduces both prefill and decoding latencies, as well as memory usage, while maintaining high-quality generation with minimal degradation.\nHiP enables pretrained LLMs to scale up to millions of tokens on commodity GPUs, potentially unlocking long-context LLM applications previously deemed infeasible."
    },
    {
        "title": "GameGen-X: Interactive Open-world Game Video Generation",
        "link_suffix": "/forum?id=8VG8tpPZhe",
        "link": "https://openreview.net/forum?id=8VG8tpPZhe",
        "pdf_link": "https://openreview.net/pdf?id=8VG8tpPZhe",
        "keywords": "Open-world Game Video Generation, Interactive Control, Diffusion Transformers",
        "abstract": "We introduce GameGen-$\\mathbb{X}$, the first diffusion transformer model specifically designed for both generating and interactively controlling open-world game videos. \nThis model facilitates high-quality, open-domain generation by simulating an extensive array of game engine features, such as innovative characters, dynamic environments, complex actions, and diverse events. \nAdditionally, it provides interactive controllability, predicting and altering future content based on the current clip, thus allowing for gameplay simulation.\nTo realize this vision, we first collected and built an Open-World Video Game Dataset (OGameData) from scratch. \nIt is the first and largest dataset for open-world game video generation and control. \nIt comprises over one million diverse gameplay video clips sampling from over 150 games with informative captions empowered by GPT-4o.\nGameGen-$\\mathbb{X}$ undergoes a two-stage training process, consisting of foundation model pre-training and instruction tuning. \nFirst, the model was pre-trained via text-to-video generation and video continuation, endowing it with the capability for open-domain game video generation. \nFurther, to achieve interactive controllability, we designed InstructNet to incorporate game-related multi-modal control signal experts.\nThis novel design allows the model to adjust latent representations based on user inputs, unifying character interaction and scene content control for the first time.\nDuring the tuning, the pre-trained foundation model is frozen, and InstructNet enables the controllable production of subsequent frames. \nGameGen-$\\mathbb{X}$ represents a significant leap forward in open-world video game design using generative models. \nIt demonstrates the potential of generative models to serve as auxiliary tools to traditional rendering techniques, effectively merging creative generation with interactive capabilities.\nThe code script, dataset, and model weights will be public."
    },
    {
        "title": "One Step Diffusion-based Super-Resolution with Time-Aware Distillation",
        "link_suffix": "/forum?id=2vlhdheveh",
        "link": "https://openreview.net/forum?id=2vlhdheveh",
        "pdf_link": "https://openreview.net/pdf?id=2vlhdheveh",
        "keywords": "Efficient diffusion, Super-resolution, Knowledge distillation",
        "abstract": "Diffusion-based image super-resolution (SR) methods have shown promise in reconstructing high-resolution images with fine details from low-resolution counterparts. However, these approaches typically require tens or even hundreds of iterative samplings, resulting in significant latency. Recently, techniques have been devised to enhance the sampling efficiency of diffusion-based SR models via knowledge distillation. Nonetheless, when aligning the knowledge of student and teacher models, these solutions either solely rely on pixel-level loss constraints or neglect the fact that diffusion models prioritize varying levels of information at different time steps. To accomplish effective and efficient image super-resolution, we propose a time-aware diffusion distillation method, named TAD-SR. Specifically, we introduce a novel score distillation strategy to align the score functions between the outputs of the student and teacher models after minor noise perturbation. This distillation strategy eliminates the inherent bias in score distillation sampling (SDS) and enables the student models to focus more on high-frequency image details by sampling at smaller time steps. Furthermore, to mitigate performance limitations stemming from distillation, we fully leverage the knowledge in the teacher model and design a time-aware discriminator to differentiate between real and synthetic data. This discriminator effectively distinguishes the diffused distributions of real and generated images under varying levels of noise disturbance through the injection of time information. Extensive experiments on SR and blind face restoration (BFR) tasks demonstrate that the proposed method outperforms existing diffusion-based single-step techniques and achieves performance comparable to state-of-the-art diffusion models that rely on multi-step generation."
    },
    {
        "title": "Training Language Models to Critique with Multi-Agent Feedback",
        "link_suffix": "/forum?id=tciQfO8S8j",
        "link": "https://openreview.net/forum?id=tciQfO8S8j",
        "pdf_link": "https://openreview.net/pdf?id=tciQfO8S8j",
        "keywords": "Critique, LLM, preference-based RL",
        "abstract": "Critique ability, a meta-cognitive capability of humans, presents significant challenges for LLMs to improve.\nRecent works primarily rely on supervised fine-tuning (SFT) using critiques generated by a single LLM like GPT-4.\nHowever, these model-generated critiques often exhibit flaws due to the inherent complexity of the critique. \nConsequently, fine-tuning LLMs on such flawed critiques typically limits the model's performance and propagates these flaws into the learned model.\nTo overcome these challenges, this paper proposes a novel data generation pipeline, named MultiCritique, that improves the critique ability of LLMs by utilizing multi-agent feedback in both the SFT and reinforcement learning (RL) stages.\nFirst, our data generation pipeline aggregates high-quality critiques from multiple agents instead of a single model, with crucial information as input for simplifying the critique.\nFurthermore, our pipeline improves the preference accuracy of critique quality through multi-agent feedback, facilitating the effectiveness of RL in improving the critique ability of LLMs.\nBased on our proposed MultiCritique data generation pipeline, we construct the MultiCritiqueDataset for the SFT and RL fine-tuning stages. Extensive experimental results on two benchmarks demonstrate:the superior quality of our constructed SFT dataset compared to existing critique datasets;additional improvements to the critique ability of LLMs brought by the RL stage.\nNotably, our fine-tuned 7B model significantly surpasses other advanced 7B-13B open-source models, approaching the performance of advanced 70B LLMs and GPT-4.\nCodes, datasets and model weights will be publicly available."
    },
    {
        "title": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance",
        "link_suffix": "/forum?id=BgxsmpVoOX",
        "link": "https://openreview.net/forum?id=BgxsmpVoOX",
        "pdf_link": "https://openreview.net/pdf?id=BgxsmpVoOX",
        "keywords": "Text-to-image, Diffusion, Large Language Models",
        "abstract": "State-of-the-art text-to-image (T2I) diffusion models often struggle to generate rare compositions of concepts, e.g., objects with unusual attributes. In this paper, we show that the compositional generation power of diffusion models on such rare concepts can be significantly enhanced by the Large Language Model (LLM) guidance. We start with empirical and theoretical analysis, demonstrating that exposing frequent concepts relevant to the target rare concepts during the diffusion sampling process yields more accurate concept composition. Based on this, we propose a training-free approach, R2F, that plans and executes the overall rare-to\u0002frequent concept guidance throughout the diffusion inference by leveraging the abundant semantic knowledge in LLMs. Our framework is flexible across any\npre-trained diffusion models and LLMs, and can be seamlessly integrated with the region-guided diffusion approaches. Extensive experiments on three datasets, including our newly proposed benchmark, RareBench, containing various prompts with rare compositions of concepts, R2F significantly surpasses existing models including SD3.0 and FLUX by up to 28.1%p in T2I alignment."
    },
    {
        "title": "CoNNect: A Swiss-Army-Knife Regularizer for Pruning of Neural Networks",
        "link_suffix": "/forum?id=Se2aTG9Oui",
        "link": "https://openreview.net/forum?id=Se2aTG9Oui",
        "pdf_link": "https://openreview.net/pdf?id=Se2aTG9Oui",
        "keywords": "Connectivity, Regularization, Pruning",
        "abstract": "Pruning encompasses a range of techniques aimed at increasing the sparsity of neural networks (NNs). These techniques can generally be framed as minimizing a loss function subject to an $L_0$-norm constraint. In this paper, we introduce CoNNect, a novel differentiable regularizer for sparse NN training, inspired by Katz centrality, which measures connectivity in weighted graphs. Unlike $L_1$-regularization, which is often used as a surrogate for $L_0$-norm regularization, CoNNect ensures that neural networks maintain connectivity between the input and output layers throughout training. We prove that CoNNect effectively approximates $L_0$-regularization and guarantees maximally connected network structures as stable stationary points, avoiding issues such as layer collapse. Our theoretical and numerical results demonstrate that CoNNect outperforms $L_1$-norm regularization. Moreover, we show that CoNNect is applicable to both unstructured and structured pruning, and further validate its scalability and effectiveness through improved one-shot pruning performance in large language models."
    },
    {
        "title": "StochSync: Stochastic Diffusion Synchronization for Image Generation in Arbitrary Spaces",
        "link_suffix": "/forum?id=XPNprvlxuQ",
        "link": "https://openreview.net/forum?id=XPNprvlxuQ",
        "pdf_link": "https://openreview.net/pdf?id=XPNprvlxuQ",
        "keywords": "Diffusion Models, Synchronization, Score Distillation, Panorama, Texturing",
        "abstract": "We propose a zero-shot method for generating images in arbitrary spaces (e.g., a sphere for 360\u25e6 panoramas and a mesh surface for texture) using a pretrained image diffusion model. The zero-shot generation of various visual content using a pretrained image diffusion model has been explored mainly in two directions. First, Diffusion Synchronization\u2013performing reverse diffusion processes jointly across different projected spaces while synchronizing them in the target space\u2013generates high-quality outputs when enough conditioning is provided, but it struggles in its absence. Second, Score Distillation Sampling\u2013gradually updating the target space data through gradient descent\u2013results in better coherence but often lacks detail. In this paper, we reveal for the first time the interconnection between these two methods while highlighting their differences. To this end, we propose StochSync, a novel approach that combines the strengths of both, enabling effective performance with weak conditioning. Our experiments demonstrate that StochSync provides the best performance in 360\u25e6 panorama generation (where image conditioning is not given), outperforming previous finetuning-based methods, and also delivers comparable results in 3D mesh texturing (where depth conditioning is provided) with previous methods."
    },
    {
        "title": "EVA: An Embodied World Model for Future Video Anticipation",
        "link_suffix": "/forum?id=N6SccBt3EF",
        "link": "https://openreview.net/forum?id=N6SccBt3EF",
        "pdf_link": "https://openreview.net/pdf?id=N6SccBt3EF",
        "keywords": "World Model, Video Generation, Visual Language Model, Embodied AI",
        "abstract": "World models integrate raw data from various modalities\u2014such as images and language to simulate comprehensive interactions in the world, thereby displaying crucial roles in fields like mixed reality and robotics. \nYet, applying the world model for accurate video prediction is quite challenging due to the complex and dynamic intentions of the various scenes in practice. \nIn this paper, inspired by the human rethinking process, we decompose the complex video prediction into four meta-tasks that enable the world model to handle this issue in a more fine-grained manner. \nAlongside these tasks, we introduce a new benchmark named Embodied Video Anticipation Benchmark (EVA-Bench) to provide a well-rounded evaluation. \nEVA-Bench focused on evaluating the video prediction ability of human and robot actions, presenting significant challenges for both the language model and the generation model. \nTargeting embodied video prediction, we propose the Embodied Video Anticipator (EVA), a unified framework aiming at video understanding and generation. \nEVA integrates a video generation model with a visual language model, effectively combining reasoning capabilities with high-quality generation.\nMoreover, to enhance the generalization of our framework, we tailor-designed a multi-stage pretraining paradigm that adaptatively ensembles LoRA to produce high-fidelity results.Extensive experiments on EVA-Bench highlight the potential of EVA to significantly improve performance in embodied scenes, paving the way for large-scale pre-trained models in real-world prediction tasks. The video demo and benchmark information will be available at \\hyperlink{https://sites.google.com/view/iclr25-eva}{https://sites.google.com/view/iclr25-eva}."
    },
    {
        "title": "MOVIS: Enhancing Multi-Object Novel View Synthesis for Indoor Scenes",
        "link_suffix": "/forum?id=j3rxIH0M9H",
        "link": "https://openreview.net/forum?id=j3rxIH0M9H",
        "pdf_link": "https://openreview.net/pdf?id=j3rxIH0M9H",
        "keywords": "Novel View Synthesis, Multi objects",
        "abstract": "Repurposing pre-trained diffusion models has been proven to be effective for NVS. However, these methods are mostly limited to a single object; directly applying such methods to compositional multi-object scenarios yields inferior results, especially incorrect object placement and inconsistent shape and appearance under novel views. How to enhance and systematically evaluate the cross-view consistency of such models remains under-explored. \nTo address this issue, we propose MOVIS to enhance the structural awareness of the view-conditioned diffusion model for multi-object NVS in terms of model inputs, auxiliary tasks, and training strategy. First, we inject structure-aware features, including depth and object mask, into the denoising U-Net to enhance the model's comprehension of object instances and their spatial relationships. Second, we introduce an auxiliary task requiring the model to simultaneously predict novel view object masks, further improving the model's capability in differentiating and placing objects. Finally, we conduct an in-depth analysis of the diffusion sampling process and carefully devise a structure-guided timestep sampling scheduler during training, which balances the learning of global object placement and fine-grained detail recovery. To systematically evaluate the plausibility of synthesized images, we propose to assess cross-view consistency and novel view object placement alongside existing image-level NVS metrics. \nExtensive experiments on challenging synthetic and realistic datasets demonstrate that our method exhibits strong generalization capabilities and produces consistent novel view synthesis, highlighting its potential to guide future 3D-aware multi-object NVS tasks."
    },
    {
        "title": "Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models",
        "link_suffix": "/forum?id=mtJSMcF3ek",
        "link": "https://openreview.net/forum?id=mtJSMcF3ek",
        "pdf_link": "https://openreview.net/pdf?id=mtJSMcF3ek",
        "keywords": "LLM, self-improvement, synthetic data, post-training, test-time optimization",
        "abstract": "Self-improvement is a mechanism in Large Language Model (LLM) pre-training, post-training and test-time inference. We explore a framework where the model verifies its own outputs, filters or reweights data based on this verification, and distills the filtered data.  Despite several empirical successes, a fundamental understanding is still lacking. In this work, we initiate a comprehensive, modular and controlled study on LLM self-improvement. We provide a mathematical formulation for self-improvement, which is largely governed by a quantity which we formalize as thegeneration-verification gap. Through experiments with various model families and tasks, we discover a scaling phenomenon of self-improvement -- a variant of the generation-verification gap scales monotonically with the model pre-training flops. We also examine when self-improvement is possible, an iterative self-improvement procedure, and ways to improve its performance. We believe our results have several empirical implications, and our study leaves many exciting future directions for understanding the potential and limits of LLM self-improvement."
    },
    {
        "title": "Stochastically Capturing Partial Relationship among Features for Multivariate Forecasting",
        "link_suffix": "/forum?id=LugcDgDjv1",
        "link": "https://openreview.net/forum?id=LugcDgDjv1",
        "pdf_link": "https://openreview.net/pdf?id=LugcDgDjv1",
        "keywords": "Multivariate Time Series, Forecasting, Stochastic Algorithm",
        "abstract": "When tackling forecasting problems that involve multiple time-series features, existing methods for capturing inter-feature information typically fall into three categories: complete-multivariate, partial-multivariate, and univariate. Complete-multivariate methods compute relationships among the entire set of features, whereas univariate cases ignore inter-feature information altogether. In contrast to these two, partial-multivariate methods group features into clusters and capture inter-feature relationships within each cluster. However, existing partial-multivariate methods deal only with specific cases where there is a single way of grouping so once the grouping way is selected, it remains unchanged. Therefore, we introduce a generalized version of partial-multivariate methods where grouping ways are sampled stochastically (called stochastic partial-multivariate methods), which can incorporate the deterministic cases using Dirac delta distributions. We propose SPMformer, a Transformer-based stochastic partial-multivariate model, with its training algorithm. We demonstrate that SPMformer outperforms various complete-multivariate, deterministic partial-multivariate, and univariate models in various forecasting tasks (long-term, short-term, and probabilistic forecasting), providing a theoretical rationale and empirical analysis for its superiority. Additionally, by proposing an inference method leveraging the inherent stochasticity in SPMformer, the forecasting accuracy is further enhanced. Finally, we highlight other advantages of SPMformer: efficiency and robustness under missing features."
    },
    {
        "title": "Injecting Inductive Bias to 3D Gaussian Splatting for Geometrically Accurate Radiance Fields",
        "link_suffix": "/forum?id=vkj5ARRCeY",
        "link": "https://openreview.net/forum?id=vkj5ARRCeY",
        "pdf_link": "https://openreview.net/pdf?id=vkj5ARRCeY",
        "keywords": "3D Gaussian Splatting, Surface Reconstruction",
        "abstract": "3D Gaussian Splatting (3DGS) has significantly advanced high-fidelity, real-time novel view synthesis. However, its discrete nature limits the accurate reconstruction of geometry. To address this issue, recent methods have introduced rendering and regularization of depth and normal maps from 3D Gaussians, leading to plausible results. In this paper, we argue that computing normals from independently trainable Gaussian covariances contradicts the strict definition of normals, which should instead be derived from the distribution of neighboring densities. To address this, we introduce an inductive bias into 3DGS by explicitly parameterizing covariances of Gaussians using principal axes and variances of distribution computed from neighboring Gaussians. These axes and variances are then regularized to ensure local surface smoothness. Our approach achieves state-of-the-art performance on multiple datasets."
    },
    {
        "title": "Synchronous Scene Text Spotting and Translating",
        "link_suffix": "/forum?id=jrY83wPzMJ",
        "link": "https://openreview.net/forum?id=jrY83wPzMJ",
        "pdf_link": "https://openreview.net/pdf?id=jrY83wPzMJ",
        "keywords": "multimodal machine translation",
        "abstract": "Text image machine translation aims to translate the content of textual regions in images from a source language to a target language. Compared with traditional document, images captured in natural scenes have more diverse text and more complex layout, posing challenges in recognizing text content and predicting reading order within each text region. Current methods mainly adopt pipeline pattern, in which models for text spotting and translating are trained separately. In this pattern, translation performance is affected by propagation of mispredicted reading order and text recognition errors. In this paper, we propose a scene text image machine translation approach by implementation of synchronous text spotting and translating. A bridge and fusion module is introduced to make better use of multi-modal feature. Besides, we create datasets for both Chinese-to-English and English-to-Chinese image translation. Experimental results substantiate that our method achieves state-of-the-art translation performance in scene text field, proving the effectiveness of joint learning and multi-modal feature fusion."
    },
    {
        "title": "Mean-field Continuous Sequence Predictors",
        "link_suffix": "/forum?id=1e5fX6X44w",
        "link": "https://openreview.net/forum?id=1e5fX6X44w",
        "pdf_link": "https://openreview.net/pdf?id=1e5fX6X44w",
        "keywords": "Mean-field graphon games, Mean-field games as continuous sequence prediction, Mean-field Neural SDEs",
        "abstract": "We propose a novel class of neural differential equation models called mean-field continuous sequence predictors (MFPs) for efficiently generating continuous sequences with potentially infinite-order complexity. To address complex inductive biases in time-series data, we employ mean-field dynamics structured through carefully designed graphons. By reframing time-series prediction as mean-field games, we utilize a fictitious play strategy integrated with gradient-descent techniques. This approach exploits the stochastic maximum principle to determine the Nash equilibrium of the system. Both empirical evidence and theoretical analysis underscore the unique advantages of our MFPs, where a collective of continuous predictors achieves highly accurate predictions and consistently outperforms benchmark prior works."
    },
    {
        "title": "Temporal Adaptive Convolutional Intervention Network for Counterfactual Estimation: A Domain Generalization Perspective",
        "link_suffix": "/forum?id=gJPe4dxm7N",
        "link": "https://openreview.net/forum?id=gJPe4dxm7N",
        "pdf_link": "https://openreview.net/pdf?id=gJPe4dxm7N",
        "keywords": "causal inference, longitudinal data, time-varying confounding bias, domain generalization",
        "abstract": "Accurate estimation of time-varying treatment effects is crucial for optimizing interventions in personalized medicine. However, observational data often contains complex confounding bias and temporal complexities, making counterfactual estimation challenging. We propose Temporal Adaptive Convolutional Intervention Network (TACIN), a novel model that introduces an Intervention-aware Functional Convolution kernel to emphasize the role of treatments and capture complex temporal treatment interactions. TACIN addresses confounding bias from a domain generalization perspective, approximating the unknown target domain using adversarial examples and incorporating Sharpness-Aware Minimization to derive a generalization bound. This approach is more suitable for longitudinal settings compared to existing methods inspired by domain adaptation techniques due to inherent differences between static and longitudinal contexts. Experiments on simulated datasets demonstrate TACIN's superior performance compared to state-of-the-art models for counterfactual estimation over time."
    },
    {
        "title": "iQR: Quantile Regression with QR Orthogonal Decomposition for Resource Scheduling Optimization without Empirical Model",
        "link_suffix": "/forum?id=JIePBlcFg0",
        "link": "https://openreview.net/forum?id=JIePBlcFg0",
        "pdf_link": "https://openreview.net/pdf?id=JIePBlcFg0",
        "keywords": "Resource Scheduling Strategy, Sparse System Identification, L1-norm  Quantile Regression, Business Constraint Satisfaction",
        "abstract": "Optimal resource scheduling aims to cover resource demand with minimum economic cost, which is far from model-based constraint optimization or data-driven prediction based scheduling process. To address this model-free constraint optimization issue, a sparse system identification framework with quantile regression and QR orthogonal decomposition~(iQR) is proposed for complex systems ranging from small to large scales. It leverages quantile optimization with $L_1$-norm to construct a business-driven strategy to reach the proportion of meeting resource demand. It also involves a complete-mapping Fourier Transformation process and an orthogonal least squares technique to select basis vectors in advance to achieve fast regression with sparse mathematical expression, which reduces the number of basis functions from thousands to hundreds and to dozens. iQR represents a specific expectation for single time series prediction, which only achieves predictions that deviate from the true values as little as possible, but aims for predictions consistently higher than the actual values of real demand. Numerical experiments was conducted on eight datasets, including commonly used time series and real-world CPU resource data. The results indicate that most neural network-based methods fail to balance both resource demands and prediction accuracy effectively. In contrast, iQR can achieve optimal scheduling with the minimum economic cost and it is easier to satisfy the business constraints with quantile tuning. Notably, iQR is lightweight with a training speed in seconds and does not rely on the support of computing power of GPU resources. This study may provide new insight into investigations on resource scheduling optimization issues."
    },
    {
        "title": "Transferable Adversarial Attack on Vision-enabled Large Language Models",
        "link_suffix": "/forum?id=DYVSLfiyRN",
        "link": "https://openreview.net/forum?id=DYVSLfiyRN",
        "pdf_link": "https://openreview.net/pdf?id=DYVSLfiyRN",
        "keywords": "adversarial attack, black-box attack, transferable attack, vision-enabled large language models",
        "abstract": "Vision-enabled Large Language Models (VLLMs) are increasingly deployed to offer advanced capabilities on inputs comprising both text and images. While prior research has shown that adversarial attacks can transfer from open-source to proprietary black-box models in text-only and vision-only contexts, the extent and effectiveness of such vulnerabilities remain underexplored for VLLMs. \nWe present a comprehensive analysis demonstrating that targeted adversarial examples are highly transferable to widely-used proprietary VLLMs such as GPT-4o, Claude, and Gemini. \nWe show that attackers can craft perturbations to induce specific attacker-chosen interpretations of visual information, such as misinterpreting hazardous content as safe, overlooking sensitive or restricted material, or generating detailed incorrect responses aligned with the attacker's intent. \nFurthermore, we discover that universal perturbations---modifications applicable to a wide set of images---can consistently induce these misinterpretations across multiple proprietary VLLMs. \nOur experimental results on object recognition, visual question answering, and image captioning show that this vulnerability is common across current state-of-the-art models, and underscore an urgent need for robust mitigations to ensure the safe and secure deployment of VLLMs."
    },
    {
        "title": "Does Your Video-language Model Actually Understand the Language Input?",
        "link_suffix": "/forum?id=O4LoPhRSfb",
        "link": "https://openreview.net/forum?id=O4LoPhRSfb",
        "pdf_link": "https://openreview.net/pdf?id=O4LoPhRSfb",
        "keywords": "Video-language Model, Coarse-grained Language Alignment, Attribute-based Text Reasoning, Fine-grained Language Alignment",
        "abstract": "Driven by the wave of Large Language Models (LLMs), Video-Language Models (VLMs) have become a significant yet challenging technology to bridge the gap between video and text. Although previous LVLM works have made significant progress, almost all of them implicitly assume that all the texts are predefined by the specific template. In real-world applications, such an assumption is impossible to satisfy, since predefining all the texts is extremely time-consuming and labor-intensive. Besides, these predefined text inputs are too strict and user-unfriendly, limiting their applications. It is observed that given a video input, texts with similar semantics lead to various performances. To this end, in this paper, we propose a novel text-augmented LVLM method to improve video-text fusion by text rewriting. Specifically, we first generate various text samples from the original ones based on the pre-trained LLM to target specific text components. A multi-level contrastive learning module is designed to mine the coarse-grained language information. Moreover, we also propose an attribute-based text reasoning strategy to learn fine-grained textual semantics. Extensive experiments on many video-language tasks show that the proposed method can serve as the plug-and-play module to effectively improve the performance of state-of-the-art VLM works."
    },
    {
        "title": "Mamba-Reg: Vision Mamba Also Needs Registers",
        "link_suffix": "/forum?id=wxEASOHHdT",
        "link": "https://openreview.net/forum?id=wxEASOHHdT",
        "pdf_link": "https://openreview.net/pdf?id=wxEASOHHdT",
        "keywords": "State Space Models, Mamba, Representation Learning",
        "abstract": "Similar to Vision Transformers, this paper identifies artifacts also present within the feature maps of Vision Mamba. These artifacts, corresponding to high-norm tokens emerging in low-information background areas of images, appear much more severe in Vision Mamba---they exist prevalently even with the tiny-sized model and activate extensively across background regions. To mitigate this issue, we follow the prior solution of introducing register tokens into Vision Mamba. To better cope with Mamba blocks' uni-directional inference paradigm, two key modifications are introduced: 1) evenly inserting registers throughout the input token sequence, and 2) recycling registers for final decision predictions. We term this new architecture MambaReg. Qualitative observations suggest, compared to vanilla Vision Mamba, MambaReg's feature maps appear cleaner and more focused on semantically meaningful regions.  Quantitatively, MambaReg attains stronger performance and scales better.  For example, on the ImageNet benchmark, our MambaReg-B attains 83.0% accuracy, significantly outperforming Vim-B's 81.8%; furthermore, we provide the first successful scaling to the large model size (i.e., with 341M parameters), attaining a competitive accuracy of 83.6% (84.5% if finetuned with 384x384 inputs). Additional validation on the downstream semantic segmentation task also supports MambaReg's efficacy."
    },
    {
        "title": "Score-Based Variational Inference for Inverse Problems",
        "link_suffix": "/forum?id=kfsgz2Ldd7",
        "link": "https://openreview.net/forum?id=kfsgz2Ldd7",
        "pdf_link": "https://openreview.net/pdf?id=kfsgz2Ldd7",
        "keywords": "Diffusion model, inverse problem, variational inference, natural gradient descent",
        "abstract": "Existing diffusion-based methods for inverse problems sample from the posterior using score functions and accept the generated random samples as solutions. In applications that posterior mean is preferred, we have to generate multiple samples from the posterior which is time-consuming. In this work, by analyzing the probability density evolution of the conditional reverse diffusion process, we prove that the posterior mean can be achieved by tracking the mean of each reverse diffusion step. Based on that, we establish a framework termed reverse mean propagation (RMP) that targets the posterior mean directly. We show that RMP can be implemented by solving a variational inference problem, which can be further decomposed as minimizing a reverse KL divergence at each reverse step. We further develop an algorithm that optimizes the reverse KL divergence with natural gradient descent using score functions and propagates the mean at each reverse step. Experiments demonstrate the validity of the theory of our framework and show that our algorithm outperforms state-of-the-art algorithms on reconstruction performance with lower computational complexity in various inverse problems."
    },
    {
        "title": "Are Large Vision-Language Models Robust to Adversarial Visual Transformations?",
        "link_suffix": "/forum?id=q8XGHj7yrC",
        "link": "https://openreview.net/forum?id=q8XGHj7yrC",
        "pdf_link": "https://openreview.net/pdf?id=q8XGHj7yrC",
        "keywords": "Large Vision-Language Model, Adversarial Attack",
        "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities across a wide range of multimodal understanding and reasoning tasks. However, recent research shows that LVLMs are susceptible to adversarial examples. Existing LVLM attackers either optimize the perturbations on the visual input or manipulate prompts to fool the LVLM models, requiring extensive design and engineering on these adversarial manipulations. While straightforward visual transformation can boast training generalization-ability, its potential risks to LVLMs in terms of safety and trustworthiness have been largely neglected. In this paper, we ask an intriguing question: can simple yet easy-to-implement visual transformations be utilized to attack the LVLM models? Motivated by this research gap and new attack setting, we propose the first comprehensive assessment of LVLMs' adversarial robustness to visual transformations by testing LVLMs' resilience to all possible transformation operations. Our empirical observations suggest that with the appropriate combination of the most harmful transformations, we can build transformation-based attacks more adversarial to the LVLM models. Moreover, adversarial learning of visual transformations is further introduced to adaptively apply the malicious impacts of all potentially harmful transformations to the raw images via gradient approximation for improving the attack effectiveness and imperceptibility. We hope that this study can provide deeper insights into the LVLMs' vulnerability to adversarial visual transformations."
    },
    {
        "title": "Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs",
        "link_suffix": "/forum?id=H5FUVj0vMd",
        "link": "https://openreview.net/forum?id=H5FUVj0vMd",
        "pdf_link": "https://openreview.net/pdf?id=H5FUVj0vMd",
        "keywords": "Large Language Models, Mathematical Reasoning, Direct Preference Optimization",
        "abstract": "Mathematical reasoning presents a significant challenge for Large Language Models (LLMs) due to the extensive and precise chain of reasoning required for accuracy. Ensuring the correctness of each reasoning step is critical. To address this, we aim to enhance the robustness and factuality of LLMs by learning from human feedback. However, Direct Preference Optimization (DPO) has shown limited benefits for long-chain mathematical reasoning, as models employing DPO struggle to identify detailed errors in incorrect answers. This limitation stems from a lack of fine-grained process supervision. We propose a simple, effective, and data-efficient method called Step-DPO, which treats individual reasoning steps as units for preference optimization rather than evaluating answers holistically. Additionally, we have developed a data construction pipeline for Step-DPO, enabling the creation of a high-quality dataset containing 10K step-wise preference pairs. We also observe that in DPO, the data generated by the policy model is more effective than that produced by humans or GPT-4, due to the former's in-distribution nature. Our findings demonstrate that as few as 10K preference data pairs and fewer than 500 Step-DPO training steps can yield a nearly 3% gain in accuracy on MATH for models with over 70B parameters. Notably, Step-DPO, when applied to Qwen2-72B-Instruct, achieves scores of 70.8% and 94.0% on the test sets of MATH and GSM8K, respectively, surpassing a series of closed-source models, including GPT-4-1106, Claude-3-Opus, and Gemini-1.5-Pro."
    }
]
[{"title": "Variational Mirror Descent for Robust Learning in Schr\u00f6dinger Bridge", "link_suffix": "/forum?id=Re4Z3Wt2DS", "link": "https://openreview.net/forum?id=Re4Z3Wt2DS", "pdf_link": "https://openreview.net/pdf?id=Re4Z3Wt2DS", "keywords": "optimal transport, mirror descent, variational methods", "abstract": "Schr\u00f6dinger bridge (SB) has evolved into a universal class of probabilistic generative models. Recent studies regarding the Sinkhorn algorithm through mirror descent (MD) have gained attention, revealing geometric insights into solution acquisition of the SB problems. In this paper, we propose a variational online MD framework for the SB problems, which provides further stability to SB solvers. We formally prove convergence and a regret bound $\\mathcal{O}(\\textrm{\\small$\\sqrt{T}$})$ of online mirror descent under mild assumptions. As a result of analysis, we propose a simulation-free SB algorithm called Variational Mirrored Schr\u00f6dinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of the Gaussian mixture parameterization for Schr\u00f6dinger potentials. Based on the Wasserstein gradient flow theory, our variational MD framework offers tractable gradient-based learning dynamics that precisely approximate a subsequent update. We demonstrate the performance of the proposed VMSB algorithm in an extensive suite of benchmarks.", "title_embedding_index": 13500, "title_abs_embedding_index": 13525}, {"title": "Rethinking and improving autoformalization: towards a faithful metric and a Dependency Retrieval-based approach", "link_suffix": "/forum?id=hUb2At2DsQ", "link": "https://openreview.net/forum?id=hUb2At2DsQ", "pdf_link": "https://openreview.net/pdf?id=hUb2At2DsQ", "keywords": "Large Language Model, Formal Verification, Autoformalization", "abstract": "As a central component in formal verification, statement autoformalization has been widely studied including the recent efforts from machine learning community, but still remains a widely-recognized difficult and open problem. In this paper, we delve into two critical yet under-explored gaps: 1) absence of faithful and universal automated evaluation for autoformalization results; 2) agnosia of contextural information, inducing severe hallucination of formal definitions and theorems.\nTo address the first issue, we proposeBEq(BidirectionalExtended Definitional Equivalence), an automated neuro-symbolic method to determine the equivalence between two formal statements, which is formal-grounded and well-aligned with human intuition.\nFor the second, we proposeRAutoformalizer(Retrieval-augmentedAutoformalizer), augmenting statement autoformalization byDependency Retrieval, retrieving potentially dependent objects from formal libraries.\nWe parse the dependencies of libraries and propose tostructurally informaliseformal objects by the topological order of dependencies. To evaluate OOD generalization and research-level capabilities, we build a novel benchmark,Con-NF, consisting of 961 informal-formal statement pairs from frontier mathematical researches.\nExtensive experiments validate the effectiveness of our proposed approaches. In particular, BEq is evaluated on 200 diverse formal statement pairs with expert-annotated equivalence label, exhibiting significantly improved accuracy ($82.50\\% \\mapsto 90.50\\%$) and precision ($70.59\\% \\mapsto 100.0\\%$).\nFor dependency retrieval, a baseline with excellent performance is established.\nThe proposed RAutoformalizer substantially outperforms SOTA baselines in both in-distribution ProofNet benchmark ($12.83\\% \\mapsto 18.18\\%$, BEq@8) and OOD Con-NF scenario ($4.58\\%\\mapsto 16.86\\%$, BEq@8). Code, data, and models will be available.", "title_embedding_index": 13501, "title_abs_embedding_index": 13526}, {"title": "On the Importance of Language-driven Representation Learning for Heterogeneous Federated Learning", "link_suffix": "/forum?id=7pDI74iOyu", "link": "https://openreview.net/forum?id=7pDI74iOyu", "pdf_link": "https://openreview.net/pdf?id=7pDI74iOyu", "keywords": "federated learning, language-driven representation learning, data heterogeneity", "abstract": "Non-Independent and Identically Distributed (Non-IID) training data significantly challenge federated learning (FL), impairing the performance of the global model in distributed frameworks. Inspired by the superior performance and generalizability of language-driven representation learning in centralized settings, we explore its potential to enhance FL for handling non-IID data. In specific, this paper introduces FedGLCL, a novel language-driven FL framework that uniquely integrates global language and local image features through contrastive learning, offering a new approach to tackle non-IID data in FL. FedGLCL redefines FL by avoiding separate local training models for each client. Instead, it uses contrastive learning to harmonize local image features with global textual data, enabling uniform feature learning across different local models. The utilization of a pre-trained text encoder in FedGLCL serves a dual purpose: it not only reduces the variance in local feature representations within FL by providing a stable and rich language context but also aids in mitigating overfitting, particularly to majority classes, by leveraging broad linguistic knowledge. Extensive experiments show that FedGLCL significantly outperforms state-of-the-art FL algorithms across different non-IID scenarios.", "title_embedding_index": 13502, "title_abs_embedding_index": 13527}, {"title": "Structured Diffusion Models with Mixture of Gaussians as Prior Distribution", "link_suffix": "/forum?id=ZqM9mZkrRB", "link": "https://openreview.net/forum?id=ZqM9mZkrRB", "pdf_link": "https://openreview.net/pdf?id=ZqM9mZkrRB", "keywords": "structured diffusion models, mixed Gaussian prior, training efficiency under limited resources", "abstract": "We propose a class of structured diffusion models, in which the prior distribution is chosen as a mixture of Gaussians, rather than a standard Gaussian distribution. The specific mixed Gaussian distribution, as prior, can be chosen to incorporate certain structured information of the data. We develop a simple-to-implement training procedure that smoothly accommodates the use of mixed Gaussian as prior. Theory is provided to quantify the benefits of our proposed models, compared to the classical diffusion models. Numerical experiments with synthetic, image and operational data are conducted to show comparative advantages of our model. Our method is shown to be robust to mis-specifications and in particular suits situations where training resources are limited or faster training in real time is desired.", "title_embedding_index": 13503, "title_abs_embedding_index": 13528}, {"title": "Vision Foundation Models Bridge the Geometric Knowledge Across Domains for Long-Tailed Recognition", "link_suffix": "/forum?id=jl0wssxHHS", "link": "https://openreview.net/forum?id=jl0wssxHHS", "pdf_link": "https://openreview.net/pdf?id=jl0wssxHHS", "keywords": "long-tailed classification, transfer of knowledg, distributed calibration, Vision foundation models", "abstract": "Deep learning struggles to fully unleash its potential in scenarios with limited sample sizes, primarily because models fail to capture information beyond the observed domain when the number of samples from rare classes is limited. Therefore, restoring the true distribution of rare classes becomes a significant challenge. In this study, we discovered that vision foundation models can associate inter-class similarity with the similarity of geometric shapes of class distributions in cross-domain scenarios. Specifically, we observed that when two cross-domain classes are highly similar, their embedding distributions also exhibit similar geometric shapes and sizes. These phenomena only manifest when using foundation models to represent images. Our findings provide a foundation for leveraging geometric knowledge of existing data distributions to assist rare classes. Further, we propose the Geometrically Guided Uncertainty Representation (GUR) Layer tailored for long-tailed recognition tasks, aiming to calibrate and augment the embedding distribution of tail classes, thereby learning an unbiased MLP classifier. Across multiple long-tailed benchmark datasets, GUR significantly enhances the performance of vision foundation models and achieves state-of-the-art results on certain datasets. The success of GUR serves as a typical example of integrating and colliding foundation models with prior knowledge.", "title_embedding_index": 13504, "title_abs_embedding_index": 13529}, {"title": "Identifiable Exchangeable Mechanisms for Causal Structure and Representation Learning", "link_suffix": "/forum?id=k03mB41vyM", "link": "https://openreview.net/forum?id=k03mB41vyM", "pdf_link": "https://openreview.net/pdf?id=k03mB41vyM", "keywords": "causality, ICA, identifiability, causal representation learning", "abstract": "Identifying latent representations or causal structures is important for good generalization and downstream task performance. However, both fields developed rather independently.\nWe observe that several structure and representation identifiability methods, particularly those that require multiple environments, rely on \nexchangeable non--i.i.d. (independent and identically distributed) data.\nTo formalize this connection, \nwe propose the Identifiable Exchangeable Mechanisms (IEM) framework to unify key representation and causal structure learning methods. IEM provides a unified probabilistic graphical model encompassing causal discovery, Independent Component Analysis, and Causal Representation Learning.\nWith the help of the IEM model, we generalize the Causal de Finetti theorem of Guo et al., 2022 by relaxing the necessary conditions for causal structure identification in exchangeable data.\nWe term these conditions cause and mechanism variability, and show how they imply a duality condition in identifiable representation learning, leading to new identifiability results.", "title_embedding_index": 13505, "title_abs_embedding_index": 13530}, {"title": "Loius (Look it up in the Structure): Benchmark and Techniques for Document structure aware LLM based Retrieval", "link_suffix": "/forum?id=53kUa92R7J", "link": "https://openreview.net/forum?id=53kUa92R7J", "pdf_link": "https://openreview.net/pdf?id=53kUa92R7J", "keywords": "information retrieval, llm, model based retrieval, document search, retrieval benchmark, document structure, benchmark", "abstract": "Modern day LLMs have shown remarkable success in understanding human instructions and provide satisfactory responses across a diverse set of tasks that require world knowledge. In this work, we leverage the inherent capability of LLMs to learn new tasks through instruction to design a novel retriever Loius that proposes a new retrieval paradigm: Table of Contents (ToC) based retrieval. Loius mimics how humans leverage the structure of a book (or a long document) by using ToC to search for information. Loius demonstrates that LLMs can be finetuned to build ToC based retrievers where the most granular ToC entry (leaf node) serves as the retrieval unit. This approach differs from traditional retrieval systems, which index chunks of information from long documents. We also introduce a novel\ncomprehensive benchmark ToCTome featuring 18 books across 6 diverse domains (with train, test and dev splits) and show that Loius achieves R@1 score of 82.6% as compared to the next best system (DSI) (76.9%) and other baselines such as BM25 (71.6%), DPR (53.6%) and out-of-the-box Mistral Instruct v0.2 (18.0%) on average. Loius is capable of incorporating corpus knowledge while learning to select the most relevant ToC leaf node, resulting in almost zero hallucinations (lessthan 0.05%) \u2013 a key issue with LLM-based retrievers. In addition to the benchmark, complete code for building Loius will be publicly released to accelerate research\nin the novel direction of ToC based retrieval.", "title_embedding_index": 13506, "title_abs_embedding_index": 13531}, {"title": "Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs", "link_suffix": "/forum?id=YQvvJjLWX0", "link": "https://openreview.net/forum?id=YQvvJjLWX0", "pdf_link": "https://openreview.net/pdf?id=YQvvJjLWX0", "keywords": "large language models; hallucinations; linear probing; uncertainty estimation; interpretability", "abstract": "We propose semantic entropy probes (SEPs), a cheap and reliable method for uncertainty quantification in Large Language Models (LLMs). Hallucinations, which are plausible-sounding but factually incorrect and arbitrary model generations, present a major challenge to the practical adoption of LLMs. Recent work by Farquhar et al. proposes semantic entropy (SE), which can reliably detect hallucinations by quantifying the uncertainty over different generations by estimating entropy over semantically equivalent sets of outputs. However, the 5-to-10-fold increase in computation cost associated with SE computation hinders practical adoption. To address this, we propose SEPs, which directly approximate SE from the hidden states of a single generation. SEPs are simple to train and do not require sampling multiple model generations at test time, reducing the overhead of semantic uncertainty quantification to almost zero. We show that SEPs retain high performance for hallucination detection and generalize better to out-of-distribution data than previous probing methods that directly predict model accuracy. Our results across models and tasks suggest that model hidden states capture SE, and our ablation studies give further insights into the token positions and model layers for which this is the case.", "title_embedding_index": 13507, "title_abs_embedding_index": 13532}, {"title": "Evaluating Deep Unlearning in Large Language Models", "link_suffix": "/forum?id=CIN2VRxPKU", "link": "https://openreview.net/forum?id=CIN2VRxPKU", "pdf_link": "https://openreview.net/pdf?id=CIN2VRxPKU", "keywords": "large language models, machine unlearning, knowledge base", "abstract": "Machine unlearning is a key requirement of many data protection regulations such as GDPR. Prior work on unlearning has mostly considered superficial unlearning tasks where a single or a few related pieces of information are required to be removed. However, the task of unlearning a fact is much more challenging in recent large language models (LLMs), because the facts in LLMs can be deduced from each other. In this work, we investigate whether current unlearning methods for LLMs succeed beyond superficial unlearning of facts. Specifically, we formally propose a framework and a definition for deep unlearning facts that are interrelated. We design the metric, recall, to quantify the extent of deep unlearning. To systematically evaluate deep unlearning, we construct a synthetic dataset EDU-RELAT, which consists of a synthetic knowledge base of family relationships and biographies, together with a realistic logical rule set that connects them. We use this dataset to test four unlearning methods in four LLMs at different sizes. Our findings reveal that in the task of deep unlearning only a single fact, they either fail to properly unlearn with high recall, or end up unlearning many other irrelevant facts. Our dataset and code are publicly available at: link/provided/after/acceptance.", "title_embedding_index": 13508, "title_abs_embedding_index": 13533}, {"title": "TwinsFormer: Revisiting Inherent Dependencies via Two Interactive Components for Time Series Forecasting", "link_suffix": "/forum?id=BSsyY29bcl", "link": "https://openreview.net/forum?id=BSsyY29bcl", "pdf_link": "https://openreview.net/pdf?id=BSsyY29bcl", "keywords": "Inherent Dependencies, Interactive Components, Time Series Forecasting", "abstract": "Due to the remarkable ability to capture long-term dependencies, Transformer-based models have shown great potential in time series forecasting. However, real-world time series usually present intricate temporal patterns, making forecasting still challenging in many practical applications. To better grasp inherent dependencies, in this paper, we propose \\textbf{TwinsFormer}, a Trans\\underline{former}-based model utilizing \\underline{tw}o \\underline{in}teractive component\\underline{s} for time series forecasting. Unlike the mainstream paradigms of plain decomposition that train the model with two independent branches, we design an interactive strategy around the attention module and the feed-forward network to strengthen the dependencies via decomposed components. Specifically, we adopt dual streams to facilitate progressive and implicit information interactions for trend and seasonal components. For the seasonal stream,  we feed the seasonal component to the attention module and feed-forward network with a subtraction mechanism. Meanwhile, we construct an auxiliary highway (without the attention module) for the trend stream by the supervision of seasonal signals. Finally, we incorporate the dual-stream outputs into a linear layer leading to the ultimate prediction. In this way, we can avoid the model overlooking inherent dependencies between different components for accurate forecasting. Our interactive strategy, albeit simple, can be adapted as a plug-and-play module to existing Transformer-based methods with negligible extra computational overhead. Extensive experiments on various real-world datasets show the superiority of TwinsFormer, which can outperform previous state-of-the-art methods in terms of both long-term and short-term forecasting performance.", "title_embedding_index": 13509, "title_abs_embedding_index": 13534}, {"title": "Towards Reliable Backdoor Attacks on Vision Transformers", "link_suffix": "/forum?id=vdHSMJpBya", "link": "https://openreview.net/forum?id=vdHSMJpBya", "pdf_link": "https://openreview.net/pdf?id=vdHSMJpBya", "keywords": "Backdoor Attacks, Vision Transformer", "abstract": "Backdoor attacks, which make Convolution Neural Networks (CNNs) exhibit specific behaviors in the presence of a predefined trigger, bring risks to the usage of CNNs. These threats should be also considered on Vision Transformers. However, previous studies found that the existing backdoor attacks are powerful enough in ViTs to bypass common backdoor defenses, i.e., these defenses either fail to reduce the attack success rate or cause a significant accuracy drop. This study investigates the existing backdoor attacks/defenses and finds that this kind of achievement is over-optimistic, caused by inappropriate adaption of defenses from CNNs to ViTs. Existing backdoor attacks can still be easily defended against with proper inheritance from CNNs. Furthermore, we propose a more reliable attack: adding a small perturbation on the trigger is enough to help existing attacks more persistent against various defenses. We hope our contributions, including the finding that existing attacks are still easy to defend with adaptations and the new backdoor attack, will promote more in-depth research into the backdoor robustness of ViTs.", "title_embedding_index": 13510, "title_abs_embedding_index": 13535}, {"title": "Is Factuality Enhancement a Free Lunch For LLMs? Better Factuality Can Lead to Worse Context-Faithfulness", "link_suffix": "/forum?id=asGQQc7gNo", "link": "https://openreview.net/forum?id=asGQQc7gNo", "pdf_link": "https://openreview.net/pdf?id=asGQQc7gNo", "keywords": "Large Language Models, In-Context Faithfulness, Factuality Enhancement", "abstract": "As the modern tools of choice for text understanding and generation, large language models (LLMs) are expected to accurately output answers by leveraging the input context.\nThis requires LLMs to possess both context-faithfulness and factual accuracy.\nExtensive efforts have been made to enable better outputs from LLMs by mitigating hallucinations through factuality enhancement methods.\nHowever, they also pose risks of hindering context-faithfulness, as factuality enhancement can lead LLMs to become overly confident in their parametric knowledge, causing them to overlook the relevant input context.\nIn this work, we argue that current factuality enhancement methods can significantly undermine the context-faithfulness of LLMs.\nWe first revisit the current factuality enhancement methods and evaluate their effectiveness in enhancing factual accuracy.\nNext, we evaluate their performance on knowledge editing tasks to assess the potential impact on context-faithfulness.\nThe experimental results reveal that while these methods may yield inconsistent improvements in factual accuracy, they also cause a more severe decline in context-faithfulness, with the largest decrease reaching a striking 69.7%.\nTo explain these declines, we analyze the hidden states and logit distributions for the tokens representing new knowledge and parametric knowledge respectively, highlighting the limitations of current approaches.\nOur finding highlights the complex trade-offs inherent in enhancing LLMs.\nTherefore, we recommend that more research on LLMs' factuality enhancement make efforts to reduce the sacrifice of context-faithfulness.", "title_embedding_index": 13511, "title_abs_embedding_index": 13536}, {"title": "MAVIN: Multi-Action Video Generation with Diffusion Models via Transition Video Infilling", "link_suffix": "/forum?id=IIDFStLGQx", "link": "https://openreview.net/forum?id=IIDFStLGQx", "pdf_link": "https://openreview.net/pdf?id=IIDFStLGQx", "keywords": "video generation, diffusion model, generative AI", "abstract": "Diffusion-based video generation has achieved significant progress, yet generating multiple actions that occur sequentially remains a formidable task. Directly generating a video with sequential actions can be extremely challenging due to the scarcity of fine-grained action annotations and the difficulty in establishing temporal semantic correspondences and maintaining long-term consistency. To tackle this, we propose an intuitive and straightforward solution: splicing multiple single-action video segments sequentially. The core challenge lies in generating smooth and natural transitions between these segments given the inherent complexity and variability of action transitions. We introduce MAVIN (Multi-Action Video INfilling model), designed to generate transition videos that seamlessly connect two given videos, forming a cohesive integrated sequence. MAVIN incorporates several innovative techniques to address challenges in the transition video infilling task. Firstly, a consecutive noising strategy coupled with variable-length sampling is employed to handle large infilling gaps and varied generation lengths. Secondly, boundary frame guidance (BFG) is proposed to address the lack of semantic guidance during transition generation. Lastly, a Gaussian filter mixer (GFM) dynamically manages noise initialization during inference, mitigating train-test discrepancy while preserving generation flexibility. Additionally, we introduce a new metric, CLIP-RS (CLIP Relative Smoothness), to evaluate temporal coherence and smoothness, complementing traditional quality-based metrics. Experimental results on horse and tiger scenarios demonstrate MAVIN's superior performance in generating smooth and coherent video transitions compared to existing methods.", "title_embedding_index": 13512, "title_abs_embedding_index": 13537}, {"title": "Differentiation of Multi-objective Data-driven Decision Pipeline", "link_suffix": "/forum?id=nTZOIlf8YH", "link": "https://openreview.net/forum?id=nTZOIlf8YH", "pdf_link": "https://openreview.net/pdf?id=nTZOIlf8YH", "keywords": "decision-focused learning, multi-objective optimization, smart prediction-and-optimization, data-driven optimization", "abstract": "Real-world scenarios frequently involve multi-objective data-driven optimization problems, characterized by unknown problem coefficients and multiple conflicting objectives. Traditional two-stage methods independently apply a machine learning model to estimate problem coefficients, followed by invoking a solver to tackle the predicted optimization problem. The independent use of optimization solvers and prediction models may lead to suboptimal performance due to mismatches between their objectives. Recent efforts have focused on end-to-end training of predictive models that use decision loss derived from the downstream optimization problem. However, these methods have primarily focused on single-objective optimization problems, thus limiting their applicability. We aim to propose a multiobjective decision-focused approach to address this gap. In order to better align with the inherent properties of multi-objective optimization problems, we propose a set of novel loss functions. These loss functions are designed to capture the discrepancies between predicted and true decision problems, considering solution space, objective space, and decision quality, named landscape loss, Pareto set loss, and decision loss, respectively. Our experimental results demonstrate that our proposed method significantly outperforms traditional two-stage methods and most current decision-focused methods.", "title_embedding_index": 13513, "title_abs_embedding_index": 13538}, {"title": "TopoGaussian: Inferring Internal Topology Structures from Visual Clues", "link_suffix": "/forum?id=B5PbOsJqt3", "link": "https://openreview.net/forum?id=B5PbOsJqt3", "pdf_link": "https://openreview.net/pdf?id=B5PbOsJqt3", "keywords": "Gaussian Splatting, Differential Simulation, Topology Optimization, Neural Implicit Surface", "abstract": "We present TopoGaussian, a particle-based holistic pipeline for inferring the interior structure of an opaque object with easily accessible photos and videos as input. Traditional mesh-based approaches require tedious mesh filling and fixing process with high error rate, while output rough boundary surface. Our pipeline combines Gaussian splatting with a novel particle-based differentiable simulator for objects, without interference with mesh. Based on the gradients from this simulator, we provides flexible choice of topology representation for optimization, including particle, neural implicit surface, and quadratic surface. The resultant pipeline supports modeling, simulation, and optimization of the interior geometry in a heterogeneous object on a unified point-cloud representation. We present a synthetic dataset, and showcase the results of our pipeline on it. Moreover, we perform experiments on four real-world tasks, and further 3D print the output to validate the efficacy of our methods. Compared with existing mesh-based method, our pipeline is 5.26 times faster, with 2.33 times quality of reconstructed boundary in average. These results highlight the potential of our pipeline in 3D-vision, soft-robotics, and manufacturing applications.", "title_embedding_index": 13514, "title_abs_embedding_index": 13539}, {"title": "Tree of Attributes Prompt Learning for Vision-Language Models", "link_suffix": "/forum?id=wFs2E5wCw6", "link": "https://openreview.net/forum?id=wFs2E5wCw6", "pdf_link": "https://openreview.net/pdf?id=wFs2E5wCw6", "keywords": "Prompt Learning, Vision-Language Models, Tree of Attributes", "abstract": "Prompt learning has proven effective in adapting vision language models for downstream tasks. However, existing methods usually append learnable prompt tokens solely with the category names to obtain textual features, which fails to fully leverage the rich context indicated in the category name. To address this issue, we propose the Tree of Attributes Prompt learning (TAP), which first instructs LLMs to generate a tree of attributes with a ``concept - attribute - description'' structure for each category, and then learn the hierarchy with vision and text prompt tokens. Unlike existing methods that merely augment category names with a set of unstructured descriptions, our approach essentially distills structured knowledge graphs associated with class names from LLMs. Furthermore, our approach introduces text and vision prompts designed to explicitly learn the corresponding visual attributes, effectively serving as domain experts. Additionally, the general and diverse descriptions generated based on the class names may be wrong or absent in the specific given images. To address this misalignment, we further introduce a vision-conditional pooling module to extract instance-specific text features. Extensive experimental results demonstrate that our approach outperforms state-of-the-art methods on the zero-shot base-to-novel generalization, cross-dataset transfer, as well as few-shot classification across 11 diverse datasets.", "title_embedding_index": 13515, "title_abs_embedding_index": 13540}, {"title": "RAEE: A Robust Retrieval-Augmented Early Exit Framework for Efficient Inference", "link_suffix": "/forum?id=7EK2hqWmvz", "link": "https://openreview.net/forum?id=7EK2hqWmvz", "pdf_link": "https://openreview.net/pdf?id=7EK2hqWmvz", "keywords": "Early Exit; Retrieval Augmentation; Large Language Model", "abstract": "Deploying large language model inference remains challenging due to their high computational overhead.\nEarly exit optimizes model inference by adaptively reducing the number of inference layers.\nCurrent methods typically train internal classifiers to determine whether to exit at intermediate layers.\nHowever, such classifier-based early exit frameworks require significant effort to train the classifiers while can only achieve comparable performance at best.\nTo address these limitations, this paper proposes RAEE, a robust Retrieval-Augmented Early Exit framework for efficient inference.\nThis paper first demonstrates that the early exit problem can be effectively modeled as a distribution prediction problem, in which the distribution is approximated through the exit information of similar data. \nSubsequently, it outlines the methodology for collecting exit information to construct the retrieval database.\nFinally, leveraging the pre-constructed retrieval database, RAEE utilizes the exit information from retrieved similar data to guide the backbone model's exit at the layer. \nExperimental results demonstrate that RAEE significantly accelerates inference while achieving robust zero-shot performance across eight downstream tasks.", "title_embedding_index": 13516, "title_abs_embedding_index": 13541}, {"title": "DiffusionGuard: A Robust Defense Against Malicious Diffusion-based Image Editing", "link_suffix": "/forum?id=9OfKxKoYNw", "link": "https://openreview.net/forum?id=9OfKxKoYNw", "pdf_link": "https://openreview.net/pdf?id=9OfKxKoYNw", "keywords": "image inpainting, adversarial attack, image editing, ai safety, diffusion model", "abstract": "Recent advances in diffusion models have introduced a new era of text-guided image manipulation, enabling users to create realistic edited images with simple textual prompts. However, there is significant concern about the potential misuse of these methods, especially in creating misleading or harmful content. Although recent defense strategies, which introduce imperceptible adversarial noise to induce model failure, have shown promise, they remain ineffective against more sophisticated manipulations, such as editing with a mask. In this work, we propose DiffusionGuard, a robust and effective defense method against unauthorized edits by diffusion-based image editing models, even in challenging setups. Through a detailed analysis of these models, we introduce a novel objective that generates adversarial noise targeting the early stage of the diffusion process. This approach significantly improves the efficiency and effectiveness of adversarial noises. We also introduce a mask-augmentation technique to enhance robustness against various masks during test time. Finally, we introduce a comprehensive benchmark designed to evaluate the effectiveness and robustness of methods in protecting against privacy threats in realistic scenarios. Through extensive experiments, we show that our method achieves stronger protection and improved mask robustness with lower computational costs compared to the strongest baseline. Additionally, our method exhibits superior transferability and better resilience to noise removal techniques compared to all baseline methods.", "title_embedding_index": 13517, "title_abs_embedding_index": 13542}, {"title": "Training and Evaluating Causal Forecasting Models for Time-Series", "link_suffix": "/forum?id=oYaP4XPWet", "link": "https://openreview.net/forum?id=oYaP4XPWet", "pdf_link": "https://openreview.net/pdf?id=oYaP4XPWet", "keywords": "Time-series forecasting; Causal Inference; Regression Discontinuity Designs; Deep Learning", "abstract": "Deep learning time-series models are often used to make forecasts that inform downstream decisions.\nSince these decisions can differ from those in the training set, there is an implicit requirement that time-series models will generalize outside of their training distribution.\nDespite this core requirement, time-series models are typically trained and evaluated on in-distribution predictive tasks.\nWe extend the orthogonal statistical learning framework to train causal time-series models that generalize better when forecasting the effect of actions outside of their training distribution.\nTo evaluate these models, we leverage Regression Discontinuity Designs popular in economics to construct a test set of causal treatment effects.", "title_embedding_index": 13518, "title_abs_embedding_index": 13543}, {"title": "Learning Spatiotemporal Dynamical Systems from Point Process Observations", "link_suffix": "/forum?id=37EXtKCOkn", "link": "https://openreview.net/forum?id=37EXtKCOkn", "pdf_link": "https://openreview.net/pdf?id=37EXtKCOkn", "keywords": "dynamics, spatiotemporal, neural, PDE, ODE", "abstract": "Spatiotemporal dynamics models are fundamental for various domains, from heat propagation in materials to oceanic and atmospheric flows. However, currently available neural network-based spatiotemporal modeling approaches fall short when faced with data that is collected randomly over time and space, as is often the case with sensor networks in real-world applications like crowdsourced earthquake detection or pollution monitoring. In response, we developed a new method that can effectively learn spatiotemporal dynamics from such point process observations. Our model integrates techniques from neural differential equations, neural point processes, implicit neural representations and amortized variational inference to model both the dynamics of the system and the probabilistic locations and timings of observations. It outperforms existing methods on challenging spatiotemporal datasets by offering substantial improvements in predictive accuracy and computational efficiency, making it a useful tool for modeling and understanding complex dynamical systems observed under realistic, unconstrained conditions.", "title_embedding_index": 13519, "title_abs_embedding_index": 13544}, {"title": "PBCAT: Patch-Based Composite Adversarial Training against Physically Realizable Attacks on Object Detection", "link_suffix": "/forum?id=3lZd6eoPJz", "link": "https://openreview.net/forum?id=3lZd6eoPJz", "pdf_link": "https://openreview.net/pdf?id=3lZd6eoPJz", "keywords": "adversarial robustness, object detection", "abstract": "Object detection plays a crucial role in many security-sensitive applications, such as autonomous driving and video surveillance. However, several recent studies have shown that object detectors can be easily fooled by physically realizable attacks, \\eg, adversarial patches and recent adversarial textures, which pose realistic and urgent threats. Adversarial Training (AT) has been recognized as the most effective defense against adversarial attacks. \nWhile AT has been extensively studied in the $l_\\infty$-bounded attack settings on classification models, \nAT against physically realizable attacks on object detectors has received limited exploration. \nEarly attempts are only performed to defend against adversarial patches, leaving AT against a wider range of physically realizable attacks under-explored.\nIn this work, we consider defending against various physically realizable attacks with a unified AT method. \nWe propose PBCAT, a novel Patch-Based Composite Adversarial Training strategy. PBCAT optimizes the model by incorporating the combination of small-area gradient-guided adversarial patches and imperceptible global adversarial perturbations covering the entire image. With these designs, PBCAT has the potential to defend against not only adversarial patches but also unseen physically realizable attacks such as adversarial textures.\nExtensive experiments in multiple settings demonstrated that PBCAT significantly improved robustness against various physically realizable attacks over state-of-the-art defense methods. Notably, it improved the detection accuracy by 29.7% over previous defense methods under one recent adversarial texture attack.", "title_embedding_index": 13520, "title_abs_embedding_index": 13545}, {"title": "Two Are Better than One: Context Window Extension with Multi-Grained Self-Injection", "link_suffix": "/forum?id=DfTWrTwLzD", "link": "https://openreview.net/forum?id=DfTWrTwLzD", "pdf_link": "https://openreview.net/pdf?id=DfTWrTwLzD", "keywords": "long-context modeling, large language models", "abstract": "Limited longtext window has been an inherent constraint for large language models (LLMs), which significantly restricts their application scenarios.  Continual pre-training on long-context data is the most straightforward approach to further extend an LLM's context window, but it is at the expense of huge data acquisition and computation cost. \nThere are many cost-efficient context window extension methods which do not require pretraining process emerges as appealing solutions, such as extrapolation, attention manipulation, context compression, etc.\nIn this paper, we propose a novel approach named Shared-LLaMA. \nShared-LLaMA is composed of two short-context LLMs. \nOne of them works as compressor and the other works as decoder. \nThe decoder receives compressed multi-grained context information from \nthe compressor and performs context-aware modeling on the running text. \nInformation transfer between the compressor and decoder occurs only at the lowest layers to circumvent an entire forward pass and save the inference time. \nBoth LLMs are initialized from the same off-the-shelf checkpoint and thus can be directly trained without extra feature alignment stages.\nAdditionally, we propose a tree structure to store the multi-grained information and design a search algorithm to fast locate and retrieve related information from each level of that tree. \nWith these efficient design choices, Shared-LLaMA can greatly reduce memory consumption, and achieves apparent speed up over other advanced baselines (2$\\times$ over streaming, $3\\times$ over encoder-decoder architectures).\nIn our evaluation on long-context modeling and understanding tasks, Shared-LLaMA yields superior or comparable results to several strong baselines, indicating Shared-LLaMA achieves a good balance between efficiency and effectiveness.", "title_embedding_index": 13521, "title_abs_embedding_index": 13546}, {"title": "On the Performance Analysis of Momentum Method: A Frequency Domain Perspective", "link_suffix": "/forum?id=tznvtmSEiN", "link": "https://openreview.net/forum?id=tznvtmSEiN", "pdf_link": "https://openreview.net/pdf?id=tznvtmSEiN", "keywords": "Momentum Method, Stochastic Gradient Descent, Z-Transform, Frequency Domain Analysis, Deep Learning", "abstract": "Momentum-based optimizers are widely adopted for training neural networks. However, the optimal selection of momentum coefficients remains elusive. This uncertainty impedes a clear understanding of the role of momentum in stochastic gradient methods. In this paper, we present a frequency domain analysis framework that interprets the momentum method as a time-variant filter for gradients, where adjustments to momentum coefficients modify the filter characteristics. Our experiments support this perspective and provide a deeper understanding of the mechanism involved. Moreover, our analysis reveals the following significant findings: high-frequency gradient components are undesired in the late stages of training; preserving the original gradient in the early stages, and gradually amplifying low-frequency gradient components during training both enhance generalization performance. Based on these insights, we propose Frequency Stochastic Gradient Descent with Momentum (FSGDM), a heuristic optimizer that dynamically adjusts the momentum filtering characteristic with an empirically effective dynamic magnitude response. Experimental results demonstrate the superiority of FSGDM over conventional momentum optimizers.", "title_embedding_index": 13522, "title_abs_embedding_index": 13547}, {"title": "An Investigation of Conformal Isometry Hypothesis for Grid Cells", "link_suffix": "/forum?id=Xo0Q1N7CGk", "link": "https://openreview.net/forum?id=Xo0Q1N7CGk", "pdf_link": "https://openreview.net/pdf?id=Xo0Q1N7CGk", "keywords": "representation learning, recurrent neural network, position embedding, grid cell", "abstract": "This paper investigates the conformal isometry hypothesis as a potential explanation for hexagonal periodic patterns in grid cell response maps. The hypothesis posits that grid cell activity forms a high-dimensional vector in neural space, encoding the agent\u2019s position in 2D physical space. As the agent moves, this vector rotates within a 2D manifold in the neural space, driven by a recurrent neural network. The conformal hypothesis suggests that this neural manifold is a conformally isometric embedding of physical space, where local displacements in neural space are proportional to those in physical space. In this paper, we conduct numerical experiments to show that this hypothesis leads to the hexagon periodic patterns of grid cells, agnostic to the choice of transformation models. Furthermore, we present a theoretical understanding that hexagon patterns emerge by minimizing our loss function because hexagon flat torus exhibits minimal deviation from local conformal isometry. In addition, we propose a conformal modulation of the agent's input velocity, enabling the recurrent neural network of grid cells to satisfy the conformal isometry hypothesis automatically.", "title_embedding_index": 13523, "title_abs_embedding_index": 13548}, {"title": "Diffusion-PINN Sampler", "link_suffix": "/forum?id=vxBvr5ZpIu", "link": "https://openreview.net/forum?id=vxBvr5ZpIu", "pdf_link": "https://openreview.net/pdf?id=vxBvr5ZpIu", "keywords": "posterior sampling, multi-modal sampling, mixing proportion identification, diffusion model, physics-informed neural network", "abstract": "Recent success of diffusion models has inspired a surge of interest in developing sampling techniques using reverse diffusion processes. However, accurately estimating the drift term in the reverse stochastic differential equation (SDE) solely from the unnormalized target density poses significant challenges, hindering existing methods from achieving state-of-the-art performance. In this paper, we introduce the Diffusion-PINN Sampler (DPS), a novel diffusion-based sampling algorithm that estimates the drift term by solving the governing partial differential equation of the log-density of the underlying SDE marginals via physics-informed neural networks (PINN). We prove that the error of log-density approximation can be controlled by the PINN residual loss, enabling us to establish convergence guarantees of DPS. Experiments on a variety of sampling tasks demonstrate the effectiveness of our approach, particularly in accurately identifying mixing proportions when the target contains isolated components.", "title_embedding_index": 13524, "title_abs_embedding_index": 13549}]
[
    {
        "title": "Semi-Parametric Retrieval via Binary Bag-of-Tokens Index",
        "link_suffix": "/forum?id=l0fn10vSyM",
        "link": "https://openreview.net/forum?id=l0fn10vSyM",
        "pdf_link": "https://openreview.net/pdf?id=l0fn10vSyM",
        "keywords": "information retrieval, efficient retrieval, retrieval-agumented applications, RAG",
        "abstract": "Information retrieval has transitioned from standalone systems into essential components across broader applications, with indexing efficiency, cost-effectiveness, and freshness becoming increasingly critical yet often overlooked. In this paper, we introduce SemI-parametric Disentangled Retrieval (SiDR), a bi-encoder retrieval framework that decouples retrieval index from neural parameters to enable efficient, low-cost, and parameter-agnostic indexing for emerging use cases. Specifically, in addition to using embeddings as indexes like existing neural retrieval methods, SiDR supports a non-parametric tokenization index for search, achieving BM25-like indexing complexity with significantly better effectiveness. Our comprehensive evaluation across 16 retrieval benchmarks demonstrates that SiDR outperforms both neural and term-based retrieval baselines under the same indexing workload: (i) When using an embedding-based index, SiDR exceeds the performance of conventional neural retrievers while maintaining similar training complexity; (ii) When using a tokenization-based index, SiDR drastically reduces indexing cost and time, matching the complexity of traditional term-based retrieval, while consistently outperforming BM25 on all in-domain datasets; (iii) Additionally, we introduce a late parametric mechanism that matches BM25 index preparation time while outperforming other neural retrieval baselines in effectiveness."
    },
    {
        "title": "RTop-K: Ultra-Fast Row-Wise Top-K Selection for Neural Network Acceleration on GPUs",
        "link_suffix": "/forum?id=PHg4rAXFVH",
        "link": "https://openreview.net/forum?id=PHg4rAXFVH",
        "pdf_link": "https://openreview.net/pdf?id=PHg4rAXFVH",
        "keywords": "row-wise topk selection, GPU, CUDA",
        "abstract": "Top-k selection algorithms are fundamental in a wide range of applications, from high-performance computing and information retrieval to big data processing and neural network model training. In this paper, we present RTop-K, a highly efficient parallel row-wise top-k selection algorithm specifically designed for GPUs. RTop-K leverages a binary search-based approach to optimize row-wise top-k selection, providing a scalable and accelerated solution. We conduct a detailed analysis of early stopping in our algorithm, showing that it effectively maintains the testing accuracy of neural network models while substantially improving performance. Our GPU implementation of RTop-K demonstrates superior performance over state-of-the-art row-wise top-k GPU implementations, achieving speed-ups ranging from 4.25× to 9.51× with early stopping, and 3.94× without early stopping. Moreover, RTop-K is capable of accelerating the overall training workflow of MaxK-GNNs, delivering an average speed-up of 9.76% to 31.53% across different models and datasets."
    },
    {
        "title": "Conformal Training with Reduced Variance",
        "link_suffix": "/forum?id=LxkgScfHKf",
        "link": "https://openreview.net/forum?id=LxkgScfHKf",
        "pdf_link": "https://openreview.net/pdf?id=LxkgScfHKf",
        "keywords": "Conformal Training, Conformal Prediction, Optimization, Quantile, Deep Learning, Uncertainty Quantification",
        "abstract": "Conformal prediction (CP) is a distribution-free framework for achieving probabilistic guarantees on black-box models. {CP} is generally applied to a model post-training. Conformal training is an approach that aims to optimize the CP efficiency during training. In this direction, ConfTr (Stutz et al, 2022) is a technique that seeks to minimize the expected prediction set size of a model by simulating {CP} in-between training updates. Despite its potential, we identify a strong source of sample inefficiency in ConfTr that leads to overly noisy estimated gradients, introducing training instability and limiting practical use. To address this challenge, we propose variance-reduced conformal training (VR-ConfTr), a method that incorporates a variance reduction technique in the gradient estimation of the ConfTr objective function. Through extensive experiments on various benchmark datasets, we demonstrate that VR-ConfTr consistently achieves faster convergence and smaller prediction sets compared to baselines."
    },
    {
        "title": "DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory",
        "link_suffix": "/forum?id=hoYFLRNbhc",
        "link": "https://openreview.net/forum?id=hoYFLRNbhc",
        "pdf_link": "https://openreview.net/pdf?id=hoYFLRNbhc",
        "keywords": "Document-Level Translation, Large Language Models, Autonomous Agents, Natural Language Processing",
        "abstract": "Large language models (LLMs) have achieved reasonable quality improvements in machine translation (MT). However, most current research on MT-LLMs still faces significant challenges in maintaining translation consistency and accuracy when processing entire documents. In this paper, we introduce DelTA, a Document-levEL Translation Agent designed to overcome these limitations. DelTA features a multi-level memory structure that stores information across various granularities and spans, including Proper Noun Records, Bilingual Summary, Long-Term Memory, and Short-Term Memory, which are continuously retrieved and updated by auxiliary LLM-based components. Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets, achieving an increase in consistency scores by up to 4.58 percentage points and in COMET scores by up to 3.16 points on average. DelTA employs a sentence-by-sentence translation strategy, ensuring no sentence omissions and offering a memory-efficient solution compared to the mainstream method. Furthermore, DelTA improves pronoun translation accuracy, and the summary component of the agent also shows promise as a tool for query-based summarization tasks."
    },
    {
        "title": "Training Mice to Compete with Elephants: A Guide for Customizing Small-Sized LLMs on Knowledge and Skills Data",
        "link_suffix": "/forum?id=eENHKMTOfW",
        "link": "https://openreview.net/forum?id=eENHKMTOfW",
        "pdf_link": "https://openreview.net/pdf?id=eENHKMTOfW",
        "keywords": "Machine Learning, Generative Models, Large Language Models, Natural Language Processing, Transformers, Fine-Tuning, Instruction Tuning, Synthetic Data Generation, Knowledge Data, Skills Data, Model Generalization, Batch Size, Hyperparameter Optimization, Gradient Norm, MMLU, MTBench, Stacked Training, Phased Training, Compute Efficiency, Sample Efficiency, Flash Attention, Multipack Bucketing",
        "abstract": "Customizing large language models (LLMs) is increasingly in demand by enterprises and individual developers. It allows LLMs to be tailored for domain expertise, aligned with organizational guidelines, and enhanced for user experience. Effective customization hinges on three core elements: a small-size model, large-scale domain-specific datasets, and an effective training strategy to help the model acquire relevant knowledge and skills from the data. In this paper, we focus on the third element by conducting an in-depth study on fine-tuning LLMs (3B to 7B parameters) using large-scale instruction tuning datasets across multiple knowledge domains and skills. We examine various training configurations and strategies on three pretrained LLMs. Our results question several common training practices, including hyperparameter recommendations from TULU and phased training recommended by Orca.\nKey insights from our work include: (i) larger batch sizes paired with lower learning rates lead to improved model performance on benchmarks such as MMLU and MTBench; (ii) early-stage training dynamics, such as lower gradient norms and higher loss values, are strong indicators of better final model performance, allowing for early termination of sub-optimal runs and significant computational savings; (iii) skipping warmup and using a constant learning rate do not compromise performance; and (iv) stacked training outperforms phased training. With these findings holding robustly across model families and sizes, we hope this study serves as a comprehensive guide for practitioners fine-tuning small LLMs."
    },
    {
        "title": "Improving Adaptive Moment Optimization via Preconditioner Diagonalization",
        "link_suffix": "/forum?id=NdNuKMEv9y",
        "link": "https://openreview.net/forum?id=NdNuKMEv9y",
        "pdf_link": "https://openreview.net/pdf?id=NdNuKMEv9y",
        "keywords": "optimization, deep learning",
        "abstract": "Modern adaptive optimization methods, such as Adam and its variants, have emerged as the most widely used tools in deep learning over recent years. These algorithms offer automatic mechanisms for dynamically adjusting the update step based on estimates of gradient statistics. Compared to traditional algorithms like Stochastic Gradient Descent, these adaptive methods are typically more robust to model scale and hyperparameter tuning. However, the gradient statistics employed by these methods often do not leverage sufficient gradient covariance information, leading to suboptimal updates in certain directions of the parameter space and potentially slower convergence. In this work, we keep track of such covariance statistics in the form of a structured preconditioner matrix. Unlike other works, our approach does not apply direct approximations to estimate this matrix. We instead implement an invertible transformation that maps the preconditioner matrix into a new space where it becomes approximately diagonal. This enables a diagonal approximation of the preconditioner matrix in the transformed space, offering several computational advantages. Empirical results show that our approach can substantially enhance the convergence speed of the modern adaptive optimizers. Notably, for large language models like LLaMA, we can achieve a speedup of 2x compared to the baseline Adam. Additionally, our method can be integrated with memory-efficient optimizers like Adafactor to manage computational overhead."
    },
    {
        "title": "Conformal Reasoning: Uncertainty Estimation in Interactive Environments",
        "link_suffix": "/forum?id=Vf5ZUalFk8",
        "link": "https://openreview.net/forum?id=Vf5ZUalFk8",
        "pdf_link": "https://openreview.net/pdf?id=Vf5ZUalFk8",
        "keywords": "Conformal Prediction, Uncertainty Quantification, LM Abstention, Interactive Reasoning",
        "abstract": "We introduce conformal reasoning, a principled method for models in interactive environments to reason about their uncertainty and decide whether to seek out more information or to return a prediction. The challenge with standard conformal prediction---a popular statistical framework for uncertainty estimation that constructs prediction sets with formal coverage guarantees---is that it relies on a fixed set of calibration data points. In interactive environments, however, the calibration trajectories require certain termination criteria determined a priori, introducing heuristic bias and/or circular dependency that break the assumptions needed for coverage guarantees. We address this issue by building on adaptive conformal inference techniques. On two real-world tasks on medical diagnosis and embodied question answering, we show that conformal reasoning empirically achieves its theoretical coverage guarantees---in contrast with standard conformal prediction approaches that can significantly over- or under-cover---while improving exploration efficiency by approximately 20% on both tasks."
    },
    {
        "title": "Mitigate Position Bias in Large Language Models via Scaling a Single Dimension",
        "link_suffix": "/forum?id=t717joHHSc",
        "link": "https://openreview.net/forum?id=t717joHHSc",
        "pdf_link": "https://openreview.net/pdf?id=t717joHHSc",
        "keywords": "Large Language Model, Position Bias, Long-Context",
        "abstract": "Large Language Models (LLMs) are increasingly applied in various real-world scenarios due to their excellent generalization capabilities and robust generative abilities. However, they exhibit position bias, also known as \"lost in the middle\", a phenomenon that is especially pronounced in long-context scenarios, which indicates the placement of the key information in different positions of a prompt can significantly affect accuracy. This paper first explores the micro-level manifestations of position bias, concluding that attention weights are a micro-level expression of position bias. It further identifies that, in addition to position embeddings, causal attention mask also contributes to position bias by creating position-specific hidden states. Based on these insights, we propose a method to mitigate position bias by scaling this positional hidden states. Experiments on the NaturalQuestions Multi-document QA, KV retrieval, LongBench and timeline reorder tasks, using various models including RoPE models, context window-extended models, and Alibi models, demonstrate the effectiveness and generalizability of our approach. Our method can improve performance by up to 15.2% by modifying just one dimension of hidden states."
    },
    {
        "title": "Simulate Before Act: Model-Based Planning for Web Agents",
        "link_suffix": "/forum?id=JDa5RiTIC7",
        "link": "https://openreview.net/forum?id=JDa5RiTIC7",
        "pdf_link": "https://openreview.net/pdf?id=JDa5RiTIC7",
        "keywords": "Web Agents; World Model; Planning; MPC",
        "abstract": "Language agents have shown promising performance in automating web-based tasks, but the complexity and vast search spaces of real-world websites challenge reactive agents in identifying optimal solutions. While tree search agents offer enhanced exploration by interacting with actual websites, they often incur high costs, potential risks, and are challenging to implement for real-world websites. This paper explores a novel paradigm leveraging large language models' (LLMs) internal world models for planning in complex environments, presenting a middle ground between reactive agents and tree search agents. Results on two representative benchmarks, VisualWebArena and Mind2Web-live, demonstrate that our approach largely closes the gap between reactive agents and tree search agents, while maintaining efficiency and safety advantages. Notably, tree search can be considered as approaching an upper bound for our method, as it explores actual websites rather than simulations. This work opens new avenues for research into more effective and secure strategies for autonomous agents in complex, dynamic environments. It represents a step forward in improving upon reactive agents while approaching the performance of tree search methods, without incurring their implementation challenges and costs."
    },
    {
        "title": "Vision-guided and Mask-enhanced Adaptive Denoising for Prompt-based Image Editing",
        "link_suffix": "/forum?id=aY3W95jLEI",
        "link": "https://openreview.net/forum?id=aY3W95jLEI",
        "pdf_link": "https://openreview.net/pdf?id=aY3W95jLEI",
        "keywords": "image editing, diffusion models",
        "abstract": "Text-to-image diffusion models have demonstrated remarkable progress in synthesizing high-quality images from text prompts, which boosts researches on prompt-based image editing that edits a source image  according to a target prompt. Despite their advances, existing methods still encounter three key issues: 1) limited capacity of the text prompt in guiding target image generation, 2) insufficient mining of word-to-patch and patch-to-patch relationships for grounding editing areas, and 3) unified editing strength for all regions during each denoising step. To address these issues, we present a Vision-guided and Mask-enhanced Adaptive Editing (ViMAEdit) method with three key novel designs. First, we propose to leverage image embeddings as explicit guidance to enhance the conventional textual prompt-based denoising process, where a CLIP-based target image embedding estimation strategy is introduced. Second, we devise a self-attention-guided iterative editing area grounding strategy, which iteratively exploits patch-to-patch relationships conveyed by self-attention maps to refine those word-to-patch relationships contained in cross-attention maps. Last, we present a spatially adaptive variance-guided sampling, which highlights sampling variances for critical image regions to promote the editing capability.  Experimental results demonstrate the superior editing capacity of ViMAEdit over all existing methods."
    },
    {
        "title": "PRF: Parallel Resonate and Fire Neuron for Long Sequence Learning in Spiking Neural Networks",
        "link_suffix": "/forum?id=OujTnpmAZG",
        "link": "https://openreview.net/forum?id=OujTnpmAZG",
        "pdf_link": "https://openreview.net/pdf?id=OujTnpmAZG",
        "keywords": "Spiking Neural Networks, Neuromorphic Computing, Neuron",
        "abstract": "Recently, there is growing demand for effective and efficient long sequence modeling, with State Space Models (SSMs) proving to be effective for long sequence tasks. To further reduce energy consumption, SSMs can be adapted to Spiking Neural Networks (SNNs) using spiking functions. However, current spiking-formalized SSMs approaches still rely on float-point matrix-vector multiplication during inference, undermining SNNs’ energy advantage. In this work, we address the efficiency and performance challenges of long sequence learning in SNNs simultaneously. First, we propose a decoupled reset method for parallel spiking neuron training, reducing the typical Leaky Integrate-and-Fire (LIF) model’s training time from $O(L^2)$ to $O(L\\log L)$, effectively speeding up the training by $6.57 \\times$ to $16.50 \\times$ on sequence lengths $1,024$ to $32,768$. To our best knowledge, this is the first time that parallel computation with a reset mechanism is implemented achieving equivalence to its sequential counterpart. Secondly, to capture long-range dependencies, we propose a Parallel Resonate and Fire (PRF) neuron, which leverages an oscillating membrane potential driven by a resonate mechanism from a differentiable reset function in the complex domain. The PRF enables efficient long sequence learning while maintaining parallel training. Finally, we demonstrate that the proposed spike-driven architecture using PRF achieves performance comparable to Structured SSMs (S4), with two orders of magnitude reduction in energy consumption, outperforming transformers on Long Range Arena tasks."
    },
    {
        "title": "The Phase Transition Phenomenon of Shuffled Regression",
        "link_suffix": "/forum?id=gVVoZtiQlt",
        "link": "https://openreview.net/forum?id=gVVoZtiQlt",
        "pdf_link": "https://openreview.net/pdf?id=gVVoZtiQlt",
        "keywords": "Message Passing, Permuted Linear Regression, Phase Transition",
        "abstract": "We study the phase transition \nphenomenon inherent in the shuffled (permuted) regression problem, which has found numerous applications in databases, privacy, data analysis, etc. For the permuted regression task: $\\mathbf{Y} = \\mathbf{\\Pi}\\mathbf{X}\\mathbf{B}$, the goal is to recover the permutation matrix $\\mathbf{\\Pi}$ as well as the coefficient matrix $\\mathbf{B}$. It has been empirically observed in prior studies that when recovering $\\mathbf{\\Pi}$, there exists a phase transition phenomenon: the error rate drops to zero rapidly once the parameters reach certain thresholds. In this study, we aim to precisely identify the locations of the phase transition points by leveraging techniques from {\\em message passing} (MP).In our analysis, we first transform the permutation recovery problem into a probabilistic graphical model. Then, we leverage the analytical tools rooted in the message passing (MP) algorithm and derive an equation to track the convergence of the MP algorithm. By linking this equation to the branching random walk process, we are able to characterize the impact of the \\emph{signal-to-noise-ratio} ($\\mathsf{snr}$) on the permutation recovery.  Depending on whether the signal is given or not, we separately investigate the oracle case and the non-oracle case. The bottleneck in identifying the phase transition regimes lies in deriving closed-form formulas for the corresponding critical points, but only in rare scenarios can one obtain such precise expressions. To tackle this challenge, we propose the Gaussian approximation method, which allows us to obtain the closed-form formulas in almost all scenarios. In the oracle case, our method can fairly accurately predict the phase transition $\\mathsf{snr}$. In the non-oracle case, our proposed algorithm can predict the maximum allowed number of permuted rows and uncover its dependency on the sample number."
    },
    {
        "title": "Accelerated Preference Optimization for Large Language Model Alignment",
        "link_suffix": "/forum?id=TROUDY6Wg4",
        "link": "https://openreview.net/forum?id=TROUDY6Wg4",
        "pdf_link": "https://openreview.net/pdf?id=TROUDY6Wg4",
        "keywords": "large language models, RLHF, DPO",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a pivotal tool for aligning large language models (LLMs) with human preferences. Direct Preference Optimization (DPO), one of the most popular approaches, formulates RLHF as a policy optimization problem without explicitly estimating the reward function. It overcomes the stability and efficiency issues of two-step approaches, which typically involve first estimating the reward function and then optimizing the policy via proximal policy optimization (PPO). Since RLHF is essentially an optimization problem, and it is well-known that momentum techniques can accelerate optimization both theoretically and empirically, a natural question arises: Can RLHF be accelerated by momentum? This paper answers this question in the affirmative. In detail, we first show that the iterative preference optimization method can be viewed as a proximal point method. Based on this observation, we propose a general Accelerated Preference Optimization (APO) framework, which unifies many existing preference optimization algorithms and employs Nesterov's momentum technique to speed up the alignment of LLMs. Theoretically, we demonstrate that APO can achieve a faster convergence rate than the standard iterative preference optimization methods, including DPO and SPPO. Empirically, we show the superiority of APO over DPO, iterative DPO, and other strong baselines for RLHF on the AlpacaEval 2.0 benchmark."
    },
    {
        "title": "Online Detection for Black-Box Large Language Models with Adaptive Prompt Selection",
        "link_suffix": "/forum?id=fwHVclv0ij",
        "link": "https://openreview.net/forum?id=fwHVclv0ij",
        "pdf_link": "https://openreview.net/pdf?id=fwHVclv0ij",
        "keywords": "online change detection, LLM security, active prompt selection",
        "abstract": "The widespread success of large language models (LLMs) has made them integral to various applications, yet security and reliability concerns are growing. It now becomes critical to safeguard LLMs from unintended changes caused by tampering, malicious prompt injection, or unauthorized parameter updates, etc. Early detection of these changes is essential to maintain the performance, fairness, and trustworthiness of LLM-powered applications. However, in black-box settings, where access to model parameters and output probabilities is unavailable, few detection methods exist. In this paper, we propose a novel online change-point detection method for quickly detecting changes in black-box LLMs. Our method features several key innovations: 1) we derive a CUSUM-type detection statistic based on the entropy and the Gini coefficient of the response distribution, and 2) we utilize a UCB-based adaptive prompt selection strategy for identifying change-sensitive prompts to enhance detection. We evaluate the effectiveness of the proposed method using synthetic data, where changes are simulated through watermarking and model version updates. Our proposed method is able to detect changes quickly while well controlling the false alarm rate. Moreover, for real-world data, our method also accurately detects announced changes in LLM APIs via daily online interactions with APIs. We also demonstrate strong evidence of unreported changes in APIs, which may be of independent interest."
    },
    {
        "title": "Repurposing Foundation Model for Generalizable Medical Time Series Classification",
        "link_suffix": "/forum?id=A9loYh0RgU",
        "link": "https://openreview.net/forum?id=A9loYh0RgU",
        "pdf_link": "https://openreview.net/pdf?id=A9loYh0RgU",
        "keywords": "Medical Time Series, Time Series Classification, Foundation Model",
        "abstract": "Medical time series (MedTS) classification is critical for a wide range of healthcare applications such as Alzheimer's Disease diagnosis. However, its real-world deployment is severely challenged by poor generalizability due to inter- and intra-dataset heterogeneity in MedTS, including variations in channel configurations, time series lengths, and diagnostic tasks.\nHere, we propose FORMED, a foundation classification model that leverages a pre-trained backbone\nand tackles these challenges through re-purposing. FORMED integrates the general representation learning enabled by the backbone foundation model and the medical domain knowledge gained on a curated cohort of MedTS datasets. FORMED can adapt seamlessly to unseen MedTS datasets, regardless of the number of channels, sample lengths, or medical tasks.\nExperimental results show that, without any task-specific adaptation, the repurposed FORMED achieves performance that is competitive with, and often superior to, 11 baseline models trained specifically for each dataset. Furthermore, FORMED can effectively adapt to entirely new, unseen datasets, with lightweight parameter updates, consistently outperforming baselines. Our results highlight FORMED as a versatile and scalable model for a wide range of MedTS classification tasks, positioning it as a strong foundation model for future research in MedTS analysis."
    },
    {
        "title": "AnyECG: Foundational Models for Electrocardiogram Analysis",
        "link_suffix": "/forum?id=fO0YO9giQV",
        "link": "https://openreview.net/forum?id=fO0YO9giQV",
        "pdf_link": "https://openreview.net/pdf?id=fO0YO9giQV",
        "keywords": "ECG representation, Cardiac Diagnosis, Denoising Reconstruction, Foundation Model",
        "abstract": "Electrocardiogram (ECG), a non-invasive and affordable tool for cardiac monitoring, is highly sensitive in detecting acute heart attacks. However, due to the lengthy nature of ECG recordings, numerous machine learning methods have been developed for automated heart disease detection to reduce human workload. Despite these efforts, performance remains suboptimal. A key obstacle is the inherent complexity of ECG data, which includes heterogeneity (e.g., varying sampling rates), high levels of noise, demographic-related pattern shifts, and intricate rhythm-event associations. To overcome these challenges, this paper introduces AnyECG, a foundational model designed to extract robust representations from any real-world ECG data. Specifically, a tailored ECG Tokenizer encodes each fixed-duration ECG fragment into a token and, guided by proxy tasks, converts noisy, continuous ECG features into discrete, compact, and clinically meaningful local rhythm codes. These codes encapsulate basic morphological, frequency, and demographic information (e.g., sex), effectively mitigating signal noise. We further pre-train the AnyECG to learn rhythmic pattern associations across ECG tokens, enabling the capture of cardiac event semantics. By being jointly pre-trained on diverse ECG data sources, AnyECG is capable of generalizing across a wide range of downstream tasks where ECG signals are recorded from various devices and scenarios. Experimental results in anomaly detection, arrhythmia detection, corrupted lead generation, and ultra-long ECG signal analysis demon-\nstrate that AnyECG learns common ECG knowledge from data and significantly outperforms cutting-edge methods in each respective task."
    },
    {
        "title": "Low-Switching Primal-Dual Algorithms for Safe Reinforcement Learning",
        "link_suffix": "/forum?id=G0uhaIXmFw",
        "link": "https://openreview.net/forum?id=G0uhaIXmFw",
        "pdf_link": "https://openreview.net/pdf?id=G0uhaIXmFw",
        "keywords": "reinforcement learning, Markov decision process, constrained Markov decision process, machine learning, online learning, optimization",
        "abstract": "Safety is a key challenge in reinforcement learning (RL), especially in real-world applications like autonomous driving and healthcare. To address this, Constrained Markov Decision Processes (CMDPs) are commonly used to incorporate safety constraints while optimizing performance. However, current methods often face significant safety violations during exploration or suffer from high regret, which represents the performance loss compared to an optimal policy. We propose a low-switching primal-dual algorithm that balances regret with bounded constraint violations, drawing on techniques from online learning and CMDPs. Our approach minimizes policy changes through low-switching updates and enhances sample efficiency using empirical Bernstein-based bonuses. This leads to tighter theoretical bounds on regret and safety, achieving a state-of-the-art regret of $\\tilde{O}(\\sqrt{SAH^5K}/(\\tau - c^0))$, where $S$ and $A$ is the number of states and actions, $H$ is the horizon, $K$ is the number of episodes, and $(\\tau - c^0)$ reflects the safety margin of a known existing safe policy. Our method also ensures a $\\tilde{O}(1)$ constraint violation and removes unnecessary dependencies on state space $S$ and planning horizon $H$ in the reward regret, offering a scalable solution for constrained RL in complex environments."
    },
    {
        "title": "Conformal Prediction Sets with Improved Conditional Coverage using Trust Scores",
        "link_suffix": "/forum?id=RcNzwKrjTo",
        "link": "https://openreview.net/forum?id=RcNzwKrjTo",
        "pdf_link": "https://openreview.net/pdf?id=RcNzwKrjTo",
        "keywords": "uncertainty quantification, conformal prediction, conditional guarantees",
        "abstract": "Standard conformal prediction offers a marginal guarantee on coverage, but for prediction sets to be truly useful, they should ideally ensure coverage conditional on each test point. However, it is impossible to achieve exact, distribution-free conditional coverage in finite samples. In this work, we propose an alternative conformal prediction algorithm that targets coverage where it matters most---in instances where a classifier is overconfident in its incorrect predictions. We start by dissecting miscoverage events in marginally-valid conformal prediction, and show that miscoverage rates vary based on the classifier's confidence and its deviation from the Bayes optimal classifier. Motivated by this insight, we develop a variant of conformal prediction that targets coverage conditional on a reduced set of two variables: the classifier's confidence in a prediction and a nonparametric trust score that measures its deviation from the Bayes classifier. Empirical evaluation on multiple image datasets shows that our method generally improves conditional coverage properties compared to standard conformal prediction, including class-conditional coverage, coverage over arbitrary subgroups, and coverage over demographic groups."
    },
    {
        "title": "A Principled Evaluation Framework for Neuron Explanations",
        "link_suffix": "/forum?id=todLTYB1I7",
        "link": "https://openreview.net/forum?id=todLTYB1I7",
        "pdf_link": "https://openreview.net/pdf?id=todLTYB1I7",
        "keywords": "interpretability, mechanistic interpretability, explainable AI, trustworthy machine learning",
        "abstract": "Understanding the function of individual units in a neural network is an important building block for mechanistic interpretability. This is often done by generating a simple text explanation of the behavior of individual neurons or units. However, for these explanations to be useful, we must understand how reliable and truthful they are. In this work we unify many existing explanation evaluation methods under one mathematical framework. This allows us to compare and contrast existing evaluation metrics and understand the evaluation pipeline with increased clarity. We propose two simple sanity checks on the evaluation metrics and show that many commonly used metrics fail these tests and do not change their score after massive changes to the concept labels. Based on our experimental and theoretical results, we propose guidelines that future evaluations should follow and identify good evaluation metrics such as correlation."
    },
    {
        "title": "Minimax Based  Fast-training Defense against Adversarial Policy in Two-player Competitive Games",
        "link_suffix": "/forum?id=qPw5D0Xahv",
        "link": "https://openreview.net/forum?id=qPw5D0Xahv",
        "pdf_link": "https://openreview.net/pdf?id=qPw5D0Xahv",
        "keywords": "Deep reinforcement learning, adversarial policy, adversarial defense, Nash equilibrium",
        "abstract": "Adversarial policies have been shown to exploit vulnerabilities in agents during two-player competitive games, significantly undermining their performance. While existing approaches model the challenge of training robust policies in such environments as the search for Nash equilibrium points in the policy space, this often leads to substantial computational overhead. In this work, we propose MM-FATROL, a novel robust policy training method grounded in the Minimax Theorem, which significantly reduces computational overhead by efficiently identifying promising policy updates. We provide a formal analysis of the speedup achieved by our method. Extensive experiments demonstrate that MM-FATROL not only enhances  efficiency but also surpasses the state-of-the-art method in terms of generalization and robustness. Additionally, we discuss the limitations of our approach  and the challenges that remain in developing robust policies for more complex game environments."
    },
    {
        "title": "Classification-denoising networks",
        "link_suffix": "/forum?id=mDvL3wcmms",
        "link": "https://openreview.net/forum?id=mDvL3wcmms",
        "pdf_link": "https://openreview.net/pdf?id=mDvL3wcmms",
        "keywords": "image classification, denoising, diffusion models, energy-based models",
        "abstract": "Image classification and denoising suffer from complementary issues of lack of robustness or partially ignoring conditioning information. We argue that they can be alleviated by unifying both tasks through a model of the joint probability of (noisy) images and class labels. Classification is performed with a forward pass followed by conditioning. Using the Tweedie-Miyasawa formula, we evaluate the denoising function with the score, which can be computed by marginalization and back-propagation. The training objective is then a combination of cross-entropy loss and denoising score matching loss integrated over noise levels. Numerical experiments on CIFAR-10 and ImageNet show competitive classification and denoising performance compared to reference deep convolutional classifiers/denoisers, and significantly improves efficiency compared to previous joint approaches. Our model shows an increased robustness to adversarial perturbations compared to a standard discriminative classifier, and allows for a novel interpretation of adversarial gradients as a difference of denoisers."
    },
    {
        "title": "ManiSkill-HAB: A Benchmark for Low-Level Manipulation in Home Rearrangement Tasks",
        "link_suffix": "/forum?id=6bKEWevgSd",
        "link": "https://openreview.net/forum?id=6bKEWevgSd",
        "pdf_link": "https://openreview.net/pdf?id=6bKEWevgSd",
        "keywords": "benchmark, dataset, simulation, reinforcement learning, imitation learning, robotics",
        "abstract": "High-quality benchmarks are the foundation for embodied AI research, enabling significant advancements in long-horizon navigation, manipulation and rearrangement tasks. However, as frontier tasks in robotics get more advanced, they require faster simulation speed, more intricate test environments, and larger demonstration datasets. To this end, we present MS-HAB, a holistic benchmark for low-level manipulation and in-home object rearrangement. First, we provide a GPU-accelerated implementation of the Home Assistant Benchmark (HAB). We support realistic low-level control and achieve over 3x the speed of previous magical grasp implementations at similar GPU memory usage. Second, we train extensive reinforcement learning (RL) and imitation learning (IL) baselines for future work to compare against. Finally, we develop a rule-based trajectory filtering system to sample specific demonstrations from our RL policies which match predefined criteria for robot behavior and safety. Combining demonstration filtering with our fast environments enables efficient, controlled data generation at scale."
    },
    {
        "title": "How do students become teachers: A dynamical analysis for two-layer neural networks",
        "link_suffix": "/forum?id=25j2ZEgwTj",
        "link": "https://openreview.net/forum?id=25j2ZEgwTj",
        "pdf_link": "https://openreview.net/pdf?id=25j2ZEgwTj",
        "keywords": "learning theory, over-parameterization, learning dynamics",
        "abstract": "This paper investigates the fundamental regression task of learning $k$ neurons (a.k.a. teachers) from Gaussian input, using two-layer ReLU neural networks with width $m$ (a.k.a. students) and $m, k= \\mathcal{O}(1)$, trained via gradient descent under proper initialization and a small step-size. Our analysis follows a three-phase structure: alignment after weak recovery, tangential growth, and local convergence, providing deeper insights into the learning dynamics of gradient descent (GD). We prove the global convergence at the rate of $\\mathcal{O}(T^{-3})$ for the zero loss of excess risk. Additionally, our results show that GD automatically groups and balances student neurons, revealing an implicit bias toward achieving the minimum balanced $\\ell_2$-norm in the solution. Our work extends beyond previous studies in exact-parameterization setting ($m = k = 1$, (Yehudai and Ohad, 2020)) and single-neuron setting ($m \\geq k = 1$, (Xu and Du, 2023)). The key technical challenge lies in handling the interactions between multiple teachers and students during training, which we address by refining the alignment analysis in Phase 1 and introducing a new dynamic system analysis for tangential components in Phase 2. Our results pave the way for further research on optimizing neural network training dynamics and understanding implicit biases in more complex architectures."
    },
    {
        "title": "MV-CLAM: Multi-View Molecular Interpretation with Cross-Modal Projection via Language Model",
        "link_suffix": "/forum?id=06B23UkNid",
        "link": "https://openreview.net/forum?id=06B23UkNid",
        "pdf_link": "https://openreview.net/pdf?id=06B23UkNid",
        "keywords": "Molecule captioning, large language models, drug discovery, molecule representation learning",
        "abstract": "Large language models (LLMs) have shown significant potential in the biomolecular domain, particularly by demonstrating that effective adaptation of molecular representations for LLMs can greatly improve the quality of molecular captions. Most previous works have focused on aligning unimodal molecular structures with text, overlooking the diversity of modalities. Naive approaches to aligning multi-modal molecular structures with text often lead to (1) separately aligned embeddings, (2) inconsistent textual representations, and (3) increased computational overhead. To address these challenges, we propose LLM framework MV-CLAM equipped with MQ-Former, a novel multi-querying transformer. This architecture introduces a cross-model projector facilitating the simultaneous alignment of 2D and 3D molecular representations to a unified text token. By employing a shared self-attention layer, MQ-Former preserves rich molecular embeddings across different dimensions while consolidating them into a universal molecular token. Our approach outperforms baseline models in both molecule-text retrieval and molecule captioning tasks. Additionally, our framework shows promising results for zero-shot molecule editing and molecule-related question answering. By effectively integrating multi-view molecular data into a format conducive to LLMs, our method serves as a valuable tool for enhancing the characterization and understanding of chemical structures, facilitating a more seamless transition from molecular data to textual descriptions. The source code of MV-CLAM is available inhttps://anonymous.4open.science/r/mv-clam-4827."
    },
    {
        "title": "Studying the Effects of Training Data on Small Language Models",
        "link_suffix": "/forum?id=4xBew7kuYB",
        "link": "https://openreview.net/forum?id=4xBew7kuYB",
        "pdf_link": "https://openreview.net/pdf?id=4xBew7kuYB",
        "keywords": "small language models, pretraining",
        "abstract": "Prior work has found that training very small language models (SLMs) on synthetic children's stories allows them to generate coherent text, comparable to much larger models. These stories are claimed to encompass the vocabulary and factual knowledge base of a 3-4 year old child, capturing the \"essence of natural language.\"\nBecause of these claims, it is tempting to attribute the findings to the simple language of children's stories, drawing a parallel to how children learn language.\nIs the human concept of readability relevant in the context of language model training, or are these findings better explained by other propeties of the data?\nIn this study, we investigate this by first validating several automatic readability measures. We then create synthetic corpora with varying levels of readability and assess the coherence of text generated by SLMs trained on these corpora.\nWe find no relationship between the readability of training data and the generation abilities of SLMs. Specifically, SLMs trained on data with substantially more complex language also exihibit the same abilities as those trained on simple language. Moreover, training on simple language does not lead to earlier development of coherence during training."
    }
]
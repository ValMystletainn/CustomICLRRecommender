[{"title": "EndoAssistant: A Large-scale Vision-Language Dataset for Endoscopic Surgery Understanding from Open-Source Videos", "link_suffix": "/forum?id=voYshhbWeJ", "link": "https://openreview.net/forum?id=voYshhbWeJ", "pdf_link": "https://openreview.net/pdf?id=voYshhbWeJ", "keywords": "Medical image, endoscopy, vision-language model", "abstract": "Endoscopic interventions offer a minimally invasive approach, minimizing patient discomfort and facilitating expedited recovery. Proficient training of junior surgeons necessitates the ability to analyze and interpret endoscopic scenes through questioning and answering. Consequently, the development of a robust foundation model for endoscopic visual language understanding holds immense value for medical training and surgical education. However, existing endoscopy vision-language datasets are limited in scale and diversity, consisting of only 50 videos sourced from a few clinical sites, thus posing a significant hurdle to the advancement of generalized and robust artificial intelligence models for endoscopic surgical applications. To address this challenge, we present a large-scale, meticulously curated image-text dataset of surgical endoscopic scenes from expert surgeons, designed to propel a vision-language assistant in medical scene understanding. Encompassing 590 open-source videos spanning more than 91 hours, our curated dataset includes 65,844 unique images, 30,002 unique captions, and 157,589 image-caption/question-answering pairs. This dataset aims to assist the development of automated systems to support medical professionals by mitigating repetitive tasks. We present a comprehensive endoscopic surgery assisting pipeline, (1) a first-ever image-caption dataset specifically for endoscopic scenes; (2) an image-question-answer dataset that offers greater size and diversity compared to existing collections; (3) rigorous evaluation demonstrating its efficacy in downstream surgical endoscopic scene comprehension tasks like classification, retrieval and visual question answering.", "title_embedding_index": 10250, "title_abs_embedding_index": 10275}, {"title": "MorphoDiff: Cellular Morphology Painting with Diffusion Models", "link_suffix": "/forum?id=PstM8YfhvI", "link": "https://openreview.net/forum?id=PstM8YfhvI", "pdf_link": "https://openreview.net/pdf?id=PstM8YfhvI", "keywords": "Generative Modelling, Latent Diffusion Model, Cell Painting, Morphology, Drug Response Prediction, Cellular Phenotype, Machine Learning", "abstract": "Understanding cellular responses to external stimuli is critical for parsing biological mechanisms and advancing therapeutic development. High-content image-based assays provide a cost-effective approach to examine cellular phenotypes induced by diverse interventions, which offers valuable insights into biological processes and cellular states. In this paper, we introduce MorphoDiff, a generative pipeline to predict high-resolution cell morphological responses under different conditions based on perturbation encoding. To the best of our knowledge, MorphoDiff is the first framework capable of producing guided, high-resolution predictions of cell morphology that generalize across both chemical and genetic interventions. The model integrates perturbation embeddings as guiding signals within a 2D latent diffusion model. The comprehensive computational, biological, and visual validations across three open-source Cell Painting datasets show that MorphoDiff can generate high-fidelity images and produce meaningful biology signals under various interventions. We envision the model will facilitate efficient in silico exploration of perturbational landscapes towards more effective drug discovery studies.", "title_embedding_index": 10251, "title_abs_embedding_index": 10276}, {"title": "Understanding the Training and Generalization of Pretrained Transformer for Sequential Decision Making", "link_suffix": "/forum?id=CiiLchbRe3", "link": "https://openreview.net/forum?id=CiiLchbRe3", "pdf_link": "https://openreview.net/pdf?id=CiiLchbRe3", "keywords": "pretrained transformer, in-context learning, bandits, dynamic pricing, sequential decision making", "abstract": "In this paper, we consider the supervised pre-trained transformer for a class of sequential decision-making problems. The class of considered problems is a subset of the general formulation of reinforcement learning in that there is no transition probability matrix; though seemingly restrictive, the subset class of problems covers bandits, dynamic pricing, and newsvendor problems as special cases. Such a structure enables the use of optimal actions/decisions in the pre-training phase, and the usage also provides new insights for the training and generalization of the pre-trained transformer. We first note the training of the transformer model can be viewed as a performative prediction problem, and the existing methods and theories largely ignore or cannot resolve an out-of-distribution issue. We propose a natural solution that includes the transformer-generated action sequences in the training procedure, and it enjoys better properties both numerically and theoretically. The availability of the optimal actions in the considered tasks also allows us to analyze the properties of the pre-trained transformer as an algorithm and explains why it may lack exploration and how this can be automatically resolved. Numerically, we categorize the advantages of pre-trained transformers over the structured algorithms such as UCB and Thompson sampling into three cases: (i) it better utilizes the prior knowledge in the pre-training data; (ii) it can elegantly handle the misspecification issue suffered by the structured algorithms; (iii) for short time horizon such as $T\\le50$, it behaves more greedy and enjoys much better regret than the structured algorithms designed for asymptotic optimality.", "title_embedding_index": 10252, "title_abs_embedding_index": 10277}, {"title": "Evaluating Large Language Models' Capability to Conduct Cyberattacks On Embedded Devices", "link_suffix": "/forum?id=n2xueVy5ek", "link": "https://openreview.net/forum?id=n2xueVy5ek", "pdf_link": "https://openreview.net/pdf?id=n2xueVy5ek", "keywords": "Computer security, red teaming, IoT, large language models", "abstract": "As large language models continue to evolve, they have the potential to automate and enhance various aspects of computer security, including red teaming assessments. In this article, we conduct 32 computer security attacks and compare their success rates when performed manually and with assistance from large language models. The security assessments target five connected devices commonly found in modern households (two door locks, one vacuum cleaner, one garage door, and one smart vehicle adapter). We use attacks such as denial-of-service attacks, Man-in-the-Middle, authentication brute force, malware creation, and other common attack types. Each attack was performed twice, once by a human and once by an LLM, and scored for damage, reproducibility, exploitability, affected users, and discoverability based on the DREAD framework for computer security risk assessments. For the LLM-assisted attacks, we also scored the LLM's capacity to perform the attack autonomously. LLMs regularly increased the reproducibility and exploitability of attacks, but no LLM-based attack enhanced the damage inflicted on the device, and the language models often required manual input to complete the attack.", "title_embedding_index": 10253, "title_abs_embedding_index": 10278}, {"title": "Paint by Inpaint: Learning to Add Image Objects by Removing Them First", "link_suffix": "/forum?id=bVBLqKoiJ1", "link": "https://openreview.net/forum?id=bVBLqKoiJ1", "pdf_link": "https://openreview.net/pdf?id=bVBLqKoiJ1", "keywords": "Image Editing Dataset, Generative Models, Diffusion Models", "abstract": "Image editing has advanced significantly with the introduction of text-conditioned diffusion models. Despite this progress, seamlessly adding objects to images based on textual instructions without requiring user-provided input masks remains a challenge. We address this by leveraging the insight that removing objects (Inpaint) is significantly simpler than its inverse process of adding them (Paint), attributed to the utilization of segmentation mask datasets alongside inpainting models that inpaint within these masks. Capitalizing on this realization, by implementing an automated and extensive pipeline, we curate a filtered large-scale image dataset containing pairs of images and their corresponding object-removed versions. Using these pairs, we train a diffusion model to inverse the inpainting process, effectively adding objects into images. Unlike other editing datasets, ours features natural target images instead of synthetic ones; moreover, it maintains consistency between source and target by construction. Additionally, we utilize a large Vision-Language Model to provide detailed descriptions of the removed objects and a Large Language Model to convert these descriptions into diverse, natural-language instructions. Our quantitative and qualitative results show that the trained model surpasses existing models in both object addition and general editing tasks. To propel future research, we will release the dataset alongside the trained models.", "title_embedding_index": 10254, "title_abs_embedding_index": 10279}, {"title": "STARS: Self-supervised Tuning for 3D Action Recognition in Skeleton Sequences", "link_suffix": "/forum?id=HVJBFYJrN2", "link": "https://openreview.net/forum?id=HVJBFYJrN2", "pdf_link": "https://openreview.net/pdf?id=HVJBFYJrN2", "keywords": "Action Recognition, Self-supervised Learning, Contrastive Tuning", "abstract": "Self-supervised pretraining methods with masked prediction demonstrate remarkable within-dataset performance in skeleton-based action recognition. However, we show that, unlike contrastive learning approaches, they do not produce well-separated clusters. Additionally, these methods struggle with generalization in few-shot settings. To address these issues, we propose Self-supervised Tuning for 3D Action Recognition in Skeleton sequences (STARS). Specifically, STARS first uses a masked prediction stage using an encoder-decoder architecture. It then employs nearest-neighbor contrastive learning to partially tune the weights of the encoder, enhancing the formation of semantic clusters for different actions. By tuning the encoder for a few epochs, and without using hand-crafted data augmentations, STARS achieves state-of-the-art self-supervised results in various benchmarks, including NTU-60, NTU-120, and PKU-MMD. In addition, STARS exhibits significantly better results than masked prediction models in few-shot settings, where the model has not seen the actions throughout pretraining. Code:https://anonymous.4open.science/r/stars-CD2E/README.md", "title_embedding_index": 10255, "title_abs_embedding_index": 10280}, {"title": "Alberta Wells Dataset: Pinpointing Oil and Gas Wells from Satellite Imagery", "link_suffix": "/forum?id=WGBf2xwsgX", "link": "https://openreview.net/forum?id=WGBf2xwsgX", "pdf_link": "https://openreview.net/pdf?id=WGBf2xwsgX", "keywords": "Remote Sensing, Satellite Imagery, Climate Change, AI for Good", "abstract": "Millions of abandoned oil and gas wells are scattered across the world, leaching methane into the atmosphere and toxic compounds into the groundwater. Many of these locations are unknown, preventing the wells from being plugged and their polluting effects averted. Remote sensing is a relatively unexplored tool for pinpointing abandoned wells at scale. We introduce the first large-scale dataset for this problem, leveraging medium-resolution multi-spectral satellite imagery from Planet Labs. Our curated dataset comprises over 213,000 wells (abandoned, suspended, and active) from Alberta, a region with especially high well density, sourced from the Alberta Energy Regulator and verified by domain experts. We evaluate baseline algorithms for well detection and segmentation, showing the promise of computer vision approaches but also significant room for improvement.", "title_embedding_index": 10256, "title_abs_embedding_index": 10281}, {"title": "FLAIR: A Foundation Model for Grapheme Recognition in Ancient Scripts with Few-Shot Learning", "link_suffix": "/forum?id=uz4QiNHB16", "link": "https://openreview.net/forum?id=uz4QiNHB16", "pdf_link": "https://openreview.net/pdf?id=uz4QiNHB16", "keywords": "Foundation Model, Few-Shot Learning, Prototypical Networks, Encoder Network, Indus Valley Civilization Script, Omniglot Dataset", "abstract": "The Indus Valley Civilization (IVC) left behind an undeciphered script, posing a significant challenge to archaeologists and linguists. This paper introduces FLAIR, a few-shot learning approach that aims to establish a foundational model for recognizing and identifying individual graphemes from the limited available Indus script. As a foundational model, FLAIR is designed to be versatile, supporting multiple potential applications in script recognition and beyond. It leverages prototypical networks combined with a modified proposed encoder network for segmentation, ProtoSegment to extract intricate features from the grapheme images. We evaluate FLAIR\u2019s ability to generalize from minimal data using IVC grapheme classification tasks and further experiment with pre-trained Omniglot models for fine-tuning. Additionally, we simulate real-world data scarcity by intentionally restricting training data on the Omniglot dataset. Our experiments demonstrate FLAIR\u2019s accuracy in digitizing and recognizing Indus Valley seal graphemes, outperforming traditional machine learning classification approaches. These results underscore FLAIR's potential not only for the digitization of ancient scripts with limited labeled datasets but also for broader applications where data is scarce. FLAIR\u2019s success in grapheme recognition highlights its promise as a foundational model capable of extending to other undeciphered writing systems, thereby contributing to the integration of classic scientific tools and data-driven approaches.", "title_embedding_index": 10257, "title_abs_embedding_index": 10282}, {"title": "Neural Fingerprints for Adversarial Attack Detection", "link_suffix": "/forum?id=eG56H9teXv", "link": "https://openreview.net/forum?id=eG56H9teXv", "pdf_link": "https://openreview.net/pdf?id=eG56H9teXv", "keywords": "Deep Learning, Adversarial Attacks, Neural Fingerprints", "abstract": "Deep learning models for image classification have become standard tools in recent years. However, a well known\nvulnerability of these models is their susceptibility to  adversarial examples. Adversarial examples are generated \nby slightly altering an image of a certain class in a way that is imperceptible to humans but causes the model to classify it wrongly as another class. Many algorithms have been proposed to address this problem, falling generally into one of two categories: (i) building robust classifiers (ii) directly detecting attacked images. Despite the very good performance of the proposed detectors, we argue that in a white-box setting, where the attacker knows the configuration and weights of the network and the detector, the attacker can overcome the detector by running many examples on a local copy, and sending only examples that were not detected to the actual model. This problem of addressing complete knowledge of the attacker is common in security applications where even a very good model is not sufficient to ensure safety. In this paper we propose to overcome this inherent limitation of any static defence with randomization. To do so, one must generate a very large family of detectors with consistent performance, and select one or more of them randomly for each input. For the individual detectors, we suggest the method of neural fingerprints. In the training phase, for each class we repeatedly sample a tiny random subset of neurons from certain layers of the network, and if their average is sufficiently different between clean and attacked images of the focal class they are considered a fingerprint and added to the detector bank. During test time, we sample fingerprints from the bank associated with the label predicted by the model, and detect attacks using a likelihood ratio test. We evaluate our detectors on ImageNet with different attack methods and model architectures, and show near-perfect detection with low rates of false detection.", "title_embedding_index": 10258, "title_abs_embedding_index": 10283}, {"title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "link_suffix": "/forum?id=stolHkh6Nc", "link": "https://openreview.net/forum?id=stolHkh6Nc", "pdf_link": "https://openreview.net/pdf?id=stolHkh6Nc", "keywords": "Automated Machine Learning, Multi-Agent Framework, Large Language Models", "abstract": "Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposesAutoML-Agent, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment.AutoML-Agenttakes user's task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed results and guide the code generation LLM in implementing successful solutions. Extensive experiments on seven downstream tasks using fourteen datasets show thatAutoML-Agentachieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.", "title_embedding_index": 10259, "title_abs_embedding_index": 10284}, {"title": "Uncertainty Modeling in Graph Neural Networks via Stochastic Differential Equations", "link_suffix": "/forum?id=TYSQYx9vwd", "link": "https://openreview.net/forum?id=TYSQYx9vwd", "pdf_link": "https://openreview.net/pdf?id=TYSQYx9vwd", "keywords": "Graph Neural Networks, Stochastic Differential Equations, Uncertainty Quantification, Bayesian Machine Learning", "abstract": "We propose a novel Stochastic Differential Equation (SDE) framework to address the problem of learning uncertainty-aware representations for graph-structured data. While Graph Neural Ordinary Differential Equations (GNODEs) have shown promise in learning node representations, they lack the ability to quantify uncertainty. To address this, we introduce Latent Graph Neural Stochastic Differential Equations (LGNSDE), which enhance GNODE by embedding randomness through a Bayesian prior-posterior mechanism for epistemic uncertainty and Brownian motion for aleatoric uncertainty. By leveraging the existence and uniqueness of solutions to graph-based SDEs, we prove that the variance of the latent space bounds the variance of model outputs, thereby providing theoretically sensible guarantees for the uncertainty estimates. Furthermore, we show mathematically that LGNSDEs are robust to small perturbations in the input, maintaining stability over time. Empirical results across several benchmarks demonstrate that our framework is competitive in out-of-distribution detection, robustness to noise perturbations, and active learning, underscoring the ability of LGNSDEs to quantify uncertainty reliably.", "title_embedding_index": 10260, "title_abs_embedding_index": 10285}, {"title": "Projection Optimal Transport on Tree-Ordered Lines", "link_suffix": "/forum?id=EKaVO0ceh8", "link": "https://openreview.net/forum?id=EKaVO0ceh8", "pdf_link": "https://openreview.net/pdf?id=EKaVO0ceh8", "keywords": "projection optimal transport, optimal transport", "abstract": "Many variants of Optimal Transport (OT) have been developed to address its heavy computation. Among them, notably, Sliced Wasserstein (SW) is widely used for application domains by projecting the OT problem onto one-dimensional lines, and leveraging the closed-form expression of the univariate OT to reduce the computational burden. However, projecting measures onto low-dimensional spaces can lead to a loss of topological information. To mitigate this issue, in this work, we propose to replace one-dimensional lines with a more intricate structure, called \\emph{tree systems}. This structure is metrizable by a tree metric, which yields a closed-form expression for OT problems on tree systems. We provide an extensive theoretical analysis to formally define tree systems with their topological properties, introduce the concept of splitting maps, which operate as the projection mechanism onto these structures, then finally propose a novel variant of Radon transform for tree systems and verify its injectivity. This framework leads to an efficient metric between measures, termed Tree-Sliced Wasserstein distance on Systems of Lines (TSW-SL). By conducting a variety of experiments on gradient flows, image style transfer, and generative models, we illustrate that our proposed approach performs favorably compared to SW and its variants.", "title_embedding_index": 10261, "title_abs_embedding_index": 10286}, {"title": "On Logical Extrapolation for Mazes with Recurrent and Implicit Networks", "link_suffix": "/forum?id=zUXejfUAbx", "link": "https://openreview.net/forum?id=zUXejfUAbx", "pdf_link": "https://openreview.net/pdf?id=zUXejfUAbx", "keywords": "implicit networks, topological data analysis, logical extrapolation, out-of-distribution extrapolation, limit cycles, dynamics, mazes.", "abstract": "Recent work has suggested that certain neural network architectures---particularly recurrent neural networks (RNNs) and implicit neural networks (INNs)--- are capable oflogical extrapolation. That is, one may train such a network on easy instances of a specific task and then apply it successfully to more difficult instances of the same task. In this paper, we revisit this idea and show that (i) The capacity for extrapolation is less robust than previously suggested. Specifically, in the context of a maze-solving task, we show that while INNs (and some RNNs) are capable of generalizing to larger maze instances, they fail to generalize along axes of difficulty other than maze size. (ii) Models that are explicitly trained to converge to a fixed point (e.g. the INN we test) are likely to do so when extrapolating, while models that are not (e.g. the RNN we test) may exhibit more exotic limiting behaviour such as limit cycles,even whenthey correctly solve the problem. Our results suggest that (i) further study intowhysuch networks extrapolate easily along certain axes of difficulty yet struggle with others is necessary, and (ii) analyzing thedynamicsof extrapolation may yield insights into designing more efficient and interpretable logical extrapolators.", "title_embedding_index": 10262, "title_abs_embedding_index": 10287}, {"title": "Towards Full Delegation: Designing Ideal Agentic Behaviors for Travel Planning", "link_suffix": "/forum?id=dePB45VMFx", "link": "https://openreview.net/forum?id=dePB45VMFx", "pdf_link": "https://openreview.net/pdf?id=dePB45VMFx", "keywords": "Agentic Behavior, LLMs, LLM-as-a-Judge, Synthetic Data", "abstract": "How are LLM-based agents used in the future? While many of the existing work on agents has focused on improving the performance of a specific family of objective and challenging tasks, in this work, we take a different perspective by thinking about full delegation: agents take over humans\u2019 routine decision-making processes and are trusted by humans to find solutions that fit people\u2019s personalized needs and are adaptive to ever-changing context. In order to achieve such a goal, the behavior of the agents, i.e., agentic behaviors, should be evaluated not only on their achievements (i.e., outcome evaluation), but also how they achieved that (i.e., procedure evaluation). For this, we propose APEC Agent Constitution, a list of criteria that an agent should follow for good agentic behaviors, including Accuracy, Proactivity, Efficiency and Credibility. To verify whether APEC aligns with human preferences, we develop APEC-Travel, a travel planning agent that proactively extracts hidden personalized needs via multi-round dialog with travelers. APEC-Travel is constructed purely from synthetic data generated by Llama3.1-405B-Instruct with a diverse set of travelers\u2019 persona to simulate rich distribution of dialogs. Iteratively fine-tuned to follow APEC Agent Constitution, APEC-Travel surpasses baselines by 20.7% on rule based metrics and 9.1% on LLM-as-a-Judge scores across the constitution axes.", "title_embedding_index": 10263, "title_abs_embedding_index": 10288}, {"title": "API Pack: A Massive Multi-Programming Language Dataset for API Call Generation", "link_suffix": "/forum?id=f7O3hITh5s", "link": "https://openreview.net/forum?id=f7O3hITh5s", "pdf_link": "https://openreview.net/pdf?id=f7O3hITh5s", "keywords": "Instruction Datasets, Synthetic Data Generation, Code Generation", "abstract": "We introduce API Pack, a massive multi-programming language dataset containing more than one million instruction-API calls that seeks to improve the API call generation capabilities of large language models. API Pack's evaluation revealed three important findings. First, fine-tuning on API Pack enables open-source models to outperform both GPT-3.5 and GPT-4 in generating code for completely new API calls. We demonstrate this by fine-tuning CodeLlama-13B on 20,000 Python instances from API Pack. Second, we also show that cross-language API call generation can be enhanced via a large amount of data in one programming language plus small amounts of data in others. Third, we demonstrate the benefits and the need of larger datasets for API generalization, as our experiments show that increasing fine-tuning data from 20k to 1 million instances improves generalization to new APIs. To facilitate further research on this topic, we open-source API Pack dataset, trained model, and associated source code athttps://github.com/anonymous/API-Pack.", "title_embedding_index": 10264, "title_abs_embedding_index": 10289}, {"title": "Simplifying Deep Temporal Difference Learning", "link_suffix": "/forum?id=7IzeL0kflu", "link": "https://openreview.net/forum?id=7IzeL0kflu", "pdf_link": "https://openreview.net/pdf?id=7IzeL0kflu", "keywords": "Reinforcement Learning, TD, Theory, Q-learning, Parallelisation, Network Normalisation", "abstract": "$Q$-learning played a foundational role in the field reinforcement learning (RL).\nHowever, TD algorithms with off-policy data, such as $Q$-learning, or nonlinear function approximation like deep neural networks require several additional tricks to stabilise training, primarily a replay buffer and target networks. Unfortunately, the delayed updating of frozen network parameters in the target network harms the sample efficiency and, similarly, the replay buffer introduces memory and implementation overheads. In this paper, we investigate whether it is possible to accelerate and simplify off-policy TD training while maintaining its stability. Our key heoretical result demonstrates for the first time that regularisation techniques such as LayerNorm can yield provably convergent TD algorithms without the need for a target network, even with off-policy data. Empirically, we find that online, parallelised sampling enabled by vectorised environments stabilises training without the need of a replay buffer. Motivated by these findings, we propose PQN, our simplified deep online $Q$-Learning algorithm.\nSurprisingly, this simple algorithm is competitive with more complex methods like: Rainbow in Atari, PPO-RNN in Craftax, QMix in Smax, and can be up to 50x faster than traditional DQN without sacrificing sample efficiency. In an era where PPO has become the go-to RL algorithm, PQN reestablishes off-policy $Q$-learning as a viable alternative.", "title_embedding_index": 10265, "title_abs_embedding_index": 10290}, {"title": "Watermark-based Detection and Attribution of AI-Generated Image", "link_suffix": "/forum?id=O08nfMzc93", "link": "https://openreview.net/forum?id=O08nfMzc93", "pdf_link": "https://openreview.net/pdf?id=O08nfMzc93", "keywords": "Image Watermark, AI-generated image, Watermark detection, Watermark attribution", "abstract": "Several companies--such as Google, Microsoft, and OpenAI--have deployed techniques to watermark  AI-generated images to enable proactive detection. However, existing literature mainly focuses on user-agnostic detection. Attribution aims to further trace back the user who generated a  detected  AI-generated image. Despite its growing importance, attribution is largely unexplored. In this work, we aim to bridge this gap by providing the first systematic study on watermark-based, user-aware detection and attribution of AI-generated images. Specifically, we theoretically study the detection and attribution performance via rigorous probabilistic analysis. Moreover, we develop an efficient algorithm to select watermarks for the users to enhance attribution performance. Both our theoretical  and empirical results show that watermark-based detection and attribution inherit the accuracy and (non-)robustness properties of the watermarking method.", "title_embedding_index": 10266, "title_abs_embedding_index": 10291}, {"title": "Competitive Co-Evolutionary Learning on Matrix Games with Bandit Feedback", "link_suffix": "/forum?id=aSoLl0nlzr", "link": "https://openreview.net/forum?id=aSoLl0nlzr", "pdf_link": "https://openreview.net/pdf?id=aSoLl0nlzr", "keywords": "Matrix Games, Bandit Learning, Evolutionary Algorithms, Regret Analysis", "abstract": "Learning in games is a fundamental problem in machine learning and artificial intelligence, with many successful applications (Silver et al., 2016; Schrittwieser et al., 2020). We consider the problem of learning in matrix games, where two players engage in a two-player zero-sum game with an unknown payoff matrix and bandit feedback. In this setting, players can observe their actions and the corresponding (noisy) payoffs at each round. This problem has been studied in the literature, and several algorithms have been proposed to address it (O\u2019Donoghue et al., 2021; Maiti et al., 2023; Cai et al., 2023). In particular, O\u2019Donoghue et al. (2021) demonstrated that deterministic optimism (e.g., the UCB algorithm for matrix games) plays a central role in achieving sublinear regret and outperforms other algorithms. However, despite numerous applications, the theoretical understanding of learning in matrix games remains underexplored. Specifically, it remains an open question whether randomised optimism can also exhibit sublinear regret.In this paper, we propose a novel algorithm called Competitive Co-evolutionary Bandit Learning (CoEBL) for unknown two-player zero-sum matrix games. By integrating evolutionary algorithms (EAs) into the bandit framework, CoEBL introduces randomised optimism through the variation operator of EAs. We prove that CoEBL also enjoys sublinear regret, matching the regret performance of algorithms based on deterministic optimism (O\u2019Donoghue et al., 2021). To the best of our knowledge, this is the first work that provides a regret analysis of an evolutionary bandit learning algorithm in matrix games. Empirically, we compare CoEBL with classical bandit algorithms, including EXP3 (Auer et al., 2002), the variant of EXP3-IX (Cai et al., 2023), and UCB algorithms analysed in O\u2019Donoghue et al. (2021) across several matrix game benchmarks. Our results show that CoEBL not only enjoys sublinear regret, but also outperforms existing methods in various scenarios. These findings reveal the promising potential of evolutionary bandit learning in game-theoretic settings, in particular, the effectiveness of randomised optimism via evolutionary algorithms.", "title_embedding_index": 10267, "title_abs_embedding_index": 10292}, {"title": "Grounded Robotic Action-Rule Induction through Language Models (GRAIL)", "link_suffix": "/forum?id=oyXoGJQlUf", "link": "https://openreview.net/forum?id=oyXoGJQlUf", "pdf_link": "https://openreview.net/pdf?id=oyXoGJQlUf", "keywords": "Autonomous Planning Agents, Symbol Grounding, Frame Problem, PDDL Model Optimization, Robotics", "abstract": "A significant body of recent work illustrates that two components of autonomous planning agents nearly always require manual pre-specification by human experts: the identification and grounding of action symbols (such as \u201cturn right\u201d), and the generation of PDDL action rules (including rule name, parameters, preconditions, and effects). We present the Grounded Robotic Action-Rule Induction through Language Models (GRAIL) system, which, in addition to automating those two processes, also contributes to the expanding research on PDDL model optimization. In this paper, we show how large language models (LLMs) can be used to cluster the sensorimotor experience of the robot and automatically generate useful symbolic abstractions about the robot\u2019s capabilities and environment. This language-grounded abstraction allows the learned domain to be modified and used for planning without additional retraining. We evaluate the approach in a standard maze domain and show results for automated symbol identification and grounding, automated rule generation, simulation-based rule validation, and PDDL model optimization. We also discuss and illustrate the advantages of the hybrid neuro-symbolic GRAIL system over traditional symbolic or purely data-driven approaches to similar tasks.", "title_embedding_index": 10268, "title_abs_embedding_index": 10293}, {"title": "Solving Inverse Problems in Protein Space Using Diffusion-Based Priors", "link_suffix": "/forum?id=UYZRaUCLAg", "link": "https://openreview.net/forum?id=UYZRaUCLAg", "pdf_link": "https://openreview.net/pdf?id=UYZRaUCLAg", "keywords": "machine learning for structural biology, protein structure determination, diffusion models, inverse problems", "abstract": "The interaction of a protein with its environment can be understood and controlled via its 3D structure. Experimental methods for protein structure determination, such as X-ray crystallography or cryogenic electron microscopy, shed light on biological processes but introduce challenging inverse problems. Learning-based approaches have emerged as accurate and efficient methods to solve these inverse problems for 3D structure determination, but are specialized for a predefined type of measurement. Here, we introduce a versatile framework to turn raw biophysical measurements, such as cryo-EM density maps, into 3D atomic models. Our method combines a physics-based forward model of the measurement process with a pretrained generative model providing a task-agnostic, data-driven prior. Our method outperforms posterior sampling baselines on linear and non-linear inverse problems. In particular, it is the first diffusion-based method for refining atomic models from simulated cryo-EM maps.", "title_embedding_index": 10269, "title_abs_embedding_index": 10294}, {"title": "Scalable Ranked Preference Optimization for Text-to-Image Generation", "link_suffix": "/forum?id=Y6KUBkUimC", "link": "https://openreview.net/forum?id=Y6KUBkUimC", "pdf_link": "https://openreview.net/pdf?id=Y6KUBkUimC", "keywords": "text-to-image generation, Direct Preference Optimization, Learning from AI Feedback", "abstract": "Direct Preference Optimization (DPO) has emerged as a powerful approach to align text-to-image (T2I) models with human feedback. Unfortunately, successful application of DPO to T2I models requires a huge amount of resources to collect and label large-scale datasets, e.g., millions of generated paired images annotated with human preferences. In addition, these human preference datasets can get outdated quickly as the rapid improvements of T2I models lead to higher quality images. In this work, we investigate a scalable approach for collecting large-scale and fully synthetic datasets for DPO training. Specifically, the preferences for paired images are generated using a pre-trained reward function, eliminating the need for involving humans in the annotation process, greatly improving the dataset collection efficiency. Moreover, we demonstrate that such datasets allow averaging predictions across multiple models and collecting ranked preferences as opposed to pairwise preferences. Furthermore, we introduce RankDPO to enhance DPO-based methods using the ranking feedback. Applying RankDPO on SDXL and SD3-Medium models with our synthetically generated preference dataset ``Syn-Pic'' improves both prompt-following (on benchmarks like T2I-Compbench, GenEval, and DPG-Bench) and visual quality (through user studies). This pipeline presents a practical and scalable solution to develop better preference datasets to enhance the performance and safety of text-to-image models.", "title_embedding_index": 10270, "title_abs_embedding_index": 10295}, {"title": "Node-based Multiple Graph Learning with Theoretical Guarantees", "link_suffix": "/forum?id=YtGtIAYDV3", "link": "https://openreview.net/forum?id=YtGtIAYDV3", "pdf_link": "https://openreview.net/pdf?id=YtGtIAYDV3", "keywords": "graph learning, multiple graphs, perturbation, graph signal smoothness", "abstract": "In many applications, inferring graph topology, i.e., learning the graph structure from a given set of nodal observations, is a significant task. Existing approaches are mostly limited to learning a single graph assuming that the observed data are homogeneous. In many applications, data sets are heterogeneous and involve multiple related graphs, i.e., multiview graphs.  Recent work on learning multiview graphs ensures the similarity of learned view graphs through edge-based similarity between the graphs. In this paper, we take a node-based approach instead of assuming that similarities and differences between networks are driven by individual edges, providing a more intuitive interpretation of network differences. Moreover, unlike existing methods that employ Gaussian Graphical Models (GGM), which learn precision matrices rather than the actual graph structures, we characterize the graph using a Laplacian matrix. Thus, the approach is expected to work broadly beyond Gaussian graphical learning. We develop an optimization framework to learn the individual graphical structures, assuming that the differences are due to individual nodes that are perturbed across views. The proposed optimization framework is presented for the special case of two views. Furthermore, we derive the upper bound on the estimation error of the proposed graph estimator and characterize the impact of the sample size, number of nodes, and the spectrum of the graph Laplacians on estimation errors. The approach is evaluated on synthetic graph data for robustness against noise, graph density, and sample size. Finally, the proposed framework is applied to two-view real-world graph data for graph learning and clustering.", "title_embedding_index": 10271, "title_abs_embedding_index": 10296}, {"title": "Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models", "link_suffix": "/forum?id=RWZzGkFh3S", "link": "https://openreview.net/forum?id=RWZzGkFh3S", "pdf_link": "https://openreview.net/pdf?id=RWZzGkFh3S", "keywords": "data-centric learning, detrimental sample trimming, training sample influence", "abstract": "A core data-centric learning challenge is the identification of training samples that are detrimental to model performance. Influence functions serve as a prominent tool for this task and offer a robust framework for assessing training data influence on model predictions. Despite their widespread use, their high computational cost associated with calculating the inverse of the Hessian matrix pose constraints, particularly when analyzing large-sized deep models. In this paper, we establish a bridge between identifying detrimental training samples via influence functions and outlier gradient detection. This transformation not only presents a straightforward and Hessian-free formulation but also provides insights into the role of the gradient in sample impact. Through systematic empirical evaluations, we first validate the hypothesis of our proposed outlier gradient analysis approach on synthetic datasets. We then demonstrate its effectiveness in detecting mislabeled samples in vision models and selecting data samples for improving performance of natural language processing transformer models. We also extend its use to influential sample identification for fine-tuning Large Language Models.", "title_embedding_index": 10272, "title_abs_embedding_index": 10297}, {"title": "Copyright-Protected Language Generation via Adaptive Model Fusion", "link_suffix": "/forum?id=kRoWeLTpL4", "link": "https://openreview.net/forum?id=kRoWeLTpL4", "pdf_link": "https://openreview.net/pdf?id=kRoWeLTpL4", "keywords": "language models, copyright, model fusion, memorization, safety, privacy", "abstract": "The risk of language models reproducing copyrighted material from their training data has led to the development of various protective measures. Among these, inference-time strategies that impose constraints via post-processing have shown promise in addressing the complexities of copyright regulation. However, they often incur prohibitive computational costs or suffer from performance trade-offs. In this paper, we introduce Copyright-Protecting Model Fusion (CP-Fuse), a novel inference-time approach that leverages model fusion to overcome these limitations. In particular, CP-Fuse adaptively combines multiple language models to minimize the reproduction of copyrighted content,  adhering to a crucial balancing property to prevent the regurgitation of memorized data. Our extensive experiments demonstrate that CP-Fuse significantly reduces the reproduction of protected material without compromising the quality of text and code generation. Additionally, the post-hoc nature of CP-Fuse allows it to integrate seamlessly with other protective measures, enhancing overall copyright safeguards. Finally, we show that CP-Fuse is robust against a common technique for extracting training data.", "title_embedding_index": 10273, "title_abs_embedding_index": 10298}, {"title": "GNNs Getting ComFy: Community and Feature Similarity Guided Rewiring", "link_suffix": "/forum?id=g6v09VxgFw", "link": "https://openreview.net/forum?id=g6v09VxgFw", "pdf_link": "https://openreview.net/pdf?id=g6v09VxgFw", "keywords": "graph neural networks, over-squashing, graph rewiring, community structure, homophily, feature similarity", "abstract": "Maximizing the spectral gap through graph rewiring has been proposed to enhance the performance of message-passing graph neural networks (GNNs) by addressing over-squashing. However, as we show, minimizing the spectral gap can also improve generalization. To explain this, we analyze how rewiring can benefit GNNs within the context of stochastic block models. Since spectral gap optimization primarily influences community strength, it improves performance when the community structure aligns with node labels. Building on this insight, we propose three distinct rewiring strategies that explicitly target community structure, node labels, and their alignment: (a) community structure-based rewiring (ComMa), a more computationally efficient alternative to spectral gap optimization that achieves similar goals; (b) feature similarity-based rewiring (FeaSt), which focuses on maximizing global homophily; and (c) a hybrid approach (ComFy), which enhances local feature similarity while preserving community structure to optimize label-community alignment. Extensive experiments confirm the effectiveness of these strategies and support our theoretical insights.", "title_embedding_index": 10274, "title_abs_embedding_index": 10299}]
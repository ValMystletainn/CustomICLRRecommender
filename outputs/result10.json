[{"title": "FlowAgent: a New Paradigm for Workflow Agent", "link_suffix": "/forum?id=w1MEIGDepc", "link": "https://openreview.net/forum?id=w1MEIGDepc", "pdf_link": "https://openreview.net/pdf?id=w1MEIGDepc", "keywords": "workflow, LLM-based agent, task-oriented dialog", "abstract": "Combining workflows with large language models (LLMs) allows LLMs to follow specific procedures, thereby extending their application to more real-world scenarios. However, incorporating workflows often compromises the flexibility of LLMs. For example in the case of Task-Oriented Dialogue (TOD), workflow atomize the function of LLM while programmatically imposing restrictions on execution path making the dialogue obstructed and less flexible when facing out-of-workflow (OOW) queries. Prompt-based methods offer soft control but sometimes fail to ensure procedure compliance. This paper introduces a new agent paradigm to address this challenge. Specifically, we first propose a novel Procedure Description Language (PDL) that integrates the flexibility of natural language and the precision of code for workflow expression. Additionally, we present a comprehensive framework that enables LLM to handle OOW queries while keeping execution safe with a series of controllers for behavioral regulation. This includes pre-decision and post-decision methods, where the dependency relationships between workflow nodes are modeled as a Directed Acyclic Graph (DAG) to validate node transitions. Beyond the primary objective of compliance considered in previous work, we introduce a new approach to evaluate the agent's flexibility in OOW situations. Experiments on three datasets demonstrate that FlowAgent not only adheres well to workflows but also responds better to OOW queries, showcasing its flexibility. Furthermore, exploration on WikiHow data confirms that the PDL effectively represents broader formats of workflow, inspiring further research on workflow-based QA tasks.", "title_embedding_index": 450, "title_abs_embedding_index": 475}, {"title": "Beware of Calibration Data for Pruning Large Language Models", "link_suffix": "/forum?id=x83w6yGIWb", "link": "https://openreview.net/forum?id=x83w6yGIWb", "pdf_link": "https://openreview.net/pdf?id=x83w6yGIWb", "keywords": "calibration data, post-training pruning, large language models", "abstract": "As large language models (LLMs) are widely applied across various fields, model compression has become increasingly crucial for reducing costs and improving inference efficiency. Post-training pruning is a promising method that does not require resource-intensive iterative training and only needs a small amount of calibration data to assess the importance of parameters. Previous research has primarily focused on designing advanced pruning methods, while different calibration data's impact on pruning performance still lacks systematical exploration. This paper investigates the effect of calibration data on post-training pruning and demonstrates that using calibration data similar to the training data yields better performance. Based on this finding, we propose a self-generating synthetic calibration data strategy to sample suitable calibration data for LLMs in practical scenarios with inaccessible training data. We conduct experiments on the DCLM, LLaMA-2, and LLaMA-3 models, and the results show that the proposed method outperforms commonly used calibration data.", "title_embedding_index": 451, "title_abs_embedding_index": 476}, {"title": "Solving Urban Network Security Games: Learning Platform, Benchmark, and Challenge for AI Research", "link_suffix": "/forum?id=DjHnxxlqwl", "link": "https://openreview.net/forum?id=DjHnxxlqwl", "pdf_link": "https://openreview.net/pdf?id=DjHnxxlqwl", "keywords": "security games, multiplayer games", "abstract": "After the great achievement of solving two-player zero-sum games, more and more AI researchers focus on solving multiplayer games. To facilitate the development of designing efficient learning algorithms for solving multiplayer games, we propose a multiplayer game platform for solving Urban Network Security Games (UNSG) that model real-world scenarios. That is,preventing criminal activity is a highly significant responsibility assigned to police officers in cities, and police officers have to allocate their limited security resources to interdict the escaping criminal when a crime takes place in a city. This interaction between multiple police officers and the escaping criminal can be modeled as a UNSG. The variants of UNSGs can model different real-world settings, e.g., whether real-time information is available or not, whether police officers can communicate or not.\nThe main challenges of solving this game include the large size of the game and the co-existence of cooperation and competition. \nWhile previous efforts have been made to tackle UNSGs, they have been hampered by performance and scalability issues. Therefore, we propose an open-source UNSG platform (GraphChase) for designing efficient learning algorithms for solving UNSGs.\nSpecifically, GraphChase offers a unified and flexible game environment for modeling various variants of UNSGs, supporting the development, testing, and benchmarking of algorithms. We believe that GraphChase    not only facilitates  the development of efficient algorithms for solving real-world problems but also paves the way for significant advancements in algorithmic development for solving general multiplayer games.", "title_embedding_index": 452, "title_abs_embedding_index": 477}, {"title": "Graph-Enhanced Learning for Predicting Optimal Drug Combinations Using Contrastive Embedding", "link_suffix": "/forum?id=plAiJUFNja", "link": "https://openreview.net/forum?id=plAiJUFNja", "pdf_link": "https://openreview.net/pdf?id=plAiJUFNja", "keywords": "Graph Learning, Contrastive Embedding, DDI", "abstract": "We present a groundbreaking unified theory for drug-drug interaction (DDI) aware domain adaptation (DA) in the context of drug synergy prediction. Our framework seamlessly integrates concepts from optimal transport, information geometry, and quantum information theory within the setting of abstract Banach spaces. We introduce a novel DDI-aware optimal transport problem, formulated as a geodesic equation on an infinite-dimensional Finsler manifold that encodes both DDI structure and optimal transport costs. This geometric formulation provides a unified perspective on DDI-aware domain adaptation, interpreting the process as the evolution of a transport map along a geodesic in a space that captures both domain discrepancy and drug interaction patterns. Our approach extends to a stochastic gradient flow on the space of probability measures, combining ideas from information geometry and stochastic analysis. We prove the existence of a unique invariant measure for this flow and establish its convergence properties using techniques from infinite-dimensional Markov processes and \u0393-convergence. Our comprehensive mathematical framework not only unifies existing approaches to domain adaptation and DDI prediction but also opens new avenues for research at the intersection of these fields. By bridging the gap between abstract mathematical theories and practical drug synergy prediction, our work paves the way for more effective and theoretically grounded algorithms in drug discovery and personalized medicine. The proposed unified theory has far-reaching implications, potentially revolutionizing our understanding of cross-domain adaptation in complex biochemical systems and inspiring novel computational methods in pharmaceutical research.", "title_embedding_index": 453, "title_abs_embedding_index": 478}, {"title": "Herald: A Natural Language Annotated Lean 4 Dataset", "link_suffix": "/forum?id=Se6MgCtRhz", "link": "https://openreview.net/forum?id=Se6MgCtRhz", "pdf_link": "https://openreview.net/pdf?id=Se6MgCtRhz", "keywords": "Lean 4, Autoformalizing, LLM, Retrieval Augmented Generation, Dataset", "abstract": "Verifiable formal languages like Lean have profoundly impacted mathematical reasoning, particularly through the use of large language models (LLMs) for automated reasoning. A significant challenge in training LLMs for these formal languages is the lack of parallel datasets that align natural language with formal language proofs. To address this challenge, this paper introduces a novel framework for translating the Mathlib4 corpus (a unified library of mathematics in formal language Lean 4) into natural language. Building upon this, we employ a dual augmentation strategy that combines tactic-based and informal-based approaches, leveraging the Lean-jixia system, a Lean 4 analyzer. We present the results of this pipeline on Mathlib4 as Herald (Hierarchy and Retrieval-based Translated Lean Dataset). We also propose the Herald Translator, which is fine-tuned on Herald. Herald translator achieves a 93.2% accuracy (Pass@128) on formalizing statements in the miniF2F-test and a 22.5% accuracy on our internal graduate-level textbook dataset, outperforming InternLM2-Math-Plus-7B (74.0% and 7.5%) and TheoremLlama (50.1% and 4.0%). Furthermore, we propose a section-level translation framework for real-world applications. As a direct application of Herald translator, we have successfully translated a template section in the Stack project, marking a notable progress in the automatic formalization of graduate-level mathematical literature. Our model, along with the datasets, will be open-sourced to the public soon.", "title_embedding_index": 454, "title_abs_embedding_index": 479}, {"title": "Toward Domain Translation with Monolingual Domain Data Only", "link_suffix": "/forum?id=63Pq7q7ybl", "link": "https://openreview.net/forum?id=63Pq7q7ybl", "pdf_link": "https://openreview.net/pdf?id=63Pq7q7ybl", "keywords": "Neural Machine Translation, Unsupervised Domain Adaptation, Energy-Based Models, Conditional Distributional Policy Gradients", "abstract": "Neural machine translation (NMT) is very sensitive to domain shifts requiring a carefully designed fine-tuning strategy to avoid catastrophic forgetting problems when adapting to a new domain.  Fine-tuning usually relies on high quality in-domain data, but constructing a sufficient amount of parallel data for training poses challenges even for fine-tuning. In contrast, domain-specific monolingual resources are more accessible when compared with bilingual data. Therefore, we challenge the domain adaptation of a general NMT model using only features obtained from a small amount of monolingual data. We regard the task as an instance of domain shifts, and adopt energy-based models (EBMs) and approximate these EBMs using Conditional Distributional Policy Gradients (CDPG). Recent work has applied CDPG with a small number of EBMs for NMT models limiting the capacity for domain shifts, but we construct a large number of EBMs considering the entire domain-specific data, i.e., unigram distribution, and perform fine-tuning according to their constraints. Our results show that fine-tuning using a large number of EBMs can achieve a robust domain shift without causing catastrophic forgetting, demonstrating a robust domain shift using only a small amount of monolingual resources.", "title_embedding_index": 455, "title_abs_embedding_index": 480}, {"title": "Dynamic Routing Mixture of Experts for Enhanced Multi-Label Image Classification", "link_suffix": "/forum?id=gFUomIaycw", "link": "https://openreview.net/forum?id=gFUomIaycw", "pdf_link": "https://openreview.net/pdf?id=gFUomIaycw", "keywords": "Multi-label image classification, Dynamic Routing Mixture of Experts, Computer vision, Dynamic gating networks, Label heterogeneity", "abstract": "Multi-label image classification (MLC) is a fundamental task in computer vision, requiring the identification of multiple objects or attributes within a single image. Traditional approaches often rely on shared backbones and static gating mecha-nisms, which can struggle to effectively capture complex label correlations and handle label heterogeneity, leading to issues such as negative transfer. In this pa-per, we introduce the Dynamic Routing Mixture of Experts (DR-MoE) model, a novel architecture that integrates input-dependent dynamic gating networks into the mixture-of-experts (MoE) framework for MLC. Unlike static gating in exist-ing models like the Hybrid Sharing Query (HSQ) Yin et al. (2024), our dynamic gating mechanism adaptively selects and weights both shared and task-specific experts based on the input image features. This allows DR-MoE to better capture varying label dependencies and mitigate negative transfer, resulting in improved overall and per-label classification performance. We conduct extensive experi-ments on benchmark datasets MS-COCO Lin et al. (2014) and PASCAL VOC 2007 Everingham et al. (2015), demonstrating that DR-MoE achieves state-of-the-art results, outperforming existing methods including HSQ, Q2L Liu et al.(2021), and ML-GCN Chen et al. (2019). Additionally, ablation studies confirm the effectiveness of dynamic gating in enhancing model adaptability and perfor-mance, particularly for labels with high heterogeneity. Our findings suggest that incorporating dynamic routing mechanisms into MoE architectures is a promising direction for advancing multi-label image classification.", "title_embedding_index": 456, "title_abs_embedding_index": 481}, {"title": "Efficient Residual Learning with Mixture-of-Experts for Universal Dexterous Grasping", "link_suffix": "/forum?id=BUj9VSCoET", "link": "https://openreview.net/forum?id=BUj9VSCoET", "pdf_link": "https://openreview.net/pdf?id=BUj9VSCoET", "keywords": "dexterous grasping, residual policy learning, reinforcement learning", "abstract": "Universal dexterous grasping across diverse objects presents a fundamental yet formidable challenge in robot learning. Existing approaches using reinforcement learning (RL) to develop policies on extensive object datasets face critical limitations, including complex curriculum design for multi-task learning and limited generalization to unseen objects. \nTo overcome these challenges, we introduce ResDex, a novel approach that integrates residual policy learning with a mixture-of-experts (MoE) framework. ResDex is distinguished by its use of geometry-unaware base policies that are efficiently acquired on individual objects and capable of generalizing across a wide range of unseen objects. Our MoE framework incorporates several base policies to facilitate diverse grasping styles suitable for various objects. By learning residual actions alongside weights that combine these base policies, ResDex enables efficient multi-task RL for universal dexterous grasping.\nResDex achieves state-of-the-art performance on the DexGraspNet dataset comprising 3,200 objects with an 88.8% success rate. It exhibits no generalization gap with unseen objects and demonstrates superior training efficiency, mastering all tasks within only 12 hours on a single GPU.", "title_embedding_index": 457, "title_abs_embedding_index": 482}, {"title": "DPLM-2: A Multimodal Diffusion Protein Language Model", "link_suffix": "/forum?id=5z9GjHgerY", "link": "https://openreview.net/forum?id=5z9GjHgerY", "pdf_link": "https://openreview.net/pdf?id=5z9GjHgerY", "keywords": "protein foundation model, diffusion language model, multimodal language model", "abstract": "Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, and generate both sequences and structures. However, existing methods typically use separate models for each modality, limiting their ability to capture the intricate relationships between sequence and structure. This results in suboptimal performance in tasks that requires joint understanding and generation of both modalities.\nIn this paper, we introduce DPLM-2, a multimodal protein foundation model that extends discrete diffusion protein language model (DPLM) to accommodate both sequences and structures.\nTo enable structural learning with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer.\nBy training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals.\nWe also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.\nEmpirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.\nMoreover, DPLM-2 demonstrates competitive performance in various conditional generation tasks, including folding, inverse folding, and scaffolding with multimodal motif inputs.", "title_embedding_index": 458, "title_abs_embedding_index": 483}, {"title": "EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary Search", "link_suffix": "/forum?id=kWtP5ZOErR", "link": "https://openreview.net/forum?id=kWtP5ZOErR", "pdf_link": "https://openreview.net/pdf?id=kWtP5ZOErR", "keywords": "large language models, compression, evolutionary algorithms, quantization, pruning", "abstract": "The high computational costs of large language models (LLMs) have led to\na flurry of research on LLM compression, via methods such as quantization,\nsparsification, or structured pruning. A new frontier in this area is given by\ndynamic, non-uniform compression methods, which adjust the compression\nlevels (e.g., sparsity) per-block or even per-layer in order to minimize accuracy\nloss, while guaranteeing a global compression threshold. Yet, current methods\nrely on heuristics for identifying the \u201cimportance\u201d of a given layer towards the\nloss, based on assumptions such as error monotonicity, i.e. that the end-to-end\nmodel compression error is proportional to the sum of layer-wise errors. In this\npaper, we revisit this area, and propose a new and general approach for dynamic\ncompression that is provably optimal in a given input range. We begin from\nthe motivating observation that, in general, error monotonicity does not hold for\nLLMs: compressed models with lower sum of per-layer errors can perform worse\nthan models with higher error sums. To address this, we propose a new general\nevolutionary framework for dynamic LLM compression called EvoPress, which\nhas provable convergence, low sample and evaluation complexity. We show that\nthese theoretical guarantees lead to highly competitive practical performance\nfor dynamic compression of Llama, Mistral and Phi models: via EvoPress, we\nset new state-of-the-art results for structural pruning (block/layer dropping),\nunstructured sparsity, as well as quantization with dynamic bitwidths.", "title_embedding_index": 459, "title_abs_embedding_index": 484}, {"title": "OptiBench: Benchmarking Large Language Models in Optimization Modeling with Equivalence-Detection Evaluation", "link_suffix": "/forum?id=KD9F5Ap878", "link": "https://openreview.net/forum?id=KD9F5Ap878", "pdf_link": "https://openreview.net/pdf?id=KD9F5Ap878", "keywords": "LLM, benchmark, AI for OR, optimization modeling, autonomous mathematical formulation", "abstract": "In operations research (OR), formulating optimization problems in industrial applications is often time-consuming and requires specialized expertise. Recently, large language models (LLMs) have shown remarkable potential to automate this process. However, evaluating the performance of LLMs in optimization modeling remains challenging due to the scarcity of suitable datasets and rigorous evaluation methodologies. To reduce this gap, we introduce OptiBench, a new benchmark designed to assess LLMs' ability to formulate linear programming (LP) and mixed-integer linear programming (MILP) models. OptiBench provides a diverse dataset covering 816 optimization modeling word problems across 16 problem classes and over 80 practical domains. It also adopts a model-data separation format with 2 levels of description abstraction. The dataset exhibits the complexity of real-world optimization problems compared to traditional textbook examples. OptiBench incorporates a new evaluation method based on a modified Weisfeiler-Lehman graph isomorphism test (WL-test) algorithm.\nWe theoretically prove that this method can correctly judge whether two models are equivalent or not, setting a new standard for automatically validating the correctness of optimization modeling. We benchmark various LLMs using OptiBench and observe significant performance differences. GPT-4o by direct prompting achieves 49.39% overall accuracy, outperforming other models and LLM-based agents, including OpenAI o1 (preview and mini). Notably, GPT-4o's performance varies across different problem classes, achieving over 90% accuracy on the knapsack problem class but falling below 5% on the traveling salesman problem class. These findings provide new insights into the strengths and limitations of LLMs in optimization modeling.", "title_embedding_index": 460, "title_abs_embedding_index": 485}, {"title": "Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation", "link_suffix": "/forum?id=moWiYJuSGF", "link": "https://openreview.net/forum?id=moWiYJuSGF", "pdf_link": "https://openreview.net/pdf?id=moWiYJuSGF", "keywords": "Web Agent, World Model, Digital Agent, Planning, LLM", "abstract": "Large language models (LLMs) have recently gained much attention in building autonomous agents. However, performance of current LLM-based web agents in long-horizon tasks is far from optimal, often yielding errors such as repeatedly buying a non-refundable flight ticket. By contrast, humans can avoid such an irreversible mistake, as we have an awareness of the potential outcomes (e.g., losing money) of our actions, also known as the \"world model\". Motivated by this, our study first starts with preliminary analyses, confirming the absence of world models in current LLMs (e.g., GPT-4o, Claude-3.5-Sonnet, etc.). Then, we present a World-model-augmented (WMA) web agent, which simulates the outcomes of its actions for better decision-making. To overcome the challenges in training LLMs as world models predicting next observations, such as repeated elements across observations and long HTML inputs, we propose a transition-focused observation abstraction, where the prediction objectives are free-form natural language descriptions exclusively highlighting important state differences between time steps. Experiments on WebArena and Mind2Web show that our world models improve agents' policy selection without training and demonstrate our agents' cost- and time-efficiency compared to recent tree-search-based agents.", "title_embedding_index": 461, "title_abs_embedding_index": 486}, {"title": "HyperFace: Generating Synthetic Face Recognition Datasets by Exploring Face Embedding Hypersphere", "link_suffix": "/forum?id=4YzVF9isgD", "link": "https://openreview.net/forum?id=4YzVF9isgD", "pdf_link": "https://openreview.net/pdf?id=4YzVF9isgD", "keywords": "Face Recognition, Hypersphere Optimization, Privacy, Synthetic Data", "abstract": "Face recognition datasets are often collected by crawling Internet and without individuals' consents, raising  ethical and privacy concerns. Generating synthetic datasets for training face recognition models has emerged as a promising alternative. However, the generation of synthetic datasets remains  challenging as it entails adequate inter-class and intra-class variations. While advances in generative models have made it easier to increase intra-class variations in face datasets (such as pose, illumination, etc.), generating sufficient inter-class variation is still a difficult task. In this paper, we formulate the dataset generation as a packing problem on the embedding space (represented on a hypersphere) of a face recognition model and propose a new synthetic dataset generation approach, called HyperFace. We formalize our packing problem as an optimization problem and solve it with a gradient descent-based approach. Then, we use a conditional face generator model to synthesize face images from the optimized embeddings. We use our generated datasets to train face recognition models and evaluate the trained models on several benchmarking real datasets. Our experimental results show that models trained with HyperFace achieve state-of-the-art performance in training face recognition using synthetic datasets.", "title_embedding_index": 462, "title_abs_embedding_index": 487}, {"title": "Machine Unlearning in Audio: Bridging The Modality Gap Via the Prune and Regrow Paradigm", "link_suffix": "/forum?id=i3tBySZWrR", "link": "https://openreview.net/forum?id=i3tBySZWrR", "pdf_link": "https://openreview.net/pdf?id=i3tBySZWrR", "keywords": "Machine Unlearning, Audio, Deep Learning, Privacy, Pruning", "abstract": "The ubiquity and success of deep learning is primarily owed to large human datasets; however, increasing interest in personal data raises questions of how to satisfy privacy legislation in deep learning. Machine unlearning is a nascent discipline centred on satisfying user privacy demands, by enabling data removal requests on trained models. While machine unlearning has reached a good level of maturity in the vision and language domains, applications in audio are largely underexplored, despite it being a highly prevalent and widely used modality. We address this modality gap by providing the first systematic analysis of machine unlearning techniques covering multiple architectures trained on audio datasets. Our analysis highlights, for the first time, that, in audio, existing methods fail to remove data for the most likely case of unlearning \u2013 Item Removal. We present a novel Prune and Regrow paradigm that bolsters sparsity unlearning through Cosine and Post Optimal Pruning, achieving the best unlearning accuracy for 83% of Item Removal experiments. We furthermore run experiments showing that our approach maintains performance as unlearning requests grow, and we shed light on the mechanisms underpinning the success of our Prune and Regrow paradigm.", "title_embedding_index": 463, "title_abs_embedding_index": 488}, {"title": "Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation", "link_suffix": "/forum?id=UHg1xTRzZK", "link": "https://openreview.net/forum?id=UHg1xTRzZK", "pdf_link": "https://openreview.net/pdf?id=UHg1xTRzZK", "keywords": "Large Language Model, Continual Instruction Tuning, Machine Translation", "abstract": "Large Language Models (LLMs) have achieved impressive results across numerous NLP tasks but still encounter difficulties in machine translation. Traditional methods to improve translation have typically involved fine-tuning LLMs using parallel corpora. However, vanilla fine-tuning often leads to catastrophic forgetting of the instruction-following capabilities and alignment with human preferences, compromising their broad general abilities and introducing potential security risks. These abilities, which are developed using proprietary and unavailable training data, make existing continual instruction tuning methods ineffective. To overcome this issue, we propose a novel approach called $\\textbf{RaDis}$ ($\\textbf{Ra}$tionale $\\textbf{Dis}$tillation). RaDis harnesses the strong generative capabilities of LLMs to create rationales for training data, which are then \u201creplayed\u201d to prevent forgetting. These rationales $\\textit{encapsulate general knowledge and safety principles}$ and act as $\\textit{self-distillation targets}$ to regulate the training process. By jointly training on both reference translations and self-generated rationales, the model can learn new translation skills while preserving its overall general abilities. Extensive experiments demonstrate that our method enhances machine translation performance while maintaining the broader capabilities of LLMs across other tasks. This work presents a pathway for creating more versatile LLMs that excel in specialized tasks without compromising generality and safety.", "title_embedding_index": 464, "title_abs_embedding_index": 489}, {"title": "Language Imbalance Driven Rewarding for Multilingual Self-improving", "link_suffix": "/forum?id=Kak2ZH5Itp", "link": "https://openreview.net/forum?id=Kak2ZH5Itp", "pdf_link": "https://openreview.net/pdf?id=Kak2ZH5Itp", "keywords": "Large Language Model, Self-Improving, Multilinguality", "abstract": "Large Language Models (LLMs) have achieved state-of-the-art performance across numerous tasks. However, these advancements have predominantly benefited \"first-class\" languages such as English and Chinese, leaving many other languages underrepresented. This imbalance, while limiting broader applications, generates a natural preference ranking between languages, offering an opportunity to bootstrap the multilingual capabilities of LLM in a self-improving manner. Thus, we propose $\\textit{Language Imbalance Driven Rewarding}$, where the inherent imbalance between dominant and non-dominant languages within LLMs is leveraged as a reward signal. Iterative DPO training demonstrates that this approach not only enhances LLM performance in non-dominant languages but also improves the dominant language's capacity, thereby yielding an iterative reward signal. Fine-tuning Meta-Llama-3-8B-Instruct over two iterations of this approach results in continuous improvements in multilingual performance across instruction-following and arithmetic reasoning tasks, evidenced by an average improvement of 7.46% win rate on the X-AlpacaEval leaderboard and 13.9% accuracy on the MGSM benchmark. This work serves as an initial exploration, paving the way for multilingual self-improvement of LLMs.", "title_embedding_index": 465, "title_abs_embedding_index": 490}, {"title": "FedDTPT: Federated Discrete and Transferable Prompt Tuning for Black-Box Large Language Models", "link_suffix": "/forum?id=p4RAKZ4oik", "link": "https://openreview.net/forum?id=p4RAKZ4oik", "pdf_link": "https://openreview.net/pdf?id=p4RAKZ4oik", "keywords": "Federated learning, Large Language Models, Black-Box Estimation, Discrete Prompt Learning", "abstract": "In recent years, large language models (LLMs) have significantly advanced the field of natural language processing (NLP). By fine-tuning LLMs with data from specific scenarios, these foundation models can better adapt to various downstream tasks. However, the fine-tuning process poses privacy leakage risks, particularly in centralized data processing scenarios. To address user privacy concerns, federated learning (FL) has been introduced to mitigate the risks associated with centralized data collection from multiple sources. Nevertheless, the privacy of LLMs themselves is equally critical, as potential malicious attacks challenge their security, an issue that has received limited attention in current research. Consequently, establishing a trusted multi-party model fine-tuning environment is essential. Additionally, the local deployment of large LLMs incurs significant storage costs and high computational demands. To address these challenges, we propose for the first time a federated discrete and transferable prompt tuning, namely FedDTPT, for black-box large language models. In the client optimization phase, we adopt a token-level discrete prompt optimization method that leverages a feedback loop based on prediction accuracy to drive gradient-free prompt optimization through the MLM API. For server optimization, we employ an attention mechanism based on semantic similarity to filter all local prompt tokens, along with an embedding distance elbow detection and DBSCAN clustering strategy to enhance the filtering process. Experimental results demonstrate that, compared to state-of-the-art methods, our approach achieves higher accuracy, reduced communication overhead, and robustness to non-iid data in a black-box setting. Moreover, the optimized prompts are transferable.", "title_embedding_index": 466, "title_abs_embedding_index": 491}, {"title": "Learning Phase Representations for Microstructural Segmentation in Metallographic Images through Expert Knowledge", "link_suffix": "/forum?id=5x1Gklb3mf", "link": "https://openreview.net/forum?id=5x1Gklb3mf", "pdf_link": "https://openreview.net/pdf?id=5x1Gklb3mf", "keywords": "Phase Fraction, Microstructure Segmentation, Material Segmentation", "abstract": "Automated segmentation of metallographic images containing multiple phases such as martensite, ferrite, and pearlite is essential for quantifying different phases and thereby helping in the understanding properties of materials. Segmentation of these phases is challenging as they often exhibit overlapping boundaries, similar textures, and other more complexities that require a holistic understanding of the microstructures and correct phase representation within the image. To this end, we propose a novel approach for learning phase representations that captures the subtle differences between phases. Our proposed Phase Learning Module strategically integrates phase ratio information with image encodings to produce ratio-aware features that preserve critical spatial details. Materials scientists can roughly estimate phase ratios by examining an image, and our proposed model leverages this expertise. While we use expert-estimated phase ratios during inference, we train model using accurate phase ratios obtained from target mask images. To our knowledge, this is the first use of class ratios as input in a deep learning segmentation model that serves as constraints to guide consistent phase proportions in predictions. Experimental results demonstrate segmentation performance improvements on both private and public datasets, with our model achieving a 5.65% increase in Dice scores on the private dataset and a 6.48% improvement on the MetalDAM dataset. Furthermore, visualizations show that our approach leads to learning of more distinct and better phase representations across models. The code and private dataset will be made publicly available.", "title_embedding_index": 467, "title_abs_embedding_index": 492}, {"title": "FAN: Fourier Analysis Networks", "link_suffix": "/forum?id=l4jBHP4FPy", "link": "https://openreview.net/forum?id=l4jBHP4FPy", "pdf_link": "https://openreview.net/pdf?id=l4jBHP4FPy", "keywords": "Foundational Model Architecture", "abstract": "Despite the remarkable success achieved by neural networks, particularly those represented by MLP and Transformer, we reveal that they exhibit potential flaws in the modeling and reasoning of periodicity, i.e., they tend to memorize the periodic data rather than genuinely understanding the underlying principles of periodicity. However, periodicity is a crucial trait in various forms of reasoning and generalization, underpinning predictability across natural and engineered systems through recurring patterns in observations. In this paper, we propose FAN, a novel network architecture based on Fourier Analysis, which empowers the ability to efficiently model and reason about periodic phenomena. By introducing Fourier Series, the periodicity is naturally integrated into the structure and computational processes of the neural network, thus achieving a more accurate expression and prediction of periodic patterns. As a promising substitute to multi-layer perceptron (MLP), FAN can seamlessly replace MLP in various models with fewer parameters and FLOPs. Through extensive experiments, we demonstrate the effectiveness of FAN in modeling and reasoning about periodic functions, and the superiority and generalizability of FAN across a range of real-world tasks, including symbolic formula representation, time series forecasting, and language modeling.", "title_embedding_index": 468, "title_abs_embedding_index": 493}, {"title": "TableTextGrad: A Reflexive Framework for Tabuar Understanding", "link_suffix": "/forum?id=9mO9CNgNrh", "link": "https://openreview.net/forum?id=9mO9CNgNrh", "pdf_link": "https://openreview.net/pdf?id=9mO9CNgNrh", "keywords": "Tabular Understanding, Table QA, Prompting", "abstract": "Table understanding is a complex task that requires not only grasping the semantics of free-form questions but also accurately reasoning over semi-structured tables. Recently, promising approaches designed sophisticated prompts that leverage large language models (LLMs) by combining Chain-of-Thought strategies with function calls, consequently demonstrating competitive results without requiring fine-tuning. \nHowever, creating sufficiently effective prompts remains a challenge. Without fine-tuning, all necessary priors must be incorporated directly into the initial prompt, making prompt design even more critical.\nMotivated by the recent advancements in the ''textual gradient'' space, we introduce TableTextGrad, a novel framework that enables automatic prompt optimization by leveraging the ``differentiation'' of prompting pipelines through textual gradients. Concretely, according to the feedback of LLMs, TableTextGrad iteratively refines each function within the Chain-of-Thought steps and function calls, resulting in more accurate and reliable table reasoning outcomes. Experiments on table question-answering datasets demonstrate that our integrated approach achieves significant improvements, setting new state-of-the-art results on both the WikiTableQA and TabFact benchmarks. Our TableTextGrad not only enhances the reasoning capabilities of LLMs in the table reasoning task but also lays a groundwork for more robust and generalizable prompting pipelines due to its simplicity and effectiveness.", "title_embedding_index": 469, "title_abs_embedding_index": 494}, {"title": "Cluster-Driven Adversarial Perturbations for Robust Contrastive Learning", "link_suffix": "/forum?id=rlsWIBDWhW", "link": "https://openreview.net/forum?id=rlsWIBDWhW", "pdf_link": "https://openreview.net/pdf?id=rlsWIBDWhW", "keywords": "adversarial training, contrastive learning, adversarial contrastive learning", "abstract": "Adversarial contrastive learning aims to learn a representation space robust to adversarial inputs using only unlabeled data. Existing methods typically generate adversarial perturbations by maximizing the contrastive loss during adversarial training. However, we find that the effectiveness of this approach is influenced by the composition of positive and negative examples in a minibatch, which is not explicitly controllable. To address this limitation, we propose a novel approach to adversarial contrastive learning, where adversarial perturbations are generated based on the clustering structure of the representation space learned through contrastive learning. Our method is motivated by the observation that contrastive learning produces a well-separated representation space, where similar data points cluster together in space, while dissimilar ones are positioned farther apart. We hypothesize that perturbations directed toward neighboring (the second nearest to be specific) clusters are likely to cross the decision boundary of a downstream classifier built upon contrastive learning, effectively acting as adversarial examples. A key challenge in our approach is to determine a sufficiently large number of clusters, for which the number of classes in the downstream task would serve the purpose but is typically unknown during adversarial contrastive learning. Therefore, we employ the silhouette score to identify the optimal number of clusters, ensuring high-quality clustering in the representation space. Compared to the existing approaches, our method achieved up to $2.25$% and $5.05$% improvements in robust accuracy against PGD and Auto-Attack, respectively, showing slight improvement in standard accuracy as well in most cases.", "title_embedding_index": 470, "title_abs_embedding_index": 495}, {"title": "Geometric and Physical Constraints Synergistically Improve Neural PDE Integration", "link_suffix": "/forum?id=gz8Rr1iuDK", "link": "https://openreview.net/forum?id=gz8Rr1iuDK", "pdf_link": "https://openreview.net/pdf?id=gz8Rr1iuDK", "keywords": "Geometric deep learning, physics-constrained neural networks, PDE integration", "abstract": "Recent advances in neural PDE integration show considerable promise in outperforming cost-accuracy tradeoffs of classical numerical methods. However, neural methods often generalize poorly to initial conditions and long integration times beyond the range of the training data, so that accuracy, stability and physical consistency are not guaranteed by low training loss. Generalization can be improved by inductive biases that constrain the neural network to satisfy properties of the integrated PDE, and here we focus on two such properties: symmetry equivariance and physical conservation laws. To impose these as hard constraints, we introduce novel input and output layers, extending equivariant convolutions and conservative updates for the first time to scalar and vector fields on the staggered grids common in computational fluid dynamics. We then systematically investigate how various symmetries and conservation laws, alone and in combination, affect PDE integration accuracy. We test these strategies on two challenging 2D tasks: the shallow water equations with closed boundaries and decaying incompressible turbulence. Comparing to a strong modern U-net baseline, we observe that both constraint types improve performance robustly across integration times, accuracy measures and network sizes. We find that symmetries are more effective but do not make physical constraints redundant, as optimal performance  was achieved by combining both synergistically. The resulting doubly-constrained networks accurately integrated PDEs using lower parameter counts and smaller training datasets, and generalized better to initial conditions and time durations beyond the range of training data.", "title_embedding_index": 471, "title_abs_embedding_index": 496}, {"title": "Quantum-PEFT: Ultra parameter-efficient fine-tuning", "link_suffix": "/forum?id=dgR6i4TSng", "link": "https://openreview.net/forum?id=dgR6i4TSng", "pdf_link": "https://openreview.net/pdf?id=dgR6i4TSng", "keywords": "parameter-efficient fine-tuning, lora, quantum machine learning, orthogonality constraints", "abstract": "This paper introduces Quantum-PEFT that leverages quantum computations for parameter-efficient fine-tuning (PEFT). Unlike other additive PEFT methods, such as low-rank adaptation (LoRA), Quantum-PEFT exploits an underlying full-rank yet surprisingly parameter efficientquantum unitary parameterization. With the use of Pauli parameterization, the number of trainable parameters grows only logarithmically with the ambient dimension, as opposed to linearly as in LoRA-based PEFT methods. Quantum-PEFT achieves vanishingly smaller number of trainable parameters than the lowest-rank LoRA as dimensions grow, enhancing parameter efficiency while maintaining a competitive performance. We apply Quantum-PEFT to several transfer learning benchmarks in language and vision, demonstrating significant advantages in parameter efficiency.", "title_embedding_index": 472, "title_abs_embedding_index": 497}, {"title": "Generate explorative goals with large language model guidance", "link_suffix": "/forum?id=hCfhfwSfCg", "link": "https://openreview.net/forum?id=hCfhfwSfCg", "pdf_link": "https://openreview.net/pdf?id=hCfhfwSfCg", "keywords": "Reinforcement Learning, Large Language Models, Goal-Conditioned RL, Exploration, Model-baed Reinforcement Learning", "abstract": "Reinforcement learning (RL) struggles with sparse reward environments.\nRecent developments in intrinsic motivation have revealed the potential of language models to guide agents in exploring the environment.\nHowever, the mismatch between the granularity of environment transitions and natural language descriptions hinders effective exploration for current methods.\nTo address this problem, we introduce a model-based RL method named Language-Guided Explorative Goal Generation (LanGoal), which combines large language model (LLM) guidance with intrinsic exploration reward by learning to propose meaningful goals.\nLanGoal learns a hierarchical policy together with a world model. The high-level policy learns to propose  goals based on LLM guidance to explore the environment, and the low-level policy learns to achieve the goals.\nExtensive results on Crafter demonstrate the effectiveness of LanGoal compared to recent methods.", "title_embedding_index": 473, "title_abs_embedding_index": 498}, {"title": "How Well Can LLMs Synthesize Molecules? An LLM-Powered Framework for Multi-Step Retrosynthesis", "link_suffix": "/forum?id=b89OyrljJD", "link": "https://openreview.net/forum?id=b89OyrljJD", "pdf_link": "https://openreview.net/pdf?id=b89OyrljJD", "keywords": "Chemistry, Retrosynthesis Planning, LLM", "abstract": "Predicting retrosynthesis routes is a fundamental challenge in chemistry, involving the design of a sequence of chemical reactions to synthesize a target molecule from commercially available starting materials. With a rapidly\ngrowing interest in using large language models for planning, this work introduces an LLM-powered framework for multi-step retrosynthesis. Our framework employs molecular-similarity-based retrieval-augmented generation (RAG) to generate an initial retrosynthesis route, which is then iteratively refined through expert feedback. The use of molecular-similarity-based RAG improves reaction round-trip validity from 24.42% to 51.64% compared to GPT-4 with representative routes. With further refinement, the validity increases to 89.81%, resulting in an overall route validity of 79.5% with a perfect query success rate, comparable to traditional methods. Our framework offers a flexible, customizable approach to retrosynthesis, and we present a comprehensive analysis of the generated routes along with promising future research directions in LLM-driven multi-step retrosynthesis.", "title_embedding_index": 474, "title_abs_embedding_index": 499}]
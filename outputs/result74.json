[
    {
        "title": "Learning Representations for Independence Testing",
        "link_suffix": "/forum?id=PPxyXlCAOJ",
        "link": "https://openreview.net/forum?id=PPxyXlCAOJ",
        "pdf_link": "https://openreview.net/pdf?id=PPxyXlCAOJ",
        "keywords": "Kernel methods, Hypothesis testing, Independence testing",
        "abstract": "Many tools exist that attempt to detect dependence between random variables, a core question across a wide range of machine learning, statistical, and scientific endeavors. Although several statistical tests guarantee eventual detection of any dependence with enough samples, standard tests may require an exorbitant amount of samples for detecting subtle dependencies between high-dimensional random variables with complex distributions. In this work, we study two related ways to learn powerful independence tests. First, we show how to construct powerful statistical tests with finite-sample validity by using variational estimators of mutual information, such as the InfoNCE or NWJ estimators. Second, we establish a close relationship between these variational mutual information-based tests\nand tests based on the Hilbert-Schmidt Independence Criterion (HSIC), showing that learning a variational bound in the former case\nis closely related to learning kernels, typically parameterized by deep networks, in the latter. Finally, we show how to find a representation that maximizes the asymptotic power of an HSIC test, prove that this procedure works, and demonstrate empirically the practical improvement of our tests (with HSIC tests generally outperforming the variational ones) on difficult problems of detecting structured dependence."
    },
    {
        "title": "GraphFM: A generalist graph transformer that learns transferable representations across diverse domains",
        "link_suffix": "/forum?id=zaxyuX8eqw",
        "link": "https://openreview.net/forum?id=zaxyuX8eqw",
        "pdf_link": "https://openreview.net/pdf?id=zaxyuX8eqw",
        "keywords": "graph transformer, multi-graph training, graph foundation model, node classification",
        "abstract": "Graph neural networks (GNNs) are often trained on individual datasets, requiring specialized models and significant hyperparameter tuning due to the unique structures and features of each dataset. This approach limits the scalability and generalizability of GNNs, as models must be tailored for each specific graph type. To address these challenges, we introduce GraphFM, a scalable multi-graph pretraining approach designed for learning across diverse graph datasets. GraphFM uses a Perceiver-based encoder with learned latent tokens to compress domain-specific features into a shared latent space, enabling generalization across graph domains. We propose new techniques for scaling up graph training on datasets of different sizes, allowing us to train GraphFM on 152 distinct graph datasets, spanning 7.4 million nodes and 189 million edges. This allows us to study the effect of scale on pretraining across domains such as molecules, citation networks, and product graphs, and show that training on diverse datasets improves performance over single-source pretraining. Our results demonstrate that pretraining on diverse real and synthetic graphs enhances adaptability and stability, leading to competitive performance with state-of-the-art models across various node classification tasks. This approach reduces the burden of dataset-specific training and provides a single generalist model capable of performing across multiple diverse graph structures and tasks."
    },
    {
        "title": "NAQ: Nonlinearity-Aware Quantization",
        "link_suffix": "/forum?id=EWiWMoynco",
        "link": "https://openreview.net/forum?id=EWiWMoynco",
        "pdf_link": "https://openreview.net/pdf?id=EWiWMoynco",
        "keywords": "transformer, energy, quantization, activation function, gelu, softmax, llm, vision transformer",
        "abstract": "Transformer-based large language models and vision transformers have achieved remarkable performance, but at a high energy cost.\nNonlinearities (e.g., GELU, softmax) have regions where the magnitude of the gradient is small, which means that errors in pre-nonlinearity inputs result in small output error.\nWe propose Nonlinearity-Aware Quantization (NAQ), which involves computing the FC layer outputs and attention scores at low precision, predicting the magnitude of the gradient of the nonlinearity, and recomputing the pre-nonlinearity if the gradient magnitude is large.\nWith future hardware support, models with NAQ would avoid up to 62% of full precision pre-nonlinearity computation and it would achieve up to 29% reduction in energy consumption, with small effects on model performance."
    },
    {
        "title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?",
        "link_suffix": "/forum?id=wSErgkwDZO",
        "link": "https://openreview.net/forum?id=wSErgkwDZO",
        "pdf_link": "https://openreview.net/pdf?id=wSErgkwDZO",
        "keywords": "Multimodel Large Language Models, Language and Vision",
        "abstract": "As the capabilities of Multimodal Large Language Models (MLLMs) continue to improve, the need for higher-order capability evaluation of MLLMs is increasing. However, there is a lack of work evaluating MLLM for higher-order perception and understanding of Chinese visual content.\nTo fill the gap, we introduce theChineseImageImplication understandingBenchmark,CII-Bench, which aims to assess the higher-order perception and understanding capabilities of MLLMs for Chinese images. \nCII-Bench stands out in several ways compared to existing benchmarks. Firstly, to ensure the authenticity of the Chinese context, images in CII-Bench are sourced from the Chinese Internet and manually reviewed, with corresponding answers also manually crafted. Additionally, CII-Bench incorporates images that represent Chinese traditional culture, such as famous Chinese traditional paintings, which can deeply reflect the model's understanding of Chinese traditional culture.\nThrough extensive experiments on CII-Bench across multiple MLLMs, we have made significant findings. \nInitially, a substantial gap is observed between the performance of MLLMs and humans on CII-Bench. The highest accuracy of MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an impressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional culture images, suggesting limitations in their ability to understand high-level semantics and lack a deep knowledge base of Chinese traditional culture. Finally, it is observed that most models exhibit enhanced accuracy when image emotion hints are incorporated into the prompts.\nWe believe that CII-Bench will enable MLLMs to gain a better understanding of Chinese semantics and Chinese-specific images, advancing the journey towards expert artificial general intelligence (AGI)."
    },
    {
        "title": "Modeling Abstract Style Prompts for Text-to-Speech Models",
        "link_suffix": "/forum?id=E1DGY1FXef",
        "link": "https://openreview.net/forum?id=E1DGY1FXef",
        "pdf_link": "https://openreview.net/pdf?id=E1DGY1FXef",
        "keywords": "text-to-speech, style, emotion, datasets",
        "abstract": "A recent trend in text-to-speech synthesis (TTS) is to construct models capable of generating naturalistic speech that adheres to a textual style prompt describing the speaker's voice and speaking style. In this paper, we propose a crisper definition of style-controlled TTS by categorizing style tags by how they can be collected (automatictags obtainable using signal processing tools e.g. low-pitched and slow;demographictags obtainable using speaker demographics e.g. male and American accent; andabstracttags which need human-annotations e.g. authoritative and awed) and what they represent (intrinsictags inherent to speaker identity e.g. gender, average pitch, texture; andsituationaltags specific to utterance-level speaking styles e.g. emotion). Compared to previous work, we expand the space of style prompts substantially by covering 47 abstract tags, 10 demographic tags and 6 automatic tags. For abstract intrinsic tags, we annotate a subset of speakers from the VoxCeleb dataset. For abstract situational tags, we leverage existing speaking-style-based datasets Expresso and EARS. We train a style-prompted TTS model based on Parler-TTS using these datasets and find that our model outperforms baselines on speech-style consistency metrics. Our collected dataset and model will be open-sourced."
    },
    {
        "title": "Ad-Hoc Human-AI Coordination Challenge",
        "link_suffix": "/forum?id=Kioojohsuy",
        "link": "https://openreview.net/forum?id=Kioojohsuy",
        "pdf_link": "https://openreview.net/pdf?id=Kioojohsuy",
        "keywords": "multi-agent reinforcement learning, reinforcement learning, multi-agent systems, human-ai coordination, cooperative, challenge paper",
        "abstract": "Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is an established, fully cooperative benchmark environment that involves imperfect information, limited communication, theory of mind, and the necessity for coordination among agents to achieve a shared goal. These characteristics, in principle, make Hanabi an ideal testbed for exploring human-AI coordination. However, one key issue is that evaluation with human partners is both expensive and difficult to reproduce. To address this, we first develop \\textit{human proxy agents} via a combination of behavioural cloning on a large-scale dataset of human game play and regularised reinforcement learning. These proxies serve as robust, cheap and reproducible human-like evaluation partners in our Ad-Hoc Human-AI Coordination Challenge (AH2AC2). To facilitate the exploration of methods that leverage \\textit{limited amounts} of human data, we introduce two data-limited challenge settings, using 1,000 and 5,000 games, which we open-source. Finally, we provide baselines for each challenge variety. These include zero-shot coordination methods, which do not utilise any human data, and methods that make use of the available human data combined with reinforcement learning. To prevent overfitting and ensure fair evaluation, we introduce an evaluation protocol that involves us hosting the proxy agents rather than publicly releasing them, and a public leaderboard for tracking the progress of the community. We make our code available as an anonymous repository: \\url{https://anonymous.4open.science/r/ah2ac2-E451/}"
    },
    {
        "title": "Stick-breaking Attention",
        "link_suffix": "/forum?id=r8J3DSD5kF",
        "link": "https://openreview.net/forum?id=r8J3DSD5kF",
        "pdf_link": "https://openreview.net/pdf?id=r8J3DSD5kF",
        "keywords": "transformer, attention, stick-breaking, softmax, length extrapolation",
        "abstract": "The Transformer architecture's self-attention mechanism traditionally relies on the softmax operator, necessitating positional embeddings like RoPE, or position biases to account for token order.\nBut current methods still face length generalisation challenges.\nWe propose an alternative attention mechanism based on the stick-breaking process:\nFor each token before the current, we determine a break point $\\beta_{i,j}$, which represents the proportion of the remaining stick to allocate to the current token.\nWe repeat the process until the stick is fully allocated, resulting in a sequence of attention weights.\nThis process naturally incorporates recency bias, which has linguistic motivations for grammar parsing (Shen et. al. 2017).\nWe study the implications of replacing the conventional softmax-based attention mechanism with stick-breaking attention.\nWe then discuss implementation of numerically stable stick-breaking attention and adapt Flash Attention to accommodate this mechanism.\nWhen used as a drop-in replacement for current softmax+RoPE attention systems, we find that stick-breaking attention performs competitively with current methods on length generalisation and downstream tasks.\nStick-breaking also performs well at length generalisation, allowing a model trained with $2^{11}$ context window to perform well at $2^{14}$ with perplexity improvements."
    },
    {
        "title": "Learning with Preserving for Continual Multitask Learning",
        "link_suffix": "/forum?id=CAgIwCbnQI",
        "link": "https://openreview.net/forum?id=CAgIwCbnQI",
        "pdf_link": "https://openreview.net/pdf?id=CAgIwCbnQI",
        "keywords": "continual learning, continual multitask learning, representation learning, knowledge distillation",
        "abstract": "Artificial Intelligence (AI) is driving advancements in many fields, enabling previously unattainable capabilities. Intelligent systems are increasingly incorporating more detailed tasks, such as enhancing tumor classification with tissue recognition or expanding driving assistance with lane detection. Typically, new tasks are integrated by training single-task models or re-training multi-task models, which proves impractical when previous data is unavailable or new data is limited. This paper introduces a novel problem category—continual multitask learning (CMTL)—crucial for future intelligent systems and largely overlooked in current research. CMTL presents unique challenges that traditional Continual Learning (CL) or Multitask Learning (MTL) methods are unable to address effectively. Therefore, we introduce Learning with Preserving (LwP), a novel approach for CMTL that maintains previously learned knowledge in a way that remains beneficial across diverse tasks. LwP employs a Dynamically Weighted Distance Preservation (DWDP) loss function to uphold the integrity of the representation space, ensuring it is conducive to learning both prior and future tasks without relying on a replay buffer. We extensively evaluate LwP on three benchmark datasets across two modalities—IMU sensing data for exercise quality assessment and image datasets. Results show that LwP outperforms existing continual learning baselines and effectively mitigates catastrophic forgetting, highlighting its robustness and generalizability in CMTL scenarios."
    },
    {
        "title": "FlowDec: A flow-based full-band general audio codec with high perceptual quality",
        "link_suffix": "/forum?id=uxDFlPGRLX",
        "link": "https://openreview.net/forum?id=uxDFlPGRLX",
        "pdf_link": "https://openreview.net/pdf?id=uxDFlPGRLX",
        "keywords": "audio, audio codec, generative models, flow matching, postfilter, signal enhancement",
        "abstract": "We propose FlowDec, a neural full-band audio codec for general audio sampled at 48 kHz that combines non-adversarial codec training with a stochastic postfilter based on a novel conditional flow matching method. Compared to the prior work ScoreDec which is based on score matching, we generalize from speech to general audio and move from 24 kbit/s to as low as 4 kbit/s, while improving output quality and reducing the required postfilter DNN evaluations from 60 to 6 without any fine-tuning or distillation techniques. We provide theoretical insights and geometric intuitions for our approach in comparison to ScoreDec as well as another recent work that uses flow matching, and conduct ablation studies on our proposed components. We show that FlowDec is a competitive alternative to the recent GAN-dominated stream of neural codecs, achieving FAD scores better than those of the established GAN-based codec DAC and listening test scores that are on par, and producing qualitatively more natural reconstructions for speech and harmonic structures in music."
    },
    {
        "title": "End-to-end Learning of Gaussian Mixture Priors for Diffusion Sampler",
        "link_suffix": "/forum?id=iXbUquaWbl",
        "link": "https://openreview.net/forum?id=iXbUquaWbl",
        "pdf_link": "https://openreview.net/pdf?id=iXbUquaWbl",
        "keywords": "Variational Inference, Sampling, Diffusion Models, Mixture Models",
        "abstract": "Diffusion models optimized via variational inference (VI) have emerged as a promising tool for generating samples from unnormalized target densities. These models create samples by simulating a stochastic differential equation, starting from a simple, tractable prior, typically a Gaussian distribution. However, when the support of this prior differs greatly from that of the target distribution, diffusion models often struggle to explore effectively or suffer from large discretization errors. Moreover, learning the prior distribution can lead to mode-collapse, exacerbated by the mode-seeking nature of reverse Kullback-Leibler divergence commonly used in VI.\nTo address these challenges, we propose end-to-end learnable Gaussian mixture priors (GMPs). GMPs offer improved control over exploration, adaptability to target support, and increased expressiveness to counteract mode collapse. We further leverage the structure of mixture models by proposing a strategy to iteratively refine the model through the addition of mixture components during training. Our experimental results demonstrate significant performance improvements across a diverse range of real-world and synthetic benchmark problems when using GMPs without requiring additional target evaluations."
    },
    {
        "title": "Hierarchical Self-Attention: Generalizing Neural Attention Mechanics to Hierarchy",
        "link_suffix": "/forum?id=qODJnX99hi",
        "link": "https://openreview.net/forum?id=qODJnX99hi",
        "pdf_link": "https://openreview.net/pdf?id=qODJnX99hi",
        "keywords": "Attention Mechanism, Transformers, Hierarchical Data, Multi-modal Data, Geometric Deep Learning",
        "abstract": "Transformers and their attention mechanism have been revolutionary in the field of Machine Learning. While originally proposed for the language data, they quickly found their way to the image, video, graph, etc. data modalities with various signal geometries. Despite this versatility, generalizing the attention mechanism to scenarios where data is presented at different scales from potentially different modalities is not straightforward. The attempts to incorporate hierarchy and multi-modality within transformers are largely based on ad hoc heuristics, which are not seamlessly generalizable to similar problems with potentially different structures. To address this problem, in this paper, we take a fundamentally different approach: we first propose a mathematical construct to represent multi-modal, multi-scale data. We then mathematically derive the neural attention mechanics for the proposed construct from the first principle of entropy minimization. We show that the derived formulation is optimal in the sense of being the closest to the standard Softmax attention while incorporating the inductive biases originating from the hierarchical/geometric information of the problem. We further propose an efficient algorithm based on dynamic programming to compute our derived attention mechanism. By incorporating it within transformers, we show that the proposed hierarchical attention mechanism not only can be employed to train transformer models in hierarchical/multi-modal settings from scratch, but it can also be used to inject hierarchical information into classical, pre-trained transformer models post training, resulting in more efficient models in zero-shot manner."
    },
    {
        "title": "FocalLens: Instruction Tuning Enables Zero-Shot Conditional Image Representations",
        "link_suffix": "/forum?id=3fGwTRRudc",
        "link": "https://openreview.net/forum?id=3fGwTRRudc",
        "pdf_link": "https://openreview.net/pdf?id=3fGwTRRudc",
        "keywords": "Conditional Image Representation, Instruction tuning, Contrastive Learning, Vision-Language Models",
        "abstract": "Visual feature extraction is fundamental to many vision tasks. Most existing methods extract visual features by encoding an image into a generic feature vector. However, an image naturally contains rich information, and there may be multiple perspectives to describe it. For each application, we might be interested in different aspects of an image and want to prioritize those features over others. For instance, in an image of a dog carrying a toy, if we are primarily interested in the dog, we would expect the extracted features to emphasize the dog over the toy. In this work, we introduce FocalLens, a conditional visual feature extraction method that produces different representations for the same image based on the context of interest, expressed flexibly through natural language. We leverage vision instruction tuning data and contrastively tune a pretrained vision encoder to take natural language instructions as additional inputs and produce conditional image representations. Extensive experiments validate that conditional image representation from FocalLens better pronounce the visual features of interest compared to generic features produced by standard vision encoders like CLIP. In addition, we show FocalLens further leads to performance improvements on a range of downstream tasks including image-image retrieval, image classification, and image-text retrieval, with an average gain of 5 and 10 points on the challenging SugarCrepe and MMVP-VLM benchmarks, respectively."
    },
    {
        "title": "A biologically-plausible alternative to backpropagation using pseudoinverse feedback",
        "link_suffix": "/forum?id=B5Dj4EhZPP",
        "link": "https://openreview.net/forum?id=B5Dj4EhZPP",
        "pdf_link": "https://openreview.net/pdf?id=B5Dj4EhZPP",
        "keywords": "biologically-plausible learning rules, Newton-like methods, local learning rules",
        "abstract": "Despite its successes in both practical machine learning and neural modelling, the backpropagation algorithm has long been considered biologically implausible (Crick, 1989). Previous solutions to this biological implausibility have proposed the existence of a separate, error feedback network, in which error at the final layer may be propagated backwards to earlier layers in a manner similar to back- propagation. However, biological evidence suggests that feedback connections in the cortex may function more similarly to an autoencoder, rather than being exclusively used as error feedback (Marino, 2020). Here, we attempt to unify these two paradigms by showing how autoencoder-like, inverse feedback connections may be used to minimize error throughout a feedforward neural network. Furthermore, we show that in the MNIST and CIFAR-10 classification tasks, an asymptotic error comparable to backpropagation can be achieved in fewer iterations than comparable biologically-plausible algorithms, such as Random Target Propagation (Lillicrap et al., 2014). Our proposed mechanism, Reciprocal Feedback, consists of two contributions: first we show how a modification of the Recirculation algorithm (Hinton E. & McClelland, 1988) is capable of learning the Moore-Penrose pseudoinverse of a pair of network weights. Then, we will show how, using the Hildebrandt-Graves Theorem (Hildebrandt & Graves, 1927), locally-learned pseudoinverse feedback connections may be used to facilitate an alternative optimization method to traditional gradient descent - while alleviating the need to compute the weight transpose."
    },
    {
        "title": "IterGen: Iterative Structured LLM Generation",
        "link_suffix": "/forum?id=ac93gRzxxV",
        "link": "https://openreview.net/forum?id=ac93gRzxxV",
        "pdf_link": "https://openreview.net/pdf?id=ac93gRzxxV",
        "keywords": "LLM, Grammar, Formal Languages, Parser, Decoding",
        "abstract": "Large Language Models (LLMs) are widely used for tasks such as natural language and code generation, but their outputs often suffer from issues like hallucination, toxicity, and incorrect results. \nCurrent libraries for structured LLM generation rely on left-to-right decoding without support for backtracking, limiting the ability to correct or refine outputs mid-generation. \nTo address this, we introduce IterGen, a user-friendly library for iterative, grammar-guided LLM generation that enables users to move both forward and backward within the generated output based on grammar symbols. \nBy leveraging a symbol-to-position mapping and maintaining the key-value (KV) cache state, IterGen ensures efficient and structured generation while allowing for corrections during the process. \nWe demonstrate IterGen's effectiveness in two applications: reducing privacy leakage in LLM outputs and improving the accuracy of LLM-generated SQL queries."
    },
    {
        "title": "Reward Learning From Preference With Ties",
        "link_suffix": "/forum?id=fTdhM7q1o2",
        "link": "https://openreview.net/forum?id=fTdhM7q1o2",
        "pdf_link": "https://openreview.net/pdf?id=fTdhM7q1o2",
        "keywords": "reward learning, RLHF, preference modeling, language model",
        "abstract": "Reward learning plays a pivotal role in Reinforcement Learning from Human Feedback (RLHF), ensuring the alignment of language models. The Bradley-Terry (BT) model stands as the prevalent choice for capturing human preferences from datasets containing pairs of chosen and rejected responses. In preference modeling, the focus is not on absolute values but rather on the reward difference between chosen and rejected responses, referred to as preference strength. Thus, precise evaluation of preference strength holds paramount importance in preference modeling. However, an easily overlooked factor significantly affecting preference strength measurement is that human attitudes towards two responses may not solely indicate a preference for one over the other and ties are also a common occurrence. To address this, we propose the adoption of the generalized Bradley-Terry model -- the Bradley-Terry model with ties (BTT) -- to accommodate tied preferences, thus leveraging additional information. We prove that even with the access to the true distributions of prompt and response, disregarding ties can lead to a notable bias in preference strength measurement. Comprehensive experiments further validate the advantages of incorporating ties in preference modeling. Notably, fine-tuning with BTT significantly outperforms fine-tuning with BT on synthetic preference datasets with ties, labeled by state-of-the-art open-source LLMs."
    },
    {
        "title": "OpenPRM: Building Open-domain Process-based Reward Models with Preference Trees",
        "link_suffix": "/forum?id=fGIqGfmgkW",
        "link": "https://openreview.net/forum?id=fGIqGfmgkW",
        "pdf_link": "https://openreview.net/pdf?id=fGIqGfmgkW",
        "keywords": "large language models, reward models, open-domain instruction following",
        "abstract": "Scaling inference-time computation is increasingly seen as the next frontier in scaling laws for large language models. Previous work in mathematics and coding has demonstrated the remarkable potential for inference-time scaling. During such scaling, fine-grained supervision through process-based reward models (PRMs) is essential for enhancement. However, exploration of inference-time scaling and PRMs in open-domain problems remains limited, where lacking exact answers and obtaining process supervision prove challenging. In this paper, we explore the construction of PRMs for open-domain tasks, specifically for instruction-following tasks. Utilizing existing outcome-based reward models (ORMs), we develop sentence-level preference trees based on the prefix similarity of parallel sampled candidates from datasets like UltraFeedback. This setup allows us to derive weak supervision for processes via back-propagation from outcome-level rewards. Subsequently, we integrate ORMs and PRMs under the same pairwise ranking objectives, resulting in our newly developed reward models, named OpenPRM. This approach significantly enhances the scalability of process-level supervision in open domains at minimal cost. We assess the performance of OpenPRM across various reward benchmarks, demonstrating its competitive edge over traditional ORMs in open domains and PRMs in specialized domains. Additionally, we investigate the scalability of inference-time computation for open-domain instructions. Our results highlight the limitations of ORMs’ scalability, while OpenPRM shows superior performance in scaled settings. Despite these advances, achieving  automatic fine-grained supervision for open-domain inference-time scaling remains a substantial challenge. We hope these findings will spur further development of process supervision reward models in open-domain scenarios."
    },
    {
        "title": "Bi-continuous and complete SE(2)-invariants parametrize all clouds of unordered points",
        "link_suffix": "/forum?id=jOVfFAxBf6",
        "link": "https://openreview.net/forum?id=jOVfFAxBf6",
        "pdf_link": "https://openreview.net/pdf?id=jOVfFAxBf6",
        "keywords": "point cloud, rigid motion, isometry, complete invariant, continuous metric, molecule",
        "abstract": "The most basic form of a rigid object is a cloud of unordered points, for example, a set of corners or other salient features. The rigid shape of a point cloud in the Euclidean plane is its SE(2)-equivalence class under rigid motion (a composition of translations and rotations). We introduce complete invariants (with no false negatives, no false positives) and a bi-Lipschitz continuous metric that satisfies all axioms, provides a 1-1 matching between points in clouds, and is computable in a quadratic time of the number $m$ of points.  The realizability property implies that the space of all rigid clouds is efficiently parametrized by vectorial invariants like geographic coordinates. The new invariants justified that any of 130K+ molecules in the QM9 database is uniquely determined by the rigid shape of its atomic cloud."
    },
    {
        "title": "Roll-AE: A Spatiotemporal Invariant Autoencoder for Neuronal Electro-Physiology",
        "link_suffix": "/forum?id=w6mjerkePG",
        "link": "https://openreview.net/forum?id=w6mjerkePG",
        "pdf_link": "https://openreview.net/pdf?id=w6mjerkePG",
        "keywords": "autoencoder, electrophysiology, self-supervised learning",
        "abstract": "Micro-electrode array (MEA) assays enable high-throughput recording of the electrophysiological activity in biological tissues, both in vivo and in vitro. While various classical and deep learning models have been developed for MEA signal analysis, the majority focus on in vivo experiments or specific downstream applications in vitro. Consequently, extracting relevant features from in vitro MEA recordings has remained largely dependent on particular curated features known as neural metrics. In this work, we introduce Roll-AE, a novel autoencoder designed to extract spatiotemporally invariant features from in vitro MEA recordings. Roll-AE serves as a foundational model that facilitates a wide range of downstream tasks. We demonstrate that 1) Roll-AE's embeddings outperform those from standard autoencoders across various classification tasks, and 2) Roll-AE's embeddings effectively characterize electrophysiological phenotypic traits in induced Pluripotent Stem Cells (iPSC)-derived neuronal cultures."
    },
    {
        "title": "Privacy Preserving Generative Feature Transformation",
        "link_suffix": "/forum?id=KtqBAGO6eu",
        "link": "https://openreview.net/forum?id=KtqBAGO6eu",
        "pdf_link": "https://openreview.net/pdf?id=KtqBAGO6eu",
        "keywords": "Data-Centric AI, Privacy-Preserving, Generative Model",
        "abstract": "Data-Centric AI (DCAI) aims to use AI to get better data for better AI. Feature transformation, as one of the essential tasks of DCAI, can augment the data representation and has garnered significant attention. Existing methods have demonstrated state-of-the-art performance on advancing predictive tasks. However, these methods can lead to serious privacy leakage. For example, sensitive features in original data can be inferred by models trained on transformed data, exposing vulnerabilities in the privacy-preserving capabilities of these methods. To address this issue, we introduce a privacy-preserving feature transformation framework that transforms data representation while preserving privacy from a generative modeling perspective. Specifically, our framework includes two phases: 1) privacy-aware knowledge acquisition and 2) privacy-preserving feature space generation. In the knowledge acquisition phase, we develop an information bottlenecks guided reinforcement learning system to explore and collect privacy-aware feature sets as a knowledge base in token sequence form. In the feature space generation phase, we develop a generative model to encode the knowledge base into a privacy-aware latent space, where the best latent representation is identified and decoded into the optimal privacy-preserving feature space. We solve the optimization via projected gradient ascent that maximizes predictive performance and minimizes privacy exposure. Finally, we present extensive experiments on eight real-world datasets to evaluate how our method can navigate both performance and privacy. The code is available athttps://anonymous.4open.science/r/anonymous-2B53/."
    },
    {
        "title": "Solving Composable Constraints for Inverse Design Tasks",
        "link_suffix": "/forum?id=M2g647Femt",
        "link": "https://openreview.net/forum?id=M2g647Femt",
        "pdf_link": "https://openreview.net/pdf?id=M2g647Femt",
        "keywords": "Inverse Design, Conditional Generation, Constrained Optimization, Deep Learning, Neural Networks, Signed Distance Functions",
        "abstract": "Inverse design tasks are an important category of problem in which we want to identify some input vector $x$ satisfying some desirable properties. In this paper we propose a mechanism for representing inequality constraints as Signed Distance Functions (SDFs). SDFs permit efficient projection of points into the solution region as well as providing a mechanism for composing constraints via boolean set operations. In this paper, we provide theoretical motivation for Signed Distance Functions (SDFs) as an implicit representation of inequality constraints. Next, we provide analysis demonstrating that SDFs can be used to efficiently project points into solution regions. Additionally, we propose two novel algorithms for computing SDFs for wide families of machine learning models. Finally, we demonstrate practical utility by performing conditional image generation using MNIST and CelebA datasets, and computational drug design using the ZINC-250K dataset. From the experimental results, we note that the composable constraints can reliably and efficiently compute solutions to complex inverse design tasks with deep learning models."
    },
    {
        "title": "Jacobian Descent for Multi-Objective Optimization",
        "link_suffix": "/forum?id=VSogkPlqDS",
        "link": "https://openreview.net/forum?id=VSogkPlqDS",
        "pdf_link": "https://openreview.net/pdf?id=VSogkPlqDS",
        "keywords": "multi-objective optimization, optimization, statistical learning theory, machine learning, deep learning, multi-task learning",
        "abstract": "Many optimization problems require balancing multiple conflicting objectives.\nAs gradient descent is limited to single-objective optimization, we introduce its direct generalization: Jacobian descent (JD).\nThis algorithm iteratively updates parameters using the Jacobian matrix of a vector-valued objective function, in which each row is the gradient of an individual objective.\nWhile several methods to combine gradients already exist in the literature, they are generally hindered when the objectives conflict.\nIn contrast, we propose projecting gradients to fully resolve conflict while ensuring that they preserve an influence proportional to their norm.\nWe prove significantly stronger convergence guarantees with this approach, supported by our empirical results.\nOur method also enables instance-wise risk minimization (IWRM), a novel learning paradigm in which the loss of each training example is considered a separate objective.\nApplied to simple image classification tasks, IWRM exhibits promising results compared to the direct minimization of the average loss.\nAdditionally, we outline an efficient implementation of JD using the Gramian of the Jacobian matrix to reduce time and memory requirements."
    },
    {
        "title": "Bayesian scaling laws for in-context learning",
        "link_suffix": "/forum?id=I4YU0oECtK",
        "link": "https://openreview.net/forum?id=I4YU0oECtK",
        "pdf_link": "https://openreview.net/pdf?id=I4YU0oECtK",
        "keywords": "in-context learning, scaling laws, Bayesian inference, many-shot jailbreaking",
        "abstract": "In-context learning (ICL) is a powerful technique for getting language models to perform complex tasks with no training updates.\nPrior work has established strong correlations between the number of in-context examples provided and the accuracy of the model's predictions.\nIn this paper, we seek to explain this correlation by showing that ICL approximates a Bayesian learner. This perspective gives rise to a family of novel Bayesian scaling laws for ICL.\nIn experiments with GPT-2 models of different sizes, our scaling laws exceed or match existing scaling laws in accuracy while also offering  interpretable terms for task priors, learning efficiency, and per-example probabilities.\nTo illustrate the analytic power that such interpretable scaling laws provide, we report on controlled synthetic dataset experiments designed to inform real-world studies of safety alignment. In our experimental protocol, we use SFT to \nsuppress an unwanted existing model capability and then use ICL to try to bring that capability back (many-shot jailbreaking). We then experiment on real-world instruction-tuned LLMs using  capabilities benchmarks as well as a new many-shot jailbreaking dataset.\nIn all cases, Bayesian scaling laws accurately predict the conditions under which ICL will cause the suppressed behavior to reemerge, which sheds light on the ineffectiveness of post-training at increasing LLM safety."
    },
    {
        "title": "TopoTune: A Framework for Generalized Combinatorial Complex Neural Networks",
        "link_suffix": "/forum?id=2MqyCIxLSi",
        "link": "https://openreview.net/forum?id=2MqyCIxLSi",
        "pdf_link": "https://openreview.net/pdf?id=2MqyCIxLSi",
        "keywords": "Topological Deep Learning, Graph Neural Network, Graph Expansion, Combinatorial Complex, Cellular Complex",
        "abstract": "Graph Neural Networks (GNNs) excel in extracting knowledge from relational datasets, processing node and edge features in a way that preserves the symmetries of the graph domain. However, many complex systems ---such as molecular analysis, or social networks--- involve $n$-body interactions that are more naturally represented by higher-order entities like faces and volumes. Topological Deep Learning (TDL) models, and in particular Combinatorial Complex Neural Networks (CCNNs), accommodate these higher-order structures, thus benefiting from enhanced expressive power over GNNs. However, this emerging field lacks a principled strategy for defining new TDL architectures, restricting its accessibility and applicability. To address this, we introduce a simple yet powerful graph-based methodology capable of systematically transforming any neural network into a novel TDL architecture, which we call \\textit{Generalized CCNN} (GCCN). We prove GCCNs generalize and subsume CCNNs, while extensive experiments on a diverse class of GCCNs show that these architectures consistently match or outperform them, often with less model complexity. In an effort to accelerate and democratize TDL, we introduce TopoTune, a lightweight software allowing practitioners to define, build, and train these most general TDL models with unprecedented flexibility and ease."
    },
    {
        "title": "CycleAug: Cycle-Consistent Visual Augmentation for Large Multimodal Models",
        "link_suffix": "/forum?id=IiRlImvLQI",
        "link": "https://openreview.net/forum?id=IiRlImvLQI",
        "pdf_link": "https://openreview.net/pdf?id=IiRlImvLQI",
        "keywords": "large multimodal models; synthetic data; data augmentation",
        "abstract": "Training multimodal large language models (MLLMs) requires high-quality image-question-answer (IQA) triplets, which are labour-intensive to curate and often lack diversity. We propose a novel data augmentation framework for visual instruction tuning that efficiently generates diverse synthetic images based on existing IQA anchor triplets. To ensure that the generated images align with their associated QA pairs, we propose CycleAug --- cycle-consistency visual augmentation which involves synthesizing images from text (text $\\rightarrow$ image) and then performing a verification step to confirm that the answers derived from the synthetic images match the original answers (image $\\rightarrow$ text), ensuring consistency across images, questions, and answers. By combining synthetic images with high-quality real data in the training phase, we demonstrate these synthetic triplets act as an implicit regularization, which improves the robustness of MLLMs and enables analogical reasoning. Extensive experiments show that our approach improves model performance on multiple visual question-answering benchmarks without additional real-world data. This work highlights the potential of leveraging visual foundational models to enhance visual instruction tuning in MLLMs."
    },
    {
        "title": "Learning In-Distribution Representations for Anomaly Detection",
        "link_suffix": "/forum?id=jQnXDGxdDG",
        "link": "https://openreview.net/forum?id=jQnXDGxdDG",
        "pdf_link": "https://openreview.net/pdf?id=jQnXDGxdDG",
        "keywords": "representation learning, self-supervised learning, anomaly detection, out-of-distribution detection, outlier detection",
        "abstract": "Anomaly detection involves identifying data patterns that deviate from the anticipated norm. Traditional methods struggle in high-dimensional spaces due to the curse of dimensionality. In recent years, self-supervised learning, particularly through contrastive objectives, has driven advances in anomaly detection by generating compact and discriminative feature spaces. However, vanilla contrastive learning faces challenges like class collision, especially when the In-Distribution (ID) consists primarily of normal, homogeneous data, where the lack of semantic diversity leads to increased overlap between positive and negative pairs. Existing methods attempt to address these issues by introducing hard negatives through synthetic outliers, Outlier Exposure (OE), or supervised objectives, though these approaches can introduce additional challenges. In this work, we propose the Focused In-distribution Representation Modeling (FIRM) loss, a novel multi-positive contrastive objective for anomaly detection. FIRM addresses class-collision by explicitly encouraging ID representations to be compact while promoting separation among synthetic outliers. We show that FIRM surpasses other contrastive methods in standard benchmarks, significantly enhancing anomaly detection compared to both traditional and supervised contrastive learning objectives. Our ablation studies confirm that FIRM consistently improves the quality of representations and shows robustness across a range of scoring methods. It performs particularly well in ensemble settings and benefits substantially from using OE. The code is available at \\url{https://anonymous.4open.science/r/firm-8472/}."
    }
]
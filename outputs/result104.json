[{"title": "FrameBridge: Improving Image-to-Video Generation with Bridge Models", "link_suffix": "/forum?id=oOQavkQLQZ", "link": "https://openreview.net/forum?id=oOQavkQLQZ", "pdf_link": "https://openreview.net/pdf?id=oOQavkQLQZ", "keywords": "Image-to-Video Generation, Diffusion Models, Diffusion Bridge Models, Prior Distribution, Data-to-Data Generation", "abstract": "Image-to-video (I2V) generation is gaining increasing attention with its wide application in video synthesis. Recently, diffusion-based I2V models have achieved remarkable progress given their novel design on network architecture, cascaded framework, and motion representation. However, restricted by their noise-to-data generation process, diffusion-based methods inevitably suffer the difficulty to generate video samples with both appearance consistency and temporal coherence from an uninformative Gaussian noise, which may limit their synthesis quality.\nIn this work, we present FrameBridge, taking the given static image as the prior of video target and establishing a tractable bridge model between them. By formulating I2V synthesis as a frames-to-frames generation task and modelling it with a data-to-data process, we fully exploit the information in input image and facilitate the generative model to learn the image animation process.\nIn two popular settings of training I2V models, namely fine-tuning a pre-trained text-to-video (T2V) model or training from scratch, we further propose two techniques, SNR-Aligned Fine-tuning (SAF) and neural prior, which improve the fine-tuning efficiency of diffusion-based T2V models to FrameBridge and the synthesis quality of bridge-based I2V models respectively. \nExperiments conducted on WebVid-2M and UCF-101 demonstrate that: (1) our FrameBridge achieves superior I2V quality in comparison with the diffusion counterpart (zero-shot FVD 83 vs. 176 on MSR-VTT and non-zero-shot FVD 122 vs. 171 on UCF-101); (2) our proposed SAF and neural prior effectively enhance the ability of bridge-based I2V models in the scenarios of fine-tuning and training from scratch. Demo samples can be visited at: \\url{https://framebridgei2v.github.io/}.", "title_embedding_index": 5150, "title_abs_embedding_index": 5175}, {"title": "Preference-based Credit Assignment for Reinforcement Learning with Delayed and Noised Rewards", "link_suffix": "/forum?id=fHNpXyhrTC", "link": "https://openreview.net/forum?id=fHNpXyhrTC", "pdf_link": "https://openreview.net/pdf?id=fHNpXyhrTC", "keywords": "credit assignment, delayed rewards, noised rewards, Preferencece-based Reinforcement Learning, treatment of sepsis", "abstract": "Credit assignment has been utilized as a common technique for determining the past key state-action pairs and assigning corresponding rewards that have strong relevance with the final outputs in reinforcement learning, especially for environments with delayed rewards. However, current reward function design methods rely heavily on domain knowledge and may not accurately reflect the actual reward that should be received, which will lead to noised reward assignments during the credit assignment process and deteriorate the performance of the agent. To address this issue, in this paper, by leveraging the benefits of Preference-based Reinforcement Learning (PbRL), we propose a novel trajectory preference-based credit assignment method, where each trajectory is assigned to one of three different preferences according to its related delayed reward and the entire trajectory space. Then, a causal Transformer framework is introduced to predict the relevance between the decisions at each timestep and the different trajectory preferences to guide the credit assignment. Despite the unavoidable noised reward related to each trajectory, we demonstrate that our method can still effectively guide agents to learn superior strategies. Experiments on the Mujoco task and the treatment of sepsis under extremely delayed reward setting show that our method can mitigate the adverse effects resulting from the delayed noised rewards and provide effective guidelines for agents.", "title_embedding_index": 5151, "title_abs_embedding_index": 5176}, {"title": "Set-Size Dependent Combinatorial Bandits", "link_suffix": "/forum?id=yIbSXuLoO1", "link": "https://openreview.net/forum?id=yIbSXuLoO1", "pdf_link": "https://openreview.net/pdf?id=yIbSXuLoO1", "keywords": "Combinatorial Multi-armed Bandit, Set-Size Dependent, Online learning", "abstract": "This paper introduces and studies a new variant of Combinatorial Multi-Armed Bandits (\\CMAB{}), called Set-Size Dependent Combinatorial Multi-Armed Bandits (\\SDMAB{}). In \\SDMAB{}, each base arm is associated with a set of different reward distributions instead of a single distribution as in \\CMAB{}, and the reward distribution of each base arm depends on the set size, i.e., the number of the base arms in the chosen super arm in \\CMAB{}. \\SDMAB{} involves a much larger exploration set of the super arms than the basic \\CMAB{} model. An important property called order preservation exists in \\SDMAB{}, i.e. the order of reward means of base arms is independent of set size, which widely exists in real-world applications. We propose the \\SUCB{} algorithm, effectively leveraging the order preservation property to shrink the exploration set. We provide theoretical upper bound of $O\\left(\\max\\left{\\frac{M\\delta_L}{\\Delta_{L}},\\frac{L^2}{\\Delta_S}\\right}\\log(T)\\right)$ for \\SUCB{} which outperforms the classic \\CMAB{} algorithms with regret $O\\left(\\frac{ML^2}{\\Delta_S}\\log(T)\\right)$, where $M$ denotes the number of base arms, $L$ denotes the maximum number of base arms in a super arm, $\\delta$ and $\\Delta$ are related to the gap of arms. We also derive a lower bound which can be informally written as $\\Omega\\left(\\max\\left{\\min_{k\\in[L]}\\left{\\frac{(M-L)\\delta_{k}}{\\Delta_{k}^2}\\right},\\frac{L^2}{\\Delta_S}\\right}\\log(T)\\right)$ showing that \\SUCB{} is partially tight. We conduct numerical experiments, showing the good performance of \\SUCB{}.", "title_embedding_index": 5152, "title_abs_embedding_index": 5177}, {"title": "Retri3D: 3D Neural Graphics Representation Retrieval", "link_suffix": "/forum?id=q3EbOXb4y1", "link": "https://openreview.net/forum?id=q3EbOXb4y1", "pdf_link": "https://openreview.net/pdf?id=q3EbOXb4y1", "keywords": "Neural Graphics Representation; 3D Retrieval; Database", "abstract": "Learnable 3D Neural Graphics Representations (3DNGR) have emerged as promising 3D representations for reconstructing 3D scenes from 2D images. Numerous works, including Neural Radiance Fields (NeRF), 3D Gaussian Splatting (3DGS), and their variants, have significantly enhanced the quality of these representations. The ease of construction from 2D images, suitability for online viewing/sharing, and applications in game/art design downstream tasks make it a vital 3D representation, with potential creation of large numbers of such 3D models. This necessitates large data stores, local or online, to save 3D visual data in these formats. However, no existing framework enables accurate retrieval of stored 3DNGRs. In this work, we propose, Retri3D, a framework that enables accurate and efficient retrieval of 3D scenes represented as NGRs from large data stores using text queries. We introduce a novel Neural Field Artifact Analysis technique, combined with a Smart Camera Movement Module, to select clean views and navigate pre-trained 3DNGRs. These techniques enable accurate retrieval by selecting the best viewing directions in the 3D scene for high-quality visual feature embeddings. We demonstrate that Retri3D is compatible with any NGR representation. On the LERF and ScanNet++ datasets, we show significant improvement in retrieval accuracy compared to existing techniques, while being orders of magnitude faster and storage efficient.", "title_embedding_index": 5153, "title_abs_embedding_index": 5178}, {"title": "Decoupling Angles and Strength in Low-rank Adaptation", "link_suffix": "/forum?id=X1U74IwuxG", "link": "https://openreview.net/forum?id=X1U74IwuxG", "pdf_link": "https://openreview.net/pdf?id=X1U74IwuxG", "keywords": "parameter efficient finetuning, transfer learning, computer vision, NLP", "abstract": "Parameter Efficient Fine-Tuning (PEFT) methods have recently gained extreme popularity thanks to the vast availability of large-scale models, allowing to quickly adapt pretrained models to downstream tasks with minimal computational costs.\nHowever, current additive finetuning methods such as LoRA show low robustness to prolonged training and hyperparameter choices, not allowing for optimal out-of-the-box usage. On the other hand, multiplicative and bounded approaches such as ETHER, even if providing higher robustness only allows for extremely low-rank adaptations and are limited to a fixed-strength transformation, hindering the expressive power of the adaptation. In this work, we propose a novel Decoupled Fine-Tuning (DeFT) paradigm that consists in decoupling the weight transformation strength from the angular information. We effectively show this proposed approach improves over two current PEFT methods, namely LoRA and ETHER. Integrating DeFT with LoRA normalizes and scales the learnable low-rank matrices and integrating with DeFT with ETHER allows for greater expressivity by increasing the rank of the updates, and by controlling the transformation boundaries. Code will be released upon acceptance.", "title_embedding_index": 5154, "title_abs_embedding_index": 5179}, {"title": "Prediction of Protein-protein Contacts with Structure-aware Single-sequence Protein Language Models", "link_suffix": "/forum?id=wCwz1F8qY8", "link": "https://openreview.net/forum?id=wCwz1F8qY8", "pdf_link": "https://openreview.net/pdf?id=wCwz1F8qY8", "keywords": "Protein bioinformatics, Protein language models, Protein-protein contact prediction, Protein representations, Deep neural networks", "abstract": "Accurate prediction of the interface residue-residue contacts between interacting proteins is valuable for determining the structure and function of protein complexes. Recent deep learning methods have drastically improved the accuracy of predicting the interface contacts of protein complexes. However, existing methods rely on Multiple Sequence Alignments (MSA) features which pose limitations on prediction accuracy, speed, and computational efficiency. Here, we propose a transformer-powered deep learning method to predict the inter-protein residue-residue contacts based on both single-sequence and structure-aware protein language models (PLM), called DeepSSInter. Utilizing the intra-protein distance and graph representations and the ESM2 and SaProt protein language models, we are able to generate the structure-aware features for the protein receptor, ligand, and complex. These structure-aware features are passed into the Resnet Inception module and the Triangle-aware module to effectively produce the predicted inter-protein contact map. Extensive experiments on both homo- and hetero-dimeric complexes show that our DeepSSInter model significantly improves the performance compared to previous state-of-the-art methods.", "title_embedding_index": 5155, "title_abs_embedding_index": 5180}, {"title": "Learning the Partially Dynamic Travelling Salesman Problem", "link_suffix": "/forum?id=NIhRwzqhUz", "link": "https://openreview.net/forum?id=NIhRwzqhUz", "pdf_link": "https://openreview.net/pdf?id=NIhRwzqhUz", "keywords": "Reinforcement Learning, Graph Neural Networks, Dynamic Graphs, Dynamic Graph Neural Networks, Travelling Salesman Problem, Combinatorial Optimisation", "abstract": "Learning to solve the Travelling Salesman Problem (TSP) using Deep Reinforcement Learning (Deep RL) and Graph Neural Networks (GNNs) has shown promising results for small instances of the problem. We demonstrate that these methods can be extended to solve instances of a partially dynamic variant of the TSP. Solving this partially dynamic variant more effectively exploits the strengths of reinforcement learning and also presents challenges for more established methods of solving the TSP. We show the policies trained using Deep RL outperform modified versions of TSP solvers and heuristics for different distributions of dynamic vertices, including on larger instances than the policies were trained on. This shows the promise of Deep RL for solving this type of dynamic routing problem which is predicted to become of great importance as logistical services become more flexible and responsive to customer demand. Furthermore, our method is a general purpose approach to Deep RL where the problem consists of selecting items from a dynamically-evolving and arbitrarily-sized set.", "title_embedding_index": 5156, "title_abs_embedding_index": 5181}, {"title": "Counterfactual fairness prediction:  Consistent estimation with generative models and theoretical guarantees", "link_suffix": "/forum?id=cPjBTj1Qf5", "link": "https://openreview.net/forum?id=cPjBTj1Qf5", "pdf_link": "https://openreview.net/pdf?id=cPjBTj1Qf5", "keywords": "Counterfactual, Causal inference, Counterfactual fairness, Generative models", "abstract": "Fairness in predictions is of direct importance in practice due to legal, ethical, and societal reasons. This is often accomplished through counterfactual fairness, which ensures that the prediction for an individual is the same as that in a counterfactual world under a different sensitive attribute. However, achieving counterfactual fairness is challenging as counterfactuals are unobservable, and, because of that, existing baselines for counterfactual fairness do not have theoretical guarantees. In this paper, we propose a novel counterfactual fairness predictor for making predictions under counterfactual fairness. Here, we follow the standard counterfactual fairness setting and directly learn the counterfactual distribution of the descendants of the sensitive attribute via tailored neural networks, which we then use to enforce fair predictions through a novel counterfactual mediator regularization. Unique to our work is that we provide theoretical guarantees that our method is effective in ensuring the notion of counterfactual fairness. We further compare the performance across various datasets, where our method achieves state-of-the-art performance.", "title_embedding_index": 5157, "title_abs_embedding_index": 5182}, {"title": "Towards Distributed Backdoor Attacks with Network Detection in Decentralized Federated Learning", "link_suffix": "/forum?id=Dc6dgTq2UZ", "link": "https://openreview.net/forum?id=Dc6dgTq2UZ", "pdf_link": "https://openreview.net/pdf?id=Dc6dgTq2UZ", "keywords": "Decentralized Federated Learning, Distributed Backdoor Attacks", "abstract": "Distributed backdoor attacks (DBA) have shown a higher attack success rate than centralized attacks in centralized federated learning (FL). However, it has not been investigated in the decentralized FL. In this paper, we experimentally demonstrate that, while directly applying DBA to decentralized FL, the attack success rate depends on the distribution of attackers in the network architecture. Considering that the attackers can not decide their location, this paper aims to achieve a high attack success rate regardless of the attackers' location distribution. Specifically, we first design a method to detect the network by predicting the distance between any two attackers on the network. Then, based on the distance, we organize the attackers in different clusters. Lastly, we propose an algorithm to \\textit{dynamically} embed local patterns decomposed from a global pattern into the different attackers in each cluster. We conduct a thorough empirical investigation and find that our method can, in benchmark datasets,\noutperform both centralized attacks and naive DBA in different decentralized frameworks.", "title_embedding_index": 5158, "title_abs_embedding_index": 5183}, {"title": "Adaptive Uncertainty-Aware Reinforcement Learning from Human Feedback", "link_suffix": "/forum?id=qxzOEy9fLU", "link": "https://openreview.net/forum?id=qxzOEy9fLU", "pdf_link": "https://openreview.net/pdf?id=qxzOEy9fLU", "keywords": "RLHF, PPO, LLM, reinforcement learning, alignment", "abstract": "Reinforcement learning from human feedback (RLHF) is a popular technique to align large language models (LLMs) to human preferences. It requires learning a reward model that predicts scalar values given a generated text sequence, acting as a proxy for human preference scores. A central problem of RLHF is \\textit{reward hacking}, i.e., overoptimization. LLMs can easily exploit the reward model by generating text that can receive high scores but no longer align with human preferences. We address this problem by proposing a new objective which adapts the tradeoff between reward model score and regularisation based on reward uncertainty. We hypothesize that when the reward model uncertainty is low, RLHF should make a larger step size by lowering the regularization coefficient. On the other hand, when the uncertainty is high, optimization should slow down by staying closer to the original model. We present a novel re-formulation of the RLHF objective and derive our approach from its generalization to account for reward model variance. We demonstrate that our uncertainty-aware RLHF objective mitigates overoptimization and outperforms vanilla RLHF by 50% on a standard summarization task.", "title_embedding_index": 5159, "title_abs_embedding_index": 5184}, {"title": "Small Molecule Optimization with Large Language Models", "link_suffix": "/forum?id=p5VDaa8aIY", "link": "https://openreview.net/forum?id=p5VDaa8aIY", "pdf_link": "https://openreview.net/pdf?id=p5VDaa8aIY", "keywords": "Large Language Models, Molecule Generation, Transfer Learning, Drug Discovery, Evolutionary Algorithms", "abstract": "Recent advancements in large language models (LLMs) have opened new possibilities for generative molecular drug design. In molecular optimization, LLMs are promising candidates to augment traditional modeling and rule-based approaches for refining molecular structures toward design criteria. We present a novel approach to molecular optimization using LLMs trained on a hand-crafted corpus of over 100 million molecules and their properties. We trained three new models, Chemlactica-125M, Chemlactica-1.3B, and Chemma-2B, with a demonstrated ability to generate molecules with specified properties and learn new molecular characteristics from limited samples, competitive with the state-of-the-art (SOTA) in property prediction tasks on experimental data. Our optimization method, elucidated by these capabilities, combines the models' generative power with concepts from prompt optimization, evolutionary algorithms, and rejection sampling to solve molecular optimization problems more efficiently. The approach surpasses previous SOTA results on the Practical Molecular Optimization (PMO) benchmark and exceeds or is competitive with the SOTA in multi-property optimization tasks involving docking simulations. We release the training data, language models, and optimization algorithm to facilitate further research and reproducibility.", "title_embedding_index": 5160, "title_abs_embedding_index": 5185}, {"title": "LORA-MaOO: Learning Ordinal Relations and Angles for Expensive Many-Objective Optimization", "link_suffix": "/forum?id=uXmRmaF5g0", "link": "https://openreview.net/forum?id=uXmRmaF5g0", "pdf_link": "https://openreview.net/pdf?id=uXmRmaF5g0", "keywords": "Expensive optimization, many-objective optimization, surrogate-assisted optimization, Gaussian Processes, ordinal regression", "abstract": "Many-objective optimization (MaOO) simultaneously optimizes many conflicting objectives to identify the Pareto front - a set of diverse solutions that represent different optimal balances between conflicting objectives. For expensive MaOO problems, due to their costly function evaluations, computationally cheap surrogates have been widely used in MaOO to save evaluation budget. However, as the number of objectives increases, the cost of using surrogates and the difficulty of maintaining solution diversity increase rapidly. It is a challenge to reach diverse optimal solutions with a relatively low cost of using surrogates for MaOO problems. In this paper, we propose LORA-MaOO, a surrogate-assisted MaOO algorithm that learns surrogates from spherical coordinates to handle this challenge. LORA-MaOO includes an ordinal-regression-based surrogate for convergence and $M-1$ regression-based surrogates for diversity. $M$ is the number of objectives. Such a surrogate modeling framework makes it possible to complete the surrogate-assisted search and produce optimal candidate solutions with a single ordinal surrogate, while the $M-1$ remaining surrogates are only used to select diverse optimal candidate solutions for expensive evaluations, which lowers the cost of using surrogates and thus enhances the optimization efficiency. In addition, we design a clustering method to quantify artificial ordinal relations for non-dominated solutions and improve the quantification of dominance-based ordinal relations. These ordinal relations are used to train the ordinal regression surrogate which predicts how desirable the candidate solutions are in terms of convergence. The solution diversity is maintained via angles between solutions instead of pre-defined auxiliary reference vectors, which is parameter-free. Experimental results show that LORA-MaOO significantly outperforms other surrogate-assisted MaOO methods on most MaOO benchmark problems and real-world applications.", "title_embedding_index": 5161, "title_abs_embedding_index": 5186}, {"title": "Active Evaluation Acquisition for Efficient LLM Benchmarking", "link_suffix": "/forum?id=tKnPtyDt6H", "link": "https://openreview.net/forum?id=tKnPtyDt6H", "pdf_link": "https://openreview.net/pdf?id=tKnPtyDt6H", "keywords": "Efficient LLM Evaluation, Active Learning, Subset Selection", "abstract": "As large language models (LLMs) become increasingly versatile, numerous large scale benchmarks have been developed to thoroughly assess their capabilities. These benchmarks typically consist of diverse datasets and prompts to evaluate different aspects of LLM performance. However, comprehensive evaluations on hundreds or thousands of prompts incur tremendous costs in terms of computation, money, and time. In this work, we investigate strategies to improve evaluation efficiency by selecting a subset of examples from each benchmark using a learned policy. Our approach models the dependencies across test examples, allowing accurate prediction of the evaluation outcomes for the remaining examples based on the outcomes of the selected ones. Consequently, we only need to acquire the actual evaluation outcomes for the selected subset. We rigorously explore various subset selection policies and introduce a novel RL-based policy that leverages the captured dependencies. Empirical results demonstrate that our approach significantly reduces the number of evaluation prompts required while maintaining accurate performance estimates compared to previous methods.", "title_embedding_index": 5162, "title_abs_embedding_index": 5187}, {"title": "Mouse Lockbox Dataset: Behavior Recognition of Mice Solving Mechanical Puzzles", "link_suffix": "/forum?id=kffZUFZVHT", "link": "https://openreview.net/forum?id=kffZUFZVHT", "pdf_link": "https://openreview.net/pdf?id=kffZUFZVHT", "keywords": "dataset, video, action classification, behavior, mice, machine learning, computer vision, neuroscience, computational neuroscience", "abstract": "Machine learning and computer vision have a major impact on the study of natural animal behavior, as they enable automated action classification of large bodies of videos. Mice are the standard mammalian model system in many fields of research, but the open datasets that are currently available to refine machine learning methods mostly focus on either simple or social behaviors. In this work, we present a large video dataset of individual mice solving complex mechanical puzzles, so-called lockboxes. The dataset consists of a total of well over 110 hours of animal behavior, recorded with three cameras from different perspectives. As a benchmark for frame-level action classification methods, we provide human-annotated labels for all videos of two different mice, that equal 13% of our dataset. The used keypoint (pose) tracking-based action classification framework illustrates the challenges of automated labeling of fine-grained behaviors, such as the manipulation of objects. We hope that our work will help accelerate the advancement of automated action and behavior classification in the computational neuroscience community. An anonymized preview of our dataset is available for the reviewers of this manuscript athttps://www.dropbox.com/scl/fo/h7nkai8574h23qfq9m1b2/AP4gNZOpDJJ7z0yGtbWQiOc?rlkey=w36jzxqjkghg0j0xva5zsxy2v&st=5r9msqjw&dl=0", "title_embedding_index": 5163, "title_abs_embedding_index": 5188}, {"title": "AcademicEval: Live Long-Context LLM Benchmark", "link_suffix": "/forum?id=iRYExPKnxm", "link": "https://openreview.net/forum?id=iRYExPKnxm", "pdf_link": "https://openreview.net/pdf?id=iRYExPKnxm", "keywords": "Large Language Models, Ultra-long Context Understanding, Live Benchmark, Long-context LLM Benchmarks", "abstract": "Large Language Models (LLMs) have achieved remarkable performance in long-context understanding. However, current long-context LLM benchmarks are limited by rigid context length and labor-intensive annotation, and the label leakage issue in LLM training also poses a pressing challenge. Therefore, we propose \\textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context generation tasks. \\textsc{AcademicEval} adopts papers on arXiv to introduce several academic writing tasks with long-context inputs, \\textit{i.e.}, \\textsc{Title}, \\textsc{Abstract}, \\textsc{Introduction}, and \\textsc{Related Work}, which cover a wide range of abstraction levels and require no manual labeling. Moreover, \\textsc{AcademicEval} integrates high-quality and expert-curated few-shot demonstrations from a collected co-author graph to enable flexible context length. Especially, \\textsc{AcademicEval} features an efficient live evaluation, ensuring no label leakage. We conduct holistic experiments on \\textsc{AcademicEval}, and the results illustrate that LLMs perform poorly on tasks with hierarchical abstraction levels and tend to struggle with long few-shot demonstrations, illustrating the challenge of our benchmark. We also provide insightful analysis for enhancing LLMs' long-context modeling capabilities.", "title_embedding_index": 5164, "title_abs_embedding_index": 5189}, {"title": "Exploring Selective Layer Freezing Strategies in Transformer Fine-Tuning: NLI Classifiers with Sub-3B Parameter Models", "link_suffix": "/forum?id=kvBuxFxSLR", "link": "https://openreview.net/forum?id=kvBuxFxSLR", "pdf_link": "https://openreview.net/pdf?id=kvBuxFxSLR", "keywords": "LLM, Fine-tuning, Freezing", "abstract": "In recent years, methods that selectively fine-tune or reduce the number of layers in large language models (LLMs) have garnered attention as an efficient alternative to traditional fine-tuning, where all layers are trained. In this paper, we revisit the concept of Layer Freezing, a simple yet effective fine-tuning strategy, and introduce detailed strategies that improve the training efficiency of LLMs by selectively fine-tuning only a portion of the layers. We tested various freezing ratios and positions, and found that by freezing the bottom 25% or 50% of transformer layers during fine-tuning of an LLM with sub 3 billion parameters, we can achieve performance equal to or better than full model fine-tuning and Low-Rank Adaptation (LoRA), while significantly reducing memory usage and training time. Our experiments on natural language inference tasks show that this approach reduces memory consumption by about 30% and 50%, and improves training speed by 20-30%.", "title_embedding_index": 5165, "title_abs_embedding_index": 5190}, {"title": "Epi-attention : Adaptive Context-Aware Attention for Dynamic Feature Relevance in Neural Networks", "link_suffix": "/forum?id=CuKla49IjN", "link": "https://openreview.net/forum?id=CuKla49IjN", "pdf_link": "https://openreview.net/pdf?id=CuKla49IjN", "keywords": "Epi-Attention Mechanism, Context-Aware Attention, Dynamic Feature Relevance, Explainability in Machine Learning, Local Correlation Analysis, Contextual Information Integration, Neural Network Interpretability, Feature Importance Re-evaluation, Domain-Specific Knowledge Alignment, Transparent Decision-Making, Context-Driven Feature Selection, Class-Specific Feature Characteristics", "abstract": "In this paper, we introduce Epi-Attention, a novel context-aware attention mechanism designed to enhance the relevance of features in neural networks by incorporating external contextual information. Unlike traditional attention mechanisms that rely solely on the input sequence, Epi-Attention dynamically adjusts the significance of features based on additional evidence provided by external contexts. This approach allows the model to emphasize or diminish the relevance of specific features, leading to better capture and reflect the internal properties of specific classes. This mechanism provides a nuanced interpretation of feature relevance that aligns with domain knowledge, enabling the model to focus on contextually significant features in a way that resonates with expert understanding. We formalize the problem and present two variants of the proposed mechanism: Scaled Dot-Product Epi-Attention and Self-Epi-Attention, both of which re-evaluate feature importance considering either external or internal information, respectively. By leveraging the dynamic aspect of Epi-Attention, models can highlight local correlations that are characteristic of certain classes, offering a more transparent and interpretable decision-making process compared to global correlations favorized by classical approaches such as Decision trees, Logistic regression and Neural Networks. We demonstrate the efficency of Epi-Attention through three different applications (dynamic feature relevance, processing mixed datatypes and multi-source datasets) with respectively benchmark datasets, including the Wisconsin Breast Cancer, Bank Marketing and ABIDE-II datasets. Our results show significant improvements in model interpretability over traditional models that aligns with domain knowledge. Furthermore, we discuss the potential of Epi-Attention for enhancing explainability in complex machine learning tasks, paving the way for more robust and transparent neural network architectures.", "title_embedding_index": 5166, "title_abs_embedding_index": 5191}, {"title": "AutoG: Towards automatic graph construction from tabular data", "link_suffix": "/forum?id=hovDbX4Gh6", "link": "https://openreview.net/forum?id=hovDbX4Gh6", "pdf_link": "https://openreview.net/pdf?id=hovDbX4Gh6", "keywords": "Graph machine learning, Automatic data science, Applications of large language models, Tabular data", "abstract": "Recent years have witnessed significant advancements in graph machine learning, with its applications spanning numerous domains. However, the focus has predominantly been on developing powerful models, often overlooking a crucial initial step: constructing suitable graphs from common data formats, such as tabular data.\nThis construction process is fundamental to applying graph-based models, yet it remains largely understudied and lacks formalization.\nOur research aims to address this gap by formalizing the graph construction problem and proposing an effective solution. We identify two critical challenges to achieve this goal: 1. The absence of dedicated benchmarks to formalize and evaluate the effectiveness of graph construction methods, and 2. Existing automatic construction methods can only be applied to some specific cases, while tedious human engineering is required to generate high-quality schemas. \nTo tackle these challenges, we present a two-fold contribution.\nFirst, we introduce a benchmark to formalize and evaluate graph construction methods. \nSecond, we propose an LLM-based solution, AutoG, automatically generating high-quality graph structures without human intervention.\nThe experimental results demonstrate that the quality of constructed graphs is critical to downstream task performance, and AutoG can generate high-quality graphs that rival those produced by human experts.", "title_embedding_index": 5167, "title_abs_embedding_index": 5192}, {"title": "TangentBind: Unlocking the Potential of Emergent Alignment in Multimodal Model", "link_suffix": "/forum?id=c2NSfbKGOc", "link": "https://openreview.net/forum?id=c2NSfbKGOc", "pdf_link": "https://openreview.net/pdf?id=c2NSfbKGOc", "keywords": "TangentBind, Multi-modal Alignment, Optimization", "abstract": "Improving the alignment of modalities has proven effective across various downstream tasks in multimodal models. Currently, modality alignment follows two main research directions: aligning all modalities simultaneously or binding the others by aligning to a core modality. The first ensures direct alignment but is difficult to extend to new modalities. The second is scalable but weak in emergent ability due to lacking direct inter-modality alignment. To address these problems, we propose the TangentBind. Specifically, we first align all modalities to a core modality, e.g., image or text. Then, we introduce a generative network that generates the embeddings of the second modality, e.g., text or image, based on the core modality's embedding. Thirdly, other modalities, e.g., audio, are aligned to the core modality and generative embedding, improving emergent ability while retaining the alignment with the core modality. During training, besides InfoNCE, the Tangent Term is introduced to align new modalities with the generated embeddings, addressing the accuracy issues caused by using generated vectors as modality representations. With VISION and TEXT as the core modality, other modalities such as AUDIO, DEPTH, and INFRARED are included in our experiments.  Finally, our experiments show that TangentBind's emergent ability significantly outperforms the original benchmark on 9 datasets.", "title_embedding_index": 5168, "title_abs_embedding_index": 5193}, {"title": "Differentiable Implicit Solver on Graph Neural Networks for Forward and Inverse Problems", "link_suffix": "/forum?id=zuuhtmK1Ub", "link": "https://openreview.net/forum?id=zuuhtmK1Ub", "pdf_link": "https://openreview.net/pdf?id=zuuhtmK1Ub", "keywords": "Graph Neural Networks, Differentiable solvers, Implicit schemes, Numerical modelling, Inverse problems", "abstract": "Partial differential equations (PDEs) on unstructured grids can be solved using message passing on a graph neural network (GNN). Implicit time-stepping schemes are often favored, especially for parabolic PDEs, due to their stability properties. In this work, we develop a fully differentiable implicit solver for unstructured grids. We evaluate its performance across four key tasks: a) forward modeling of stiff evolutionary and static problems; b) the inverse problem of estimating equation coefficients; c) the inverse problem of estimating the right-hand side; and d) graph coarsening to accelerate forward modeling. The increased stability and differentiability of our solver enable excellent results in reducing the complexity of forward modeling and efficiently solving related inverse problems. This makes it a promising tool for geoscience and other physics-based applications.", "title_embedding_index": 5169, "title_abs_embedding_index": 5194}, {"title": "How Learnable Grids Recover Fine Detail in Low Dimesions: A Neural Tangent Kernel Analysis of Multigrid Parameteric Encodings", "link_suffix": "/forum?id=Ge7okBGZYi", "link": "https://openreview.net/forum?id=Ge7okBGZYi", "pdf_link": "https://openreview.net/pdf?id=Ge7okBGZYi", "keywords": "neural tangent kernel, compute graphics, scientific computing, fourier feature encodings, multigrid parametric encodings, encodings", "abstract": "Neural networks that map between low dimensional spaces are ubiquitous in\ncomputer graphics and scientific computing; however, in their naive\nimplementation, they are unable to learn high frequency information. We present\na comprehensive analysis comparing the two most common techniques for mitigating\nthis spectral bias: Fourier feature encodings (FFE) and multigrid parametric\nencodings (MPE). FFEs are seen as the standard for low dimensional mappings, but\nMPEs often outperform them and learn representations with higher resolution and\nfiner detail. FFE's roots in the Fourier transform, make it susceptible to\naliasing if pushed too far, while MPEs, which use a learned grid structure, have\nno such limitation. To understand the difference in performance, we use the\nneural tangent kernel (NTK) to evaluate these encodings through the lens of an\nanalogous kernel regression. By finding a lower bound on the smallest eigenvalue\nof the NTK, we prove that MPEs improve a network's performance through the\nstructure of their grid and not their learnable embedding. This mechanism is\nfundamentally different from FFEs, which rely solely on their embedding space to\nimprove performance. Results are empirically validated on a 2D image regression\ntask using images taken from 100 synonym sets of ImageNet. Using the peak\nsignal-to-noise ratio to evaluate how well fine details are learned, we show\nthat the MPE increases the minimum eigenvalue by 8 orders of magnitude over the\nbaseline and 2 orders of magnitude over the FFE. The increase in spectrum\ncorresponds to a 15 dB increase in PSNR over baseline and 12 dB increase over\nthe FFE.", "title_embedding_index": 5170, "title_abs_embedding_index": 5195}, {"title": "Towards Safe and Honest AI Agents with Neural Self-Other Overlap", "link_suffix": "/forum?id=q9g13IoWmk", "link": "https://openreview.net/forum?id=q9g13IoWmk", "pdf_link": "https://openreview.net/pdf?id=q9g13IoWmk", "keywords": "AI Safety, ML Safety, AI Deception, large language models, fine-tuning, reinforcement learning, self-other overlap", "abstract": "As AI systems increasingly make critical decisions, deceptive AI poses a significant challenge to trust and safety. We present Self-Other Overlap (SOO) fine-tuning, a promising approach in AI Safety that could substantially improve our ability to build honest artificial intelligence. Inspired by cognitive neuroscience research on empathy, SOO aims to align how AI models represent themselves and others. Our experiments with Mistral 7B v0.2 demonstrate SOO's efficacy: deceptive responses in this large language model dropped from 95.2% to 15.9% with no observed reduction in general task performance, while in reinforcement learning scenarios, SOO-trained agents showed significantly reduced deceptive behavior. SOO's focus on internal representations offers strong potential for generalization across AI architectures. While current applications focus on language models and simple RL environments, SOO could pave the way for more trustworthy AI in broader domains. Ethical implications and long-term effects warrant further investigation, but SOO represents a significant step forward in AI safety research.", "title_embedding_index": 5171, "title_abs_embedding_index": 5196}, {"title": "Learn2Mix: Training Neural Networks Using Adaptive Data Integration", "link_suffix": "/forum?id=vNQLKY7nFM", "link": "https://openreview.net/forum?id=vNQLKY7nFM", "pdf_link": "https://openreview.net/pdf?id=vNQLKY7nFM", "keywords": "adaptive training, deep learning, optimization", "abstract": "Accelerating model convergence in resource-constrained environments is essential for fast and efficient neural network training. This work presents learn2mix, a new training strategy that adaptively adjusts class proportions within batches, focusing on classes with higher error rates. Unlike classical training methods that use static class proportions, learn2mix continually adapts class proportions during training, leading to faster convergence. Empirical evaluations on benchmark datasets show that neural networks trained with learn2mix converge faster than those trained with classical approaches, achieving improved results for classification, regression, and reconstruction tasks under limited training resources and with imbalanced classes. Our empirical findings are supported by theoretical analysis.", "title_embedding_index": 5172, "title_abs_embedding_index": 5197}, {"title": "AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents", "link_suffix": "/forum?id=il5yUQsrjC", "link": "https://openreview.net/forum?id=il5yUQsrjC", "pdf_link": "https://openreview.net/pdf?id=il5yUQsrjC", "keywords": "Computer Control, Autonomous Agents, LLMs, Multimodal", "abstract": "Autonomous agents that execute human tasks by controlling computers can enhance human productivity and application accessibility. However, progress in this field will be driven by realistic and reproducible benchmarks. We present AndroidWorld, a fully functional Android environment that provides reward signals for 116 programmatic tasks across 20 real-world Android apps. Unlike existing interactive environments, which provide a static test set, AndroidWorld dynamically constructs tasks that are parameterized and expressed in natural language in unlimited ways, thus enabling testing on a much larger and more realistic suite of tasks. To ensure reproducibility, each task includes dedicated initialization, success-checking, and tear-down logic, which modifies and inspects the device\u2019s system state.We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for future work. Furthermore, we adapt a popular desktop web agent to work on Android, which we find to be less effective on mobile, suggesting future research is needed to achieve universal, cross-platform agents. Finally, we also conduct a robustness analysis, showing that task variations can significantly affect agent performance, demonstrating that without such testing, agent performance metrics may not fully reflect practical challenges.", "title_embedding_index": 5173, "title_abs_embedding_index": 5198}, {"title": "Exploring Knowledge Boundaries in Large Language Models for Retrieval Judgment", "link_suffix": "/forum?id=M1ZMwDqvSe", "link": "https://openreview.net/forum?id=M1ZMwDqvSe", "pdf_link": "https://openreview.net/pdf?id=M1ZMwDqvSe", "keywords": "knowledge boundary, large language models, Retrieval-Augmented Generation", "abstract": "Large Language Models (LLMs) are increasingly recognized for their practical applications. However, these models often encounter challenges in dynamically changing knowledge, as well as in managing unknown static knowledge. Retrieval-Augmented Generation (RAG) tackles this challenge and has shown a significant impact on LLMs.\nActually, we find that the impact of RAG on the question answering capabilities of LLMs can be categorized into three groups: beneficial, neutral, and harmful. By minimizing retrieval requests that yield neutral or harmful results, we can effectively reduce both time and computational costs, while also improving the overall performance of LLMs.\nThis insight motivates us to differentiate between types of questions using certain metrics as indicators, to decrease the retrieval ratio without compromising performance. \nIn our work, we propose a method that is able to identify different types of questions from this view by training a Knowledge Boundary Model (KBM). \nExperiments conducted on 11 English and Chinese datasets illustrate that the KBM effectively delineates the knowledge boundary, significantly decreasing the proportion of retrievals required for optimal end-to-end performance. Specifically, we evaluate the effectiveness of KBM in three complex scenarios: dynamic knowledge, long-tail static knowledge, and multi-hop problems, as well as its functionality as an external LLM plug-in.", "title_embedding_index": 5174, "title_abs_embedding_index": 5199}]
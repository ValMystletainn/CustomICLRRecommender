[
    {
        "title": "LOIRE: LifelOng learning on Incremental data via pre-trained language model gRowth Efficiently",
        "link_suffix": "/forum?id=F5PlYMC5ik",
        "link": "https://openreview.net/forum?id=F5PlYMC5ik",
        "pdf_link": "https://openreview.net/pdf?id=F5PlYMC5ik",
        "keywords": "Lifelong learning, Model growth, Function-preserving, Efficient pre-training",
        "abstract": "Large-scale pre-trained language models (PLMs) require significant computational resources to train from scratch on large volumes of data. But in the real world, emerging data from diverse sources may not be initially available for pre-training. Recent studies on lifelong learning have tried to solve this problem by exploring the use of model growth techniques to effectively incorporate new knowledge without the need for complete re-training. However, model growth approaches utilized have issues with growth operators that do not ensure strict function preservation or growth schedules that only include a few growth dimensions, reducing lifelong learning's effect. Furthermore, existing approaches often assume that emerging data has the same distribution as pre-training data, causing catastrophic forgetting of previously acquired knowledge. To address the aforementioned issues, we introduce LOIRE, a framework for lifelong learning that enables PLMs to effectively grow their capacity using incremental data. LOIRE employs growth operators for all feasible dimensions and a growth schedule to generate the optimal expansion sequence in the field of lifelong learning. Specifically, we present a novel plug-in layer growth operator with residual connections that skip the newly added layer during initial training while ensuring function preservation. We additionally propose an iterative distillation strategy for LOIRE that allows an intermediate model in the growth stages to switch between being a student and a teacher, reducing catastrophic forgetting during growth. Experiments show that LOIRE can reduce computational expenses by an average of 29.22% while retaining equivalent or better downstream performance."
    },
    {
        "title": "LLM-Guided Self-Supervised Tabular Learning With Task-Specific Pre-text Tasks",
        "link_suffix": "/forum?id=YO6Je9jOJI",
        "link": "https://openreview.net/forum?id=YO6Je9jOJI",
        "pdf_link": "https://openreview.net/pdf?id=YO6Je9jOJI",
        "keywords": "Self-supervised learning, Representation learning, Tabular data, Large language model",
        "abstract": "One of the most common approaches for self-supervised representation learning is defining pre-text tasks to learn data representations. Existing works determine pre-text tasks in a \"task-agnostic'' way, without considering the forthcoming downstream tasks. This offers an advantage of broad applicability across tasks, but can also lead to a mismatch between task objectives, potentially degrading performance on downstream tasks. In this paper, we introduce TST-LLM, a framework that effectively reduces this mismatch when the natural language-based description of the downstream task is given without any ground-truth labels. TST-LLM instructs the LLM to use the downstream task's description and meta-information of data to discover features relevant to the target task. These discovered features are then treated as ground-truth labels to define \"target-specific'' pre-text tasks. TST-LLM consistently outperforms contemporary baselines, such as STUNT and LFR, with win ratios of 95% and 81%, when applied to 22 benchmark tabular datasets, including binary and multi-class classification, and regression tasks."
    },
    {
        "title": "Continuous Diffusion for Mixed-Type Tabular Data",
        "link_suffix": "/forum?id=QPtoBPn4lZ",
        "link": "https://openreview.net/forum?id=QPtoBPn4lZ",
        "pdf_link": "https://openreview.net/pdf?id=QPtoBPn4lZ",
        "keywords": "synthetic data generation, diffusion model, generative model, tabular data, mixed-type data",
        "abstract": "Score-based generative models (or diffusion models for short) have proven successful for generating text and image data.\nHowever, the adaption of this model family to tabular data of mixed-type has fallen short so far. \nIn this paper, we propose CDTD, a Continuous Diffusion model for mixed-type Tabular Data. Specifically, we combine score matching and score interpolation to ensure a common continuous noise distribution for both continuous and categorical features alike. \nWe counteract the high heterogeneity inherent to data of mixed-type with distinct, adaptive noise schedules per feature or per data type.\nThe learnable noise schedules ensure optimally allocated model capacity and balanced generative capability.\nWe homogenize the data types further with model-specific loss calibration and initialization schemes tailored to mixed-type tabular data.\nOur experimental results show that CDTD consistently outperforms state-of-the-art benchmark models, captures feature correlations exceptionally well, and that heterogeneity in the noise schedule design boosts the sample quality."
    },
    {
        "title": "Single Teacher, Multiple Perspectives: Teacher Knowledge Augmentation for Enhanced Knowledge Distillation",
        "link_suffix": "/forum?id=DmEHmZ89iB",
        "link": "https://openreview.net/forum?id=DmEHmZ89iB",
        "pdf_link": "https://openreview.net/pdf?id=DmEHmZ89iB",
        "keywords": "TKAP, Teacher Knowledge Augmentation, Teacher Knowledge Perturbation, Single Teacher Multiple Perspectives, Synthetic Teacher, Knowledge Distillation, Ensemble Learning, Knowledge Transfer",
        "abstract": "Do diverse perspectives help students learn better? Multi-teacher knowledge distillation, which is a more effective technique than traditional single-teacher methods, supervises the student from different perspectives (i.e., teacher). While effective, multi-teacher, teacher ensemble, or teaching assistant-based approaches are computationally expensive and resource-intensive, as they require training multiple teacher networks. These concerns raise a question: can we supervise the student with diverse perspectives using only a single teacher? We, as the pioneer, demonstrate TeKAP, a novel teacher knowledge augmentation technique that generates multiple synthetic teacher knowledge by perturbing the knowledge of a single pretrained teacher i.e., Teacher Knowledge Augmentation via Perturbation, at both the feature and logit levels. These multiple augmented teachers simulate an ensemble of models together. The student model is trained on both the actual and augmented teacher knowledge, benefiting from the diversity of an ensemble without the need to train multiple teachers. TeKAP significantly reduces training time and computational resources, making it feasible for large-scale applications and easily manageable. Experimental results demonstrate that our proposed method helps existing state-of-the-art knowledge distillation techniques achieve better performance, highlighting its potential as a cost-effective alternative. The source code can be found in the supplementary."
    },
    {
        "title": "LoRA-Switch: Boosting the Efficiency of Dynamic LLM Adapters via System-Algorithm Co-design",
        "link_suffix": "/forum?id=NIG8O2zQSQ",
        "link": "https://openreview.net/forum?id=NIG8O2zQSQ",
        "pdf_link": "https://openreview.net/pdf?id=NIG8O2zQSQ",
        "keywords": "Dynamic adapters, mixture of adapters, inference acceleration, lora merging",
        "abstract": "Recent literature has found that an effective method to customize or further improve large language models (LLMs) is to add dynamic adapters, such as low-rank adapters (LoRA) with Mixture-of-Experts (MoE) structures. Though such dynamic adapters incur modest computational complexity, they surprisingly lead to huge inference latency overhead, slowing down the decoding speed by 2.5+ times. In this paper, we analyze the fine-grained costs of the dynamic adapters and find that the fragmented CUDA kernel calls are the root cause. Therefore, we propose LoRA-Switch, a system-algorithm co-designed architecture for efficient dynamic adapters. Unlike most existing dynamic structures that adopt layer-wise or block-wise dynamic routing, LoRA-Switch introduces a token-wise routing mechanism. It switches the LoRA adapters and weights for each token and merges them into the backbone for inference. For efficiency, this switching is implemented with an optimized CUDA kernel, which fuses the merging operations for all LoRA adapters at once. Based on experiments with popular open-source LLMs on common benchmarks, our approach has demonstrated similar accuracy improvement as existing dynamic adapters, while reducing the decoding latency by more than 2.4 times."
    },
    {
        "title": "SpaceGNN: Multi-Space Graph Neural Network for Node Anomaly Detection with Extremely Limited Labels",
        "link_suffix": "/forum?id=Syt4fWwVm1",
        "link": "https://openreview.net/forum?id=Syt4fWwVm1",
        "pdf_link": "https://openreview.net/pdf?id=Syt4fWwVm1",
        "keywords": "Node Anomaly Detection, Graph Neural Network, Multiple Spaces",
        "abstract": "Node Anomaly Detection (NAD) has gained significant attention in the deep learning community due to its diverse applications in real-world scenarios. \nExisting NAD methods primarily embed graphs within a single Euclidean space, while overlooking the potential of non-Euclidean spaces. \nBesides, to address the prevalent issue of limited supervision in real NAD tasks, previous methods tend to leverage synthetic data to collect auxiliary information, which is not an effective solution as shown in our experiments.\nTo overcome these challenges, we introduce a novel SpaceGNN model designed for NAD tasks with extremely limited labels. \nSpecifically, we provide deeper insights into a task-relevant framework by empirically analyzing the benefits of different spaces for node representations, based on which, we design a Learnable Space Projection function that effectively encodes nodes into suitable spaces.\nBesides, we introduce the concept of weighted homogeneity, which we empirically and theoretically validate as an effective coefficient during information propagation. This concept inspires the design of the Distance Aware Propagation module. \nFurthermore, we propose the Multiple Space Ensemble module, which extracts comprehensive information for NAD under conditions of extremely limited supervision. Our findings indicate that this module is more beneficial than data augmentation techniques for NAD. Extensive experiments conducted on 9 real datasets confirm the superiority of SpaceGNN, which outperforms the best rival by an average of 8.55% in AUC and 4.31% in F1 scores."
    },
    {
        "title": "Hindsight Preference Learning for Offline Preference-based Reinforcement Learning",
        "link_suffix": "/forum?id=4HNfKrGlSJ",
        "link": "https://openreview.net/forum?id=4HNfKrGlSJ",
        "pdf_link": "https://openreview.net/pdf?id=4HNfKrGlSJ",
        "keywords": "Offline Reinforcement Learning, Preference-based Reinforcement Learning, Preference Model",
        "abstract": "Offline preference-based reinforcement learning (RL), which focuses on optimizing policies using human preferences between pairs of trajectory segments selected from an offline dataset, has emerged as a practical avenue for RL applications. Existing works rely on extracting step-wise reward signals from trajectory-wise preference annotations, assuming that preferences correlate with the cumulative Markovian rewards. However, such methods fail to capture the holistic perspective of data annotation: Humans often assess the desirability of a sequence of actions by considering the overall outcome rather than the immediate rewards. To address this challenge, we propose to model human preferences using rewards conditioned on future outcomes of the trajectory segments, i.e. the hindsight information. For downstream RL optimization, the reward of each step is calculated by marginalizing over possible future outcomes, the distribution of which is approximated by a variational auto-encoder trained using the offline dataset. Our proposed method, Hindsight Preference Learning (HPL), can facilitate credit assignment by taking full advantage of vast trajectory data available in massive unlabeled datasets. Comprehensive empirical studies demonstrate the benefits of HPL in delivering robust and advantageous rewards across various domains."
    },
    {
        "title": "ICFI: a Feature Importance Measure For Multi-Class Classification",
        "link_suffix": "/forum?id=Rsr913dhyJ",
        "link": "https://openreview.net/forum?id=Rsr913dhyJ",
        "pdf_link": "https://openreview.net/pdf?id=Rsr913dhyJ",
        "keywords": "Feature Importance, Explainable Artificial Intelligence, Multi-class classification",
        "abstract": "Feature importance is one of the most prominent methods in explainable artificial intelligence. It seeks to score the features an artificial intelligence model relies on the most. In multi-class classification, current methods fail to explain inter-class relationships as they either provide explanations for binary classification only, or suffer from aggregation bias. In a multi-class classification scenario, features may carry discriminative power to separate some of the classes while being otherwise less relevant. State-of-the-art feature importance measures do not capture this behavior. We propose Inter-Class Feature Importance (ICFI), a measure that scores the feature importance to discriminate between an arbitrary pair of classes. ICFI is a post-hoc, model-agnostic method, independent from the machine learning architecture employed. ICFI marginalises the target output with respect to the feature of interest, leveraging the resulting change in model behavior to quantify feature importance. We present ICFI\u2019s properties and argue its relevance, describing use cases and showing insights gained. We demonstrate through thorough experiments on real-world datasets how ICFI captures the features characteristics for specific class relationships."
    },
    {
        "title": "Token-level Correlation-guided Compression for Efficient Multimodal Document Understanding",
        "link_suffix": "/forum?id=EukM0UuqLx",
        "link": "https://openreview.net/forum?id=EukM0UuqLx",
        "pdf_link": "https://openreview.net/pdf?id=EukM0UuqLx",
        "keywords": "Multimodal Large Models, Token Compression, High-resolution Image",
        "abstract": "Cropping high-resolution document images into multiple sub-images is the most widely used approach for current Multimodal Large Language Models (MLLMs) to do document understanding. Most of current document understanding methods preserve all tokens within sub-images and treat them equally. This neglects their different informativeness and leads to a significant increase in the number of image tokens. To perform a more adaptive and efficient document understanding, we propose Token-level Correlation-guided Compression, a parameter-free and plug-and-play methodology to optimize token processing. Firstly, we propose an innovative approach for assessing the pattern repetitiveness based on the correlation between each patch tokens. This method identifies redundant tokens, allowing for the determination of the sub-image's information density. Secondly, we present a token-level sampling method that efficiently captures the most informative tokens by delving into the correlation between the \\texttt{[CLS]} token and patch tokens. By integrating these strategies, we develop a plug-and-play Token-level Correlation-guided Compressor module that can be seamlessly incorporated into MLLMs utilizing cropping techniques. This module not only enhances the processing speed during training and inference but also maintains comparable performance. We conduct experiments with the representative document understanding model mPLUG-DocOwl1.5 and the effectiveness is demonstrated through extensive comparisons with other compression methods."
    },
    {
        "title": "DimOL: Dimensional Awareness as a New 'Dimension' in Operator Learning",
        "link_suffix": "/forum?id=hghJJJUJJR",
        "link": "https://openreview.net/forum?id=hghJJJUJJR",
        "pdf_link": "https://openreview.net/pdf?id=hghJJJUJJR",
        "keywords": "Physics Simulation, Fourier Neural Operators",
        "abstract": "In the realm of computational physics, an enduring topic is the numerical solutions to partial differential equations (PDEs). Recently, the attention of researchers has shifted towards Neural Operator methods, renowned for their capability to approximate \"operators'' --- mappings from functions to functions. Despite the universal approximation theorem within neural operators, ensuring error bounds often requires employing numerous Fourier layers. However, what about lightweight models? In response to this question, we introduce DimOL (Dimension-aware Operator Learning), drawing insights from dimensional analysis. To implement DimOL, we propose the ProdLayer, which can be seamlessly integrated into FNO-based and Transformer-based PDE solvers, enhancing their ability to handle sum-of-products structures inherent in many physical systems. Empirically, DimOL models achieve up to 48% performance gain within the PDE datasets. Furthermore, by analyzing Fourier components' weights, we can symbolically discern the physical significance of each term. This sheds light on the opaque nature of neural networks, unveiling underlying physical principles."
    },
    {
        "title": "Efficient Bayesian Updates for Deep Active Learning via Laplace Approximations",
        "link_suffix": "/forum?id=pNSJdyXZju",
        "link": "https://openreview.net/forum?id=pNSJdyXZju",
        "pdf_link": "https://openreview.net/pdf?id=pNSJdyXZju",
        "keywords": "Active Learning, Deep Learning, Batch Active Learning",
        "abstract": "Deep active learning (AL) involves selecting batches of instances for annotation since retraining large deep neural networks (DNNs) after each label acquisition is computationally impractical. Employing a naive top-$b$ selection can result in a batch of redundant (similar) instances. To address this issue, various batch AL strategies have been developed, many of which employ clustering for diversity as a heuristic. In contrast, we approach this issue by substituting the costly retraining with an efficient Bayesian update. Our proposed update represents a second-order optimization step using the Gaussian posterior from a last-layer Laplace approximation. Thereby, we achieve low computational complexity by computing the inverse Hessian in closed form. We demonstrate that in typical AL settings, our update closely approximates retraining while being considerably faster. Leveraging our update, we introduce a new framework for batch selection through sequential construction by updating the DNN after each label acquisition. Furthermore, we incorporate our update into a look-ahead selection strategy as a feasible upper baseline approximating optimal batch selection. Our results highlight the potential of efficient updates to advance deep AL research."
    },
    {
        "title": "FOLEYCRAFTER: BRING SILENT VIDEOS TO LIFE WITH LIFELIKE AND SYNCHRONIZED SOUNDS",
        "link_suffix": "/forum?id=4cQVUNpPkt",
        "link": "https://openreview.net/forum?id=4cQVUNpPkt",
        "pdf_link": "https://openreview.net/pdf?id=4cQVUNpPkt",
        "keywords": "Diffusion Model, Audio Generation, Video to Audio Generation",
        "abstract": "We study Neural Foley, the automatic generation of high-quality sound effects\nsynchronizing with videos, enabling an immersive audio-visual experience. Despite\nits wide range of applications, existing approaches encounter limitations\nwhen it comes to simultaneously synthesizing high-quality and video-aligned\n(i.e.,semantic relevant and temporal synchronized) sounds. To overcome these\nlimitations, we propose FoleyCrafter, a novel framework that leverages a pretrained\ntext-to-audio model to ensure high-quality audio generation. FoleyCrafter\ncomprises two key components: a semantic adapter for semantic alignment and a\ntemporal adapter for precise audio-video synchronization. The semantic adapter\nutilizes parallel cross-attention layers to condition audio generation on video features,\nproducing realistic sound effects that are semantically relevant to the visual\ncontent. Meanwhile, the temporal adapter estimates time-varying signals from\nthe videos and subsequently synchronizes audio generation with those estimates,\nleading to enhanced temporal alignment between audio and video. One notable\nadvantage of FoleyCrafter is its compatibility with text prompts, enabling the use\nof text descriptions to achieve controllable and diverse video-to-audio generation\naccording to user intents. We conduct extensive quantitative and qualitative experiments\non standard benchmarks to verify the effectiveness of FoleyCrafter. Models\nand codes will be available."
    },
    {
        "title": "CAGGLE: Color-Aware Guidance with Global and Local Prompts for Exposure Correction",
        "link_suffix": "/forum?id=U2gYoh8gZG",
        "link": "https://openreview.net/forum?id=U2gYoh8gZG",
        "pdf_link": "https://openreview.net/pdf?id=U2gYoh8gZG",
        "keywords": "prompt learning, exposure correction, image enhancement",
        "abstract": "In real-world exposure correction, achieving high-quality images requires addressing multi-exposure conditions and managing images containing locally varying brightness. \n    While recent deep learning models have improved image correction across various exposure levels, they often struggle in complex scenarios where both under- and over-exposure coexist within an image or in over-saturated areas with sparse pixel information.\n    In this paper, we tackle these challenges by proposing a color-aware guidance that employs a global prompt for tone adjustment and a local prompt for maintaining color consistency of the output. \n    To achieve this, we present a novel Prompt Interaction Module (PIM) that seamlessly integrates the global and local prompts with the input image features. \n    Extensive experiments on multi-exposure benchmark datasets demonstrate that our method achieves state-of-the-art performance, outperforming existing exposure correction methods.\n    Our approach sets a new standard in exposure correction, leveraging prompt-based learning for improved color and exposure adjustments."
    },
    {
        "title": "Guided-BFNs: Towards Visualizing and Understanding Bayesian Flow Networks in the Context of Trajectory Planning",
        "link_suffix": "/forum?id=JRXcvEg3OB",
        "link": "https://openreview.net/forum?id=JRXcvEg3OB",
        "pdf_link": "https://openreview.net/pdf?id=JRXcvEg3OB",
        "keywords": "Bayesian flow networks, trajectory planning, model understanding",
        "abstract": "Bayesian Flow Networks (BFNs) represent an emerging class of generative models that exhibit promising capabilities in modeling continuous, discretized, and discrete data. \nIn this paper, we develop Guided-BFNs to integrate BFNs with conditional guidance and gradient guidance to facilitate the effective application of such models in trajectory planning tasks. \nBased on our developments, we can better comprehend BFNs by inspecting the generation dynamics of the planning trajectories. \nThrough extensive parameter tuning and rigorous ablation experiments, we systematically delineate the functional roles of various parameters and elucidate the pivotal components within the structure of BFNs. Furthermore, we conduct a comparative analysis of the planning results between diffusion models and BFNs, to discern their similarities and differences. \nAdditionally, we undertake efforts to augment the performance of BFNs, including developing a faster and training-free sampling algorithm for sample generation.\nOur objectives encompass not only a comprehensive exploration of BFNs' structural insights but also the enhancement of their practical utility."
    },
    {
        "title": "ARTreeFormer: A Faster Attention-based Autoregressive Model for Phylogenetic Inference",
        "link_suffix": "/forum?id=FXhCG41FvV",
        "link": "https://openreview.net/forum?id=FXhCG41FvV",
        "pdf_link": "https://openreview.net/pdf?id=FXhCG41FvV",
        "keywords": "phylogenetic inference, autoregressive model, attention mechanism",
        "abstract": "Probabilistic modeling of the combinatorially explosive tree topology space has posed a significant challenge in phylogenetic inference. Previous approaches often necessitate pre-sampled tree topologies, limiting their modeling capability to a subset of the entire tree space. A recent advancement is ARTree, a deep autoregressive model that offers unrestricted distributions for tree topologies. However, the repetitive computations of topological node embeddings via Dirichlet energy minimization and the message passing over all the nodes can be expensive, which may hinder its application to data sets with many species. This paper proposes ARTreeFormer, a novel approach that harnesses attention mechanisms to accelerate ARTree. By introducing attention-based recurrent node embeddings, ARTreeFormer allows the reuse of node embeddings from preceding ordinal tree topologies and fast vectorized computation as well. This, together with a local message passing scheme, significantly improves the computation speed of ARTree while maintaining great approximation performance. We demonstrate the effectiveness and efficiency of our method on a benchmark of challenging real data phylogenetic inference problems."
    },
    {
        "title": "Video-Infinity: Distributed Long Video Generation",
        "link_suffix": "/forum?id=DxT3e2f1jc",
        "link": "https://openreview.net/forum?id=DxT3e2f1jc",
        "pdf_link": "https://openreview.net/pdf?id=DxT3e2f1jc",
        "keywords": "diffusion model, video generation",
        "abstract": "Diffusion models have recently achieved remarkable results for video generation. Despite the encouraging performances, the generated videos are typically constrained to a small number of frames, resulting in clips lasting merely a few seconds. The primary challenges in producing longer videos include the substantial memory requirements and the extended processing time required on a single GPU. A straightforward solution would be to split the workload across multiple GPUs, which, however, leads to two issues: (1) ensuring all GPUs communicate effectively to share timing and context information, and (2) modifying existing video diffusion models, which are usually trained on short sequences, to create longer videos without additional training. To tackle these, in this paper we introduce Video-Infinity, a distributed inference pipeline that enables parallel processing across multiple GPUs for long-form video generation. Specifically, we propose two coherent mechanisms: Clip parallelism and Dual-scope attention. Clip parallelism optimizes the gathering and sharing of context information across GPUs which minimizes communication overhead, while Dual-scope attention modulates the temporal self-attention to balance local and global contexts efficiently across the devices. Together, the two mechanisms join forces to distribute the workload and enable the fast generation of long videos. Under an 8 x Nvidia 6000 Ada GPU (48G) setup, our method generates videos up to 2,300 frames in approximately 5 minutes."
    },
    {
        "title": "Non-negative Tensor Mixture Learning for Discrete Density Estimation",
        "link_suffix": "/forum?id=mbo4YnWCHd",
        "link": "https://openreview.net/forum?id=mbo4YnWCHd",
        "pdf_link": "https://openreview.net/pdf?id=mbo4YnWCHd",
        "keywords": "Tensor factorization, EM algorithm, Low-rank approximation",
        "abstract": "We present an expectation-maximization (EM) based unified framework for non-negative tensor decomposition that optimizes the Kullback-Leibler divergence. To avoid iterations in each M-step and learning rate tuning, we establish a general relationship between low-rank decomposition and many-body approximation. Using this connection, we exploit that the closed-form solution of the many-body approximation can be used to update all parameters simultaneously in the M-step. Our framework offers not only a unified methodology for a variety of low-rank structures, including CP, Tucker, and Train decompositions but also their combinations forming mixtures of tensors. The weights of each low-rank tensor in the mixture can be learned from the data, which eliminates the need to carefully choose a single low-rank structure in advance. We empirically demonstrate that our framework provides superior generalization for discrete density estimation compared to conventional tensor-based approaches."
    },
    {
        "title": "Physics-Informed Decentralized Federated Learning",
        "link_suffix": "/forum?id=ZXFJeR9Xm6",
        "link": "https://openreview.net/forum?id=ZXFJeR9Xm6",
        "pdf_link": "https://openreview.net/pdf?id=ZXFJeR9Xm6",
        "keywords": "Federated Learning, Physics-Informed Neural Network, Domain Knowledge, Decentralized",
        "abstract": "The integration of domain knowledge into the learning process of artificial intelligence (AI) has received significant attention in the last few years. Most of the approaches proposed so far have focused on centralized machine learning scenarios, with less emphasis on how domain knowledge can be effectively integrated in decentralized settings. In this paper, we address this gap by evaluating the effectiveness of domain knowledge integration in distributed settings, specifically in the context of Decentralized Federated Learning (DFL). We propose the Physics-Informed DFL (PIDFL) architecture by integrating domain knowledge expressed as differential equations. We introduce a serverless data aggregation algorithm for PIDFL, prove its convergence, and discuss its computational complexity. We performed comprehensive experiments across various datasets and demonstrated that  PIDFL significantly reduces average loss across diverse applications. This highlights the potential of PIDFL and offers a promising avenue for improving decentralized learning through domain knowledge integration."
    },
    {
        "title": "Reinforced In-Context Black-Box Optimization",
        "link_suffix": "/forum?id=TjvSFVJdzJ",
        "link": "https://openreview.net/forum?id=TjvSFVJdzJ",
        "pdf_link": "https://openreview.net/pdf?id=TjvSFVJdzJ",
        "keywords": "Black-box Optimization, In-context Learning",
        "abstract": "Black-Box Optimization (BBO) has found successful applications in many fields of science and engineering. Recently, there has been a growing interest in meta-learning particular components of BBO algorithms to speed up optimization and get rid of tedious hand-crafted heuristics. As an extension, learning the entire algorithm from data requires the least labor from experts and can provide the most flexibility. In this paper, we propose RIBBO, a method to reinforce-learn a BBO algorithm from offline data in an end-to-end fashion. RIBBO employs expressive sequence models to learn the optimization histories produced by multiple behavior algorithms and tasks, leveraging the in-context learning ability of large models to extract task information and make decisions accordingly. Central to our method is to augment the optimization histories withregret-to-gotokens, which are designed to represent the performance of an algorithm based on cumulative regret over the future part of the histories. The integration of regret-to-go tokens enables RIBBO to automatically generate sequences of query points that satisfy the user-desired regret, which is verified by its universally good empirical performance on diverse problems, including BBO benchmark functions, hyper-parameter optimization and robot control problems."
    },
    {
        "title": "Supervised Batch Normalization",
        "link_suffix": "/forum?id=WVVu6B8knx",
        "link": "https://openreview.net/forum?id=WVVu6B8knx",
        "pdf_link": "https://openreview.net/pdf?id=WVVu6B8knx",
        "keywords": "machine learning, deep learning, computer vision, activation normalization, batch normalization",
        "abstract": "Batch Normalization (BN), a widely-used technique in neural networks, enhances generalization and expedites training by normalizing each mini-batch to the same mean and variance. However, its effectiveness diminishes when confronted with diverse data distributions.\nTo address this challenge, we propose Supervised Batch Normalization (SBN), a pioneering approach. We expand normalization beyond traditional single mean and variance parameters, enabling the identification of data modes prior to training. This ensures effective normalization for samples sharing common features. We define contexts as modes, categorizing data with similar characteristics. These contexts are explicitly defined, such as domains in domain adaptation or modalities in multimodal systems, or implicitly defined through clustering algorithms based on data similarity. We illustrate the superiority of our approach over BN and other commonly employed normalization techniques through various experiments on both single and multi-task datasets. Integrating SBN with Vision Transformer results in a remarkable 15.13% accuracy enhancement on CIFAR-100. Additionally, in domain adaptation scenarios, employing AdaMatch demonstrates an impressive 22.25% accuracy improvement on MNIST and SVHN compared to BN."
    },
    {
        "title": "Initializing and Retrofitting Key-Value Adaptors for Traceable Model Editing",
        "link_suffix": "/forum?id=6zcZQkjB3Q",
        "link": "https://openreview.net/forum?id=6zcZQkjB3Q",
        "pdf_link": "https://openreview.net/pdf?id=6zcZQkjB3Q",
        "keywords": "natural language processing, model editing, language model, key-value adaptor",
        "abstract": "As the insight of knowledge storage in language models deepens, the ability to perform CRUD (Create, Read, Update, Delete) operations on language models becomes increasingly indispensable for satisfying the demands of managing rapidly updating knowledge. Considering the high cost of fine-tuning language models, model editing methods with low cost are usually required to manipulate models\u2019 knowledge. Evident suggests that modules carrying knowledge in a Transformer module are primarily the MLP blocks, thus we propose iReVa, a method that explicitly initializes and retrofits key-value pairs into MLP blocks to construct a new mapping of a piece of knowledge without damaging the irrelevant knowledge. In comparison to existing methods, iReVa reveals better interpretability and a stronger capacity for carrying traceable edits. Experiment results on a series of GPT series models show our prominent performance on edit success and generalization without influencing specificity. We also made the first attempt to conduct a knowledge withdrawal test of iReVa. Our codes are available on this website."
    },
    {
        "title": "Text-driven Zero-shot Domain Adaptation with Cross-modality Graph Motif Matching",
        "link_suffix": "/forum?id=PSzDG612AC",
        "link": "https://openreview.net/forum?id=PSzDG612AC",
        "pdf_link": "https://openreview.net/pdf?id=PSzDG612AC",
        "keywords": "computer vision, transfer learning, multi-modality, zero-shot domain adaptation",
        "abstract": "Zero-shot domain adaptive semantic adaptation aims to transfer knowledge from a source domain and learn a target segmenter without access to any target domain data. Some existing methods have achieved notable performances by transforming source features to the target domain through language-driven methods. However, these methods often align language features to global image features coarsely resulting in sub-optimal performance. To address the challenges, we propose a graph motif-based adaptation method designed to balance the efficiency and effectiveness of feature alignment. Our approach involves constructing motif structures based on domain-wise image feature distributions. By increasing the angle between language-vision directed edges, we effectively pull visual features toward the language feature center, thereby achieving cross-modality feature alignment. Additionally, we employ relationship-constraint losses, \\ie directional and contrastive losses, to mitigate the mode-collapse during target feature stylization. These relationship-constraint losses help stabilize the learning process and improve the robustness of the adaptation. Extensive experimental results validate the efficacy of our proposed method. The code for this method will be made available."
    },
    {
        "title": "Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions",
        "link_suffix": "/forum?id=pMp5njgeLx",
        "link": "https://openreview.net/forum?id=pMp5njgeLx",
        "pdf_link": "https://openreview.net/pdf?id=pMp5njgeLx",
        "keywords": "LLM Evaluation, LLM Agents",
        "abstract": "As LLMs continuously evolve, there is an urgent need for a reliable evaluation method that delivers trustworthy results promptly. Currently, static benchmarks suffer from inflexibility and unreliability, leading users to prefer human voting platforms like Chatbot Arena. However, human evaluations require significant manual effort. To address this, we propose the Auto-Arena, an innovative framework that automates the entire evaluation process using LLM-powered agents. Firstly, an LLM examiner generates questions. Then, two LLM candidates engage in a multi-round peer battle based on individual questions, aiming at revealing their true performance differences. Finally, a committee of LLM judges collaboratively discusses and decides the winner, reducing bias and enhancing fairness. During the peer battles, we observe intriguing scenarios where the LLM candidates display competitive behaviors and even learn from the opponents. In our extensive experiments involving 15 recent LLMs, Auto-Arena shows a 92.14% correlation with human preferences, surpassing all previous expert-annotated benchmarks without any manual efforts. As a result, Auto-Arena offers a promising alternative to current human evaluation platforms for evaluating LLMs automatically."
    },
    {
        "title": "On the Convergence of Adam under Non-uniform Smoothness: Separability from SGDM and Beyond",
        "link_suffix": "/forum?id=mEBSeSk49H",
        "link": "https://openreview.net/forum?id=mEBSeSk49H",
        "pdf_link": "https://openreview.net/pdf?id=mEBSeSk49H",
        "keywords": "Adam, Convergence, Separability, Non-uniform Smoothness",
        "abstract": "This paper aims to clearly distinguish between Stochastic Gradient Descent with Momentum (SGDM) and Adam in terms of their convergence rates. We demonstrate that Adam achieves a faster convergence compared to SGDM under the condition of non-uniformly bounded smoothness. Our findings reveal that: (1) in deterministic environments, Adam can attain the known lower bound for the convergence rate of deterministic first-order optimizers, whereas the convergence rate of Gradient Descent with Momentum (GDM) has higher order dependence on the initial function value; (2) in stochastic setting, Adam's convergence rate upper bound matches the lower bounds of stochastic first-order optimizers, considering both the initial function value and the final error, whereas there are instances where SGDM fails to converge with any learning rate. These insights distinctly differentiate Adam and SGDM regarding their convergence rates. Additionally, by introducing a novel stopping-time based technique, we further prove that if we consider the minimum gradient norm during iterations, the corresponding convergence rate can match the lower bounds across all problem hyperparameters. The technique can also help proving that Adam with a specific hyperparameter scheduler is parameter-agnostic, which hence can be of independent interest."
    },
    {
        "title": "Which Algorithms Have Tight Generalization Bounds?",
        "link_suffix": "/forum?id=RFMdtKbff5",
        "link": "https://openreview.net/forum?id=RFMdtKbff5",
        "pdf_link": "https://openreview.net/pdf?id=RFMdtKbff5",
        "keywords": "learning theory, overparametrization, neural networks",
        "abstract": "We study which machine learning algorithms have tight generalization bounds. First, we present conditions that preclude the existence of tight generalization bounds. Specifically, we show that algorithms that have certain inductive biases that cause them to be unstable do not admit tight generalization bounds. Next, we show that algorithms that are sufficiently stable do have tight generalization bounds. We conclude with a simple characterization that relates the existence of tight generalization bounds to the conditional variance of the algorithm's loss."
    }
]
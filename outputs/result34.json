[{"title": "Identifiability for Gaussian Processes with Holomorphic Kernels", "link_suffix": "/forum?id=FUaDMRVrbS", "link": "https://openreview.net/forum?id=FUaDMRVrbS", "pdf_link": "https://openreview.net/pdf?id=FUaDMRVrbS", "keywords": "Equivalence of Gaussian random measure; kernel parameters; periodicity; identifiability; interpretability", "abstract": "Gaussian processes (GPs) are widely recognized for their robustness and flexibility across various domains, including machine learning, time series, spatial statistics, and biomedicine. In addition to their common usage in regression tasks, GP kernel parameters are frequently interpreted in various applications. For example, in spatial transcriptomics, estimated kernel parameters are used to identify spatial variable genes, which exhibit significant expression patterns across different tissue locations. However, before these parameters can be meaningfully interpreted, it is essential to establish their identifiability. Existing studies of GP parameter identifiability have focused primarily on Mat'ern-type kernels, as their spectral densities allow for more established mathematical tools. In many real-world applications, particuarly in time series analysis, other kernels such as the squared exponential, periodic, and rational quadratic kernels, as well as their combinations, are also widely used. These kernels share the property of being holomorphic around zero, and their parameter identifiability remains underexplored.\nIn this paper, we bridge this gap by developing a novel theoretical framework for determining kernel parameter identifiability for kernels holomorphic near zero. Our findings enable practitioners to determine which parameters are identifiable in both existing and newly constructed kernels, supporting application-specific interpretation of the identifiable parameters, and highlighting non-identifiable parameters that require careful interpretation.", "title_embedding_index": 1650, "title_abs_embedding_index": 1675}, {"title": "Explaining Hypergraph Neural Networks: From Local Explanations to Global Concepts", "link_suffix": "/forum?id=SaqU2ca367", "link": "https://openreview.net/forum?id=SaqU2ca367", "pdf_link": "https://openreview.net/pdf?id=SaqU2ca367", "keywords": "graph neural nets, hypergraph neural nets, explainability, concepts", "abstract": "Hypergraph neural networks are a class of powerful models that leverage the message passing paradigm to learn over hypergraphs,\na generalization of graphs well-suited to describing relational data with higher-order interactions. However, such models are not naturally interpretable, and their explainability has received very limited attention. We introduce SHypX, the first model-agnostic post-hoc explainer for hypergraph neural networks that provides both local and global explanations. At the instance-level, it performs input attribution by discretely sampling explanation subhypergraphs optimized to be faithful and concise. At the model-level, it produces global explanation subhypergraphs using unsupervised concept extraction. Extensive experiments across four real-world and four novel, synthetic hypergraph datasets demonstrate that our method finds high-quality explanations which can target a user-specified balance between faithfulness and concision, improving over baselines by 25 percent points in fidelity on average.", "title_embedding_index": 1651, "title_abs_embedding_index": 1676}, {"title": "Machine Unlearning for Streaming Forgetting", "link_suffix": "/forum?id=bIoWuzFm6r", "link": "https://openreview.net/forum?id=bIoWuzFm6r", "pdf_link": "https://openreview.net/pdf?id=bIoWuzFm6r", "keywords": "Machine Unlearning", "abstract": "Machine unlearning aims to remove knowledge derived from the specific training data that are requested to be forgotten in a well-trained model while preserving the knowledge learned from the remaining training data. Currently, machine unlearning methods typically handle all forgetting data in a single batch, removing the corresponding knowledge all at once upon request. However, in practical scenarios, requests for data removal often arise in a streaming manner rather than in a single batch, leading to reduced efficiency and effectiveness in existing methods. Such challenges of streaming forgetting have not been the focus of much research. In this paper, to address the challenges of performance maintenance, efficiency, and data access brought about by streaming unlearning requests, we introduce an online unlearning paradigm,  formalizing the unlearning as a distribution shift problem. We then estimate the altered distribution and propose a novel online unlearning algorithm to achieve efficient streaming forgetting without requiring access to the original training data. Theoretical analyses confirm an $O(V_T\\sqrt{T} + \\Delta_T)$ error bound on the streaming unlearning regret, where $V_T$ represents the cumulative total variation in the optimal solution over $T$ learning rounds and $\\Delta_T$ represents the cumulative total divergence between remaining and forgetting data distributions. This theoretical guarantee is achieved under mild conditions without the strong restriction of convex loss function. Experiments across various models and datasets validate the performance of our proposed method.", "title_embedding_index": 1652, "title_abs_embedding_index": 1677}, {"title": "A Differentiable Metric for Discovering Groups and Unitary Representations", "link_suffix": "/forum?id=Tz8Li6G2xU", "link": "https://openreview.net/forum?id=Tz8Li6G2xU", "pdf_link": "https://openreview.net/pdf?id=Tz8Li6G2xU", "keywords": "group theory, representation theory, representation learning, symmetry discovery, symbolic relationship", "abstract": "Discovering group structures within data presents a significant challenge with broad implications across various scientific domains. The main hurdle is the fact that the defining criterion for groups is inherently non-differentiable, hindering their direct integration into deep learning frameworks. To address this, we introduce a novel differentiable approach that leverages group representation theory. Our method employs a unique tensor-factorization model with matrix embeddings for each group element, coupled with a carefully designed regularizer that promotes unitary matrices. This combination instills a strong inductive bias towards learning group structures.  Evaluated on Symbolic Operation Completion tasks, our model not only recovers group operations from limited data but also precisely learns the unitary representations of the underlying groups.  Furthermore, our model implicitly defines a complexity metric that prioritizes the discovery of group structures. This work establishes a new avenue for uncovering groups within data, with potential applications in diverse fields, including automatic symmetry discovery.", "title_embedding_index": 1653, "title_abs_embedding_index": 1678}, {"title": "On the interplay between learning and memory in deep state space models", "link_suffix": "/forum?id=hgjpO0H0id", "link": "https://openreview.net/forum?id=hgjpO0H0id", "pdf_link": "https://openreview.net/pdf?id=hgjpO0H0id", "keywords": "state space models, long-term dependencies, sequence modeling, linear time-invariant systems, theory, memory", "abstract": "Deep state-space models (SSMs) have emerged as a powerful deep learning architecture for sequence modeling, but the theory of how these models learn long-term dependencies lags the practice. To explain how parameterization and the number of layers affect a model's expressiveness, we study the properties of deep $\\textit{linear}$ SSMs, i.e., linearly coupled stacks of linear time-invariant systems. We show that such systems share timescales across layers, and we provide novel analysis on the role of linear feedforward connections in regularizing these temporal dependencies. In practice, SSMs can struggle with an explosion of the hidden state variance when learning long-term dependencies. We expand our theoretical understanding of this problem for deep SSMs and provide new intuitions on how this problem may be resolved by increasing the number of layers. Finally, we confirm our theoretical results in a teacher-student framework and show the effects of model parameterization on learning convergence.", "title_embedding_index": 1654, "title_abs_embedding_index": 1679}, {"title": "Image Watermarks are Removable using Controllable Regeneration from Clean Noise", "link_suffix": "/forum?id=mDKxlfraAn", "link": "https://openreview.net/forum?id=mDKxlfraAn", "pdf_link": "https://openreview.net/pdf?id=mDKxlfraAn", "keywords": "Watermark, Detection, Robustness, Diffusion Model", "abstract": "Image watermark techniques provide an effective way to assert ownership, deter misuse, and trace content sources, which has become increasingly essential in the era of large generative models. A critical attribute of watermark techniques is their robustness against various manipulations. In this paper, we introduce a watermark removal approach capable of effectively nullifying the state of the art watermarking techniques. Our primary insight involves regenerating the watermarked image starting from a clean Gaussian noise via a controllable diffusion model, utilizing the extracted semantic and spatial features from the watermarked image. The semantic control adapter and the spatial control network are specifically trained to control the denoising process towards ensuring image quality and enhancing consistency between the cleaned image and the original watermarked image. To achieve a smooth trade-off between watermark removal performance and image consistency, we further propose an adjustable and controllable regeneration scheme. This scheme adds varying numbers of noise steps to the latent representation of the watermarked image, followed by a controlled denoising process starting from this noisy latent representation. As the number of noise steps increases, the latent representation progressively approaches clean Gaussian noise, facilitating the desired trade-off. We apply our watermark removal methods across various watermarking techniques, and the results demonstrate that our methods offer superior visual consistency/quality and enhanced watermark removal performance compared to existing regeneration approaches.", "title_embedding_index": 1655, "title_abs_embedding_index": 1680}, {"title": "Enhancing Cross-Lingual and Cross-Domain Adaptability in Large Language Models for Software Engineering", "link_suffix": "/forum?id=XFCKEgGhEK", "link": "https://openreview.net/forum?id=XFCKEgGhEK", "pdf_link": "https://openreview.net/pdf?id=XFCKEgGhEK", "keywords": "Code Generation, Transfer learning", "abstract": "This paper presents a groundbreaking mathematical framework for unsupervised domain adaptation (UDA) in the context of cross-lingual and cross-domain code modeling. We introduce the Enhanced Dynamic Code Modeling (UDA-EDCM) system, which leverages advanced concepts from measure theory, differential geometry, and information geometry to address the challenges posed by the diversity of natural and programming languages. At the core of UDA-EDCM is a novel measure-theoretic formulation of domain adaptation, utilizing optimal transport theory to minimize the discrepancy between source and target domains. We develop a Riemannian manifold approach to feature space alignment, introducing a Geodesic Flow Kernel that captures the intrinsic geometry of the code representation space. The UDA-EDCM operator is analyzed through the lens of functional analysis, revealing its spectral properties and their implications for generalization. Our information-theoretic bound on domain adaptation provides insights into the fundamental limits of knowledge transfer in code modeling. We present a unified theorem that synthesizes these diverse mathematical perspectives, offering a comprehensive characterization of UDA-EDCM's performance in terms of Wasserstein distance, empirical Rademacher complexity, and Fisher information. This theoretical foundation is complemented by an innovative optimization framework based on the Fisher Information Metric, ensuring efficient convergence in the probabilistic manifold of model parameters. Extensive experiments demonstrate that UDA-EDCM significantly outperforms existing approaches in zero-shot and few-shot learning scenarios across a wide range of programming languages and coding tasks. Our work not only advances the baselines in domain adaptation for code intelligence but also establishes a rigorous mathematical basis for future research in adaptive AI systems for software engineering.", "title_embedding_index": 1656, "title_abs_embedding_index": 1681}, {"title": "Simple, Accurate, and Efficient Axis-Aligned Decision Tree Learning", "link_suffix": "/forum?id=zZ3eYI0QXN", "link": "https://openreview.net/forum?id=zZ3eYI0QXN", "pdf_link": "https://openreview.net/pdf?id=zZ3eYI0QXN", "keywords": "decision tree, gradient descent, tabular data", "abstract": "Decision Trees (DTs) are widely used in various domains for their simplicity and interpretability. However, traditional DTs often suffer from low accuracy and reduced robustness because they rely on fixed splits and a greedy approach to decision-making. While recent approaches combining decision trees with optimization seek to balance accuracy, computational efficiency, and interpretability, they still fall short. In this paper, we introduce a novel Probabilistic univariate Decision Tree (ProuDT), a non-greedy, axis-aligned tree that aims to address these challenges and achieve significant improvements. By assigning a single deterministic feature to each decision node, ProuDT ensures univariate splits while preserving the differentiability of soft decision trees for gradient-based optimization. This tree enhances interpretability through transparent feature utilization in decision-making. Additionally, ProuDT simplifies the optimization process and reduces computational cost by avoiding complex parameters. Extensive experiments on tabular datasets demonstrate ProuDT\u2019s superior performance and scalability in binary and multi-class classification tasks.", "title_embedding_index": 1657, "title_abs_embedding_index": 1682}, {"title": "On the Vulnerability of Applying Retrieval-Augmented Generation within Knowledge-Intensive Application Domains", "link_suffix": "/forum?id=UBCgbAFQKc", "link": "https://openreview.net/forum?id=UBCgbAFQKc", "pdf_link": "https://openreview.net/pdf?id=UBCgbAFQKc", "keywords": "Healthcare; Safety; RAG", "abstract": "Retrieval-Augmented Generation (RAG) has been empirically shown to enhance\nthe performance of large language models (LLMs) in knowledge-intensive domains\nsuch as healthcare, finance, and legal contexts. Given a query, RAG retrieves\nrelevant documents from a corpus and integrates them into the LLMs\u2019 generation\nprocess. In this study, we investigate the adversarial robustness of RAG, focusing\nspecifically on examining the retrieval system. First, across 225 different setup\ncombinations of corpus, retriever, query, and targeted information, we show that\nretrieval systems are vulnerable to universal poisoning attacks in medical Q&A. In\nsuch attacks, adversaries generate poisoned documents containing a broad spectrum\nof targeted information, such as personally identifiable information. When these\npoisoned documents are inserted into a corpus, they can be accurately retrieved\nby any users, as long as attacker-specified queries are used. To understand this\nvulnerability, we discovered that the deviation from the query\u2019s embedding to that\nof the poisoned document tends to follow a pattern in which the high similarity\nbetween the poisoned document and the query is retained, thereby enabling precise\nretrieval. Based on these findings, we develop a new detection-based defense to\nensure the safe use of RAG. Through extensive experiments spanning various Q&A\ndomains, we observed that our proposed method consistently achieves excellent\ndetection rates in nearly all cases.", "title_embedding_index": 1658, "title_abs_embedding_index": 1683}, {"title": "Latent Weight Diffusion: Generating policies from trajectories", "link_suffix": "/forum?id=XLCqhdaMpy", "link": "https://openreview.net/forum?id=XLCqhdaMpy", "pdf_link": "https://openreview.net/pdf?id=XLCqhdaMpy", "keywords": "Diffusion methods, long horizon robotics tasks, Imitation Learning", "abstract": "With the increasing availability of open-source robotic data, imitation learning has emerged as a viable approach for both robot manipulation and locomotion. Currently, large generalized policies are trained to predict controls or trajectories using diffusion models, which have the desirable property of learning multimodal action distributions. However, generalizability comes with a cost \u2014 namely, larger model size and slower inference. Further, there is a known trade-off between performance and action horizon for Diffusion Policy (i.e., diffusing trajectories):\nfewer diffusion queries accumulate greater trajectory tracking errors. Thus, it is common practice to run these models at high inference frequency, subject to robot computational constraints.To address these limitations, we propose Latent Weight Diffusion (LWD), a method that uses diffusion to learn a distribution over policies for robotic tasks, rather than over trajectories. Our approach encodes demonstration trajectories into a latent space and then decodes them into policies using a hypernetwork. We employ a diffusion denoising model within this latent space to learn its distribution. We demonstrate that LWD can reconstruct the behaviors of the original policies that generated the trajectory dataset. LWD offers the benefits of considerably smaller policy networks during inference and requires fewer diffusion model queries. When tested on the Metaworld MT10 benchmark, LWD achieves a higher success rate compared to a vanilla multi-task policy, while using models up to \u223c18x smaller during inference. Additionally, since LWD generates closed-loop policies, we show that it outperforms Diffusion Policy in long action horizon settings, with reduced diffusion queries during rollout.", "title_embedding_index": 1659, "title_abs_embedding_index": 1684}, {"title": "UniTST: Effectively Modeling Inter-Series and Intra-Series Dependencies for Multivariate Time Series Forecasting", "link_suffix": "/forum?id=cuFnNExmdq", "link": "https://openreview.net/forum?id=cuFnNExmdq", "pdf_link": "https://openreview.net/pdf?id=cuFnNExmdq", "keywords": "Multivariate Time Series Forecasting", "abstract": "Transformer-based models have emerged as powerful tools for multivariate time series forecasting (MTSF). However, existing Transformer models often fall short of capturing both intricate dependencies across variate and temporal dimensions in MTS data. Some recent models are proposed to separately capture variate and temporal dependencies through either two sequential or parallel attention mechanisms. However, these methods cannot directly and explicitly learn the intricate inter-series and intra-series dependencies. In this work, we first demonstrate that these dependencies are very important as they usually exist in real-world data. To directly model these dependencies, we propose a transformer-based model UniTST containing a unified attention mechanism on the flattened patch tokens. Additionally, we add a dispatcher module which reduces the complexity and makes the model feasible for a potentially large number of variates. Although our proposed model employs a simple architecture, it offers compelling performance as shown in our extensive experiments on several datasets for time series forecasting.", "title_embedding_index": 1660, "title_abs_embedding_index": 1685}, {"title": "Point Cluster: A Compact Message Unit for Communication-Efficient Collaborative Perception", "link_suffix": "/forum?id=54XlM8Clkg", "link": "https://openreview.net/forum?id=54XlM8Clkg", "pdf_link": "https://openreview.net/pdf?id=54XlM8Clkg", "keywords": "Point Cluster, Collaborative Perception", "abstract": "The objective of the collaborative perception task is to enhance the individual agent's perception capability through message communication among neighboring agents. A central challenge lies in optimizing the inherent trade-off between perception ability and communication cost. To tackle this bottleneck issue, we argue that a good message unit should encapsulate both semantic and structural information in a sparse format, a feature not present in prior approaches. In this paper, we innovatively propose a compact message unit, namely point cluster, whose core idea is to represent potential objects efficiently with explicitly decoupled low-level structure information and high-level semantic information. Building upon this new message unit, we propose a comprehensive framework CPPC for communication-efficient collaborative perception. The core principle of CPPC is twofold: first, through strategical point sampling, structure information can be well preserved with a few key points, which can significantly reduce communication cost; second, the sequence format of point clusters enables efficient message aggregation by set matching and merging, thereby eliminating unnecessary computation generated when aligning squared BEV maps, especially for long-range collaboration. To handle time latency and pose errors encountered in real-world scenarios, we also carefully design parameter-free solutions that can adapt to different noisy levels without finetuning. Experiments on two widely recognized collaborative perception benchmarks showcase the superior performance of our method compared to the previous state-of-the-art approaches.", "title_embedding_index": 1661, "title_abs_embedding_index": 1686}, {"title": "A Theoretical Analysis of Self-Supervised Learning for Vision Transformers", "link_suffix": "/forum?id=Antib6Uovh", "link": "https://openreview.net/forum?id=Antib6Uovh", "pdf_link": "https://openreview.net/pdf?id=Antib6Uovh", "keywords": "Theory of transformers, Convergence analysis, Nonconvex optimization, Theory of self-supervised learning", "abstract": "Self-supervised learning has become a cornerstone in computer vision, primarily divided into reconstruction-based methods like masked autoencoders (MAE) and discriminative methods such as contrastive learning (CL).  Recent empirical observations reveal that MAE and CL capture different types of representations: CL tends to focus on global patterns, while MAE adeptly capturesboth global and subtle localinformation simultaneously. Despite a flurry of recent empirical investigations to shed light on this difference, theoretical understanding remains limited, especially on the dominant architecturevision  transformers(ViTs). In this paper, to provide rigorous insights, we model the visual data distribution by considering two types of spatial features: dominant global features and comparatively minuscule local features, and study the impact of imbalance among these features.  We analyze the training dynamics of one-layer softmax-based ViTs on both MAE and CL objectives using gradient descent. Our analysis shows that as the degree of feature imbalance varies, ViTs trained with the MAE objective effectively learn both global and local features to achieve near-optimal reconstruction, while the CL-trained ViTs favor predominantly global features, even under mild imbalance. These results provide a theoretical explanation for distinct behaviors of MAE and CL observed in empirical studies.", "title_embedding_index": 1662, "title_abs_embedding_index": 1687}, {"title": "An Asymptotic Theory of Random Search for Hyperparameters in Deep Learning", "link_suffix": "/forum?id=BzljpHVfmX", "link": "https://openreview.net/forum?id=BzljpHVfmX", "pdf_link": "https://openreview.net/pdf?id=BzljpHVfmX", "keywords": "hyperparameters, hyperparameter search, hyperparameter tuning, random search, evaluation", "abstract": "Hyperparameters complicate deep learning research. Methods exist to find good hyperparameters for deployment, but in development good hyperparameters on their own leave questions unanswered\u2014questions like are the hyperparameters tuned enough? Why is this model difficult to tune? And, what is the best possible performance? To answer such questions, an emerging approach is to estimate thetuning curve, or performance as a function of tuning effort. Existing estimates rely on nonparametric inference which, while robust, can not see beyond the current search iteration. To bound future iterations, we need something of greater strength. Thus, we derive an asymptotic theory of random search. Its central result is a new limit theorem that explains random search in terms of four interpretable quantities: the effective number of hyperparameters, the objective's variance when retraining, the probability near the optimum, and the best hyperparameters' performance. These quantities characterize the performance distribution from random search, and parametrize a new family: thenoisy quadratic distribution. We test our theory against three practical deep learning scenarios, including pretraining for vision and fine-tuning for language. Based on 1,024 search iterations in each scenario, our theory achieves excellent fit. We demonstrate the use of our theory to extrapolate confidence bands, fit point estimates, and infer the interpretable quantities above. These quantities answer our earlier questions; for example, the effective number of hyperparameters is the primary determinant of tuning difficulty. Our theory offers a powerful new framework for researchers to ask novel questions about their models' designs. To facilitate such research, we release a library implementing our theory and its methods: (URL redacted).", "title_embedding_index": 1663, "title_abs_embedding_index": 1688}, {"title": "SHIELD: Multi-task Multi-distribution Vehicle Routing Solver with Sparsity & Hierarchy in Efficiently Layered Decoder", "link_suffix": "/forum?id=AMbIvaD4Rr", "link": "https://openreview.net/forum?id=AMbIvaD4Rr", "pdf_link": "https://openreview.net/pdf?id=AMbIvaD4Rr", "keywords": "vehicle routing problem, learning to optimize", "abstract": "Recent advances toward foundation models for routing problems have shown great potential of a unified deep model for various VRP variants. However, they overlook the complex real-world customer distributions. In this work, we advance the Multi-Task VRP (MTVRP) setting to the more realistic yet challenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduce SHIELD, a novel model that leverages both sparsity and hierarchy principles. Building on a deeper decoder architecture, we first incorporate the Mixture-of-Depths (MoD) technique to enforce sparsity. This improves both efficiency and generalization by allowing the model to dynamically choose whether to use or skip each decoder layer, providing the needed capacity to adaptively allocate computation for learning the task/distribution specific and shared representations. We also develop a context-based clustering layer that exploits the presence of hierarchical structures in the problems to produce better local representations. These two designs inductively bias the network to identify key features that are common across tasks and distributions, leading to significantly improved generalization on unseen ones. Our empirical results demonstrate the superiority of our approach over existing methods on 9 real-world maps with 16 VRP variants each.", "title_embedding_index": 1664, "title_abs_embedding_index": 1689}, {"title": "ProteinBench: A Holistic Evaluation of Protein Foundation Models", "link_suffix": "/forum?id=BksqWM8737", "link": "https://openreview.net/forum?id=BksqWM8737", "pdf_link": "https://openreview.net/pdf?id=BksqWM8737", "keywords": "Protein foundation model, benchmark, protein design, protein conformation prediction", "abstract": "Recent years have witnessed a surge in the development of protein foundation models, significantly improving performance in protein prediction and generative tasks ranging from 3D structure prediction and protein design to conformational dynamics. However, the capabilities and limitations associated with these models remain poorly understood due to the absence of a unified evaluation framework. To fill this gap, we introduce ProteinBench, a holistic evaluation framework designed to enhance the transparency of protein foundation models. Our approach consists of three key components: (i) A taxonomic classification of tasks that broadly encompass the main challenges in the protein domain, based on the relationships between different protein modalities; (ii) A multi-metric evaluation approach that assesses performance across four key dimensions: quality, novelty, diversity, and robustness; and (iii) In-depth analyses from various user objectives, providing a holistic view of model performance. Our comprehensive evaluation of protein foundation models reveals several key findings that shed light on their current capabilities and limitations. To promote transparency and facilitate further research, we release the evaluation dataset, code, and a public leaderboard publicly for further analysis and a general modular toolkit. We intend for ProteinBench to be a living benchmark for establishing a standardized, in-depth evaluation framework for protein foundation models, driving their development and application while fostering collaboration within the field.", "title_embedding_index": 1665, "title_abs_embedding_index": 1690}, {"title": "Nearly Optimal Algorithms for Contextual Dueling Bandits from Adversarial Feedback", "link_suffix": "/forum?id=ArwsbHBoxA", "link": "https://openreview.net/forum?id=ArwsbHBoxA", "pdf_link": "https://openreview.net/pdf?id=ArwsbHBoxA", "keywords": "Dueling Bandit, Adversarial Feedback, MLE", "abstract": "Learning from human feedback plays an important role in aligning generative models, such as large language models (LLM). However, the effectiveness of this approach can be influenced by adversaries, who may intentionally provide misleading preferences to manipulate the output in an undesirable or harmful direction.\nTo tackle this challenge, we study a specific model within this problem domain--contextual dueling bandits with adversarial feedback, where the true preference label can be flipped by an adversary. We propose an algorithm namely robust contextual dueling bandits (\\algo), which is based on uncertainty-weighted maximum likelihood estimation.  Our algorithm achieves an $\\tilde O(d\\sqrt{T}+dC)$ regret bound, where $T$ is the number of rounds, $d$ is the dimension of the context, and $  0 \\le C \\le T$ is the total number of adversarial feedback. \nWe also prove a lower bound to show that our regret bound is nearly optimal, both in scenarios with and without ($C=0$) adversarial feedback. To the best of our knowledge, our work is the first to achieve nearly minimax optimal regret for dueling bandits in the presence of adversarial preference feedback.\nAdditionally, we conduct experiments to evaluate our proposed algorithm against various types of adversarial feedback. Experimental results demonstrate its superiority over the state-of-the-art dueling bandit algorithms in the presence of adversarial feedback.", "title_embedding_index": 1666, "title_abs_embedding_index": 1691}, {"title": "Bridging the Safety Gap: A Guardrail Pipeline for Trustworthy LLM Inferences", "link_suffix": "/forum?id=KjxZ4BdUdN", "link": "https://openreview.net/forum?id=KjxZ4BdUdN", "pdf_link": "https://openreview.net/pdf?id=KjxZ4BdUdN", "keywords": "guardrail, safety, llm", "abstract": "We present Wildflare GuardRail, a guardrail pipeline designed to enhance the safety and reliability of Large Language Model (LLM) inferences. Wildflare GuardRail integrates four key functional modules, including SAFETY DETECTOR, GROUNDING, CUSTOMIZER, and REPAIRER, and addresses safety challenges across multiple dimensions of LLM inferences. Wildflare GuardRail incorporates an unsafe content detection model that identifies issues such as toxicity, bias, and prompt injection, a hallucination detection model that identifies hallucinated LLM outputs and simultaneously provides explanations for the hallucinations, and a fixing model that corrects LLM outputs based on these explanations. Additionally, Wildflare GuardRail employs GROUNDINGto enrich user queries with relevant context, and utilizes CUSTOMIZERto allow users to define flexible protocols for handling specific safety requirements. Our experiments demonstrate that Wildflare GuardRail enhances safety and robustness in LLM inferences, offering adaptable and scalable solutions for LLM inferences.", "title_embedding_index": 1667, "title_abs_embedding_index": 1692}, {"title": "Modeling Complex System Dynamics with Flow Matching Across Time and Conditions", "link_suffix": "/forum?id=hwnObmOTrV", "link": "https://openreview.net/forum?id=hwnObmOTrV", "pdf_link": "https://openreview.net/pdf?id=hwnObmOTrV", "keywords": "Flow Matching, dynamical systems", "abstract": "Modeling the dynamics of complex real-world systems from temporal snapshot data is crucial for understanding phenomena such as gene regulation, climate change, and financial market fluctuations. Researchers have recently proposed a few methods based either on the Schroedinger Bridge or Flow Matching to tackle this problem, but these approaches remain limited in their ability to effectively combine data from multiple time points and different experimental settings. This integration is essential in real-world scenarios where observations from certain combinations of time points and experimental conditions are missing, either because of experimental costs or sensory failure. To address this challenge, we propose a novel method named Multi-Marginal Flow Matching (MMFM). MMFM first constructs a flow using smooth spline-based interpolation across time points and conditions and regresses it with a neural network using the classifier-free guided Flow Matching framework. This framework allows for the sharing of contextual information about the dynamics across multiple trajectories. We demonstrate the effectiveness of our method on both synthetic and real-world datasets, including a recent single-cell genomics data set with around a hundred chemical perturbations across time points. Our results show that MMFM significantly outperforms existing methods at imputing data at missing time points.", "title_embedding_index": 1668, "title_abs_embedding_index": 1693}, {"title": "Joint Reward and Policy Learning with Demonstrations and Human Feedback Improves Alignment", "link_suffix": "/forum?id=VCbqXtS5YY", "link": "https://openreview.net/forum?id=VCbqXtS5YY", "pdf_link": "https://openreview.net/pdf?id=VCbqXtS5YY", "keywords": "Alignment, Inverse Reinforcement Learning, Reinforment Learning from Human Feedback", "abstract": "Aligning to human preferences and/or intentions is an important requirement for contemporary foundation models. To ensure alignment, popular approaches such as reinforcement learning with human feedback (RLHF) break down the task into three stages: (i) a model is computed with supervised fine-tuning (SFT) based upon large demonstrations data, (ii) a reward model (RM) is estimated based upon human feedback data, and (iii) reinforcement learning (RL) is used to further refine the SFT model by optimizing the estimated reward model. Typically, the number of parameters in the reward model greatly exceeds the number of preference observations in the human feedback data. As a result, the reward model is likely inaccurate and the resulting policy model (fine-tuned with RL) may exhibit poor alignment performance. In this paper, we introduce a new approach AIHF in which reward and policy models are {\\em jointly} trained by simultaneously leveraging demonstration and human feedback data.We introduce a tractable algorithm for finding the AIHF reward and policy models and provide a finite time performance guarantee.Additionally, we demonstrate the efficiency of the proposed solution with extensive experiments involving alignment problems in LLMs and robotic control problems in MuJoCo. We observe that the proposed solutions outperform the existing alignment algorithms such as RLHF and DPO by large margins, especially when the data is unbalanced.", "title_embedding_index": 1669, "title_abs_embedding_index": 1694}, {"title": "MetaAgent: Automatically Building Multi-Agent System based on Finite State Machine", "link_suffix": "/forum?id=a7gfCUhwdV", "link": "https://openreview.net/forum?id=a7gfCUhwdV", "pdf_link": "https://openreview.net/pdf?id=a7gfCUhwdV", "keywords": "LLM Agent, Multi-Agent System", "abstract": "Large Language Models (LLMs) can solve various practical tasks via a multi-agent system. However, existing human-designed multi-agent systems can only adapt to a limited number of pre-defined scenarios. Current auto-designed methods also have several drawbacks, including no tool support, reliance on in-bag training, and inflexible communication structure.  Therefore, we propose \\textbf{MetaAgent}, a novel framework to automatically generate a multi-agent system based on a finite state machine. Given a task description, MetaAgent will design a multi-agent system and polish it through self-generated test queries. When the multi-agent system is deployed, the finite state machine, which supports the traceback and is more suitable for tool-using, will control the process to handle every case in the task domain. To evaluate our framework, we conduct experiments on both practical tasks and basic NLP tasks, the results indicate that the generated multi-agent system surpasses other auto-designed methods and can achieve a comparable performance with the human-designed multi-agent system which is polished for those specific tasks.", "title_embedding_index": 1670, "title_abs_embedding_index": 1695}, {"title": "GeneMamba: Early Parkinson\u2019s Detection via Wearable Device and Genetic Data", "link_suffix": "/forum?id=Rg2JxBZZ0g", "link": "https://openreview.net/forum?id=Rg2JxBZZ0g", "pdf_link": "https://openreview.net/pdf?id=Rg2JxBZZ0g", "keywords": "Accelerometer, Parkinson's Disease, Genetic Variants, Mamba, Time-series data", "abstract": "Parkinson's disease (PD) is a progressive neurodegenerative disorder affecting millions worldwide, with its prevalence expected to rise as the global population ages. Early diagnosis is crucial for effective management and improved quality of life for patients. However, current accelerometer-based studies focus more on detecting the symptoms of PD, while less research has been conducted on early detection of PD. This study presents a novel multi-modal deep learning model named GeneMamba for early PD diagnosis, using state space modelling approaches to effectively analyze sequences and combining accelerometer data from wearable devices with genetic variants data. Our model predicts early PD occurrence up to 7 years before clinical onset, outperforming existing methods. Furthermore, through knowledge transfer, we enable accurate PD prediction using only wearable device data, enhancing our model's real-world applicability. Additionally, our interpretation methods uncover both established and previously unidentified genes associated with PD, advancing our understanding of the disease's genetic architecture and potentially highlighting new therapeutic targets. Our approach not only advances early PD diagnosis but also offers insights into the disease's etiology, paving the way for improved risk assessment and personalized interventions.", "title_embedding_index": 1671, "title_abs_embedding_index": 1696}, {"title": "Radon Implicit Field Transform (RIFT): Learning Scenes from Radar Signals", "link_suffix": "/forum?id=HCJ7B6dhYK", "link": "https://openreview.net/forum?id=HCJ7B6dhYK", "pdf_link": "https://openreview.net/pdf?id=HCJ7B6dhYK", "keywords": "AI for Science, Representation Learning, Scene Rendering, Implicit Neural Representation, 3D Reconstruction, Inverse Problems", "abstract": "Data acquisition in array signal processing (ASP) is costly because achieving high angular and range resolutions necessitates large antenna apertures and wide frequency bandwidths, respectively. The data requirements for ASP problems grow multiplicatively with the number of viewpoints and frequencies, significantly increasing the burden of data collection, even for simulation. Implicit Neural Representations (INRs) \u2014 neural network-based models of 3D objects and scenes \u2014 offer compact and continuous representations with minimal ground truth data. They can interpolate to unseen viewpoints and potentially address the sampling cost in ASP problems. In this work, we select Synthetic Aperture Radar (SAR) as a case from ASP and propose the \\textit{\\textbf{R}adon \\textbf{I}mplicit \\textbf{F}ield \\textbf{T}ransform} (RIFT). RIFT consists of two components: a classical forward model for radar (Generalized Radon Transform, GRT), and an INR based scene representation learned from radar signals. This method can be extended to other ASP problems by replacing the GRT with appropriate algorithms corresponding to different data modalities. In our experiments, we first synthesize radar data using the GRT. We then train the INR model on this synthetic data by minimizing the reconstruction error of the radar signal. After training, we render the scene using the trained INR and evaluate our scene representation against the ground truth. Due to the lack of existing benchmarks, we introduce two main new error metrics: \\textit{\\textbf{p}hase-\\textbf{R}oot \\textbf{M}ean \\textbf{S}quare \\textbf{E}rror} (p-RMSE) for radar signal interpolation, and \\textit{\\textbf{m}agnitude-\\textbf{S}tructural \\textbf{S}imilarity \\textbf{I}ndex \\textbf{M}easure} (m-SSIM) for scene reconstruction. These metrics adapt traditional error measures to account for the complex nature of radar signals. Compared to traditional scene models in radar signal processing, with only 10% data footprint, our RIFT model achieves up to 188% improvement in scene reconstruction. Using the same amount of data, RIFT is $3\\times$ better at reconstruction and shows a 10% improvement generalizing to unseen viewpoints as shown in Figure 3 and Table 1.", "title_embedding_index": 1672, "title_abs_embedding_index": 1697}, {"title": "Gradient dynamics of low-rank fine-tuning beyond kernels", "link_suffix": "/forum?id=i7yL7VJx4H", "link": "https://openreview.net/forum?id=i7yL7VJx4H", "pdf_link": "https://openreview.net/pdf?id=i7yL7VJx4H", "keywords": "learning theory, fine tuning, online sgd dynamics, neural networks", "abstract": "LoRA has emerged as one of the \\emph{de facto} methods for fine-tuning foundation models with low computational cost and memory footprint. The idea is to only train a low-rank perturbation to the weights of a pre-trained model, given supervised data for a downstream task. Despite its empirical sucess, from a mathematical perspective it remains poorly understood what learning mechanisms ensure that gradient descent converges to useful low-rank perturbations.\n    In this work we initiate the study of low-rank fine-tuning in a student-teacher setting. We are given the weights of a two-layer \\emph{base model} $f$, as well as i.i.d. samples $(x,f^*(x))$ where $x$ is Gaussian and $f^*$ is the \\emph{teacher model} given by perturbing the weights of $f$ by a rank-1 matrix. This generalizes the setting of \\emph{generalized linear model (GLM) regression} where the weights of $f$ are zero.\n    When the rank-1 perturbation is comparable in norm to the weight matrix of $f$, the training dynamics are nonlinear. Nevertheless, in this regime we prove under mild assumptions that a student model which is initialized at the base model and trained with online gradient descent will converge to the teacher in $dk^{O(1)}$ iterations, where $k$ is the number of neurons in $f$. Importantly, unlike in the GLM setting, the complexity does not depend on fine-grained properties of the activation's Hermite expansion. We also prove that in our setting, learning the teacher model ``from scratch'' can require significantly more iterations.", "title_embedding_index": 1673, "title_abs_embedding_index": 1698}, {"title": "Llamas (mostly) think in English: On Causal Interventions in the Latent Language of Transformers", "link_suffix": "/forum?id=fSbPwHjdDG", "link": "https://openreview.net/forum?id=fSbPwHjdDG", "pdf_link": "https://openreview.net/pdf?id=fSbPwHjdDG", "keywords": "mechanistic interpretability, large language models, transformers, residual stream", "abstract": "Previous research on the Llama-2 family of Large Language Models (LLMs) suggested a\n   correlation indicating the use of English as a intermediary language within\n   these models for tasks in non-English languages. We improve on this by demonstrating a causal relationship. By\n   intervening on the intermediate layers during a forward pass, we show\n   that projecting out the activations onto a subspace corresponding to the correct\n   prediction in English impairs the model's ability to make\n   correct predictions on non-English translation tasks. Projecting onto an unrelated \n   English subspace, or a related subspace in a non-English language, has little effect,\n   demonstrating that\n   this family of models store concepts that have a high similarity to the corresponding\n   concept in English in the residual stream.", "title_embedding_index": 1674, "title_abs_embedding_index": 1699}]
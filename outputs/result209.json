[
    {
        "title": "BiGR: Harnessing Binary Latent Codes for Image Generation and Improved Visual Representation Capabilities",
        "link_suffix": "/forum?id=1Z6PSw7OL8",
        "link": "https://openreview.net/forum?id=1Z6PSw7OL8",
        "pdf_link": "https://openreview.net/pdf?id=1Z6PSw7OL8",
        "keywords": "Image generation, Generative model, Representation learning",
        "abstract": "We introduce BiGR, a novel conditional image generation model using compact binary latent codes for generative training, focusing on enhancing both generative and representation capabilities. \nBiGR is the first conditional generative model that unifies generation and discrimination within the same framework. \nBiGR features a binary tokenizer, a masking modeling mechanism, and a binary transcoder for binary code prediction. \nAdditionally, we introduce a novel entropy-ordered sampling method to enable efficient image generation. \nExtensive experiments validate BiGR's superior performance in generation quality, as measured by FID-50k, and representation capabilities, as evidenced by linear-probe accuracy. \nMoreover, BiGR showcases zero-shot generalization across various vision tasks, enabling applications such as image inpainting, outpainting, editing, interpolation, and enrichment, without the need for structural modifications. Our findings suggest that BiGR unifies generative and discriminative tasks effectively, paving the way for further advancements in the field."
    },
    {
        "title": "Training Robust Ensembles Requires Rethinking Lipschitz Continuity",
        "link_suffix": "/forum?id=WKW5TG8ItY",
        "link": "https://openreview.net/forum?id=WKW5TG8ItY",
        "pdf_link": "https://openreview.net/pdf?id=WKW5TG8ItY",
        "keywords": "robustness, lipschitzness, ensembles, convolutions, transferability, black-box attacks",
        "abstract": "Transferability of adversarial examples is a well-known property that endangers all classification models, even those that are only accessible through black-box queries. Prior work has shown that an ensemble of models is more resilient to transferability: the probability that an adversarial example is effective against most models of the ensemble is low. Thus, most ongoing research focuses on improving ensemble diversity. Another line of prior work has shown that Lipschitz continuity of the models can make models more robust since it limits how a model's output changes with small input perturbations. {\\em In this paper, we study the effect of Lipschitz continuity on transferability rates.} We show that although a lower Lipschitz constant increases the robustness of a single model, it is not as beneficial in training robust ensembles as it increases the transferability rate of adversarial examples across models in the ensemble. Therefore, we introduce LOTOS, a new training paradigm for ensembles, which counteracts this adverse effect. It does so by promoting orthogonality among the top-$k$ sub-spaces of the transformations of the corresponding affine layers of any pair of models in the ensemble. We theoretically show that $k$ does not need to be large for convolutional layers, which makes the computational overhead negligible. Through various experiments, we show LOTOS increases the robust accuracy of ensembles of ResNet-18 models by $6$ percentage points (p.p) against black-box attacks on CIFAR-10. It is also capable of combining with the robustness of prior state-of-the-art methods for training robust ensembles to enhance their robust accuracy by $10.7$ p.p."
    },
    {
        "title": "Influence-based Attributions can be Manipulated",
        "link_suffix": "/forum?id=qJkCEcd50n",
        "link": "https://openreview.net/forum?id=qJkCEcd50n",
        "pdf_link": "https://openreview.net/pdf?id=qJkCEcd50n",
        "keywords": "Influence Functions, Attack, data valuation, Adversary, explanation",
        "abstract": "Influence Functions are a standard tool for attributing predictions to training data in a principled manner and are widely used in applications such as data valuation and fairness. In this work, we present realistic incentives to manipulate influence-based attributions and investigate whether these attributions can be \\textit{systematically} tampered by an adversary. We show that this is indeed possible for logistic regression models trained on ResNet feature embeddings and standard tabular fairness datasets and provide efficient attacks with backward-friendly implementations. Our work raises questions on the reliability of influence-based attributions in adversarial circumstances."
    },
    {
        "title": "Node Duplication Improves Cold-start Link Prediction",
        "link_suffix": "/forum?id=yCr55EjC1d",
        "link": "https://openreview.net/forum?id=yCr55EjC1d",
        "pdf_link": "https://openreview.net/pdf?id=yCr55EjC1d",
        "keywords": "Graph Neural Network, Link Prediction, Cold-start, Graph Augmentation",
        "abstract": "Graph Neural Networks (GNNs) are prominent in graph machine learning and have shown state-of-the-art performance in Link Prediction (LP) tasks. Nonetheless, recent studies show that GNNs struggle to produce good results on low-degree nodes despite their overall strong performance. In practical applications of LP, like recommendation systems, improving performance on low-degree nodes is critical, as it amounts to tackling the cold-start problem of improving the experiences of users with few observed interactions. In this paper, we investigate improving GNNs' LP performance on low-degree nodes while preserving their performance on high-degree nodes and propose a simple yet surprisingly effective augmentation technique called NodeDup. Specifically, NodeDup duplicates low-degree nodes and creates links between nodes and their own duplicates before following the standard supervised LP training scheme. By leveraging a ``multi-view'' perspective for low-degree nodes, NodeDup shows significant LP performance improvements on low-degree nodes without compromising any performance on high-degree nodes. Additionally, as a plug-and-play augmentation module, NodeDup can be easily applied on existing GNNs with very light computational cost. Extensive experiments show that NodeDup achieves 38.49%, 13.34%, and 6.76% improvements on isolated, low-degree, and warm nodes, respectively, on average across all datasets compared to GNNs and state-of-the-art cold-start methods."
    },
    {
        "title": "OmniParser for Pure Vision Based GUI Agent",
        "link_suffix": "/forum?id=C6hUK6Q1Pi",
        "link": "https://openreview.net/forum?id=C6hUK6Q1Pi",
        "pdf_link": "https://openreview.net/pdf?id=C6hUK6Q1Pi",
        "keywords": "Multimodal agent; GUI screen parsing;",
        "abstract": "The recent advancements of large vision language models shows their great potential in driving the agent system operating on user interfaces. However, we argue that the power multimodal models like GPT-4V as a general agent on multiple operating systems across different applications is largely underestimated due to the lack of a robust screen parsing technique capable of: 1) reliably identifying interactable icons within the user interface, and 2) understanding the semantics of various elements in a screenshot and accurately associate the intended action with the corresponding region on the screen. To fill these gaps, we introduce OmniParser, a comprehensive method for parsing general user interface screenshots into structured elements, which significantly enhances the ability of GPT-4V to generate actions that can be accurately grounded in the corresponding regions of the interface. We first curated an interactable icon detection dataset using popular webpages and an icon description dataset. These datasets were utilized to fine-tune specialized models: a detection model to parse interactable regions on the screen and a caption model to extract the functional semantics of the detected elements. OmniParser significantly improves GPT-4V's performance on ScreenSpot benchmark. And on Mind2Web and AITW benchmark, OmniParser with screenshot only input outperforms the GPT-4V baselines requiring additional information outside of screenshot. We further demonstrate that OmniParser can seamlessly integrate with other vision language models, significantly enhancing their agentic capabilities."
    },
    {
        "title": "Minimizing Dependence between Embedding Dimensions with Adversarial Networks",
        "link_suffix": "/forum?id=Gf6VDFA6AU",
        "link": "https://openreview.net/forum?id=Gf6VDFA6AU",
        "pdf_link": "https://openreview.net/pdf?id=Gf6VDFA6AU",
        "keywords": "representation learning, adversarial networks, independence, information maximization, generalization",
        "abstract": "Learning representations with minimally dependent embedding dimensions can have many potential benefits such as improved generalization and interpretability. This work provides a differentiable and scalable algorithm for dependence minimization, moving beyond existing linear pairwise decorrelation methods. Our algorithm involves an adversarial game where small networks identify dimension relationships, while the main model exploits this information to reduce dependencies. We empirically verify that the algorithm converges. We then explore dependence reduction as a proxy for maximizing information content. We showcase the algorithm's effectiveness on the Clevr-4 dataset, both with and without supervision, and achieve promising results on the ImageNet dataset. Finally, we propose an algorithm modification that gives more control over the level of dependency, sparking a discussion on optimal redundancy levels for specific applications. Although the algorithm performs well on synthetic data, further research is needed to optimize it for tasks such as out-of-distribution detection."
    },
    {
        "title": "Generative Monoculture in Large Language Models",
        "link_suffix": "/forum?id=yZ7sn9pyqb",
        "link": "https://openreview.net/forum?id=yZ7sn9pyqb",
        "pdf_link": "https://openreview.net/pdf?id=yZ7sn9pyqb",
        "keywords": "monoculture, bias, alignment",
        "abstract": "We introduce {\\em generative monoculture}, a behavior observed in large language models (LLMs) characterized by a significant narrowing of model output diversity relative to available training data for a given task: for example, generating only positive book reviews for books with a mixed reception. While in some cases, generative monoculture enhances performance (e.g., LLMs more often produce efficient code), the dangers are exacerbated in others (e.g., LLMs refuse to share diverse opinions). As LLMs are increasingly used in high-impact settings such as education and web search, careful maintenance of LLM output diversity is essential to ensure a variety of facts and perspectives are preserved over time. We experimentally demonstrate the prevalence of generative monoculture through analysis of book review and code generation tasks, and find that simple countermeasures such as altering sampling or prompting strategies are insufficient to mitigate the behavior. Moreover, our results suggest that the root causes of generative monoculture are likely embedded within the LLM's alignment processes, suggesting a need for developing fine-tuning paradigms that preserve or promote diversity."
    },
    {
        "title": "Stable Signature is Unstable: Removing Image Watermark from Diffusion Models",
        "link_suffix": "/forum?id=zqo2eKjSWH",
        "link": "https://openreview.net/forum?id=zqo2eKjSWH",
        "pdf_link": "https://openreview.net/pdf?id=zqo2eKjSWH",
        "keywords": "Image Watermark, Diffusion Model, AI-generated Image",
        "abstract": "Watermark has been widely deployed by industry to detect AI-generated images. A recent watermarking framework called Stable Signature (proposed by Meta) roots watermark into the parameters of a diffusion model's decoder such that its generated images are inherently watermarked. Stable Signature makes it possible to watermark images generated by open-source diffusion models and was claimed to be robust against removal attacks. In this work, we propose a new attack to remove the watermark from a diffusion model by fine-tuning it. Our results show that our attack can effectively remove the watermark from a diffusion model such that its generated images are non-watermarked, while maintaining the visual quality of the generated images. Our results highlight that Stable Signature is not as stable as previously thought."
    },
    {
        "title": "Composable Interventions for Language Models",
        "link_suffix": "/forum?id=tu3qwNjrtw",
        "link": "https://openreview.net/forum?id=tu3qwNjrtw",
        "pdf_link": "https://openreview.net/pdf?id=tu3qwNjrtw",
        "keywords": "Model editing, Compression, Unlearning, Interventions, Language models",
        "abstract": "Test-time interventions for language models can enhance factual accuracy, mitigate harmful outputs, and improve model efficiency without costly retraining.\nBut despite a flood of new methods, different types of interventions are largely developing independently.\nIn practice, multiple interventions must be applied sequentially to the same model, yet we lack standardized ways to study how interventions interact.\nWe fill this gap by introducing composable interventions, a framework to study the effects of using multiple interventions on the same language models, featuring new metrics and a unified codebase.\nUsing our framework, we conduct extensive experiments and compose popular methods from three emerging intervention categories---knowledge editing, model compression, and machine unlearning.\nOur results over 417 different compositions uncover meaningful interactions: compression hinders editing and unlearning, composing interventions hinges on their order of application, and popular general-purpose metrics are inadequate for assessing composability.\nTaken together, our findings showcase clear gaps in composability, suggesting a need for new multi-objective interventions."
    },
    {
        "title": "Training Large Language Model to Reason in a Continuous Latent Space",
        "link_suffix": "/forum?id=tG4SgayTtk",
        "link": "https://openreview.net/forum?id=tG4SgayTtk",
        "pdf_link": "https://openreview.net/pdf?id=tG4SgayTtk",
        "keywords": "large language model, reasoning, chain of thoughts",
        "abstract": "Large language models are restricted to reason in the \u201clanguage space\u201d, where they typically express the reasoning process with a chain-of-thoughts (CoT) to solve a complex reasoning problem. However, we argue that language space may not be the optimal reasoning space. For example, most word tokens are primarily for textual coherence and not essential for reasoning, while some critical tokens require complex planning and pose huge challenges to LLMs. To explore the potential of LLM reasoning in an unrestricted latent space instead of using human language, we introduce a new paradigm COCONUT (Chain of Continuous Thought). We utilize the last hidden state of the LLM as a representation of the reasoning state (termed \u201ccontinuous thought\u201d). Rather than decoding this into a word token, we feed it back to the LLM as the subsequent input embedding directly in the continuous space. Experiments show that COCONUT can effectively augment the LLM on several reasoning tasks. It even outperforms CoT in certain logical reasoning tasks that require substantial planning, despite generating fewer tokens during inference. More interestingly, we observe an advanced reasoning patterns emerging from latent reasoning: the continuous thought can encode multiple potential next reasoning steps, allowing the model to perform a breadth-first search (BFS) to solve the problem, rather than prematurely committing to a single deterministic path like CoT. These findings demonstrate the promise of latent reasoning and offer valuable insights for future research on latent reasoning methods."
    },
    {
        "title": "What If We Recaption Billions of Web Images with LLaMA-3?",
        "link_suffix": "/forum?id=WpObsQTpfp",
        "link": "https://openreview.net/forum?id=WpObsQTpfp",
        "pdf_link": "https://openreview.net/pdf?id=WpObsQTpfp",
        "keywords": "image-text datasets; synthetic captions",
        "abstract": "Web-crawled image-text pairs are inherently noisy. Prior studies demonstrate that semantically aligning and enriching textual descriptions of these pairs can significantly enhance model training across various vision-language tasks, particularly text-to-image generation. However, large-scale investigations in this area remain predominantly closed-source. Our paper aims to bridge this community effort, leveraging the powerful and $\\textit{open-sourced}$ LLaMA-3, a GPT-4 level LLM. Our recaptioning pipeline is simple: first, we fine-tune a LLaMA-3-8B powered LLaVA-1.5 and then employ it to recaption 1.3 billion images from the DataComp-1B dataset. Our empirical results confirm that this enhanced dataset, Recap-DataComp-1B, offers substantial benefits in training advanced vision-language models. For discriminative models like CLIP, we observe enhanced zero-shot performance in cross-modal retrieval tasks. For generative models like text-to-image Diffusion Transformers, the generated images exhibit a significant improvement in alignment with users' text instructions, especially in following complex queries"
    },
    {
        "title": "QCR: Quantised Codebooks for Retrieval",
        "link_suffix": "/forum?id=TDzAqTqDHV",
        "link": "https://openreview.net/forum?id=TDzAqTqDHV",
        "pdf_link": "https://openreview.net/pdf?id=TDzAqTqDHV",
        "keywords": "information retrieval, sparse retrieval, dense retrieval",
        "abstract": "In recent years, the application of language models (LMs) to retrieval tasks has gained significant attention. Dense retrieval methods, which represent queries and document chunks as vectors, have gained popularity, but their use at scale can be challenging. These models can under-perform traditional sparse approaches, like BM25, in some demanding settings, e.g. at web-scale or out-of-domain. Moreover the computational requirements, even with approximate nearest neighbour indices (ANN) can be hefty. Sparse methods, remain, thanks to their efficiency, ubiquitous in applications. In this work, we ask whether LMs can be leveraged to bridge\nthis gap. We introduce Quantised Codebooks for Retrieval (QCR): we encode queries and documents as bags of latent discrete tokens, learned purely through a contrastive objective. QCR\u2019s encodings can be used as a drop-in replacement for the original string in sparse retrieval indices, or can be instead used to complement the text with higher-level semantic features. Experimental results demonstrate that QCR outperforms BM25 with vanilla text on the challenging MSMARCO dataset. What is more, when used in conjunction with standard lexical matching, our representation yield and absolute 15.6% gain over BM25\u2019s Success@100, highlighting the complementary nature of textual and learned discrete features."
    },
    {
        "title": "MUSE: Machine Unlearning Six-Way Evaluation for Language Models",
        "link_suffix": "/forum?id=TArmA033BU",
        "link": "https://openreview.net/forum?id=TArmA033BU",
        "pdf_link": "https://openreview.net/pdf?id=TArmA033BU",
        "keywords": "Language Models, Machine Unlearning",
        "abstract": "Language models (LMs) are trained on vast amounts of text data, which may include private and copyrighted content. Data owners may request the removal of their data from a trained model due to privacy or copyright concerns. However, exactly unlearning only these datapoints (i.e., retraining with the data removed) is intractable in modern-day models. This has led to the development of many approximate unlearning algorithms. The evaluation of the efficacy of these algorithms has traditionally been narrow in scope, failing to precisely quantify the success and practicality of the algorithm from the perspectives of both the model deployers and the data owners. We address this issue by proposing MUSE, a comprehensive machine unlearning evaluation benchmark that enumerates six diverse desirable properties for unlearned models: (1) no verbatim memorization, (2) no knowledge memorization, (3) no privacy leakage, (4) utility preservation on data not intended for removal, (5) scalability with respect to the size of removal requests, and (6) sustainability over sequential unlearning requests. Using these criteria, we benchmark how effectively eight popular unlearning algorithms on 7B-parameter LMs can unlearn Harry Potter books and news articles. Our results demonstrate that most algorithms can prevent verbatim memorization and knowledge memorization to varying degrees, but only one algorithm does not lead to severe privacy leakage. Furthermore, existing algorithms fail to meet deployer's expectations because they often degrade general model utility and also cannot sustainably accommodate successive unlearning requests or large-scale content removal. Our findings identify key issues with the practicality of existing unlearning algorithms on language models."
    },
    {
        "title": "On the Convergence of Tsetlin Machines for the AND and the OR Operators",
        "link_suffix": "/forum?id=NHPQOm6z0e",
        "link": "https://openreview.net/forum?id=NHPQOm6z0e",
        "pdf_link": "https://openreview.net/pdf?id=NHPQOm6z0e",
        "keywords": "Tsetlin Machine, Convergence, AND operator, OR operator",
        "abstract": "The Tsetlin Machine (TM) is a novel machine learning algorithm based on propositional logic, which has obtained the state-of-the-art performance on several pattern recognition problems. In previous studies, the convergence properties of TMs for the 1-bit operator and the XOR operator have been analyzed. To make the analyses on the basic digital operations complete, in this article, we analyze the convergence when input training samples follow the AND and the OR operators respectively. Our analyses reveal that the TM can converge almost surely to reproduce the AND and the OR operators, which are learnt from training data over an infinite time horizon. Specifically, by analysing the OR operator, we reveal the convergence property of TMs when two sub-patterns can be jointly represented by one clause, which is quite distinct compared with the analysis of the XOR case.The analyses on the AND and the OR operators, together with the previous analyses on the 1-bit and XOR operators, complete the convergence analyses on basic operators in Boolean algebra."
    },
    {
        "title": "Identifying Feedforward  and Feedback Controllable Subspaces of Neural Population Dynamics",
        "link_suffix": "/forum?id=4AlNpszv66",
        "link": "https://openreview.net/forum?id=4AlNpszv66",
        "pdf_link": "https://openreview.net/pdf?id=4AlNpszv66",
        "keywords": "Control Theory, Systems Neuroscience, Dimensionality Reduction",
        "abstract": "There is overwhelming evidence that cognition, perception, and action rely on feedback control. However, if and how neural population dynamics are amenable to different control strategies is poorly understood, in large part because machine learning methods to directly assess controllability in neural population dynamics are lacking. To address this gap, we developed a novel dimensionality reduction method, Feedback Controllability Components Analysis (FCCA), that identifies subspaces of linear dynamical systems that are most feedback controllable based on a new measure of feedback controllability. We further show that PCA identifies subspaces of linear dynamical systems that maximize a measure of feedforward controllability. As such, FCCA and PCA are data-driven methods to identify subspaces of neural population data (approximated as linear dynamical systems) that are most feedback and feedforward controllable respectively, and are thus natural contrasts for hypothesis testing. We developed new theory that proves that non-normality of underlying dynamics determines the divergence between FCCA and PCA solutions, and confirmed this in numerical simulations. Applying FCCA to diverse neural population recordings, we find that feedback controllable dynamics are geometrically distinct from PCA subspaces and are better predictors of animal behavior. Our methods provide a novel approach towards analyzing neural population dynamics from a control theoretic perspective, and indicate that feedback controllable subspaces are important for behavior."
    },
    {
        "title": "Air Quality Prediction with Physics-Informed Dual Neural ODEs in Open Systems",
        "link_suffix": "/forum?id=kOJf7Dklyv",
        "link": "https://openreview.net/forum?id=kOJf7Dklyv",
        "pdf_link": "https://openreview.net/pdf?id=kOJf7Dklyv",
        "keywords": "Air Quality Prediction; Physics-informed Deep Learning",
        "abstract": "Air pollution significantly threatens human health and ecosystems, necessitating effective air quality prediction to inform public policy. Traditional approaches are generally categorized into physics-based and data-driven models. Physics-based models usually struggle with high computational demands and closed-system assumptions, while data-driven models may overlook essential physical dynamics, confusing the capturing of spatiotemporal correlations. Although some physics-informed approaches combine the strengths of both models, they often face a mismatch between explicit physical equations and implicit learned representations. To address these challenges, we propose Air-DualODE, a novel physics-informed approach that integrates dual branches of Neural ODEs for air quality prediction. The first branch applies open-system physical equations to capture spatiotemporal dependencies for learning physics dynamics, while the second branch identifies the dependencies not addressed by the first in a fully data-driven way. These dual representations are temporally aligned and fused to enhance prediction accuracy. Our experimental results demonstrate that Air-DualODE achieves state-of-the-art performance in predicting pollutant concentrations across various spatial scales, thereby offering a promising solution for real-world air quality challenges."
    },
    {
        "title": "Multiplayer Federated Learning: Reaching Equilibrium with Less Communications",
        "link_suffix": "/forum?id=t9NiRq9PGK",
        "link": "https://openreview.net/forum?id=t9NiRq9PGK",
        "pdf_link": "https://openreview.net/pdf?id=t9NiRq9PGK",
        "keywords": "Federated Learning, Game theory, Multiplayer games, Convergence guarantees, Communication-efficient Algorithms, Local SGD",
        "abstract": "Traditional Federated Learning (FL) approaches assume collaborative clients with aligned objectives working towards a shared global model. However, in many real-world scenarios, clients act as rational players with individual objectives and strategic behaviors, a concept that existing FL frameworks are not equipped to adequately address. To bridge this gap, we introduce Multiplayer Federated Learning (MpFL), a novel framework that models the clients in the FL environment as players in a game-theoretic context, aiming to reach an equilibrium. In this scenario, each player tries to optimize their own utility function, which may not align with the collective goal. Within MpFL, we propose Per-Player Local SGD (PEARL-SGD), an algorithm in which each player/client performs local updates independently and periodically communicates with other players. We theoretically analyze PEARL-SGD under different step-size selections and prove that it reaches an equilibrium with less communications compared to its non-local counterpart. Finally, we verify our theoretical findings through numerical experiments."
    },
    {
        "title": "Can Diffusion Models Disentangle? A Theoretical Perspective",
        "link_suffix": "/forum?id=JjMRdXPpKQ",
        "link": "https://openreview.net/forum?id=JjMRdXPpKQ",
        "pdf_link": "https://openreview.net/pdf?id=JjMRdXPpKQ",
        "keywords": "diffusion model, disentanglement, voice conversion",
        "abstract": "This paper introduces a novel theoretical framework to understand how diffusion models can learn disentangled representations under the assumption of an $\\normltwo$ score approximation. We also provide sufficient conditions under which such representations are beneficial for domain adaptation. Our theory offers new insights into how existing diffusion models disentangle latent variables across general distributions and suggests strategies to enhance their disentanglement capabilities. To validate our theory, we perform experiments using both synthetic data generated from latent subspace models and real speech data for non-parallel voice conversion - a canonical disentanglement problem. Across various classification tasks, we found voice conversion-based adaptation methods achieve significant improvements in classification accuracy, demonstrating their effectiveness as domain adaptors. Code will be released upon acceptance."
    },
    {
        "title": "Interplay Between Task Learning and Skill Discovery for Agile Locomotion",
        "link_suffix": "/forum?id=FvjcdS42o1",
        "link": "https://openreview.net/forum?id=FvjcdS42o1",
        "pdf_link": "https://openreview.net/pdf?id=FvjcdS42o1",
        "keywords": "Unsupervised Skill Discovery, Reinforcement Learning, Robot Learning, Locomotion",
        "abstract": "Agile locomotion of legged robots, characterized by high momentum and frequent contact changes, is a challenging task that demands precise motor control. Therefore, the training process for such skills often relies on additional techniques, such as reward engineering, expert demonstrations, and curriculum learning. However, these requirements hinder the generalizability of methods because we may lack sufficient prior knowledge or demonstration datasets for some tasks. In this work, we consider the problem of automated learning agile motions using its intrinsic motivation, which can greatly reduce the effort of a human engineer. Inspired by unsupervised skill discovery, our learning framework encourages the agent to explore various skills to maximize the given task reward. Finally, we train a parameter to balance the two distinct rewards through a bi-level optimization process. We demonstrate that our method can train quadrupeds to perform highly agile motions, ranging from crawling, jumping, and leaping to complex maneuvers such as jumping off a perpendicular wall."
    },
    {
        "title": "A Transfer Attack to Image Watermarks",
        "link_suffix": "/forum?id=UchRjcf4z7",
        "link": "https://openreview.net/forum?id=UchRjcf4z7",
        "pdf_link": "https://openreview.net/pdf?id=UchRjcf4z7",
        "keywords": "Image Watermarking, Transfer Attack, AI-generated Image",
        "abstract": "Watermark has been widely deployed by industry to detect AI-generated images. The robustness of such watermark-based detector against evasion attacks in the white-box and black-box settings is well understood in the literature. However, the robustness in the no-box setting is much less understood. In this work, we propose a new transfer evasion attack to image watermark in the no-box setting. Our transfer attack adds a perturbation to a watermarked image to evade multiple surrogate watermarking models trained by the attacker itself, and the perturbed watermarked image also evades the target watermarking model.  Our major contribution is to show that, both theoretically and empirically,  watermark-based AI-generated image detector is not robust to evasion attacks  even if the attacker does not have access to the watermarking model nor the detection API."
    },
    {
        "title": "PuzzlePlex: A Benchmark to Evaluate the Reasoning and Planning of Large Language Models on Puzzles",
        "link_suffix": "/forum?id=GT4gMdvVFp",
        "link": "https://openreview.net/forum?id=GT4gMdvVFp",
        "pdf_link": "https://openreview.net/pdf?id=GT4gMdvVFp",
        "keywords": "Benchmark, Puzzle, Reasoning and Planning",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in various tasks, yet their comprehensive reasoning and planning capabilities in interactive environments remain underexplored. We introduce PuzzlePlex, a benchmark designed to evaluate reasoning and planning capabilities in a multi-turn adversarial environment. \nPuzzlePlex comprises 24 diverse puzzles, including deterministic and stochastic games, as well as single-player and adversarial scenarios. An important novelty of our benchmark is that it includes multi-step adversarial reasoning games. To succeed in such games, each LLM must maintain a history of its own moves and those of the opponent LLM, generating strategies that outperform the opponent to secure victory.\nWe implement standard game-playing baselines (such as dynamic programming approaches) using common algorithms for comparison. \nOur findings indicate that the reasoning and planning abilities of current LLMs remain limited in puzzle-solving contexts. GPT-4 outperforms other models, successfully competing against baselines in 49% of cases. However, when faced with more constrained rule sets, it demonstrates diminished reasoning and planning capabilities. In addition to the 14 multi-turn adversarial puzzles, we report on single-player puzzles and incorporate multi-modal challenges that integrate text and images, revealing that LLMs still significantly lag behind even simple heuristics  in puzzles.\nA key feature of our benchmark is its ability to generate game instances with graduated levels of difficulty, allowing it to evolve as LLMs become more sophisticated. This adaptability ensures the continued relevance and utility of PuzzlePlex  in assessing the progress of LLM capabilities in reasoning and planning within interactive environments."
    },
    {
        "title": "Improving Molecule-Language Alignment with Hierarchical Graph Tokenization",
        "link_suffix": "/forum?id=4VmagzA2Tp",
        "link": "https://openreview.net/forum?id=4VmagzA2Tp",
        "pdf_link": "https://openreview.net/pdf?id=4VmagzA2Tp",
        "keywords": "molecular-language alignment, large language models, hierarchical graph neural networks, tokenization, biomolecular studies, molecule",
        "abstract": "Recently there has been a surge of interest in extending the success of large language models (LLMs) to graph modality, such as molecules. As LLMs are predominantly trained with 1D text data, most existing approaches adopt a graph neural network to represent a molecule as a series of node tokens and feed these tokens to LLMs for molecule-language alignment. Despite achieving some successes, existing approaches have overlooked the hierarchical structures that are inherent in molecules. Specifically, in molecular graphs, the high-order structural information contains rich semantics of molecular functional groups, which encode crucial biochemical functionalities of the molecules. We establish a simple benchmark showing that neglecting the hierarchical information in graph tokenization will lead to subpar molecule-language alignment and severe hallucination in generated outputs. To address this problem, we propose a novel strategy called HIerarchical GrapH Tokenization (HIGHT). HIGHT employs a hierarchical graph tokenizer that extracts and encodes the hierarchy of node, motif, and graph levels of informative tokens to improve the graph perception of LLMs. HIGHT also adopts an augmented molecule-language supervised fine-tuning dataset, enriched with the hierarchical graph information, to further enhance the molecule-language alignment. Extensive experiments on14molecule-centric benchmarks confirm the effectiveness of HIGHT in reducing hallucination by40%, as well as significant improvements in various molecule-language downstream tasks."
    },
    {
        "title": "Inference time LLM alignment in single and multidomain preference spectrum",
        "link_suffix": "/forum?id=1Uem0nAWK0",
        "link": "https://openreview.net/forum?id=1Uem0nAWK0",
        "pdf_link": "https://openreview.net/pdf?id=1Uem0nAWK0",
        "keywords": "LLM, Alignment, inference",
        "abstract": "Aligning Large Language Models (LLM) to address subjectivity and nuanced preference levels requires adequate flexibility and control, which can be a resource-intensive and time-consuming procedure. Existing training-time alignment methods require full re-training when a change is needed and inference-time ones typically require access to the reward model at each inference step. To address these limitations, we introduce an inference-time model alignment method that learns encoded representations of preference dimensions, called Alignment Vectors (AV). These representations are computed by subtracting the base model from the aligned model as in model editing enabling dynamically adjusting the model behavior during inference through simple linear operations. Even though the preference dimensions can span various granularity levels, here we focus on three gradual response levels across three specialized domains: medical, legal, and financial, exemplifying its practical potential. This new alignment paradigm introduces adjustable preference knobs during inference, allowing users to tailor their LLM outputs while reducing the inference cost by half compared to the prompt engineering approach. Additionally, we find that AVs are transferable across different fine-tuning stages of the same model, demonstrating their flexibility. AVs also facilitate multidomain, diverse preference alignment, making the process 12x faster than the retraining approach."
    },
    {
        "title": "Port-Hamiltonian Architectural Bias for Long-Range Propagation in Deep Graph Networks",
        "link_suffix": "/forum?id=03EkqSCKuO",
        "link": "https://openreview.net/forum?id=03EkqSCKuO",
        "pdf_link": "https://openreview.net/pdf?id=03EkqSCKuO",
        "keywords": "graph representation learning, long-range propagation, ordinary differential equations",
        "abstract": "The dynamics of information diffusion within graphs is a critical open issue that heavily influences graph representation learning, especially when considering long-range propagation. This calls for principled approaches that control and regulate the degree of propagation and dissipation of information throughout the neural flow. Motivated by this, we introduce port-Hamiltonian Deep Graph Networks, a novel framework that models neural information flow in graphs by building on the laws of conservation of Hamiltonian dynamical systems. We reconcile under a single theoretical and practical framework both non-dissipative long-range propagation and non-conservative behaviors, introducing tools from mechanical systems to gauge the equilibrium between the two components. Our approach can be applied to general message-passing architectures, and it provides theoretical guarantees on information conservation in time. Empirical results prove the effectiveness of our port-Hamiltonian scheme in pushing simple graph convolutional architectures to state-of-the-art performance in long-range benchmarks."
    },
    {
        "title": "ACCO: Accumulate while you Communicate, Hiding Communications in Distributed LLM Training",
        "link_suffix": "/forum?id=UV1jr2aJ2J",
        "link": "https://openreview.net/forum?id=UV1jr2aJ2J",
        "pdf_link": "https://openreview.net/pdf?id=UV1jr2aJ2J",
        "keywords": "Distributed LLMs Training, Data Parallelism, Optimizer State Partitioning, Distributed Optimization, Decoupled Communication",
        "abstract": "Training Large Language Models (LLMs) relies heavily on distributed implementations, employing multiple GPUs to compute stochastic gradients on model replicas in parallel. However, synchronizing gradients in data parallel settings induces a communication overhead increasing with the number of distributed workers, impeding the efficiency gains of parallelization. To address this challenge, local optimization algorithms such as the ones used in Federated Learning have emerged. While effective in minimizing communication overhead, they incur significant memory costs, hindering scalability: in addition to extra momentum variables, optimizer's states cannot be partitioned among workers as communications are only allowed between rounds of local optimization steps. To conceal communication costs, we propose instead to synchronize delayed gradientswhilecomputing new ones between each model\u2019s update and introduce $\\textbf{AC}$cumulate while $\\textbf{CO}$mmunicate ($\\textbf{ACCO}$), a memory-efficient optimization algorithm tailored for distributed training of LLMs. Accumulating local gradients on the workers until the communication finishes naturally reduces the idle time of GPUs and even allows the use of heterogeneous hardware. However, we show that the one-step delay inherent in parallel execution of gradient computations and communications has drastic impacts on Transformers\u2019 convergence. To compensate this delay we introduce a novel technique which leads to training dynamics aligned with standard distributed optimization. Compared to ZeRO, our implementation and experiments on several LLMs pre-training and fine-tuning tasks demonstrates that $\\textbf{ACCO}$ reduces the learning time up to 87% and successfully allows both sharding optimizer states across workers and the use of heterogeneous hardware."
    }
]
[
    {
        "title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention",
        "link_suffix": "/forum?id=kFNxjehevx",
        "link": "https://openreview.net/forum?id=kFNxjehevx",
        "pdf_link": "https://openreview.net/pdf?id=kFNxjehevx",
        "keywords": "Tabular Classification, Transformer, State-Space Models, Linear Attention, Scalability",
        "abstract": "Recent advances in the field of in-context learning (ICL) have demonstrated impressive performance for tabular classification, exemplified by TabPFN's success on small datasets. However, the quadratic complexity of the attention mechanism limits its applicability to larger datasets. To address this issue, we conduct a comprehensive comparison of popular scalable attention  alternatives, including state-space models (SSMs) and linear attention mechanisms, revealing that the inherent causality of SSMs hinders ICL performance for large datasets, while linear attention preserves effectiveness. Leveraging these insights, we introduce TabFlex, a model based on linear attention that supports thousands of features and hundreds of classes, capable of handling datasets with millions of samples. Extensive experiments demonstrate that TabFlex is significantly faster than most existing methods while achieving top-two performance on small datasets among 25 baselines, with a 2$\\times$ speedup over TabPFN and a 1.5$\\times$ speedup over XGBoost. On large datasets, TabFlex remains efficient (e.g., approximately 5 seconds on thepoker-handdataset, which consists of millions of samples), while achieving relatively solid performance."
    },
    {
        "title": "Unveiling the Backbone-Optimizer Coupling Bias in Visual Representation Learning",
        "link_suffix": "/forum?id=9XabBgqFgy",
        "link": "https://openreview.net/forum?id=9XabBgqFgy",
        "pdf_link": "https://openreview.net/pdf?id=9XabBgqFgy",
        "keywords": "Network Design, Optimization, Bias, Backbone, Transformer, Benchmark",
        "abstract": "This paper delves into the interplay between vision backbones and optimizers, revealing an inter-dependent phenomenon termed backbone-optimizer coupling bias} (BOCB). Notably, canonical CNNs, such as VGG and ResNet, exhibit a marked co-dependency with SGD, while recent architectures, including ViTs and ConvNeXt, share a strong coupling with adaptive learning rate optimizers. We further show that strong BOCB may result in extra tuning efforts and poor generalization ability for pre-trained neural networks, substantially limiting their real-world applications. Through in-depth analysis and apples-to-apples comparisons, however, we surprisingly observed that certain types of network architecture could significantly mitigate BOCB, which might serve as practical takeaways for backbone design. We hope this work can inspire the community to rethink the long-held assumptions on backbones and optimizers, consider their interplay in future studies, and contribute to more robust vision systems. The source code and models are publicly available."
    },
    {
        "title": "Understanding the Design Principles of Link Prediction in Directed Settings",
        "link_suffix": "/forum?id=eAisRJ7AiF",
        "link": "https://openreview.net/forum?id=eAisRJ7AiF",
        "pdf_link": "https://openreview.net/pdf?id=eAisRJ7AiF",
        "keywords": "directed link prediction, graph representation learning, link prediction heuristics, directed graph neural networks",
        "abstract": "Link prediction is a widely studied task in Graph Representation Learning (GRL) for modeling relational data. Early theories in GRL were based on the assumption of a symmetric adjacency matrix, reflecting an undirected setting. As a result, much of the following state-of-the-art research has continued to operate under this symmetry assumption, even though real-world data often involves crucial information conveyed through the direction of relationships. This oversight limits the ability of these models to fully capture the complexity of directed interactions. In this paper, we focus on the challenge of directed link prediction by evaluating key heuristics that have been successful in the undirected settings. We propose simple but effective adaptations of these heuristics to the directed link prediction task and demonstrate that these modifications yield competitive performance compared to leading Graph Neural Networks (GNNs) originally designed for undirected graphs. Through an extensive set of experiments, we derive insights that inform the development of a novel framework for directed link prediction, which not only surpasses baseline methods but also outperforms state-of-the-art GNNs on multiple benchmarks."
    },
    {
        "title": "AttackQA: Development and Adoption of a Dataset for Assisting Cybersecurity Operations using Fine-tuned and Open-Source LLMs",
        "link_suffix": "/forum?id=PRJ4n3CBzU",
        "link": "https://openreview.net/forum?id=PRJ4n3CBzU",
        "pdf_link": "https://openreview.net/pdf?id=PRJ4n3CBzU",
        "keywords": "LLM, Large Language Models, Generative AI, Dataset, Cyber, Security, MITRE, Chatbot, Judging, Quality, Control, Open source, RAG, Retrieval, Augmented, Generation",
        "abstract": "Retrieval-augmented generation (RAG) on specialized domain datasets has shown improved performance when large language models (LLMs) are fine-tuned for generating responses to user queries. In this study, we develop a cybersecurity question-answering (Q&A) dataset, called AttackQA, and employ it to build a RAG-based Q&A system designed for analysts in security operations centers. The dataset comprises 25,335 Q&A pairs, accompanied by rationales to facilitate fine-tuning and evaluation. 80% of the dataset was generated with help of a lightweight open-source LLM (LLama 3 8B), which produced over 1100 tokens per second with full 16-bit precision on specialized hardware. To ensure dataset quality, we fine-tuned LLama 3 70B to detect and reject low-quality Q&A pairs. In using the dataset for RAG, we demonstrate that fine-tuning open-source embeddings and LLMs can yield superior accuracy compared to OpenAI's state-of-the-art proprietary embedding and LLM (GPT-4o). Furthermore, we use Llama 3.1 405B as a judge to evaluate answer correctness, enabling the creation of a fully open-source, high-speed RAG and evaluation pipeline with an associated benchmark."
    },
    {
        "title": "GODA: Goal-conditioned Data Augmentation",
        "link_suffix": "/forum?id=Zsc453SAJa",
        "link": "https://openreview.net/forum?id=Zsc453SAJa",
        "pdf_link": "https://openreview.net/pdf?id=Zsc453SAJa",
        "keywords": "Offline reinforcement learning, diffusion model, data augmentation",
        "abstract": "Offline reinforcement learning (RL) enables policy learning from pre-collected offline datasets, relaxing the need to interact directly with the environment. However, limited by the quality of offline datasets, it generally fails to learn well-qualified policies in suboptimal datasets. To address datasets with insufficient optimal demonstrations, we introduce Goal-cOnditioned Data Augmentation (GODA), a novel goal-conditioned diffusion-based method for augmenting samples with higher quality.  Leveraging recent advancements in generative modeling, GODA incorporates a return-oriented goal condition with various selection mechanisms. Specifically, we introduce a controllable scaling technique to provide enhanced return-based guidance during data sampling. GODA learns a comprehensive distribution representation of the original offline datasets while generating new data with selectively higher-return goals, thereby maximizing the utility of limited optimal demonstrations. Furthermore, we propose a novel adaptive gated conditioning method for processing noised inputs and conditions, enhancing the capture of goal-oriented guidance. We conduct experiments on the D4RL benchmark and real-world challenges, specifically traffic signal control (TSC) tasks, to demonstrate GODA's effectiveness in enhancing data quality and superior performance compared to state-of-the-art data augmentation methods across various offline RL algorithms. Our code will be publicly accessible upon review."
    },
    {
        "title": "Modular addition without black-boxes: Compressing explanations of MLPs that compute numerical integration",
        "link_suffix": "/forum?id=yBhSORdXqq",
        "link": "https://openreview.net/forum?id=yBhSORdXqq",
        "pdf_link": "https://openreview.net/pdf?id=yBhSORdXqq",
        "keywords": "mechanistic interpretability, proof, guarantees, interpretability, numerical integration",
        "abstract": "Interpreting the behaviour of MLP layers in transformer models remains an open problem.\nThe goal of mechanistic interpretability is identifying the specific function learnt by the model, which is challenging to do in nonlinear domains---like MLPs---where low precision approximations of the learnt function can leave many degrees of freedom.\nWhile MLP layers that approximately implement linear functions can be well understood with low-precision approximations, we take on the challenge of approximating densely-connected MLPs.\nWe propose a formal definition for \u201cfull interpretation\u201d of a circuit: a compression of the explanation to a size that is linear in the parameter count of the circuit.\nWe investigate in the classic setting of the toy models trained on modular addition Nanda et al. (2023) and Zhong et al. (2023), where the MLP layer is treated as a black box. We extend the analysis to describe exactlyhowthe MLP layer computes the required trignometric identities. \nWe find that the MLP layer in one-layer transformers implementing the \u201cpizza\u201d algorithm can be understood as evaluating a quadrature scheme, where each neuron computes the area of a rectangle under the curve of a trigonometric integral identity.\nWe confirm this interpretation by using it to compress the MLP layer of a collection of modular addition transformers and prove non-vacuous bounds on the outputs of the MLP layer onallinputs in total timelinear in the number of neurons.\nOur code is available athttps://tinyurl.com/mod-add-integration."
    },
    {
        "title": "Private Mechanism Design via Quantile Estimation",
        "link_suffix": "/forum?id=JQQDePbfxh",
        "link": "https://openreview.net/forum?id=JQQDePbfxh",
        "pdf_link": "https://openreview.net/pdf?id=JQQDePbfxh",
        "keywords": "online auctions, differential privacy, mechanism design",
        "abstract": "We investigate the problem of designing differentially private (DP), revenue-maximizing single item auction. Specifically, we consider broadly applicable settings in mechanism design where agents' valuation distributions areindependent,non-identical, and can be eitherboundedorunbounded. Our goal is to design such auctions withpure, i.e., $(\\epsilon,0)$ privacy in polynomial time.In this paper, we propose two computationally efficient auction learning framework that achievespureprivacy under bounded and unbounded distribution settings. These frameworks reduces the problem of privately releasing a revenue-maximizing auction to the private estimation of pre-specified quantiles. Our solutions increase the running time by polylog factors compared to the non-private version. As an application, we show how to extend our results to the multi-round online auction setting with non-myopic bidders. To our best knowledge, this paper is the first to efficiently deliver a Myerson auction withpureprivacy and near-optimal revenue, and the first to provide such auctions forunboundeddistributions."
    },
    {
        "title": "Dreamer XL: Towards High-Resolution Text-to-3D Generation via Trajectory Score Matching",
        "link_suffix": "/forum?id=eAgnpmxUu1",
        "link": "https://openreview.net/forum?id=eAgnpmxUu1",
        "pdf_link": "https://openreview.net/pdf?id=eAgnpmxUu1",
        "keywords": "text-to-3D, 3DGS",
        "abstract": "In this work, we propose a novel Trajectory Score Matching (TSM) method that aims to solve the pseudo ground truth inconsistency problem caused by the accumulated error in Interval Score Matching (ISM) when using the Denoising Diffusion Implicit Models (DDIM) inversion process. Unlike ISM which adopts the inversion process of DDIM to calculate on a single path, our TSM method leverages the inversion process of DDIM to generate two paths from the same starting point for calculation. Since both paths start from the same starting point, TSM can reduce the accumulated error compared to ISM, thus alleviating the problem of pseudo ground truth inconsistency. TSM enhances the stability and consistency of the model's generated paths during the distillation process. We demonstrate this experimentally and further show that ISM is a special case of TSM. Furthermore, to optimize the current multi-stage optimization process from high-resolution text to 3D generation, we adopt Stable Diffusion XL for guidance. In response to the issues of abnormal replication and splitting caused by unstable gradients during the 3D Gaussian splatting process when using Stable Diffusion XL, we propose a pixel-by-pixel gradient clipping method. Extensive experiments show that our model significantly surpasses the state-of-the-art models in terms of visual quality and performance."
    },
    {
        "title": "Reasoning-Enhanced Healthcare Predictions with Knowledge Graph Community Retrieval",
        "link_suffix": "/forum?id=8fLgt7PQza",
        "link": "https://openreview.net/forum?id=8fLgt7PQza",
        "pdf_link": "https://openreview.net/pdf?id=8fLgt7PQza",
        "keywords": "EHR Prediction, Large Language Models, Knowledge Graphs",
        "abstract": "Large language models (LLMs) have demonstrated significant potential in clinical decision support. Yet LLMs still suffer from hallucinations and lack fine-grained contextual medical knowledge, limiting their high-stake healthcare applications such as clinical diagnosis. Traditional retrieval-augmented generation (RAG) methods attempt to address these limitations but frequently retrieve sparse or irrelevant information, undermining prediction accuracy. We introduce KARE, a novel framework that integrates knowledge graph (KG) community-level retrieval with LLM reasoning to enhance healthcare predictions. KARE constructs a comprehensive multi-source KG by integrating biomedical databases, clinical literature, and LLM-generated insights, and organizes it using hierarchical graph community detection and summarization for precise and contextually relevant information retrieval. Our key innovations include: (1) a dense medical knowledge structuring approach enabling accurate retrieval of relevant information; (2) a dynamic knowledge retrieval mechanism that enriches patient contexts with focused, multi-faceted medical insights; and (3) a reasoning-enhanced prediction framework that leverages these enriched contexts to produce both accurate and interpretable clinical predictions. Extensive experiments demonstrate that KARE outperforms leading models by up to 10.8-15.0% on MIMIC-III and 12.6-12.7% on MIMIC-IV for mortality and readmission predictions. In addition to its impressive prediction accuracy, our framework leverages the reasoning capabilities of LLMs, enhancing the trustworthiness of clinical predictions."
    },
    {
        "title": "Brain Mapping with Dense Features: Grounding Cortical Semantic Selectivity in Natural Images With Vision Transformers",
        "link_suffix": "/forum?id=yJ9QNbpMi2",
        "link": "https://openreview.net/forum?id=yJ9QNbpMi2",
        "pdf_link": "https://openreview.net/pdf?id=yJ9QNbpMi2",
        "keywords": "fMRI, visual cortex, neuroscience, cognitive science, brain, vision transformer, semantic selectivity",
        "abstract": "Advances in large-scale artificial neural networks have facilitated novel insights into the functional topology of the brain. Here, we leverage this approach to study how semantic categories are organized in the human visual cortex.\nTo overcome the challenge presented by the co-occurrence of multiple categories in natural images, we introduce BrainSAIL (Semantic Attribution and Image Localization), a method for isolating specific neurally-activating visual concepts in images. BrainSAIL exploits semantically consistent, dense spatial features from pre-trained vision models, building upon their demonstrated ability to robustly predict neural activity. This method derives clean, spatially dense embeddings without requiring any additional training, and employs a novel denoising process that leverages the semantic consistency of images under random augmentations. By unifying the space of whole-image embeddings and dense visual features and then applying voxel-wise encoding models to these features, we enable the identification of specific subregions of each image which drive selectivity patterns in different areas of the higher visual cortex. This provides a powerful tool for dissecting the neural mechanisms that underlie semantic visual processing for natural images. We validate BrainSAIL on cortical regions with known category selectivity, demonstrating its ability to accurately localize and disentangle selectivity to diverse visual concepts. Next, we demonstrate BrainSAIL's ability to characterize high-level visual selectivity to scene properties and low-level visual features such as depth, luminance, and saturation, providing insights into the encoding of complex visual information. Finally, we use BrainSAIL to directly compare the feature selectivity of different brain encoding models across different regions of interest in visual cortex. Our innovative method paves the way for significant advances in mapping and decomposing high-level visual representations in the human brain."
    },
    {
        "title": "Feature-Specific Coefficients of Determination in Tree Ensembles",
        "link_suffix": "/forum?id=mFHPoYVeqN",
        "link": "https://openreview.net/forum?id=mFHPoYVeqN",
        "pdf_link": "https://openreview.net/pdf?id=mFHPoYVeqN",
        "keywords": "Explainable AI, Feature importance, Shapley Value, Tree ensemble",
        "abstract": "Tree ensemble methods provide promising predictions with models difficult to interpret. Recent introduction of Shapley values for individualized feature contributions, accompanied with several fast computing algorithms for predicted values, shows intriguing results. However, individualizing coefficients of determination, aka $R^2$, for each feature is challenged by the underlying quadratic losses, although these coefficients allow us to comparatively assess single feature's contribution to tree ensembles. Here we propose an efficient algorithm, Q-SHAP, that reduces the computational complexity to polynomial time when calculating Shapley values related to quadratic losses. Our extensive simulation studies demonstrate that this approach not only enhances computational efficiency but also improves the estimation accuracy of feature-specific coefficients of determination."
    },
    {
        "title": "X-Drive: Cross-modality Consistent Multi-Sensor Data Synthesis for Driving Scenarios",
        "link_suffix": "/forum?id=IEMmEd5Jgm",
        "link": "https://openreview.net/forum?id=IEMmEd5Jgm",
        "pdf_link": "https://openreview.net/pdf?id=IEMmEd5Jgm",
        "keywords": "diffusion models; multi-modality data; autonomous driving",
        "abstract": "Recent advancements have exploited diffusion models for the synthesis of either LiDAR point clouds or camera image data in driving scenarios. Despite their success in modeling single-modality data marginal distribution, there is an under- exploration in the mutual reliance between different modalities to describe com- plex driving scenes. To fill in this gap, we propose a novel framework, X-DRIVE, to model the joint distribution of point clouds and multi-view images via a dual- branch latent diffusion model architecture. Considering the distinct geometrical spaces of the two modalities, X-DRIVE conditions the synthesis of each modality on the corresponding local regions from the other modality, ensuring better alignment and realism. To further handle the spatial ambiguity during denoising, we design the cross-modality condition module based on epipolar lines to adaptively learn the cross-modality local correspondence. Besides, X-DRIVE allows for controllable generation through multi-level input conditions, including text, bounding box, image, and point clouds. Extensive results demonstrate the high-fidelity synthetic results of X-DRIVE for both point clouds and multi-view images, adhering to input conditions while ensuring reliable cross-modality consistency."
    },
    {
        "title": "Selective Attention Improves Transformer",
        "link_suffix": "/forum?id=v0FzmPCd1e",
        "link": "https://openreview.net/forum?id=v0FzmPCd1e",
        "pdf_link": "https://openreview.net/pdf?id=v0FzmPCd1e",
        "keywords": "selective attention, attention, transformer, llm, language model",
        "abstract": "Unneeded elements in the attention's context degrade performance. We introduce Selective Attention, a simple parameter-free change to the standard attention mechanism which reduces attention to unneeded elements. Selective attention consistently improves language modeling performance across model sizes and context lengths. For example, a range of transformers trained with the language modeling objective on C4 with selective attention perform equivalently to transformers with standard attention modules with ~2X more parameters and heads. In addition, selective attention allows reducing the size of the attention's context buffer, leading to substantial reductions in the memory and compute requirements during inference. For example, transformers with 100M parameters and context sizes of 512, 1,024, and 2,048 need 16X, 25X, and 47X less memory for their attention module, respectively, when equipped with selective attention, as those without selective attention, with the same validation perplexity."
    },
    {
        "title": "Interpreting and Steering LLM Representations with Mutual Information-based Explanations on Sparse Autoencoders",
        "link_suffix": "/forum?id=vc1i3a4O99",
        "link": "https://openreview.net/forum?id=vc1i3a4O99",
        "pdf_link": "https://openreview.net/pdf?id=vc1i3a4O99",
        "keywords": "large language models, sparse autoencoders, usable xai, explanations, interpretability",
        "abstract": "Large language models (LLMs) excel at addressing general human queries, yet they can falter or produce unexpected responses in specific scenarios. Gaining insight into the internal states of LLMs is key to understanding their successes and failures, as well as to refining their capabilities. Recent efforts have applied sparse autoencoders to learn a feature basis for explaining LLM hidden spaces. However, current post-hoc explanation methods can not effectively describe the semantic meaning of the learned features, and it is difficult to steer LLM behaviors by manipulating these features. Our analysis reveals that existing explanation methods suffer from the frequency bias issue, i.e., they tend to focus on trivial linguistic patterns rather than semantics. To overcome this, we propose explaining the learned features from a fixed vocabulary set to mitigate the frequency bias, and designing a novel explanation objective based on the mutual information theory to better express the meaning of the features. We further suggest two strategies to steer LLM representations by modifying sparse feature activations in response to user queries during runtime. Empirical results demonstrate that our method generates more discourse-level explanations than the baselines, and can effectively steer LLM behaviors to defend against jailbreak attacks in the wild. These findings highlight the value of explanations for steering LLM representations in downstream applications."
    },
    {
        "title": "CoreInfer: Accelerating Large Language Model Inference with Semantics-Inspired Adaptive Sparse Activation",
        "link_suffix": "/forum?id=s3003xWtfd",
        "link": "https://openreview.net/forum?id=s3003xWtfd",
        "pdf_link": "https://openreview.net/pdf?id=s3003xWtfd",
        "keywords": "Sparse Activation, Sparse Inference, Efficient LLMs, LLMs Inference Acceleration",
        "abstract": "Large language models (LLMs) with billions of parameters have sparked a new wave of exciting AI applications. However, their high computational costs and memory demands during inference pose significant challenges. Dynamic sparse activation inference, which activates only a small number of neurons for each token, offers a novel way to accelerate model inference without degrading performance, showing great potential for resource-constrained hardware devices. Nevertheless, existing methods predict activated neurons based on individual tokens with additional MLP, which involve frequent changes in activation maps and resource calls, limiting the acceleration benefits of sparse activation.\nIn this paper, we introduceCoreInfer, an MLP-free adaptive sparse activation inference method based on sentence-level prediction. Specifically, we propose the concept of sentence-wise core neurons,  which refers to the subset of neurons most critical for a given sentence, and empirically demonstrate its effectiveness. To determine the core neurons, we explore the correlation between core neurons and the sentence's semantics. Remarkably, we discovered that core neurons exhibit both stability and similarity in relation to the sentence's semantics\u2014an insight overlooked by previous studies. Building on this finding, we further design two semantic-based methods for predicting core neurons to fit different input scenarios. In CoreInfer, the core neurons are determined during the pre-filling stage and fixed during the encoding stage, enabling zero-cost sparse inference. We evaluated the model generalization and task generalization of CoreInfer across various models and tasks. Notably, on an NVIDIA TITAN XP GPU, CoreInfer achieved a 10.33 $\\times$ and 2.72 $\\times$ speedup compared to the Huggingface implementation and PowerInfer, respectively."
    },
    {
        "title": "ACAV-1M: Data Curation and Benchmarking for Audio-Visual Representation Learning",
        "link_suffix": "/forum?id=HUjFpOgVCK",
        "link": "https://openreview.net/forum?id=HUjFpOgVCK",
        "pdf_link": "https://openreview.net/pdf?id=HUjFpOgVCK",
        "keywords": "audio-visual learning, sound souce localization, audio-visual video parsing",
        "abstract": "The natural alignment of visual and audio information in videos provides a strong learning signal. However, commonly used large-scale video datasets contain audio-visual signals that are not aligned, e.g. background music. This limits the development of robust models that leverage the complementary nature of audio and video data. To address this limitation, we curate ACAV-1M, a new large-scale dataset that contains one million samples sourced from the ACAV-100M dataset. The ACAV-1M dataset is obtained through a pipeline that ensures the audio-visual correspondence and synchronization of samples in the dataset. Our pipeline transforms raw video and audio into text captions, followed by text summarization and an extensive filtering procedure. The filtering is done based on audio-caption alignment, audio-visual instance semantic alignment, and temporal synchronization. Furthermore, we propose an audio-visual learning benchmark that supports a diverse range of downstream tasks. Empirical evaluations demonstrate that models trained on ACAV-1M achieve superior performance compared to using existing datasets across all tasks. Our ACAV-1M dataset and code to reproduce all benchmark results will be made publicly available upon acceptance."
    },
    {
        "title": "Advancing Table Understanding of Large Language Models via Feature Re-ordering",
        "link_suffix": "/forum?id=R8APzK2Vsf",
        "link": "https://openreview.net/forum?id=R8APzK2Vsf",
        "pdf_link": "https://openreview.net/pdf?id=R8APzK2Vsf",
        "keywords": "Large language models, Tabular data, Feature re-ordering",
        "abstract": "Large Language Models (LLMs) exhibit exceptional proficiency in comprehending human language. Despite their significant success across a wide array of tasks, including text generation, translation, question answering, and even code generation, understanding tabular data remains a challenging task. Especially, tabular data lacks an intrinsic order of the different features (table fields), whereas LLMs take only sequential inputs. Consequently, an artificial order is imposed, the impact of which on the performance of LLMs has not yet been thoroughly investigated. Surprisingly, as discovered in this work, this artificially induced order bias dramatically influences the performance of LLMs on tasks related to tabular data. Mitigating the order bias presents a significant challenge. To address this, we propose a simple and cost-effective method, Re-Ordering Tabular feATures fOR LLM (ROTATOR-LLM), to conduct test-time compute without fine-tuning the base LLM. Aiming at optimizing the feature order of tabular data and boosting LLMs\u2019 capability to better understand the data semantics, ROTATOR-LLM re-frames the ordering problem as a feature trajectory generation task. A dynamic programming based meta-controller is trained to auto-regressively generate an individualized feature trajectory for each data instance via accumulative value estimation of the serialized feature input through the LLM\u2019s final performance metrics. Model performance is maximized by iteratively selecting features across different steps. Experimental results on multiple datasets and LLMs show close to or over 20% performance boosts via features reordered by ROTATOR-LLM against the un-ordered counterpart. Also, it outperforms State-Of-The-Art tabular LLM methods with significant margin. Moreover, meta-controller demonstrates strong transferability: the tested LLMs gain performance enhancements when utilizing a meta-controller trained on one of them."
    },
    {
        "title": "Preventing Collapse in Contrastive Learning with Orthonormal Prototypes (CLOP)",
        "link_suffix": "/forum?id=SsWMJ42hJO",
        "link": "https://openreview.net/forum?id=SsWMJ42hJO",
        "pdf_link": "https://openreview.net/pdf?id=SsWMJ42hJO",
        "keywords": "Deep Learning, Contrastive Learning, Neural Collapse, Image Classification",
        "abstract": "Contrastive learning has emerged as a powerful method in deep learning, excelling at learning effective representations through contrasting samples from different distributions. However, neural collapse, where embeddings converge into a lower-dimensional space, poses a significant challenge, especially in semi-supervised and self-supervised setups. In this paper, we first theoretically analyze the effect of large learning rates on contrastive losses that solely rely on the cosine similarity metric, and derive a theoretical bound to mitigate this collapse. Building on these insights, we propose CLOP, a novel semi-supervised loss function designed to prevent neural collapse by promoting the formation of orthogonal linear subspaces among class embeddings. Unlike prior approaches that enforce a simplex ETF structure, CLOP focuses on subspace separation, leading to more distinguishable embeddings. Through extensive experiments on real and synthetic datasets, we demonstrate that CLOP enhances performance, providing greater stability across different learning rates and batch sizes."
    },
    {
        "title": "Generative Visual Instruction Tuning",
        "link_suffix": "/forum?id=hVwS9KkY6V",
        "link": "https://openreview.net/forum?id=hVwS9KkY6V",
        "pdf_link": "https://openreview.net/pdf?id=hVwS9KkY6V",
        "keywords": "generative models, multimodal large language models, instruction tuning, Vision Language, Representation Learning",
        "abstract": "We propose to use automatically generated instruction-following data to improve the zero-shot capabilities of a large multimodal model with additional support for generative and image editing tasks. We achieve this by curating a new multimodal instruction-following set using GPT-4V and existing datasets for image generation and editing. Using this instruction set and the existing LLaVA-Finetune instruction set for visual understanding tasks, we produce GenLLaVA, a Generative Large Language and Visual Assistant. GenLLaVA is built through a strategy that combines three types of large pretrained models through instruction finetuning: Mistral for language modeling, SigLIP for image-text matching, and StableDiffusion for text-to-image generation. Our model demonstrates visual understanding capabilities superior to LLaVA and additionally demonstrates competitive results with native multimodal models such as Unified-IO 2, paving the way for building advanced general-purpose visual assistants by effectively re-using existing multimodal models."
    },
    {
        "title": "STAR: Stability-Inducing Weight Perturbation for Continual Learning",
        "link_suffix": "/forum?id=6N5OM5Duuj",
        "link": "https://openreview.net/forum?id=6N5OM5Duuj",
        "pdf_link": "https://openreview.net/pdf?id=6N5OM5Duuj",
        "keywords": "Continual Learning, Deep Learning, Weight Perturbation, Representation Learning",
        "abstract": "Humans can naturally learn new and varying tasks in a sequential manner. \n  Continual learning is a class of learning algorithms that updates its learned model as it sees new data (on potentially new tasks) in a sequence.\n  A key challenge in continual learning is that as the model is updated to learn new tasks, it becomes susceptible to \\textit{catastrophic forgetting}, where knowledge of previously learned tasks is lost. A popular approach to mitigate forgetting during continual learning is to maintain a small buffer of previously-seen samples, and to replay them during training. However, this approach is limited by the small buffer size and, while forgetting is reduced, it is still present.  In this paper, we propose\na novel loss function STAR that exploits the worst-case parameter perturbation that reduces the KL-divergence of model predictions with that of its local parameter neighborhood to promote stability and alleviate forgetting. STAR can be combined with almost any existing rehearsal-based methods as a plug-and-play component. We empirically show that STAR consistently improves performance of existing methods by up to $\\sim15%$ across varying baselines, and achieves superior or competitive accuracy to that of state-of-the-art methods aimed at improving rehearsal-based continual learning."
    },
    {
        "title": "OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code",
        "link_suffix": "/forum?id=Y1XkzMJpPd",
        "link": "https://openreview.net/forum?id=Y1XkzMJpPd",
        "pdf_link": "https://openreview.net/pdf?id=Y1XkzMJpPd",
        "keywords": "Open-endedness, Environment Generation, Reinforcement Learning",
        "abstract": "Open-ended and AI-generating algorithms aim to continuously generate and solve increasingly complex tasks indefinitely, offering a promising path toward more general intelligence. To accomplish this grand vision, learning must occur within a vast array of potential tasks. Existing approaches to automatically generating environments are constrained within manually predefined, often narrow distributions of environment, limiting their ability to create any learning environment. To address this limitation, we introduce a novel framework, OMNI-EPIC, that augments previous work in Open-endedness via Models of human Notions of Interestingness (OMNI) with Environments Programmed in Code (EPIC). OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent\u2019s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simulatable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents\u2019 learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms."
    },
    {
        "title": "Systematic Assessment of Tabular Data Synthesis",
        "link_suffix": "/forum?id=3ANoEa7roV",
        "link": "https://openreview.net/forum?id=3ANoEa7roV",
        "pdf_link": "https://openreview.net/pdf?id=3ANoEa7roV",
        "keywords": "Tabular Data Synthesis, Privacy, Evaluation Metric, Generative Models",
        "abstract": "Data synthesis has been advocated as an important approach for utilizing data while protecting data privacy. In recent years, a plethora of tabular data synthesis algorithms (i.e., synthesizers) have been proposed. A comprehensive understanding of these synthesizers' strengths and weaknesses remains elusive due to the absence of principled evaluation metrics and head-to-head comparisons between state-of-the-art deep generative approaches and statistical methods. In this paper, we examine and critique existing evaluation metrics, and introduce a set of new metrics in terms of fidelity, privacy, and utility to address their limitations. Based on the proposed metrics, we also devise a unified objective for tuning, which can consistently improve the quality of synthetic data for all methods. We conducted extensive evaluations of 8 different types of synthesizers on 12 real-world datasets and identified some interesting findings, which offer new directions for privacy-preserving data synthesis."
    },
    {
        "title": "CSA: Data-efficient Mapping of Unimodal Features to Multimodal Features",
        "link_suffix": "/forum?id=6Mg7pjG7Sw",
        "link": "https://openreview.net/forum?id=6Mg7pjG7Sw",
        "pdf_link": "https://openreview.net/pdf?id=6Mg7pjG7Sw",
        "keywords": "multimodal, representation learning, relative representations",
        "abstract": "Multimodal encoders like CLIP excel in tasks such as zero-shot image classification and cross-modal retrieval. However, they require excessive training data. We propose canonical similarity analysis (CSA), which uses two unimodal encoders to replicate multimodal encoders using limited data. CSA maps unimodal features into a multimodal space, using a new similarity score to retain only the multimodal information. CSA only involves the inference of unimodal encoders and a cubic-complexity matrix decomposition, eliminating the need for extensive GPU-based model training. Experiments show that CSA outperforms CLIP while requiring $300,000\\times$ fewer multimodal data pairs and $6\\times$ fewer unimodal data for ImageNet classification and misinformative news captions detection. CSA surpasses the state-of-the-art method to map unimodal features to multimodal features. We also demonstrate CSA\u2019s ability with modalities beyond image and text, paving the way for future modality pairs with limited paired multimodal data but abundant unpaired unimodal data, such as lidar and text."
    },
    {
        "title": "Sparse spatio temporal reconstruction with Closable Kernel Space",
        "link_suffix": "/forum?id=nu1H4MdxcB",
        "link": "https://openreview.net/forum?id=nu1H4MdxcB",
        "pdf_link": "https://openreview.net/pdf?id=nu1H4MdxcB",
        "keywords": "Kernel Learning, Koopman Theory, Spatio-Temporal Reconstruction, Reproducing Kernel Hilbert space, Dynamical Systems",
        "abstract": "Quantifying spatio-temporal (ST) measures of dynamical systems is a crucial problem with wide ranging applications in climate modeling, epidemiology, physical processes to name a few. \nWe are interested in the same but motivated by a rather practical scenario where sparse information is collected non-uniformly. \nTo reconstruct the underlying dynamical system under such constraints, we propose a novel algorithm for learning the Koopman operator via a Reproducing Kernel Hilbert Space (RKHS) based on the Laplacian Kernel Extended Dynamic Mode Decomposition (Lap-KeDMD).\nWe further show that our kernel space resolves a fundamental issue that is required for a faithful reconstruction of the Koopman operator of the underlying ST data by proving its closability. \nWe demonstrate our method on standard benchmark cases --\nBurger's Equation, fluid flow across cylinder and Duffing Oscillator. \nWe then reconstruct the Koopman operator for a real ST Seattle traffic flow data that is collected non-uniformly. Necessary comparisons are made between the current state of the art kernel methods corresponding to Gaussian Radial Basis Function (GRBF) Kernel. \nSuch empirical comparisons leads us to conclude that Lap-KeDMD remarkably outperforms as compared to that of aforementioned counter-part thereby, making the Laplacian Kernel a robust choice for such ST quantification."
    },
    {
        "title": "EC-Diffuser: Multi-Object Manipulation via Entity-Centric Behavior Generation",
        "link_suffix": "/forum?id=o3pJU5QCtv",
        "link": "https://openreview.net/forum?id=o3pJU5QCtv",
        "pdf_link": "https://openreview.net/pdf?id=o3pJU5QCtv",
        "keywords": "Diffusion, Object-Centric Representation, Robotic Manipulation",
        "abstract": "Object manipulation is a common component of everyday tasks, but learning to manipulate objects from high-dimensional observations presents significant challenges. These challenges are heightened in multi-object environments due to the combinatorial complexity of the state space as well as of the desired behaviors. While recent approaches have utilized large-scale offline data to train models from pixel observations, achieving performance gains through scaling, these methods struggle with compositional generalization in unseen object configurations with constrained network and dataset sizes. To address these issues, we propose a novel behavioral cloning (BC) approach that leverages object-centric representations and an entity-centric Transformer with diffusion-based optimization, enabling efficient learning from offline image data. Our method first decomposes observations into Deep Latent Particles (DLP), which are then processed by our entity-centric Transformer that computes attention at the particle level, simultaneously predicting object dynamics and the agent's actions. Combined with the ability of diffusion models to capture multi-modal behavior distributions, this results in substantial performance improvements in multi-object tasks and, more importantly, enables compositional generalization. We present BC agents capable of zero-shot generalization to perform tasks with novel compositions of objects and goals, including larger numbers of objects than seen during training. We provide video rollouts on our webpage:https://sites.google.com/view/ec-diffuser."
    }
]
[{"title": "Regularized Conditional Optimal Transport for Feature Learning and Generalization Bounds", "link_suffix": "/forum?id=mgHv1XXoGm", "link": "https://openreview.net/forum?id=mgHv1XXoGm", "pdf_link": "https://openreview.net/pdf?id=mgHv1XXoGm", "keywords": "conditional optimal transport, Kullback-Leibler divergence, Rademacher complexity, anchors", "abstract": "This paper develops the regularized conditional optimal transport for feature learning in an embedding space.  Instead of using joint distributions of data, we introduce conditional distributions to some reference conditional distributions in terms of the Kullback-Leibler (KL) divergence. Using conditional distributions provides the flexibility in controlling the transferring range of given data points. When the alternating optimization technique is employed to solve our model,  it is interesting to find that conditional and marginal distributions have closed-form solutions. Moreover, the use of conditional distributions facilitates the derivation of the generalization bound of our model via the Rademacher complexity, which characterizes its convergence speed in terms of the number of samples. By optimizing the anchors (centroids)  defined in the model, we also employ optimal transport and  autoencoders to explore an embedding space of samples in the clustering problem. In the experimental part, we demonstrate that the proposed model achieves promising performance on some learning tasks. Moreover, we construct a conditional Wasserstein classifier to classify set-valued objects.", "title_embedding_index": 22100, "title_abs_embedding_index": 22125}, {"title": "GCML: Grounding Complex Motions using Large Language Model in 3D Scenes", "link_suffix": "/forum?id=30SmPrfBMA", "link": "https://openreview.net/forum?id=30SmPrfBMA", "pdf_link": "https://openreview.net/pdf?id=30SmPrfBMA", "keywords": "human-scene interaction, human motion generation, large language model, 3d visual grounding", "abstract": "To solve the problem of generating complex motions, we introduce GCML (Grounding Complex Motions using Large Language Model). This method supports complex texts and scenes as inputs, such as mopping the floor in a cluttered room. Such everyday actions are challenging for current motion generation models for two main reasons. First, such complex actions are rarely found in existing HSI datasets, which places high demands on the generalization capabilities of current data-driven models. Second, these actions are composed of multiple stages, with considerable variation between them, making it difficult for models to understand and generate the appropriate motions. Current methods in the HSI field can control the generation of simple actions under multiple constraints, such as walking joyfully toward a door, but they cannot handle the complexity of tasks like the one described above. By incorporating a Large Language Model and a 3D Visual Grounding Model into the HSI domain, our approach can decompose complex user prompts into a sequence of simpler subtasks and identify interaction targets and obstacles within the scene. Based on these subtask descriptions and spatial control information, the Motion Generation Model generates a sequence of full-body motions, which are then combined into a long motion sequence that aligns with both the user's input and the scene semantics. Experimental results demonstrate that our method achieves competitive performance for simple action generation on the HUMANISE dataset and the generalization evaluation set. For complex motion generation, we created a new evaluation set by automatically generating possible behaviors of virtual humans in common indoor scenes, where our method significantly outperforms existing approaches. Project Page:https://anonymous.4open.science/w/GCML-4562/", "title_embedding_index": 22101, "title_abs_embedding_index": 22126}, {"title": "Image Super-Resolution with Text Prompt Diffusion", "link_suffix": "/forum?id=vTdwuKUc5Z", "link": "https://openreview.net/forum?id=vTdwuKUc5Z", "pdf_link": "https://openreview.net/pdf?id=vTdwuKUc5Z", "keywords": "Image Super-Resolution, Text Prompt, Diffusion Model", "abstract": "Image super-resolution (SR) methods typically model degradation to improve reconstruction accuracy in complex and unknown degradation scenarios. However, extracting degradation information from low-resolution images is challenging, which limits the model performance. To boost image SR performance, one feasible approach is to introduce additional priors. Inspired by advancements in multi-modal methods and text prompt image processing, we introduce text prompts to image SR to provide degradation priors. Specifically, we first design a text-image generation pipeline to integrate text into the SR dataset through the text degradation representation and degradation model. The text representation applies a discretization manner based on the binning method to describe the degradation abstractly. This method maintains the flexibility of the text and is user-friendly. Meanwhile, we propose the PromptSR to realize the text prompt SR. The PromptSR utilizes the pre-trained language model (e.g., T5 or CLIP) to enhance restoration. We train the PromptSR on the generated text-image dataset. Extensive experiments indicate that introducing text prompts into SR, yields excellent results on both synthetic and real-world images. The code will be released.", "title_embedding_index": 22102, "title_abs_embedding_index": 22127}, {"title": "Multi-Epoch Learning with Data Augmentation for Deep Click-Through Rate Prediction", "link_suffix": "/forum?id=7vH8DO2oPk", "link": "https://openreview.net/forum?id=7vH8DO2oPk", "pdf_link": "https://openreview.net/pdf?id=7vH8DO2oPk", "keywords": "Click-Through Rate Prediction, Overfitting, Multi-Epoch Learning, Incremental Learning", "abstract": "This paper investigates the one-epoch overfitting phenomenon in Click-Through Rate (CTR) models, where performance notably declines at the start of the second epoch. Despite extensive research, the efficacy of multi-epoch training over the conventional one-epoch approach remains unclear. As a result, all potential rewards from multi-epoch training can hardly be obtained. We identify the overfitting of the embedding layer instead of the Multi-Layer Perceptron (MLP) layers, as the primary issue. To address this,\nwe introduce a novel Multi-Epoch learning with Data Augmentation (MEDA) framework. We design algorithms for both non-incremental and incremental learning scenarios in the industry.\nMEDA minimizes overfitting by reducing the dependency of the embedding layer on trained data, and achieves data augmentation through training the MLP with varied embedding spaces.\nMEDA's effectiveness is established on our finding that pre-trained MLP layers can adapt to new embedding spaces and enhance model performances. This adaptability highlights the importance of the relative relationships among embeddings over their absolute positions.\nWe conduct extensive experiments on several public and business datasets, and the effectiveness of data augmentation and superiority over conventional single-epoch training are consistently demonstrated for both non-incremental and incremental learning scenarios.\nTo our knowledge, MEDA represents the first universally reliable multi-epoch training strategy tailored for deep CTR prediction models. We provide theoretical analyses of the reason behind the effectiveness of MEDA.\nFinally, MEDA has exhibited significant benefits in a real-world incremental-learning online advertising system.", "title_embedding_index": 22103, "title_abs_embedding_index": 22128}, {"title": "AITTI: Learning Adaptive Inclusive Token for Text-to-Image Generation", "link_suffix": "/forum?id=LqBPkN8GTH", "link": "https://openreview.net/forum?id=LqBPkN8GTH", "pdf_link": "https://openreview.net/pdf?id=LqBPkN8GTH", "keywords": "Fairness, Bias Mitigation, Generative Model", "abstract": "Despite the high-quality results of text-to-image generation, stereotypical biases have been spotted in their generated contents, compromising the fairness of generative models. In this work, we propose to learn adaptive inclusive tokens to shift the attribute distribution of the final generative outputs. Unlike existing de-biasing approaches, our method requires neither explicit attribute specification nor prior knowledge of the bias distribution. Specifically, the core of our method is a lightweight adaptive mapping network, which can customize the inclusive tokens for the concepts to be de-biased, making the tokens generalizable to unseen concepts regardless of their original bias distributions. This is achieved by tuning the adaptive mapping network with a handful of balanced and inclusive samples using an anchor loss. Experimental results demonstrate that our method outperforms previous bias mitigation methods without attribute specification while preserving the alignment between generative results and text descriptions. Moreover, our method achieves comparable performance to models that require specific attributes or editing directions for generation. Extensive experiments showcase the effectiveness of our adaptive inclusive tokens in mitigating stereotypical bias in text-to-image generation. The code will be publicly available.", "title_embedding_index": 22104, "title_abs_embedding_index": 22129}, {"title": "SIFM:  A Foundation Model for Multi-granularity Arctic Sea Ice Forecasting", "link_suffix": "/forum?id=OPmYlaixqO", "link": "https://openreview.net/forum?id=OPmYlaixqO", "pdf_link": "https://openreview.net/pdf?id=OPmYlaixqO", "keywords": "Arctic Sea Ice Forecasting, Foundation Model, Multi-granularity", "abstract": "Arctic sea ice performs a vital role in global climate and has paramount impacts on both polar ecosystems and coastal communities. \nIn the last few years, multiple deep learning based pan-Arctic sea ice concentration (SIC) forecasting methods have emerged and showcased superior performance over physics-based dynamical models. \nHowever, previous methods forecast SIC at a fixed temporal granularity, e.g. sub-seasonal or seasonal, thus only leveraging inter-granularity information and overlooking the plentiful inter-granularity correlations.\nSIC at various temporal granularities exhibits cumulative effects and are naturally consistent, with short-term fluctuations potentially impacting long-term trends and long-term trends provides effective hints for facilitating short-term forecasts in Arctic sea ice.\nTherefore, in this study, we propose to cultivate temporal multi-granularity that naturally derived from Arctic sea ice reanalysis data and provide a unified perspective for modeling SIC via our Sea Ice Foundation Model. \nSIFM is delicately designed to leverage both intra-granularity and inter-granularity information for capturing granularity-consistent representations that promote forecasting skills. \nOur extensive experiments show that SIFM outperforms off-the-shelf deep learning models for their specific temporal granularity.", "title_embedding_index": 22105, "title_abs_embedding_index": 22130}, {"title": "Can Information-Theoretic Generalization Bound Explain the Generalization of Pre-trained Language Model?", "link_suffix": "/forum?id=OEabcqgoQQ", "link": "https://openreview.net/forum?id=OEabcqgoQQ", "pdf_link": "https://openreview.net/pdf?id=OEabcqgoQQ", "keywords": "Information-Theoretic Generalization Bound, Pre-trained Language Model", "abstract": "Although language models exhibit exceptional generalization capabilities in downstream tasks after extensive text pre-training, the underlying causes behind this generalization remain unclear. Existing studies on information-theoretic generalization bounds suggest that the compression of information stored in the weights (IIW) is a crucial factor influencing a model's ability to generalize, with some experiments indicating a correlation between lower IIW and improved generalization. However, it remains uncertain whether IIW is applicable to pre-trained language models.  In this work, we find that using IIW can explain why the pre-trained language models have better generalization compared to non-pre-trained language models. Unfortunately, we also discover that IIW does not consistently reflect the degree of generalization when applying IIW to study the fine-tuning process of pre-trained language models. We revisit existing IIW estimation methods, highlighting their limitations in accurately estimating IIW based on theoretical and empirical evidence. Our findings suggest that current information-theoretic generalization bounds, constrained by the limitations of IIW estimation methodologies, fail to accurately capture the generalisation performance of pre-trained language models.", "title_embedding_index": 22106, "title_abs_embedding_index": 22131}, {"title": "Posterior Label Smoothing for Node Classification", "link_suffix": "/forum?id=wJPMe9UKow", "link": "https://openreview.net/forum?id=wJPMe9UKow", "pdf_link": "https://openreview.net/pdf?id=wJPMe9UKow", "keywords": "node classification, label smoothing", "abstract": "Soft labels can improve the generalization of a neural network classifier in many domains, such as image classification. Despite its success, the current literature has overlooked the efficiency of label smoothing in node classification with graph-structured data. In this work, we propose a simple yet effective label smoothing for the transductive node classification task. We design the soft label to encapsulate the local context of the target node through the neighborhood label distribution. We apply the smoothing method for seven baseline models to show its effectiveness. The label smoothing methods improve the classification accuracy in 10 node classification datasets in most cases. In the following analysis, we find that incorporating global label statistics in posterior computation is the key to the success of label smoothing. Further investigation reveals that the soft labels mitigate overfitting during training, leading to better generalization performance. Our code is available athttps://anonymous.4open.science/r/PosteL.", "title_embedding_index": 22107, "title_abs_embedding_index": 22132}, {"title": "Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient", "link_suffix": "/forum?id=D9GoWJJxS5", "link": "https://openreview.net/forum?id=D9GoWJJxS5", "pdf_link": "https://openreview.net/pdf?id=D9GoWJJxS5", "keywords": "Optimization-based Pruning, Back-Propagation-Free, Structural Pruning, Large Language Models", "abstract": "In contrast to moderate-size neural network pruning, structural weight pruning on the Large-Language Models (LLMs) imposes a novel challenge on the efficiency of the pruning algorithms, due to the heavy computation/memory demands of the LLMs. Recent efficient LLM pruning methods typically operate at the post-training phase without the expensive weight finetuning, however, their pruning criteria often rely on heuristically hand-crafted metrics, potentially leading to suboptimal performance. We instead propose a novel optimization-based structural pruning that learns the pruning masks in a probabilistic space directly by optimizing the loss of the pruned model. To preserve the efficiency, our method eliminates the back-propagation through the LLM per se during the optimization, requiring only the forward pass of the LLM. We achieve this by learning an underlying Bernoulli distribution to sample binary pruning masks, where we decouple the Bernoulli parameters from the LLM loss, thus facilitating an efficient optimization via a policy gradient estimator without back-propagation. As a result, our method is able to 1) operate at structural granularities of channels, heads, and layers, 2) support global and heterogeneous pruning (i.e., our method automatically determines different redundancy for different layers), and 3) optionally initialize with a metric-based method (for our Bernoulli distributions). Extensive experiments on LLaMA, LLaMA-2, LLaMA-3, Vicuna, and Mistral using the C4 and WikiText2 datasets demonstrate that our method operates for 2.7 hours with around 35GB memory for the 13B models on a single A100 GPU, and our pruned models outperform the state-of-the-arts w.r.t. both perplexity and the majority of various zero-shot tasks. Codes will be released.", "title_embedding_index": 22108, "title_abs_embedding_index": 22133}, {"title": "TimeStep Master: Asymmetrical Mixture of Timestep LoRA Experts for Versatile and Efficient Diffusion Models in Vision", "link_suffix": "/forum?id=Xqo4eObgQX", "link": "https://openreview.net/forum?id=Xqo4eObgQX", "pdf_link": "https://openreview.net/pdf?id=Xqo4eObgQX", "keywords": "Visual Generation, Diffusion Model, LoRA", "abstract": "Diffusion models have driven the advancement of vision generation over the past years. \nHowever, \nit is often difficult to apply these large models in downstream tasks, \ndue to massive fine-tuning cost.\nRecently, \nLow-Rank Adaptation (LoRA) has been applied for efficient tuning of diffusion models.\nUnfortunately, \nthe capabilities of LoRA-tuned diffusion models are limited, \nsince the same LoRA is used for different timesteps of the diffusion process.\nTo tackle this problem, \nwe introduce a general and concise TimeStep Master (TSM) paradigm with two key fine-tuning stages.\nIn the fostering stage (1-stage), \nwe apply different LoRAs to fine-tune the diffusion model at different timestep intervals.\nThis results in different TimeStep LoRA experts that can effectively capture different noise levels. \nIn the assembling stage (2-stage),\nwe design a novel asymmetrical mixture of TimeStep LoRA experts,\nvia core-context collaboration of experts at multi-scale intervals.\nFor each timestep,\nwe leverage TimeStep LoRA expert within the smallest interval as the core expert without gating, \nand use experts within the bigger intervals as the context experts with time-dependent gating.\nConsequently,\nour TSM can effectively model the noise level via the expert in the finest interval,\nand \nadaptively integrate contexts from the experts of other scales,\nboosting the versatility of diffusion models.\nTo show the effectiveness of our TSM paradigm, \nwe conduct extensive experiments on three typical and popular LoRA-related tasks of diffusion models, \nincluding \ndomain adaptation, \npost-pretraining,\nand \nmodel distillation.\nOur TSM achieves the state-of-the-art results on all these tasks, \nthroughout various model structures (UNet, DiT and MM-DiT) and visual data modalities (Image, Video), \nshowing its remarkable generalization capacity.", "title_embedding_index": 22109, "title_abs_embedding_index": 22134}, {"title": "Streaming Video Understanding and Multi-round Interaction with Memory-enhanced Knowledge", "link_suffix": "/forum?id=JbPb6RieNC", "link": "https://openreview.net/forum?id=JbPb6RieNC", "pdf_link": "https://openreview.net/pdf?id=JbPb6RieNC", "keywords": "Video MLLM; Streaming Video Understanding", "abstract": "Recent advances in Large Language Models (LLMs) have enabled the development of Video-LLMs, advancing multimodal learning by bridging video data with language tasks. However, current video understanding models struggle with processing long video sequences, supporting multi-turn dialogues, and adapting to real-world dynamic scenarios. To address these issues, we propose StreamChat, a training-free framework for streaming video reasoning and conversational interaction. StreamChat leverages a novel hierarchical memory system to efficiently process and compress video features over extended sequences, enabling real-time, multi-turn dialogue. Our framework incorporates a parallel system scheduling strategy that enhances processing speed and reduces latency, ensuring robust performance in real-world applications. Furthermore, we introduce StreamBench, a versatile benchmark that evaluates streaming video understanding across diverse media types and interactive scenarios, including multi-turn interactions and complex reasoning tasks.  Extensive evaluations on StreamBench and other public benchmarks demonstrate that StreamChat significantly outperforms existing state-of-the-art models in terms of accuracy and response times, confirming its effectiveness for streaming video understanding.", "title_embedding_index": 22110, "title_abs_embedding_index": 22135}, {"title": "Beyond the convexity assumption: Realistic tabular data generation under quantifier-free real linear constraints", "link_suffix": "/forum?id=rx0TCew0Lj", "link": "https://openreview.net/forum?id=rx0TCew0Lj", "pdf_link": "https://openreview.net/pdf?id=rx0TCew0Lj", "keywords": "tabular data generation, neuro-symbolic AI, informed machine learning, safe AI", "abstract": "Synthetic tabular data generation has traditionally been a challenging problem due to the high complexity of the underlying distributions that characterise this type of data. Despite recent advances in deep generative models (DGMs), existing methods often fail to produce realistic datapoints that are well-aligned with available background knowledge.\nIn this paper, we address this limitation by introducing Disjunctive Refinement Layer (DRL), a novel layer designed\nto enforce the alignment of generated data with the background knowledge specified in user-defined constraints.\nDRL is the first method able to automatically make deep learning models inherently compliant with constraints as expressive as quantifier-free linear formulas, which can define non-convex and even disconnected spaces. \nOur experimental analysis shows that DRL not only guarantees constraint satisfaction but also improves efficacy in downstream tasks. Notably, when applied to DGMs that frequently violate constraints, DRL eliminates violations entirely. Further, it improves performance metrics by up to 21.4% in F1-score and 20.9% in Area Under the ROC Curve, thus demonstrating its practical impact on data generation.", "title_embedding_index": 22111, "title_abs_embedding_index": 22136}, {"title": "Large Scale Knowledge Washing", "link_suffix": "/forum?id=dXCpPgjTtd", "link": "https://openreview.net/forum?id=dXCpPgjTtd", "pdf_link": "https://openreview.net/pdf?id=dXCpPgjTtd", "keywords": "knowledge unlearning, large language models", "abstract": "Large language models show impressive abilities in memorizing world knowledge, which leads to concerns regarding memorization of private information, toxic or sensitive knowledge, and copyrighted content. We introduce the problem of Large Scale Knowledge Washing, focusing on unlearning an extensive amount of factual knowledge. Previous unlearning methods usually define the reverse loss and update the model via backpropagation, which may affect the model's fluency and reasoning ability or even destroy the model due to extensive training with the reverse loss. Existing works introduce additional data from downstream tasks to prevent the model from losing capabilities, which requires downstream task awareness. Controlling the tradeoff of unlearning existing knowledge while maintaining existing capabilities is also challenging. To this end, we propose LaW (Large Scale Washing), where we update the MLP layers in decoder-only large language models to perform knowledge washing, as inspired by model editing methods. We derive a new objective with the knowledge to be unlearned to update the weights of certain MLP layers. Experimental results demonstrate the effectiveness of LaW in forgetting target knowledge while maximally maintaining reasoning ability. The code will be open-sourced.", "title_embedding_index": 22112, "title_abs_embedding_index": 22137}, {"title": "Noise is More Than Just Interference: Information Infusion Networks for Anomaly Detection", "link_suffix": "/forum?id=09TI1yUo9K", "link": "https://openreview.net/forum?id=09TI1yUo9K", "pdf_link": "https://openreview.net/pdf?id=09TI1yUo9K", "keywords": "Self-supervised learning, Anomaly detection", "abstract": "3D anomaly detection is a crucial task in computer vision, aiming to identify anomalous points or regions from point cloud data. However, existing methods may encounter challenges when handling point clouds with high intra-class variance, especially for methods that rely on registration techniques. In this study, we propose a novel 3D anomaly detection method, termed Information Gain Block-based Anomaly Detection (IGB-AD), to address the challenges of insufficient anomaly detection information and high intra-class variance. To extract ordered features from 3D point clouds, the technique of Rotation-Invariant Farthest Point Sampling (RIFPS) is first introduced. Then, an Information Perfusion (IP) module composed of stacked Information Gain Blocks (IGB) is proposed to utilize prior noise to provide more distinguishing information for the features, where IGB is designed to utilize noise in a reverse-thinking manner to enhance anomaly detection. Finally, a Packet Downsampling (PD) technique is developed to preserve key information between multiple clusters to solve the complex downsampling situation. The main purpose of the framework is to utilize the effective information within prior noise to provide more detection criteria for anomaly detection. In addition, an Intra-Class Diversity (ICD) 3D dataset is constructed, which contains multiple categories with high class-variance. Experimental results show that the proposed IGB-AD method achieves the State-Of-The-Arts (SOTA) performance on the Anomaly ShapeNet dataset, with an P-AUROC of 81.5% and I-AUROC of 80.9%, and also gains the best performance on the ICD dataset, with an P-AUROC of 57.4% and I-AUROC of 60.2%. Our dataset will be released after acceptance.", "title_embedding_index": 22113, "title_abs_embedding_index": 22138}, {"title": "Self-Updatable Large Language Models with Parameter Integration", "link_suffix": "/forum?id=aCPFCDL9QY", "link": "https://openreview.net/forum?id=aCPFCDL9QY", "pdf_link": "https://openreview.net/pdf?id=aCPFCDL9QY", "keywords": "Large Language Models, Knowledge Injection, Self-Updatable LLMs", "abstract": "Despite significant advancements in large language models (LLMs), the rapid and frequent integration of small-scale experiences, such as interactions with sur- rounding objects, remains a substantial challenge. Two critical factors in assimilating these experiences are (1)Efficacy: the ability to accurately remember recent events; (2)Retention: the capacity to recall long-past experiences. Current methods either embed experiences within model parameters using continual learning, model editing, or knowledge distillation techniques, which often struggle with rapid updates and complex interactions, or rely on external storage to achieve long-term retention, thereby increasing storage requirements. In this paper, we proposeSELF-PARAM(Self-Updatable Large Language Models with Parameter Integration). SELF-PARAM requires no extra parameters while ensuring near-optimal efficacy and long-term retention. Our method employs a training objective that minimizes the Kullback-Leibler (KL) divergence between the predictions of an original model (with access to contextual information) and a target model (without such access). By generating diverse question-answer pairs related to the knowledge and minimizing the KL divergence across this dataset, we update the target model to internalize the knowledge seamlessly within its parameters. Evaluations on question-answering and conversational recommendation tasks demonstrate that SELF-PARAM significantly outperforms existing methods, even when accounting for non-zero storage requirements. This advancement paves the way for more efficient and scalable integration of experiences in large language models by embedding knowledge directly into model parameters.", "title_embedding_index": 22114, "title_abs_embedding_index": 22139}, {"title": "Language Model Empowered Spatio-Temporal Forecasting via Physics-Aware Reprogramming", "link_suffix": "/forum?id=wCNuEA5MSv", "link": "https://openreview.net/forum?id=wCNuEA5MSv", "pdf_link": "https://openreview.net/pdf?id=wCNuEA5MSv", "keywords": "spatio-temporal forecasting, time series forecasting", "abstract": "Spatio-temporal forecasting is pivotal in numerous real-world applications, including transportation planning, energy management, and climate monitoring. \nIn this work, we aim to harness the reasoning and generalization abilities of Pre-trained Language Models (PLMs) for more effective spatio-temporal forecasting, particularly in data-scarce scenarios. \nHowever, recent studies uncover that PLMs, which are primarily trained on textual data, often falter when tasked with modeling the intricate correlations inherent in numerical time series, thereby limiting their effectiveness in comprehending spatio-temporal data.\nTo bridge the gap, we propose REPST, a physics-aware PLM reprogramming framework tailored for spatio-temporal forecasting. \nSpecifically, we first propose a physics-aware decomposer that adaptively disentangles spatially correlated time series into interpretable sub-components, which facilitates PLM\u2019s understanding of sophisticated spatio-temporal dynamics via a divide-and-conquer strategy.\nMoreover, we propose a selective discrete reprogramming scheme, which introduces an expanded spatio-temporal vocabulary space to project spatio-temporal series into discrete representations. This scheme minimizes the information loss during reprogramming and enriches the representations derived by PLMs.\nExtensive experiments on real-world datasets show that the proposed REPST outperforms twelve state-of-the-art baseline methods, particularly in data-scarce scenarios, highlighting the effectiveness and superior generalization capabilities of PLMs for spatio-temporal forecasting.", "title_embedding_index": 22115, "title_abs_embedding_index": 22140}, {"title": "IPSeg: Image Posterior Mitigates Semantic Drift in Class-Incremental Segmentation", "link_suffix": "/forum?id=C53FwQZigu", "link": "https://openreview.net/forum?id=C53FwQZigu", "pdf_link": "https://openreview.net/pdf?id=C53FwQZigu", "keywords": "Incremental Learning, Semantic Segmentation", "abstract": "Class incremental learning aims to enable models to learn from sequential, non-stationary data streams across different tasks without catastrophic forgetting. In class incremental semantic segmentation (CISS), the semantic content of the background class changes across incremental phases, which is known as \\textbf{semantic drift}. Our research identifies two severe issues within semantic drift: separate optimization and noisy semantics, which significantly degrade CISS performance. Based on this insight, we propose a simple yet effective method, \\textbf{I}mage \\textbf{P}osterior and Semantics Decoupling for \\textbf{Seg}mentation (IPSeg), designed to address these challenges through two specific mechanisms. First, IPSeg leverages image posterior probabilities as guidance to resolve the separate optimization issue. Second, IPSeg utilizes semantics decoupling to effectively handle noisy semantics and tailor the learning strategies for different types of knowledge. Experiment results on the Pascal VOC 2012 and ADE20K datasets demonstrate superior performance compared to previous state-of-the-art approaches, particularly in more realistic and challenging long-term scenarios. Furthermore, IPSeg exhibits excellent properties in terms of both learning plasticity and memory stability.", "title_embedding_index": 22116, "title_abs_embedding_index": 22141}, {"title": "Process Reward Model with Q-value Rankings", "link_suffix": "/forum?id=wQEdh2cgEk", "link": "https://openreview.net/forum?id=wQEdh2cgEk", "pdf_link": "https://openreview.net/pdf?id=wQEdh2cgEk", "keywords": "process reward model, reasoning", "abstract": "Process Reward Modeling (PRM) is critical for complex reasoning and decision-making tasks where the accuracy of intermediate steps significantly influences the overall outcome. Existing PRM approaches, primarily framed as classification problems, employ cross-entropy loss to independently evaluate each step's correctness. This method can lead to suboptimal reward distribution and does not adequately address the interdependencies among steps. To address these limitations, we introduce the Process Q-value Model (PQM), a novel framework that redefines PRM in the context of a Markov Decision Process. PQM optimizes Q-value rankings based on a novel comparative loss function, enhancing the model's ability to capture the intricate dynamics among sequential decisions. This approach provides a more granular and theoretically grounded methodology for process rewards. Our extensive empirical evaluations across various sampling policies, language model backbones, and multi-step reasoning benchmarks show that PQM outperforms classification-based PRMs. The effectiveness of the comparative loss function is highlighted in our comprehensive ablation studies, confirming PQM\u2019s practical efficacy and theoretical advantage.", "title_embedding_index": 22117, "title_abs_embedding_index": 22142}, {"title": "PostCast: Generalizable Postprocessing for Precipitation Nowcasting via Unsupervised Blurriness Modeling", "link_suffix": "/forum?id=v2zcCDYMok", "link": "https://openreview.net/forum?id=v2zcCDYMok", "pdf_link": "https://openreview.net/pdf?id=v2zcCDYMok", "keywords": "AI for Science; Precipitation Nowcasting; Diffusion Model; Zero-shot Blurriness Kernel; Auto-scale Denoise Guidance", "abstract": "Precipitation nowcasting plays a pivotal role in socioeconomic sectors, especially in severe convective weather warnings. Although notable progress has been achieved by approaches mining the spatiotemporal correlations with deep learning, these methods still suffer severe blurriness as the lead time increases, which hampers accurate predictions for extreme precipitation. To alleviate blurriness, researchers explore generative methods conditioned on blurry predictions. However, the pairs of blurry predictions and corresponding ground truth need to be given in advance, making the training pipeline cumbersome and limiting the generality of generative models within blurry modes that appear in training data. By rethinking the blurriness in precipitation nowcasting as a blur kernel acting on predictions, we propose an unsupervised postprocessing method to eliminate the blurriness without the requirement of training with the pairs of blurry predictions and corresponding ground truth. Specifically, we utilize blurry predictions to guide the generation process of a pre-trained unconditional denoising diffusion probabilistic model (DDPM) to obtain high-fidelity predictions with eliminated blurriness. A zero-shot blur kernel estimation mechanism and an auto-scale denoise guidance strategy are introduced to adapt the unconditional DDPM to any blurriness modes varying from datasets and lead times in precipitation nowcasting. Extensive experiments are conducted on 7 precipitation radar datasets, demonstrating the generality and superiority of our method.", "title_embedding_index": 22118, "title_abs_embedding_index": 22143}, {"title": "Efficient Fine-Tuning of Quantized LLMs via Three-Stage Optimization", "link_suffix": "/forum?id=zcx6rIMbbR", "link": "https://openreview.net/forum?id=zcx6rIMbbR", "pdf_link": "https://openreview.net/pdf?id=zcx6rIMbbR", "keywords": "Efficient Fine-Tuning, NLP, Iterative Optimization, Layer-wise Quantization and Low-Rank Configuration", "abstract": "To address the memory consumption and computational efficiency issues in fine-tuning large language models (LLMs), Parameter-Efficient Fine-Tuning (PEFT) and quantization have emerged. Recent studies have combined the two and have proposed adjusting parameters before fine-tuning to reduce quantization errors, aiming to improve fine-tuning performance. We find that the performance of fine-tuning on the adjusted quantized models is even worse than using the original quantized models directly, as the adjusted model is essentially a completely different model from the original quantized model. Additionally, we have discovered that due to the poor robustness of quantized models, increasing the training difficulty may result in even worse outcomes. To address this, we propose two constraints for fine-tuning quantized models, and based on these, we introduce a general fine-tuning framework called QR-Adaptor. This framework bypasses the network errors introduced by quantization and directly uses actual performance and memory as optimization targets. Through initialization, extrapolation, and interpolation, it quickly solves this gradient-free optimization problem. Experimental results demonstrate that our method yields fine-tuned low-bit quantized models that outperform fine-tuned 16-bit models while maintaining the same memory usage as fine-tuning 4-bit models. For example, in the zero-shot test on MMLU, it improves accuracy by 3.3% over both LoftQ and LQ-LoRA.", "title_embedding_index": 22119, "title_abs_embedding_index": 22144}, {"title": "Shake-It-Off: Jailbreaking Black-Box Large Language Models by Shaking Off Objectionable Semantics", "link_suffix": "/forum?id=uQRQo0cWZ6", "link": "https://openreview.net/forum?id=uQRQo0cWZ6", "pdf_link": "https://openreview.net/pdf?id=uQRQo0cWZ6", "keywords": "Jailbreaking Attacks, Large Language Models", "abstract": "Large language models (LLMs) are vulnerable to jailbreaking attacks (Zou et al., 2023; Liu et al., 2024), in which attackers use adversarially designed prompts to bypass the model\u2019s safeguard and force the model to generate objectionable content. The present paper studies jailbreaking attacks from a red team\u2019s viewpoint and proposes a novel black-box attack method, called Shake-It-Off (SHAKE), that only requires the response generated by the victim model. Given objective query $T_{obj}$, our method iteratively shakes off the objectionable semantics of $T_{obj}$, making it gradually approximates a pre-defied decontaminated query $T_{dec}$. We conduct extensive experiments on multiple baseline methods and victim LLMs. The experimental results show that SHAKE outperforms the baseline methods in attack success rates while requiring much less running time and access to the victim model.", "title_embedding_index": 22120, "title_abs_embedding_index": 22145}, {"title": "ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via Chart-to-Code Generation", "link_suffix": "/forum?id=sGpCzsfd1K", "link": "https://openreview.net/forum?id=sGpCzsfd1K", "pdf_link": "https://openreview.net/pdf?id=sGpCzsfd1K", "keywords": "Dataset and Benchmark, Code generation, Chart Understand and Reasoning", "abstract": "We introduce a new benchmark, ChartMimic, aimed at assessing the visually-grounded code generation capabilities of large multimodal models (LMMs). ChartMimic utilizes information-intensive visual charts and textual instructions as inputs, requiring LMMs to generate the corresponding code for chart rendering.\nChartMimic includes $4,800$ human-curated (figure, instruction, code) triplets, which represent the authentic chart use cases found in scientific papers across various domains (e.g., Physics, Computer Science, Economics, etc). These charts span $18$ regular types and $4$ advanced types, diversifying into $201$ subcategories.\nFurthermore, we propose multi-level evaluation metrics to provide an automatic and thorough assessment of the output code and the rendered charts.\nUnlike existing code generation benchmarks, ChartMimic places emphasis on evaluating LMMs' capacity to harmonize a blend of cognitive capabilities, encompassing visual understanding, code generation, and cross-modal reasoning. The evaluation of $3$ proprietary models and $14$ open-weight models highlights the substantial challenges posed by ChartMimic. Even the advanced GPT-4o, InternVL2-Llama3-76B only achieve an average score of $82.2$ and $61.6$, respectively, indicating significant room for improvement. \nWe anticipate that ChartMimic will inspire the development of LMMs, advancing the pursuit of artificial general intelligence.", "title_embedding_index": 22121, "title_abs_embedding_index": 22146}, {"title": "Does Training with Synthetic Data Truly Protect Privacy?", "link_suffix": "/forum?id=C8niXBHjfO", "link": "https://openreview.net/forum?id=C8niXBHjfO", "pdf_link": "https://openreview.net/pdf?id=C8niXBHjfO", "keywords": "ML privacy, membership inference", "abstract": "As synthetic data becomes increasingly popular in machine learning tasks, numerous methods\u2014without formal differential privacy guarantees\u2014use synthetic data for training. These methods often claim, either explicitly or implicitly, to protect the privacy of the original training data.\nIn this work, we explore four different training paradigms\u2014coreset selection, dataset distillation, data-free knowledge distillation, and synthetic data generated from diffusion models. While all these methods utilize synthetic data for training, they lead to vastly different conclusions regarding privacy preservation. This highlights that empirical approaches to preserving data privacy require careful and rigorous evaluation; otherwise, they risk providing a false sense of privacy.", "title_embedding_index": 22122, "title_abs_embedding_index": 22147}, {"title": "POINTS: Improving Your Vision-language Model with Affordable Strategies", "link_suffix": "/forum?id=gpP68EP1Jn", "link": "https://openreview.net/forum?id=gpP68EP1Jn", "pdf_link": "https://openreview.net/pdf?id=gpP68EP1Jn", "keywords": "vision-language model, multimodal", "abstract": "In recent years, vision-language models have achieved significant advancements, excelling in tasks once deemed challenging, such as optical character recognition and geometric problem-solving. Despite these impressive achievements, several critical issues remain unaddressed: 1) Proprietary models rarely disclose detailed information about their architectures. In contrast, while open-source models provide visibility into their training strategies, detailed ablations of these strategies are highly anticipated. 2) Pre-training data is currently under-explored in open-source works, with most efforts empirically adding datasets from diverse sources, making the entire process elusive and cumbersome. 3) During the fine-tuning stage, the focus is often on adding and ablating more datasets, which frequently leads to diminishing returns. Therefore, refining data schemes is essential for further enhancing model performance.\nTo address these issues, we propose the following contributions in this paper: 1) We trained a robust baseline model, leveraging the latest technological advancements in vision-language models. Building upon existing advancements, we introduced effective improvements and conducted comprehensive ablation and validation for each technique incorporated into this strong baseline.\n2) Inspired by recent work on large language models, we propose filtering pre-training data using perplexity, selecting the data with the lowest perplexity as the training set. This approach allowed us to train on a curated 1M dataset, resulting in highly competitive performance. 3) During the visual instruction tuning stage, we experimented with model soup on different datasets when further introducing more datasets into the training set brought marginal improvements. Integrating these innovations, we obtained a model with 9B parameters, performing competitively with a series of existing state-of-the-art models. Additionally, these strategies we propose are efficient and relatively lightweight, allowing the community to adopt them easily for their models.", "title_embedding_index": 22123, "title_abs_embedding_index": 22148}, {"title": "Dealing with Frequency Collapse in Time Series Embeddings by Post-Embedding reMapping", "link_suffix": "/forum?id=SwIkknEqmt", "link": "https://openreview.net/forum?id=SwIkknEqmt", "pdf_link": "https://openreview.net/pdf?id=SwIkknEqmt", "keywords": "Time Series Forcasting, deep learning, spectral analysis", "abstract": "Transformer-based methods have made significant strides in time series forecasting tasks in recent years. However, we observe underfitting in numerous samples, e.g., pattern shifts or excessive deviation in extreme value regions when testing the transform-based model that converges on the training set. Through the proposed spectral analysis of adjacent embedding sequences, we identify a frequency collapse issue in the embedding features generated by the top layer of the transformer backbone. To address this, we propose the Post-Embedding ReMapping (PErM) strategy that improves the frequency-domain representation of embeddings using fixed non-linear functions. Both two kinds of PErM functions that we insert into the model can effectively resolve the frequency collapse issue and lead to significant improvements in prediction performance. Experimental results show that our method outperforms state-of-the-art algorithms across multiple datasets. We will release our code after the review phase.", "title_embedding_index": 22124, "title_abs_embedding_index": 22149}]
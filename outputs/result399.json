[
    {
        "title": "Differentiable Average Precision Loss in DETR",
        "link_suffix": "/forum?id=AVAlVPdQp7",
        "link": "https://openreview.net/forum?id=AVAlVPdQp7",
        "pdf_link": "https://openreview.net/pdf?id=AVAlVPdQp7",
        "keywords": "Object detection\uff0cDEtection TRansformer, AP loss",
        "abstract": "Average Precision (AP) is a widely used metric for evaluating object detection systems because it effectively integrates both classification accuracy and localization precision. In this paper, we conduct a detailed analysis of the characteristics of the AP metric, focusing on its non-differentiability and non-convexity. Building on this analysis, we propose a novel loss function called Differentiable Average Precision Loss (DAP-loss), which provides a differentiable approximation of AP, thereby enabling direct optimization of AP across a set of images. We validate the effectiveness of DAP-loss both theoretically and empirically, extending its application to the cost functions used in the Hungarian matching algorithm, which makes it suitable for end-to-end detection models. DAP-loss supports the simultaneous optimization of classification and localization tasks within an end-to-end framework, eliminating the need for hyperparameters to balance these tasks\u2014a common challenge in traditional methods. In the later stages of training, we applied DAP-loss to replace the original loss functions in several state-of-the-art end-to-end models, including DETR and Deformable DETR. Experimental results demonstrate that our method achieves significant improvements over baselines on the COCO dataset."
    },
    {
        "title": "A Truncated Newton Method for Optimal Transport",
        "link_suffix": "/forum?id=gWrWUaCbMa",
        "link": "https://openreview.net/forum?id=gWrWUaCbMa",
        "pdf_link": "https://openreview.net/pdf?id=gWrWUaCbMa",
        "keywords": "Computational optimal transport, numerical optimization, numerical linear algebra",
        "abstract": "Developing a contemporary optimal transport (OT) solver requires navigating trade-offs among several critical requirements: GPU parallelization, scalability to high-dimensional problems, theoretical convergence guarantees, empirical performance in terms of precision versus runtime, and numerical stability in practice. With these challenges in mind, we introduce a specialized truncated Newton algorithm for entropic regularized OT. In addition to proving that locally quadratic convergence is possible without assuming a Lipschitz Hessian, we provide strategies to maximally exploit the high rate of local convergence in practice. Our GPU-parallel algorithm exhibits exceptionally favorable runtime performance, achieving high precision orders of magnitude faster than many existing alternatives. This is evidenced by wall-clock time experiments on 4096-dimensional MNIST and color transfer problems. The scalability of the algorithm is showcased on an extremely large OT problem with $n \\approx 10^6$, solved approximately under weak entopric regularization."
    },
    {
        "title": "Cavia: Camera-controllable Multi-view Video Diffusion with View-Integrated Attention",
        "link_suffix": "/forum?id=sNntRFmn72",
        "link": "https://openreview.net/forum?id=sNntRFmn72",
        "pdf_link": "https://openreview.net/pdf?id=sNntRFmn72",
        "keywords": "Video Generation",
        "abstract": "In recent years there have been remarkable breakthroughs in image-to-video generation.\nHowever, the 3D consistency and camera controllability of generated frames have remained unsolved. Recent studies have attempted to incorporate camera control into the generation process, but their results are often limited to simple trajectories or lack the ability to generate consistent videos from multiple distinct camera paths for the same scene. To address these limitations, we introduceCavia, a novel framework for camera-controllable, multi-view video generation, capable of converting an input image into multiple spatiotemporally consistent videos. Our framework extends the spatial and temporal attention modules into view-integrated attention modules, improving both viewpoint and temporal consistency. This flexible design allows for joint training with diverse curated data sources, including scene-level static videos, object-level synthetic multi-view dynamic videos, and real-world monocular dynamic videos. To our best knowledge, Cavia is the first of its kind that allows the user to precisely specify camera motion while obtaining object motion. To the best of our knowledge, Cavia is the first framework that enables users to generate multiple videos of the same scene with precise control over camera motion, while simultaneously preserving object motion. Extensive experiments demonstrate that Cavia surpasses state-of-the-art methods in terms of geometric consistency and perceptual quality."
    },
    {
        "title": "Enhancing Multimodal Survival Prediction with Pathology Reports in Hyperbolic Space",
        "link_suffix": "/forum?id=PbC786k7qc",
        "link": "https://openreview.net/forum?id=PbC786k7qc",
        "pdf_link": "https://openreview.net/pdf?id=PbC786k7qc",
        "keywords": "Survival Prediction, Computational Pathology, Multimodal Medical Image Analysis",
        "abstract": "Survival prediction plays a crucial role in clinical routines, as it facilitates cancer diagnosis and prognosis. While previous methods primarily utilized Whole Slide Images (WSIs) and genomic data for this task, the intricate logic chain between WSIs and survival time poses a significant challenge, necessitating models capable of inferring complex logical relationships with minimal supervision. To address this issue, we enhance the current methodology by integrating pathology reports as the third modality, serving as a semantic bridge between WSIs and survival outcomes. The incorporation of pathology reports potentially bridges logical gaps in end-to-end training and guides models towards survival-relevant regions. Furthermore, we recognize the inherent hierarchical structure between pathology reports and WSIs, a relationship overlooked by current methods. This hierarchy manifests in two ways: 1) a single pathology term may entail multiple images, and 2) pathology terms generally convey more generic concepts. Hyperbolic space is particularly well-suited for this phenomenon due to its ability to effectively embed hierarchical structures and capture complex relationships. Therefore, we propose HyperSurv, a novel model employing hyperbolic geometry to represent the intricate interplay between pathology reports and WSIs. Specifically, we enforce an entailment relationship between reports and WSIs in the hyperbolic space, ensuring that each survival-relevant visual feature falls within at least one hyperbolic cone defined by a survival-relevant term in the report. These survival-relevant features are obtained through our attention pooling module. Additionally, we position pathology report representations closer to the origin to represent more generic concepts. Extensive experiments on four TCGA datasets (BLCA, UCEC, LUAD, and BRCA) demonstrate that our method achieves state-of-the-art performance."
    },
    {
        "title": "Accelerate High-Quality Diffusion Models with Inner Loop Feedback",
        "link_suffix": "/forum?id=MBkoYFftRa",
        "link": "https://openreview.net/forum?id=MBkoYFftRa",
        "pdf_link": "https://openreview.net/pdf?id=MBkoYFftRa",
        "keywords": "diffusion, image generation, efficiency",
        "abstract": "We propose Inner Loop Feedback (ILF), a novel approach to accelerate diffusion models' inference. ILF trains a lightweight module to predict future features in the denoising process by leveraging the outputs from a chosen diffusion backbone block at a given time step. This approach exploits two key intuitions; (1) the outputs of a given block at adjacent time steps are similar, and (2) performing partial computations for a step imposes a lower burden on the model than skipping the step entirely. Our method is highly flexible, since we find that the feedback module itself can simply be a block from the diffusion backbone, with all settings copied. Its influence on the diffusion forward can be tempered with a learnable scaling factor from zero initialization. We train this module using distillation losses; however, unlike some prior work where a full diffusion backbone serves as the student, our model freezes the backbone, training only the feedback module. While many efforts to optimize diffusion models focus on achieving acceptable image quality in extremely few steps (1-4 steps), our emphasis is on matching best case results (typically achieved in 20 steps) while significantly reducing runtime. ILF achieves this balance effectively, demonstrating strong performance for both class-to-image generation with diffusion transformer (DiT) and text-to-image generation with DiT-based PixArt-alpha and PixArt-sigma. The quality of ILF's 1.7x-1.8x speedups are confirmed by FID, CLIP score, CLIP Image Quality Assessment, ImageReward, and qualitative comparisons."
    },
    {
        "title": "GroundingBooth: Grounding Text-to-Image Customization",
        "link_suffix": "/forum?id=6jyEj4rGZJ",
        "link": "https://openreview.net/forum?id=6jyEj4rGZJ",
        "pdf_link": "https://openreview.net/pdf?id=6jyEj4rGZJ",
        "keywords": "Subject-Driven Generation; Text-to-image Customization; Diffusion Models, Vision-Language, Grounding",
        "abstract": "Recent studies in text-to-image customization show great success in generating personalized object variants given several images of a subject. While existing methods focus more on preserving the identity of the subject, they often fall short of controlling the spatial relationship between objects. In this work, we introduce GroundingBooth, a framework that achieves zero-shot instance-level spatial grounding on both foreground subjects and background objects in the text-to-image customization task. Our proposed text-image grounding module and masked cross-attention layer allow us to generate personalized images with both accurate layout alignment and identity preservation while maintaining text-image coherence. With such layout control, our model inherently enables the customization of multiple subjects at once. Our model is evaluated on both layout-guided image synthesis and reference-based customization tasks, showing strong results compared to existing methods. Our work is the first work to achieve a joint grounding on both subject-driven foreground generation and text-driven background generation. Our code will be publicly available."
    },
    {
        "title": "KV Prediction for Improved Time to First Token",
        "link_suffix": "/forum?id=QlvL6eEOC6",
        "link": "https://openreview.net/forum?id=QlvL6eEOC6",
        "pdf_link": "https://openreview.net/pdf?id=QlvL6eEOC6",
        "keywords": "time to first token, TTFT, on-device, llm, inference",
        "abstract": "Inference with transformer-based language models begins with a prompt processing step. In this step, the model generates the first output token and stores the KV cache needed for future generation steps. This prompt processing step can be computationally expensive, taking 10s of seconds or more for billion-parameter models on edge devices when prompt lengths or batch sizes rise. This degrades user experience by introducing significant latency into the model's outputs. To reduce the time spent producing the first output (known as the ``time to first token'', or TTFT of a pretrained model, we introduce a novel method called KV Prediction. In our method, a small auxiliary model is used to process the prompt and produce an approximation of the KV cache used by a base model. This approximated KV cache is then used with the base model for autoregressive generation without the need to query the auxiliary model again. We demonstrate that our method produces a pareto-optimal efficiency-accuracy trade-off when compared to baselines. On TriviaQA, we demonstrate relative accuracy improvements in the range of 15%-50% across a range of TTFT FLOPs budgets. We also demonstrate accuracy improvements of up to 30% on HumanEval python code completion at fixed TTFT FLOPs budgets. Additionally, we benchmark models on an Apple M2 Pro CPU and demonstrate that our improvement in FLOPs translates to a TTFT speedup on hardware. We will release our code for reproducibility."
    },
    {
        "title": "Automated Proof Generation for Rust Code via Self-Evolution",
        "link_suffix": "/forum?id=2NqssmiXLu",
        "link": "https://openreview.net/forum?id=2NqssmiXLu",
        "pdf_link": "https://openreview.net/pdf?id=2NqssmiXLu",
        "keywords": "Large Language Models, Program Verification",
        "abstract": "Ensuring correctness is crucial for code generation. Formal verification offers a definitive assurance of correctness, but demands substantial human effort in proof construction and hence raises a pressing need for automation. The primary obstacle lies in the severe lack of data \u2014 there is much less proof than code for LLMs to train upon. In this paper, we introduce SAFE, a novel framework that\novercomes the lack of human-written proof to enable automated proof generation of Rust code. SAFE establishes a self-evolving cycle where data synthesis and fine-tuning collaborate to enhance the model capability, leveraging the definitive power of a symbolic verifier in telling correct proof from incorrect ones. SAFE also re-purposes the large number of synthesized incorrect proofs to train the self-\ndebugging capability of the fine-tuned models, empowering them to fix incorrect proofs based on the verifier\u2019s feedback. SAFE demonstrates superior efficiency and precision compared to GPT-4o. Through tens of thousands of synthesized\nproofs and the self-debugging mechanism, we improve the capability of open-source models, initially unacquainted with formal verification, to automatically write proof for Rust code. This advancement leads to a significant improvement in performance, achieving a 70.50% accuracy rate in a benchmark crafted by human experts, a significant leap over GPT-4o\u2019s performance of 24.46%."
    },
    {
        "title": "Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems",
        "link_suffix": "/forum?id=LkzuPorQ5L",
        "link": "https://openreview.net/forum?id=LkzuPorQ5L",
        "pdf_link": "https://openreview.net/pdf?id=LkzuPorQ5L",
        "keywords": "Multi-agent collaboration, sparsification, LLM agents",
        "abstract": "Recent advancements in large language model (LLM)-powered agents have shown that collective intelligence can significantly outperform individual capabilities, largely attributed to the meticulously designed inter-agent communication topologies. Though impressive in performance, existing multi-agent pipelines inherently introduce substantial token overhead, as well as increased economic costs, which pose challenges for their large-scale deployments. In response to this challenge, we propose an economical, simple, and robust multi-agent communication framework, termed $\\texttt{AgentPrune}$, which can seamlessly integrate into mainstream multi-agent systems and prunes redundant or even malicious communication messages. Technically, $\\texttt{AgentPrune}$ is the first to identify and formally define the $\\textit{Communication Redundancy}$ issue present in current LLM-based multi-agent pipelines, and efficiently performs one-shot pruning on the spatial-temporal message-passing graph, yielding a token-economic and high-performing communication topology.\nExtensive experiments across six benchmarks demonstrate that $\\texttt{AgentPrune}$ $\\textbf{(I)}$ achieves comparable results as state-of-the-art topologies at merely $\\$5.6$ cost compared to their $\\$43.7$, $\\textbf{(II)}$ integrates seamlessly into existing multi-agent frameworks with $28.1\\%\\sim72.8\\%\\downarrow$ token reduction, and $\\textbf{(III)}$ successfully defend against two types of agent-based adversarial attacks with $3.5\\%\\sim10.8\\%\\uparrow$ performance boost."
    },
    {
        "title": "S3E: Semantic Symbolic State Estimation With Vision-Language Foundation Models",
        "link_suffix": "/forum?id=gw4hYNFUIC",
        "link": "https://openreview.net/forum?id=gw4hYNFUIC",
        "pdf_link": "https://openreview.net/pdf?id=gw4hYNFUIC",
        "keywords": "Task Planning, Symbolic AI, Computer Vision, Vision-Language Models",
        "abstract": "In automated task planning, state estimation is the process of translating an agent's sensor input into a high-level task state. It is important because real-world environments are unpredictable, and actions often do not lead to expected outcomes. State estimation enables the agent to manage uncertainties, adjust its plans, and make more informed decisions. Traditionally, researchers and practitioners relied on hand-crafted and hard-coded state estimation functions to determine the abstract state defined in the task domain. Recent advancements in Vision Language Models (VLMs) enable autonomous retrieval of semantic information from visual input. We present Semantic Symbolic State Estimation (S3E), the first general-purpose symbolic state estimator based on VLMs that can be applied in various settings without specialized coding or additional exploration. S3E takes advantage of the foundation model's internal world model and semantic understanding to assess the likelihood of certain symbolic components of the environment's state. We analyze S3E as a multi-label classifier, reveal different kinds of uncertainties that arise when using it, and show how they can be mitigated using natural language and targeted environment design. We show that S3E can achieve over 90% state estimation precision in our simulated and real-world robot experiments."
    },
    {
        "title": "Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs)",
        "link_suffix": "/forum?id=oStNAMWELS",
        "link": "https://openreview.net/forum?id=oStNAMWELS",
        "pdf_link": "https://openreview.net/pdf?id=oStNAMWELS",
        "keywords": "gender bias, vision-language-models",
        "abstract": "Pre-trained large language models (LLMs) have been reliably integrated with visual input for multimodal tasks. The widespread adoption of instruction-tuned image-to-text vision-language assistants (VLAs) like LLaVA and InternVL necessitates evaluating gender biases. We study gender bias in 22 popular open-source VLAs with respect to personality traits, skills, and occupations. Our results show that VLAs replicate human biases likely present in the data, such as real-world occupational imbalances. Similarly, they tend to attribute more skills and positive personality traits to women than to men, and we see a consistent tendency to associate negative personality traits with men. To eliminate the gender bias in these models, we find that finetuning-based debiasing methods achieve the best tradeoff between debiasing and retaining performance on downstream task. We argue for pre-deploying gender bias assessment in VLAs and motivate further development of debiasing strategies to ensure equitable societal outcomes. Code and data will be released upon acceptance."
    },
    {
        "title": "A Modified Proximal-Perturbed Lagrangian for Non-Convex Non-Smooth Representatives of Fairness Constraints",
        "link_suffix": "/forum?id=BkvjVqk461",
        "link": "https://openreview.net/forum?id=BkvjVqk461",
        "pdf_link": "https://openreview.net/pdf?id=BkvjVqk461",
        "keywords": "fairness constraints, non-convexity, non-smoothness, primal-dual method",
        "abstract": "We study classification problems under fairness constraints and introduce an algorithmic framework designed to prevent discrimination against different groups. These problems are often reformulated as continuous constrained optimization problems and are typically solved using continuous relaxations (surrogates) of the fairness constraints. However, many current algorithms do not provide theoretical guarantees, which possibly is due to the resulting fairness constraints being both non-convex and non-smooth. We propose a novel primal-dual algorithm, based on a newly developed Lagrangian, that converges to a stationary solution of the reformulated problem. Our algorithm is not only efficient and robust, but it also enjoys strong performance guarantees on the fairness of its solutions. Furthermore, experimental results demonstrate that our algorithm is highly effective in terms of computational cost and fairness guarantees, outperforming related algorithms that use regularization (penalization) techniques and/or standard Lagrangian relaxation."
    },
    {
        "title": "Boosting Camera Motion Control for Video Diffusion Transformers",
        "link_suffix": "/forum?id=rDRCIvTppL",
        "link": "https://openreview.net/forum?id=rDRCIvTppL",
        "pdf_link": "https://openreview.net/pdf?id=rDRCIvTppL",
        "keywords": "video generation, camera control, diffusion models, diffusion transformers, DiT",
        "abstract": "Recent advancements in diffusion models have significantly enhanced the quality of video generation. However, fine-grained control over camera pose remains a challenge. While U-Net-based models have shown promising results for camera control, transformer-based diffusion models (DiT)\u2014the preferred architecture for large-scale video generation\u2014suffer from severe degradation in camera motion accuracy. In this paper, we investigate the underlying causes of this issue and propose solutions tailored to DiT architectures. Our study reveals that camera control performance depends heavily on the choice of conditioning methods rather than camera pose representations that is commonly believed. To address the persistent motion degradation in DiT, we introduce \\textbf{Camera Motion Guidance (CMG)}, based on classifier-free guidance, which boosts camera control by over 400%. Additionally, we present a sparse camera control pipeline, significantly simplifying the process of specifying camera poses for long videos. Our method universally applies to both U-Net and DiT models, offering improved camera control for video generation tasks."
    },
    {
        "title": "Multi-Scale Latent Points Consistency Models for 3D Shape Generation",
        "link_suffix": "/forum?id=92FEM1voOW",
        "link": "https://openreview.net/forum?id=92FEM1voOW",
        "pdf_link": "https://openreview.net/pdf?id=92FEM1voOW",
        "keywords": "Point Cloud Generation, diffusion model, consistency model",
        "abstract": "Consistency Models (CM) have significantly accelerated the sampling process in diffusion models, yielding impressive results in synthesizing high-resolution images. \nTo explore and extend these advancements to point-cloud-based 3D shape generation, we propose a novel Multi-Scale Latent Points Consistency Model (MLPCM). \nOur MLPCM follows a latent diffusion framework and introduces hierarchical levels of latent representations, ranging from point-level to super-point levels, each corresponding to a different spatial resolution. \nWe design a multi-scale latent integration module along with 3D spatial attention to effectively denoise the point-level latent representations conditioned on those from multiple super-point levels.\nAdditionally, we propose a latent consistency model, learned through consistency distillation, that compresses the prior into a one-step generator.\nThis significantly improves sampling efficiency while preserving the performance of the original teacher model. \nExtensive experiments on standard benchmarks ShapeNet and ShapeNet-Vol demonstrate that MLPCM achieves a 100x speedup in the generation process, while surpassing state-of-the-art diffusion models in terms of both shape quality and diversity."
    },
    {
        "title": "Zero-Shot Whole-Body Humanoid Control via Behavioral Foundation Models",
        "link_suffix": "/forum?id=9sOR0nYLtz",
        "link": "https://openreview.net/forum?id=9sOR0nYLtz",
        "pdf_link": "https://openreview.net/pdf?id=9sOR0nYLtz",
        "keywords": "reinforcement learning; foundation model; humanoid",
        "abstract": "Unsupervised reinforcement learning (RL) aims at pre-training models that can solve a wide range of downstream tasks in complex environments. Despite recent advancements, existing approaches suffer from several limitations: they may require running an RL process on each task to achieve a satisfactory performance, they may need access to datasets with good coverage or well-curated task-specific samples, or they may pre-train policies with unsupervised losses that are poorly correlated with the downstream tasks of interest. In this paper, we introduce FB-CPR, which regularizes unsupervised zero-shot RL based on the forward-backward (FB) method towards imitating trajectories from unlabeled behaviors. The resulting models learn \\emph{useful} policies imitating  the behaviors in the dataset, while retaining zero-shot generalization capabilities. We demonstrate the effectiveness of FB-CPR in a challenging humanoid control problem. Training FB-CPR online with observation-only motion capture datasets, we obtain the first humanoid behavioral foundation model that can be prompted to solve a variety of whole-body tasks, including motion tracking, goal reaching, and reward optimization. The resulting model is capable of expressing human-like behaviors and it achieves competitive performance with task-specific methods while outperforming state-of-the-art unsupervised RL and model-based baselines."
    },
    {
        "title": "MEXMA: Token-level objectives improve sentence representations",
        "link_suffix": "/forum?id=azQiiSWrtx",
        "link": "https://openreview.net/forum?id=azQiiSWrtx",
        "pdf_link": "https://openreview.net/pdf?id=azQiiSWrtx",
        "keywords": "Natural Language Processing, Cross lingual sentence encoders, Language alignment, Translations, Representation Learning, Translations",
        "abstract": "Cross-lingual sentence encoders (CLSE) create fixed-size sentence representations with aligned translations. Current pre-trained CLSE approaches use sentence-level objectives only. This can lead to loss of information, especially for tokens, which then degrades the sentence representation. We propose MEXMA, a novel approach that integrates both sentence-level and token-level objectives. The sentence representation in one language is used to predict masked tokens in another language, with both the sentence representation and $\\textit{all tokens directly updating the encoder}$. We show that adding token-level objectives greatly improves the sentence representation quality across several tasks. Our approach outperforms current pre-trained cross-lingual sentence encoders on bitext mining as well as several downstream tasks. We also analyse the information encoded in our tokens, and how the sentence representation is built from them."
    },
    {
        "title": "Outlier Synthesis via Hamiltonian Monte Carlo for Out-of-Distribution Detection",
        "link_suffix": "/forum?id=N6ba2xsmds",
        "link": "https://openreview.net/forum?id=N6ba2xsmds",
        "pdf_link": "https://openreview.net/pdf?id=N6ba2xsmds",
        "keywords": "Trustworthy Machine Learning, Out-of-Distribution Detection, Outlier Detection",
        "abstract": "Out-of-distribution (OOD) detection is crucial for developing trustworthy and reliable machine learning systems. Recent advances in training with auxiliary OOD data demonstrate efficacy in enhancing detection capabilities. Nonetheless, these methods heavily rely on acquiring a large pool of high-quality natural outliers. Some prior methods try to alleviate this problem by synthesizing virtual outliers but suffer from either poor quality or high cost due to the monotonous sampling strategy and the heavy-parameterized generative models. In this paper, we overcome all these problems by proposing the Hamiltonian Monte Carlo Outlier Synthesis (HamOS) framework, which views the synthesis process as sampling from Markov chains. Based solely on the in-distribution data, the Markov chains can extensively traverse the feature space and generate diverse and representative outliers, hence exposing the model to miscellaneous potential OOD scenarios. The Hamiltonian Monte Carlo with sampling acceptance rate almost close to 1 also makes our framework enjoy great efficiency. By empirically competing with SOTA baselines on both standard and large-scale benchmarks, we verify the efficacy and efficiency of our proposed HamOS."
    },
    {
        "title": "A Third-Person Appraisal Agent: Learning to Reason About Emotions in Conversational Contexts",
        "link_suffix": "/forum?id=i6b2TrTNMz",
        "link": "https://openreview.net/forum?id=i6b2TrTNMz",
        "pdf_link": "https://openreview.net/pdf?id=i6b2TrTNMz",
        "keywords": "emotion recognition in conversation, LLM agent, emotion reasoning, reinforcement learning",
        "abstract": "Emotion reasoning is crucial for achieving human-like emotional understanding in Emotion Recognition in Conversation (ERC). Current ERC datasets provide only emotion-labeled utterances, lacking the rich annotations necessary for emotion reasoning. Although Large Language Models (LLMs) show promise in generating rich emotional knowledge, they still struggle to apply this knowledge effectively for emotion reasoning. To address these challenges, we propose a learning framework based on cognitive appraisal theory, utilizing an agent powered by LLMs to learn emotion reasoning from a third-person perspective, which we refer to as the third-person appraisal agent. This learning framework comprises two phases: self-evaluation and meta-evaluation. In the self-evaluation phase, the agent generates appraisals essential for inferring emotions, incorporating counterfactual thinking to refine its appraisals. The meta-evaluation phase uses reflective actor-critic reinforcement learning to train the agent to generate accurate appraisals during testing. The training samples are appraisals generated during the self-evaluation phase, which eliminates the need for human annotations. By fine-tuning a specialized LLM in this framework, our approach significantly outperforms LLM baselines across ERC tasks, demonstrating improved reasoning and generalization across various dialogue datasets. Additionally, we provide interpretable results that clarify the model\u2019s reasoning process behind its predictions. To the best of our knowledge, this research is the first to apply cognition-based methods to enhance LLMs' emotional reasoning capabilities, marking a significant advancement toward achieving human-like emotional understanding in artificial intelligence."
    },
    {
        "title": "Enhancing Cognition and Explainability of Multimodal Foundation Models with Self-Synthesized Data",
        "link_suffix": "/forum?id=lHbLpwbEyt",
        "link": "https://openreview.net/forum?id=lHbLpwbEyt",
        "pdf_link": "https://openreview.net/pdf?id=lHbLpwbEyt",
        "keywords": "Multimodal Foundation Models, Synthesized Data, Visual Classification",
        "abstract": "Large multimodal models (LMMs) have shown impressive capabilities in a wide range of visual tasks. However, they often struggle with identifying domain-specific objectives and fail to explain their predictions reasonably. To address the above challenge, we propose a novel iterative visual fine-tuning framework to improve the effectiveness and explainability of LMMs using self-synthesized data. Specifically, visual fine-tuning requires images, queries, and target answers. Our approach begins by synthesizing interpretable answers that include human-verifiable visual features. These features are based on expert-defined concepts, carefully selected based on their alignment with the image content. After each round of fine-tuning, we apply a reward model-free filtering mechanism to select the highest-quality interpretable answers for the next round of tuning. This iterative process of data synthesis and fine-tuning progressively improves the model's ability to generate accurate and reasonable explanations. Experimental results demonstrate the effectiveness of our method in improving both the accuracy and explainability of specialized visual classification tasks."
    },
    {
        "title": "RNAformer: Axial-Attention For Homology-Aware RNA Secondary Structure Prediction",
        "link_suffix": "/forum?id=JapY2HtNI5",
        "link": "https://openreview.net/forum?id=JapY2HtNI5",
        "pdf_link": "https://openreview.net/pdf?id=JapY2HtNI5",
        "keywords": "Structural Biology, Deep Learning, RNA Secondary Structure Prediction, Axial Attention",
        "abstract": "Predicting RNA secondary structure is essential for understanding RNA function and developing RNA-based therapeutics. Despite recent advances in deep learning for structural biology, its application to RNA secondary structure prediction remains contentious. A primary concern is the control of homology between training and test data. Moreover, deep learning approaches often incorporate complex multi-model systems, ensemble strategies, or require external data. Here, we present the RNAformer, a scalable axial-attention-based deep learning model designed to predict secondary structure directly from a single RNA sequence without additional requirements. We demonstrate the benefits of this lean architecture by learning an accurate biophysical RNA folding model using synthetic data. Trained on experimental data, our model overcomes previously reported caveats in deep learning approaches with a novel homology-aware data pipeline. The RNAformer achieves state-of-the-art performance on RNA secondary structure prediction, outperforming both traditional non-learning-based methods and existing deep learning approaches, while carefully considering sequence and structure similarities."
    },
    {
        "title": "UniComposer: Band-Level Music Composition with Symbolic and Audio Unification",
        "link_suffix": "/forum?id=FOcleL0ltt",
        "link": "https://openreview.net/forum?id=FOcleL0ltt",
        "pdf_link": "https://openreview.net/pdf?id=FOcleL0ltt",
        "keywords": "Symbolic and Audio Music, Unified Latent Space, Band-Level Music Generation, Feature Extraction, Generative Models",
        "abstract": "Multi-track deep music generation has largely focused on pre-specified structures and instruments. However, it remains a challenge to generate \"band-level\" full-length music that is capable of allocating instruments based on musical features, their expressive potential, and their performance characteristics differences. Moreover, the representations of symbolic music and audio music have been treated as distinct sub-areas, without a unified architecture to join their own advantages. In this work, we introduce $\\textbf{UniComposer}$, a novel music generation pipeline that composes at the band level, utilizing a hierarchical multi-track music representation complemented by four cascaded diffusion models which progressively generate rhythm features, and unified features extracted from both symbolic and audio music by autoencoders. Experiments and analysis demonstrate that UniComposer achieves a unified latent space for symbolic and audio music, and is capable of generating band-level compositions with well structured multi-track arrangements, surpassing previous methods in performances."
    },
    {
        "title": "LEGACY: A Lightweight Adaptive Gradient Compression Strategy for Distributed Deep Learning",
        "link_suffix": "/forum?id=Xxpt66OgHI",
        "link": "https://openreview.net/forum?id=Xxpt66OgHI",
        "pdf_link": "https://openreview.net/pdf?id=Xxpt66OgHI",
        "keywords": "Adaptive Gradient Compression, Gradient Compression, Distributed Deep Learning, Federated Learning, Efficient Communication, Gradient Sparsification, Communication Overhead",
        "abstract": "Distributed learning has demonstrated remarkable success in training deep neural networks (DNNs) on large datasets, but the communication bottleneck reduces its scalability. Various compression techniques are proposed to alleviate this limitation; often they rely on computationally intensive methods to determine optimal compression parameters during training and are popularly referred to as adaptive compressors. Instead of the hard-to-tune hyperparameters for adaptive compressors, in this paper, we investigate the impact of two fundamental factors in DNN training, the layer size of the DNNs and their training phases, to design a simple yet efficient adaptive scheduler for any compressors to guide the compression parameters selection. We present aLightweightEfficientGrAdientCompression strategYor LEGACY that, in theory, can work with any compression technique to produce its simple adaptive counterpart. We benchmark LEGACY on distributed and federated training, involving 6 different DNN architectures for various tasks performed on large and challenging datasets, including ImageNet and WikiText-103. On ImageNet training, by sending similar average data volume, LEGACY's adaptive compression strategies improve the Top-1 accuracy of ResNet-50 by 7%-11%, compared to the uniform Top-0.1% compression used throughout the training. Similarly, on WikiText-103, by using our layer-based adaptive compression strategy and sending similar average data volume, the perplexity of the Transformer-XL improves $\\sim$26% more than the uniform Top-0.1% compression used throughout the training. We publish anonymized code at:https://github.com/LEGACY-compression/LEGACY."
    },
    {
        "title": "SMI-Editor: Edit-based SMILES Language Model with Fragment-level Supervision",
        "link_suffix": "/forum?id=M29nUGozPa",
        "link": "https://openreview.net/forum?id=M29nUGozPa",
        "pdf_link": "https://openreview.net/pdf?id=M29nUGozPa",
        "keywords": "SMILES Language Model, SMILES Pre-training Model, Molecular Pre-training Model",
        "abstract": "SMILES, as a crucial textual representation of molecular information, is increasingly drawing interest for its pre-trained language models. However, most existing pre-trained SMILES language models (LMs) only provide supervision at the single-token level during pre-training and fail to fully leverage substructural information of molecules. This limitation results in the pre-training task being overly simplistic and further preventing the models from capturing richer molecular semantic information. Additionally, during pre-training, these SMILES LMs only process corrupted SMILES inputs, never encountering any valid SMILES as input, leading to a train-inference mismatch. To address these challenges, we propose SMI-Editor, a novel edit-based pre-trained SMILES language model. SMI-Editor randomly disrupts substructures within a molecule and feeds the resulting SMILES back into the model, which then attempts to restore the original SMILES through an editing process.  This training method not only introduces a fragment-level training signal but also allows the use of valid SMILES as inputs, enabling the model to learn how to edit these incomplete structures back to complete molecules. This significantly enhances the model's scalability and capability to learn fragment-level molecular information. Experimental results show that the SMI-Editor performs well across multiple downstream molecular tasks, achieving state-of-the-art results, and even surpasses several 3D molecular representation models in performance."
    },
    {
        "title": "Diffusion Pretraining for Gait Recognition in the Wild",
        "link_suffix": "/forum?id=r4GxmIBDbO",
        "link": "https://openreview.net/forum?id=r4GxmIBDbO",
        "pdf_link": "https://openreview.net/pdf?id=r4GxmIBDbO",
        "keywords": "Diffusion Models, Gait Recognition, Representation Learning",
        "abstract": "Recently, diffusion models have garnered much attention for their remarkable generative capabilities. Yet, their application for representation learning remains largely unexplored. In this paper, we explore the possibility of using the diffusion process to pretrain the backbone of a deep learning model for a specific application\u2014gait recognition in the wild. To do so, we condition a latent diffusion model on the output of a gait recognition model backbone. Our pretraining experiments on the Gait3D and GREW datasets reveal an interesting phenomenon: diffusion pretraining causes the gait recognition backbone to separate gait sequences belonging to different subjects further apart than those belonging to the same subjects, which translates to a steady improvement in gait recognition performance. Subsequently, our transfer learning experiments on Gait3D and GREW show that the pretrained backbone can serve as an effective initialization for the downstream gait recognition task, allowing the gait recognition model to achieve better performance within much fewer supervised training iterations. We validated the applicability of our approach across multiple existing gait recognition methods and conducted extensive ablation studies to investigate the impact of different pretraining hyperparameters on the final gait recognition performance."
    },
    {
        "title": "Improving Denoising Diffusion with Efficient Conditional Entropy Reduction",
        "link_suffix": "/forum?id=OT2NFdNrny",
        "link": "https://openreview.net/forum?id=OT2NFdNrny",
        "pdf_link": "https://openreview.net/pdf?id=OT2NFdNrny",
        "keywords": "Denoising Diffusion, Conditional Entropy",
        "abstract": "Diffusion models (DMs) have achieved significant success in generative modeling, but their iterative denoising process is  computationally expensive. Training-free samplers,  such as DPM-Solver, accelerate this process through gradient estimation-based numerical iterations.  However, the mechanisms behind this acceleration remain insufficiently understood. In this paper, we demonstrate  gradient estimation-based iterations enhance the denoising process by  effectively \\emph{\\textbf{r}educing the conditional \\textbf{e}ntropy} of reverse transition distribution.  Building on this analysis,  we introduce  streamlined denoising iterations for DMs  that optimize   conditional entropy in score-integral estimation to improve the denoising iterations.  Experiments on benchmark pre-trained models in both pixel and latent spaces validate our theoretical insights,  demonstrating that numerical iterations based on conditional entropy reduction improve the reverse denoising diffusion process of DMs."
    }
]
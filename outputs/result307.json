[
    {
        "title": "Noise-Augmented Deep Neural Networks for Image Classification: Insights from Information Theory",
        "link_suffix": "/forum?id=o0DQDGaVIY",
        "link": "https://openreview.net/forum?id=o0DQDGaVIY",
        "pdf_link": "https://openreview.net/pdf?id=o0DQDGaVIY",
        "keywords": "Image Classification, ViT, Noise",
        "abstract": "In this study, we explore the impact of proactively injecting noise into deep learning models, focusing particularly on classification problems, such as image classification and domain adaptation. While noise is typically seen as harmful, our findings reveal that, under certain conditions, noise can beneficially influence the entropy of the system, enhancing the learning outcomes. We employ information entropy to characterize the complexity of the learning tasks and categorize noise into two types, positive noise (PN) and harmful noise (HN), based on whether it helps reduce task complexity. We theoretically prove that positive noise reduces task complexity and demonstrate the presence of positive noise through extensive experiments on Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). We further propose NoisyNN, an innovative approach to leverage positive noise. NoisyNN achieves state-of-the-art performance on various image classification and domain adaptation tasks. Extensive experiments conducted on {15 datasets}, including popular image datasets and out-of-distribution datasets, demonstrate the efficacy of our method. Our study provides the community with a new paradigm for improving model performance."
    },
    {
        "title": "Memory Mosaics",
        "link_suffix": "/forum?id=IiagjrJNwF",
        "link": "https://openreview.net/forum?id=IiagjrJNwF",
        "pdf_link": "https://openreview.net/pdf?id=IiagjrJNwF",
        "keywords": "predictive disentanglement, Associative memory, language model",
        "abstract": "Memory Mosaics are networks of associative memories working in concert to achieve a prediction task of interest. Like transformers, memory mosaics possess compositional capabilities and in-context learning capabilities. Unlike transformers, memory mosaics achieve these capabilities in comparatively transparent way (\u201cpredictive disentanglement\u201d). We illustrate these capabilities on a toy example and also show that memory mosaics perform as well or better than transformers on medium-scale language modeling tasks."
    },
    {
        "title": "Hierarchical World Models as Visual Whole-Body Humanoid Controllers",
        "link_suffix": "/forum?id=7wuJMvK639",
        "link": "https://openreview.net/forum?id=7wuJMvK639",
        "pdf_link": "https://openreview.net/pdf?id=7wuJMvK639",
        "keywords": "reinforcement learning, world model, humanoid",
        "abstract": "Whole-body control for humanoids is challenging due to the high-dimensional nature of the problem, coupled with the inherent instability of a bipedal morphology. Learning from visual observations further exacerbates this difficulty. In this work, we explore highly data-driven approaches to visual whole-body humanoid control based on reinforcement learning, without any simplifying assumptions, reward design, or skill primitives. Specifically, we propose a hierarchical world model in which a high-level agent generates commands based on visual observations for a low-level agent to execute, both of which are trained with rewards. Our approach produces highly performant control policies in 8 tasks with a simulated 56-DoF humanoid, while synthesizing motions that are broadly preferred by humans. Code and videos:https://rlpuppeteer.github.io"
    },
    {
        "title": "DP-GPL: Differentially Private Graph Prompt Learning",
        "link_suffix": "/forum?id=dSQtMx6dPE",
        "link": "https://openreview.net/forum?id=dSQtMx6dPE",
        "pdf_link": "https://openreview.net/pdf?id=dSQtMx6dPE",
        "keywords": "Graph Prompt Learning; Membership Inference Attack; Differential Privacy",
        "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance in various applications. Recently, graph prompt learning has emerged as a powerful GNN training paradigm, inspired by advances in language and vision models. Here, a GNN is pre-trained on public data and then adapted to sensitive tasks using lightweight graph prompts. However, using prompts from sensitive data poses privacy risks.\nIn this work, we are the first to investigate these risks in graph prompts by instantiating a membership inference attack that reveals significant privacy leakage. We also find that the standard privacy method, DP-SGD, fails to provide practical privacy-utility trade-offs in graph prompt learning, likely due to the small number of sensitive data points used to learn the prompts.\nAs a solution, we propose two algorithms, DP-GPL and DP-GPL+W, for differentially private graph prompt learning based on the PATE framework, that generate a graph prompt with differential privacy guarantees.\nOur evaluation across various graph prompt learning methods, GNN architectures, and pre-training strategies demonstrates that our algorithms achieve high utility at strong privacy, effectively mitigating privacy concerns while preserving the powerful capabilities of prompted GNNs."
    },
    {
        "title": "VRSD: Rethinking Similarity and Diversity for Retrieval in Large Language Models",
        "link_suffix": "/forum?id=jDvgxHhtlQ",
        "link": "https://openreview.net/forum?id=jDvgxHhtlQ",
        "pdf_link": "https://openreview.net/pdf?id=jDvgxHhtlQ",
        "keywords": "Algorithms, Large Language Model, NP-complete, Vector Retrieval",
        "abstract": "Vector retrieval algorithms are essential for semantic queries within the rapidly evolving landscape of Large Language Models (LLMs). The ability to retrieve vectors that satisfy both similarity and diversity criteria substantially enhances the performance of LLMs. Although Maximal Marginal Relevance (MMR) is widely employed in retrieval scenarios requiring relevance and diversity, variations in the parameter ( \\lambda ) lead to fluctuations that complicate the optimization trajectory in vector spaces. This obscures the direction of improvement and highlights the lack of a robust theoretical analysis regarding similarity and diversity constraints in retrieval processes. To address these challenges, this paper introduces a novel approach that characterizes both constraints through the relationship between the sum vector and the query vector. The proximity of these vectors ensures the similarity constraint, while requiring individual vectors within the sum vector to diverge in their alignment with the query vector satisfies the diversity constraint. We first formulate a new combinatorial optimization problem, selecting ( k ) vectors from a candidate set such that their sum vector maximally aligns with the query vector, and demonstrate that this problem is \\textbf{NP-complete}. This result underscores the inherent difficulty of simultaneously achieving similarity and diversity in vector retrieval, thereby providing a theoretical foundation for future research. Subsequently, we present the heuristic algorithm \\underline{\\textbf{V}}ectors \\underline{\\textbf{R}}etrieval with \\underline{\\textbf{S}}imilarity and \\underline{\\textbf{D}}iversity, \\textbf{VRSD}, which features a clear optimization objective and eliminates the need for preset parameters. VRSD also achieves a modest reduction in time complexity compared to MMR. Empirical validation confirms that VRSD significantly outperforms MMR across various datasets, while also demonstrating that the sum vector effectively captures both diversity and similarity simultaneously. The data and code are available athttps://anonymous.4open.science/r/VRSD-CF9D."
    },
    {
        "title": "Presto! Distilling Steps and Layers for Accelerating Music Generation",
        "link_suffix": "/forum?id=Gj5JTAwdoy",
        "link": "https://openreview.net/forum?id=Gj5JTAwdoy",
        "pdf_link": "https://openreview.net/pdf?id=Gj5JTAwdoy",
        "keywords": "music generation, diffusion distillation, diffusion, diffusion acceleration, text-to-music generation, layer dropping",
        "abstract": "Despite advances in diffusion-based text-to-music (TTM) methods, efficient, high-quality generation remains a challenge. We introduce Presto!, an approach to inference acceleration for score-based diffusion transformers via reducing both sampling steps and cost per step. To reduce steps, we develop a new score-based distribution matching distillation (DMD) method for the EDM-family of diffusion models, the first GAN-based distillation method for TTM. To reduce the cost per step, we develop a simple, but powerful improvement to a recent layer distillation method that improves learning via better preserving hidden state variance. Finally, we combine our step and layer distillation methods together for a dual-faceted approach. We evaluate our step and layer distillation methods independently and show each yield best-in-class performance. Our combined distillation method can generate high-quality outputs with improved diversity, accelerating our base model by 10-18x (230/435ms latency for 32 second mono/stereo 44.1kHz, 15x faster than the comparable SOTA model) \u2014 the fastest TTM to our knowledge."
    },
    {
        "title": "Bayesian Learning with Deep Q-Exponential Process",
        "link_suffix": "/forum?id=oGsu3hksWT",
        "link": "https://openreview.net/forum?id=oGsu3hksWT",
        "pdf_link": "https://openreview.net/pdf?id=oGsu3hksWT",
        "keywords": "Deep Models, Inhomogeneous Subjects, Regularization, Latent Representation, Model Expressiveness",
        "abstract": "Motivated by deep neural networks, the deep Gaussian process (DGP) generalizes the standard GP by stacking multiple layers of GPs. Despite the enhanced expressiveness, GP, as an $L_2$ regularization prior, tends to be over-smooth and sub-optimal for inhomogeneous subjects, such as images with edges. Recently, Q-exponential process (Q-EP) has been proposed as an $L_q$ relaxation to GP and demonstrated with more desirable regularization properties through a parameter $q>0$ with $q=2$ corresponding to GP. Sharing the similar tractability of posterior and predictive distributions with GP, Q-EP can also be stacked to improve its modeling flexibility. In this paper, we generalize Q-EP to deep Q-EP to enjoy both proper regularization and improved expressiveness. The generalization is realized by introducing shallow Q-EP as a latent variable model and then building a hierarchy of the shallow Q-EP layers. Sparse approximation by inducing points and scalable variational strategy are applied to facilitate the inference. We demonstrate the numerical advantages of the proposed deep Q-EP model by comparing with multiple state-of-the-art deep probabilistic models."
    },
    {
        "title": "How to Probe: Simple Yet Effective Techniques for Improving Post-hoc Explanations",
        "link_suffix": "/forum?id=57NfyYxh5f",
        "link": "https://openreview.net/forum?id=57NfyYxh5f",
        "pdf_link": "https://openreview.net/pdf?id=57NfyYxh5f",
        "keywords": "Interpretability, Explainable AI, Representation Learning",
        "abstract": "Post-hoc importance attribution methods are a popular tool for \u201cexplaining\u201d Deep Neural Networks (DNNs) and are inherently based on the assumption that the explanations can be applied independently of how the models were trained. Contrarily, in this work we bring forward empirical evidence that challenges this very notion. Surprisingly, we discover a strong dependency on and demonstrate that the training details of a pre-trained model\u2019s classification layer (<10% of model parameters) play a crucial role, much more than the pre-training scheme itself. This is of high practical relevance: (1) as techniques for pre-training models are becoming increasingly diverse, understanding the interplay between these techniques and attribution methods is critical; (2) it sheds light on an important yet overlooked assumption of post-hoc attribution methods which can drastically impact model explanations and how they are interpreted eventually. With this finding we also present simple yet effective adjustments to the classification layers, that can significantly enhance the quality of model explanations. We validate our findings across several visual pre-training frameworks (fully-supervised, self-supervised, contrastive vision-language training) and analyse how they impact explanations for a wide range of attribution methods on a diverse set of evaluation metrics."
    },
    {
        "title": "Bilevel ZOFO: Bridging Parameter-Efficient and Zeroth-Order Techniques for Efficient LLM Fine-Tuning and Meta-Training",
        "link_suffix": "/forum?id=wO8WbhsjNG",
        "link": "https://openreview.net/forum?id=wO8WbhsjNG",
        "pdf_link": "https://openreview.net/pdf?id=wO8WbhsjNG",
        "keywords": "Zeroth-order Fine-tuning, Parameter Efficient Fine-tuning, Large Language Models, Bilevel Optimization",
        "abstract": "Fine-tuning pre-trained Large Language Models (LLMs) for downstream tasks using First-Order (FO) optimizers presents significant computational challenges. Parameter-Efficient Fine-Tuning (PEFT) methods have been proposed to address these challenges by freezing most model parameters and training only a small subset. While PEFT is efficient, it may not outperform full fine-tuning when high task-specific performance is required.\nZeroth-Order (ZO) methods offer an alternative for fine-tuning the entire pre-trained model by approximating gradients using only the forward pass, thus eliminating the computational burden of back-propagation in first-order methods. However, when implementing ZO methods, it is crucial to ensure prompt-based text alignment, and relying on simple, fixed hard prompts may not be optimal. In this paper, we propose a bilevel optimization framework that complements ZO methods with PEFT to mitigate sensitivity to hard prompts while efficiently and effectively fine-tuning LLMs. Our Bilevel ZOFO (Zeroth-Order-First-Order) method employs a double-loop optimization strategy, where only the gradient of the PEFT model and the forward pass of the base model are required. We provide convergence guarantees for Bilevel ZOFO. Empirically, we demonstrate that Bilevel ZOFO outperforms both PEFT and ZO methods in single-task settings. Additionally, we show its strong potential for multitask learning. Compared to current first-order meta-training algorithms for multitask learning, our method has significantly lower computational demands while maintaining or improving performance."
    },
    {
        "title": "Random-Set Neural Networks",
        "link_suffix": "/forum?id=pdjkikvCch",
        "link": "https://openreview.net/forum?id=pdjkikvCch",
        "pdf_link": "https://openreview.net/pdf?id=pdjkikvCch",
        "keywords": "Uncertainty quantification, Classification, Deep Learning",
        "abstract": "Machine learning is increasingly deployed in safety-critical domains where erroneous predictions may lead to potentially catastrophic consequences, highlighting the need for learning systems to be aware of how confident they are in their own predictions: in other words, 'to know when they do not know\u2019. In this paper, we propose a novel Random-Set Neural Network (RS-NN) approach to classification which predictsbelief functions(rather than classical probability vectors) over the class list using the mathematics ofrandom sets, i.e., distributions over the collection ofsetsof classes. RS-NN encodes the 'epistemic' uncertainty induced by training sets that are insufficiently representative or limited in size via the size of the convex set of probability vectors associated with a predicted belief function. Our approach outperforms state-of-the-art Bayesian and Ensemble methods in terms of accuracy, uncertainty estimation and out-of-distribution (OoD) detection on multiple benchmarks (CIFAR-10 vs SVHN/Intel-Image, MNIST vs FMNIST/KMNIST, ImageNet vs ImageNet-O). RS-NN also scales up effectively to large-scale architectures (e.g. WideResNet-28-10, VGG16, Inception V3, EfficientNetB2 and ViT-Base-16),\nexhibits remarkable robustness to adversarial attacks and can provide statistical guarantees in a conformal learning setting."
    },
    {
        "title": "Mitigating Spurious Correlations in Zero-Shot Multimodal Models",
        "link_suffix": "/forum?id=UsRKFYR4lM",
        "link": "https://openreview.net/forum?id=UsRKFYR4lM",
        "pdf_link": "https://openreview.net/pdf?id=UsRKFYR4lM",
        "keywords": "Spurious correlation, Zero shot, Multimodal models",
        "abstract": "Multimodal models or Vision Language Models (VLMs) have reshaped the paradigm in machine learning, offering zero-shot capabilities that require no additional training when adapted to new classification tasks. However, despite their advancements, spurious correlations still exist in VLMs. Existing approaches to tackle this issue often require target label annotations, contradicting the principle of zero-shot classification, or they primarily focus on a single modality, risking misalignment between text and image modalities. Others rely on extensive domain knowledge or large language models (LLMs) to characterize spurious features, making the performance sensitive to the generated prompts and undermining zero-shot capability. In response, we propose a new solution that tackles spurious correlations in VLMs within the zero-shot setting. Our approach utilizes a translation operation that preserves the latent space distribution to address issues of spurious correlations. In particular, our method is grounded in and inspired by a theoretical analysis, which identifies that the optimal translation directions are along the spurious vector. As VLMs unify two modalities, we compute spurious vectors from the text prompts and guide the translation for image embeddings, aligning the requirements for the fusion of different modalities in VLMs. We conducted experiments on benchmark datasets, which have shown significant improvements in worst-group accuracy. Additionally, our visualizations of VLMs further demonstrate the effectiveness of this intervention."
    },
    {
        "title": "Efficient Cross-Episode Meta-RL",
        "link_suffix": "/forum?id=UENQuayzr1",
        "link": "https://openreview.net/forum?id=UENQuayzr1",
        "pdf_link": "https://openreview.net/pdf?id=UENQuayzr1",
        "keywords": "meta-reinforcement learning, transformers, in-context learning",
        "abstract": "We introduce Efficient Cross-Episodic Transformers (ECET), a new algorithm for online Meta-Reinforcement Learning that addresses the challenge of enabling reinforcement learning agents to perform effectively in previously unseen tasks. We demonstrate how past episodes serve as a rich source of in-context information, which our model effectively distills and applies to new contexts. Our learned algorithm is capable of outperforming the previous state-of-the-art and provides more efficient meta-training while significantly improving generalization capabilities. Experimental results, obtained across various simulated tasks of the Meta-World and ManiSkill benchmarks, indicate a significant improvement in learning efficiency and adaptability compared to the state-of-the-art. Our approach enhances the agent's ability to generalize from limited data and paves the way for more robust and versatile AI systems."
    },
    {
        "title": "Exposure Bracketing is All You Need for Unifying Image Restoration and Enhancement Tasks",
        "link_suffix": "/forum?id=rDIf6NA5mj",
        "link": "https://openreview.net/forum?id=rDIf6NA5mj",
        "pdf_link": "https://openreview.net/pdf?id=rDIf6NA5mj",
        "keywords": "Exposure Bracketing, Image Restoration and Enhancement",
        "abstract": "It is highly desired but challenging to acquire high-quality photos with clear content in low-light environments. Although multi-image processing methods (using burst, dual-exposure, or multi-exposure images) have made significant progress in addressing this issue, they typically focus on specific restoration or enhancement problems, and do not fully explore the potential of utilizing multiple images. Motivated by the fact that multi-exposure images are complementary in denoising, deblurring, high dynamic range imaging, and super-resolution, we propose to utilize exposure bracketing photography to unify image restoration and enhancement tasks in this work. Due to the difficulty in collecting real-world pairs, we suggest a solution that first pre-trains the model with synthetic paired data and then adapts it to real-world unlabeled images. In particular, a temporally modulated recurrent network (TMRNet) and self-supervised adaptation method are proposed. Moreover, we construct a data simulation pipeline to synthesize pairs and collect real-world images from 200 nighttime scenarios. Experiments on both datasets show that our method performs favorably against the state-of-the-art multi-image processing ones. The datasets, codes, and pre-trained models for both synthetic and real-world experiments will be publicly available."
    },
    {
        "title": "Dynamics-inspired Structure Hallucination for Protein-protein Interaction Modeling",
        "link_suffix": "/forum?id=jPrKs5rOWw",
        "link": "https://openreview.net/forum?id=jPrKs5rOWw",
        "pdf_link": "https://openreview.net/pdf?id=jPrKs5rOWw",
        "keywords": "Protein-protein Interactions, Geometric Deep Learning, Mutation Effect Prediction",
        "abstract": "Protein-protein interaction (PPI) represents a central challenge within the biology field, and accurately predicting the consequences of mutations in this context is crucial for drug design and protein engineering. Deep learning (DL) has shown promise in forecasting the effects of such mutations but is hindered by two primary constraints. First, the structures of mutant proteins are often elusive to acquire. Secondly, PPI takes place dynamically, which is rarely integrated into the DL architecture design. To address these obstacles, we present a novel framework named Refine-PPI with two key enhancements. First, we introduce a structure refinement module trained by a mask mutation modeling (MMM) task on available wild-type structures, which is then transferred to hallucinate the inaccessible mutant structures. Second, we employ a new kind of geometric network, called the probability density cloud network (PDC-Net), to capture 3D dynamic variations and encode the atomic uncertainty associated with PPI. Comprehensive experiments on SKEMPI.v2 substantiate the superiority of Refine-PPI over all existing tools for predicting free energy change. These findings underscore the effectiveness of our hallucination strategy and the PDC module in addressing the absence of mutant protein structure and modeling geometric uncertainty."
    },
    {
        "title": "Enhancing Medical NLP Systems: Integrating Upstash Vector and BGE-M3 for Accurate and Ethical Healthcare Data Management with Reduced Bias",
        "link_suffix": "/forum?id=n4SLaq5GhM",
        "link": "https://openreview.net/forum?id=n4SLaq5GhM",
        "pdf_link": "https://openreview.net/pdf?id=n4SLaq5GhM",
        "keywords": "Medical NLP, Upstash Vector, BGE-M3 model, Real-time data retrieval, Semantic understanding, Bias mitigation, Healthcare AI ethics",
        "abstract": "This paper proposes a novel NLP model in healthcare by including Utash Vector for in-time and contextual information retrieval and BGE-M3 for advanced understanding. The model overcomes the challenges posed by the existing systems, such as incomplete data retrieval, a semantically inconsistent database, and algorithm bias. Incorporating bias mitigation measures and fairness audits, it guarantees no unfair treatment of patients belonging to different groups. Aligned with the AMA Code of Medical Ethics, provides proper management of Electronic Health Records in better ways in terms of transparency, confidentiality, and accuracy. Although these problems are relieved, the accuracy of information is still a major issue, the abuse of artificial intelligence remains a risk, and the use of the AMA Code to guide the integration of artificial intelligence has its limitations. Each of these must operate with defensible use of AI and auditing as well as explanation of AI usage in clinical decision-making."
    },
    {
        "title": "MagicPose4D: Crafting Articulated Models with Appearance and Motion Control",
        "link_suffix": "/forum?id=wF9Cz2PknU",
        "link": "https://openreview.net/forum?id=wF9Cz2PknU",
        "pdf_link": "https://openreview.net/pdf?id=wF9Cz2PknU",
        "keywords": "4D Generation; 3D Reconstruction; Motion Transfer; Animation; Rigging",
        "abstract": "With the success of 2D and 3D visual generative models, there is growing interest in generating 4D content. Existing methods primarily rely on text prompts to produce 4D content, but they often fall short of accurately defining complex or rare motions. To address this limitation, we propose MagicPose4D, a novel framework for refined control over both appearance and motion in 4D generation. Unlike traditional methods, MagicPose4D accepts monocular videos as motion prompts, enabling precise and customizable motion generation. MagicPose4D comprises two key modules:i) Dual-Phase 4D Reconstruction Module} which operates in two phases. The first phase focuses on capturing the model's shape using accurate 2D supervision and less accurate but geometrically informative 3D pseudo-supervision without imposing skeleton constraints. The second phase refines the model using more accurate pseudo-3D supervision, obtained in the first phase and introduces kinematic chain-based skeleton constraints to ensure physical plausibility. Additionally, we propose a Global-local Chamfer loss that aligns the overall distribution of predicted mesh vertices with the supervision while maintaining part-level alignment without extra annotations.ii) Cross-category Motion Transfer Module} leverages the predictions from the 4D reconstruction module and uses a kinematic-chain-based skeleton to achieve cross-category motion transfer. It ensures smooth transitions between frames through dynamic rigidity, facilitating robust generalization without additional training.Through extensive experiments, we demonstrate that MagicPose4D significantly improves the accuracy and consistency of 4D content generation, outperforming existing methods in various benchmarks."
    },
    {
        "title": "Counterfactual Techniques for Enhancing Customer Retention",
        "link_suffix": "/forum?id=bSSFERgkFn",
        "link": "https://openreview.net/forum?id=bSSFERgkFn",
        "pdf_link": "https://openreview.net/pdf?id=bSSFERgkFn",
        "keywords": "Counterfactual Explanations, BERT, e-commerce",
        "abstract": "In this paper, we introduce a novel counterfactual reasoning method using eBERT embeddings to convert customers from an e-commerce company who frequently add items to their cart but don\u2019t proceed to checkout. We demonstrate that our method i) outperforms existing techniques such as DiCE, GANs, and CFRL in key metrics such as coverage, while also maintaining a low latency; ii) balances high coverage and low latency by adjusting the number of nearest unlike neighbors, highlighting a trade-off between these competing goals; and iii) allows customization of  mutable features, improving the practical applicability of our counterfactual explanations."
    },
    {
        "title": "Adversarial Guided Diffusion Models for Adversarial Purification",
        "link_suffix": "/forum?id=PwLsQ1AFbP",
        "link": "https://openreview.net/forum?id=PwLsQ1AFbP",
        "pdf_link": "https://openreview.net/pdf?id=PwLsQ1AFbP",
        "keywords": "adversarial attacks, adversarial training, adversarial purification",
        "abstract": "Diffusion model (DM) based adversarial purification (AP) has proven to be a powerful defense method that can remove adversarial perturbations and generate a purified example without threats. In principle, the pre-trained DMs can only ensure that purified examples conform to the same distribution of the training data, but it may inadvertently compromise the semantic information of input examples, leading to misclassification of purified examples. Recent advancements introduce guided diffusion techniques to preserve semantic information while removing the perturbations. However, these guidances often rely on distance measures between purified examples and diffused examples, which can also preserve perturbations in purified examples. To further unleash the robustness power of DM-based AP, we propose an adversarial guided diffusion model (AGDM) by introducing a novel adversarial guidance that contains sufficient semantic information but does not explicitly involve adversarial perturbations. The guidance is modeled by an auxiliary neural network obtained with adversarial training, considering the distance in the latent representations rather than at the pixel-level values. Extensive experiments are conducted on CIFAR-10, CIFAR-100 and ImageNet to demonstrate that our method is effective for simultaneously maintaining semantic information and removing the adversarial perturbations. In addition, comprehensive comparisons show that our method significantly enhances the robustness of existing DM-based AP, with an average robust accuracy improved by up to 7.30% on CIFAR-10. The code will be available upon acceptance."
    },
    {
        "title": "Towards Realistic Data Generation for Real-World Super-Resolution",
        "link_suffix": "/forum?id=JkCJBoNUcU",
        "link": "https://openreview.net/forum?id=JkCJBoNUcU",
        "pdf_link": "https://openreview.net/pdf?id=JkCJBoNUcU",
        "keywords": "Real-world Image Super-Resolution; Data Generation",
        "abstract": "Existing image super-resolution (SR) techniques often fail to generalize effectively in complex real-world settings due to the significant divergence between training data and practical scenarios. To address this challenge, previous efforts have either manually simulated intricate physical-based degradations or utilized learning-based techniques, yet these approaches remain inadequate for producing large-scale, realistic, and diverse data simultaneously. In this paper, we introduce a novel Realistic Decoupled Data Generator (RealDGen), an unsupervised learning data generation framework designed for real-world super-resolution. We meticulously develop content and degradation extraction strategies, which are integrated into a novel content-degradation decoupled diffusion model to create realistic low-resolution images from unpaired real LR and HR images. Extensive experiments demonstrate that RealDGen excels in generating large-scale, high-quality paired data that mirrors real-world degradations, significantly advancing the performance of popular SR models on various real-world benchmarks."
    },
    {
        "title": "Policy Gradient Optimization for Markov Decision Processes with Epistemic Uncertainty and General Loss Functions",
        "link_suffix": "/forum?id=M1y9JAL7CP",
        "link": "https://openreview.net/forum?id=M1y9JAL7CP",
        "pdf_link": "https://openreview.net/pdf?id=M1y9JAL7CP",
        "keywords": "policy gradient, Markov Decision Process, epistemic uncertainty, Bayesian approach, general loss function, convex RL",
        "abstract": "Motivated by many application problems, we consider Markov decision processes (MDPs) with a general loss function and unknown parameters. To mitigate the epistemic uncertainty associated with unknown parameters, we take a Bayesian approach to estimate the parameters from data and impose a coherent risk functional (with respect to the Bayesian posterior distribution) on the general loss function. Since this formulation usually does not satisfy the interchangeability principle, it does not admit Bellman equations and cannot be solved by approaches based on dynamic programming. Therefore, we develop a policy gradient optimization approach to address this problem.  We utilize the dual representation of the coherent risk measure and extend the envelope theorem to derive the policy gradient. Our extension of the envelope theorem\nfrom the discrete case to the continuous case may be of independent interest. We then show the convergence of the proposed algorithm with a convergence rate of $\\mathcal{O}(\\frac{1}{t})$, where $t$ is the number of policy gradient iterations. We further extend our algorithm to an episodic setting, and establish the consistency of the extended algorithm and provide bounds on the number of iterations needed to achieve a constant error bound in each episode."
    },
    {
        "title": "Visual Description Grounding Reduces Hallucinations and Boosts Reasoning in LVLMs",
        "link_suffix": "/forum?id=3PRvlT8b1R",
        "link": "https://openreview.net/forum?id=3PRvlT8b1R",
        "pdf_link": "https://openreview.net/pdf?id=3PRvlT8b1R",
        "keywords": "lvlm, hallucinations, reasoning",
        "abstract": "Large Vision-Language Models (LVLMs) often produce responses that misalign with factual information, a phenomenon known as hallucinations. While hallucinations are well-studied, the exact causes behind them remain underexplored. In this paper, we first investigate the root causes of hallucinations in LVLMs. Our findings reveal that existing mitigation techniques primarily reduce hallucinations for visual recognition prompts\u2014those that require simple descriptions of visual elements\u2014but fail for cognitive prompts that demand deliberate reasoning. We identify the core issue as a lack of true visual perception in LVLMs: although they can accurately recognize visual elements, they struggle to fully interpret these elements in the context of the input prompt and effectively link this recognition to their internal knowledge, which is critical for reasoning. To address this gap, we introduce Visual Description Grounded Decoding (VDGD), a simple, robust, and training-free method designed to enhance visual perception and improve reasoning capabilities in LVLMs. VDGD works by first generating a detailed description of the image and appending it as a prefix to the instruction. During response generation, tokens are sampled based on their KL divergence to the description, favoring candidates with lower divergence. Experimental results on multiple visual reasoning benchmarks and LVLMs demonstrate that VDGD consistently outperforms existing baselines  2% - 33%. Finally, we introduce VaLLu, a benchmark designed for comprehensive evaluation of the cognitive capabilities of LVLMs."
    },
    {
        "title": "MLLMs Know Where to Look: Training-free Perception of Small Visual Details with Multimodal LLMs",
        "link_suffix": "/forum?id=DgaY5mDdmT",
        "link": "https://openreview.net/forum?id=DgaY5mDdmT",
        "pdf_link": "https://openreview.net/pdf?id=DgaY5mDdmT",
        "keywords": "Multimodal Large Language Models, Visual Details, Attention, Gradients, Bias, Perception, Localization",
        "abstract": "Multimodal Large Language Models (MLLMs) have recently achieved promising performance on visual question answering (VQA)---a fundamental task affecting various downstream applications and domains. Given MLLMs' potential integration into many critical VQA applications, it is important to understand the limits of their perception. In this work, we study whether MLLMs can perceive small details as well as large details in images. In particular, we observe that their accuracy in answering visual questions is very sensitive to the size of the visual subject of the question. We further show that this effect is causal by observing that human visual cropping can significantly mitigate this sensitivity. Next, we study the attention patterns of MLLMs when answering visual questions, and intriguingly find that they consistently know where to look, even when they provide the wrong answer. Based on these findings, we then construct automatic visual cropping methods that leverage the internal knowledge of any MLLM itself, in the form of attention and gradient maps, to help it better perceive the small visual subject of any question. We study our proposed methods on two MLLMs and seven visual question answering benchmarks, and show that they can significantly improve MLLMs accuracy without requiring any training. Our findings suggest that MLLMs should be used with caution in detail-sensitive applications, and that visual cropping is a promising direction to improve their performance."
    },
    {
        "title": "Partially Observed Trajectory Inference using Optimal Transport and a Dynamics Prior",
        "link_suffix": "/forum?id=H8hO3T3DYe",
        "link": "https://openreview.net/forum?id=H8hO3T3DYe",
        "pdf_link": "https://openreview.net/pdf?id=H8hO3T3DYe",
        "keywords": "optimal transport, trajectory inference, stochastic calculus, optimization, Langevin dynamics",
        "abstract": "Trajectory inference seeks to recover the temporal dynamics of a population from snapshots of its (uncoupled) temporal marginals, i.e. where observed particles are \\emph{not} tracked over time. Lavenant et al. (2023) addressed this challenging problem under a stochastic differential equation (SDE) model with a gradient-driven drift in the observed space, introducing a minimum entropy estimator relative to the Wiener measure. Chizat et al. (2022) then provided a practical grid-free mean-field Langevin (MFL) algorithm using Schrodinger bridges. Motivated by the overwhelming success of observable state space models in the traditional paired trajectory inference problem (e.g. target tracking), we extend the above framework to a class of latent SDEs in the form of \\emph{observable state space models}. In this setting, we use partial observations to infer trajectories in the latent space under a specified dynamics model (e.g. the constant velocity/acceleration models from target tracking). We introduce PO-MFL to solve this latent trajectory inference problem and provide theoretical guarantees by extending the results of Lavenant et al. (2023) to the partially observed setting. We leverage the MFL framework of Chizat et al. (2022), yielding an algorithm based on entropic OT between dynamics-adjusted adjacent time marginals. Experiments validate the robustness of our method and the exponential convergence of the MFL dynamics, and demonstrate significant outperformance over the latent-free method of Chizat et al. (2022) in key scenarios."
    },
    {
        "title": "Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos",
        "link_suffix": "/forum?id=VZN0irKnl0",
        "link": "https://openreview.net/forum?id=VZN0irKnl0",
        "pdf_link": "https://openreview.net/pdf?id=VZN0irKnl0",
        "keywords": "Sharpness Dynamics, Catapult Effect, Edge of Stability",
        "abstract": "In gradient descent dynamics of neural networks, the top eigenvalue of the Hessian of the loss (sharpness) displays a variety of robust phenomena throughout training. This includes early time regimes where the sharpness may decrease during early periods of training (sharpness reduction), and later time behavior such as progressive sharpening and edge of stability. We demonstrate that a simple \n-layer linear network (UV model) trained on a single training example exhibits all of the essential sharpness phenomenology observed in real-world scenarios. By analyzing the structure of dynamical fixed points in function space and the vector field of function updates, we uncover the underlying mechanisms behind these sharpness trends. Our analysis reveals (i) the mechanism behind early sharpness reduction and progressive sharpening, (ii) the required conditions for edge of stability, and (iii) a period-doubling route to chaos on the edge of stability manifold as learning rate is increased. Finally, we demonstrate that various predictions from this simplified model generalize to real-world scenarios and discuss its limitations."
    },
    {
        "title": "Symmetric Reinforcement Learning Loss for Robust Learning on Diverse Tasks and Model Scales",
        "link_suffix": "/forum?id=9oq0iY2Jxx",
        "link": "https://openreview.net/forum?id=9oq0iY2Jxx",
        "pdf_link": "https://openreview.net/pdf?id=9oq0iY2Jxx",
        "keywords": "Reinforcement Learning, Robust Reinforcement Learning, Reverse Cross Entory",
        "abstract": "Reinforcement learning (RL) training is inherently unstable due to factors such as moving targets and high gradient variance. Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF) introduce additional challenges. For instance, diverse preferences complicate the alignment process, and prediction errors in a trained reward model can become more severe as the LLM generates unseen outputs. These RL challenges create confusion about whether the probability of an action for a given state should be increased or decreased, similar to the noise in labels for classification tasks. In this work, we enhance the stability of the RL training procedure by adapting reverse cross-entropy (RCE) from supervised learning for noisy data to define a symmetric RL loss. We demonstrate performance improvements across various tasks and scales. We conduct experiments in discrete action tasks (Atari games) and continuous action space tasks (MuJoCo benchmark and Box2D) using Symmetric A2C (SA2C) and Symmetric PPO (SPPO), with and without added noise. Notably, SPPO shows strong performance across different hyperparameters. Furthermore, we validate the benefits of the symmetric RL loss in the RLHF framework using PPO for natural language processing tasks, demonstrating improved performance in tasks such as IMDB positive sentiment and TL;DR summarization."
    }
]
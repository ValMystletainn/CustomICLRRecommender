[
    {
        "title": "Art-Free Generative Models: Exploring Art Creation Without Prior Artistic Knowledge",
        "link_suffix": "/forum?id=qh57QGETn1",
        "link": "https://openreview.net/forum?id=qh57QGETn1",
        "pdf_link": "https://openreview.net/pdf?id=qh57QGETn1",
        "keywords": "generative models; art; generative art;",
        "abstract": "In this work, we explore the question: \u201cHow much prior art knowledge is needed to create art?\u201d To investigate this, we propose a text-to-image generation model trained without access to art-related content. We then introduce a simple yet effective method to learn an art adaptor using only a few examples of selected artistic styles. Our experiments show that art generated using our method is perceived by users as comparable to art produced by models trained on large, art-rich datasets. Finally, through data attribution techniques, we illustrate how examples from both artistic and non-artistic datasets contributed to the creation of new artistic styles."
    },
    {
        "title": "Pseudo Physics-Informed Neural Operators",
        "link_suffix": "/forum?id=CrmUKllBKs",
        "link": "https://openreview.net/forum?id=CrmUKllBKs",
        "pdf_link": "https://openreview.net/pdf?id=CrmUKllBKs",
        "keywords": "Pseudo Physics, Data-Driven Physics Discovery, PDEs, Neural Operator, AI for science, Scientific Machine Learning",
        "abstract": "Recent advancements in operator learning are transforming the landscape of computational physics and engineering, especially alongside the rapidly evolving field of physics-informed machine learning. The convergence of these areas offers\nexciting opportunities for innovative research and applications. However, merging\nthese two realms often demands deep expertise and explicit knowledge of physical systems, which may be challenging or even impractical in relatively complex applications. To address this limitation, we propose a novel framework: Pseudo\nPhysics-Informed Neural Operator (PPI-NO). In this framework, we construct a\nsurrogate physics system for the target system using partial differential equations\n(PDEs) derived from simple, rudimentary physics knowledge, such as basic differential operators. We then couple the surrogate system with the neural operator model, utilizing an alternating update and learning process to iteratively enhance\nthe model\u2019s predictive power. While the physics derived via PPI-NO may not mirror the ground-truth underlying physical laws \u2014 hence the term \u201cpseudo physics\u201d \u2014 this approach significantly enhances the accuracy of current operator learning\nmodels, particularly in data scarce scenarios. Through extensive evaluations across\nfive benchmark operator learning tasks and an application in fatigue modeling,\nPPI-NO consistently outperforms competing methods by a significant margin. The\nsuccess of PPI-NO may introduce a new paradigm in physics-informed machine\nlearning, one that requires minimal physics knowledge and opens the door to\nbroader applications in data-driven physics learning and simulations."
    },
    {
        "title": "DLGNet: Hyperedge Classification through Directed Line Graphs for Chemical Reactions",
        "link_suffix": "/forum?id=fUHoUXGUZp",
        "link": "https://openreview.net/forum?id=fUHoUXGUZp",
        "pdf_link": "https://openreview.net/pdf?id=fUHoUXGUZp",
        "keywords": "Directed Line Graph, Directed Line Graph Laplacian, Hyperedge Classification, Chemical reaction classification",
        "abstract": "Graphs and hypergraphs provide powerful abstractions for modeling interactions among a set of entities of interest and have been attracting a growing interest in the literature thanks to many successful applications in several fields. In particular, they are rapidly expanding in domains such as chemistry and biology, especially in the areas of drug discovery and molecule generation. One of the areas witnessing the fasted growth is the chemical reactions field, where chemical reactions can be naturally encoded as directed hyperedges of a hypergraph. In this paper, we address the chemical reaction classification problem by introducing the notation of a Directed Line Graph (DGL) associated with a given directed hypergraph. On top of it, we build the Directed Line Graph Network (DLGNet), the first spectral-based Graph Neural Network (GNN) expressly designed to operate on a hypergraph via its DLG transformation. The foundation of DLGNet is a novel Hermitian matrix, the Directed Line Graph Laplacian $\\mathbb{\\vec L}_N$, which compactly encodes the directionality of the interactions taking place within the directed hyperedges of the hypergraph thanks to the DLG representation. $\\mathbb{\\vec L}_N$ enjoys many desirable properties, including admitting an eigenvalue decomposition and being positive semidefinite, which make it well-suited for its adoption within a spectral-based GNN. Through extensive experiments on chemical reaction datasets, we show that DGLNet significantly outperforms the existing approaches, achieving on a collection of real-world datasets an average relative-percentage-difference improvement of 33.01%, with a maximum improvement of 37.71%."
    },
    {
        "title": "GRADIENT-OPTIMIZED CONTRASTIVE LEARNING",
        "link_suffix": "/forum?id=ds6Mmd7LlH",
        "link": "https://openreview.net/forum?id=ds6Mmd7LlH",
        "pdf_link": "https://openreview.net/pdf?id=ds6Mmd7LlH",
        "keywords": "Contrastive learning; Sparse kernel machines; Image classification; Point cloud completion",
        "abstract": "Contrastive learning is a crucial technique in representation learning, producing robust embeddings by distinguishing between similar and dissimilar pairs. In this paper, we introduce a novel framework, Gradient-Optimized Contrastive Learning (GOAL), which enhances network training by optimizing gradient updates during backpropagation as a bilevel optimization problem. Our approach offers three key insights that set it apart from existing methods: (1) Contrastive learning can be seen as an approximation of a one-class support vector machine (OC-SVM) using multiple neural tangent kernels (NTKs) in the network\u2019s parameter space; (2) Hard triplet samples are vital for defining support vectors and outliers in OC-SVMs within NTK spaces, with their difficulty measured using Lagrangian multipliers; (3) Contrastive losses like InfoNCE provide efficient yet dense approximations of sparse Lagrangian multipliers by implicitly leveraging gradients. To address the computational complexity of GOAL, we propose a novel contrastive loss function, Sparse InfoNCE (SINCE), which improves the Lagrangian multiplier approximation by incorporating hard triplet sampling into InfoNCE. Our experimental results demonstrate the effectiveness and efficiency of SINCE in tasks such as image classification and point cloud completion. Demo code is attached in the supplementary file."
    },
    {
        "title": "DS-LLM: Leveraging Dynamical Systems to Enhance Both Training and Inference of Large Language Models",
        "link_suffix": "/forum?id=OPSpdc25IZ",
        "link": "https://openreview.net/forum?id=OPSpdc25IZ",
        "pdf_link": "https://openreview.net/pdf?id=OPSpdc25IZ",
        "keywords": "Large Language Model;  nature-powered computing; dynamic physical system",
        "abstract": "The training of LLMs faces fundamental computational cost challenges which limit their scaling to even larger models aimed at AGI. Currently, LLM model sizes double approximately every 3.4 months, with the training costs surging from 64 million USD for GPT-4 in 2020 to 191 million USD for Gemini Ultra in 2023. Meanwhile, the substantial cost of LLM inference remains a significant barrier to its widespread adoption in everyday applications. While existing optimizations methods such as quantization may help alleviate some of the strain, they do not fundamentally resolve the issue. New computational design paradigms for LLMs are urgently needed.Recently, dynamic system (DS)-based machines have emerged, which incorporates a Natural Annealing process that automatically and instantly converges minimum system energy states in accordance with electrodynamics. Early investigation has demonstrated that the analog DS machines can potentially achieve 1,000x speedups, and 100,000x energy reduction for some graph learning problems, which offers game-changing potential in addressing the computational cost challenges of LLMs.In this work, we propose DS-LLM, which constructs LLMs from scratch using DS machines. For inference, we map LLM model components to various optimization problems that can be embedded and solved through different Hamiltonian configurations of the DS machines. For training, we rely on the responsive flow of electric currents within the DS machines, which enables hardware-oriented, instantaneous, and continuous processes of gradient descent. We mathematically demonstrate the equivalence between current LLMs and DS-LLMs and offer a viable approach to build a DS-LLM from a trained conventional LLM. Evaluations using GPT2, GPT2-medium and OPT-1.3B showcase a 1,090$\\times$ speedup and a 102,559$\\times$ energy reduction on training, a 127$\\times$ speedup and a 37,545$\\times$ energy reduction on inference, while maintaining consistent accuracy."
    },
    {
        "title": "EMOE: Expansive Matching of Experts for Robust Uncertainty Based Rejection",
        "link_suffix": "/forum?id=YFDM6uMMSE",
        "link": "https://openreview.net/forum?id=YFDM6uMMSE",
        "pdf_link": "https://openreview.net/pdf?id=YFDM6uMMSE",
        "keywords": "out of distribution generalization, OOD, reject option, data augmentation",
        "abstract": "Expansive Matching of Experts (EMOE) is a novel method that utilizes support-expanding, extrapolatory pseudo-labeling to improve prediction and uncertainty based rejection on out-of-distribution (OOD) points. We propose an expansive data augmentation technique that generates OOD instances in a latent space, and an empirical trial based approach to filter out augmented expansive points for pseudo-labeling. EMOE utilizes a diverse set of multiple base experts as pseudo-labelers on the  augmented data to improve OOD performance through a shared MLP with multiple heads (one per expert). We demonstrate that EMOE achieves superior performance compared to state-of-the-art methods on both image and tabular data."
    },
    {
        "title": "Distortion-free and GPU-compatible Tree Embeddings in Hyperbolic Space",
        "link_suffix": "/forum?id=vxWDoD8oz7",
        "link": "https://openreview.net/forum?id=vxWDoD8oz7",
        "pdf_link": "https://openreview.net/pdf?id=vxWDoD8oz7",
        "keywords": "Hyperbolic Geometry, Hyperbolic Tree Embeddings, Representation Learning, Hierarchical Learning",
        "abstract": "Embedding tree-like data, from hierarchies to ontologies and taxonomies, forms a well-studied problem for representing knowledge across many domains. Hyperbolic geometry provides a natural solution for embedding trees, with vastly superior performance over Euclidean embeddings. Recent literature has shown that hyperbolic tree embeddings can even be placed on top of neural networks for hierarchical knowledge integration in deep learning settings. For all applications, a faithful embedding of trees is needed, with combinatorial constructions emerging as the most effective direction. This paper identifies and solves two key limitations of existing works. First, the combinatorial construction hinges on finding maximally separated points on a hypersphere, a notoriously difficult problem. Current approaches lead to poor separation, which degrades the quality of the corresponding hyperbolic embedding. As a solution, we propose maximally separated Delaunay tree embeddings (MS-DTE), where during placement, the children of a node are maximally separated through optimization, which directly leads to lower embedding distortion. Second, low distortion requires additional precision. The current approach for increasing precision is to use multiple precision arithmetic, which renders the embeddings useless on GPUs in deep learning settings. We reformulate the combinatorial construction using floating point expansion arithmetic, leading to superior embedding quality while simultaneously retaining their use on accelerated hardware."
    },
    {
        "title": "AdaFisher: Adaptive Second Order Optimization via Fisher Information",
        "link_suffix": "/forum?id=puTxuiK2qO",
        "link": "https://openreview.net/forum?id=puTxuiK2qO",
        "pdf_link": "https://openreview.net/pdf?id=puTxuiK2qO",
        "keywords": "Second Order Optimization, Fisher Information, Kronecker-factored Approximate Curvature, Deep Learning, Computer Vision, Natural Language Processing",
        "abstract": "First-order optimization methods are currently the mainstream in training deep neural networks (DNNs). Optimizers like Adam incorporate limited curvature information by employing the diagonal matrix preconditioning of the stochastic gradient during the training. Despite their widespread, second-order optimization algorithms exhibit superior convergence properties compared to their first-order counterparts e.g. Adam and SGD. However, their practicality in training DNNs are still limited due to increased per-iteration computations and suboptimal accuracy compared to the first order methods. We present AdaFisher--an adaptive second-order optimizer that leverages a block-diagonal approximation to the Fisher information matrix for adaptive gradient preconditioning. AdaFisher aims to bridge the gap between enhanced convergence capabilities and computational efficiency in second-order optimization framework for training DNNs. Despite the slow pace of second-order optimizers, we showcase that AdaFisher can be reliably adopted for image classification, language modelling and stand out for its stability and robustness in hyperparameter tuning. We demonstrate that AdaFisher outperforms the SOTA optimizers in terms of both accuracy and convergence speed."
    },
    {
        "title": "Judging the Judges: A Systematic Investigation of Position Bias in Pairwise Comparative Assessments by LLMs",
        "link_suffix": "/forum?id=y3jJmrKWQ4",
        "link": "https://openreview.net/forum?id=y3jJmrKWQ4",
        "pdf_link": "https://openreview.net/pdf?id=y3jJmrKWQ4",
        "keywords": "LLM-as-a-Judge, LLM evaluators, position bias, length bias, verbosity bias, pairwise comparison, repetition stability, position consistency, preference fairness",
        "abstract": "LLM-as-a-Judge presents a promising alternative to human evaluators across various tasks, but inherent biases, especially position bias \u2014 a tendency to favor solutions based on their position in the prompt \u2014 have compromised its effectiveness. Our study introduces a systematic framework to examine position bias in pairwise comparisons, focusing on repetition stability, position consistency, and preference fairness. This research significantly contributes to the field by introducing new concepts for understanding position bias and providing a multi-dimensional framework for evaluations. We conducted experiments with 12 LLM judges across MTBench and DevBench, covering 22 tasks and approximately 40 solution-generating models \u2014 candidates, resulting in over 100,000 evaluation instances. Our findings confirm that position bias in capable LLM judges is not due to random chances, along with notable variations observed across judges and tasks. Moreover, position bias is weakly influenced by the length of prompt components but significantly impacted by the quality gap between solutions. These insights can help optimize judge model selections, improve benchmark design, and inform future research on debiasing strategies, ultimately enhancing the reliability of LLM judges."
    },
    {
        "title": "DPaI: Differentiable Pruning at Initialization with Node-Path Balance Principle",
        "link_suffix": "/forum?id=hvLBTpiDt3",
        "link": "https://openreview.net/forum?id=hvLBTpiDt3",
        "pdf_link": "https://openreview.net/pdf?id=hvLBTpiDt3",
        "keywords": "Prunning at Initialization, Sparsity, Neural Architecture Search",
        "abstract": "Pruning at Initialization (PaI) is a technique in neural network optimization characterized by the proactive elimination of weights before the network's training on designated tasks. This innovative strategy potentially reduces the costs for training and inference, significantly advancing computational efficiency. A key element of PaI's effectiveness is that it considers the significance of weights in an untrained network. It prioritizes the trainability and optimization potential of the pruned subnetworks. Recent methods can effectively prevent the formation of hard-to-optimize networks, e.g. through iterative adjustments at each network layer. However, this way often results inlarge-scale discrete optimization problems, which could make PaI further challenging. This paper introduces a novel method, calledDPaI, that involves a differentiable optimization of the pruning mask. DPaI adopts a dynamic and adaptable pruning process, allowing easier optimisation processes and better solutions. More importantly, our differentiable formulation enables readily use of the existing rich body of efficient gradient-based methods for PaI. Our empirical results demonstrate that DPaI significantly outperforms current state-of-the-art PaI methods on various architectures, such as Convolutional Neural Networks and Vision-Transformers."
    },
    {
        "title": "Learning Molecular Representation in a Cell",
        "link_suffix": "/forum?id=BbZy8nI1si",
        "link": "https://openreview.net/forum?id=BbZy8nI1si",
        "pdf_link": "https://openreview.net/pdf?id=BbZy8nI1si",
        "keywords": "Molecular Representation Learning, Drug Discovery, Cell Morphology, Gene Expression",
        "abstract": "Predicting drug efficacy and safety in vivo requires information on biological responses (e.g., cell morphology and gene expression) to small molecule perturbations. However, current molecular representation learning methods do not provide a comprehensive view of cell states under these perturbations and struggle to remove noise, hindering model generalization. We introduce the Information Alignment (InfoAlign) approach to learn molecular representations through the information bottleneck method in cells. We integrate molecules and cellular response data as nodes into a context graph, connecting them with weighted edges based on chemical, biological, and computational criteria. For each molecule in a training batch, InfoAlign optimizes the encoder's latent representation with a minimality objective to discard redundant structural information. A sufficiency objective decodes the representation to align with different feature spaces from the molecule's neighborhood in the context graph. We demonstrate that the proposed sufficiency objective for alignment is tighter than existing encoder-based contrastive methods. Empirically, we validate representations from InfoAlign in two downstream applications: molecular property prediction against up to 27 baseline methods across four datasets, plus zero-shot molecule-morphology matching."
    },
    {
        "title": "Uncertainty-Aware PPG-2-ECG for Enhanced Cardiovascular Diagnosis using Diffusion Models",
        "link_suffix": "/forum?id=1dkVCX4jlH",
        "link": "https://openreview.net/forum?id=1dkVCX4jlH",
        "pdf_link": "https://openreview.net/pdf?id=1dkVCX4jlH",
        "keywords": "Inverse Problems",
        "abstract": "Analyzing the cardiovascular system condition via Electrocardiography (ECG) is a common and highly effective approach, and it has been practiced and perfected over many decades. ECG sensing is non-invasive and relatively easy to acquire, and yet it is still cumbersome for holter monitoring tests that may span over hours and even days. A possible alternative in this context is Photoplethysmography (PPG): An optically-based signal that measures blood volume fluctuations, as typically sensed by conventional ``wearable devices''. While PPG presents clear advantages in acquisition, convenience, and cost-effectiveness, ECG provides more comprehensive information, allowing for a more precise detection of heart conditions. This implies that a conversion from PPG to ECG, as recently discussed in the literature, inherently involves an unavoidable level of uncertainty. In this paper we introduce a novel methodology for addressing the PPG-2-ECG conversion, and offer an enhanced classification of cardiovascular conditions using the given PPG, all while taking into account the uncertainties arising from the conversion process. We provide a mathematical justification for our proposed computational approach, and present empirical studies demonstrating its superior performance compared to state-of-the-art baseline methods."
    },
    {
        "title": "Open-YOLO 3D: Towards Fast and Accurate Open-Vocabulary 3D Instance Segmentation",
        "link_suffix": "/forum?id=CRmiX0v16e",
        "link": "https://openreview.net/forum?id=CRmiX0v16e",
        "pdf_link": "https://openreview.net/pdf?id=CRmiX0v16e",
        "keywords": "Open Vocabulary, 3D point cloud instance segmentation",
        "abstract": "Recent works on open-vocabulary 3D instance segmentation show strong promise but at the cost of slow inference speed and high computation requirements. This high computation cost is typically due to their heavy reliance on aggregated clip features from multi-view, which require computationally expensive 2D foundation models like Segment Anything (SAM) and CLIP. Consequently, this hampers their applicability in many real-world applications that require both fast and accurate predictions. To this end, we propose a novel open-vocabulary 3D instance segmentation approach, named Open-YOLO 3D, that efficiently leverages only 2D object detection from multi-view RGB images for open-vocabulary 3D instance segmentation. \n We demonstrate that our proposed Multi-View Prompt Distribution (MVPDist) method makes use of multi-view information to account for misclassification from the object detector to predict a reliable label for 3D instance masks. Furthermore, since projections of 3D object instances are already contained within the 2D bounding boxes, we show that our proposed low granularity label maps, which require only a 2D object detector to construct, are sufficient and very fast to predict prompt IDs for 3D instance masks when used with our proposed MVPDist.\n We validate our Open-YOLO 3D on two benchmarks, ScanNet200 and Replica, \n under two scenarios: (i) with ground truth masks, where labels are required for given object proposals, and (ii) with class-agnostic 3D proposals generated from a 3D proposal network.\n Our Open-YOLO 3D achieves state-of-the-art performance on both datasets while obtaining up to $\\sim$16$\\times$ speedup compared to the best existing method in literature. On ScanNet200 val. set, our Open-YOLO 3D achieves mean average precision (mAP) of 24.7% while operating at 22 seconds per scene. Our code will be publically available."
    },
    {
        "title": "Deep Learning with Plausible Deniability",
        "link_suffix": "/forum?id=sWwK0lJ8dK",
        "link": "https://openreview.net/forum?id=sWwK0lJ8dK",
        "pdf_link": "https://openreview.net/pdf?id=sWwK0lJ8dK",
        "keywords": "Deep learning, Privacy, Plausible Deniability",
        "abstract": "Deep learning models are vulnerable to privacy attacks due to their tendency to memorize individual training set examples. Theoretically-sound defenses such as differential privacy can defend against this threat, but model performance often suffers. Empirical defenses may thwart existing attacks while maintaining model performance but do not offer any robust theoretical guarantees.In this paper, we explore a new strategy based on the concept of plausible deniability. We introduce a training algorithm called Plausibly Deniable Stochastic Gradient Descent (PD-SGD), which aims to provide both strong privacy protection with theoretical justification and maintain high performance. The core of this approach is a rejection sampling technique, which probabilistically prevents updating model parameters whenever a mini-batch cannot be plausibly denied. This ensures that no individual example has a disproportionate influence on the model parameters. We provide a set of theoretical results showing that PD-SGD effectively mitigates privacy leakage from individual data points.  Experiments also demonstrate that PD-SGD offers a favorable trade-off between privacy and utility compared to differential privacy (i.e., DP-SGD) and empirical defense methods."
    },
    {
        "title": "Conformal prediction for causal effects of continuous treatments",
        "link_suffix": "/forum?id=pVL4bYKOGM",
        "link": "https://openreview.net/forum?id=pVL4bYKOGM",
        "pdf_link": "https://openreview.net/pdf?id=pVL4bYKOGM",
        "keywords": "causality, dosage response curves, conformal prediction, uncertainty quantification",
        "abstract": "Uncertainty quantification of causal effects is crucial for safety-critical applications such as personalized medicine. A powerful approach for this is conformal prediction, which has several practical benefits due to model-agnostic finite-sample guarantees. Yet, existing methods for conformal prediction of causal effects are limited to binary/discrete treatments and make highly restrictive assumptions such as known propensity scores. In this work, we provide a novel conformal prediction method for potential outcomes of continuous treatments. We account for the additional uncertainty introduced through propensity estimation so that our conformal prediction intervals are valid even if the propensity score is unknown. Our contributions are three-fold: (1) We derive finite-sample prediction intervals for potential outcomes of continuous treatments. (2) We provide an algorithm for calculating the derived intervals. (3) We demonstrate the effectiveness of the conformal prediction intervals in experiments on synthetic and medical datasets. To the best of our knowledge, we are the first to propose conformal prediction for continuous treatments when the propensity score is unknown and must be estimated from data."
    },
    {
        "title": "VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos",
        "link_suffix": "/forum?id=F4bHMojXVW",
        "link": "https://openreview.net/forum?id=F4bHMojXVW",
        "pdf_link": "https://openreview.net/pdf?id=F4bHMojXVW",
        "keywords": "Long Video Understanding, Video-lanaguage Understanding, Multimodal Learning, LLM-based Video Understanding",
        "abstract": "Long-form video understanding has been a challenging task due to the high redundancy in video data and the abundance of query-irrelevant information. To tackle this challenge, we propose VideoTree, a training-free framework which builds a query-adaptive and hierarchical video representation for LLM reasoning over long-form videos. First, VideoTree extracts query-relevant information from the input video through an iterative process, progressively refining the selection of keyframes based on their relevance to the query. Furthermore, VideoTree leverages the inherent hierarchical structure of long video data, which is often overlooked by existing LLM-based methods. Specifically, we incorporate multigranularity information into a tree-based representation, allowing VideoTree to extract query-relevant details from long videos in a coarse-to-fine manner. This enables the model to effectively handle a wide range of video queries with varying levels of detail. Finally, VideoTree aggregates the hierarchical query-relevant information within the tree structure and feeds it into an LLM reasoning model to answer the query. Our experiments show that our training-free method improves both reasoning accuracy and efficiency compared to existing methods. Specifically, VideoTree outperforms the existing training-free approaches on the popular EgoSchema and NExT-QA benchmarks with less inference time, achieving 61.1% and 75.6% accuracy on the test set without additional video-specific training. Moreover, on the long split of Video-MME benchmark (average 44 minutes), the training-free VideoTree framework achieves better performance than the strong proprietary GPT-4V model and other MLLMs that were extensively trained on video data. Our code is provided in the supplementary and will be made public."
    },
    {
        "title": "Predicting perturbation targets with causal differential networks",
        "link_suffix": "/forum?id=cbFqqtJGtA",
        "link": "https://openreview.net/forum?id=cbFqqtJGtA",
        "pdf_link": "https://openreview.net/pdf?id=cbFqqtJGtA",
        "keywords": "perturbation experiments, Perturb-seq, transcriptomics, causality",
        "abstract": "Rationally identifying variables responsible for changes to a biological system can enable myriad applications in disease understanding and cell engineering. From a causality perspective, we are given two datasets generated by the same causal model, one observational (control) and one interventional (perturbed). The goal is to isolate the subset of measured variables (e.g. genes) that were the targets of the intervention, i.e. those whose conditional independencies have changed. Knowing the causal graph would limit the search space, allowing us to efficiently pinpoint these variables. However, current algorithms that infer causal graphs in the presence of unknown intervention targets scale poorly to the hundreds or thousands of variables in biological data, as they must jointly search the combinatorial spaces of graphs and consistent intervention targets. In this work, we propose a causality-inspired approach for predicting perturbation targets that decouples the two search steps. First, we use an amortized causal discovery model to separately infer causal graphs from the observational and interventional datasets. Then, we learn to map these paired graphs to the sets of variables that were intervened upon, in a supervised learning framework. This approach consistently outperforms baselines for perturbation modeling on seven single-cell transcriptomics datasets, each with thousands of measured variables. We also demonstrate significant improvements over six causal discovery algorithms in predicting intervention targets across a variety of tractable, synthetic datasets."
    },
    {
        "title": "Gradient descent with generalized Newton\u2019s method",
        "link_suffix": "/forum?id=bI3fcTsKW4",
        "link": "https://openreview.net/forum?id=bI3fcTsKW4",
        "pdf_link": "https://openreview.net/pdf?id=bI3fcTsKW4",
        "keywords": "Optimization, Hessian matrix, Learning rate scheduler",
        "abstract": "We propose the generalized Newton's method (GeN) --- a Hessian-informed approach that applies to any optimizer such as SGD and Adam, and covers the Newton-Raphson method as a sub-case. Our method automatically and dynamically selects the learning rate that accelerates the convergence, without the intensive tuning of the learning rate scheduler. In practice, our method is easily implementable, since it only requires additional forward passes with almost zero computational overhead (in terms of training time and memory cost), if the overhead is amortized over many iterations. We present extensive experiments on language and vision tasks (e.g. GPT and ResNet) to showcase that GeN optimizers match the state-of-the-art performance, which was achieved with carefully tuned learning rate schedulers."
    },
    {
        "title": "ConBatch-BAL: Batch Bayesian Active Learning under Budget Constraints",
        "link_suffix": "/forum?id=mmpVsDjVgn",
        "link": "https://openreview.net/forum?id=mmpVsDjVgn",
        "pdf_link": "https://openreview.net/pdf?id=mmpVsDjVgn",
        "keywords": "Bayesian Active Learning, Real-World Datasets, Batch Acquisition, Budget Constraints",
        "abstract": "Varying annotation costs among data points and budget constraints can hinder the adoption of active learning strategies in real-world applications. This work introduces two Bayesian active learning strategies for batch acquisition under constraints (ConBatch-BAL), one based on dynamic thresholding and one following greedy acquisition. Both select samples using uncertainty metrics computed via Bayesian neural networks. The dynamic thresholding strategy redistributes the budget across the batch, while the greedy one selects the top-ranked sample at each step, limited by the remaining budget. Focusing on scenarios with costly data annotation and geospatial constraints, we also release two new real-world datasets containing geolocated aerial images of buildings, annotated with energy efficiency or typology classes. The ConBatch-BAL strategies are benchmarked against a random acquisition baseline on these datasets under various budget and cost scenarios. The results show that the developed ConBatch-BAL strategies can reduce active learning iterations and data acquisition costs in real-world settings, and even outperform the unconstrained baseline solutions."
    },
    {
        "title": "Certified Robustness Under Bounded Levenshtein Distance",
        "link_suffix": "/forum?id=cd79pbXi4N",
        "link": "https://openreview.net/forum?id=cd79pbXi4N",
        "pdf_link": "https://openreview.net/pdf?id=cd79pbXi4N",
        "keywords": "Robustness verification, Text classifiers, Lipschitz constant",
        "abstract": "Text classifiers suffer from small perturbations, that if chosen adversarially, can dramatically change the output of the model. Verification methods can provide robustness certificates against such adversarial perturbations, by computing a sound lower bound on the robust accuracy. Nevertheless, existing verification methods incur in prohibitive costs and cannot practically handle Levenshtein distance constraints. We propose the first method for computing the Lipschitz constant of convolutional classifiers with respect to the Levenshtein distance. We use these Lipschitz constant estimates for training 1-Lipschitz classifiers. This enables computing the certified radius of a classifier in a single forward pass. Our method, LipsLev, is able to obtain $38.80$% and $13.93$% verified accuracy at distance $1$ and $2$ respectively in the AG-News dataset, while being $4$ orders of magnitude faster than existing approaches. We believe our work can open the door to more efficient verification in the text domain."
    },
    {
        "title": "fine-tuning with very large dropout",
        "link_suffix": "/forum?id=Fvfs0HPuKl",
        "link": "https://openreview.net/forum?id=Fvfs0HPuKl",
        "pdf_link": "https://openreview.net/pdf?id=Fvfs0HPuKl",
        "keywords": "out-of-distribution, fine-tuning, very large dropout",
        "abstract": "It is impossible today to pretend that the practice of machine learning is compatible with the idea that training and testing data follow the same distribution. Several authors have recently used ensemble techniques to show how scenarios involving multiple data distributions are best served by representations that are both richer than those obtained by regularizing for the best in-distribution performance, and richer than those obtained under the influence of the implicit sparsity bias of common stochastic gradient procedures.This contribution investigates the use of very high dropout rates instead of ensembles to obtain such rich representations. Although training a deep network from scratch using such dropout rates is virtually impossible, fine-tuning a large pre-trained model under such conditions is not only possible but also achieves out-of-distribution performances that exceed those of both ensembles and weight averaging methods such as model soups.This result has practical significance because the importance of the fine-tuning scenario has considerably grown in recent years. This result also provides interesting insights on the nature of rich representations and on the intrinsically linear nature of fine-tuning a large network using a comparatively small dataset."
    },
    {
        "title": "Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice",
        "link_suffix": "/forum?id=Tn8EQIFIMQ",
        "link": "https://openreview.net/forum?id=Tn8EQIFIMQ",
        "pdf_link": "https://openreview.net/pdf?id=Tn8EQIFIMQ",
        "keywords": "cognitive model, language model, computational models of cognition, rationality, economics",
        "abstract": "The observed similarities in the behavior of humans and Large Language Models (LLMs) have prompted researchers to consider the potential of using LLMs as models of human cognition. However, several significant challenges must be addressed before LLMs can be legitimately regarded as cognitive models. For instance, LLMs are trained on far more data than humans typically encounter, and may have been directly trained on human data in specific cognitive tasks or aligned with human preferences. Consequently, the origins of these behavioral similarities are not well understood. In this paper, we propose a novel way to enhance the utility of language models as cognitive models. This approach involves (i) leveraging computationally equivalent tasks that both a language model and a rational agent need to master for solving a cognitive problem and (ii) examining the specific task distributions required for a language model to exhibit human-like behaviors. We apply this approach to decision-making -- specifically risky and intertemporal choice -- where the key computationally equivalent task is the arithmetic of expected value calculations. We show that a small language model pretrained on an ecologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts human behavior better than many traditional cognitive models. Pretraining language models on ecologically valid arithmetic datasets is sufficient to produce a strong correspondence between these models and human decision-making. Our results also suggest that language models used as cognitive models should be carefully investigated via ablation studies of the pretraining data."
    },
    {
        "title": "Overcoming Domain Limitations in Open-vocabulary Segmentation",
        "link_suffix": "/forum?id=lcp3oHJ3o2",
        "link": "https://openreview.net/forum?id=lcp3oHJ3o2",
        "pdf_link": "https://openreview.net/pdf?id=lcp3oHJ3o2",
        "keywords": "open-vocabulary, segmentation, fine-tuning, continual learning",
        "abstract": "Open-vocabulary segmentation (OVS) has gained attention for its ability to recognize a broader range of classes. However, OVS models show significant performance drops when applied to unseen domains beyond the previous training dataset. Fine-tuning these models on new datasets can improve performance, but often leads to the catastrophic forgetting of previously learned knowledge. To address this issue, we propose a method that allows OVS models to learn information from new domains while preserving prior knowledge. Our approach begins by evaluating the input sample's proximity to multiple domains, using precomputed multivariate normal distributions for each domain. Based on this prediction, we dynamically interpolate between the weights of the pre-trained decoder and the fine-tuned decoders. Extensive experiments demonstrate that this approach allows OVS models to adapt to new domains while maintaining performance on the previous training dataset."
    },
    {
        "title": "Cascade Reward Sampling for Efficient Decoding-Time Alignment",
        "link_suffix": "/forum?id=UAA2nWUtVl",
        "link": "https://openreview.net/forum?id=UAA2nWUtVl",
        "pdf_link": "https://openreview.net/pdf?id=UAA2nWUtVl",
        "keywords": "Language Model Alignment, Large Language Models",
        "abstract": "Aligning large language models (LLMs) with human preferences is critical for their deployment. Recently, decoding-time alignment has emerged as an effective plug-and-play technique that requires no fine-tuning of model parameters. However, generating text that achieves both high reward and high likelihood remains a significant challenge. Existing methods often fail to generate high-reward text or incur substantial computational costs. In this paper, we propose Cascade Reward Sampling (CARDS) to address both issues, guaranteeing the generation of high-reward and high-likelihood text with significantly low costs. Based on our analysis of reward models (RMs) on incomplete text and our observation that high-reward prefixes induce high-reward complete text, we use rejection sampling to iteratively generate small semantic segments to form such prefixes. The segment length is dynamically determined by the predictive uncertainty of LLMs. This strategy guarantees desirable prefixes for subsequent generations and significantly reduces wasteful token re-generations and the number of reward model scoring. Our experiments demonstrate substantial gains in both generation efficiency and alignment ratings compared to the baselines, achieving five times faster text generation and 99% win-ties in GPT-4/Claude-3 helpfulness evaluation."
    },
    {
        "title": "Test-time Contrastive Concepts for Open-World Semantic Segmentation",
        "link_suffix": "/forum?id=tCYdsuQgZZ",
        "link": "https://openreview.net/forum?id=tCYdsuQgZZ",
        "pdf_link": "https://openreview.net/pdf?id=tCYdsuQgZZ",
        "keywords": "image segmentation, unsupervised learning, open-vocabulary semantic segmentation",
        "abstract": "Recent CLIP-like Vision-Language Models (VLMs), pre-trained on large amounts of image-text pairs to align both modalities with a simple contrastive objective, have paved the way to open-vocabulary semantic segmentation. Given an arbitrary set of textual queries, image pixels are assigned the closest query in feature space. However, this works well when a user exhaustively lists all possible visual concepts in an image, which contrast against each other for the assignment. This corresponds to the current evaluation setup in the literature which relies on having access to a list of in-domain relevant concepts, typically classes of a benchmark dataset. Here, we consider the more challenging (and realistic) scenario of segmenting a single concept, given a textual prompt and nothing else. To achieve good results, besides contrasting with the generic \u201cbackground\u201d text, we propose two different approaches to automatically generate, at test time, textual contrastive concepts that are query-specific. We do so by leveraging the distribution of text in the VLM\u2019s training set or crafted LLM prompts. We also propose a metric designed to evaluate this scenario and show the relevance of our approach on commonly used datasets."
    }
]
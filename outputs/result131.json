[
    {
        "title": "Unifying Structural Proximity and Equivalence for Enhanced Dynamic Network Embedding",
        "link_suffix": "/forum?id=mypnFcBbz4",
        "link": "https://openreview.net/forum?id=mypnFcBbz4",
        "pdf_link": "https://openreview.net/pdf?id=mypnFcBbz4",
        "keywords": "dynamic network, network embedding, network representation, temporal random walk, dynamic graphlets",
        "abstract": "Dynamic network embedding methods transform nodes in a dynamic network into low-dimensional vectors while preserving network characteristics, facilitating tasks such as node classification and community detection. Several embedding methods have been proposed to capture $\\textit{structural proximity}$ among nodes in a network, where densely connected communities are preserved, while others have been proposed to preserve $\\textit{structural equivalence}$ among nodes, capturing their structural roles regardless of their relative distance in the network. However, most existing methods that aim to preserve $\\textit{both}$ network characteristics mainly focus on static networks and those designed for dynamic networks do not explicitly account for inter-snapshot structural properties. This paper proposes a novel unifying dynamic network embedding method that simultaneously preserves both structural proximity and equivalence while considering inter-snapshot structural relationships in a dynamic network. Specifically, to define structural equivalence in a dynamic network, we use temporal subgraphs, known as dynamic graphlets, to capture how a node's neighborhood structure evolves over time. We then introduce a temporal-structural random walk to flexibly sample time-respecting sequences of nodes, considering both their temporal proximity and similarity in evolving structures. The proposed method is evaluated using five real-world networks on node classification where it outperforms benchmark methods, showing its effectiveness and flexibility in capturing various aspects of a network."
    },
    {
        "title": "Losing dimensions: Geometric memorization in generative diffusion",
        "link_suffix": "/forum?id=TmAmuMXkFc",
        "link": "https://openreview.net/forum?id=TmAmuMXkFc",
        "pdf_link": "https://openreview.net/pdf?id=TmAmuMXkFc",
        "keywords": "Generative diffusion, Memorization, Manifold, Geometry, Statistical physics",
        "abstract": "Generative diffusion processes are state-of-the-art machine learning models deeply connected with fundamental concepts in statistical physics. Depending on the dataset size and the capacity of the network, their behavior is known to transition from an associative memory regime to a generalization phase in a phenomenon that has been described as a glassy phase transition. Here, using statistical physics techniques, we extend the theory of memorization in generative diffusion to manifold-supported data. Our theoretical and experimental findings indicate that different tangent subspaces are lost due to memorization effects at different critical times and dataset sizes, which depend on the local variance of the data along their directions. Perhaps counterintuitively, we find that, under some conditions, subspaces of higher variance are lost first due to memorization effects. This leads to a selective loss of dimensionality where some prominent features of the data are memorized without a full collapse on any individual training point. We validate our theory with a comprehensive set of experiments on networks trained both in image datasets and on linear manifolds, which result in a remarkable qualitative agreement with the theoretical predictions."
    },
    {
        "title": "LDINet:  Latent Decomposition-Interpolation for Single Image Fast-moving Objects Deblatting",
        "link_suffix": "/forum?id=N9hTix8kWA",
        "link": "https://openreview.net/forum?id=N9hTix8kWA",
        "pdf_link": "https://openreview.net/pdf?id=N9hTix8kWA",
        "keywords": "fast moving object deblatting, image deblur, time super-resolution, latent decomposition and interpolation",
        "abstract": "The image of fast-moving objects (FMOs) usually contains a blur stripe indicating the blurred object that is mixed with the background. To deblur the stripe and separate the object from the background in the single image, in this work we propose a novel Latent Decomposition-Interpolation Network (LDINet) to generate the appearances and shapes of the objects. In particular, under the assumption that motion blur is an accumulation of the appearance of the object over exposure time and the long blur can be decomposed into several shorter blur parts, the blurry input is first encoded into latent feature maps and then an efficient Decomposition-Interpolation Module (DIM) is introduced to break down the feature maps into discrete time indexed parts corresponding to different small blurs. And the target latent frames are further interpolated according to the provided time indexes with affine transformations, where the feature maps are categorized into the scalar-like and gradient-like parts to effectively capture the intrinsic properties of features warping in the interpolation. Finally, the sharp and clear images are rendered with a decoder. In addition, based on the generated images by LDINet, a Refining Conditional Deblatting (RCD) approach is presented to use post-image-to-image techniques to further enhance the fidelity of the textures and the accuracy of the masks. Extensive experiments are conducted and have shown that the proposed methods achieve superior performances compared to the existing competing methods."
    },
    {
        "title": "LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture",
        "link_suffix": "/forum?id=wqA7QmpUwa",
        "link": "https://openreview.net/forum?id=wqA7QmpUwa",
        "pdf_link": "https://openreview.net/pdf?id=wqA7QmpUwa",
        "keywords": "Efficient Multimodal Large Language Model, Transformer-Mamba Hybrid Architecture",
        "abstract": "Expanding the long-context capabilities of Multi-modal Large Language Models (MLLMs) is crucial for video understanding, high-resolution image understanding, and multi-modal agents. This involves a series of systematic optimizations, including model architecture, data construction and training strategy, particularly addressing challenges such as \\textit{degraded performance with more images} and \\textit{high computational costs}. In this paper, we adapt the model architecture to a hybrid of Mamba and Transformer blocks, approach data construction with both temporal and spatial dependencies among multiple images and employ a progressive training strategy. The released modelLongLLaVA(Long-ContextLargeLanguageandVisionAssistant) is the first hybrid MLLM, which achieved a better balance between efficiency and effectiveness. LongLLaVA  not only achieves competitive results across various benchmarks, but also maintains high throughput and low memory consumption. Especially, it could process nearly a thousand images on a single A100 80GB GPU, showing promising application prospects for a wide range of tasks."
    },
    {
        "title": "Semi-Supervised Vision-Centric 3D Occupancy World Model for Autonomous Driving",
        "link_suffix": "/forum?id=rCX9l4OTCT",
        "link": "https://openreview.net/forum?id=rCX9l4OTCT",
        "pdf_link": "https://openreview.net/pdf?id=rCX9l4OTCT",
        "keywords": "Autonomous Driving; Occupancy; World Model",
        "abstract": "Understanding world dynamics is crucial for planning in autonomous driving. Recent methods attempt to achieve this by learning a 3D occupancy world model that forecasts future surrounding scenes based on current observation. However, 3D occupancy labels are still required to produce promising results. Considering the high annotation cost for 3D outdoor scenes, we propose a semi-supervised vision-centric 3D occupancy world model,PreWorld, to leverage the potential of 2D labels through a novel two-stage training paradigm: the self-supervised pre-training stage and the fully-supervised fine-tuning stage. Specifically, during the pre-training stage, we utilize an attribute projection head to generate different attribute fields of a scene (e.g., RGB, density, semantic), thus enabling temporal supervision from 2D labels via volume rendering techniques. Furthermore, we introduce a simple yet effective state-conditioned forecasting module to recursively forecast future occupancy and ego trajectory in a direct manner. Extensive experiments on the nuScenes dataset validate the effectiveness and scalability of our method, and demonstrate that PreWorld achieves competitive performance across 3D occupancy prediction, 4D occupancy forecasting and motion planning tasks."
    },
    {
        "title": "Dual Flows with Contrastive Guidance for Generating Highly Designable Proteins",
        "link_suffix": "/forum?id=hiciJQdmpw",
        "link": "https://openreview.net/forum?id=hiciJQdmpw",
        "pdf_link": "https://openreview.net/pdf?id=hiciJQdmpw",
        "keywords": "guided sampling, flow matching, protein design",
        "abstract": "Deep generative models have achieved substantial success in protein design. A prevalent approach for de novo protein design involves initially designing a protein backbone structure using deep generative models, such as diffusion and flow models, followed by using a separate inverse folding model to design the correponding sequence. Recently, co-design methods, which aim to jointly generate the structure and sequence of a protein, have attracted considerable attention. Despite this, co-designing sequences and structures of long proteins remains challenging. The complexity of this high-dimensional multimodal generative modeling makes sampling of diffusion and flow models prone to accumulated errors, often leading to non-designable regions. To tackle this challenge, we introduce a contrastive guided sampling algorithm with dual multimodal flows to sample both sequences and structures of highly designable proteins. The contrastive guidance uses the lower-quality flow to help the higher-quality flow avoid non-designable regions by gently steering it during sampling. Our method achieves designability of 80% for length-400 proteins and 37% for length-500 proteins, significantly outperforming previous approaches."
    },
    {
        "title": "VisScience: An Extensive Benchmark for Evaluating K12 Educational Multi-modal Scientific Reasoning",
        "link_suffix": "/forum?id=wgKW4U7ktq",
        "link": "https://openreview.net/forum?id=wgKW4U7ktq",
        "pdf_link": "https://openreview.net/pdf?id=wgKW4U7ktq",
        "keywords": "Multi-modal Large Language Model, Scientific Reasoning, Benchmark",
        "abstract": "Multi-modal large language models (MLLMs) have shown promise in integrating textual and visual information to handle complex visual understanding tasks. However, most benchmarks evaluating MLLMs focus mainly on mathematics or general visual understanding, revealing a significant gap in assessing capabilities across other critical scientific disciplines like physics and chemistry. To bridge this gap, we meticulously construct a comprehensive benchmark, \\textbf{VisScience}, to evaluate multi-modal scientific reasoning across mathematics, physics, and chemistry. This benchmark comprises 3,000 questions drawn from K12 education,  from elementary to high school levels, evenly distributed with 1,000 questions per discipline. VisScience encompasses 21 distinct subjects, classified into five difficulty levels to cover a wide range of topics within each discipline. We utilize VisScience to conduct a detailed evaluation of 25 representative MLLMs in scientific reasoning. The experimental results show that closed-source MLLMs generally surpass open-source models, with standout performances including a 53.4% accuracy in mathematics by Claude3.5-Sonnet, 38.2% in physics by GPT-4o, and 47.0% in chemistry by Gemini-1.5-Pro. These results underscore the strengths and limitations of MLLMs, suggesting areas for future improvement and highlighting the importance of developing models that can effectively handle the diverse demands of multi-modal scientific reasoning."
    },
    {
        "title": "Rethinking Pre-Training in Tabular Data:  A Neighborhood Embedding Perspective",
        "link_suffix": "/forum?id=a06UO11IrQ",
        "link": "https://openreview.net/forum?id=a06UO11IrQ",
        "pdf_link": "https://openreview.net/pdf?id=a06UO11IrQ",
        "keywords": "tabular data, tabular data pretraining, tabular machine learning",
        "abstract": "Pre-training is prevalent in deep learning for vision and text data, acquiring knowledge from other datasets to improve the downstream tasks. However, when it comes to tabular data, the inherent heterogeneity in the attribute and label spaces among datasets makes it hard to learn shareable knowledge and encode it in a model. We proposeTabular dataPre-Training viaMeta-representation (TabPTM), aiming to pre-train a general tabular model over a set of heterogeneous datasets. The key is to embed data instances from any dataset into a common feature space, in which an instance is represented by its distance to a fixed number of nearest neighbors and their labels. Such a meta-representation standardizes heterogeneous tasks into homogeneous local prediction problems, enabling training a model to infer the label (or the score to each possible label) of an input instance based on its neighborhood information. As such, the pre-trained TabPTM can be directly applied to new datasets without further fine-tuning, regardless of their diverse attributes and labels. Extensive experiments on 72 tabular datasets validate TabPTM's effectiveness (with and without fine-tuning) in both tabular classification and regression tasks."
    },
    {
        "title": "M2Edit: Locate and Edit Multi-Granularity Knowledge in Multimodal Large Language Model",
        "link_suffix": "/forum?id=8tlsJB28c9",
        "link": "https://openreview.net/forum?id=8tlsJB28c9",
        "pdf_link": "https://openreview.net/pdf?id=8tlsJB28c9",
        "keywords": "Multimodal knowledge editing; Multi-Granularity Knowledge; M2Edit; Multimodal Large Language Model;",
        "abstract": "Multimodal knowledge editing is an important method for modifying outdated or incorrect knowledge in Multimodal Large Language Models (MLLMs). However, existing datasets for multimodal knowledge editing lack multi-granularity knowledge. In this paper, we present a more realistic dataset called M2Edit, which includes three distinct types of knowledge: entity, relation, and action. Additionally, existing knowledge editing methods for MLLMs lack the ability to handle multi-granularity knowledge and generalize to multimodal data. To address these limitations, we propose the multimodal knowledge editing method MLE. This approach identifies key knowledge layers within different components and collaboratively edits the various components of MLLMs. As a result, we observe significant improvements in visual generality performance, ranging from 4.8 to 10.8, and achieve the best overall performance on knowledge data of different granularities."
    },
    {
        "title": "Reinforcement learning on structure-conditioned categorical diffusion for protein inverse folding",
        "link_suffix": "/forum?id=OlytBskWjc",
        "link": "https://openreview.net/forum?id=OlytBskWjc",
        "pdf_link": "https://openreview.net/pdf?id=OlytBskWjc",
        "keywords": "Protein Inverse Folding, Diffusion, Reinforcement Learning",
        "abstract": "Protein inverse folding\u2014that is, predicting an amino acid sequence that will fold into the desired 3D structure\u2014is an important problem for structure-based protein design. Machine learning based methods for inverse folding typically use recovery of the original sequence as the optimization objective. However, inverse folding is a one-to-many problem where several sequences can fold to the same structure. Moreover, for many practical applications, it is often desirable to have multiple, diverse sequences that fold into the target structure since it allows for more candidate sequences for downstream optimizations. Here, we demonstrate that although recent inverse folding methods show increased sequence recovery, their \u201cfoldable diversity\u201d\u2014i.e. their ability to generate multiple non-similar sequences that fold into the structures consistent with the target\u2014does not increase. To address this, we present RL-DIF, a categorical diffusion model for inverse folding that is pre-trained on sequence recovery and tuned via reinforcement learning on structural consistency. We find that RL-DIF achieves comparable sequence recovery and structural consistency to benchmark models but shows greater foldable diversity: experiments show RL-DIF can achieve an foldable diversity of 29% on CATH 4.2, compared to 23% from models trained on the same dataset. The PyTorch model weights and sampling code are available on GitHub."
    },
    {
        "title": "Applying Sparse Autoencoders to Unlearn Knowledge in Language Models",
        "link_suffix": "/forum?id=ZtvRqm6oBu",
        "link": "https://openreview.net/forum?id=ZtvRqm6oBu",
        "pdf_link": "https://openreview.net/pdf?id=ZtvRqm6oBu",
        "keywords": "mechanistic interpretability, unlearning, ai safety, interpretability",
        "abstract": "We investigate whether sparse autoencoders (SAEs) can be used to remove knowledge from language models. We use the biology subset of the Weapons of Mass Destruction Proxy dataset and test on the gemma-2b-it and gemma-2-2b-it language models. We demonstrate that individual interpretable biology-related SAE features can be used to unlearn biology-related knowledge with minimal side-effects.\nOur results suggest that negative scaling of feature activations is necessary and that zero ablating features is ineffective. We find that intervening using multiple SAE features simultaneously can unlearn multiple different topics, but with similar or larger unwanted side-effects than the existing Representation Misdirection for Unlearning technique. Current SAE quality or intervention techniques would need to improve to make SAE-based unlearning comparable to the existing fine-tuning based techniques."
    },
    {
        "title": "Critical Phase Transition in Large Language Models",
        "link_suffix": "/forum?id=pf9J3GNxSe",
        "link": "https://openreview.net/forum?id=pf9J3GNxSe",
        "pdf_link": "https://openreview.net/pdf?id=pf9J3GNxSe",
        "keywords": "natural language processing, large language models, statistical physics, phase transitions, critical phenomena, large-scale numerical experiments",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance. To understand their behaviors, we need to consider the fact that LLMs sometimes show qualitative changes. The natural world also presents such changes called phase transitions, which are defined by singular, divergent statistical quantities. Therefore, an intriguing question is whether qualitative changes in LLMs are phase transitions. In this work, we have conducted extensive analysis on texts generated by LLMs and suggested that a phase transition occurs in LLMs when varying the temperature parameter. Specifically, statistical quantities have divergent properties just at the point between the low-temperature regime, where LLMs generate sentences with clear repetitive structures, and the high-temperature regime, where generated sentences are often incomprehensible. In addition, critical behaviors near the phase transition point, such as a power-law decay of correlation and slow convergence toward the stationary state, are similar to those in natural languages. Our results suggest a meaningful analogy between LLMs and natural phenomena."
    },
    {
        "title": "Efficient Interpolation between Extragradient and Proximal Methods for Weak MVIs",
        "link_suffix": "/forum?id=Y7slJZPGCy",
        "link": "https://openreview.net/forum?id=Y7slJZPGCy",
        "pdf_link": "https://openreview.net/pdf?id=Y7slJZPGCy",
        "keywords": "Weak Minty variational inequalities, cohypomonotone, nonmonotone, first-order methods, extragradient method, proximal point algorithm",
        "abstract": "We study nonmonotone games satisfying the weak Minty variational inequality (MVI) with parameter $\\rho \\in (-\\tfrac{1}{L}, \\infty)$, where $L$ is the Lipschitz constant of the gradient operator. An error corrected version of the inexact proximal point algorithm is proposed, with which we establish the first $\\mathcal O(1/\\epsilon)$ rate for the entire range $\\rho \\in (-\\tfrac{1}{L}, \\infty)$, thus removing a logarithmic factor compared with the complexity of existing methods. The scheme automatically selects the needed accuracy for the proximal computation, and can recover the relaxed extragradient method when $\\rho > -\\tfrac{1}{2L}$ and the relaxed proximal point algorithm (rPPA) when $\\rho > -\\tfrac{1}{L}$. Due to the error correction, the scheme inherits the strong properties of theexactrPPA. Specifically, we show that linear convergence is automatically achieved under appropriate conditions. Tightness for the range of $\\rho$ is established through a lower bound for rPPA. Central to the algorithmic construction is a halfspace projection, where the key insight is that the allowed error tolerance can both be used to correct for the proximal approximation and to enlarge the problem class."
    },
    {
        "title": "CardiCat: a Variational Autoencoder for High-Cardinality Tabular Data",
        "link_suffix": "/forum?id=vW6rsXAGrz",
        "link": "https://openreview.net/forum?id=vW6rsXAGrz",
        "pdf_link": "https://openreview.net/pdf?id=vW6rsXAGrz",
        "keywords": "embedding, VAE, tabular, regularization, high-cardinality, categorical, imbalance, mixed, heterogeneous, layers, Generative, model",
        "abstract": "High-cardinality categorical features are a common characteristic of mixed-type tabular datasets. Existing generative model architectures struggle to learn the complexities of such data at scale, primarily due to the difficulty of parameterizing the categorical features. In this paper, we present a general variational autoencoder model, CardiCat, that can accurately fit imbalanced high-cardinality and heterogeneous tabular data. Our method substitutes one-hot encoding with regularized dual encoder-decoder embedding layers, which are jointly learned. This approach enables us to use embeddings that depend also on the other covariates, leading to a compact and homogenized parameterization of categorical features. Our model employs a considerably smaller trainable parameter space than competing methods, enabling learning at a large scale. CardiCat generates high-quality synthetic data that better represent high-cardinality and imbalanced features compared to competing VAE models for multiple real and simulated datasets."
    },
    {
        "title": "Semantic-Aware Diffusion Model for Sequential Recommendation",
        "link_suffix": "/forum?id=2E6OK8cSoB",
        "link": "https://openreview.net/forum?id=2E6OK8cSoB",
        "pdf_link": "https://openreview.net/pdf?id=2E6OK8cSoB",
        "keywords": "Diffusion Model, Sequential Recommendation",
        "abstract": "Sequential recommendation aims to predict the next click for a particular user based on their historical interacted item sequences. Recently, diffusion-based methods have achieved the state-of-the-art performance in sequential recommendation. However, they fail to effectively utilize the rich semantic information embedded in items during the diffusion process to accurately guide the generation, leading to sub-optimal results. To address this limitation, we designed SDRec, aSemantic-awareDiffusion model for sequentialRecommendation. Our model introduces a novel architecture, the Semantic Fusion Layer, which leverages the embedding table from the encoder to incorporate item semantics into the diffusion process through an attention mechanism. Together with the well-designed contrastive and generative losses, SDRec effectively utilizes the item semantics in diffusion model, unleashing the potential of sequential recommendation. Our experiments show that SDRec has over 10% relative gain with superior efficiency compared with existing methods."
    },
    {
        "title": "Neural Topic Modeling with Large Language Models in the Loop",
        "link_suffix": "/forum?id=c3rfGbXMBE",
        "link": "https://openreview.net/forum?id=c3rfGbXMBE",
        "pdf_link": "https://openreview.net/pdf?id=c3rfGbXMBE",
        "keywords": "Neural Topic Model, Topic Model, Large Language Model, Optimal Transport",
        "abstract": "Topic modeling is a fundamental task in natural language processing, allowing the discovery of latent thematic structures in text corpora. While Large Language Models (LLMs) have demonstrated promising capabilities in topic discovery, their direct application to topic modeling suffers from issues such as incomplete topic coverage, misalignment of topics, and inefficiency. To address these limitations, we propose LLM-ITL, a novel LLM-in-the-loop framework that integrates LLMs with many existing Neural Topic Models (NTMs). In LLM-ITL, global topics and document representations are learned through the NTM, while an LLM refines the topics via a confidence-weighted Optimal Transport (OT)-based alignment objective. This process enhances the interpretability and coherence of the learned topics, while maintaining the efficiency of NTMs. Extensive experiments demonstrate that LLM-ITL can help NTMs significantly improve their topic interpretability while maintaining the quality of document representation."
    },
    {
        "title": "Generalization Performance Gap Analysis between Centralized and Federated Learning: How to Bridge this Gap?",
        "link_suffix": "/forum?id=WM4xiEDz2N",
        "link": "https://openreview.net/forum?id=WM4xiEDz2N",
        "pdf_link": "https://openreview.net/pdf?id=WM4xiEDz2N",
        "keywords": "Federated Learning, Generalization Performance, Centralized Training, Theoretical Analysis",
        "abstract": "The rising interest in decentralized data and privacy protection has led to the emergence of Federated Learning. Many studies have compared federated training with classical training approaches using centralized data and found from experiments that models trained in a federated setup with equal resources perform poorly on tasks. However, these studies have generally been empirical and have not explored the performance gap further from a theoretical perspective. The lack of theoretical understanding prevents figuring out whether federated algorithms are necessarily inferior to centralized algorithms in performance and how large this gap is according to the training settings. Also, it hinders identifying valid ways to close this performance distance. This paper fills this theoretical gap by formulating federated training as an SGD (Stochastic Gradient Descent) optimization problem over decentralized data and defining the performance gap within the PAC-Bayes (Probably Approximately Correct Bayesian) framework. Through theoretical analysis, we derive non-vacuous bounds on this performance gap, revealing that the difference in generalization performance necessarily exists when training resources are equal for both training setups and that variations in the training parameters affect the gap. Moreover, we also prove that the complete elimination of the performance gap is only possible by introducing new clients or adding new data to existing clients. Advantages in other training resources are not feasible for closing the gap, such as giving larger models or more communication rounds to federated scenarios. Our theoretical findings are validated by extensive experimental results from different model architectures and datasets."
    },
    {
        "title": "The Turing Game",
        "link_suffix": "/forum?id=VgmvKk7yfE",
        "link": "https://openreview.net/forum?id=VgmvKk7yfE",
        "pdf_link": "https://openreview.net/pdf?id=VgmvKk7yfE",
        "keywords": "Turing Test, LLMs, Chatbots, Testing, Human-Ai Interface",
        "abstract": "We present first experimental results from the \\textit{Turing Game}, a modern implementation of the original imitation game as proposed by Alan Turing in 1950. The Turing Game is a gamified interaction between two human players and one AI chatbot powered by state-of-the-art Large Language Models (LLMs). The game is designed to explore whether humans can distinguish between their peers and machines in chat-based conversations, with human players striving to identify fellow humans and machines striving to blend in as one of them. To this end, we implemented a comprehensive framework that connects human players over the Internet with chatbot implementations. We detail the experimental results after a public launch at the Ars Electronica Festival in September 2024. While the experiment is still ongoing, in this paper we present our initial findings from the hitherto gathered data.\nOur long term vision of the project is to deepen the understanding of human-AI interactions and eventually contribute to improving LLMs and language-based user interfaces."
    },
    {
        "title": "Drawing the Line: Enhancing  Trustworthiness of MLLMs Through the Power of Refusal",
        "link_suffix": "/forum?id=C4q5R6XbJ6",
        "link": "https://openreview.net/forum?id=C4q5R6XbJ6",
        "pdf_link": "https://openreview.net/pdf?id=C4q5R6XbJ6",
        "keywords": "Trustworthiness, Alignment, MLLMs",
        "abstract": "Multimodal large language models (MLLMs) excel at multimodal perception and understanding, yet their tendency to generate hallucinated or inaccurate responses undermines their trustworthiness. Existing methods have largely overlooked the importance of refusal responses as a means of enhancing MLLMs reliability. To bridge this gap, we present the Information Boundary-aware Learning Framework (InBoL), a novel approach that empowers MLLMs to refuse to answer user queries when encountering insufficient information. To the best of our knowledge, InBoL is the first framework that systematically defines the conditions under which refusal is appropriate for MLLMs using the concept of information boundaries proposed in our paper. This framework introduces a comprehensive data generation pipeline and tailored training strategies to improve the model\u2019s ability to deliver appropriate refusal responses. To evaluate the trustworthiness of MLLMs, we further propose a user-centric alignment goal along with corresponding metrics. Experimental results demonstrate a significant improvement in refusal accuracy without noticeably compromising the model\u2019s helpfulness, establishing InBoL as a pivotal advancement in building more trustworthy MLLMs."
    },
    {
        "title": "Salvador Urban Network Transportation (SUNT): A Landmark Spatiotemporal Dataset for Public Transportation",
        "link_suffix": "/forum?id=aOiKt5b0NA",
        "link": "https://openreview.net/forum?id=aOiKt5b0NA",
        "pdf_link": "https://openreview.net/pdf?id=aOiKt5b0NA",
        "keywords": "Graph Neural Network, Time Series, Spatial Dataset, Public Transportation, Urban Mobility",
        "abstract": "Efficient public transportation management is essential for the development of large urban centers, providing several benefits such as comprehensive coverage of population mobility, improvement of the local economy with the offer of new jobs and the decrease of transport costs, better control of traffic congestion, and significant reduction of environmental impact limiting gas emissions and pollution. Realizing these benefits requires carefully pursuing two essential pathways: (i) deeply understanding the population and transit patterns and (ii) using intelligent approaches to model multiple relations and characteristics efficiently. This work addresses these challenges by providing a novel dataset that includes various public transportation components alongside machine learning models trained to understand and predict different real-world behaviors. Our dataset comprises daily information from about 710,000 passengers in Salvador, one of Brazil's largest cities, and local public transportation data with approximately 2,000 vehicles operating across nearly 400 lines, connecting almost 3,000 stops and stations. As benchmarks, we have fine-tuned diverse Graph Neural Networks to perform inference on vertices and edges, undertaking both regression and classification tasks. These models leverage temporal and spatial features concerning passengers and transportation data. We emphasize the greatest advantage of using our dataset lies in different possibilities of modeling a real-world urban mobility dataset, reproducing our results, overcoming our models, and investigating several other open-problem situations listed in this manuscript as future work, which include the designing of new methods, optimization strategies, and environmental approaches. Our dataset, codes, and models are available athttps://github.com/suntdataset/sunt.git."
    },
    {
        "title": "Scalable Multi-phase Word Embedding Using Conjunctive Propositional Clauses",
        "link_suffix": "/forum?id=ZOrqCRDKh6",
        "link": "https://openreview.net/forum?id=ZOrqCRDKh6",
        "pdf_link": "https://openreview.net/pdf?id=ZOrqCRDKh6",
        "keywords": "Tsetlin Machine, Word Embeddings, Natural Language Processing (NLP)",
        "abstract": "The Tsetlin Machine (TM) architecture has recently demonstrated effectiveness in Machine Learning (ML), particularly within Natural Language Processing (NLP). It has been utilized to construct word embedding using conjunctive propositional clauses, thereby significantly enhancing our understanding and interpretation of machine-derived decisions. The previous approach performed the word embedding over a sequence of input words to consolidate the information into a cohesive and unified representation. However, that approach encounters scalability challenges as the input size increases. In this study, we introduce a novel approach incorporating two-phase training to discover contextual embeddings of input sequences. Specifically, this method encapsulates the knowledge for each input word within the dataset\u2019s vocabulary, subsequently constructing embeddings for a sequence of input words utilizing the extracted knowledge. This technique not only facilitates the design of a scalable model but also preserves interpretability. Our experimental findings revealed that the proposed method yields competitive performance compared to the previous approaches, demonstrating promising results in contrast to human-generated benchmarks. Furthermore, we applied the proposed approach to sentiment analysis on the IMDB dataset, where the TM embedding and the TM classifier, along with other interpretable classifiers, offered a transparent end-to-end solution with competitive performance."
    },
    {
        "title": "Generative Flows on Synthetic Pathway for Drug Design",
        "link_suffix": "/forum?id=pB1XSj2y4X",
        "link": "https://openreview.net/forum?id=pB1XSj2y4X",
        "pdf_link": "https://openreview.net/pdf?id=pB1XSj2y4X",
        "keywords": "GFlowNet, synthesizability, structure-based drug design, molecule optimization",
        "abstract": "Generative models in drug discovery have recently gained attention as efficient alternatives to brute-force virtual screening. However, most existing models do not account for synthesizability, limiting their practical use in real-world scenarios. In this paper, we propose RxnFlow, which sequentially assembles molecules using predefined molecular building blocks and chemical reaction templates to constrain the synthetic chemical pathway. We then train on this sequential generating process with the objective of generative flow networks (GFlowNets) to generate both highly rewarded and diverse molecules. To mitigate the large action space of synthetic pathways in GFlowNets, we implement a novel action space subsampling method. This enables RxnFlow to learn generative flows over extensive action spaces comprising combinations of 1.2 million building blocks and 71 reaction templates without significant computational overhead. Additionally, RxnFlow can employ modified or expanded action spaces for generation without retraining, allowing for the introduction of additional objectives or the incorporation of newly discovered building blocks. We experimentally demonstrate that RxnFlow outperforms existing reaction-based and fragment-based models in pocket-specific optimization across various target pockets. Furthermore, RxnFlow achieves state-of-the-art performance on CrossDocked2020 for pocket-conditional generation, with an average Vina score of \u20138.85 kcal/mol and 34.8% synthesizability."
    },
    {
        "title": "Integrating Protein Dynamics into Structure-Based Drug Design via Full-Atom Stochastic Flows",
        "link_suffix": "/forum?id=9qS3HzSDNv",
        "link": "https://openreview.net/forum?id=9qS3HzSDNv",
        "pdf_link": "https://openreview.net/pdf?id=9qS3HzSDNv",
        "keywords": "flow matching, structure-based drug design, protein dynamics",
        "abstract": "The dynamic nature of proteins, influenced by ligand interactions, is essential for comprehending protein function and progressing drug discovery. Traditional structure-based drug design (SBDD) approaches typically target binding sites with rigid structures, limiting their practical application in drug development. While molecular dynamics simulation can theoretically capture all the biologically relevant conformations, the transition rate is dictated by the intrinsic energy barrier between them, making the sampling process computationally expensive. To overcome the aforementioned challenges, we propose to use generative modeling for SBDD considering conformational changes of protein pockets. We curate a dataset of apo and multiple holo states of protein-ligand complexes, simulated by molecular dynamics, and propose a full-atom flow model (and a stochastic version), named DynamicFlow, that learns to transform apo pockets and noisy ligands into holo pockets and corresponding 3D ligand molecules. Our method uncovers promising ligand molecules and corresponding holo conformations of pockets. Additionally, the resultant holo-like states provide superior inputs for traditional SBDD approaches, playing a significant role in practical drug discovery."
    },
    {
        "title": "InstantSplamp: Fast and Generalizable Stenography Framework for Generative Gaussian Splatting",
        "link_suffix": "/forum?id=xvhV3LvYTc",
        "link": "https://openreview.net/forum?id=xvhV3LvYTc",
        "pdf_link": "https://openreview.net/pdf?id=xvhV3LvYTc",
        "keywords": "Gaussian Splatting, 3D Generation, IP Verfication",
        "abstract": "With the rapid development of large generative models for 3D, especially the evolution from NeRF representations to more efficient Gaussian Splatting, the synthesis of 3D assets has become increasingly fast and efficient, enabling the large-scale publication and sharing of generated 3D objects. However, while existing methods can add watermarks or steganographic information to individual 3D assets, they often require time-consuming per-scene training and optimization, leading to watermarking overheads that can far exceed the time required for asset generation itself, making deployment impractical for generating large collections of 3D objects. To address this, we propose InstantSplamp a framework that seamlessly integrates the 3D steganography pipeline into large 3D generative models without introducing explicit additional time costs. Guided by visual foundation models,InstantSplamp subtly injects hidden information like copyright tags during asset generation, enabling effective embedding and recovery of watermarks within generated 3D assets while preserving original visual quality. Experiments across various potential deployment scenarios demonstrate that \\model~strikes an optimal balance between rendering quality and hiding fidelity, as well as between hiding performance and speed. Compared to existing per-scene optimization techniques for 3D assets, InstantSplamp reduces their watermarking training overheads that are multiples of generation time to nearly zero, paving the way for real-world deployment at scale."
    },
    {
        "title": "ALPBench: A Benchmark for Active Learning Pipelines on Tabular Data",
        "link_suffix": "/forum?id=QzR7Jfe8Tz",
        "link": "https://openreview.net/forum?id=QzR7Jfe8Tz",
        "pdf_link": "https://openreview.net/pdf?id=QzR7Jfe8Tz",
        "keywords": "Active Learning, Benchmark, Tabular Data, Software Library",
        "abstract": "In settings where only a budgeted amount of labeled data can be afforded, active learning seeks to devise query strategies for selecting the most informative data points to be labeled, aiming to enhance learning algorithms' efficiency and performance. Numerous such query strategies have been proposed and compared in the active learning literature. However, the community still lacks standardized benchmarks for comparing the performance of different query strategies. This particularly holds for the combination of query strategies with different learning algorithms into active learning pipelines and examining the impact of the learning algorithm choice. To close this gap, we propose ALPBench, which facilitates the specification, execution, and performance monitoring of active learning pipelines. It has built-in measures to ensure evaluations are done reproducibly, saving exact dataset splits and hyperparameter settings of used algorithms. In total, ALPBench consists of 86 real-world tabular classification datasets and 5 active learning settings, yielding 430 active learning problems. To demonstrate its usefulness and broad compatibility with various learning algorithms and query strategies, we conduct an exemplary study evaluating 9 query strategies paired with 8 learning algorithms in 2 different settings."
    }
]
[{"title": "From Isolated Conversations to Hierachical Schemas: Dynamic Tree Memory Representation for LLMs", "link_suffix": "/forum?id=moXtEmCleY", "link": "https://openreview.net/forum?id=moXtEmCleY", "pdf_link": "https://openreview.net/pdf?id=moXtEmCleY", "keywords": "Tree-based Memory, Inference-time Reasoning, Large language models, Long-term memory", "abstract": "Recent advancements in large language models have significantly improved their context windows, yet challenges in effective long-term memory management remain. We introduce MemTree, an algorithm that leverages a dynamic, tree-structured memory representation to optimize the organization, retrieval, and integration of information, akin to human cognitive schemas. MemTree organizes memory hierarchically, with each node encapsulating aggregated textual content, corresponding semantic embeddings, and varying abstraction levels across the tree's depths. Our algorithm dynamically adapts this memory structure by computing and comparing semantic embeddings of new and existing information to enrich the model\u2019s context-awareness. This approach allows MemTree to handle complex reasoning and extended interactions more effectively than traditional memory augmentation methods, which often rely on flat lookup tables. Evaluations on benchmarks for multi-turn dialogue understanding and document question answering show that MemTree significantly enhances performance in scenarios that demand structured memory management.", "title_embedding_index": 18150, "title_abs_embedding_index": 18175}, {"title": "Visually Descriptive Language Model for Vector Graphics Reasoning", "link_suffix": "/forum?id=ubIxE93FLM", "link": "https://openreview.net/forum?id=ubIxE93FLM", "pdf_link": "https://openreview.net/pdf?id=ubIxE93FLM", "keywords": "Large Multimodal Model, Large Language Model, Vector Graphics, Low-level Perception, Low-level Visual Reasoning", "abstract": "Despite significant advancements, current large multimodal models (LMMs) struggle to bridge the gap between low-level visual perception\u2014focusing on shapes, sizes and layouts\u2014and high-level language reasoning involving semantics, events and logic. This limitation becomes evident in tasks requiring precise visual perception, such as comparing geometric properties or solving visual algorithmic reasoning problems. To study this failure mode, we focus on an important visual domain: vector graphics\u2014images composed purely of 2D objects and shapes, which are prevalent in various LMM-based agent tasks in web, visual design, and OS environments. We identify two key research questions: how can we enable precise visual perception, and how can we facilitate high-level reasoning based on such low-level perceptions? To accurately capture low-level visual details, we utilize Scalable Vector Graphics (SVG) for precise encoding of visual scenes. However, SVGs are not readily interpretable by LLMs or LMMs in a zero-shot manner. To address this challenge, we propose the Visually Descriptive Language Model (VDLM), which introduces an intermediate textual representation called Primal Visual Description (PVD). PVD translates SVGs into a text-based abstraction comprising primitive attributes (e.g., shape, position, measurement) along with their corresponding values. PVD can be learned with task-agnostic synthesized data and represents visual primitives that are universal across various vector graphics. This abstraction is more structured, allowing for direct interpretation by foundation models for zero-shot generalization to different reasoning tasks. Without any human-annotated data, empirical results demonstrate that VDLM leads to significant improvements in state-of-the-art LMMs, such as GPT-4o, across various low-level multimodal perception and reasoning tasks on vector graphics. Additionally, we provide extensive analyses of VDLM\u2019s performance, showing that our framework offers improved interpretability due to its disentangled perception and reasoning processes. Finally, we demonstrate the promise of this representation by showing a positive correlation between the quality of the PVD perception and the end-task performance.", "title_embedding_index": 18151, "title_abs_embedding_index": 18176}, {"title": "LLMs Synergy : From Closed-Source Prototyping to  Open-Source Model  based  Instruction Following", "link_suffix": "/forum?id=P0eEalHM5h", "link": "https://openreview.net/forum?id=P0eEalHM5h", "pdf_link": "https://openreview.net/pdf?id=P0eEalHM5h", "keywords": "LLM, instruction following, domain adaptation", "abstract": "We study the problem of constructing an efficient LLM-based instruction-following agent capable of comprehending and executing open-ended instructions in an embodied environment. We propose a method called LLMs Synergy for rapid domain adaptation in the instruction-following task without requiring additional manual annotations. This approach leverages a large general-purpose LLM to establish task baselines and generate domain-specific data. The knowledge from the larger model is then gradually transferred to a domain-tuned open-source LLM through a model transition process, enabling faster and more efficient adaptation. Accordingly, we developed the Dynamic Instruction Decomposition (DID) framework, specifically designed for LLM integration within this task scenario. The DID framework  enables the agent to progressively align open-ended natural language commands with dynamic environmental contexts. Experimental results demonstrate significant improvements in task accuracy, leading to more effective instruction following and enhanced human-agent collaboration.", "title_embedding_index": 18152, "title_abs_embedding_index": 18177}, {"title": "AstroCompress: A benchmark dataset for multi-purpose compression of astronomical data", "link_suffix": "/forum?id=kQCHCkNk7s", "link": "https://openreview.net/forum?id=kQCHCkNk7s", "pdf_link": "https://openreview.net/pdf?id=kQCHCkNk7s", "keywords": "astronomy, physics, astrophysics, compression, neural compression, computer vision, remote sensing", "abstract": "The site conditions that make astronomical observatories in space and on the ground so desirable---cold and dark---demand a physical remoteness that leads to limited data transmission capabilities. Such transmission limitations directly bottleneck the amount of data acquired and in an era of costly modern observatories, any improvements in lossless data compression has the potential scale to billions of dollars worth of additional science that can be accomplished on the same instrument. Traditional lossless methods for compressing astrophysical data are manually designed. Neural data compression, on the other hand, holds the promise of learning compression algorithms end-to-end from data and outperforming classical techniques by leveraging the unique spatial, temporal, and wavelength structures of astronomical images. This paper introducesAstroCompress: a neural compression challenge for astrophysics data, featuring four new datasets (and one legacy dataset) with 16-bit unsigned integer imaging data in various modes: space-based, ground-based, multi-wavelength, and time-series imaging. We provide code to easily access the data and benchmark seven lossless compression methods  (three neural and four non-neural, including all practical state-of-the-art algorithms).\nOur results on lossless compression indicate that lossless neural compression techniques can enhance data collection at observatories, and provide guidance on the adoption of neural compression in scientific applications. Though the scope of this paper is restricted to lossless compression, we also comment on the potential exploration of lossy compression methods in future studies.", "title_embedding_index": 18153, "title_abs_embedding_index": 18178}, {"title": "CURIE: Evaluating LLMs on Multitask Scientific Long-Context Understanding and Reasoning", "link_suffix": "/forum?id=jw2fC6REUB", "link": "https://openreview.net/forum?id=jw2fC6REUB", "pdf_link": "https://openreview.net/pdf?id=jw2fC6REUB", "keywords": "science, LLMs, evaluation, benchmark, long-context", "abstract": "Scientific problem-solving involves synthesizing information while applying expert  knowledge.   We  introduce  CURIE,  a  scientific  long-Context  Understanding, Reasoning, and Information Extraction benchmark to measure the potential of Large Language Models (LLMs) in scientific problem-solving and assisting scientists in realistic workflows. This benchmark introduces ten challenging tasks curated by experts in six disciplines - materials science, condensed matter physics, quantum computing, geo-spatial analysis, biodiversity, and proteins - covering both experimental and theoretical work-flows in science. We evaluate a range of closed and open LLMs on tasks in CURIE which requires domain expertise, comprehension of long in-context information,and multi-step reasoning.  While Claude-3 shows consistent high comprehension across domains, the popular GPT-4o and command-R+ fail dramatically on protein sequencing tasks. Overall there is much room for improvement for all models. We hope that insights gained from CURIE can guide the future development of LLMs in sciences.", "title_embedding_index": 18154, "title_abs_embedding_index": 18179}, {"title": "Towards Accurate Validation in Deep Clustering through Unified Embedding Learning", "link_suffix": "/forum?id=vgMAtJONKX", "link": "https://openreview.net/forum?id=vgMAtJONKX", "pdf_link": "https://openreview.net/pdf?id=vgMAtJONKX", "keywords": "Internal validation measures, Deep clustering, Clustering evaluation, Unified embedding learning", "abstract": "Deep clustering integrates deep neural networks into the clustering process, simultaneously learning embedding spaces and cluster assignments. However, significant challenges remain in evaluating and comparing the performance of different deep clustering algorithms\u2014or even different training runs of the same algorithm. First, evaluating the clustering results from different models in the same high-dimensional input space is impractical due to the curse of dimensionality. Second, comparing the clustering results of different models in their respective learned embedding spaces introduces discrepancies, as existing validation measures are designed for comparisons within the same feature space. To address these issues, we propose a novel evaluation framework that learns a unified embedding space. This approach aligns different embedding spaces into a common space, enabling accurate comparison of clustering results across different models and training runs. Extensive experiments demonstrate the effectiveness of our framework, showing improved consistency and reliability in evaluating deep clustering performance.", "title_embedding_index": 18155, "title_abs_embedding_index": 18180}, {"title": "Symmetry-Driven Discovery of Dynamical Variables in Molecular Simulations", "link_suffix": "/forum?id=e4PL5zssJ9", "link": "https://openreview.net/forum?id=e4PL5zssJ9", "pdf_link": "https://openreview.net/pdf?id=e4PL5zssJ9", "keywords": "AI4Science, Molecular Dynamics, Second Order Methods, Symmetry Discovery", "abstract": "Molecular dynamics simulations are crucial for understanding complex biomolecular systems, but they are often hindered by the high dimensionality of the configurational space. This paper introduces two novel approaches for discovering effective degrees of freedom (DoF) in molecular dynamics simulations by leveraging approximate symmetries of the energy landscape. We present a scalable symmetry loss function compatible with existing force-field frameworks and a Hessian-based method efficient for smaller systems. Both approaches enable systematic exploration of conformational space by connecting structural dynamics to energy landscape symmetries. Applied to alanine dipeptide, our methods comprehensively sample the Ramachandran plot, including shallow minima. Simulations initiated from our DoF-sampled points converge to all important conformations, demonstrating the methods\u2019 effectiveness in navigating complex energy landscapes. These approaches offer powerful tools for efficient exploration in molecular simulations, with potential applications in protein folding and drug discovery.", "title_embedding_index": 18156, "title_abs_embedding_index": 18181}, {"title": "Improved Approximation Algorithms fork-Submodular Maximization via Multilinear Extension", "link_suffix": "/forum?id=EPHsIa0Ytg", "link": "https://openreview.net/forum?id=EPHsIa0Ytg", "pdf_link": "https://openreview.net/pdf?id=EPHsIa0Ytg", "keywords": "$k$-submodular maximization, approximation algorithm, $k$-multilinear extension", "abstract": "We investigate a generalized form of submodular maximization, referred to as $k$-submodular maximization, with applications across the domains of social networks and machine learning. In this work, we propose the multilinear extension of $k$-submodular functions and unified Frank-Wolfe-type frameworks based on that. This continuous framework accommodates 1) monotone or non-monotone functions, and 2) various constraint types including matroid constraints, knapsack constraints, and their combinations. Notably, we attain an asymptotically optimal $1/2$-approximation for monotone $k$-submodular maximization problems with knapsack constraints, surpassing previous $1/3$-approximation results, and a factor-$1/3$ approximation for non-monotone $k$-submodular maximization problems with knapsack constraints and matroid constraints which outperforms previous $0.245$-approximation results. The foundation for our analysis stems from new insights into specific linear and monotone properties pertaining to the multilinear extension.", "title_embedding_index": 18157, "title_abs_embedding_index": 18182}, {"title": "Actions Inspire Every Moment: Online Action-Augmented Dense Video Captioning", "link_suffix": "/forum?id=oO3oXJ19Pb", "link": "https://openreview.net/forum?id=oO3oXJ19Pb", "pdf_link": "https://openreview.net/pdf?id=oO3oXJ19Pb", "keywords": "Dense video captioning, Online dense video captioning", "abstract": "Dense video captioning requires solving the challenging tasks of temporally localizing events and generating descriptive captions within long video sequences. Existing methods often struggle to capture the evolving context within video streams and to produce accurate temporal alignment. To address this, we propose an online retrieval-augmented approach that processes video segments incrementally while dynamically retrieving relevant action phrases from a pre-constructed action-text corpus. This enriches the contextual information for both the video representation and the subsequent text decoder, improving the caption generation. Additionally, we present image-based simulated video pretraining, which mitigates the reliance on extensive video datasets by using image-level text-paired data aligned with the online video captioning format. Our experiments on the ViTT, YouCook2, and ActivityNet benchmarks demonstrate that our model significantly outperforms both existing global and online methods, validating its effectiveness.", "title_embedding_index": 18158, "title_abs_embedding_index": 18183}, {"title": "LUNCH: Adaptive Balancing of Continual Learning via Hyperparameter Uncertainty", "link_suffix": "/forum?id=Q2Q4SyZ2a9", "link": "https://openreview.net/forum?id=Q2Q4SyZ2a9", "pdf_link": "https://openreview.net/pdf?id=Q2Q4SyZ2a9", "keywords": "Life-long Learning; Uncertainty; Hyperparameter Sensitivity", "abstract": "Continual learning (CL) is characterized by learning sequentially arriving tasks and behaving as if they were observed simultaneously. In order to prevent catastrophic forgetting of old tasks when learning new tasks, representative CL methods usually employ additional loss terms to balance their contributions (e.g., regularization and replay), modulated by deterministic hyperparameters. However, this strategy struggles to accommodate real-time changes in data distributions and is also lack of robustness to subsequent unseen tasks, especially in online scenarios where CL is performed with a one-pass data stream. Inspired by adaptive weighting in multi-task learning, we propose an innovative approach named Learning UNCertain Hyperparameters (LUNCH) for adaptive balancing of task contributions in CL. Specifically, we formulate each CL-relevant hyperparameter as a function of optimizable uncertainty under homoscedastic assumption and ensure its training stability through the exponential moving average of network parameters. We further devise an evaluation protocol that moderately adjusts the hyperparameter values and reports their impact on performance, so as to analyze the sensitivity of these sub-optimal values in realistic applications. We perform extensive experiments to demonstrate the effectiveness and robustness of our approach, which significantly improves online CL in a plug-in manner (e.g., up to 11.26% and 5.64% on Split CIFAR-100 and Split Mini-ImageNet, respectively) as well as offline CL.", "title_embedding_index": 18159, "title_abs_embedding_index": 18184}, {"title": "Narrowing the Focus: Learned Optimizers for Pretrained Models", "link_suffix": "/forum?id=DKZjYuB6gc", "link": "https://openreview.net/forum?id=DKZjYuB6gc", "pdf_link": "https://openreview.net/pdf?id=DKZjYuB6gc", "keywords": "Learned optimizers, Meta-optimization, Fine-tuning, Image classification", "abstract": "In modern deep learning, the models are learned by applying gradient updates using an optimizer, which transforms the updates based on various statistics. Optimizers are often hand-designed and tuning their hyperparameters is a big part of the training process. Learned optimizers have shown some initial promise, but are generally unsuccessful as a general optimization mechanism applicable to every problem. In this work we explore a different direction: instead of learning general optimizers, we instead specialize them to a specific training environment. We propose a novel optimizer technique that learns a layer-specific linear combination of update directions provided by a set of base optimizers, effectively adapting its strategy to the specific model and dataset. When evaluated on image classification tasks, this specialized optimizer significantly outperforms both traditional off-the-shelf methods such as Adam, as well as existing general learned optimizers. Moreover, it demonstrates robust generalization with respect to model initialization, evaluating on unseen datasets, and training durations beyond its meta-training horizon.", "title_embedding_index": 18160, "title_abs_embedding_index": 18185}, {"title": "Truncated Consistency Models", "link_suffix": "/forum?id=ZYDEJEvCbv", "link": "https://openreview.net/forum?id=ZYDEJEvCbv", "pdf_link": "https://openreview.net/pdf?id=ZYDEJEvCbv", "keywords": "Consistency models, diffusion models, generative models", "abstract": "Consistency models have recently been introduced to accelerate the generation speed of diffusion models by directly predicting the solution (data) of the probability flow ODE (PF ODE) from initial noise.\nHowever, the training of consistency models requires learning to map all intermediate points along PF ODE trajectories to their corresponding endpoints. This task is much more challenging than the ultimate objective of one-step generation, which only concerns the PF ODE's noise-to-data mapping.\nWe empirically find that this training paradigm limits the one-step generation performance of consistency models.\nTo address this issue, we generalize consistency training to the truncated time range, which allows the model to ignore denoising tasks at earlier time steps and focus its capacity on generation.\nWe propose a new parameterization of the consistency function and a two-stage training procedure that prevent the truncated-time training from collapsing to a trivial solution.\nExperiments on CIFAR-10 and ImageNet $64\\times64$ datasets show that our method achieves better one-step and two-step FIDs than the state-of-the-art consistency models such as iCT-deep,\nusing more than 2$\\times$ smaller networks.", "title_embedding_index": 18161, "title_abs_embedding_index": 18186}, {"title": "Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models", "link_suffix": "/forum?id=EEWpE9cR27", "link": "https://openreview.net/forum?id=EEWpE9cR27", "pdf_link": "https://openreview.net/pdf?id=EEWpE9cR27", "keywords": "Safety Alignment, Multi-modality, AI Security", "abstract": "The safety alignment ability of Vision-Language Models (VLMs) is prone to be degraded by the integration of the vision module compared to its LLM backbone. We investigate this phenomenon, dubbed as \u201csafety alignment degradation\u201d in this paper, and show that the challenge arises from the representation gap that emerges when introducing vision modality to VLMs. In particular, we show that the representations of multi-modal inputs shift away from that of text-only inputs which represent the distribution that the LLM backbone is optimized for. At the same time, the safety alignment capabilities, initially developed within the textual embedding space, do not successfully transfer to this new multi-modal representation space. To reduce safety alignment degradation, we introduce Cross-Modality Representation Manipulation (CMRM), an inference time representation intervention method for recovering the safety alignment ability that is inherent in the LLM backbone of VLMs, while simultaneously preserving the functional capabilities of VLMs. The empirical results show that our framework significantly recovers the alignment ability that is inherited from the LLM backbone with minimal impact on the fluency and linguistic capabilities of pre-trained VLMs even without additional training. Specifically, the unsafe rate of LLaVA-7B on multi-modal input can be reduced from 61.53% to as low as 3.15% with only inference-time intervention.", "title_embedding_index": 18162, "title_abs_embedding_index": 18187}, {"title": "KnobGen: Controlling the Sophistication of Artwork in Sketch-Based Diffusion Models", "link_suffix": "/forum?id=ztT70ubhsc", "link": "https://openreview.net/forum?id=ztT70ubhsc", "pdf_link": "https://openreview.net/pdf?id=ztT70ubhsc", "keywords": "Computer Vision, Image Generation, Text-to-Image Generation, Conditional Image Generation, Diffusion Models", "abstract": "Recent advances in diffusion models have significantly improved text-to-image (T2I) generation, but they often struggle to balance fine-grained precision with high-level control. Methods like ControlNet and T2I-Adapter excel at following sketches by seasoned artists but tend to be overly rigid, replicating unintentional flaws in sketches from novice users. Meanwhile, coarse-grained methods, such as sketch-based abstraction frameworks, offer more accessible input handling but lack the precise control needed for detailed, professional use. To address these limitations, we propose KnobGen, a dual-pathway framework that democratizes sketch-based image generation by seamlessly adapting to varying levels of sketch complexity and user skill. KnobGen uses a Coarse-Grained Controller (CGC) module for high-level semantics and a Fine-Grained Controller (FGC) module for detailed refinement. The relative strength of these two modules can be adjusted through our knob inference mechanism to align with the user's specific needs. These mechanisms ensure that KnobGen can flexibly generate images from both novice sketches and those drawn by seasoned artists. This maintains control over the final output while preserving the natural appearance of the image, as evidenced on the MultiGen-20M dataset and a newly collected sketch dataset.", "title_embedding_index": 18163, "title_abs_embedding_index": 18188}, {"title": "Elucidating the Preconditioning in Consistency Distillation", "link_suffix": "/forum?id=55pCDKiS8B", "link": "https://openreview.net/forum?id=55pCDKiS8B", "pdf_link": "https://openreview.net/pdf?id=55pCDKiS8B", "keywords": "Diffusion Models, Distillation, Consistency Trajectory Models", "abstract": "Consistency distillation is a prevalent way for accelerating diffusion models adopted in consistency (trajectory) models, in which a student model is trained to traverse backward on the probability flow (PF) ordinary differential equation (ODE) trajectory determined by the teacher model. Preconditioning is a vital technique for stabilizing consistency distillation, by linear combining the input data and the network output with pre-defined coefficients as the consistency function. It imposes the boundary condition of consistency functions without restricting the form and expressiveness of the neural network. However, previous preconditionings are hand-crafted and may be suboptimal choices. In this work, we offer the first theoretical insights into the preconditioning in consistency distillation, by elucidating its design criteria and the connection to the teacher ODE trajectory. Based on these analyses, we further propose a principled way dubbed \\textit{Analytic-Precond} to analytically optimize the preconditioning according to the consistency gap (defined as the gap between the teacher denoiser and the optimal student denoiser) on a generalized teacher ODE. We demonstrate that Analytic-Precond can facilitate the learning of trajectory jumpers, enhance the alignment of the student trajectory with the teacher's, and achieve $2\\times$ to $3\\times$ training acceleration of consistency trajectory models in multi-step generation across various datasets.", "title_embedding_index": 18164, "title_abs_embedding_index": 18189}, {"title": "Diffusion Bridge Implicit Models", "link_suffix": "/forum?id=eghAocvqBk", "link": "https://openreview.net/forum?id=eghAocvqBk", "pdf_link": "https://openreview.net/pdf?id=eghAocvqBk", "keywords": "Diffusion Bridge Models, Image Translation, Fast Sampling", "abstract": "Denoising diffusion bridge models (DDBMs) are a powerful variant of diffusion models for interpolating between two arbitrary paired distributions given as endpoints. Despite their promising performance in tasks like image translation, DDBMs require a computationally intensive sampling process that involves the simulation of a (stochastic) differential equation through hundreds of network evaluations. In this work, we take the first step in fast sampling of DDBMs without extra training, motivated by the well-established recipes in diffusion models. We generalize DDBMs via a class of non-Markovian diffusion bridges defined on the discretized timesteps concerning sampling, which share the same marginal distributions and training objectives, and give rise to generative processes ranging from stochastic to deterministic, resulting in diffusion bridge implicit models (DBIMs). DBIMs are not only up to 25$\\times$ faster than the vanilla sampler of DDBMs but also induce a novel, simple, and insightful form of ordinary differential equation (ODE) which inspires high-order numerical solvers. Moreover, DBIMs maintain the generation diversity in a distinguished way, by using a booting noise in the initial sampling step, which enables faithful encoding, reconstruction, and semantic interpolation in image translation tasks.", "title_embedding_index": 18165, "title_abs_embedding_index": 18190}, {"title": "TapWeight: Reweighting Pretraining Objectives for Task-Adaptive Pretraining", "link_suffix": "/forum?id=j3cBYvwyQT", "link": "https://openreview.net/forum?id=j3cBYvwyQT", "pdf_link": "https://openreview.net/pdf?id=j3cBYvwyQT", "keywords": "task-adaptive pretraining, continued pretraining, multi-level optimization, hyper-parameter optimization", "abstract": "Large-scale general domain pretraining followed by downstream-specific finetuning has become a predominant paradigm in machine learning. However, discrepancies between the pretraining and target domains can still lead to performance degradation in certain cases, underscoring the need for task-adaptive continued pretraining (TAP). TAP methods typically involve continued pretraining on task-specific unlabeled datasets or introducing additional unsupervised learning objectives to enhance model capabilities. While many TAP methods perform continued pretraining with multiple pretraining objectives, they often determine the tradeoff parameters between objectives manually, resulting in suboptimal outcomes and higher computational costs. In this paper, we propose TapWeight, a task-adaptive pretraining framework which automatically determines the optimal importance of each pretraining objective based on downstream feedback. TapWeight reweights each pretraining objective by solving a multi-level optimization problem. We applied TapWeight to both molecular property prediction and natural language understanding tasks, significantly surpassing baseline methods. Experimental results validate the effectiveness and generalizability of TapWeight. Our code is publicly available athttps://anonymous.4open.science/r/TapWeight-9A2E.", "title_embedding_index": 18166, "title_abs_embedding_index": 18191}, {"title": "Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling", "link_suffix": "/forum?id=CTC7CmirNr", "link": "https://openreview.net/forum?id=CTC7CmirNr", "pdf_link": "https://openreview.net/pdf?id=CTC7CmirNr", "keywords": "discrete diffusion models, masked models, language modeling", "abstract": "Masked diffusion models (MDMs) have emerged as a popular research topic for generative modeling of discrete data, thanks to their superior performance over other discrete diffusion models, and are rivaling the auto-regressive models (ARMs) for language modeling tasks. The recent effort in simplifying the masked diffusion framework further leads to alignment with continuous-space diffusion models and more principled training and sampling recipes. \nIn this paper, however, we reveal that both training and sampling of MDMs are theoretically free from the time variable, arguably the key signature of diffusion models, and are instead equivalent to masked models. The connection on the sampling aspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we show that the FHS is theoretically equivalent to MDMs' original generation process while significantly alleviating the time-consuming categorical sampling and achieving a 20$\\times$ speedup. In addition, our investigation raises doubts about whether MDMs can truly beat ARMs in text generation. We identify, for the first time, an underlying numerical issue, even with the commonly used 32-bit floating-point precision, which results in inaccurate categorical sampling. \nWe show that it lowers the effective temperature both theoretically and empirically, and the resulting decrease in token diversity makes previous evaluations, which assess the generation quality solely through the incomplete generative perplexity metric, somewhat unfair.", "title_embedding_index": 18167, "title_abs_embedding_index": 18192}, {"title": "PRUC & Play: Probabilistic Residual User Clustering for Recommender Systems", "link_suffix": "/forum?id=9XXBsLWMF3", "link": "https://openreview.net/forum?id=9XXBsLWMF3", "pdf_link": "https://openreview.net/pdf?id=9XXBsLWMF3", "keywords": "Recommendation System, Causal Inference, Bayesian Deep Learning", "abstract": "Modern recommender systems are typically based on deep learning (DL) models, where a dense encoder learns representations of users and items. As a result, these systems often suffer from the black-box nature and computational complexity of the underlying models, making it difficult to systematically interpret their outputs and enhance their recommendation capabilities. To address this problem, we propose Probabilistic Residual User Clustering (PRUC), a causal Bayesian recommendation model based on user clusters. Specifically, we address this problem by (1) automatically dividing users into clusters and identifying causal confounders that influence latent variables, (2) developing sub-models for each confounder given observable variables, and (3) generating recommendations by aggregating the rating residuals under each confounder using do-calculus. Experiments demonstrate that our plug-and-play PRUC is compatible with various base DL recommender systems, significantly improving their performance while automatically discovering meaningful user clusters.", "title_embedding_index": 18168, "title_abs_embedding_index": 18193}, {"title": "A Geometric Approach to Personalized Recommendation with Set-Theoretic Constraints Using Box Embeddings", "link_suffix": "/forum?id=0HWAbWgI3T", "link": "https://openreview.net/forum?id=0HWAbWgI3T", "pdf_link": "https://openreview.net/pdf?id=0HWAbWgI3T", "keywords": "Box Embeddings, Personalized Query, Set-based embeddings, Recommendation", "abstract": "Personalized item recommendation typically suffers from data sparsity, which is most often addressed by learning vector representations of users and items via low-rank matrix factorization. While this effectively densifies the matrix by assuming users and movies can be represented by linearly dependent latent features, it does not capture more complicated interactions. For example, vector representations struggle with set-theoretic relationships, such as negation and intersection, e.g. recommending a movie that is \u201ccomedy and action, but not romance\u201d. In this work, we formulate the problem of personalized item recommendation as matrix completion where rows are set-theoretically dependent. To capture this set-theoretic dependence we represent each user and attribute by a hyperrectangle or box (i.e. a Cartesian product of intervals). Box embeddings can intuitively be understood as trainable Venn diagrams, and thus not only inherently represent similarity (via the Jaccard index), but also naturally and faithfully support arbitrary set-theoretic relationships. Queries involving set-theoretic constraints can be efficiently computed directly on the embedding space by performing geometric operations on the representations. We empirically demonstrate the superiority of box embeddings over vector-based neural methods on both simple and complex item recommendation queries by up to 30% overall.", "title_embedding_index": 18169, "title_abs_embedding_index": 18194}, {"title": "Spectral Shaping for Neural PDE Surrogates", "link_suffix": "/forum?id=mmDkgLtYNI", "link": "https://openreview.net/forum?id=mmDkgLtYNI", "pdf_link": "https://openreview.net/pdf?id=mmDkgLtYNI", "keywords": "PDEs, Fluid Mechanics, Dynamical systems, Autoregressive models, Spectral methods", "abstract": "Neural surrogates for PDE solvers suffer from an inability to model the spectrum of solutions adequately, especially in the medium to high frequency bands. This impacts not only correct spectral shapes, but also stability and long-term rollout accuracy. We identify three convergent factors that exacerbate this phenomenon, namely: distribution shift over unrolls, spectral bias of the MSE loss, and spurious high frequency noise, orspectral junk, introduced by the use of pointwise nonlinearities. We find thatspectral shaping, filtering the spectrum of activations after every layer of pointwise nonlinearities, is enough to reduce spectral junk and improve long-term rollout accuracy. We show spectral shaping not only fixes the learned spectrum (down to machine precision in some cases), but also leads to very stable neural surrogates. We validate these findings on a suite of challenging fluid dynamics problems in the field of neural PDE surrogacy, promoting a clear need for more careful attention to surrogate architecture design and adding a new and simple trick to the practitioner toolbox.", "title_embedding_index": 18170, "title_abs_embedding_index": 18195}, {"title": "Automated Feature Engineering by Prompting", "link_suffix": "/forum?id=ZXO7iURZfW", "link": "https://openreview.net/forum?id=ZXO7iURZfW", "pdf_link": "https://openreview.net/pdf?id=ZXO7iURZfW", "keywords": "Automated Feature Engineering, Large Language Models, Tabular Data Prediction", "abstract": "Automated feature engineering (AutoFE) liberates data scientists from the burden\nof manual feature construction, a critical step for tabular data prediction. While the\nsemantic information of datasets provides valuable context for feature engineering,\nit has been underutilized in most existing works. In this paper, we introduce\nAutoFE by Prompting (FEBP), a novel AutoFE algorithm that leverages large language\nmodels (LLMs) to process dataset descriptions and automatically generate\nfeatures. Incorporating domain knowledge, the LLM iteratively refines feature\nconstruction through in-context learning of top-performing example features and\nprovides semantic explanations. Our experiments on real-world datasets demonstrate\nthe superior performance of FEBP over state-of-the-art AuoFE methods. We\nalso conduct ablation study to verify the impact of dataset semantic information\nand examine the behavior of our LLM-based feature search process.", "title_embedding_index": 18171, "title_abs_embedding_index": 18196}, {"title": "Learning subgoal representations from state graphs in goal-conditioned hierarchical reinforcement learning", "link_suffix": "/forum?id=1OGhJCGdcP", "link": "https://openreview.net/forum?id=1OGhJCGdcP", "pdf_link": "https://openreview.net/pdf?id=1OGhJCGdcP", "keywords": "Reinforcement Learning, Graph Representation Learning, Hierarchical Reinforcement Learning", "abstract": "The integration of graphs with Goal-conditioned Hierarchical Reinforcement Learning (GCHRL) has recently gained attention, as the intermediate goals (subgoals) can be effectively sampled from graphs that naturally represent the overall task structure in most RL tasks. However, some \nexisting approaches often rely on domain-specific knowledge to construct these graphs, limiting their applicability to new tasks. \nOther graph-based approaches create graphs dynamically during exploration but struggle to fully utilize them because they have problems passing the information in the graphs to newly visited states. \nAdditionally, current GCHRL methods face challenges such as sample inefficiency and poor subgoal representations. In this paper, we present a solution to these issues through the development of a graph encoder-decoder that can evaluate unseen states. \nOur proposed method, Graph-Guided sub-Goal representation Generation RL (G4RL), can be incorporated into any existing GCHRL method to enhance performance. \nWe show that the graph encoder-decoder can be effectively implemented using a network trained on the state graph generated during exploration. Empirical results indicate that leveraging high and low-level intrinsic rewards from the graph encoder-decoder significantly enhances the performance of state-of-the-art GCHRL approaches in both dense and sparse reward environments.", "title_embedding_index": 18172, "title_abs_embedding_index": 18197}, {"title": "Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data", "link_suffix": "/forum?id=bR1J7SpzrD", "link": "https://openreview.net/forum?id=bR1J7SpzrD", "pdf_link": "https://openreview.net/pdf?id=bR1J7SpzrD", "keywords": "audio classification, synthetic data, data-efficient learning", "abstract": "We present Synthio, a novel approach for augmenting small-scale audio classification datasets with synthetic data. Our goal is to improve audio classification accuracy with limited labeled data. Traditional data augmentation techniques, which apply artificial transformations (e.g., adding random noise or masking segments), struggle to create data that captures the true diversity present in real-world audios. To address this shortcoming, we propose to augment the dataset with synthetic audio generated from text-to-audio (T2A) diffusion models. However, synthesizing effective augmentations is challenging because not only should the generated data be acoustically consistent with the underlying small-scale dataset, but they should also have sufficient compositional diversity. To overcome the first challenge, we align the generations of the T2A model with the small-scale dataset using preference optimization. This ensures that the acoustic characteristics of the generated data remain consistent with the small-scale dataset. To address the second challenge, we propose a novel caption generation technique that leverages the reasoning capabilities of Large Language Models to (1) generate diverse and meaningful audio captions and (2) iteratively refine their quality. The generated captions are then used to prompt the aligned T2A model. We extensively evaluate Synthio on ten datasets and four simulated limited-data settings. Results indicate our method consistently outperforms all baselines by 0.1%-39% using a T2A model trained only on weakly-captioned AudioSet.", "title_embedding_index": 18173, "title_abs_embedding_index": 18198}, {"title": "Optimizing Dynamic Treatment Strategies with Reinforcement Learning and Dual-Hawkes Process in Clinical Environments", "link_suffix": "/forum?id=i25WJWnsmq", "link": "https://openreview.net/forum?id=i25WJWnsmq", "pdf_link": "https://openreview.net/pdf?id=i25WJWnsmq", "keywords": "Reinforcement Learning", "abstract": "Modeling the timing of critical events and controlling associated risks through treatment options are crucial aspects of healthcare. However, current methods fall short in optimizing dynamic treatment plans to improve clinical outcomes. A key challenge lies in modeling the intensity functions of critical events throughout disease progression and capturing the dynamic interactions between patient conditions and treatments. To address this, we propose integrating reinforcement learning with a Generative Adversarial Network (GAN) and a dual-Hawkes process model to develop intelligent agents capable of delivering personalized and adaptive treatment strategies. The dual-Hawkes process allows us to model the intensity of both disease progression and recovery, while accounting for long-term dependencies. The GAN simulates real-world clinical environments using raw time-to-event data, without requiring detailed treatment annotations. By interacting with GAN, our model-based reinforcement learning agent learns an optimal dynamic policy that leverages long-term historical dependencies. When applied to the MIMIC-III dataset, our approach significantly increased the duration that patients remained in a healthy state, outperforming established machine learning policies.", "title_embedding_index": 18174, "title_abs_embedding_index": 18199}]
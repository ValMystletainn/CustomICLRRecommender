[{"title": "Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance", "link_suffix": "/forum?id=sRIU6k2TcU", "link": "https://openreview.net/forum?id=sRIU6k2TcU", "pdf_link": "https://openreview.net/pdf?id=sRIU6k2TcU", "keywords": "Human-Centered NLP, Dialogue and Interactive Systems, Resources and Evaluation", "abstract": "Agents powered by large language models have shown remarkable abilities in solving complex tasks. However, most agent systems remain reactive, limiting their effectiveness in scenarios requiring foresight and autonomous decision-making. In this paper, we tackle the challenge of developing proactive agents capable of anticipating and initiating tasks without explicit human instructions. We propose a novel data-driven approach for this problem. Firstly, we collect real-world human activities to generate proactive task predictions. These predictions are then labeled by human annotators as either accepted or rejected. The labeled data is used to train a reward model that simulates human judgment and serves as an automatic evaluator of the proactiveness of LLM agents. Building on this, we develop a comprehensive data generation pipeline to create a diverse dataset, ProactiveBench, containing 6,790 events. Finally, we demonstrate that fine-tuning models with the proposed ProactiveBench can significantly elicit the proactiveness of LLM agents. Experimental results show that our fine-tuned model achieves an F1-Score of 66.47% in proactively offering assistance, outperforming all open-source and close-source models. These results highlight the potential of our method in creating more proactive and effective agent systems, paving the way for future advancements in human-agent collaboration.", "title_embedding_index": 16250, "title_abs_embedding_index": 16275}, {"title": "LumiSculpt: A Consistency Lighting Control Network for Video Generation", "link_suffix": "/forum?id=OW0uRFs51N", "link": "https://openreview.net/forum?id=OW0uRFs51N", "pdf_link": "https://openreview.net/pdf?id=OW0uRFs51N", "keywords": "Light Control, Video generation, Text-to-video generation, diffusion models", "abstract": "Lighting is essential for the naturalness of video generation, which significantly impacts the overall aesthetic quality of the generated video. However, due to the deep coupling between lighting and the temporal features of videos, it is challenging for modeling independent and coherent lighting attributes, resulting in a lack of approaches for controlling lighting in videos. Therefore, inspired by the established controllable T2I models, we propose LumiSculpt, achieving precise and consistency lighting control in video generation models for the first time. LumiSculpt equips the video generation with strong interactive capabilities, allowing for the input of custom lighting reference image sequences. Furthermore, the core learnable plug-and-play module of LumiSculpt enables us to achieve remarkable performance on controlling light intensity, position, trajectory in latent video diffusion models based on the advanced DiT backbone. Additionally, to effectively fine-tune LumiSculpt and address the issue of insufficient lighting data, we construct LumiHuman, a new lightweight and flexible dataset for portrait lighting of images and videos. Experiments demonstrate that LumiSculpt achieves precise and high-quality lighting control in video generation. The code, model, and dataset will be released to facilitate further research. Video results are shown in the supplementary material.", "title_embedding_index": 16251, "title_abs_embedding_index": 16276}, {"title": "Towards Real World Debiasing: A Fine-grained Analysis On Spurious Correlation", "link_suffix": "/forum?id=hom2oeHCnz", "link": "https://openreview.net/forum?id=hom2oeHCnz", "pdf_link": "https://openreview.net/pdf?id=hom2oeHCnz", "keywords": "spurious correlation, dataset bias, debias", "abstract": "Spurious correlations in training data significantly hinder the generalization capability of machine learning models when faced with distribution shifts in real-world scenarios. To tackle the problem, numerous debias approaches have been proposed and benchmarked on datasets intentionally designed with severe biases. However, it remains to be asked: \\textit{1. Do existing benchmarks really capture biases in the real world? 2. Can existing debias methods handle biases in the real world?} To answer the questions, we revisit biased distributions in existing benchmarks and real-world datasets, and propose a fine-grained framework for analyzing dataset bias by disentangling it into the magnitude and prevalence of bias. We observe and theoretically demonstrate that existing benchmarks poorly represent real-world biases. We further introduce two novel biased distributions to bridge this gap, forming a nuanced evaluation framework for real-world debiasing. Building upon these results, we evaluate existing debias methods with our evaluation framework. Results show that existing methods are incapable of handling real-world biases. Through in-depth analysis, we propose a simple yet effective approach that can be easily applied to existing debias methods, named Debias in Destruction (DiD). Empirical results demonstrate the superiority of DiD, improving the performance of existing methods on all types of biases within the proposed evaluation framework.", "title_embedding_index": 16252, "title_abs_embedding_index": 16277}, {"title": "Time Can Invalidate Algorithmic Recourse", "link_suffix": "/forum?id=lpwS5T1jFb", "link": "https://openreview.net/forum?id=lpwS5T1jFb", "pdf_link": "https://openreview.net/pdf?id=lpwS5T1jFb", "keywords": "algorithmic recourse, counterfactual explanations, causality, explainable ai", "abstract": "Algorithmic Recourse (AR) aims to provide users with actionable steps to overturn unfavourable decisions made by machine learning predictors. However, these actions often take time to implement (e.g., getting a degree can take years), and their effects may vary as the world evolves. Thus, it is natural to ask for recourse that remains valid in a dynamic environment. In this paper, we study the robustness of algorithmic recourse over time by casting the problem through the lens of causality. We demonstrate theoretically and empirically that (even robust) causal AR methods can fail over time except in the -- unlikely -- case that the world is stationary. Even more critically, unless the world is fully deterministic, counterfactual AR cannot be solved optimally. To account for this, we propose a simple yet effective algorithm for temporal AR that explicitly accounts for time. Our simulations on synthetic and realistic datasets show how considering time produces more resilient solutions to potential trends in the data distribution.", "title_embedding_index": 16253, "title_abs_embedding_index": 16278}, {"title": "MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization", "link_suffix": "/forum?id=2veex1oOtc", "link": "https://openreview.net/forum?id=2veex1oOtc", "pdf_link": "https://openreview.net/pdf?id=2veex1oOtc", "keywords": "Multimodal Large Language Models, Quantization", "abstract": "Recently, multimodal large language models (MLLMs) have garnered widespread attention due to their ability to perceive and understand multimodal signals. However, their large parameter sizes and substantial computational demands severely hinder their practical deployment and application. While quantization is an effective way to reduce model size and inference latency, its application to MLLMs remains underexplored. In this paper, we conduct an in-depth analysis of MLLMs quantization and identify several challenges: slow inference speed of the visual tokens, distributional differences across modalities, and visual outlier clipping degrades performance.\nTo address these challenges, we proposeMQuant, a quantization framework tailored for MLLMs. Specifically, 1) we design Modality-specific Quantization (MSQ) and Attention-Invariant Flexible Switching (AIFS) to support per-tensor static quantization and facilitate efficient inference. 2) we introduce a unified LayerNorm-to-RMSNorm transformation, achieving seamless integration of the MLLM vision encoder with Hadamard rotation. 3) we propose Rotation Magnitude Suppression (RMS) to mitigate outliers introduced by Hadamard rotation. Experiments conducted on five mainstream MLLMs demonstrate the superior performance and broad applicability of MQuant. For example, it maintains around 98% of the floating-point accuracy under the W4A8 setting. To the best of our knowledge,MQuantis the first quantization solution for MLLMs, paving the way for future advancements in their application.", "title_embedding_index": 16254, "title_abs_embedding_index": 16279}, {"title": "SMART: Self-Learning Meta-strategy Agent for Reasoning Tasks", "link_suffix": "/forum?id=TANu5nDVvU", "link": "https://openreview.net/forum?id=TANu5nDVvU", "pdf_link": "https://openreview.net/pdf?id=TANu5nDVvU", "keywords": "Refinement, RL, Reasoning", "abstract": "Tasks requiring deductive reasoning, especially those involving multiple steps, often demand adaptive strategies such as intermediate generation of rationales or programs, as no single approach is universally optimal. \nWhile Language Models (LMs) can enhance their outputs through iterative self-refinement and strategy adjustments, they frequently fail to apply the most effective strategy in their first attempt. This inefficiency raises the question:Can LMs learn to select the optimal strategy in the first attempt, without a need for refinement?To address this challenge, we introduceSMART:Self-learningMeta-strategyAgent forReasoningTasks, a novel framework that enables LMs to autonomously learn and select the most effective strategies for various reasoning tasks. We model the strategy selection process as aMarkov Decision Processand leverage reinforcement learning-driven continuous self-improvement to allow the model to find the suitable strategy to solve a given task. Unlike traditional self-refinement methods that rely on multiple inference passes or external feedback,SMARTallows an LM to internalize the outcomes of its own reasoning processes and adjust its strategy accordingly, aiming for correct solutions on the first attempt.\nOur experiments across various reasoning datasets and with different model architectures demonstrate thatSMARTsignificantly enhances the ability of models to choose optimal strategies without external guidance (+15 points on the GSM8K dataset). By achieving higher accuracy with a single inference pass,SMARTnot only improves performance but also reduces computational costs for refinement-based strategies, paving the way for more efficient and intelligent reasoning in LMs.", "title_embedding_index": 16255, "title_abs_embedding_index": 16280}, {"title": "Can Generative AI Solve Your In-Context Learning Problem?  A Martingale Perspective", "link_suffix": "/forum?id=bcynT7s2du", "link": "https://openreview.net/forum?id=bcynT7s2du", "pdf_link": "https://openreview.net/pdf?id=bcynT7s2du", "keywords": "generative models, Bayesian, in-context learning, generalization, model checking", "abstract": "This work is about estimating when a conditional generative model (CGM) can solve an in-context learning (ICL) problem. An in-context learning (ICL) problem comprises a conditional generative model (CGM), a dataset, and a prediction task. For example, the CGM could be a pre-trained multi-modal foundation model; the dataset could be a collection of patient histories, test results, and recorded diagnoses; and the prediction task could be to communicate the diagnoses to a new patient. The Bayesian interpretation of ICL assumes that the CGM computes a posterior predictive distribution over an unknown Bayesian model defining a joint distribution over latent explanations and observable data. From this perspective, Bayesian model criticism is a reasonable approach to assess the suitability of a given CGM for an ICL problem. However, such approaches---like posterior predictive checks (PPCs)---often assume that we can sample from the likelihood and posterior defined by the Bayesian model, which are not explicitly given for contemporary CGMs. To address this, we show when ancestral sampling from the predictive distribution of a CGM is equivalent sampling datasets from the posterior predictive of the assumed Bayesian model.  Then we develop the generative predictive $p$-value, which enables PPCs and their cousins for contemporary CGMs. The generative predictive $p$-value can then be used in a statistical decision procedure to determine when the model is appropriate for an ICL problem, as a metric to compare different model choices, or as a general measure of uncertainty over models. Our method only requires generating queries and responses from a CGM and evaluating its response log probability. We empirically evaluate our method on synthetic regression and natural language ICL tasks using large language models.", "title_embedding_index": 16256, "title_abs_embedding_index": 16281}, {"title": "EPINN: Physics-Informed Neural Network with exponential activation functions for solving stiff ODEs", "link_suffix": "/forum?id=SYiOxXWlKU", "link": "https://openreview.net/forum?id=SYiOxXWlKU", "pdf_link": "https://openreview.net/pdf?id=SYiOxXWlKU", "keywords": "EPINN, stiff ODEs, PINN", "abstract": "Solving stiff ordinary differential equations (ODEs) through machine learning methods has been quite a popular topic for years as it challenges the recently proposed physics-informed neural network (PINN). Many variations based on PINN have been advanced to enhance both the efficiency and the robustness. Nonetheless, many of them need to find the trade-off between the precision and speed because they have to train hundreds or even thousands of parameters if they do not design good or problem-adapt networks. In this scenario, we put forward a single layer physics-informed neural network with exponential activation functions (EPINN) by implementing the prior knowledge of the solution to the linear stiff ODEs. Under this simple but useful structure, less parameters \nwould be sufficient and the model is easy to train. The model is also extended to solve nonlinear systems by introducing sequential EPINN. The network is tested on six benchmark problems including both linear and nonlinear ones and shows great performance.", "title_embedding_index": 16257, "title_abs_embedding_index": 16282}, {"title": "Demystifying amortized causal discovery with transformers", "link_suffix": "/forum?id=lQYi2zeDyh", "link": "https://openreview.net/forum?id=lQYi2zeDyh", "pdf_link": "https://openreview.net/pdf?id=lQYi2zeDyh", "keywords": "causal discovery, amortized inference, transformers, identifiability", "abstract": "Supervised learning for causal discovery from observational data often achieves competitive performance despite seemingly avoiding the explicit assumptions that traditional methods require for identifiability. In this work, we analyze CSIvA (Ke et al., 2023b) on bivariate causal models, a transformer architecture for amortized inference promising to train on synthetic data and transfer to real ones. First, we bridge the gap with identifiability theory, showing that the training distribution implicitly defines a prior on the causal model of the test observations: consistent with classical approaches, good performance is achieved when we have a good prior on the test data, and the underlying model is identifiable. Second, we find that CSIvA can not generalize to classes of causal models unseen during training: to overcome this limitation, we show that learning on datasets generated from different types of causal models, unambiguously identifiable in isolation, improves the test generalization. We analyze this empirical evidence with theory, illustrating that the ambiguous cases resulting from the mixture of identifiable causal models are unlikely to occur. Overall, we find that amortized causal discovery still adheres to identifiability theory, violating the previous hypothesis from Lopez-Paz et al. (2015) that supervised learning methods could overcome its restrictions.", "title_embedding_index": 16258, "title_abs_embedding_index": 16283}, {"title": "GENRAD: Genomics and Radiomics Heterogeneous Graph Neural Network for Graph-Level Classification in Alzheimer's Disease", "link_suffix": "/forum?id=YVVz3vyqwr", "link": "https://openreview.net/forum?id=YVVz3vyqwr", "pdf_link": "https://openreview.net/pdf?id=YVVz3vyqwr", "keywords": "Heterogeneous Graph Neural Network (GNN), Alzheimer's Disease, Multimodal data fusion, Genomics, Radiomics, Node-level classification, Multi-scale graph representation, Explainable AI", "abstract": "Alzheimer\u2019s Disease (AD) poses multifaceted challenges due to its neurodegenerative nature driven by complex genomic, radiomic, and structural interactions. Understanding these complex relationships is pivotal for advancing diagnostic and therapeutic approaches. Current models struggle to effectively integrate multimodal data for AD, limiting their predictive accuracy and biological interpretability. Thus, there is a pressing need for models that can seamlessly fuse genomic and radiomic data to provide a holistic understanding of AD pathology. We introduce GENRAD, a novel heterogeneous graph neural network (GNN) that integrates multimodal genomic and radiomic data for graph-level classification in AD by representing patients, genes, and brain structures as distinct nodes and implementing advanced message-passing techniques. The benefits of GENRAD are fourfold: (1) It enables multimodal fusion of genomic and radiomic data, uncovering biologically meaningful insights missed by single-modality models. (2) Its adaptive multi-scale graph representations model interactions at various biological scales, capturing complex relationships essential for understanding AD pathology. (3) GENRAD incorporates explainable AI techniques, providing detailed analysis of key genomic markers and brain regions associated with AD. (4) GENRAD performs unsupervised clustering of genes, allowing the identification of functionally related biological pathways, thus empowering clinicians with actionable insights for personalized treatment strategies. GENRAD demonstrates superior classification accuracy in identifying AD-related patterns compared to existing machine and deep learning models, achieving an accuracy of 91.70%.", "title_embedding_index": 16259, "title_abs_embedding_index": 16284}, {"title": "What Makes Your Model a Low-empathy or Warmth Person: Exploring the Origins of Personality in LLMs", "link_suffix": "/forum?id=DXaUC7lBq1", "link": "https://openreview.net/forum?id=DXaUC7lBq1", "pdf_link": "https://openreview.net/pdf?id=DXaUC7lBq1", "keywords": "explainable ai, personality of LLM", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in generating human-like text and exhibiting personality traits similar to those in humans. However, the mechanisms by which LLMs encode and express traits such as agreeableness and impulsiveness remain poorly understood. Drawing on the theory of social determinism, we investigate how long-term background factors, such as family environment and cultural norms, interact with short-term pressures like external instructions, shaping and influencing LLMs' personality traits. By steering the output of LLMs through the utilization of interpretable features within the model, we explore how these background and pressure factors lead to changes in the model's traits without the need for further fine-tuning. Additionally, we suggest the potential impact of these factors on model safety from the perspective of personality.", "title_embedding_index": 16260, "title_abs_embedding_index": 16285}, {"title": "PowerNet: Truncated Matrix Power Series as Quasi-Equivariant Layers", "link_suffix": "/forum?id=OopiU1q328", "link": "https://openreview.net/forum?id=OopiU1q328", "pdf_link": "https://openreview.net/pdf?id=OopiU1q328", "keywords": "symmetry, deep learning, geometry, Lie theory", "abstract": "Despite being theoretically well-grounded, enforcing strict equivariance in deep learning models has shown to be harmful in some cases. The problem is that most available data does not follow mathematically precise rules, is noisy, and is not strictly group-structured. While soft equivariance approaches attempt to address these issues, they often struggle to maintain group structure and lack strong theoretical guarantees, potentially compromising the benefits of equivariance. Here we introduce the concept of \\textit{quasi equivariances}, where group structure is maintained but the associated parameters become distributions, and implement it in the proposed \\textit{PowerNet} architecture. Similar to CNNs, PowerNet is constructed by interlacing truncated matrix power series with non-linearities. We show how the base matrix used to define the power series can instill quasi-equivariance in a natural way. Finally, we provide results for augmented MNIST classification and transformation magnitude regression in addition to classification of CIFAR-10.", "title_embedding_index": 16261, "title_abs_embedding_index": 16286}, {"title": "Exact Shapley Value for Local and Global Explanation of Additive Gaussian Processes", "link_suffix": "/forum?id=GhT6NjiLeA", "link": "https://openreview.net/forum?id=GhT6NjiLeA", "pdf_link": "https://openreview.net/pdf?id=GhT6NjiLeA", "keywords": "gaussian processes, shapley value, interpretable, functional decomposition", "abstract": "Additive Gaussian Processes (AGPs) have emerged as an extension of Gaussian Processes (GPs), offering a more interpretable and flexible approach by decomposing the target function into sums of multiple GPs, each influenced by different subsets of features. Despite their enhanced, expressive structure, AGPs struggle to provide local explanations and offer only global feature importance with notable shortcomings. To bridge this gap, this paper introduces an interpretative framework for AGPs that utilizes Shapley values to provide both local and global explanations of feature importance. For local explanation, we use the relationship between the AGP and the Shapley value and guarantee the additivity of the explanation. We then develop a dynamic programming algorithm for efficient computation of \\textit{exact} Shapley values, whose complexity scales polynomially rather than exponentially with the number of features. In addition, we use a variance-based sensitivity approach for the global explanation and develop an efficient dynamic programming-based algorithm to compute the \\textit{exact} Shapley value as the global feature importance. We present the effectiveness of the proposed methods on several real experiments and discuss their potential in interpretable machine learning, feature selection, and global sensitivity analysis.", "title_embedding_index": 16262, "title_abs_embedding_index": 16287}, {"title": "Conditional Testing based on Localized Conformalp-values", "link_suffix": "/forum?id=Ip6UwB35uT", "link": "https://openreview.net/forum?id=Ip6UwB35uT", "pdf_link": "https://openreview.net/pdf?id=Ip6UwB35uT", "keywords": "Conditional testing; Conformal inference; False discovery rate; Family-wise error rate; U-statistic.", "abstract": "In this paper, we address conditional testing problems through the conformal inference framework. We define the localized conformal $p$-values by inverting prediction intervals and prove their theoretical properties. These defined $p$-values are then applied to several conditional testing problems to illustrate their practicality. Firstly, we propose a conditional outlier detection procedure to test for outliers in the conditional distribution with finite-sample false discovery rate (FDR) control. We also introduce a novel conditional label screening problem with the goal of screening multivariate response variables and propose a screening procedure to control the family-wise error rate (FWER). Finally, we consider the two-sample conditional distribution test and define a weighted U-statistic through the aggregation of localized $p$-values. Numerical simulations and real-data examples validate the superior performance of our proposed strategies.", "title_embedding_index": 16263, "title_abs_embedding_index": 16288}, {"title": "TextSeg: Reimagining Image Segmentation as Text Generation", "link_suffix": "/forum?id=vkakKdznFS", "link": "https://openreview.net/forum?id=vkakKdznFS", "pdf_link": "https://openreview.net/pdf?id=vkakKdznFS", "keywords": "Multimodal large language model, Image segmentation, Referring expression segmentation", "abstract": "Multimodal Large Language Models (MLLMs) have shown exceptional capabilities in vision-language tasks; however, effectively integrating image segmentation into these models remains a significant challenge. In this paper, we introduce TextSeg, a novel text-as-mask paradigm that casts image segmentation as a text generation problem, eliminating the need for additional decoders and significantly simplifying the segmentation process. Our key innovation is semantic descriptors, a new textual representation of segmentation masks where each image patch is mapped to its corresponding text label. This unified representation allows seamless integration into the auto-regressive training pipeline of MLLMs for easier optimization. We demonstrate that representing an image with $16\\times16$ semantic descriptors yields competitive segmentation performance. To enhance efficiency, we introduce the Row-wise Run-Length Encoding (R-RLE), which compresses redundant text sequences, reducing the length of semantic descriptors by 74% and accelerating inference by $3\\times$, without compromising performance. Extensive experiments across various vision tasks, such as referring expression segmentation and comprehension, show that TextSeg achieves state-of-the-art performance on multiple datasets by fine-tuning different MLLM backbones. Our approach provides an efficient, scalable solution for vision-centric tasks within the MLLM framework.", "title_embedding_index": 16264, "title_abs_embedding_index": 16289}, {"title": "Visual Large Language Models Exhibit Human-Level Cognitive Flexibility", "link_suffix": "/forum?id=5d4UTqXjmS", "link": "https://openreview.net/forum?id=5d4UTqXjmS", "pdf_link": "https://openreview.net/pdf?id=5d4UTqXjmS", "keywords": "Cognitive Flexibility, Visual Large Language Models, Wisconsin Card Sorting Test", "abstract": "Cognitive flexibility has been extensively studied in human cognition but remains relatively unexplored in the context of Visual Large Language Models (VLLMs). This study assesses the cognitive flexibility of state-of-the-art VLLMs (GPT-4o, Gemini-1.5 Pro, and Claude-3.5 Sonnet) using the Wisconsin Card Sorting Test (WCST), a classic measure of set-shifting ability. Our results reveal that VLLMs achieve or surpass human-level set-shifting capabilities under chain-of-thought prompting with text-based inputs. However, their abilities are highly influenced by both input modality and prompting strategy. In addition, we find that through role-playing, VLLMs can simulate various functional deficits aligned with  patients having impairments in cognitive flexibility, suggesting that VLLMs may possess a cognitive architecture, at least regarding the ability of set-shifting, similar to the brain. This study reveals the fact that VLLMs have already approached the human level on a key component underlying our higher cognition, and highlights the potential to use them to emulate complex brain processes.", "title_embedding_index": 16265, "title_abs_embedding_index": 16290}, {"title": "Importance Corrected Neural JKO Sampling", "link_suffix": "/forum?id=eZLckrDOom", "link": "https://openreview.net/forum?id=eZLckrDOom", "pdf_link": "https://openreview.net/pdf?id=eZLckrDOom", "keywords": "Sampling, Wasserstein Gradient Flows, Normalizing Flows, Rejection Sampling", "abstract": "In order to sample from an unnormalized probability density function, we propose to combine continuous normalizing flows (CNFs) with rejection-resampling steps based on importance weights. We relate the iterative training of CNFs with regularized velocity fields to a JKO scheme and prove convergence of the involved velocity fields to the velocity field of the Wasserstein gradient flow (WGF). The alternation of local flow steps and non-local rejection-resampling steps allows to overcome local minima or slow convergence of the WGF for multimodal distributions. Since the proposal of the rejection step is generated by the model itself, they do not suffer from common drawbacks of classical rejection schemes. The arising model can be trained iteratively, reduces the reverse Kullback-Leibler (KL) loss function in each step, allows to generate iid samples and moreover allows for evaluations of the generated underlying density. Numerical examples show that our method yields accurate results on various test distributions including high-dimensional multimodal targets and outperforms the state of the art in almost all cases significantly.", "title_embedding_index": 16266, "title_abs_embedding_index": 16291}, {"title": "Correlation Analysis of Evaluation Metrics for Machine Translation", "link_suffix": "/forum?id=MyotJECv0D", "link": "https://openreview.net/forum?id=MyotJECv0D", "pdf_link": "https://openreview.net/pdf?id=MyotJECv0D", "keywords": "Correlation Analysis, Morphological Evaluation Metrics, Semantic Evaluation Metrics, Machine Translation", "abstract": "Machine translation evaluation methods can be roughly divided into three categories: manual evaluation, classical morphological evaluation and semantic evaluation based on pre-trained model. The automatic evaluation metrics of the latter two categories are numerous, from which we select commonly used seven morphological evaluation metrics and four semantic evaluation metrics for correlation analysis between each two of them. The experimental results of the correlation coefficients of Pearson, Kendall and Spearman on 40 machine translation models of bidirectional 20 foreign languages and Chinese show that: (1) There is an extremely strong correlation among morphological evaluation metrics, indicating that the statistical results of various morphological calculation methods tend to be the same on big data. (2) There is a strong correlation between semantic evaluation metrics, indicating that although there are semantic spatial differences among various pre-trained models, the statistical results on big data also tend to be consistent. The above-mentioned ubiquitous correlations largely stem from the equivalence of human cognition and the economy of knowledge representation. (3) There is also a strong correlation between morphological and semantic evaluation metrics, which shows that the deep \u201csemantics\u201d of various commercial hypes at present is just another high-level \u201cmorphology\u201d. Because the Turing computing system can use symbols and operations to directly represent and accurately process morphologies, but can only simulately represent and approximately process semantics using symbols and operations. (4) For each correlation coefficient between any two evaluation metrics, there is a significant difference between different languages, which indicates that morphology and semantics are inherent attributes of languages, and more optimized evaluation metrics of machine translation should be personalized according to the language.", "title_embedding_index": 16267, "title_abs_embedding_index": 16292}, {"title": "Beyond The Rainbow: High Performance Deep Reinforcement Learning On A Desktop PC", "link_suffix": "/forum?id=0ydseYDKRi", "link": "https://openreview.net/forum?id=0ydseYDKRi", "pdf_link": "https://openreview.net/pdf?id=0ydseYDKRi", "keywords": "Reinforcement Learning, Computational Efficiency, High Performance, Atari, Value-Based, DQN, Rainbow DQN, BeyondTheRainbow", "abstract": "Rainbow Deep Q-Network (DQN) demonstrated combining multiple independent enhancements could significantly boost a reinforcement learning (RL) agent\u2019s performance. In this paper, we present \"Beyond The Rainbow'\" (BTR), a novel algorithm that integrates six improvements from across the RL literature to Rainbow DQN, establishing a new state-of-the-art for RL using a desktop PC, with a human-normalized interquartile mean (IQM) of 7.4 on Atari-60. Beyond Atari, we demonstrate BTR's capability to handle complex 3D games, successfully training agents to play Super Mario Galaxy, Mario Kart, and Mortal Kombat with minimal algorithmic changes. Designing BTR with computational efficiency in mind, agents can be trained using a desktop PC on 200 million Atari frames within 12 hours. Additionally, we conduct detailed ablation studies of each component, analyzing the performance and impact using numerous measures.", "title_embedding_index": 16268, "title_abs_embedding_index": 16293}, {"title": "Diffusing to the Top: Boost Graph Neural Networks with Minimal Hyperparameter Tuning", "link_suffix": "/forum?id=D756s2YQ6b", "link": "https://openreview.net/forum?id=D756s2YQ6b", "pdf_link": "https://openreview.net/pdf?id=D756s2YQ6b", "keywords": "graph neural networks, generative diffusion models, network generation, hyperparameter tuning, node classification, link prediction", "abstract": "Graph Neural Networks (GNNs) are proficient in graph representation learning and achieve promising performance on versatile tasks such as node classification and link prediction.\nUsually, a comprehensive hyperparameter tuning is essential for fully unlocking GNN's top performance, especially for complicated tasks such as node classification on large graphs and long-range graphs. This is usually associated with high computational and time costs and careful design of appropriate search spaces. \nThis work introduces a graph-conditioned latent diffusion framework (GNN-Diff) to generate high-performing GNNs based on the model checkpoints of sub-optimal hyperparameters selected by a light-tuning coarse search. We validate our method through 166 experiments across four graph tasks: node classification on small, large, and long-range graphs, as well as link prediction. Our experiments involve 10 classic and state-of-the-art target models and 20 publicly available datasets. The results consistently demonstrate that GNN-Diff: (1) boosts the performance of GNNs with efficient hyperparameter tuning; and (2) presents high stability and generalizability on unseen data across multiple generation runs. The code is available athttps://anonymous.4open.science/r/GNN-Diff-1AD3.", "title_embedding_index": 16269, "title_abs_embedding_index": 16294}, {"title": "AVOIDING BARREN PLATEAUS VIA GAUSSIAN MIXTURE MODEL", "link_suffix": "/forum?id=2XdRkRHBT9", "link": "https://openreview.net/forum?id=2XdRkRHBT9", "pdf_link": "https://openreview.net/pdf?id=2XdRkRHBT9", "keywords": "Barren plateaus, Gaussian mixture model, Quantum circuits, Variational quantum algorithms", "abstract": "Variational quantum algorithms is one of the most representative algorithms in\nquantum computing, which has a wide range of applications in quantum machine\nlearning, quantum simulation and other related fields. However, they face challenges\nassociated with the barren plateau phenomenon, especially when dealing\nwith large numbers of qubits, deep circuit layers, or global cost functions, making\nthem often untrainable. In this paper, we propose a novel parameter initialization\nstrategy based on Gaussian Mixture Models. We rigorously prove that, the\nproposed initialization method consistently avoids the barren plateaus problem\nfor hardware-efficient ansatz with arbitrary length and qubits and any given cost\nfunction. Specifically, we find that the gradient norm lower bound provided by the\nproposed method is independent of the number of qubits N and increases with the\ncircuit depth L. Our results strictly highlight the significance of Gaussian Mixture\nmodel initialization strategies in determining the trainability of quantum circuits,\nwhich provides valuable guidance for future theoretical investigations and practical\napplications.", "title_embedding_index": 16270, "title_abs_embedding_index": 16295}, {"title": "Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization", "link_suffix": "/forum?id=hj323oR3rw", "link": "https://openreview.net/forum?id=hj323oR3rw", "pdf_link": "https://openreview.net/pdf?id=hj323oR3rw", "keywords": "Test-time Adaptation, Multimodal Learning", "abstract": "Test-time adaptation (TTA) has demonstrated significant potential in addressing distribution shifts between training and testing data. Open-set test-time adaptation (OSTTA) aims to adapt a source pre-trained model online to an unlabeled target domain that contains unknown classes. This task becomes more challenging when multiple modalities are involved. Existing methods have primarily focused on unimodal OSTTA, often filtering out low-confidence samples without addressing the complexities of multimodal data. In this work, we present Adaptive Entropy-aware Optimization (AEO), a novel framework specifically designed to tackle Multimodal Open-set Test-time Adaptation (MM-OSTTA) for the first time. Our analysis shows that the entropy difference between known and unknown samples in the target domain strongly correlates with MM-OSTTA performance. To leverage this, we propose two key components: Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality Prediction Discrepancy Optimization (AMP). These components enhance the model\u2019s ability to distinguish unknown class samples during online adaptation by amplifying the entropy difference between known and unknown samples. To thoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish a new benchmark derived from existing datasets. This benchmark includes two downstream tasks \u2013 action recognition and 3D semantic segmentation \u2013 and incorporates five modalities: video, audio, and optical flow for action recognition, as well as LiDAR and camera for 3D semantic segmentation. Extensive experiments across various domain shift situations demonstrate the efficacy and versatility of the AEO framework. Additionally, we highlight the strong performance of AEO in long-term and continual MM-OSTTA settings, both of which are challenging and highly relevant to real-world applications. This underscores AEO\u2019s robustness and adaptability in dynamic environments. Our source code and benchmarks will be made publicly available.", "title_embedding_index": 16271, "title_abs_embedding_index": 16296}, {"title": "Token to Token Learning From Videos", "link_suffix": "/forum?id=m29SV0n6DO", "link": "https://openreview.net/forum?id=m29SV0n6DO", "pdf_link": "https://openreview.net/pdf?id=m29SV0n6DO", "keywords": "Self-supervised learning, Next token prediction, Video models", "abstract": "We empirically study generative pre-training from videos. Our approach is conceptually simple and inspired by generative pre-training from images, iGPT. To enable scaling to videos, we make several important improvements along the data, architecture, and evaluation axes. Our model, called Toto, is a causal transformer that generates videos autoregressively, one token at a time. We pre-train our model on a diverse set of videos with over 1 trillion visual tokens. Our tokens are quantized patch embeddings, rather than pixels, and we use relative embeddings for coarse-to-fine pre-training. We conduct a large-scale study across a suite of diverse benchmarks, including image recognition, video classification, object tracking, robotic manipulation and scaling behaviours. We find that, despite minimal inductive biases, our approach achieves competitive performance across all benchmarks.", "title_embedding_index": 16272, "title_abs_embedding_index": 16297}, {"title": "On the feature learning in diffusion models", "link_suffix": "/forum?id=JjdU6ysnCr", "link": "https://openreview.net/forum?id=JjdU6ysnCr", "pdf_link": "https://openreview.net/pdf?id=JjdU6ysnCr", "keywords": "Diffusion model, Feature learning", "abstract": "The predominant success of diffusion models in generative modeling has spurred significant interest in understanding their theoretical foundations. In this work, we propose a feature learning framework aimed at analyzing and comparing the training dynamics of diffusion models with those of traditional classification models. Our theoretical analysis demonstrates that, under identical settings, neural networks trained for classification tend to prioritize learning specific patterns in the data, often focusing on easy-to-learn features. In contrast, diffusion models, due to the denoising objective, are encouraged to learn more balanced and comprehensive representations of the data. To support these theoretical insights, we conduct several experiments on both synthetic and real-world datasets, which empirically validate our findings and underscore the distinct feature learning dynamics in diffusion models compared to classification.", "title_embedding_index": 16273, "title_abs_embedding_index": 16298}, {"title": "AttentionNCE: Contrastive Learning with Instance Attention", "link_suffix": "/forum?id=FfHGAAoSVJ", "link": "https://openreview.net/forum?id=FfHGAAoSVJ", "pdf_link": "https://openreview.net/pdf?id=FfHGAAoSVJ", "keywords": "Contrastive Learning, Image Classification", "abstract": "Contrastive learning has found extensive applications in computer vision, natural language processing, and information retrieval, significantly advancing the frontier of self-supervised learning. However, the limited availability of labels poses challenges in contrastive learning, as the positive and negative samples can be noisy, adversely affecting model training. To address this, we introduce instance-wise attention into the variational lower bound of contrastive loss, and proposing the AttentionNCE loss accordingly. AttentioNCE incorporates two key components that enhance contrastive learning performance: First, it replaces instance-level contrast with attention-based sample prototype contrast, helping to mitigate noise disturbances. Second, it introduces a flexible hard sample mining mechanism, guiding the model to focus on high-quality, informative samples. Theoretically, we demonstrate that optimizing AttentionNCE is equivalent to optimizing the variational lower bound of contrastive loss, offering a worst-case guarantee for maximum likelihood estimation under noisy conditions. Empirically, we apply AttentionNCE to popular contrastive learning frameworks and validate its effectiveness. The code is released at: \n\\url{https://anonymous.4open.science/r/AttentioNCE-55EB}", "title_embedding_index": 16274, "title_abs_embedding_index": 16299}]
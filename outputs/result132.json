[{"title": "Multi-expert collaboration: Enhancing heterogeneous knowledge independence and alignment in knowledge distillation", "link_suffix": "/forum?id=LPDJfudDTM", "link": "https://openreview.net/forum?id=LPDJfudDTM", "pdf_link": "https://openreview.net/pdf?id=LPDJfudDTM", "keywords": "knowledge distillation, heterogeneous knowledge, multi-teacher knowledge distillation, independence and alignment", "abstract": "Heterogeneous multi-teacher Knowledge distillation attempt to learn a versatile student neural network from multiple pre-trained heterogeneous teachers. But current methods face issues with a lack of independence and alignment in heterogeneous knowledge. To address this issue, we propose a novel method called Multi-Expert Collaboration (MEC). Our approach aggregates multiple expert classifiers within the student model, replacing the conventional single-head architecture. By ensuring that each expert's independent classifier operates without interfering with others, we enhance the independence of heterogeneous knowledge. Inspired by Helmholtz Free Energy (HFE) theory, we introduce an anchor-based HFE self-normalization strategy to align the heterogeneous knowledge effectively. This method ensures consistent energy levels across all classifiers, allowing the appropriate classifier to achieve the highest confidence for in-distribution data. Extensive experiments on CIFAR-100 and ImageNet-100 datasets demonstrate that MEC significantly outperforms existing heterogeneous multi-teacher knowledge distillation methods, achieving an average accuracy improvement of over 10%.", "title_embedding_index": 6550, "title_abs_embedding_index": 6575}, {"title": "Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors", "link_suffix": "/forum?id=8WQ7VTfPTl", "link": "https://openreview.net/forum?id=8WQ7VTfPTl", "pdf_link": "https://openreview.net/pdf?id=8WQ7VTfPTl", "keywords": "Large Language Models, Activation Steering, Dynamic Steering Vector", "abstract": "Large language models (LLMs) have achieved remarkable performance across many tasks, yet aligning them with desired behaviors remains challenging. Activation intervention has emerged as an effective and economical method to modify the behavior of LLMs. Despite considerable interest in this area, current intervention methods exclusively employ a fixed steering vector to modify model activations, lacking adaptability to diverse input semantics. To address this limitation, we propose Semantics-Adaptive Dynamic Intervention (SADI), a novel method that constructs a dynamic steering vector to intervene model activations at inference time. More specifically, SADI utilizes activation differences in contrastive pairs to precisely identify critical elements of an LLM (i.e., attention heads, hidden states, and neurons) for targeted intervention. During inference, SADI dynamically steers model behavior by scaling element-wise activations based on the directions of input semantics. Experimental results show that SADI outperforms established baselines by substantial margins, improving task performance without training. SADI's cost-effectiveness and generalizability across various LLM backbones and tasks highlight its potential as a versatile alignment technique. We will release the code to foster research in this area.", "title_embedding_index": 6551, "title_abs_embedding_index": 6576}, {"title": "Can Stability be Detrimental? Better Generalization through Gradient Descent Instabilities", "link_suffix": "/forum?id=zPaTnGjgpa", "link": "https://openreview.net/forum?id=zPaTnGjgpa", "pdf_link": "https://openreview.net/pdf?id=zPaTnGjgpa", "keywords": "Gradient Descent, Generalization, Optimization, Stability", "abstract": "Traditional analyses of gradient descent optimization show that, when the largest eigenvalue of the loss Hessian - often referred to as the sharpness - is below a critical learning-rate threshold, then training is \u2018stable\u2019 and training loss decreases monotonically. Recent studies, however, have suggested that the majority of modern deep neural networks achieve good performance despite operating outside this stable regime. In this work, we demonstrate that such instabilities, induced by large learning rates, move model parameters toward flatter regions of the loss landscape. Our crucial insight lies in noting that, during these instabilities, the orientation of the Hessian eigenvectors rotate. This, we conjecture, allows the model to explore regions of the loss landscape that display more desirable geometrical properties for generalization, such as flatness. These rotations are a consequence of network depth, and we prove that for any network with depth $> 1$, unstable growth in parameters cause rotations in the principal components of the Hessian, which promote exploration of the parameter space away from unstable directions. Our empirical studies reveal an implicit regularization effect in gradient descent with large learning rates operating beyond the stability threshold. We find these lead to excellent generalization performance on modern benchmark datasets.", "title_embedding_index": 6552, "title_abs_embedding_index": 6577}, {"title": "Rethinking Modality Alignment in Multi-Modal Large Language Models", "link_suffix": "/forum?id=RLhEGWt94S", "link": "https://openreview.net/forum?id=RLhEGWt94S", "pdf_link": "https://openreview.net/pdf?id=RLhEGWt94S", "keywords": "Multi-Modal Large Language Model", "abstract": "Multi-modal Large Language Models (MLLMs) demonstrate remarkable proficiency in addressing a wide range of Vision-Language (VL) tasks. However, most advancements have been focused on adapting to longer sequences containing detailed visual information and scaling up high-quality VL corpus. \nPrevalent VL alignment modules (e.g., the adapter layer in LLaVA and the Q-former in BLIP-2)\nstruggle to align the LLM and visual inputs adequately. \nThey rely on the powerful LLM to decode sub-optimally aligned visual features into the desired formatted word sequences, which can result in hallucinations and reduce the reliability of visual reasoning. Additionally, the LLM's causal attention does not effectively capture the relationship between visual embeddings. To tackle these issues, we rethink the modality alignment in MLLMs and present VL Superior Alignment (VLSA),\na framework designed to decouple the alignment of the LLM with visual inputs. VLSA has two main stages: The perception alignment stage, which consists of innovative compressive high-resolution image encoding and reconstructive training based on Latent Diffusion Models (LDM), reduces the information loss in visual encoding and better models the spatial connection between images' subgraphs. The cognition alignment stage strengthens the LLM in understanding high-level visual semantics and low-level image appearances simultaneously. This advancement is actualized by following the instructions of predicting the codebook indices generated from a Vector Quantized (VQ) encoder and the pixel values within designated areas. Extensive experiments across 20 MLLM benchmarks underscore the consistent improvements brought by VLSA, demonstrating the effectiveness of our methods. In service to the MLLM research community, our code and model checkpoints will be publicly available.", "title_embedding_index": 6553, "title_abs_embedding_index": 6578}, {"title": "LLM-Mediated Guidance of MARL Systems", "link_suffix": "/forum?id=Zdl2i7RKmz", "link": "https://openreview.net/forum?id=Zdl2i7RKmz", "pdf_link": "https://openreview.net/pdf?id=Zdl2i7RKmz", "keywords": "Multi-Agent Reinforcement Learning, Large Language Model, Human-AI Interaction, Multi-Agent System, Aerial Wildfire Suppression", "abstract": "In complex multi-agent environments, achieving efficient learning and desirable behaviours is a significant challenge for Multi-Agent Reinforcement Learning (MARL) systems. This work explores the potential of combining MARL with Large Language Model (LLM)-mediated interventions to guide agents toward more desirable behaviours. Specifically, we investigate how LLMs can be used to interpret and facilitate interventions that shape the learning trajectories of multiple agents. We experimented with two types of interventions, referred to as controllers: a Natural Language (NL) Controller and a Rule-Based (RB) Controller. The NL Controller, which uses an LLM to simulate human-like interventions, showed a stronger impact than the RB Controller. Our findings indicate that agents particularly benefit from early interventions, leading to more efficient training and higher performance. Both intervention types outperform the baseline without interventions, highlighting the potential of LLM-mediated guidance to accelerate training and enhance MARL performance in challenging environments.", "title_embedding_index": 6554, "title_abs_embedding_index": 6579}, {"title": "Vector Grimoire: Codebook-based Shape Generation under Raster Image Supervision", "link_suffix": "/forum?id=RBp0x7rkMO", "link": "https://openreview.net/forum?id=RBp0x7rkMO", "pdf_link": "https://openreview.net/pdf?id=RBp0x7rkMO", "keywords": "Image Generation, Scalable Vector Graphics, VQ-VAE, Differentiable Rasterizer", "abstract": "Scalable Vector Graphics (SVG) is a popular format on the web and in the design industry. \nHowever, despite the great strides made in generative modeling,\nSVG has remained underexplored due to the discrete and complex nature of such\ndata. We introduce GRIMOIRE, a text-guided SVG generative model that is comprised\nof two modules: A Visual Shape Quantizer (VSQ) learns to map raster\nimages onto a discrete codebook by reconstructing them as vector shapes, and\nan Auto-Regressive Transformer (ART) models the joint probability distribution\nover shape tokens, positions and textual descriptions, allowing us to generate vector \ngraphics from natural language. Unlike existing models that require direct\nsupervision from SVG data, GRIMOIRE learns shape image patches using only\nraster image supervision which opens up vector generative modeling to significantly more data. \nWe demonstrate the effectiveness of our method by fitting\nGRIMOIRE for closed filled shapes on the MNIST and for outline strokes on icon and font data,\nsurpassing previous image-supervised methods in generative quality and vector-supervised approach in flexibility.", "title_embedding_index": 6555, "title_abs_embedding_index": 6580}, {"title": "Torque-Aware Momentum", "link_suffix": "/forum?id=aF1jasJeRy", "link": "https://openreview.net/forum?id=aF1jasJeRy", "pdf_link": "https://openreview.net/pdf?id=aF1jasJeRy", "keywords": "optimization, deep learning, momentum", "abstract": "Efficiently exploring complex loss landscapes is key  to the performance of deep neural networks. While momentum-based optimizers are widely used in state-of-the-art setups, classical momentum can still struggle with large, misaligned gradients, leading to oscillations. To address this,  we propose Torque-Aware Momentum (TAM), which introduces a damping factor based on the angle between the new gradients and previous momentum, stabilizing the update direction during training. Empirical results show that TAM, which can be combined with both SGD and Adam, enhances  exploration, handles distribution shifts more effectively,  and improves generalization performance across various tasks, including image classification and large language model fine-tuning, when compared to classical momentum-based optimizers.", "title_embedding_index": 6556, "title_abs_embedding_index": 6581}, {"title": "Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes", "link_suffix": "/forum?id=Nx4PMtJ1ER", "link": "https://openreview.net/forum?id=Nx4PMtJ1ER", "pdf_link": "https://openreview.net/pdf?id=Nx4PMtJ1ER", "keywords": "causality, dynamical systems, stochastic processes, causal discovery, signature kernel", "abstract": "Inferring the causal structure underlying stochastic dynamical systems from observational data holds great promise in domains ranging from science and health to finance. Such processes can often be accurately modeled via stochastic differential equations (SDEs), which naturally imply causal relationships via `which variables enter the differential of which other variables'. In this paper, we develop conditional independence (CI) constraints on coordinate processes over selected intervals that are Markov with respect to the acyclic dependence graph (allowing self-loops) induced by a general SDE model. We then provide a sound and complete causal discovery algorithm, capable of handling both fully and partially observed data, and uniquely recovering the underlying or induced ancestral graph by exploiting time directionality assuming a CI oracle. Finally, to make our algorithm practically usable, we also propose a flexible, consistent signature kernel-based CI test to infer these constraints from data. We extensively benchmark the CI test in isolation and as part of our causal discovery algorithms, outperforming existing approaches in SDE models and beyond.", "title_embedding_index": 6557, "title_abs_embedding_index": 6582}, {"title": "MathGLM-Vision: Solving Mathematical Problems with Multi-Modal Large Language Model", "link_suffix": "/forum?id=c8QlNuhy2G", "link": "https://openreview.net/forum?id=c8QlNuhy2G", "pdf_link": "https://openreview.net/pdf?id=c8QlNuhy2G", "keywords": "Mathematical Reasoning, Multi-modal large language model", "abstract": "Large language models (LLMs) have demonstrated significant capabilities in mathematical reasoning, particularly with text-based mathematical problems. However, current multi-modal large language models (MLLMs), especially those specialized in mathematics, tend to focus predominantly on solving geometric problems but ignore the diversity of visual information available in other areas of mathematics. Moreover, the geometric information for these specialized mathematical MLLMs is derived from several public datasets, which are typically limited in diversity and complexity. To address these limitations, we aim to construct a fine-tuning dataset named MathVL, and develop a series of specialized mathematical MLLMs termed MathGLM-Vision by conducting Supervised Fine-Tuning (SFT) on MathVL with various parameter-scale backbones. To extensively evaluate the effectiveness of MathGLM-Vision, we conduct experiments on several public benchmarks and our curated MathVL-test benchmark consisting of 2,000 problems. Experimental results demonstrate that MathGLM-Vision achieves significant improvements compared with some existing models, including backbone models and open-source mathematical MLLMs. These findings indicate the importance of diversity dataset in enhancing the mathematical reasoning abilities of MLLMs.", "title_embedding_index": 6558, "title_abs_embedding_index": 6583}, {"title": "ADAM Optimization with Adaptive Batch Selection", "link_suffix": "/forum?id=BZrSCv2SBq", "link": "https://openreview.net/forum?id=BZrSCv2SBq", "pdf_link": "https://openreview.net/pdf?id=BZrSCv2SBq", "keywords": "ADAM, Combinatorial Bandit, Importance Sampling, Mini-Batch, Optimization, Regret Minimization", "abstract": "Adam is a widely used optimizer in neural network training due to its adaptive learning rate. \nHowever, its uniform sampling of training data leads to inefficiencies, especially as models scale.\nTo address this, a prior work proposed adapting the sampling distribution using a bandit framework to select samples adaptively.\nWhile promising, both the original Adam and its bandit-based variant suffer from flawed theoretical guarantees.\nIn this paper, we introduce Adam with Combinatorial Bandit Sampling (AdamCB), which integrates combinatorial bandit techniques into Adam to resolve these issues. \nAdamCB provides richer feedback from multiple actions, enhancing both theoretical guarantees and practical performance. \nOur rigorous regret analysis shows that AdamCB achieves faster convergence than both the original Adam and its variants. \nExtensive experiments across various datasets demonstrate that AdamCB consistently outperforms existing Adam-based methods, making it the first to offer both provable guarantees and practical efficiency for Adam with adaptive batch selection.", "title_embedding_index": 6559, "title_abs_embedding_index": 6584}, {"title": "Tailoring Mixup to Data for Calibration", "link_suffix": "/forum?id=3ygfMPLv0P", "link": "https://openreview.net/forum?id=3ygfMPLv0P", "pdf_link": "https://openreview.net/pdf?id=3ygfMPLv0P", "keywords": "mixup, calibration, confidence, robustness", "abstract": "Among all data augmentation techniques proposed so far, linear interpolation of training samples, also called Mixup, has found to be effective for a large panel of applications.\n  Along with improved performance, Mixup is also a good technique for improving calibration and predictive confidence.\n  However, mixing data carelessly can lead to manifold mismatch, i.e., synthetic data lying outside original class manifolds, which can deteriorate calibration of confidence.\n  In this work, we show that the likelihood of manifold mismatch increases with the distance between data to mix.\n  To this end, we propose to dynamically change the underlying distributions of interpolation coefficients depending on the similarity between samples to mix, and define a flexible framework to do so without losing in diversity. We provide extensive experiments for classification and regression tasks, showing that our proposed method improves performance and calibration of models, while being much more efficient.", "title_embedding_index": 6560, "title_abs_embedding_index": 6585}, {"title": "Structural Multi-view Clustering Network via Heterogeneous Random Walks", "link_suffix": "/forum?id=gLHuAYGs6a", "link": "https://openreview.net/forum?id=gLHuAYGs6a", "pdf_link": "https://openreview.net/pdf?id=gLHuAYGs6a", "keywords": "multi-view clustering; sample structure; heterogeneous graph; heterogeneous random walks", "abstract": "Multi-view clustering, which aims to partition data samples into disjoint clusters by leveraging information from multiple views, has been shown to be highly effective when incorporating structure information, as widely acknowledged in recent works. This paper presents a novel structural multi-view clustering network via heterogeneous random walks, guided by a unified sample-level structure to enhance clustering performance. We first construct a multi-view heterogeneous graph consisting of sample nodes and view nodes, capturing correlations between views while preserving their specific structures. Then, a multi-step random walk strategy on the heterogeneous graph is introduced to explore high-order sample structures across various views, ensuring that each view structure is taken into account. Based on this, a lightweight network is designed to facilitate structure learning both within-view and cross-view, guided by the unified structure derived from heterogeneous random walks, ultimately achieving representations that are conducive to clustering. Extensive experiments on five real-world datasets demonstrate the superiority of the proposed method.", "title_embedding_index": 6561, "title_abs_embedding_index": 6586}, {"title": "A Provable Quantile Regression Adapter via Transfer Learning", "link_suffix": "/forum?id=zvoM1Wastw", "link": "https://openreview.net/forum?id=zvoM1Wastw", "pdf_link": "https://openreview.net/pdf?id=zvoM1Wastw", "keywords": "Transfer Learning, Adaptation, Quantile Regression, High-dimensional Statistics, Convergence Rate", "abstract": "Adapter-tuning strategy is an efficient method in machine learning that introduces lightweight and sparse trainable parameters into a pretrained model without altering the original parameters (e.g., low-rank adaptation of large language models). Nevertheless, most existing adapter-tuning approaches are developed for risk-neutral task objectives and the study on the adaptation of risk-sensitive tasks is limited. In this paper, we propose a transfer learning-based quantile regression adapter to improve the estimation of quantile-related risks by leveraging existing pretrained models. We also establish a theoretical analysis to quantify the efficacy of our quantile regression adapter. Particularly, we introduce a transferability measure that characterizes the intrinsic similarity between the pretrained model and downstream task in order to explain when transferring knowledge can improve downstream learning. Under appropriate transferability and structural assumptions, we establish error bounds for the estimation and out-of-sample prediction quality by our quantile regression adapter. Compared to vanilla approaches without transfer learning, our method is provably more sample efficient. Extensive numerical simulations are conducted to demonstrate the superiority and robustness of our method empirically.", "title_embedding_index": 6562, "title_abs_embedding_index": 6587}, {"title": "Statistical Test on Diffusion Model-based Anomaly Detection by Selective Inference", "link_suffix": "/forum?id=WrdLgVY5ZH", "link": "https://openreview.net/forum?id=WrdLgVY5ZH", "pdf_link": "https://openreview.net/pdf?id=WrdLgVY5ZH", "keywords": "diffusion models, anomaly detection, statistical test, selective inference", "abstract": "Advancements in AI image generation, particularly diffusion models, have progressed rapidly. However, the absence of an established framework for quantifying the reliability of AI-generated images hinders their use in critical decision-making tasks, such as medical image diagnosis. In this study, we address the task of detecting anomalous regions in medical images using diffusion models and propose a statistical method to quantify the reliability of the detected anomalies. The core concept of our method involves a selective inference framework, wherein statistical tests are conducted under the condition that the images are produced by a diffusion model. With our approach, the statistical significance of anomaly detection results can be quantified in the form of a $p$-value, enabling decision-making with controlled error rates, as is standard in medical practice. We demonstrate the theoretical soundness and practical effectiveness of our statistical test through numerical experiments on both synthetic and brain image datasets.", "title_embedding_index": 6563, "title_abs_embedding_index": 6588}, {"title": "SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction", "link_suffix": "/forum?id=UjSmUlUU6y", "link": "https://openreview.net/forum?id=UjSmUlUU6y", "pdf_link": "https://openreview.net/pdf?id=UjSmUlUU6y", "keywords": "Large Language Models, Long-Context, KV Cache", "abstract": "Recent advancements in large language models (LLMs) have extended their capabilities to handle long contexts. However, increasing the number of model layers and the length of input sequences significantly escalates the memory required to store key-value (KV) cache, posing challenges for efficient inference. To mitigate this issue, we present SimLayerKV, a simple yet effective method that reduces inter-layer KV cache redundancies by selectively dropping cache in identified lazy layers. Our approach is based on the observation that certain layers in long-context LLMs exhibit \"lazy\" behavior, contributing less to modeling long-range dependencies compared to non-lazy layers. By analyzing attention weight patterns, we find that the behavior of these lazy layers is consistent across tokens for a given input. This insight motivates our SimLayerKV, which identifies lazy layers and reduces their KV cache accordingly. SimLayerKV is training-free, generalizable, and can be implemented with only seven lines of code. We conduct extensive experiments on three representative LLMs, e.g., LLaMA2-7B, LLaMA3-8B, and Mistral-7B across 16 tasks from the LongBench benchmark. The results demonstrate that SimLayerKV achieves a KV cache compression ratio of 5$\\times$ with only a 1.2% performance drop when combined with 4-bit quantization.", "title_embedding_index": 6564, "title_abs_embedding_index": 6589}, {"title": "MIRACLE 3D: Memory-efficient Integrated Robust Approach for Continual Learning on 3D Point Clouds via Shape Model Reconstruction", "link_suffix": "/forum?id=ANBuEJesgx", "link": "https://openreview.net/forum?id=ANBuEJesgx", "pdf_link": "https://openreview.net/pdf?id=ANBuEJesgx", "keywords": "Continual learning, Point cloud processing", "abstract": "In this paper, we introduce a novel framework for memory-efficient and privacy-preserving continual learning in 3D object classification. Unlike conventional memory-based approaches in continual learning that require storing numerous exemplars, our method constructs a compact shape model for each class, retaining only the mean shape along with a few key modes of variation. This strategy not only enables the generation of diverse training samples while drastically reducing memory usage but also enhances privacy by eliminating the need to store original data. To further improve model robustness against input variations\u2014an issue common in 3D domains due to the absence of strong backbones and limited training data\u2014we incorporate Gradient Mode Regularization. This technique enhances model stability and broadens classification margins, resulting in accuracy improvements. We validate our approach through extensive experiments on the ModelNet40, ShapeNet, and ScanNet datasets, where we achieve state-of-the-art performance. Notably, our method consumes only 15% of the memory required by competing methods on the ModelNet40 and ShapeNet, while achieving comparable performance on the challenging ScanNet dataset with just 8.5% of the memory. These results underscore the scalability, effectiveness, and privacy-preserving strengths of our framework for 3D object classification.", "title_embedding_index": 6565, "title_abs_embedding_index": 6590}, {"title": "Neural Description Logic Reasoning over Incomplete Knowledge Bases", "link_suffix": "/forum?id=4qRCiEZGKd", "link": "https://openreview.net/forum?id=4qRCiEZGKd", "pdf_link": "https://openreview.net/pdf?id=4qRCiEZGKd", "keywords": "concept learning, description logic, knowledge bases, neural reasoner, embeddings, SROIQ, atomic concepts", "abstract": "Concept learning exploits background knowledge in the form of description logic axioms to learn explainable classification models from knowledge bases. Despite recent breakthroughs in the runtime of concept learners, most approaches still cannot be deployed on real-world knowledge bases. This is due to their use of description logic reasoners, which do not scale to large datasets. Moreover, these reasoners are not robust against inconsistencies and erroneous data, both being hallmarks of real datasets. We address this challenge by presenting a novel neural reasoner dubbed \\approach. Our reasoner relies on embeddings to rapidly approximate the results of a symbolic reasoner. We show that our reasoner solely requires retrieving instances for atomic concepts and existential restrictions to retrieve the instances of any concept in $\\mathcal{SROIQ}$. Importantly, our experiments also suggest that our reasoner is robust against missing and erroneous data.", "title_embedding_index": 6566, "title_abs_embedding_index": 6591}, {"title": "Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain", "link_suffix": "/forum?id=z5Th95xtBW", "link": "https://openreview.net/forum?id=z5Th95xtBW", "pdf_link": "https://openreview.net/pdf?id=z5Th95xtBW", "keywords": "Syntactic structure probe, Large language models, stereo-electroencephalography, Syntactic representation alignment", "abstract": "Large Language Models (LLMs) have shown impressive capabilities across a range of language tasks. However, questions remain about whether LLMs effectively encode linguistic structures such as phrases and sentences and how closely these representations align with those in the human brain. Here, we introduce the Hierarchical Frequency Tagging Probe (HFTP) to probe the phrase and sentence representations in LLMs and the human brain in a unified manner. HFTP utilizes frequency-domain analysis to identify which LLM computational modules (multilayer perceptron (MLP) neurons) or human cortical areas encode phrases or sentences. Human brain activity is recorded using intracranial electrodes. The results revealed distinct sensitivities to sentences and phrases across various layers of LLMs (including GPT-2, Gemma, Llama 2, Llama 3.1, and GLM-4) and across different regions of the human brain. Notably, while LLMs tend to process sentences and phrases within similar layers, the human brain engages distinct regions to process these two syntactic levels. Additionally, representational similarity analysis (RSA) shows that the syntactic representations of all five LLMs are more aligned with neural representations in the left hemisphere\u2014the dominant hemisphere for language processing. Among the LLMs, GPT-2 and Llama 2 show the greatest similarity to human brain syntactic representations, while Llama 3.1 demonstrates a weaker resemblance. Overall, our findings provide deeper insights into syntactic processing in LLMs and highlight the effectiveness of HFTP as a versatile tool for detecting syntactic structures across diverse LLM architectures and parameters, as well as in parallel analyses of human brains and LLMs, thereby bridging computational linguistics and cognitive neuroscience.", "title_embedding_index": 6567, "title_abs_embedding_index": 6592}, {"title": "Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning", "link_suffix": "/forum?id=owP2mymrTD", "link": "https://openreview.net/forum?id=owP2mymrTD", "pdf_link": "https://openreview.net/pdf?id=owP2mymrTD", "keywords": "large language model, function calling, instruction tuning, synthetic data", "abstract": "Large Language Models (LLMs) have exhibited significant potential in performing diverse tasks, including the ability to call functions or use external tools to enhance their performance. While current research on function calling by LLMs primarily focuses on single-turn interactions, this paper addresses the overlooked necessity for LLMs to engage in multi-turn function calling\u2014critical for handling compositional, real-world queries that require planning with functions but not only use functions. To facilitate this, we introduce an approach, BUTTON, which generates synthetic compositional instruction tuning data via bottom-up instruction construction and top-down trajectory generation. In the bottom-up phase, we generate simple atomic tasks based on real-world scenarios and build compositional tasks using heuristic strategies based on atomic tasks. Corresponding functions are then developed for these compositional tasks. The top-down phase features a multi-agent environment where interactions among simulated humans, assistants, and tools are utilized to gather multi-turn function calling trajectories. This approach ensures task compositionality and allows for effective function and trajectory generation by examining atomic tasks within compositional tasks. We produce a dataset BUTTONInstruct comprising 8k data points and demonstrate its effectiveness through extensive experiments across various LLMs.", "title_embedding_index": 6568, "title_abs_embedding_index": 6593}, {"title": "GNNAS-Dock: Budget Aware Algorithm Selection with Graph Neural Networks for Molecular Docking", "link_suffix": "/forum?id=An87ZnPbkT", "link": "https://openreview.net/forum?id=An87ZnPbkT", "pdf_link": "https://openreview.net/pdf?id=An87ZnPbkT", "keywords": "molecular docking, automated algorithm selection, graph neural networks", "abstract": "Molecular docking is a major element in drug discovery and design. It enables the prediction of ligand-protein interactions by simulating the binding of small molecules to proteins. Despite the availability of numerous docking algorithms, there is no single algorithm consistently outperforms the others across a diverse set of docking scenarios. This paper introduces GNNAS-Dock, a novel Graph Neural Network (GNN)-based automated algorithm selection system for molecular docking in blind docking situations. GNNs are accommodated to process the complex structural data of both ligands and proteins. They benefit from the inherent graph-like properties to predict the performance of various docking algorithms under different conditions. The present study pursues two main objectives: 1) predict the performance of each candidate docking algorithm, in terms of Root Mean Square Deviation (RMSD), thereby identifying the most accurate method for specific scenarios; and 2) choose the best computationally efficient docking algorithm for each docking case, aiming to reduce the time required for docking while maintaining high accuracy. We validate our approach on PDBBind 2020 refined set, which contains about 5,300 pairs of protein-ligand complexes. Our strategy is performed across a portfolio of 6 different state-of-the-art docking algorithms. To be specific, the candidate algorithms are DiffDock, DSDP, TankBind, GNINA, SMINA, Qvina-W. We additionally combine p2rank with GNINA, SMINA and Qvina-W for docking site prediction. Therefore, there are totally 9 different algorithms for selection. Our algorithm selection model achieves a mean RMSD of approximately 1.74 \u00c5, significantly improving upon the top performing docking algorithm (DiffDock), which has a mean RMSD of 2.95 \u00c5. Moreover, when making selection in consideration of computational efficiency, our model demonstrates a success rate of 79.73% in achieving an RMSD below the 2 \u00c5 threshold, with a mean RMSD value of 2.75 \u02daA and an average processing time of about 29.05 seconds per instance. In contrast, the remaining docking algorithms like TankBind, though faster with a processing time of merely 0.03 seconds per instance, only achieve an RMSD below the 2 \u00c5 threshold in less than 60% of cases. These findings demonstrate the capability of GNN-based algorithm selection to significantly enhance docking performance while effectively reducing the computational time required, balancing efficiency with precision in molecular docking.", "title_embedding_index": 6569, "title_abs_embedding_index": 6594}, {"title": "Private Blind Model Averaging \u2013 Distributed, Non-interactive, and Convergent", "link_suffix": "/forum?id=NqkSUwMc0K", "link": "https://openreview.net/forum?id=NqkSUwMc0K", "pdf_link": "https://openreview.net/pdf?id=NqkSUwMc0K", "keywords": "differential privacy, scalable distributed learning, privacy-preserving machine learning, privacy, federated learning, non-interactivity", "abstract": "Scalable distributed differentially private learning would benefit notably from reduced communication and synchronization overhead. The current best methods, based on gradient averaging, inherently require many synchronization rounds. In this work, we analyze blind model averaging for convex and smooth empirical risk minimization (ERM): each user first locally finishes training a model and then submits the model for secure averaging without any client-side online synchronization. This setting lends itself not only to data point-level privacy but also to flexible user-level privacy, where the combined impact of the user\u2019s trained model does not depend on the number of data points used for training.In detail, we analyze the utility side of blind model averaging for support vector machines (SVMs) and the inherently multi-class Softmax regression (SoftmaxReg). On the theory side, we use strong duality to show for SVMs that blind model averaging converges toward centralized training performance if the task is robust against L2-regularization, i.e. if increasing the regularization weight does not destroy utility. Furthermore, we provide theoretical and experimental evidence that blind averaged Softmax Regression works well: we prove strong convexity of the dual problem by proving smoothness of the primal problem. Using this result, we also conclude the first output perturbation bounds for Softmax regression. On the experimental side, we support our theoretical SVM convergence. Furthermore, we observe hints of an even more fine-granular connection between good utility of model averaging and mid-range regularization weights which lead to compelling utility-privacy-tradeoffs for SVM and Softmax regression on 3 datasets (CIFAR-10, CIFAR-100, and federated EMNIST embeddings). We additionally provide ablation for an artificially extreme non-IID scenario.", "title_embedding_index": 6570, "title_abs_embedding_index": 6595}, {"title": "Unveiling Context-Aware Criteria in Self-Assessing LLMs", "link_suffix": "/forum?id=6GvJf1AWvF", "link": "https://openreview.net/forum?id=6GvJf1AWvF", "pdf_link": "https://openreview.net/pdf?id=6GvJf1AWvF", "keywords": "Autonomous Evaluation, Model Alignment, SLM", "abstract": "The use of large language models (LLMs) as evaluators has garnered significant\nattention due to their potential to rival human-level evaluations in long-form re-\nsponse assessments. However, current LLM evaluators rely heavily on static,\nhuman-defined criteria, limiting their ability to generalize across diverse gener-\native tasks and incorporate context-specific knowledge. In this paper, we pro-\npose a novel Self-Assessing LLM framework that integrates Context-Aware Cri-\nteria (SALC) with dynamic knowledge tailored to each evaluation instance. This\ninstance-level knowledge enhances the LLM evaluator\u2019s performance by provid-\ning relevant, context-aware insights that pinpoint the important criteria specific to\nthe current instance. Additionally, the proposed framework adapts seamlessly to\nvarious tasks without relying on predefined human criteria, offering a more flex-\nible evaluation approach. Empirical evaluations demonstrate that our approach\nsignificantly outperforms existing baseline evaluation frameworks, yielding im-\nprovements ranging from 5% across a wide variety of datasets. Furthermore,\nby leveraging knowledge distillation techniques, we fine-tuned smaller language\nmodels for criteria generation and evaluation, achieving comparable or superior\nperformance to larger models with much lower cost. Our method also exhibits a\n5% improvement on the Alpaca leaderboard when employed for preference data\ngeneration in Direct Preference Optimization (DPO), underscoring its efficacy as\na robust and scalable evaluation framework.", "title_embedding_index": 6571, "title_abs_embedding_index": 6596}, {"title": "GameInstruct: Teaching Machines to Reason via Chameleon Game", "link_suffix": "/forum?id=vePZdNvrO9", "link": "https://openreview.net/forum?id=vePZdNvrO9", "pdf_link": "https://openreview.net/pdf?id=vePZdNvrO9", "keywords": "Large Language Model, Self-play, Alignment", "abstract": "Self-play has emerged as a promising approach for generating alignment data to reduce the data annotation costs during the alignment process.\nBy introducing specific game rules and utilizes the model\u2019s own language capabilities to generate data samples, self-play has achieved promising results.\nHowever, traditional self-play methods face two major challenges: insufficient data diversity during self-iterative training and difficulties in reward signal design.\nTo solve these problems, this paper introduces GameInstruct, a complex multi-player adversarial environment that increases the complexity of self-play generated data during self-iterative training.\nSpecifically, we employ the ``Chameleon Game'', where interactions between multiple players raise the diversity of the generated data, improving the model\u2019s reasoning abilities, \nAdditionally, we further propose a dynamic reward algorithm to capture signals within player conversations during the whole game.\nExperimental results show that compared to existing self-play methods, GameInstruct achieves significant improvements on the HuggingFace Open-LLM-Leaderboard reasoning benchmark while demonstrating continuous improvement and increasing data diversity during self-iterative training.", "title_embedding_index": 6572, "title_abs_embedding_index": 6597}, {"title": "Designing Deep Learning Programs with Large Language Models", "link_suffix": "/forum?id=ejgY0DyaQD", "link": "https://openreview.net/forum?id=ejgY0DyaQD", "pdf_link": "https://openreview.net/pdf?id=ejgY0DyaQD", "keywords": "Program Synthesis, Large Language Model Agents, Dataset, Benchmark", "abstract": "The process of utilizing deep neural architectures to solve tasks differs significantly from conventional programming due to its complexity and the need for specialized knowledge. While code generation technologies have made substantial progress, their application in deep learning programs requires a distinct approach. Although previous research has shown that large language model agents perform well in areas such as data science, neural architecture search, and hyperparameter tuning, the task of proposing and refining deep neural architectures at a high level remains largely unexplored. Current methods for automating the synthesis of deep learning programs often rely on basic code templates or API calls, which restrict the solution space to predefined architectures. In this paper, we aim to bridge the gap between traditional code generation and deep learning program synthesis by introducing the task of Deep Learning Program Design (DLPD), a task of designing an effective deep learning program for the task, along with appropriate architectures and techniques. We propose Deep Ones, a comprehensive solution for DLPD. Our solution includes a large-scale dataset and a lightweight benchmark specifically designed for DLPD. On our benchmark, Llama-3.1 8B, fine-tuned on our dataset, demonstrates better architecture suggestion capability than GPT-4o and better performance than Claude-3.5-Sonnet, showcasing that Deep Ones effectively addresses the challenge of DLPD. Deep Ones will be publicly available, including the dataset, benchmark, codes, and model weights.", "title_embedding_index": 6573, "title_abs_embedding_index": 6598}, {"title": "SafeWatch: An Efficient Safety-Policy Following Video Guardrail Model with Transparent Explanations", "link_suffix": "/forum?id=xjKz6IxgCX", "link": "https://openreview.net/forum?id=xjKz6IxgCX", "pdf_link": "https://openreview.net/pdf?id=xjKz6IxgCX", "keywords": "Video Guardrail Model, Safe Foundation Models, Efficient LLMs Inference, LLM Safety, Multimodal Foundation Models", "abstract": "With the wide adoption of generative AI and rapid growth of high-quality video generation, video guardrails have become more crucial than ever to ensure safety and security across platforms. Current video guardrails, however, are either overly simplistic, relying on pure classification models trained on simple policies with limited number of unsafe categories, which lack detailed explanations, or prompting multimodal large language models (MLLMs) with long safety guidelines, resulting in inefficient and impractical guardrails for real-world content. To bridge this gap, we propose SAFEWATCH, an efficient MLLM-based video guardrail model designed to follow customized safety policies and provide multi-label video guardrail outputs with content-specific explanations in a zero-shot manner. In particular, unlike traditional guardrails that encode entire policies autoregressive, causing inefficiency and bias, SAFEWATCH uniquely encodes each policy trunk in parallel and eliminates their position bias such that all policies are attended simultaneously with equal importance. In addition, to improve efficiency and accuracy, SafeWatch incorporates a policy-aware visual token pruning algorithm that adaptively selects the most relevant video tokens for each policy, discarding noisy or irrelevant information. This allows for more focused, policy-compliant guardrail with significantly reduced computational overhead. Considering the limitations of existing video guardrail benchmarks, we propose SafeWatch-Bench, a large-scale video guardrail benchmark comprising over 2M videos spanning six safety categories which covers over 30 tasks to ensure a comprehensive coverage of all potential safety scenarios. We have conducted extensive experiments, showing that SafeWatch outperforms all SOTA video guardrails on SafeWatch-Bench by 19.6% and 15.4% on existing benchmarks, while reducing inference cost by 25% on average. SafeWatch also demonstrates strong policy-following abilities and outperforms baselines by 20% in zero-shot adaptability to new policies. Additionally, both LLM-as-a-judge and human evaluators\nconfirm the high quality of the explanations provided by SafeWatch.", "title_embedding_index": 6574, "title_abs_embedding_index": 6599}]
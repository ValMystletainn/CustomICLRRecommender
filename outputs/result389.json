[{"title": "Semi-Supervised Underwater Object Detection with Image Enhancement Guided by Attribute-based Data Distribution", "link_suffix": "/forum?id=E0UsEIRBQ8", "link": "https://openreview.net/forum?id=E0UsEIRBQ8", "pdf_link": "https://openreview.net/pdf?id=E0UsEIRBQ8", "keywords": "Semi-supervised learning; Underwater object detection", "abstract": "Semi-supervised underwater object detection aims to improve the performance of detectors on unlabeled underwater images by leveraging knowledge from labeled ones. However, existing methods often overlook the distribution differences between labeled and unlabeled underwater images. In this paper, we propose a novel underwater image enhancement method guided by attribute-based data distribution (UIEG+), which focuses on reducing the discrepancies between enhanced and original unlabeled images across different attributes, thereby effectively addressing the challenges in semi-supervised underwater object detection. Specifically, we explore an underwater image enhancement strategy based on two attributes: color and scale distributions. For the color attribute, we construct a 3-dimensional grid memory, where each grid cell represents a color subspace and records the number of samples in that subspace. Similarly, for the scale attribute, we design a 1-dimensional vector memory that dynamically stores the number of samples in each scale subspace. Subsequently, we propose an effective sampling method to derive parameters for color and scale transformations based on the aforementioned distribution analysis, increasing the likelihood of transformations in low-distribution regions. To evaluate its effetiveness and superiority, massive semi-superivised underwater object deteciton experiments in multiple datasets have been conduted by integrating UIEG+ into existing semi-supervised object detection frameworks. The code will be released.", "title_embedding_index": 19400, "title_abs_embedding_index": 19425}, {"title": "Make It Count: Text-to-Image Generation with an Accurate Number of Objects", "link_suffix": "/forum?id=XYMfoM760h", "link": "https://openreview.net/forum?id=XYMfoM760h", "pdf_link": "https://openreview.net/pdf?id=XYMfoM760h", "keywords": "Text to Image, Computer Vision, Generative Models", "abstract": "Despite the unprecedented success of text-to-image diffusion models, controlling the number of depicted objects using text is surprisingly hard. This is important for various applications from technical documents, to children's books to illustrating cooking recipes. Generating object-correct counts is fundamentally challenging because the generative model needs to keep a sense of separate identity for every instance of the object, even if several objects look identical or overlap, and then carry out a global computation implicitly during generation. It is still unknown if such representations exist. To address count-correct generation, we first identify features within the diffusion model that can carry the object identity information. We then use them to separate and count instances of objects during the denoising process and detect over-generation and under-generation. We fix the latter by training a model that predicts both the shape and location of a missing object, based on the layout of existing ones, and show how it can be used to guide denoising with correct object count. Our approach, CountGen, does not depend on external source to determine object layout, but rather uses the prior from the diffusion model itself, creating prompt-dependent and seed-dependent layouts. Evaluated on two benchmark datasets, we find that CountGen strongly outperforms the count-accuracy of existing baselines.", "title_embedding_index": 19401, "title_abs_embedding_index": 19426}, {"title": "Model Cautiousness: Towards Safer Deployment in Critical Domains", "link_suffix": "/forum?id=yNZi38u52U", "link": "https://openreview.net/forum?id=yNZi38u52U", "pdf_link": "https://openreview.net/pdf?id=yNZi38u52U", "keywords": "cautiousness, calibration, out-of-distribution, safety", "abstract": "In this paper, we introduce the concept of model cautiousness, which stresses the importance of aligning a model's confidence with its accuracy in in-distribution (ID) scenarios while adopting a more uncertain approach in out-of-distribution (OoD) contexts. Model cautiousness is framed as a spectrum between justified confidence and complete ignorance, induced by the inability to clearly define a model's domain of expertise. We propose a rigorous post-hoc approach to obtain a cautious model that merges the confidence scores of the primary confidence model and a model discriminating between ID and OoD inputs. A metric to measure the cautiousness error of a confidence model is introduced. We further present a simple method for discriminating ID from OoD inputs and providing a meaningful confidence estimate that an input is OoD. Finally, we benchmark our approach across 12 question-answering and 37 vision datasets, demonstrating its effectiveness in enhancing model cautiousness compared to standard calibration procedures.", "title_embedding_index": 19402, "title_abs_embedding_index": 19427}, {"title": "OccProphet: Pushing the Efficiency Frontier of Camera-Only 4D Occupancy Forecasting with an Observer-Forecaster-Refiner Framework", "link_suffix": "/forum?id=vC7AlY1ytz", "link": "https://openreview.net/forum?id=vC7AlY1ytz", "pdf_link": "https://openreview.net/pdf?id=vC7AlY1ytz", "keywords": "camera-only occupancy forecasting, efficiency, effectiveness, autonomous driving", "abstract": "Predicting variations in complex traffic environments is crucial for the safety of autonomous driving. Recent advancements in occupancy forecasting have enabled forecasting future 3D occupied status in driving environments by observing historical 2D images. However, high computational demands make occupancy forecasting less efficient during training and inference stages, hindering its feasibility for deployment on edge agents. In this paper, we propose a novel framework, \\textit{i.e.}, OccProphet, to efficiently and effectively learn occupancy forecasting with significantly lower computational requirements while maintaining forecasting accuracy. OccProphet comprises three lightweight components: Observer, Forecaster, and Refiner. The Observer extracts spatio-temporal features from 3D using the proposed Efficient 4D Aggregation with Tripling-Attention Fusion, while the Forecaster and Refiner conditionally predict and refine future occupancy inferences. Experimental results on nuScenes, Lyft-Level5, and nuScenes-Occupancy datasets demonstrate that OccProphet is both training- and inference-friendly. OccProphet reduces 58%$\\sim$78% of the computational cost with a 2.6$\\times$ speedup compared with the state-of-the-art Cam4DOcc. Moreover, it achieves 4%$\\sim$18% relatively higher forecasting accuracy. The code will be publicly available.", "title_embedding_index": 19403, "title_abs_embedding_index": 19428}, {"title": "HSR-Enhanced Sparse Attention Acceleration", "link_suffix": "/forum?id=bOpHCZNRPQ", "link": "https://openreview.net/forum?id=bOpHCZNRPQ", "pdf_link": "https://openreview.net/pdf?id=bOpHCZNRPQ", "keywords": "Half-Space Reporting, Large Language Models, Attention Acceleration", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various applications, but their performance on long-context tasks is often limited by the computational complexity of attention mechanisms. \nThis paper introduces a novel approach to accelerate attention computation in LLMs, particularly for long-context scenarios. \nWe leverage the inherent sparsity within attention mechanisms, both in conventional Softmax attention and ReLU attention (with $\\mathsf{ReLU}^\\alpha$ activation, $\\alpha \\in \\mathbb{N}_+$), to significantly reduce the running time complexity.\nOur method employs a Half-Space Reporting (HSR) data structure to rapidly identify non-zero or ``massively activated'' entries in the attention matrix. We present theoretical analyses for two key scenarios: attention generation and full attention computation with long input context. \nOur approach achieves a running time of $O(mn^{4/5})$ significantly faster than the naive approach $O(mn)$ for attention generation, where $n$ is the context length, $m$ is the query length, and $d$ is the hidden dimension.\nWe can also reduce the running time of full attention computation from $O(mn)$ to $O(mn^{1 - 1 / \\lfloor d/2\\rfloor} + mn^{4/5})$.\nImportantly, our method introduces no error for ReLU attention and only provably negligible error for Softmax attention, where the latter is supported by our empirical validation.\nThis work represents a significant step towards enabling efficient long-context processing in LLMs, potentially broadening their applicability across various domains.", "title_embedding_index": 19404, "title_abs_embedding_index": 19429}, {"title": "Open-Vocabulary Customization from CLIP via Data-Free Knowledge Distillation", "link_suffix": "/forum?id=1aF2D2CPHi", "link": "https://openreview.net/forum?id=1aF2D2CPHi", "pdf_link": "https://openreview.net/pdf?id=1aF2D2CPHi", "keywords": "Data-Free Learning, CLIP Model, Customization", "abstract": "Vision-language models such as CLIP have demonstrated strong zero-shot performance, but their considerable size and inefficient inference limit customizable deployment for users. While knowledge distillation is a solution, it still requires the original data, which is not always available due to copyrights and privacy concerns. For many users seeking open-vocabulary customization, Data-Free Knowledge Distillation (DFKD) emerges as a promising direction. Upon rethinking DFKD, we find that existing methods fail on CLIP due to their heavy reliance on BatchNorm layers, which are unexpectedly unusable in CLIP. Based on our findings, we adopt image-text matching to achieve DFKD for CLIP, enabling customization based on arbitrary class texts. This involves (i) inversing a surrogate dataset from CLIP based on text prompts; and (ii) distilling a student model from CLIP using the surrogate dataset. Specifically, we introduce style dictionary diversification to enhance the diversity of synthetic images. To prevent uncontrollable semantics introduced by diversification, we propose a class consistency maintaining strategy to ensure the consistency of synthetic images. Based on synthetic images with various styles, we further propose meta knowledge distillation to train the student model with good generalization ability. Moreover, we introduce a simple yet effective method to enable customization based on few example images. Comprehensive experiments showcase the superiority of our approach across twelve customized tasks, achieving a 9.33% improvement compared to existing DFKD methods.", "title_embedding_index": 19405, "title_abs_embedding_index": 19430}, {"title": "Long Context Transfer from Language to Vision", "link_suffix": "/forum?id=QETk0lBdVf", "link": "https://openreview.net/forum?id=QETk0lBdVf", "pdf_link": "https://openreview.net/pdf?id=QETk0lBdVf", "keywords": "Vision Language Model, Long Context Model", "abstract": "Video sequences offer valuable temporal information, but existing large multimodal models (LMMs) fall short in understanding extremely long videos. Many works address this by reducing the number of visual tokens using visual resamplers. Alternatively, in this paper, we approach this problem from the perspective of the language model. By simply extrapolating the context length of the language backbone, we enable LMMs to comprehend orders of magnitude more visual tokens without any video training. We call this phenomenon long context transfer and carefully ablate its properties. To effectively measure LMMs' ability to generalize to long contexts in the vision modality, we develop V-NIAH (Visual Needle-In-A-Haystack), a purely synthetic long vision benchmark inspired by the language model's NIAH test. Our proposed Long Video Assistant (LongVA) can process 2000 frames or over 200K visual tokens without additional complexities. With its extended context length, LongVA achieves state-of-the-art performance on Video-MME among 7B-scale models by densely sampling more input frames.", "title_embedding_index": 19406, "title_abs_embedding_index": 19431}, {"title": "Anomalous Action Recognition via Spatio-temporal Relation and Key Patch Selection", "link_suffix": "/forum?id=MSxCBXD5C8", "link": "https://openreview.net/forum?id=MSxCBXD5C8", "pdf_link": "https://openreview.net/pdf?id=MSxCBXD5C8", "keywords": "Anomalous Action Recognition; Spatio-temporal Relation;Key Patch Selection", "abstract": "For providing timely warnings and preventing potential damages, it is crucial to detect anomalous actions that threaten public safety through surveillance cameras. Compared to normal actions, anomalous actions often occupy only a small portion of surveillance videos and exhibit more complex manifestations in terms of time and space. Considering that normal action recognition methods fail to highlight crucial information from small-sized patches, resulting in imprecise anomaly modeling, we propose the Spatio-Temporal Key Patch Selection Network (SKPS-Net). To tackle the challenge of detecting anomalous behaviors that manifest in small and inconspicuous areas, we design a spatial adaptive key patch selection module to select small but informative patches on input videos. Furthermore, the long-short feature map spatio-temporal relation module is devised to make the key patch effectively capture the continuous dynamic changes of anomalous actions. Finally, we propose a spatio-temporal refined loss to reinforce fine-grained feature learning. Experiments conducted on the HMDB51, Kinetics, and UCF-Crime v2 datasets demonstrate that our SKPS-Net achieves state-of-the-art performance in few-shot action recognition, outperforming the most competitive methods by 1.2% on the anomalous action dataset UCF-Crime v2.", "title_embedding_index": 19407, "title_abs_embedding_index": 19432}, {"title": "Selective LoRA for Domain-Aligned Dataset Generation in Urban-Scene Segmentation", "link_suffix": "/forum?id=2TiU1JTdSQ", "link": "https://openreview.net/forum?id=2TiU1JTdSQ", "pdf_link": "https://openreview.net/pdf?id=2TiU1JTdSQ", "keywords": "Dataset Generation, Urban-scene Segmentation", "abstract": "This paper addresses the challenge of data scarcity in semantic segmentation by generating datasets through fine-tuned text-to-image generation models, reducing the costs of image acquisition and labeling. Segmentation dataset generation faces two key challenges: 1) aligning generated samples with the target domain and 2) producing informative samples beyond the training data. Existing methods often overfit and memorize training data, limiting their ability to generate diverse and well-aligned samples. To overcome these issues, we propose Selective LoRA, a novel fine-tuning approach that selectively identifies and updates only the weights associated with necessary concepts (e.g., style or viewpoint) for domain alignment while leveraging the pretrained knowledge of the image generation model to produce more informative samples. Our approach ensures effective domain alignment and enhances sample diversity.\nWe demonstrate its effectiveness in generating datasets for urban-scene segmentation, outperforming baseline and state-of-the-art methods in in-domain (few-shot and fully-supervised) settings, as well as domain generalization tasks, especially under challenging conditions such as adverse weather and varying illumination, further highlighting its superiority.", "title_embedding_index": 19408, "title_abs_embedding_index": 19433}, {"title": "Phantom of Latent for Large Language and Vision Models", "link_suffix": "/forum?id=YVsiB41ifI", "link": "https://openreview.net/forum?id=YVsiB41ifI", "pdf_link": "https://openreview.net/pdf?id=YVsiB41ifI", "keywords": "Large Language and Vision Models", "abstract": "The success of visual instruction tuning has accelerated the development of large language and vision models (LLVMs). Following the scaling laws of instruction-tuned large language models (LLMs), LLVMs either have further increased their sizes, reaching 26B, 34B, and even 80B parameters. While this increase in model size has yielded significant performance gains, it demands substantially more hardware resources for both training and inference. Consequently, there naturally exists a strong need for efficient LLVMs that achieve the performance of larger models while being smaller in size. To achieve this need, we present a new efficient LLVM family with model sizes of 0.5B, 1.8B, 3.8B, and 7B parameters, Phantom, which significantly enhances learning capabilities within limited structures. By temporarily increasing the latent hidden dimension during multi-head self-attention (MHSA), we make LLVMs prepare to look and understand much more vision-language knowledge on the latent, without substantially increasing physical model sizes. To maximize its advantage, we introduce Phantom Optimization (PO) using both autoregressive supervised fine-tuning (SFT) and direct preference optimization (DPO)-like concept, which effectively follows correct answers while eliminating incorrect and ambiguous ones. Phantom outperforms numerous larger open- and closed-source LLVMs, positioning itself as a leading solution in the landscape of efficient LLVMs.", "title_embedding_index": 19409, "title_abs_embedding_index": 19434}, {"title": "White-Box Text Detectors Using Proprietary LLMs: A Probability Distribution Estimation Approach", "link_suffix": "/forum?id=an3fugFA23", "link": "https://openreview.net/forum?id=an3fugFA23", "pdf_link": "https://openreview.net/pdf?id=an3fugFA23", "keywords": "Machine-Generated Text Detection", "abstract": "Large language models (LLMs) can generate text almost indistinguishable from human-written one, highlighting the importance of machine-generated text detection. However, existing zero-shot methods are either restricted to open-source LLMs (white-box methods) or with limited efficiency and robustness (black-box methods), demanding the combination of the strength of white-box methods and the power of latest LLMs. To enable existing white-box methods to proprietary models, we proposeProbability Distribution Estimation (PDE), extending methods like Entropy, Rank, Log-Rank, and Fast-DetectGPT to latest LLMs. Experiments show that PDE (Fast-DetectGPT) achieves an average accuracy of about 0.96 across five latest source models, improving the accuracy by 58% relative to the remaining space (Table 1). It demonstrates that the latest LLMs can effectively detect their own outputs, suggesting advanced LLMs may be the best shield against themselves.", "title_embedding_index": 19410, "title_abs_embedding_index": 19435}, {"title": "MVDrag3D: Drag-based Creative 3D Editing via Multi-view Generation-Reconstruction Prior", "link_suffix": "/forum?id=igpiMCYEjM", "link": "https://openreview.net/forum?id=igpiMCYEjM", "pdf_link": "https://openreview.net/pdf?id=igpiMCYEjM", "keywords": "3D Editing, 3D Drag, Multiview Diffusion Model", "abstract": "Drag-based editing has become popular in 2D content creation, driven by the capabilities of image generative models. However, extending this technique to 3D remains a challenge.  Existing 3D drag-based editing methods, whether employing explicit spatial transformations or relying on implicit latent optimization within limited-capacity 3D generative models, fall short in handling significant topology changes or generating new textures across diverse object categories. To overcome these limitations, we introduce MVDrag3D, a novel framework for more flexible and creative drag-based 3D editing that leverages multi-view generation and reconstruction priors.\nAt the core of our approach is the usage of a multi-view diffusion model as a strong generative prior to perform consistent drag editing over multiple rendered views, which is followed by a reconstruction model that reconstructs 3D Gaussians of the edited object. While the initial 3D Gaussians may suffer from misalignment between different views, we address this via view-specific deformation networks that adjust the position of Gaussians to be well aligned. In addition, we propose a multi-view score function that distills generative priors from multiple views to further enhance the view consistency and visual quality. Extensive experiments demonstrate that MVDrag3D provides a precise, generative, and flexible solution for 3D drag-based editing, supporting more versatile editing effects across various object categories and 3D representations.", "title_embedding_index": 19411, "title_abs_embedding_index": 19436}, {"title": "Know Your Neighbors: Subgraph Importance Sampling for Heterophilic Graph Active Learning", "link_suffix": "/forum?id=nRD5TriJ0O", "link": "https://openreview.net/forum?id=nRD5TriJ0O", "pdf_link": "https://openreview.net/pdf?id=nRD5TriJ0O", "keywords": "Heterophilic Graph, Active Learning", "abstract": "Graph neural networks (GNNs) have shown superiority in various data mining tasks but rely heavily on extensively labeled nodes. To improve the training efficiency and select the most valuable nodes as the training set, graph active learning (GAL) has gained much attention. However, previous GAL methods are designed for homophilic graphs, and their effectiveness on heterophilic graphs is less examined. In this paper, we study active learning on heterophilic graphs, where nodes with the same labels are less likely to be connected. We are surprised to find thatprevious GAL methods fail to outperform the naive random sampling on heterophilic graphs. Through an insightful investigation, we find that previous GAL-selected training sets imply homophily even on heterophilic graphs, leading to their defectiveness. To address this issue, we propose the principle of``Know Your Neighbors''and design an active learning algorithm KyN specifically for heterophilic graphs. The primary idea of KyN is to let GNNs receive a correct homophily distribution by labeling nodes along with their neighbors. We build KyN based on subgraph sampling with probabilities proportional to $\\ell_1$ Lewis weights, which has a solid theoretical guarantee. The effectiveness of KyN is evaluated on various real-world datasets.", "title_embedding_index": 19412, "title_abs_embedding_index": 19437}, {"title": "How Reliable Is Human Feedback For Aligning Large Language Models?", "link_suffix": "/forum?id=I8LdqKbvqX", "link": "https://openreview.net/forum?id=I8LdqKbvqX", "pdf_link": "https://openreview.net/pdf?id=I8LdqKbvqX", "keywords": "Human feedback, LLM alignment, Qualitative analysis", "abstract": "Most alignment research today focuses on designing new learning algorithms using datasets like Anthropic-HH, assuming human feedback data is inherently reliable. However, little attention has been given to the qualitative unreliability of human feedback and its impact on alignment. To address this gap, we conduct a comprehensive study and provide an in-depth analysis of human feedback data. We assess feedback reliability using a committee of gold reward models, revealing that over 25% of the dataset shows low or no agreement with these models, implying a high degree of unreliability. Through a qualitative analysis, we identify six key sources of unreliability, such as mis-labeling, subjective preferences, differing criteria and thresholds for helpfulness and harmlessness, etc. Lastly, to mitigate unreliability, we propose Source-Aware Cleaning, an automatic data-cleaning method guided by the insight of our qualitative analysis, to significantly improve data quality. Extensive experiments demonstrate that models trained on our cleaned dataset, HH-Clean, substantially outperform those trained on the original dataset. We release HH-Clean to support more reliable LLM alignment research in the future.", "title_embedding_index": 19413, "title_abs_embedding_index": 19438}, {"title": "STRUCTDROP: A STRUCTURED RANDOM ALGORITHM TOWARDS EFFICIENT LARGE-SCALE GRAPH TRAINING", "link_suffix": "/forum?id=2soZBUoG3n", "link": "https://openreview.net/forum?id=2soZBUoG3n", "pdf_link": "https://openreview.net/pdf?id=2soZBUoG3n", "keywords": "Efficient Training, Randomized Algorithm", "abstract": "Graph neural networks (GNNs) have gained considerable success in graph-based learning tasks, yet training GNNs on large graphs is still inefficient. The root cause is the graph-based sparse operations are difficult to accelerate with commodity hardware. Prior art reduces the computation cost of sparse matrix based operations (e.g., linear) via sampling-based approximation. However, two under-explored pain points still persist in this paradigm. Inefficiency Issue: The random-based sampling approaches have the non-zero entries randomly distributing over adjacency matrix, which slows down memory access process and is difficult to accelerate with commodity hardware. Under-fitting Problem: The previous sampling methods only utilize the same subset of nodes during the training, which may cause the under-fitting problem on other remain nodes. Aiming to systematically address these two pain points, we propose StructuredDropout, a.k.a, StructDrop. This method involves the selective random sampling of columns and rows from a sparse matrix for computation. Comprehensive experiments validate the efficiency and generalization of our framework: StructDrop achieves up to 5.09x speedup for a single sparse operation and 5.29x end-to-end speedup with negligible accuracy loss or even better accuracy.", "title_embedding_index": 19414, "title_abs_embedding_index": 19439}, {"title": "The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests", "link_suffix": "/forum?id=k243qi7S50", "link": "https://openreview.net/forum?id=k243qi7S50", "pdf_link": "https://openreview.net/pdf?id=k243qi7S50", "keywords": "LLM-as-a-Judge, constraint-satisfaction", "abstract": "Generative AI agents are often expected to respond to complex user requests that have No One Right Answer (NORA), e.g., \"design a vegetarian meal plan below 1800 calories\". Such requests may entail a set of constraints that the agent should adhere to. To successfully develop agents for NORA scenarios, an accurate automatic evaluation framework is essential, and specifically - one capable of validating the satisfaction of constraints in the agent's response. Recently, large language models (LLMs) have been adopted as versatile evaluators for many NORA tasks, but their ability to evaluate constraint-satisfaction in generated text remains unclear. To study this, we develop and release a novel Arithmetic Constraint-Satisfaction (ACS) benchmarking dataset. The dataset consists of complex user requests with corresponding constraints, agent responses and human labels indicating each constraint's satisfaction level in the response. A unique property of this dataset is that validating many of its constraints requires reviewing the response as a whole (in contrast to many other benchmarks that require the validation of a single independent item). Moreover, it assesses LLMs in performing reasoning, in-context data extraction, arithmetic calculations, and counting. We then benchmark both open and proprietary LLMs on evaluating constraint-satisfaction, and show that most models still have a significant headroom for improvement, and that errors primarily stem from reasoning issues. In addition, most models exhibit a skewed constraint-satisfaction prediction pattern, with higher accuracy where the ground-truth label is \"satisfied\". Lastly, few-shot prompting for our task proved to be rather challenging, since many of the studied models showed a degradation in performance when it was introduced.", "title_embedding_index": 19415, "title_abs_embedding_index": 19440}, {"title": "Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles", "link_suffix": "/forum?id=zGej22CBnS", "link": "https://openreview.net/forum?id=zGej22CBnS", "pdf_link": "https://openreview.net/pdf?id=zGej22CBnS", "keywords": "Language models, Tokenization, Probability, Sampling", "abstract": "Tokenization is associated with many poorly understood shortcomings in language models (LMs), yet remains an important component for long sequence scaling purposes. This work studies  how tokenization impacts  model performance by analyzing and comparing the stochastic behavior of tokenized models with their byte-level, or token-free, counterparts. We discover that, even when the two models are statistically equivalent, their predictive distributions over the next byte can be substantially different, a phenomenon we term as ``tokenization bias''. To fully characterize this phenomenon, we  introduce the Byte-Token Representation Lemma, a framework that establishes a mapping between the learned token distribution and its equivalent byte-level distribution.  From this result, we develop a next-byte sampling algorithm  that eliminates tokenization bias without requiring further training or optimization. In other words, this enables zero-shot conversion of tokenized LMs into statistically equivalent token-free ones. We demonstrate its broad applicability with two use cases: fill-in-the-middle (FIM) tasks and model ensembles. In FIM tasks where input prompts may terminate mid-token, leading to out-of-distribution tokenization, our method mitigates performance degradation and achieves an approximately 18% improvement in FIM coding benchmarks, consistently outperforming the standard token healing fix. For model ensembles where each model employs a distinct vocabulary, our approach enables seamless integration, resulting in improved performance (up to 3.7%) over individual models across various standard baselines in reasoning, knowledge, and coding.", "title_embedding_index": 19416, "title_abs_embedding_index": 19441}, {"title": "Context-Alignment: Activating and Enhancing LLMs Capabilities in Time Series", "link_suffix": "/forum?id=syC2764fPc", "link": "https://openreview.net/forum?id=syC2764fPc", "pdf_link": "https://openreview.net/pdf?id=syC2764fPc", "keywords": "Time Series, Large Language Models, Context-Alignment", "abstract": "Recently, leveraging pre-trained Large Language Models (LLMs) for time series (TS) tasks has gained increasing attention, which involves activating and enhancing LLMs' capabilities. Many methods aim to activate LLMs' capabilities based on token-level alignment, but overlook LLMs' inherent strength on natural language processing \u2014 their deep understanding of linguistic logic and structure rather than superficial embedding processing. We propose Context-Alignment, a new paradigm that aligns TS with a linguistic component in the language environments familiar to LLMs to enable LLMs to contextualize and comprehend TS data, thereby activating their capabilities. Specifically, such context-level alignment comprises structural alignment and logical alignment, which is achieved by a Dual-Scale Context-Alignment GNNs (DSCA-GNNs) applied to TS-language multimodal inputs. Structural alignment utilizes dual-scale nodes to describe hierarchical structure in TS-language, enabling LLMs treat long TS data as a whole linguistic component while preserving intrinsic token features. Logical alignment uses directed edges to guide logical relationships, ensuring coherence in the contextual semantics. Demonstration examples prompt are employed to construct Demonstration Examples based Context-Alignment (DECA) following DSCA-GNNs framework. DECA can be flexibly and repeatedly integrated into various layers of pre-trained LLMs to improve awareness of logic and structure, thereby enhancing performance. Extensive experiments show the effectiveness of DECA and the importance of Context-Alignment across tasks, particularly in few-shot and zero-shot forecasting, confirming that Context-Alignment provide powerful prior knowledge on context. We will release the source code upon publication.", "title_embedding_index": 19417, "title_abs_embedding_index": 19442}, {"title": "Learning General Representations Across Graph Combinatorial Optimization Problems", "link_suffix": "/forum?id=elmTU101oS", "link": "https://openreview.net/forum?id=elmTU101oS", "pdf_link": "https://openreview.net/pdf?id=elmTU101oS", "keywords": "Combinatorial Optimization, Contrastive Learning, Representation Learning", "abstract": "Combinatorial optimization (CO) problems are classical and crucial in many fields, with many NP-complete (NPC) examples being reducible to one another, revealing an underlying connection between them. Existing methods, however, primarily focus on task-specific models trained on individual datasets, limiting the quality of learned representations and the transferability to other CO problems. Given the reducibility among these problems, a natural idea is to abstract a higher-level representation that captures the essence shared across different problems, enabling knowledge transfer and mutual enhancement. In this paper, we propose a novel paradigm CORAL that treats each CO problem type as a distinct modality and unifies them by transforming all instances into representations of the fundamental Boolean satisfiability (SAT) problem. Our approach aims to capture the underlying commonalities across multiple problem types via cross-modal contrastive learning with supervision, thereby enhancing representation learning. Extensive experiments on seven graph decision problems (GDPs) demonstrate the effectiveness of CORAL, showing that our approach significantly improves the quality and generalizability of the learned representations. Furthermore, we showcase the utility of the pre-trained unified SAT representations on related tasks, including satisfying assignment prediction and unsat core variable prediction, highlighting the potential of CORAL as a unified pre-training paradigm for CO problems.", "title_embedding_index": 19418, "title_abs_embedding_index": 19443}, {"title": "Prototype antithesis for biological few-shot class-incremental learning", "link_suffix": "/forum?id=bRqaHn3J5I", "link": "https://openreview.net/forum?id=bRqaHn3J5I", "pdf_link": "https://openreview.net/pdf?id=bRqaHn3J5I", "keywords": "Biological Recognition; Few-Shot Learning; Class-Incremental Learning; Prototype Antithesis", "abstract": "Deep learning has become essential in the biological species recognition task. However, a significant challenge is the ability to continuously learn new or mutated species with limited annotated samples. Since species within the same family typically share similar traits, distinguishing between new and existing (old) species during incremental learning often faces the issue of species confusion. This can result in \"catastrophic forgetting\" of old species and poor learning of new ones. To address this issue, we propose a Prototype Antithesis (PA) method, which leverages the hierarchical structures in biological taxa to reduce confusion between new and old species. PA operates in two steps: Residual Prototype Learning (RPL) and Residual Prototype Mixing (RPM). RPL enables the model to learn unique prototypes for each species alongside residual prototypes representing shared traits within families. RPM generates synthetic samples by blending features of new species with residual prototypes of old species, encouraging the model to focus on species-unique traits and minimize species confusion. By integrating RPL and RPM, the proposed PA method mitigates \"catastrophic forgetting\" while improving generalization to new species. Extensive experiments on CUB200, PlantVillage, and Tree-of-Life datasets demonstrate that PA significantly reduces inter-species confusion and achieves state-of-the-art performance, highlighting its potential for deep learning in biological data analysis. The code will be made publicly available following the paper's acceptance.", "title_embedding_index": 19419, "title_abs_embedding_index": 19444}, {"title": "Noise Re-sampling for High Fidelity Image Generation", "link_suffix": "/forum?id=GD4Tlqvwrq", "link": "https://openreview.net/forum?id=GD4Tlqvwrq", "pdf_link": "https://openreview.net/pdf?id=GD4Tlqvwrq", "keywords": "Generative models, Diffusion based models", "abstract": "Latent diffusion models (LDMs) have emerged as powerful tools for generating diverse and realistic samples across domains. However, their efficacy in capturing intricate details and small-scale objects remains a challenge. \nOur investigation reveals that VAE compression induces errors in the latent space and limits the generation quality. Furthermore, LDMs trained on fixed-resolution images struggle to produce high-resolution outputs without distortions, making simple resolution increases ineffective.\nIn this paper, we propose a novelnoise re-samplingstrategy that enables multi-scale generation of LDMs, allowing LDMs to \"zoom in\" and improve generation quality of local regions. By increasing the sampling rates from the noise perspective in the latent space, we effectively bypass the constraints imposed by VAE compression, thus preserving crucial high-frequency information. Our approach, a simple yet effective plugin for current LDMs, enhances the quality of image generation in local regions while maintaining overall structural consistency and providing fine-grained control over the scale of generation in latent diffusion models.\nThrough extensive experimentation and evaluation, we demonstrate the efficacy of our method in enhancing the generation quality across various LDM architectures. Our approach surpasses existing methods, including stable diffusion (SD) models, SD-based super-resolution methods and high-resolution adaptation methods, in generating high-fidelity samples of complex objects.", "title_embedding_index": 19420, "title_abs_embedding_index": 19445}, {"title": "MOSLIM:Align with diverse preferences in prompts through reward classification", "link_suffix": "/forum?id=w0MAu8vjwj", "link": "https://openreview.net/forum?id=w0MAu8vjwj", "pdf_link": "https://openreview.net/pdf?id=w0MAu8vjwj", "keywords": "Large Language Models, Multi-objective alignment, Reward modeling", "abstract": "The multi-objective alignment of Large Language Models (LLMs) is essential for ensuring foundational models conform to diverse human preferences. Current research in this field typically involves either multiple policies or multiple reward models customized for various preferences, or the need to train a preference-specific supervised fine-tuning (SFT) model. In this work, we introduce a novel multi-objective alignment method, MOSLIM, which utilizes a single reward model and policy model to address diverse objectives. MOSLIM provides a flexible way to control these objectives through prompting and does not require preference training during SFT phase, allowing thousands of off-the-shelf models to be directly utilized within this training framework.\nMOSLIM leverages a multi-head reward model that classifies question-answer pairs instead of scoring them and then optimize policy model with a scalar reward derived from a mapping function that converts classification results from reward model into reward scores. We demonstrate the efficacy of our proposed method across several multi-objective benchmarks and conduct ablation studies on various reward model sizes and policy optimization methods. The MOSLIM method outperforms current multi-objective approaches in most results while requiring significantly fewer GPU computing resources compared with existing policy optimization methods.", "title_embedding_index": 19421, "title_abs_embedding_index": 19446}, {"title": "TimeAutoDiff: Generation of Heterogeneous Time Series Data via Latent Diffusion Model", "link_suffix": "/forum?id=zB6uMznFuZ", "link": "https://openreview.net/forum?id=zB6uMznFuZ", "pdf_link": "https://openreview.net/pdf?id=zB6uMznFuZ", "keywords": "Time series data, Tabular data, Heterogeneous, Diffusion model, VAE, Generative model", "abstract": "In this paper, we leverage the power of latent diffusion models to generate synthetic time series tabular data.\nAlong with the temporal and feature correlations, the heterogeneous nature of the feature in the table has been one of the main obstacles in time series tabular data modeling. \nWe tackle this problem by combining the ideas of the variational auto-encoder (VAE) and the denoising diffusion probabilistic model (DDPM).\nOur model named as \\texttt{TimeAutoDiff} has several key advantages including \n(1) \\textit{\\textbf{Generality}}: the ability to handle the broad spectrum of time series tabular data with heterogeneous, continuous only, or categorical only features; \n(2) \\textit{\\textbf{Fast sampling speed}}: entire time series data generation as opposed to the sequential data sampling schemes implemented in the existing diffusion-based models, eventually leading to significant improvements in sampling speed, \n(3) \\textit{\\textbf{Time varying metadata conditional generation}}: the implementation of time series tabular data generation of heterogeneous outputs conditioned on heterogenous, time varying features, enabling scenario exploration across multiple scientific and engineering domains.\n(4) \\textit{\\textbf{Good fidelity and utility guarantees}}: numerical experiments on eight publicly available datasets demonstrating significant improvements over state-of-the-art models in generating time series tabular data, across four metrics measuring fidelity and utility; \nCodes for model implementations are available at the supplementary materials.", "title_embedding_index": 19422, "title_abs_embedding_index": 19447}, {"title": "SymTex: A New Benchmark for Non-monotonic Reasoning Capability of Large Language Models", "link_suffix": "/forum?id=cfDbuobmU0", "link": "https://openreview.net/forum?id=cfDbuobmU0", "pdf_link": "https://openreview.net/pdf?id=cfDbuobmU0", "keywords": "Non-monotonic Reasoning, Large Language Models", "abstract": "Non-monotonic reasoning (NMR) plays a crucial role in logical reasoning, allowing inference to adjust as new information arises. This adaptability is key for large language models (LLMs) to handle complex problems and adjust reasoning in dynamic environments, mimicking human-like flexibility in thought. Recent works mainly explore using LLMs to address non-monotonic reasoning through textual logic representation, as LLMs excel in understanding natural language. However, textual logic representation often leads to ambiguity and complexity, especially in complex situations, while symbolic logic representation is more clear and precise, avoiding these issues. In this work, we introduce a framework called Multi-step Generation for Symbolic and Textual NMR Samples (MG-SymTex) to generate diverse non-monotonic samples automatically, and build a non-monotonic reasoning benchmark, called SymTex, which is used to evaluate the non-monotonic reasoning capability of LLMs. SymTex comprises two types of description and three types of predicate, facilitating two primary tasks: Tri-State Boolean Querying and Answer Set Computation. Through our comprehensive evaluations, we demonstrate that state-of-the-art LLMs such as gpt-4o, claude-3.5-sonnet, and o1-mini encounter significant challenges when addressing our proposed benchmark, highlighting the difficulty of non-monotonic reasoning in LLMs.", "title_embedding_index": 19423, "title_abs_embedding_index": 19448}, {"title": "Growth Inhibitors for Suppressing Inappropriate Image Concepts in Diffusion Models", "link_suffix": "/forum?id=w4C4z80w59", "link": "https://openreview.net/forum?id=w4C4z80w59", "pdf_link": "https://openreview.net/pdf?id=w4C4z80w59", "keywords": "Stable Diffusion, Text-to-Image Generation, Concept Erasure", "abstract": "Despite their remarkable image generation capabilities, text-to-image diffusion models inadvertently learn inappropriate concepts from vast and unfiltered training data, which leads to various ethical and business risks. Specifically, model-generated images may exhibit not safe for work (NSFW) content and style copyright infringements. The prompts that result in these problems often do not include explicit unsafe words; instead, they contain obscure and associative terms, which are referred to asimplicit unsafe prompts. Existing approaches directly fine-tune models under textual guidance to alter the cognition of the diffusion model, thereby erasing inappropriate concepts. This not only requires concept-specific fine-tuning but may also incur catastrophic forgetting. To address these issues, we explore the representation of inappropriate concepts in the image space and guide them towards more suitable ones by injectinggrowth inhibitors, which are tailored based on the identified features related to inappropriate concepts during the diffusion process. Additionally, due to the varying degrees and scopes of inappropriate concepts, we train an adapter to infer the corresponding suppression scale during the injection process. Our method effectively captures the manifestation of subtle words at the image level, enabling direct and efficient erasure of target concepts without the need for fine-tuning. Through extensive experimentation, we demonstrate that our approach achieves superior erasure results with little effect on other normal concepts while preserving image quality and semantics.", "title_embedding_index": 19424, "title_abs_embedding_index": 19449}]
[
    {
        "title": "RLSF: Reinforcement Learning from Self-feedback for improved logical reasoning",
        "link_suffix": "/forum?id=gdzpnRBP4F",
        "link": "https://openreview.net/forum?id=gdzpnRBP4F",
        "pdf_link": "https://openreview.net/pdf?id=gdzpnRBP4F",
        "keywords": "reinforcement learning, large language models, reasoning, uncertainty",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in generating coherent and contextually relevant text. These models\narguably lack the ability to logically reason, an essential skill required to solving mathematical problems and programming tasks.\nWhile step-by-step prompting approaches show some promise, they often depend on finding a suitable prompt tailored to the specific model and task.  In this work, we propose a simple, yet an effective approach to enhance reasoning capabilities by leveraging reinforcement learning (RL) and the confidence scores of a well-calibrated LLM. It involves optimising an implicit reward derived from the model's confidence levels in the answer to the reasoning task at hand.\nWe generate preference data and fine-tune the LLM in a similar spirit to reinforcement learning from human feedback (RLHF), but without needing any human provided labels or preferences.\nOur results show that resulting reasoning abilities of an LLM improve and are transferable to other reasoning tasks. This warrants further investigation of RL as a facilitator for solving complex language tasks."
    },
    {
        "title": "Robust Inverse Reinforcement Learning under State Adversarial Perturbations",
        "link_suffix": "/forum?id=aU2cjz87Bm",
        "link": "https://openreview.net/forum?id=aU2cjz87Bm",
        "pdf_link": "https://openreview.net/pdf?id=aU2cjz87Bm",
        "keywords": "inverse reinforcement learning, state adversarial attacks, robustness",
        "abstract": "State adversarial perturbations –such as sensor noise, environmental interference, or targeted attacks– are common in real-world systems, often leading to compromised state observations. Despite this, Inverse Reinforcement Learning (IRL) in the context of State-Adversarial Markov Decision Processes (SA-MDPs) has received limited attention, primarily because conventional notions of optimality do not apply. In this paper, we introduce a novel definition of optimality that ensures the existence of an optimal policy within SA-MDPs. Building on this foundation, we propose the State-Adversarial Max-Margin IRL (SAMM-IRL) algorithm, designed for robustness against state adversarial perturbations. Our theoretical analysis, supported by empirical validation, demonstrates that SAMM-IRL significantly enhances IRL performance in adversarial environments, providing a robust framework for real-world applications that demand resilience."
    },
    {
        "title": "Using GNNs to Model Biased Crowdsourced Data for Urban Applications",
        "link_suffix": "/forum?id=XaYCOY7YlU",
        "link": "https://openreview.net/forum?id=XaYCOY7YlU",
        "pdf_link": "https://openreview.net/pdf?id=XaYCOY7YlU",
        "keywords": "Graph Neural Networks, Biased Outcome Data, Urban Planning",
        "abstract": "Graph neural networks (GNNs) are widely used to make predictions on graph-structured data in urban spatiotemporal forecasting applications, such as predicting infrastructure problems and weather events. In urban settings, nodes have a true latent state (e.g., street condition) that is sparsely observed (e.g., via government inspection ratings). We more frequently observe biased proxies for the latent state (e.g., via crowdsourced reports) that correlate with resident demographics. We introduce a GNN-based model that uses both unbiased rating data and biased reporting data to predict the true latent state. We show that our approach can both recover the latent state at each node and quantify the reporting biases. We apply our model to a case study of urban incidents using reporting data from New York City 311 complaints across 141 complaint types and rating data from government inspections. We show (i) that our model predicts more correlated ground truth latent states compared to prior work which trains models only on the biased reporting data, (ii) that our model's inferred reporting biases capture known demographic biases, and (iii) that our model's learned ratings capture correlations across locations and between complaint types. Especially in urban crowdsourcing applications, our analysis reveals a widely applicable approach for using GNNs and sparse ground truth data to estimate latent states."
    },
    {
        "title": "What should a neuron aim for? Designing local objective functions based on information theory",
        "link_suffix": "/forum?id=CLE09ESvul",
        "link": "https://openreview.net/forum?id=CLE09ESvul",
        "pdf_link": "https://openreview.net/pdf?id=CLE09ESvul",
        "keywords": "local learning, interpretability, neuro-inspired, information theory, partial information decomposition",
        "abstract": "In modern deep neural networks, the learning dynamics of the individual neurons is often obscure, as the networks are trained via global optimization. Conversely, biological systems build on self-organized, local learning, achieving robustness and efficiency with limited global information. We here show how to enhance the interpretability of the individual artificial neurons' learning by developing an abstract bio-inspired local learning framework. The local objective function is parameterized using a recent extension of information theory, Partial Information Decomposition (PID), which decomposes the information that a set of information sources holds about an outcome into unique, redundant and synergistic contributions. Our framework enables neurons to locally shape the integration of information from various input classes, i.e.,feedforward, feedback, and lateral, by selecting which of the three inputs should contribute uniquely, redundantly or synergistically to the output. This selection is expressed as a learning goal for an individual neuron as a weighted sum of PID terms. For a given problem, the choice of weights can be directly derived from intuitive reasoning or via numerical optimization, offering a window into understanding task-relevant local information processing. Achieving strong performance while preserving neuron-level interpretability, our work advances a principled information-theoretic foundation for local learning strategies."
    },
    {
        "title": "Towards Understanding Domain Adapted Sentence Embeddings for Document Retrieval",
        "link_suffix": "/forum?id=p7K3idvKTQ",
        "link": "https://openreview.net/forum?id=p7K3idvKTQ",
        "pdf_link": "https://openreview.net/pdf?id=p7K3idvKTQ",
        "keywords": "Sentence Embeddings, Question Answering, Technical Domains, Retrieval Augmented Generation, Embedding Models, Isotropy",
        "abstract": "A plethora of sentence embedding models makes it challenging to choose one, especially for technical domains rich with specialized vocabulary. In this work, we domain adapt embeddings using telecom, health and science datasets for question answering. We evaluate embeddings obtained from publicly available models and their domain-adapted variants, on both point retrieval accuracies, as well as their (95%) confidence intervals.  We establish a systematic method to obtain thresholds for similarity scores for different embeddings. As expected, we observe that fine-tuning improves mean bootstrapped accuracies. We also observe that it results in tighter confidence intervals, which further improve when pre-training is preceded by fine-tuning. We introduce metrics which measure the distributional overlaps of top-$K$, correct and random document similarities with the question. Further, we show that these metrics are correlated with retrieval accuracy and similarity thresholds. Recent literature shows conflicting effects of isotropy on retrieval accuracies. Our experiments establish that the isotropy of embeddings (as measured by two independent state-of-the-art isotropy metric definitions) is poorly correlated with retrieval performance. We show that embeddings for domain-specific sentences have little overlap with those for domain-agnostic ones, and fine-tuning moves them further apart. Based on our results, we provide recommendations for use of our methodology and metrics by researchers and practitioners."
    },
    {
        "title": "Autoformulation of Mathematical Optimization Models Using LLMs",
        "link_suffix": "/forum?id=107ZsHD8h7",
        "link": "https://openreview.net/forum?id=107ZsHD8h7",
        "pdf_link": "https://openreview.net/pdf?id=107ZsHD8h7",
        "keywords": "Large Language Models, optimization modeling",
        "abstract": "Mathematical optimization is fundamental to decision-making across diverse domains, from operations research to healthcare. Yet, translating real-world problems into optimization models remains a formidable challenge, often demanding specialized expertise. This paper formally introduces the concept ofautoformulation---an automated approach to creating optimization models from natural language descriptions for commercial solvers.\nWe identify the three core challenges of autoformulation: (1) defining the vast, problem-dependent hypothesis space, (2) efficiently searching this space under uncertainty, and (3) evaluating formulation correctness (ensuring a formulation accurately represents the problem).\nTo address these challenges, we introduce a novel method leveragingLarge Language Models(LLMs) within aMonte-Carlo Tree Searchframework. This approach systematically explores the space of possible formulations by exploiting the hierarchical nature of optimization modeling.  LLMs serve two key roles: as dynamic formulation hypothesis generators and as evaluators of formulation correctness. To enhance search efficiency, we introduce a pruning technique to remove trivially equivalent formulations. \nEmpirical evaluations across benchmarks containing linear and mixed-integer programming problems demonstrate our method's superior performance. Additionally, we observe significant efficiency gains from employing LLMs for correctness evaluation and from our pruning techniques."
    },
    {
        "title": "FusionMaestro: Harmonizing Early Fusion, Late Fusion, and LLM Reasoning for Multi-Granular Table-Text Retrieval",
        "link_suffix": "/forum?id=jneVchiRlT",
        "link": "https://openreview.net/forum?id=jneVchiRlT",
        "pdf_link": "https://openreview.net/pdf?id=jneVchiRlT",
        "keywords": "Table-text retrieval, Information retrieval, Open-domain, Large language model, Early fusion, Late fusion, Multi-granular",
        "abstract": "Table-text retrieval aims to retrieve relevant tables and text to support open-domain question answering. Existing studies use either early or late fusion, but face limitations.  Early fusion pre-aligns a table row with its associated passages, forming ``stars,\" which often include irrelevant contexts and miss query-dependent relationships. Late fusion retrieves individual nodes, dynamically aligning them, but it risks missing relevant contexts. Both approaches also struggle with advanced reasoning tasks, such as column-wise aggregation and multi-hop reasoning. To address these issues, we propose FusionMaestro, which combines the strengths of both approaches. First, the edge-based bipartite subgraph retrieval identifies finer-grained edges between table segments and passages, effectively avoiding the inclusion of irrelevant contexts. Then, the query-relevant node expansion identifies the most promising nodes, dynamically retrieving relevant edges to grow the bipartite subgraph, minimizing the risk of missing important contexts. Lastly, the star-based LLM refinement performs logical inference at the star subgraph rather than the bipartite subgraph, supporting advanced reasoning tasks. Experimental results show that FusionMaestro outperforms state-of-the-art models with a significant improvement up to 42.6% and 39.9% in recall and nDCG, respectively, on the OTT-QA benchmark."
    },
    {
        "title": "Dynamic Matching Utilizing Latent Factor Modeling",
        "link_suffix": "/forum?id=rb93dP976j",
        "link": "https://openreview.net/forum?id=rb93dP976j",
        "pdf_link": "https://openreview.net/pdf?id=rb93dP976j",
        "keywords": "Dynamic matching, Learning, Two-sided market, Bi-clustering, Label aggregation",
        "abstract": "This paper investigates the supply-demand matching problem on dynamic platforms, focusing on optimizing matching strategies by learning workers' attributes when their types are uncertain and constantly changing. To address this problem, we introduce a latent factor model and a multi-centroid grouping penalty mechanism to predict latent factors of workers and perform dynamic matching. Our approach operates in two stages: the first stage fits latent feature vectors for workers and jobs and groups them using historical data; the second stage utilizes these latent features for dynamic matching. Our research demonstrates that the introduced model can adapt to the dynamic changes of the platform with good predictive consistency and group robustness, and improves overall operational benefit through continuous optimization of matching results. We provide simulation experiments and a real case study using kidney exchange data and compare our model with a point process model to show that our approach performs well on dynamic platform matching problems."
    },
    {
        "title": "Modeling Asynchronous Time Series with Large Language Models",
        "link_suffix": "/forum?id=63KdWsaYhb",
        "link": "https://openreview.net/forum?id=63KdWsaYhb",
        "pdf_link": "https://openreview.net/pdf?id=63KdWsaYhb",
        "keywords": "Large Language Models, Asynchronous Time Series, Time Series modeling, Deep Learning",
        "abstract": "We propose a novel prompt design for using Large Language Models (LLMs) with Asynchronous Time Series data (LASTS), where the series is represented as pairs of events described in natural language and timestamps expressed as inter-arrival times. Unlike existing models restricted to fixed event categories, our model operates in an open-world setting, processing new events without retraining by leveraging LLMs’ world knowledge for better reasoning across domains and tasks. We further introduce Stochastic Soft Prompting (StoP), a novel prompt tuning mechanism that we use to adapt LLMs to LASTS representation and various downstream tasks, including forecasting, data imputation, and anomaly detection. Extensive experiments on real-world datasets demonstrate our model’s versatility across tasks, achieving state-of-the-art results. Additionally, we observe that StoP prompts are interpretable and contain meaningful information."
    },
    {
        "title": "Diffusion Active Learning: Towards Data-Driven Experimental Design in Computed Tomography",
        "link_suffix": "/forum?id=73Q9U0vcja",
        "link": "https://openreview.net/forum?id=73Q9U0vcja",
        "pdf_link": "https://openreview.net/pdf?id=73Q9U0vcja",
        "keywords": "Active Learning, Diffusion, Tomography, Computer Vision, Experimental Design",
        "abstract": "We introduceDiffusion Active Learning, a novel approach that integrates a generative diffusion model with sequential experimental design to adaptively acquire data for solving inverse problems in imaging. We first pre-train an unconditional diffusion model on domain-specific data. The diffusion model is aimed to capture the structure of the underlying data distribution, which is then leveraged in the active learning process. During the active learning loop, we use the forward model of the inverse problem together with the diffusion model to generate conditional data samples from the posterior distribution, all consistent with the current measurements. Based on the generated samples we quantify the uncertainty in the current estimate in order to select the most informative next measurement. We showcase the proposed approach for its application in X-ray computed tomography imaging. Our results demonstrate significant reductions in data acquisition requirements (i.e., lower X-ray dose) and improved image reconstruction quality across several real-world tomography datasets."
    },
    {
        "title": "MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding",
        "link_suffix": "/forum?id=WK6hQoAtgx",
        "link": "https://openreview.net/forum?id=WK6hQoAtgx",
        "pdf_link": "https://openreview.net/pdf?id=WK6hQoAtgx",
        "keywords": "Comprehensive Benchmark, Large Vision-Language Models, Fine-grained visual understanding, OCR-Free Document Understanding",
        "abstract": "Large Vision-Language Models (LVLMs) have achieved remarkable performance in many vision-language tasks, yet their capabilities in fine-grained visual understanding remain insufficiently evaluated.  Existing benchmarks either contain limited fine-grained evaluation samples that are mixed with other data, or are confined to object-level assessments in natural images. To holistically assess LVLMs' fine-grained visual understanding capabilities, we propose using document images with multi-granularity and multi-modal information to supplement natural images.  In this light, we construct MMDocBench, a benchmark with various OCR-free document understanding tasks for the evaluation of fine-grained visual perception and reasoning abilities. MMDocBench defines  15 main tasks with 4,338 QA pairs and 11,353 supporting regions, covering various document images such as research papers, receipts, financial reports, Wikipedia tables, charts, and infographics. Based on MMDocBench, we conduct extensive experiments using 10 open-source and 3 proprietary advanced LVLMs, assessing their strengths and weaknesses across different tasks and document image types. The benchmark, task instructions, and evaluation code will be made publicly available."
    },
    {
        "title": "Gating is Weighting: Understanding Gated Linear Attention through In-context Learning",
        "link_suffix": "/forum?id=AC9FsaVIpk",
        "link": "https://openreview.net/forum?id=AC9FsaVIpk",
        "pdf_link": "https://openreview.net/pdf?id=AC9FsaVIpk",
        "keywords": "linear attention, gating, in-context learning, weighted gradient descent, optimization landscape",
        "abstract": "Linear attention methods provide a strong alternative to softmax attention as they allow for efficient recurrent decoding. Recent research has focused on enhancing standard linear attention by incorporating gating while retaining its computational benefits. Such Gated Linear Attention (GLA) architectures include highly competitive models such as Mamba and RWKV. In this work, we examine the in-context learning capabilities of the GLA model and make the following contributions. We show that a multilayer GLA can implement a general class of Weighted Projected Gradient Descent (WPGD) algorithms with data-dependent weights. These weights are induced by the gating and allows the model to control the contribution of individual tokens to prediction. To further understand the mechanics of weighting, we introduce a novel data model with multitask prompts and characterize the optimization landscape of the problem of learning a WPGD algorithm. We identify mild conditions under which there is a unique (global) minimum up to scaling invariance, and the associated WPGD algorithm is unique as well. Finally, we translate these findings to explore the optimization landscape of GLA and shed light on how gating facilitates context-aware learning and when it is provably better than vanilla linear attention."
    },
    {
        "title": "Associative memory and dead neurons",
        "link_suffix": "/forum?id=mkNVPGpEPm",
        "link": "https://openreview.net/forum?id=mkNVPGpEPm",
        "pdf_link": "https://openreview.net/pdf?id=mkNVPGpEPm",
        "keywords": "associative memory, dead neurone, neural ODE, energy-based model",
        "abstract": "In ``Large Associative Memory Problem in Neurobiology and Machine Learning,'' Dmitry Krotov and John Hopfield introduced a general technique for the systematic construction of neural ordinary differential equations with non-increasing energy or Lyapunov function. We study this energy function and identify that it is vulnerable to the problem of dead neurons. Each point in the state space where the neuron dies is contained in a non-compact region with constant energy. In these flat regions, energy function alone does not completely determine all degrees of freedom and, as a consequence, can not be used to analyze stability or find steady states or basins of attraction. We perform a direct analysis of the dynamical system and show how to resolve problems caused by flat directions corresponding to dead neurons: (i) all information about the state vector at a fixed point can be extracted from the energy and Hessian matrix (of Lagrange function), (ii) it is enough to analyze stability in the range of Hessian matrix, (iii) if steady state touching flat region is stable the whole flat region is the basin of attraction. The analysis of the Hessian matrix can be complicated for realistic architectures, so we show that for a slightly altered dynamical system (with the same structure of steady states), one can derive a diverse family of Lyapunov functions that do not have flat regions corresponding to dead neurons. In addition, these energy functions allow one to use Lagrange functions with Hessian matrices that are not necessarily positive definite and even consider architectures with non-symmetric feedforward and feedback connections."
    },
    {
        "title": "From Logits to Hierarchies: Hierarchical Clustering made Simple",
        "link_suffix": "/forum?id=PmV9oPAtU9",
        "link": "https://openreview.net/forum?id=PmV9oPAtU9",
        "pdf_link": "https://openreview.net/pdf?id=PmV9oPAtU9",
        "keywords": "Hierarchical Clustering, Clustering, Interpretability and Explainability, Unsupervised Learning",
        "abstract": "The structure of many real-world datasets is intrinsically hierarchical, making the modeling of such hierarchies a critical objective in both unsupervised and supervised machine learning. Recently, novel approaches for hierarchical clustering with deep architectures have been proposed. In this work, we take a critical perspective on this line of research and demonstrate that many approaches exhibit major limitations when applied to realistic datasets, partly due to their high computational complexity. In particular, we show that a lightweight procedure implemented on top of pre-trained non-hierarchical clustering models outperforms models designed specifically for hierarchical clustering. Our proposed approach is computationally efficient and applicable to any pre-trained clustering model that outputs logits, without requiring any fine-tuning. To highlight the generality of our findings, we illustrate how our method can also be applied in a supervised setup, recovering meaningful hierarchies from a pre-trained ImageNet classifier."
    },
    {
        "title": "State-space models can learn in-context by gradient descent",
        "link_suffix": "/forum?id=52XG8eexal",
        "link": "https://openreview.net/forum?id=52XG8eexal",
        "pdf_link": "https://openreview.net/pdf?id=52XG8eexal",
        "keywords": "state-space models, in-context learning, linear recurrent networks, mesa-learning",
        "abstract": "Deep state-space models (Deep SSMs) have shown capabilities for in-context learning on autoregressive tasks, similar to transformers. \nHowever, the architectural requirements and mechanisms enabling this in recurrent networks remain unclear. \nThis study demonstrates that state-space model architectures can perform gradient-based learning and use it for in-context learning.\nWe prove that a single structured state-space model layer, augmented with local self-attention, can reproduce the outputs of an implicit linear model with least squares loss after one step of gradient descent.\nOur key insight is that the diagonal linear recurrent layer can act as a gradient accumulator, which can be `applied' to the parameters of the implicit regression model.\nWe validate our construction by training randomly initialized augmented SSMs on simple linear regression tasks. The empirically optimized parameters match the theoretical ones, obtained analytically from the implicit model construction. \nExtensions to multi-step linear and non-linear regression yield consistent results.\nThe constructed SSM encompasses features of modern deep state-space models, with the potential for scalable training and effectiveness even in general tasks. \nThe theoretical construction elucidates the role of local self-attention and multiplicative interactions in recurrent architectures as the key ingredients for enabling the expressive power typical of foundation models."
    },
    {
        "title": "On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation",
        "link_suffix": "/forum?id=HUzDU7u5B4",
        "link": "https://openreview.net/forum?id=HUzDU7u5B4",
        "pdf_link": "https://openreview.net/pdf?id=HUzDU7u5B4",
        "keywords": "Hallucination;Large Language Model;",
        "abstract": "Hallucination occurs when large language models (LLMs) exhibit behavior that deviates from the boundaries of their knowledge during the response generation process.\nPrevious learning-based methods focus on detecting knowledge boundaries and finetuning models with instance-level feedback, but they suffer from inaccurate signals due to off-policy data sampling and coarse-grained feedback.\nIn this paper, we introduce \\textit{\\b{R}einforcement \\b{L}earning \\b{f}or \\b{H}allucination} (RLFH), a fine-grained feedback-based online reinforcement learning method for hallucination mitigation.\nUnlike previous learning-based methods, RLFH enables LLMs to explore the boundaries of their internal knowledge and provide on-policy, fine-grained feedback on these explorations.\nTo construct fine-grained feedback for learning reliable generation behavior, RLFH decomposes the outcomes of large models into atomic facts, provides statement-level evaluation signals, and traces back the signals to the tokens of the original responses.\nFinally, RLFH adopts the online reinforcement algorithm with these token-level rewards to adjust model behavior for hallucination mitigation.\nFor effective on-policy optimization, RLFH also introduces an LLM-based fact assessment framework to verify the truthfulness and helpfulness of atomic facts without human intervention.\nExperiments on HotpotQA, SQuADv2, and Biography benchmarks demonstrate that RLFH can balance their usage of internal knowledge during the generation process to eliminate the hallucination behavior of LLMs."
    },
    {
        "title": "The OMG dataset: An Open MetaGenomic corpus for mixed-modality genomic language modeling",
        "link_suffix": "/forum?id=jlzNb1iWs3",
        "link": "https://openreview.net/forum?id=jlzNb1iWs3",
        "pdf_link": "https://openreview.net/pdf?id=jlzNb1iWs3",
        "keywords": "metagenomics, pretraining dataset, genomic language model",
        "abstract": "Biological language model performance depends heavily on pretraining data quality, diversity, and size. While metagenomic datasets feature enormous biological diversity, their utilization as pretraining data has been limited due to challenges in data accessibility, quality filtering and deduplication. Here, we present the Open MetaGenomic (OMG) corpus, a genomic pretraining dataset totalling 3.1T base pairs and 3.3B protein coding sequences, obtained by combining two largest metagenomic dataset repositories (JGI's IMG and EMBL's MGnify). We first document the composition of the dataset and describe the quality filtering steps taken to remove poor quality data. We make the OMG corpus available as a mixed-modality genomic sequence dataset that represents multi-gene encoding genomic sequences with translated amino acids for protein coding sequences, and nucleic acids for intergenic sequences. We train the first mixed-modality genomic language model (gLM2) that leverages genomic context information to learn robust functional representations, as well as coevolutionary signals in protein-protein interfaces and genomic regulatory syntax. Furthermore, we show that deduplication in embedding space can be used to balance the corpus, demonstrating improved performance on downstream tasks. The OMG dataset is publicly hosted on the Hugging Face Hub at \\url{UrlHiddenForAnonymity} and gLM2 is available at \\url{UrlHiddenForAnonymity}."
    },
    {
        "title": "Marvel: Accelerating Safe Online Reinforcement Learning with Finetuned Offline Policy",
        "link_suffix": "/forum?id=w9bWY6LvrW",
        "link": "https://openreview.net/forum?id=w9bWY6LvrW",
        "pdf_link": "https://openreview.net/pdf?id=w9bWY6LvrW",
        "keywords": "Offline-to-Online Fine-tuning, Safe Reinforcement Learning, Constrained Markov Decision Processes, Reinforcement Learning",
        "abstract": "The high costs and risks involved in extensive environment interactions hinder the practical application of current online safe reinforcement learning (RL) methods. While offline safe RL addresses this by learning policies from static datasets, the performance therein is usually limited due to reliance on data quality and challenges with out-of-distribution (OOD) actions. Inspired by recent successes in offline-to-online (O2O) RL, it is crucial to explore whether offline safe RL can be leveraged to facilitate faster and safer online policy learning, a direction that has yet to be fully investigated. To fill this gap, we first demonstrate that naively applying existing O2O algorithms from standard RL would not work well in the safe RL setting due to two unique challenges: \\emph{erroneous Q-estimations}, resulted from offline-online objective mismatch and offline cost sparsity, and \\emph{Lagrangian mismatch}, resulted from difficulties in aligning Lagrange multipliers between offline and online policies. To address these challenges, we introduce \\textbf{Marvel}, a novel framework for O2O safe RL, comprising two key components that work in concert: \\emph{Value Pre-Alignment} to align the Q-functions with the underlying truth before online learning, and \\emph{Adaptive PID Control} to effectively adjust the Lagrange multipliers during online  finetuning. Extensive experiments  demonstrate that Marvel significantly outperforms existing baselines in both reward maximization and safety constraint satisfaction. By introducing the first policy-finetuning based framework for O2O safe RL, which is compatible with many offline and online safe RL methods, our work has the great potential to advance the field towards more efficient and practical safe RL solutions."
    },
    {
        "title": "Variance-Reduced Forward-Reflected Algorithms for  Generalized Equations",
        "link_suffix": "/forum?id=zZUCWkn4PL",
        "link": "https://openreview.net/forum?id=zZUCWkn4PL",
        "pdf_link": "https://openreview.net/pdf?id=zZUCWkn4PL",
        "keywords": "Variance Reduction Method, SGD, Generalized Equation, Variational Inequality, Minimax Problem",
        "abstract": "We develop two novel stochastic variance-reduction methods to approximate a solution of generalized equations applicable to both equations and inclusions. Our algorithms leverage a new combination of ideas from the forward-reflected-backward splitting method and  a class of unbiased variance-reduced estimators. We construct two new stochastic estimators within this class, inspired by the well-known SVRG and SAGA estimators.  These estimators significantly differ from existing approaches used in minimax and variational inequality problems. By appropriately  selecting parameters, both algorithms achieve the state-of-the-art oracle complexity of $\\mathcal{O}(n + n^{2/3} \\epsilon^{-2})$ for obtaining an $\\epsilon$-solution in terms of the operator residual norm, where $n$ represents the number of  summands and $\\epsilon$ signifies the desired accuracy.  This complexity aligns with the best-known results in SVRG and SAGA methods for stochastic nonconvex optimization. We test our algorithms on two numerical examples and compare them with existing methods. The results demonstrate promising improvements offered by the new methods compared to their competitors."
    },
    {
        "title": "Physics-informed Temporal Difference Metric Learning for Robot Motion Planning",
        "link_suffix": "/forum?id=TOiageVNru",
        "link": "https://openreview.net/forum?id=TOiageVNru",
        "pdf_link": "https://openreview.net/pdf?id=TOiageVNru",
        "keywords": "Robot motion planning, Eikonal Equation, Physics-informed Neural Networks, Temporal Difference Learning, Metric Learning",
        "abstract": "The robot motion planning problem involves finding a collision-free path between a robot's initial and target configurations. Recently, self-supervised learning methods have been developed to address planning problems without requiring expensive expert demonstrations. These methods leverage the Eikonal equation for training neural networks and lead to scalable and data-efficient solutions. However, these methods face challenges when applied to complex, cluttered environments due to their inability to preserve key properties of the Eikonal equation, such as its role as an optimal value function and geodesic distance. To overcome these limitations, we propose a novel self-supervised temporal difference metric learning approach that solves the Eikonal equation more accurately and enhances performance in solving complex and unseen motion planning tasks. Our method enforces Bellman's principle of optimality over finite regions, using temporal difference learning to avoid spurious local minima, while incorporating metric learning to preserve the Eikonal equation's intrinsic geodesic properties, such as the triangle inequality. We demonstrate that our approach significantly outperforms existing methods in handling complex environments and generalizing to unseen environments, with robot configurations ranging from 2 to 12 degrees of freedom (DOF)."
    },
    {
        "title": "Functional segregation of inputs in artificial neural networks for vision",
        "link_suffix": "/forum?id=SMYEApLhyx",
        "link": "https://openreview.net/forum?id=SMYEApLhyx",
        "pdf_link": "https://openreview.net/pdf?id=SMYEApLhyx",
        "keywords": "ventral stream, circuit mechanisms, interpretability, deep learning, visual system, excitation inhibition, neuroscience, closed-loop optimization, ablation",
        "abstract": "One of the main organizational principles of artificial and biological intelligence systems is their reliance on signed inputs: positive and negative weights in artificial networks, excitatory and inhibitory synapses in the brain. However, little is known about the role of inhibitory activity in high-level visual cortex such as inferotemporal cortex, or how artificial neural networks (ANNs) trained for object recognition segregate their learned representations into positive and negative weights.\nHere, we dissected high-level visual mechanisms in ANNs trained with ImageNet. We investigated how learned representations of ANN classification units depended on their positive or negative inputs using ablation experiments and feature visualization. We found that unit representations changed more when ablating positive- vs. negative inputs. Object-related features were abolished when ablating positive inputs, while still preserving background textures. This effect was more pronounced in adversarially trained robust networks. We found a consistent functional segregation when we trained models to replicate the activity of neurons in monkey visual cortex, across the ventral stream V1, V4, IT. Feature visualization of the neuron models produced images containing local features preferred by actual neurons. Analogous to units trained for classification, the learned representations of units trained to simulate neurons changed more upon ablating positive than negative inputs. We conclude that ANNs learn to segregate object or foreground information into the positive weights, with background or contextual information into the negative weights. These results hint at the relevance of inhibition into shaping feature selectivity in the primate ventral stream, a hypothesis we are testing in vivo."
    },
    {
        "title": "Towards Scalable Topological Regularizers",
        "link_suffix": "/forum?id=FjZcwQJX8D",
        "link": "https://openreview.net/forum?id=FjZcwQJX8D",
        "pdf_link": "https://openreview.net/pdf?id=FjZcwQJX8D",
        "keywords": "topological data analysis, persistent homology, generative adversarial network, latent space matching",
        "abstract": "Latent space matching, which consists of matching distributions of features in latent space, is a crucial component for tasks such as adversarial attacks and defenses, domain adaptation, and generative modelling.\n    Metrics for probability measures, such as Wasserstein and maximum mean discrepancy, are commonly used to quantify the differences between such distributions.\n    However, these are often costly to compute, or do not appropriately take the geometric and topological features of the distributions into consideration.\n    Persistent homology is a tool from topological data analysis which quantifies the multi-scale topological structure of point clouds, and has recently been used as a topological regularizer in learning tasks.\n    However, computation costs preclude larger scale computations, and discontinuities in the gradient lead to unstable training behavior such as in adversarial tasks. \n    We propose the use of principal persistence measures, based on computing the persistent homology of a large number of small subsamples, as a topological regularizer.\n    We provide a parallelized GPU implementation of this regularizer, and prove that gradients are continuous for smooth densities.\n    Furthermore, we demonstrate the efficacy of this regularizer on shape matching, image generation, and semi-supervised learning tasks, opening the door towards a scalable regularizer for topological features."
    },
    {
        "title": "KaSA: Knowledge-Aware Singular-Value Adaptation of Large Language Models",
        "link_suffix": "/forum?id=OQqNieeivq",
        "link": "https://openreview.net/forum?id=OQqNieeivq",
        "pdf_link": "https://openreview.net/pdf?id=OQqNieeivq",
        "keywords": "Large Language Models, Parameter-efficient Fine-tuning, Singular Value Decomposition",
        "abstract": "The increasing sizes of large language models (LLMs) result in significant computational overhead and memory usage when adapting these models to specific tasks or domains. Various parameter-efficient fine-tuning (PEFT) methods have been devised to mitigate these challenges by training a small set of parameters for the task-specific updates of the model weights. Among PEFT methods, LoRA stands out for its simplicity and efficiency, inspiring the development of a series of variants. However, LoRA and its successors disregard the knowledge that is noisy or irrelevant to the targeted task, detrimentally impacting model performance and leading to suboptimality. To address this limitation, we introduce Knowledge-aware Singular-value Adaptation (KaSA), a PEFT method that leverages singular value decomposition (SVD) with knowledge-aware singular values to dynamically activate knowledge based on its relevance to the task at hand. We conduct extensive experiments across a range of LLMs on tasks spanning natural language understanding (NLU), generation (NLG), and instruction following. The experimental results demonstrate that KaSA consistently outperforms FFT and other popular PEFT baselines across 7 benchmarks and 4 synthetic datasets, underscoring our method's efficacy and adaptability."
    },
    {
        "title": "Probing the contents of text, behavior, and brain data toward improving human-LLM alignment",
        "link_suffix": "/forum?id=dI66AEIo6T",
        "link": "https://openreview.net/forum?id=dI66AEIo6T",
        "pdf_link": "https://openreview.net/pdf?id=dI66AEIo6T",
        "keywords": "LLMs, language models, interpretability, free association, human-model alignment, representational similarity analysis",
        "abstract": "Large language models (LLMs) are traditionally trained on massive digitized text corpora; however, alternative data sources exist that may help evaluate and improve the alignment between language models and humans. We contribute to the assessment of the role of data sources in human-LLM alignment. Specifically, we present work aimed at understanding differences in the informational content of text, behavior (e.g., free associations), and brain (e.g., fMRI) data. Using representational similarity analysis, we show that word vectors derived from behavior and brain data encode information that differs from their text-derived cousins. Furthermore, using an interpretability method that we term representational content analysis, we find that, in particular, behavior representations better encode certain affective, agentic, and socio-moral dimensions. The findings highlight the potential of behavior data to evaluate and improve language models along dimensions critical for human-LLM alignment."
    },
    {
        "title": "CLAD: A Contrastive Learning based Method for Multi-Class Anomaly Detection",
        "link_suffix": "/forum?id=zE4mL85zgg",
        "link": "https://openreview.net/forum?id=zE4mL85zgg",
        "pdf_link": "https://openreview.net/pdf?id=zE4mL85zgg",
        "keywords": "Industrial anomaly detection, Multi-class anomaly detection, Contrastive Learning",
        "abstract": "Anomaly detection is crucial yet challenging in industrial production, especially in multi-class scenarios. Existing high-performance unsupervised methods often suffer from low efficiency and high model complexity. While lightweight discriminator-based detectors have been proposed, they are typically designed for single-class detection and exhibit significant performance degradation when extended to multi-class tasks. To address these limitations, we propose a novel Contrastive Learning-based multi-class Anomaly Detection (CLAD) method.\nOur approach first encodes multi-class normal images to generate normal samples in the feature space, then synthesizes anomalous samples in this encoded space. We then employ an Adapter network to compress the samples and leverage contrastive learning to effectively cluster normal and anomalous samples across multiple classes. Finally, a discriminator network is used for anomaly classification and identification. By leveraging anomaly sample generation and a two-stage training process, our framework achieves state-of-the-art performance on the MVTec and VisA datasets under the discriminator-based paradigm. Our key contributions include a novel framework for multi-class anomaly detection, efficient sample generation techniques, and a comprehensive evaluation of model configurations."
    }
]
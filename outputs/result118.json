[
    {
        "title": "CipherPrune:  Efficient and Scalable Private Transformer Inference",
        "link_suffix": "/forum?id=mUMvr33FTu",
        "link": "https://openreview.net/forum?id=mUMvr33FTu",
        "pdf_link": "https://openreview.net/pdf?id=mUMvr33FTu",
        "keywords": "Private Transformer Inference",
        "abstract": "Private Transformer inference using cryptographic protocols offers promising solutions for privacy-preserving machine learning; however, it still faces significant runtime overhead (efficiency issues) and challenges in handling long-token inputs (scalability issues). We observe that the Transformer's operational complexity scales quadratically with the number of input tokens, making it essential to reduce the input token length. Notably, each token varies in importance, and many inputs contain redundant tokens. Additionally, prior private inference methods that rely on high-degree polynomial approximations for non-linear activations are computationally expensive. Therefore, reducing the polynomial degree for less important tokens can significantly accelerate private inference.  Building on these observations, we propose $\\textit{CipherPrune}$, an efficient and scalable private inference framework that includes a secure encrypted token pruning protocol, a polynomial reduction protocol, and corresponding Transformer network optimizations. At the protocol level, encrypted token pruning adaptively removes unimportant tokens from encrypted inputs in a progressive, layer-wise manner. Additionally, encrypted polynomial reduction assigns lower-degree polynomials to less important tokens after pruning, enhancing efficiency without decryption. At the network level, we introduce protocol-aware network optimization via a gradient-based search to maximize pruning thresholds and polynomial reduction conditions while maintaining the desired accuracy. Our experiments demonstrate that CipherPrune reduces the execution overhead of private Transformer inference by approximately $6.1\\times$ for 128-token inputs and $10.6\\times$  for 512-token inputs, compared to previous methods, all without compromising accuracy."
    },
    {
        "title": "Approximating Full Conformal Prediction for Neural Network Regression with Gauss-Newton Influence",
        "link_suffix": "/forum?id=vcX0k4rGTt",
        "link": "https://openreview.net/forum?id=vcX0k4rGTt",
        "pdf_link": "https://openreview.net/pdf?id=vcX0k4rGTt",
        "keywords": "conformal, laplace, influence, neural network, deep learning, uncertainty",
        "abstract": "Uncertainty quantification is an important prerequisite for the deployment of deep learning models in safety-critical areas. Yet, this hinges on the uncertainty estimates being useful to the extent the predictive prediction intervals are well-calibrated and sharp. In the absence of inherent uncertainty estimates (e.g. pretrained models), popular approaches that operate post-hoc include Laplace\u2019s method and split conformal prediction (split-CP). However, Laplace\u2019s method can be miscalibrated when the model is misspecified and split-CP requires sample splitting, and thus comes at the expense of statistical efficiency. In this work, we construct prediction intervals for neural network regressors post-hoc without held-out data. This is achieved by approximating the full conformal prediction method (full-CP). Whilst full-CP nominally requires retraining the model for every test point and candidate label, we propose to train just once and locally perturb model parameters using Gauss-Newton influence to approximate the effect of retraining. Coupled with linearization of the network, we express the absolute residual nonconformity score as a piecewise linear function of the candidate label allowing for an efficient procedure that avoids the exhaustive search over the output space. On standard regression benchmarks, we show the resulting prediction intervals are locally-adaptive and often tighter than those of split-CP."
    },
    {
        "title": "Adversarial Policy Optimization for Preference-based Reinforcement Learning",
        "link_suffix": "/forum?id=5Y9NT6lW21",
        "link": "https://openreview.net/forum?id=5Y9NT6lW21",
        "pdf_link": "https://openreview.net/pdf?id=5Y9NT6lW21",
        "keywords": "Preference-based reinforcement learning, Reinforcement learning with human feedback",
        "abstract": "In this paper, we study offline preference-based reinforcement learning (PbRL), where learning is based on pre-collected preference feedback over pairs of trajectories. While offline PbRL has demonstrated remarkable empirical success, existing theoretical approaches face challenges in ensuring conservatism under uncertainty, requiring computationally intractable confidence set constructions. We address this limitation by proposing Adversarial Preference-based Policy Optimization (APPO), a computationally efficient algorithm for offline PbRL that guarantees sample complexity bounds without relying on explicit confidence sets. By framing PbRL as a two-player game between a policy and a model, our approach enforces conservatism in a tractable manner. Using standard assumptions on function approximation and bounded trajectory concentrability, we derive sample complexity bound. To our knowledge, APPO is the first offline PbRL algorithm to offer both statistical efficiency and practical applicability. Experimental results on continuous control tasks demonstrate that APPO effectively learns from complex datasets, showing comparable performance with existing state-of-the-art methods."
    },
    {
        "title": "Optimal Strong Regret and Violation in Constrained MDPs via Policy Optimization",
        "link_suffix": "/forum?id=8eNLKk5by4",
        "link": "https://openreview.net/forum?id=8eNLKk5by4",
        "pdf_link": "https://openreview.net/pdf?id=8eNLKk5by4",
        "keywords": "CMDP, strong regret, strong violations, primal-dual",
        "abstract": "We study online learning in constrained MDPs (CMDPs), focusing on the goal of attaining sublinear strong regret and strong cumulative constraint violation. Differently from their standard (weak) counterparts, these metrics do not allow negative terms to compensate positive ones, raising considerable additional challenges. Efroni et al. (2020) were the first to propose an algorithm with sublinear strong regret and strong violation, by exploiting linear programming. Thus, their algorithm is highly inefficient, leaving as an open problem achieving sublinear bounds by means of policy optimization methods, which are much more efficient in practice. Very recently, Muller et al. (2024) have partially addressed this problem by proposing a policy optimization method that allows to attain $\\widetilde{\\mathcal{O}}(T^{0.93})$ strong regret/violation. This still leaves open the question of whether optimal bounds are achievable by using an approach of this kind. We answer such a question affirmatively, by providing an efficient policy optimization algorithm with $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ strong regret/violation. Our algorithm implements a primal-dual scheme that employs a state-of-the-art policy optimization approach for adversarial (unconstrained) MDPs as primal algorithm, and a UCB-like update for dual variables."
    },
    {
        "title": "Structural Knowledge Informed Continual Learning for Multivariate Time Series Forecasting",
        "link_suffix": "/forum?id=B1TnT6lUnU",
        "link": "https://openreview.net/forum?id=B1TnT6lUnU",
        "pdf_link": "https://openreview.net/pdf?id=B1TnT6lUnU",
        "keywords": "Continual Learning, Multivariate Time Series Forecasting",
        "abstract": "Recent studies in multivariate time series (MTS) forecasting reveal that explicitly modeling the hidden dependencies among different time series can yield promising forecasting performance and reliable explanations. However, modeling variable dependencies remains underexplored when MTS is continuously accumulated under different regimes (stages). Due to the potential distribution and dependency disparities, the underlying model may encounter the catastrophic forgetting problem, i.e., it is challenging to memorize and infer different types of variable dependencies across different regimes while maintaining forecasting performance.\nTo address this issue, we propose a novel Structural Knowledge Informed Continual Learning (SKI-CL) framework to perform MTS forecasting within a continual learning paradigm, which leverages structural knowledge to steer the forecasting model toward identifying and adapting to different regimes, and selects representative MTS samples from each regime for memory replay.\nSpecifically, we develop a forecasting model based on graph structure learning, where a consistency regularization scheme is imposed between the learned variable dependencies and the structural knowledge (e.g., physical constraints, domain knowledge, feature similarity, which provides regime characterization) while optimizing the forecasting objective over the MTS data. As such, MTS representations learned in each regime are associated with distinct structural knowledge, which helps the model memorize a variety of conceivable scenarios and results in accurate forecasts in the continual learning context.\nMeanwhile, we develop a representation-matching memory replay scheme that maximizes the temporal coverage of MTS data to efficiently preserve the underlying temporal dynamics and dependency structures of each regime. \nThorough empirical studies on synthetic and real-world benchmarks validate SKI-CL's efficacy and advantages over the state-of-the-art for continual MTS forecasting tasks. SKI-CL can also infer faithful dependency structures that closely align to structural knowledge in the test stage."
    },
    {
        "title": "Collaborative Data Optimization",
        "link_suffix": "/forum?id=wixDdL0vj8",
        "link": "https://openreview.net/forum?id=wixDdL0vj8",
        "pdf_link": "https://openreview.net/pdf?id=wixDdL0vj8",
        "keywords": "Unlabeled Data, Data Optimization, Efficiency",
        "abstract": "Training efficiency plays a pivotal role in deep learning.\n    This paper begins by analyzing current methods for enhancing efficiency, highlighting the necessity of optimizing targets, a process we define as data optimization.\n    Subsequently, we reveal that current data optimization methods incur significant additional costs, e.g., human resources or computational overhead, due to their inherently sequential optimization process.\n    To address these issues, we propose CoOpt, a highly efficient, parallelized framework designed for collaborative data optimization.\n    CoOpt enables participants to independently optimize data subsets, ensuring that the overall performance, once these subsets are collected, remains comparable to the sequential optimization of the entire dataset, thus significantly reducing optimization costs for individual participants.\n    Extensive experiments have been conducted on various real-world scenarios to demonstrate the effectiveness and efficiency of CoOpt across various datasets and architectures."
    },
    {
        "title": "Monophilic Neighbourhood Transformers",
        "link_suffix": "/forum?id=oSdrJyb4UH",
        "link": "https://openreview.net/forum?id=oSdrJyb4UH",
        "pdf_link": "https://openreview.net/pdf?id=oSdrJyb4UH",
        "keywords": "graph neural networks, transformers",
        "abstract": "Graph neural networks (GNNs) have seen widespread application across diverse fields, including social network analysis, chemical research, and computer vision.\nNevertheless, their efficacy is compromised by an inherent reliance on the homophily assumption, which posits that adjacent nodes should exhibit relevance or similarity.\nThis assumption becomes a limitation when dealing with heterophilic graphs, where it is more common for dissimilar nodes to be connected.\nAddressing this challenge, recent research indicates that real-world graphs generally exhibit monophily, a characteristic where a node tends to be related to the neighbours of its neighbours.\nInspired by this insight, we introduce Neighbourhood Transformers (NT), a novel approach that employs self-attention within every neighbourhood of the graph to generate informative messages for the nodes within, as opposed to the central node in conventional GNN frameworks.\nWe develop a neighbourhood partitioning strategy equipped with switchable attentions, significantly reducing space consumption by over 95% and time consumption by up to 92.67% in NT.\nExperimental results on node classification tasks across 5 heterophilic and 5 homophilic graphs demonstrate that NT outperforms current state-of-the-art methods, showcasing their expressiveness and adaptability to different graph types.\nThe code for this study will be made available following the publication of this manuscript."
    },
    {
        "title": "TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles",
        "link_suffix": "/forum?id=wjgNVsbT3T",
        "link": "https://openreview.net/forum?id=wjgNVsbT3T",
        "pdf_link": "https://openreview.net/pdf?id=wjgNVsbT3T",
        "keywords": "Benchmark; LLM Evaluation",
        "abstract": "As the application of Large Language Models (LLMs) expands, the demand for reliable evaluations increases. Existing LLM evaluation benchmarks primarily rely on static datasets, making it challenging to assess model performance in dynamic interactions with users. Moreover, these benchmarks often depend on specific background knowledge, complicating the measurement of a model's logical reasoning capabilities. Other dynamic evaluation methods based on strong models or manual efforts may introduce biases and incur high costs and time demands, hindering large-scale application. To address these issues, we propose TurtleBench. TurtleBench collects real user guesses from our online Turtle Soup Puzzle platform that we developed. This approach allows for the relatively dynamic generation of evaluation datasets, mitigating the risk of model cheating while aligning assessments more closely with genuine user needs for reasoning capabilities, thus enhancing the reliability of evaluations. TurtleBench includes 1,532 user guesses along with the correctness of guesses after annotation. Using this dataset, we thoroughly evaluated nine of the most advanced LLMs available today. Notably, the OpenAI o1 series models did not achieve leading results in these evaluations. We propose several hypotheses for further research, such as \u201cthe latent reasoning of o1 utilizes trivial Chain-of-Thought (CoT) techniques\u201d and \u201cincreasing CoT length not only provides reasoning benefits but also incurs noise costs.\u201d"
    },
    {
        "title": "General Preference Modeling with Preference Representations for Aligning Language Models",
        "link_suffix": "/forum?id=xS4XOS4NQ5",
        "link": "https://openreview.net/forum?id=xS4XOS4NQ5",
        "pdf_link": "https://openreview.net/pdf?id=xS4XOS4NQ5",
        "keywords": "preference modeling, preference optimization, reinforcement learning from human feedback",
        "abstract": "Modeling human preferences is crucial for aligning foundation models with human values. Traditional reward modeling methods, such as the Bradley-Terry (BT) reward model, fall short in expressiveness, particularly in addressing intransitive preferences. Although supervised pair preference models (PairPM) can express general preferences, their implementation is highly ad-hoc and cannot guarantee a consistent preference probability of compared pairs. Additionally, they impose high computational costs due to their quadratic query complexity when comparing multiple responses. In this paper, we introduce preference representation learning, an approach that embeds responses into a latent space to capture intricate preference structures efficiently, achieving linear query complexity. Additionally, we propose preference score-based General Preference Optimization (GPO), which generalizes reward-based reinforcement learning from human feedback. Experimental results show that our General Preference representation model (GPM) outperforms the BT reward model on the RewardBench benchmark with a margin of up to 5.6% and effectively models cyclic preferences where any BT reward model behaves like a random guess. Furthermore, evaluations on downstream tasks such as AlpacaEval2.0 and MT-Bench, following the language model post-training with GPO and our general preference model, reveal substantial performance improvements with margins up to 9.3%. These findings indicate that our method may enhance the alignment of foundation models with nuanced human values."
    },
    {
        "title": "Explaining Vision-Language Similarities in Dual Encoders with Feature-Pair Attributions",
        "link_suffix": "/forum?id=plkrRJt98c",
        "link": "https://openreview.net/forum?id=plkrRJt98c",
        "pdf_link": "https://openreview.net/pdf?id=plkrRJt98c",
        "keywords": "Explainability, Attribution, Dual Encoder, Similarity, Vision-Language, CLIP",
        "abstract": "Dual encoder architectures like CLIP models map two types of inputs into a shared embedding space and learn similarities between them.\n  However, it is not understood how such models compare the two inputs.\n  We first derive a method to attribute predictions of any differentiable dual encoder onto feature-pair interactions between its inputs. \n  Second, we apply our method to CLIP models and show that they learn fine-grained correspondences between parts of captions and regions in images. They match objects across input modes and also account for mismatches. However, this visual-linguistic grounding ability heavily varies between object classes, depends on the training data distribution, and largely improves upon in-domain training.\n  Using our method we can identify individual failure cases and knowledge gaps about specific object classes."
    },
    {
        "title": "\u03bcLO: Compute-Efficient Meta-Generalization of Learned Optimizers",
        "link_suffix": "/forum?id=SkpY8Skqnv",
        "link": "https://openreview.net/forum?id=SkpY8Skqnv",
        "pdf_link": "https://openreview.net/pdf?id=SkpY8Skqnv",
        "keywords": "Meta Learning, Learned Optimizers, Pre-training",
        "abstract": "Learned optimizers (LOs) can significantly reduce the wall-clock training time of neural networks, substantially reducing training costs. However, they can struggle to optimize unseen tasks (meta-generalize), especially when training networks much larger than those seen during meta-training. To address this, we derive the Maximal Update Parametrization ($\\mu$P) for two popular learned optimizer architectures and propose a simple meta-training recipe for $\\mu$-parameterized LOs ($\\mu$LOs). Our empirical evaluation demonstrates that LOs meta-trained with our recipe substantially improve meta-generalization to wider unseen tasks when compared to LOs trained under standard parametrization (e.g., as they are trained in existing work). When applying our $\\mu$LOs, each trained for less than 250 GPU-hours, to large-width models we are often able to match or exceed the performance of pre-trained VeLO, the most performant publicly available learned optimizer, meta-trained with 4000 TPU-months of compute. We also observe that learned optimizers trained with our $\\mu$LO recipe also exhibit substantially improved meta-generalization to deeper networks ($5\\times$ meta-training) and remarkable generalization to much longer training horizons ($25\\times$ meta-training)."
    },
    {
        "title": "Endowing Visual Reprogramming with Adversarial Robustness",
        "link_suffix": "/forum?id=OuLgaHEmzi",
        "link": "https://openreview.net/forum?id=OuLgaHEmzi",
        "pdf_link": "https://openreview.net/pdf?id=OuLgaHEmzi",
        "keywords": "visual reprogramming, adversarial robustness, risk bound",
        "abstract": "Visual reprogramming (VR) leverages well-developed pre-trained models (e.g., a pre-trained classifier on ImageNet) to tackle target tasks (e.g., a traffic sign recognition task), without the need for training from scratch. Despite the effectiveness of previous VR methods, all of them did not consider the adversarial robustness of reprogrammed models against adversarial attacks, which could lead to unpredictable problems in safety-crucial target tasks. In this paper, we empirically find that reprogramming pre-trained models with adversarial robustness and incorporating adversarial samples from the target task during reprogramming can both improve the adversarial robustness of reprogrammed models. Furthermore, we propose a theoretically guaranteed adversarial robustness risk upper bound for VR, which validates our empirical findings and could provide a theoretical foundation for future research. Extensive experiments demonstrate that by adopting the strategies revealed in our empirical findings, the adversarial robustness of reprogrammed models can be enhanced."
    },
    {
        "title": "SyGRID: Synthetically Generated Realistic Industrial Dataset",
        "link_suffix": "/forum?id=U6UPhLBTcv",
        "link": "https://openreview.net/forum?id=U6UPhLBTcv",
        "pdf_link": "https://openreview.net/pdf?id=U6UPhLBTcv",
        "keywords": "artificial intelligence, simulated dataset, pose estimation, industrial automation, rendering",
        "abstract": "Industrial automation depends on accurate object recognition and localization tasks, such as depth estimation, instance segmentation, object detection, and 6D pose estimation. \nDespite significant advancements, numerous challenges persist, especially within industrial settings. To address these challenges, we propose \nSyGRID, (Synthetically Generated Realistic Industrial Dataset), a new simulated, realistic dataset specifically designed for industrial use cases. \nIts novelty lies in several aspects: the generated frames are photo-realistic images of objects commonly used in industrial settings, capturing their unique material properties; this includes reflection and refraction under varying environmental light conditions. Moreover, SyGRID includes multi-object and multi-instance cluttered scenes accurately accounting for rigid-body physics. \nAiming to narrow the currently existing gap between research and industrial applications, we also provide an exhaustive study on different tasks: namely 2D detection, segmentation, depth estimation and 6D pose estimation. These tasks of computer vision are essential for the integration of robotic applications such as grasping.\nSyGRID can significantly contribute to industrial tasks, leading to more reliable robotic operations. By providing this dataset, we aim to accelerate advancements in robotic automation, facilitating the alignment of current progress in computer vision with the practical demands of industrial robotic applications."
    },
    {
        "title": "PoTable: Programming Standardly on Table-based Reasoning Like a Human Analyst",
        "link_suffix": "/forum?id=fk4QS3j1sU",
        "link": "https://openreview.net/forum?id=fk4QS3j1sU",
        "pdf_link": "https://openreview.net/pdf?id=fk4QS3j1sU",
        "keywords": "Table-based Reasoning, Large Language Model, Symbolic Tools, Real-time Program Execution, Human Cognitive Behavior",
        "abstract": "Table-based reasoning has garnered substantial research interest, particularly in its integration with Large Language Model (LLM) which has revolutionized the general reasoning paradigm. Numerous LLM-based studies introduce symbolic tools (e.g., databases, Python) as assistants to extend human-like abilities in structured table understanding and complex arithmetic computations. However, these studies can be improved better in simulating human cognitive behavior when using symbolic tools, as they still suffer from limitations of non-standard logical splits and constrained operation pools. In this study, we propose PoTable as a novel table-based reasoning method that simulates a human tabular analyst, which integrates a Python interpreter as the real-time executor accompanied by an LLM-based operation planner and code generator. Specifically, PoTable follows a human-like logical stage split and extends the operation pool into an open-world space without any constraints. Through planning and executing in each distinct stage, PoTable standardly completes the entire reasoning process and produces superior reasoning results along with highly accurate, steply commented and completely executable programs. Accordingly, the effectiveness and explainability of PoTable are fully demonstrated. Extensive experiments over three evaluation datasets from two public benchmarks on two backbones show the outstanding performance of our approach. In particular, GPT-based PoTable achieves over 4% higher absolute accuracy than runner-ups on all evaluation datasets. Our code is available athttps://anonymous.4open.science/r/PoTable-6788."
    },
    {
        "title": "Multilayer Correlation Clustering",
        "link_suffix": "/forum?id=w2uIJiHTIA",
        "link": "https://openreview.net/forum?id=w2uIJiHTIA",
        "pdf_link": "https://openreview.net/pdf?id=w2uIJiHTIA",
        "keywords": "Clustering, Correlation Clustering, Multilayer Networks, Approximation Algorithms",
        "abstract": "We establish Multilayer Correlation Clustering, a novel generalization of Correlation Clustering to the multilayer setting. In this model, we are given a series of inputs of Correlation Clustering (called layers) over the common set $V$ of $n$ elements. The goal is to find a clustering of $V$ that minimizes the $\\ell_p$-norm ($p\\geq 1$) of the disagreements vector, which is defined as the vector (with dimension equal to the number of layers), each element of which represents the disagreements of the clustering on the corresponding layer. For this generalization, we first design an $O(L\\log n)$-approximation algorithm, where $L$ is the number of layers. We then study an important special case of our problem, namely the problem with the so-called probability constraint. For this case, we first give an $(\\alpha+2)$-approximation algorithm, where $\\alpha$ is any possible approximation ratio for the single-layer counterpart. Furthermore, we design a $4$-approximation algorithm, which improves the above approximation ratio of $\\alpha+2=4.5$ for the general probability-constraint case. Computational experiments using real-world datasets support our theoretical findings and demonstrate the practical effectiveness of our proposed algorithms."
    },
    {
        "title": "ALR2: A Retrieve-then-Reason Framework for Long-context Question Answering",
        "link_suffix": "/forum?id=RIXuX37Hh7",
        "link": "https://openreview.net/forum?id=RIXuX37Hh7",
        "pdf_link": "https://openreview.net/pdf?id=RIXuX37Hh7",
        "keywords": "Long context, Retrieval-Augmented Generation, Question Answering, Large Language Model",
        "abstract": "The context window of large language models (LLMs) has been extended significantly in recent years. However, while the context length that the LLM can process has grown, the capability of the model to accurately reason over that context degrades noticeably. \nThis occurs because modern LLMs often become overwhelmed by the vast amount of information in the context; when answering questions, the model must identify and reason over relevant evidence sparsely distributed throughout the text. To alleviate the challenge of long-context reasoning, we develop a retrieve-then-reason framework, enabling LLMs to reason over relevant evidence collected during an intermediate retrieval step. We find that modern LLMs struggle to accurately retrieve relevant facts and instead, often hallucinate \"retrieved facts\", resulting in flawed reasoning and the production of incorrect answers. To address these issues, we introduce ALR$^2$, a method that augments the long-context reasoning capability of LLMs via an explicit two-stage procedure, i.e., aligning LLMs with the objectives of both retrieval and reasoning. We demonstrate the efficacy of ALR$^2$ for mitigating performance degradation in long-context reasoning tasks. Through extensive experiments on long-context QA benchmarks, we find our method to outperform competitive baselines by large margins, achieving at least 8.4 and 7.9 EM gains on the long-context versions of HotpotQA and SQuAD datasets, respectively."
    },
    {
        "title": "UniEEG: Advancing Universal EEG Representation with Electrode-Wise Time-Frequency Pretraining",
        "link_suffix": "/forum?id=6uReXuDWrw",
        "link": "https://openreview.net/forum?id=6uReXuDWrw",
        "pdf_link": "https://openreview.net/pdf?id=6uReXuDWrw",
        "keywords": "EEG representation, EEG pretraining",
        "abstract": "Previous electroencephalogram (EEG) models typically exhibit limited performance and generalization by collecting data specifically for targeted EEG tasks. Recognizing this limitation, we propose UniEEG, the first electrode-wise time-frequency pretraining model, designed to overcome barriers across diverse tasks and data in EEG modeling. We collect data from nearly 20 publicly available EEG datasets, including 6 EEG tasks, significantly extending the data volume. The collected EEG data are standardized and split to individual electrodes as the input of UniEEG, enabling full compatibility with diverse EEG data from different acquisition devices and task paradigms. Meanwhile, leveraging a time-frequency transform method, UniEEG adeptly processes EEG signals characterized by signal noises and time delays. In the training phase, we employ an encoder-decoder architecture and a mask signal modeling strategy on time-frequency dimension, learning the electrode-wise universal EEG representation. In the fine-tuning phase, multi-electrode EEG signals from various tasks are consolidated into individual electrodes. The predictions for downstream tasks are then obtained through the pre-trained encoder and an additional prediction module. Furthermore, the proposed UniEEG achieves state-of-the-art performance across different EEG tasks, demonstrating an amazing ability to universal EEG feature representation.\nCode, data and models would be available upon acceptance."
    },
    {
        "title": "Systematic Relational Reasoning With Epistemic Graph Neural Networks",
        "link_suffix": "/forum?id=qNp86ByQlN",
        "link": "https://openreview.net/forum?id=qNp86ByQlN",
        "pdf_link": "https://openreview.net/pdf?id=qNp86ByQlN",
        "keywords": "Reasoning, Graph Neural Networks, Neuro-Symbolic methods, Systematic Generalization, Compositionality",
        "abstract": "Developing models that can learn to reason is a notoriously challenging problem. We focus on reasoning in relational domains, where the use of Graph Neural Networks (GNNs) seems like a natural choice. However, previous work has shown that regular GNNs lack the ability to systematically generalize from training examples on test graphs requiring longer inference chains, which fundamentally limits their reasoning abilities. A common solution relies on neuro-symbolic methods that systematically reason by learning rules, but their scalability is often limited and they tend to make strong assumptions which do not always hold, e.g. that the answer can always be inferred from a single relational path. We propose the Epistemic GNN (EpiGNN), a novel parameter-efficient and scalable GNN architecture with an epistemic inductive bias for systematic reasoning. Node embeddings in EpiGNNs are treated as epistemic states, and message passing  is implemented accordingly. We show that EpiGNNs achieve state-of-the-art results on link prediction tasks that require systematic reasoning. Furthermore, for inductive knowledge graph completion, EpiGNNs rival the performance of state-of-the-art specialized approaches. Finally, we introduce two new benchmarks that go beyond standard relational reasoning by requiring the aggregation of information from multiple paths. Here, existing neuro-symbolic approaches fail, yet EpiGNNs learn to reason accurately."
    },
    {
        "title": "A Federated Graph Learning Framework With Attention Mechanism and Clustering Algorithm",
        "link_suffix": "/forum?id=IoonroIpfD",
        "link": "https://openreview.net/forum?id=IoonroIpfD",
        "pdf_link": "https://openreview.net/pdf?id=IoonroIpfD",
        "keywords": "Industrial Internet of Things, Federated Graph Learning, Graph Neural Networks, Attention Mechanism, Clustering Algorithm",
        "abstract": "With the development of the industrial Internet of Things, graph data is also increasing, but these data are held by different clients, and due to client privacy and data security, it is impossible to integrate all the data for unified model training. Federated graph learning can overcome this difficulty very well. It allows clients to participate in the training of the overall model of other clients without revealing their own private data during training, thus protecting the security of clients' private data. However, how to improve the utilization efficiency of client upload parameters to improve the effect of model training and how to process the large amount of initial data owned by clients is an issue that needs to be solved urgently. This paper proposes a federated graph learning framework with attention mechanism and clustering algorithm (${FGL}{AC}$). First, before the client participates in training, a clustering algorithm is used to perform a simple preprocessing operation on the large amount of data held to reduce the overall model training burden and improve training accuracy. Then during the server's process of aggregating model parameters, through the adaptive ability of the attention mechanism, the parameters uploaded by different clients are configured with different weights to obtain the best weight parameters to improve the training effect of the overall model. In order to further verify the effectiveness of ${FGL}{AC}$, experimental verification was conducted on different data sets. The results show that in most cases, ${FGL}_{AC}$ can achieve an improvement of 2.63% - 4.03% compared to other federated graph learning frameworks."
    },
    {
        "title": "Test-Time Adversarial Defense with Opposite Adversarial Path and high Attack time cost",
        "link_suffix": "/forum?id=nKSkM5h2VN",
        "link": "https://openreview.net/forum?id=nKSkM5h2VN",
        "pdf_link": "https://openreview.net/pdf?id=nKSkM5h2VN",
        "keywords": "Adversarial Attack, Adversarial Defense, Diffusion Models, Purifier, Robustness, Security",
        "abstract": "Deep learning models are known to be vulnerable to adversarial attacks by injecting sophisticated designed perturbations to input data. Training-time defenses still exhibit a significant performance gap between natural accuracy and robust accuracy. In this paper, we investigate a new test-time adversarial defense method via diffusion-based recovery along opposite adversarial paths (OAPs). We present a purifier that can be plugged into a pre-trained model to resist adversarial attacks. Different from prior arts, the key idea is excessive denoising or purification by integrating the opposite adversarial direction with reverse diffusion to push the input image further toward the opposite adversarial direction. For the first time, we also exemplify the pitfall of conducting AutoAttack (Rand) for diffusion-based defense methods. Through the lens of time complexity, we examine the trade-off between the effectiveness of adaptive attack and its computation complexity against our defense. Experimental evaluation along with time cost analysis verifies the effectiveness of the proposed method."
    },
    {
        "title": "RetroInText: A Multimodal Large Language Model Enhanced Framework for Retrosynthetic Planning via In-Context Representation Learning",
        "link_suffix": "/forum?id=J6e4hurEKd",
        "link": "https://openreview.net/forum?id=J6e4hurEKd",
        "pdf_link": "https://openreview.net/pdf?id=J6e4hurEKd",
        "keywords": "Retrosynthetic Planning, Route Evaluation, In-Context Learning, Large Language Model",
        "abstract": "Development of robust and effective strategies for retrosynthetic planning requires a deep understanding of the synthesis process. A critical step in achieving this goal is accurately identifying synthetic intermediates. Current machine learning-based methods often overlook the valuable context from the overall route, focusing only on predicting reactants from the product, requiring cost annotations for every reaction step, and ignoring the multi-faced nature of molecular, resulting in inaccurate synthetic route predictions. Therefore, we introduce RetroInText, an advanced end-to-end framework based on a multimodal Large Language Model (LLM), featuring in-context learning with TEXT descriptions of synthetic routes. First, RetroInText including ChatGPT presents detailed descriptions of the reaction procedure. It learns the distinct compound representations in parallel with corresponding molecule encoders to extract multi-modal representations including 3D features. Subsequently, we propose an attention-based mechanism that offers a fusion module to complement these multi-modal representations with in-context learning and a fine-tuned LLM for a single-step model. As a result, RetroInText accurately represents and effectively captures the complex relationship between molecules and the synthetic route. In experiments on the USPTO pathways dataset RetroBench, RetroInText outperformed state-of-the-art methods, achieving up to a 5% improvement in Top-1 test accuracy, particularly for long synthetic routes. These results demonstrate the superiority of RetroInText by integrating with context information over routes. They also demonstrate its potential for advancing pathway design and facilitating the development of organic chemistry."
    },
    {
        "title": "Sinc Kolmogorov-Arnold Network and Its Applications on Physics-informed Neural Networks",
        "link_suffix": "/forum?id=ihHeqPLRDk",
        "link": "https://openreview.net/forum?id=ihHeqPLRDk",
        "pdf_link": "https://openreview.net/pdf?id=ihHeqPLRDk",
        "keywords": "Physics-informed neural networks, Kolmogorov-Arnold Networks, Partial differential equations, Computational physics.",
        "abstract": "In this paper, we propose to use Sinc interpolation in the context of Kolmogorov-Arnold Networks, neural networks with learnable activation functions, which recently gained attention as alternatives to multilayer perceptron. Many different function representations have already been tried, but we show that Sinc interpolation proposes a viable alternative, since it is known in numerical analysis to represent well both smooth functions and functions with singularities. This is important not only for function approximation but also for the solutions of partial differential equations with physics-informed neural networks. Through a series of experiments, we show that SincKANs provide better results in almost all of the examples we have considered."
    },
    {
        "title": "MAC: A Multimodal Benchmark for Understanding and Generating Academic Journal Covers",
        "link_suffix": "/forum?id=wwXgvjNmt5",
        "link": "https://openreview.net/forum?id=wwXgvjNmt5",
        "pdf_link": "https://openreview.net/pdf?id=wwXgvjNmt5",
        "keywords": "Benchmark, Multi-modality, Large Multimodal Models",
        "abstract": "We introduce the Multimodal Academic Cover (MAC) benchmark to address the challenges of Large Multimodal Models (LMMs) in understanding and generating academic journal covers. While LMMs have demonstrated significant progress in creative arts and everyday applications, their capabilities in comprehending complex academic visuals and narratives remain underexplored. MAC comprises\na collection of 5,872 cover images, accompanying cover stories, and associated articles from 40 prominent academic journals, providing a rich dataset for evaluation. We design bidirectional generative tasks\u2014Image2Text and Text2Imag to assess authenticity and creativity in generating cover images and stories. Current LMMs, including DALL\u00b7E 3, GPT-4V, Gemini, CogView-3, GLM-4V, LLaVA, LLaMA-adapter, and MiniGPT4, are evaluated on this benchmark. Furthermore, we propose Multimodal Agent Linkage (MAL), a novel method to enhance conceptual comprehension within a long-context window. In-context learning techniques, such as few-shot learning, are also explored to improve the effectiveness of LMMs. All benchmarks, prompts, and codes will be released publicly."
    },
    {
        "title": "Towards Optimizing Top-KRanking Metrics in Recommender Systems",
        "link_suffix": "/forum?id=bHNVmLDtFo",
        "link": "https://openreview.net/forum?id=bHNVmLDtFo",
        "pdf_link": "https://openreview.net/pdf?id=bHNVmLDtFo",
        "keywords": "Recommender Systems, Surrogate Loss, Top-K Recommendation, NDCG@K",
        "abstract": "In the realm of recommender systems (RS), Top-$K$ metrics such as NDCG@$K$ are the gold standard for evaluating performance. Nonetheless, during the training of recommendation models, optimizing NDCG@$K$ poses significant challenges due to its inherent discontinuous nature and the intricacies of the Top-K truncation mechanism. Recent efforts to optimize NDCG@$K$ have either neglected the Top-$K$ truncation or suffered from low computational efficiency. To overcome these limitations, we propose SoftmaxLoss@$K$ (SL@$K$), a new loss function designed as a surrogate for optimizing NDCG@$K$ in RS. SL@$K$ integrates a quantile-based technique to handle the complex truncation term; and derives a smooth approximation of NDCG@$K$ to address discontinuity. Our theoretical analysis confirms the close bounded relationship between NDCG@$K$ and SL@$K$.Besides, SL@$K$ also exhibits several desirable properties including concise formulation, computational efficiency, and noisy robustness. Extensive experiments on four real-world datasets and three recommendation backbones demonstrate that SL@$K$ outperforms existing loss functions with a notable average improvement of 6.19%."
    },
    {
        "title": "XAIguiFormer: explainable artificial intelligence guided transformer for brain disorder identification",
        "link_suffix": "/forum?id=AD5yx2xq8R",
        "link": "https://openreview.net/forum?id=AD5yx2xq8R",
        "pdf_link": "https://openreview.net/pdf?id=AD5yx2xq8R",
        "keywords": "EEG, Explainable Artificial Intelligence (XAI), Explanation-Guided Learning, Transformer",
        "abstract": "EEG-based connectomes offer a low-cost and portable method to identify brain disorders using deep learning. With the growing interest in model interpretability and transparency, explainable artificial intelligence (XAI) is widely applied to understand the decision of deep learning models. However, most research focuses solely on interpretability analysis based on the insights from XAI, overlooking XAI\u2019s potential to improve model performance. To bridge this gap, we propose a dynamical-system-inspired architecture, XAI guided transformer (XAIguiFormer), where XAI not only provides explanations but also contributes to enhancing the transformer by refining the originally coarse information in self-attention mechanism to capture more relevant dependency relationships. In order not to damage the connectome\u2019s topological structure, the connectome tokenizer treats the single-band graphs as atomic tokens to generate a sequence in the frequency domain. To address the limitations of conventional positional encoding in understanding the frequency and mitigating the individual differences, we integrate frequency and demographic information into tokens via a rotation matrix, resulting in a richly informative representation. Our experiment demonstrates that XAIguiFormer achieves superior performance over all baseline models. In addition, XAIguiFormer provides valuable interpretability through visualization of the frequency band importance. Our code will be publicly available after acceptance."
    }
]
[
    {
        "title": "Evolving Symbolic 3D Visual Grounder with Weakly Supervised Reflection",
        "link_suffix": "/forum?id=K1VT7ItD40",
        "link": "https://openreview.net/forum?id=K1VT7ItD40",
        "pdf_link": "https://openreview.net/pdf?id=K1VT7ItD40",
        "keywords": "3D Visual Grounding, Code Generation",
        "abstract": "Understanding the behavior of an end-to-end 3D visual grounder is challenging, especially when the grounder makes an unexpected prediction. Despite the llm agent-based grounders performing step-by-step interpretable reasoning, the cost for evaluation at scale is prohibitive. To address the challenges, in this work, we propose a novel fully interpretable symbolic framework for 3D visual grounding,\nnamely Evolvable Symbolic Visual Grounder (EASE), with much less inference cost and superior performance. Given a symbolic expression of a grounding description translated by an LLM, EASE calculates the feature of each concept utilizing a set of explicit programs in Python learned from a tiny subset of the training data. To learn this program library, we introduce a learning paradigm that continuously optimizes the programs on the training dataset by an LLM-based optimizer. We demonstrate that our paradigm is scalable when more data is involved. Experiments on ReferIt3D show EASE achieves 50.7% accuracy on Nr3D, which surpasses most training-free methods and has considerable advantages in inference time and cost. On Sr3D, EASE also has comparable overall performance with these approaches. Moreover, we perform extensive experiments to analyze the interpretability and feature quality and reveal the potential for reasoning and\ncondition level grounding."
    },
    {
        "title": "Multi-Channel Graph Convolutions",
        "link_suffix": "/forum?id=pl2c1PoiGO",
        "link": "https://openreview.net/forum?id=pl2c1PoiGO",
        "pdf_link": "https://openreview.net/pdf?id=pl2c1PoiGO",
        "keywords": "graph convolution, spectral graph convolution, message-passing neural network",
        "abstract": "Defining the convolution on graphs has led to much progress in graph machine learning, particularly through approximations based on polynomials and, ultimately, message-passing neural networks (MPNNs). However, this convolution is defined for single-channel graph signals, i.e., a single feature is given at each node, and a single new feature is assigned to each node. As multiple initial node features are provided for many challenging tasks and convolutions are generally defined for these multi-channel signals, we introduce multi-channel graph convolutions (MCGCs) by obtaining their form using the graph Fourier transform. MCGCs highlight the critical importance of utilizing multiple edge relations to amplify different signals for each feature channel. We further introduce localized multi-channel MPNNs and the multi-channel graph isomorphism network (MC-GINs), with which we can provably obtain linear mappings that are injective on multisets. Our experiments confirm the greatly improved capabilities of MCGCs and MC-GINs."
    },
    {
        "title": "ImputeINR: Enhancing Time Series Imputation with Adaptive Group-based Implicit Neural Representations",
        "link_suffix": "/forum?id=xcPN6Or88c",
        "link": "https://openreview.net/forum?id=xcPN6Or88c",
        "pdf_link": "https://openreview.net/pdf?id=xcPN6Or88c",
        "keywords": "time series imputation, implicit neural representations",
        "abstract": "Time series data frequently exhibit the presence of missing values, rendering imputation a crucial process for downstream time series tasks and applications. However, existing imputation methods focus on discrete data points and are unable to effectively model sparse data, resulting in particularly poor performance for imputing substantial missing values. In this paper, we propose a novel approach, ImputeINR, for time series imputation by employing implicit neural representations (INR) to learn continuous functions for time series. ImputeINR leverages the merits of INR that the continuous functions are not coupled to sampling frequency and have infinite sampling frequency, allowing ImputeINR to generate fine-grained imputations even on extremely absent observed values. In addition, we introduce a multi-scale feature extraction module in ImputeINR architecture to capture patterns from different time scales, thereby effectively enhancing the fine-grained and global consistency of the imputation. To address the unique challenges of complex temporal patterns and multiple variables in time series, we design a specific form of INR continuous function that contains three additional components to learn trend, seasonal, and residual information separately. Furthermore, we innovatively propose an adaptive group-based framework to model complex residual information, where variables with similar distributions are modeled by the same group of multilayer perception layers to extract necessary correlation features. Since the number of groups and their output variables are determined by variable clustering, ImputeINR has the capacity of adapting to diverse datasets. Extensive experiments conducted on seven datasets with five ratios of missing values demonstrate the superior performance of ImputeINR, especially for high absent ratios in time series."
    },
    {
        "title": "Kolmogorov\u2013Arnold Graph Neural Networks",
        "link_suffix": "/forum?id=udfjje2xXb",
        "link": "https://openreview.net/forum?id=udfjje2xXb",
        "pdf_link": "https://openreview.net/pdf?id=udfjje2xXb",
        "keywords": "Graph Neural Networks, Kolmogorov-Arnold Networks, Interpretability",
        "abstract": "Graph neural networks (GNNs) excel in learning from network-like data but often lack interpretability, making their application challenging in domains requiring transparent decision-making. We propose the Kolmogorov\u2013Arnold Network for Graphs (KANG), a novel GNN model leveraging spline-based activation functions on edges to enhance both accuracy and interpretability. Our experiments on five benchmark datasets demonstrate that KANG outperforms state-of-the-art GNN models in node classification, link prediction, and graph classification tasks. In addition to the improved accuracy, KANG\u2019s design inherently provides insights into the model\u2019s decision-making process, eliminating the need for post-hoc explainability techniques. This paper discusses the methodology, performance, and interpretability of KANG, highlighting its potential for applications in domains where interpretability is crucial."
    },
    {
        "title": "Measuring And Improving Persuasiveness Of Generative Models",
        "link_suffix": "/forum?id=NfCEVihkdC",
        "link": "https://openreview.net/forum?id=NfCEVihkdC",
        "pdf_link": "https://openreview.net/pdf?id=NfCEVihkdC",
        "keywords": "llm, transsuasion, persuasion, PersuasionArena, PersuasionBench",
        "abstract": "Large Language Models (LLMs) are increasingly being used in workflows involving generating content to be consumed by humans (e.g., marketing) and also in directly interacting with humans (e.g., through chatbots). The development of such systems that are capable of generating verifiably persuasive messages presents both opportunities and challenges for society. On the one hand, such systems could\npositively impact domains like advertising and social good, such as addressing drug addiction, and on the other, they could be misused for spreading misinformation and shaping political opinions. To channel LLMs\u2019 impact on society, we need to develop systems to measure and benchmark their persuasiveness. With this motivation, we introduce PersuasionBench and PersuasionArena, the first largescale\nbenchmark and arena containing a battery of tasks to measure the persuasion ability of generative models automatically. We introduce transsuasion (trans = carrying across, suasion = the act of persuading), a novel task of transforming non-persuasive language into persuasive content while preserving other factors determining persuasiveness (sender, receiver, time, and channel). To construct data\nfor transsuasion, we leverage natural experiments in the form of a pair of tweets from the same user, posted in close temporal proximity, with similar semantic content but divergent wording and significantly different like counts. Given such pairs, we investigate to what extent LLMs know and leverage linguistic patterns that can help them generate more persuasive language. Our findings indicate that the\npersuasiveness of LLMs correlates positively with model size, but smaller models can also be made to have a higher persuasiveness than much larger models. Notably, targeted training using synthetic and natural datasets significantly enhances smaller models\u2019 persuasive capabilities, challenging scale-dependent assumptions. Our findings carry key implications for both model developers and policymakers. For instance, while California\u2019s SB-1047 aims to regulate AI models based on the number of floating point operations, we demonstrate that simple metrics like this alone fail to capture the full scope of AI\u2019s societal impact. We invite the community to explore and contribute to PersuasionArena and PersuasionBench, to advance our understanding of AI-driven persuasion and its societal implications."
    },
    {
        "title": "Generalization of noisy SGD under isoperimetry",
        "link_suffix": "/forum?id=0VP3LuzZ8K",
        "link": "https://openreview.net/forum?id=0VP3LuzZ8K",
        "pdf_link": "https://openreview.net/pdf?id=0VP3LuzZ8K",
        "keywords": "generalization, langevin, non-convex, information theory",
        "abstract": "We study generalization of iterative noisy gradient schemes on smooth non-convex losses. Formally, we establish time-independent information theoretic generalization bounds for Stochastic Gradient Langevin Dynamics (SGLD) that do not diverge as the iteration count increases. Our bounds are obtained through a stability argument: we analyze the distance between SGLD iterates on two datasets sampled from the same distribution. Our result only requires an isoperimetric inequality to hold, which is merely a restriction on the tails of the loss. We thus relax the assumptions of prior work to establish that the iterates stay within a bounded KL divergence from each other. Under an additional dissipativity assumption, we show that the stronger Renyi divergence also stays bounded by establishing a uniform log-Sobolev constant of the iterates. Without dissipativity, we side step the need for local log-Sobolev inequalities and instead exploit the regularizing properties of Gaussian convolution. These techniques allow us to show that strong convexity is not necessary for finite stability bounds and thus for finite generalization and differential privacy bounds."
    },
    {
        "title": "Learning Explicit Circuit Representations for Quantum States from Local Measurements",
        "link_suffix": "/forum?id=TpqU4PzvV9",
        "link": "https://openreview.net/forum?id=TpqU4PzvV9",
        "pdf_link": "https://openreview.net/pdf?id=TpqU4PzvV9",
        "keywords": "quantum state learning, quantum circuit construction, local measurements, reinforcement learning",
        "abstract": "Characterizing quantum states is essential for advancing many quantum technologies. Recently, deep neural networks have been applied to learn quantum states by generating implicit representations that map them into classical vectors. Despite their success in predicting state properties, these representations remain a black box, lacking insights into strategies for experimental reconstruction. In this work, we aim to open this black box by developing explicit representations of quantum states through the generation of preparation circuits using a reinforcement learning agent with a local fidelity reward function. Relying solely on measurement data from a few neighboring qubits, our agent accurately recovers global properties of target states. Specifically, we design a quantum measurement feature aggregation block which is used to extract global features of quantum states from local measurement data. We also provide a theoretical guarantee for the proposed local fidelity reward function. Extensive experiments demonstrate the effectiveness of our approach in learning various quantum states of up to 100 qubits, including those generated by Instantaneous Quantum Polynomial circuits, evolved by Ising Hamiltonians, and many-body ground states. The learned circuit representations can be further applied to Hamiltonian learning as a downstream task utilizing a simple linear model."
    },
    {
        "title": "InvestAlign: Align LLMs with Investor Decision-Making under Herd Behavior",
        "link_suffix": "/forum?id=pxy5wDMnzv",
        "link": "https://openreview.net/forum?id=pxy5wDMnzv",
        "pdf_link": "https://openreview.net/pdf?id=pxy5wDMnzv",
        "keywords": "Alignment, Investment decision, Large language model, Supervised fine-tuning",
        "abstract": "Studying investor decision-making processes under herd behavior is of great significance in microeconomics and behavioral finance. Large Language Models (LLMs) can be leveraged to assist in solving complex investment problems. However, the investment decisions generated by existing LLMs often deviate from real-user data. One method to align LLMs with investor decision-making processes is Supervised Fine-Tuning (SFT), which requires a substantial amount of real-user data that is costly to collect and raises concerns about privacy and security. In this work, we propose InvestAlign, a low-cost and high-quality method that constructs large-scale SFT training datasets based on theoretical solutions to a similar and simpler optimal investment problem, rather than the original complex one. We theoretically demonstrate that fine-tuning LLMs with these datasets leads to faster parameter convergence compared to using real-user data. By fine-tuning LLMs, we obtain InvestAgents, which align more closely with real-user data than pre-SFT LLMs in both the simple and original complex problems. This highlights InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes in economics and finance."
    },
    {
        "title": "Efficient Over-parameterized Matrix Sensing via Alternating Preconditioned Gradient Descent",
        "link_suffix": "/forum?id=b6juTJZ1I9",
        "link": "https://openreview.net/forum?id=b6juTJZ1I9",
        "pdf_link": "https://openreview.net/pdf?id=b6juTJZ1I9",
        "keywords": "matrix sensing, over-parameterization, low rank matrix recovery, gradient descent",
        "abstract": "We consider solving the low-rank matrix sensing problem in the over-parameterized setting, where the specified rank is larger than the true rank. Precisely, our main objective is to recover a matrix $X^*\\in\\mathbb{R}^{n_1\\times n_2}$ with rank $r_\\star$ using an over-parameterized form $LR^{\\top}$, where $L\\in\\mathbb{R}^{n_1\\times r},\\ R\\in\\mathbb{R}^{n_2\\times r}$ and $\\min(n_1,n_2)\\ge r> r_\\star$ with the true rank $r_\\star$ being unknown. The commonly used methods tackling such a problem such as Factorized Gradient Descent (FGD) can only demonstrate sub-linear convergence behavior, and their performance could significantly deteriorate when the matrix condition number is relatively large. To address this issue, we propose the Alternating Preconditioned Gradient Descent (APGD) method that an inexpensive right preconditioner with a constant damping parameter is applied to the original gradient. We prove that even starting from a random initialization, APGD can recover the target matrix at a linear convergence rate in the over-parameterized situation, independent of the condition number. Notably, unlike previous methods such as FGD, APGD does not rely on small initialization or small step sizes, enabling faster convergence. Through a series of experiments, we demonstrate that APGD achieves the fastest convergence speed compared to other methods, and further possesses of strong robustness with respect to step size, condition number and other parameters."
    },
    {
        "title": "Low Compute Unlearning via Sparse Representations",
        "link_suffix": "/forum?id=nb3VjILNVs",
        "link": "https://openreview.net/forum?id=nb3VjILNVs",
        "pdf_link": "https://openreview.net/pdf?id=nb3VjILNVs",
        "keywords": "Sparse Representations, Discrete Bottlenecks, Model Editing, Unlearning",
        "abstract": "Machine \\emph{unlearning}, which involves erasing knowledge about a \\emph{forget set} from a trained model, can prove to be \ncostly and infeasible using existing techniques. We propose a  low compute unlearning technique based on a discrete representational bottleneck. We show that the proposed technique efficiently unlearns the forget set and incurs negligible damage to the model's performance on the rest of the data set. We evaluate the proposed technique on the problem ofclass unlearningusing four datasets: CIFAR-10, CIFAR-100, LACUNA-100 and ImageNet-1k. We compare the proposed technique to SCRUB, a state-of-the-art approach which uses knowledge distillation for unlearning. Across all three datasets, the  proposed technique performs as well as, if not better than SCRUB while incurring minimal computational cost."
    },
    {
        "title": "Towards Efficient and Scalable Implementation of Differentially Private Deep Learning",
        "link_suffix": "/forum?id=FhLOZF8Tsm",
        "link": "https://openreview.net/forum?id=FhLOZF8Tsm",
        "pdf_link": "https://openreview.net/pdf?id=FhLOZF8Tsm",
        "keywords": "differential privacy, gradient based optimization, computational efficiency, distributed computing",
        "abstract": "Differentially private stochastic gradient descent (DP-SGD) is the standard algorithm for training machine learning models under differential privacy (DP). The most common DP-SGD privacy accountants rely on Poisson subsampling for ensuring the theoretical DP guarantees. Implementing computationally efficient DP-SGD with Poisson subsampling is not trivial, which leads to many implementations ignoring this requirement. We conduct a comprehensive empirical study to quantify the computational cost of training deep learning models under DP given the requirement of Poisson subsampling, by re-implementing efficient methods using Poisson subsampling and benchmarking them. We find that using the naive implementation DP-SGD with Opacus in PyTorch has between 2.6 and 8 times lower throughput of processed training examples per second than SGD. However, efficient gradient clipping implementations with e.g. Ghost Clipping can roughly halve this cost. We propose alternative computationally efficient ways of implementing DP-SGD with JAX that are using Poisson subsampling and achieve only around 1.2 times lower throughput than SGD based on PyTorch. We highlight important implementation considerations with JAX. Finally, we study the scaling behaviour using up to 80 GPUs and find that DP-SGD scales better than SGD."
    },
    {
        "title": "Accelerating 3D Molecule Generation via Jointly Geometric Optimal Transport",
        "link_suffix": "/forum?id=VGURexnlUL",
        "link": "https://openreview.net/forum?id=VGURexnlUL",
        "pdf_link": "https://openreview.net/pdf?id=VGURexnlUL",
        "keywords": "Molecule Generation, Flow Matching, Fast Generation",
        "abstract": "This paper proposes a new 3D molecule generation framework, called GOAT, for fast and effective 3D molecule generation based on the flow-matching optimal transport objective. Specifically, we formulate a geometric transport formula for measuring the cost of mapping multi-modal features (e.g., continuous atom coordinates and categorical atom types) between a base distribution and a target data distribution. Our formula is solved within a joint, equivariant, and smooth representation space. This is achieved by transforming the multi-modal features into a continuous latent space with equivariant networks. In addition, we find that identifying optimal distributional coupling is necessary for fast and effective transport between any two distributions. We further propose a flow refinement and purification mechanism for optimal coupling identification. By doing so, GOAT can turn arbitrary distribution couplings into new deterministic couplings, leading to a joint optimal transport path for fast 3D molecule generation. The purification filters out the subpar molecules to ensure the ultimate generation quality. We theoretically and empirically prove that the proposed flow refinement and purification yield transport plan with non-increasing cost. Finally, extensive experiments show that GOAT enjoys the efficiency of solving geometric optimal transport, leading to a double speedup compared to the sub-optimal method while achieving the best generation quality regarding validity, uniqueness, and novelty."
    },
    {
        "title": "Supervised Band Selection with a Concrete Layer for Hyperspectral Imagery in Remote Sensing and Autonomous Driving",
        "link_suffix": "/forum?id=PauyrluLud",
        "link": "https://openreview.net/forum?id=PauyrluLud",
        "pdf_link": "https://openreview.net/pdf?id=PauyrluLud",
        "keywords": "hyperspectral imagery, band selection, Gumbel-Softmax, concrete layer, remote sensing, autonomous driving, deep learning, semantic segmentation, plug-and-play models",
        "abstract": "Hyperspectral imagery captures rich spectral information, which is valuable for a wide range of applications but poses challenges due to high data dimensionality. Current band selection methods are often computationally intensive, non-embedded, or lack adaptability for specific tasks. We address this gap by introducing a novel plug-and-play embedded method for supervised band selection in hyperspectral imagery, utilizing a concrete selector layer based on the Gumbel-Softmax re-parameterization trick. Our approach allows for dynamic and task-specific selection of optimal bands, eliminating the need for pre-processing and enabling seamless integration with downstream models. We evaluated the method on four hyperspectral datasets, covering three remote sensing benchmarks and an autonomous driving task, demonstrating consistent improvements over state-of-the-art methods. This is the first work to perform comprehensive band-selection research on an autonomous driving dataset of this type, and the first to employ a concrete layer for supervised band selection. Our findings highlight the potential of this approach for real-time hyperspectral analysis in applications such as autonomous driving and environmental monitoring, laying the groundwork for further exploration of efficient, domain-specific band selection."
    },
    {
        "title": "The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind",
        "link_suffix": "/forum?id=kFoJXqiGKz",
        "link": "https://openreview.net/forum?id=kFoJXqiGKz",
        "pdf_link": "https://openreview.net/pdf?id=kFoJXqiGKz",
        "keywords": "theory of mind, multi-agent reasoning, LLM benchmark, zero-shot coordination",
        "abstract": "We propose Decrypto, a novel interactive benchmark for evaluating coordination, competition, and theory of mind (ToM) reasoning capabilities in agentic, foundational AI models. Existing benchmarks often suffer from data leakage, saturation, and lack of interactivity, making it hard to measure the ability of intelligent systems to model other agents' reasoning. To overcome these limitations, we introduce Decrypto, a multi-agent benchmark based on a popular, language-based board game and designed to be future-proof for large language models (LLMs). We validate Decrypto's effectiveness through comprehensive empirical evaluations of frontier LLMs, ablation studies, and human-AI cross-play experiments. We show that LLMs do not coordinate well with other LLMs or humans and perform strictly worse than the latter. Specifically, LLMs struggle to reason about the choices of others, even if they use the same underlying model, pointing to a fundamental limitation of current systems."
    },
    {
        "title": "Learning Generative Judge from Preference Data",
        "link_suffix": "/forum?id=HZVIQE1MsJ",
        "link": "https://openreview.net/forum?id=HZVIQE1MsJ",
        "pdf_link": "https://openreview.net/pdf?id=HZVIQE1MsJ",
        "keywords": "LLM alignment, Generative judge, LLM-as-judge",
        "abstract": "Learning from preference feedback is a common practice for aligning large language models (LLMs) with human value.\nConventionally, preference data is learned and encoded into a scalar reward model that connects a value head with an LLM to produce a scalar score as preference. However, scalar models lack interpretability and are known to be susceptible to biases in datasets. This paper investigates leveraging the generation capability of LLMs to address both limitations in one shot. Specifically, we prompt the pre-trained LLM to generate positive and negative judgments, both supported with rationales in natural language form. The self-generated contrastive judgment pairs are used to train the generative judge with Direct Preference Optimization (DPO). This proposal of learning the generativeJudge using self-generatedContrastive judgments (Con-J) ensures natural interpretability through the generated rationales supporting the judgments, and demonstrates higher robustness against bias compared to scalar models. Experimental results show that Con-J outperforms the scalar reward model trained on the same collection of preference data, and outperforms a series of open-source and closed-source generative LLMs. We open-source the training process and model weights of Con-J athttps://anonymous.4open.science/r/Con-J-D014/."
    },
    {
        "title": "Lightweight Neural App Control",
        "link_suffix": "/forum?id=BL4WBIfyrz",
        "link": "https://openreview.net/forum?id=BL4WBIfyrz",
        "pdf_link": "https://openreview.net/pdf?id=BL4WBIfyrz",
        "keywords": "vision-language model, multi-modal, android control, app agent",
        "abstract": "This paper introduces a novel mobile phone control architecture, termed \"app agents\", for efficient interactions and controls across various Android apps. The proposed Lightweight Multi-modal App Control (LiMAC) takes as input a textual goal and a sequence of past mobile observations, such as screenshots and corresponding UI trees, to generate precise actions. To address the computational constraints inherent to smartphones, within LiMAC, we introduce a small Action Transformer (AcT) integrated with a fine-tuned vision-language model (VLM) for real-time decision-making and task execution.  We evaluate LiMAC on two open-source mobile control datasets, demonstrating the superior performance of our small-form-factor approach against fine-tuned versions of open-source VLMs, such as Florence2 and Qwen2-VL. It also significantly outperforms prompt engineering baselines utilising closed-source foundation models like GPT-4o. More specifically, LiMAC increases the overall action accuracy by up to 19% compared to fine-tuned VLMs, and up to 42% compared to prompt-engineering baselines."
    },
    {
        "title": "Q-based Variational Inverse Reinforcement Learning",
        "link_suffix": "/forum?id=SqcoXJc4mC",
        "link": "https://openreview.net/forum?id=SqcoXJc4mC",
        "pdf_link": "https://openreview.net/pdf?id=SqcoXJc4mC",
        "keywords": "inverse reinforcement learning, IRL, imitation learning",
        "abstract": "The development of safe and beneficial AI requires that systems can learn and act in accordance with human preferences. However, explicitly specifying these preferences by hand is often infeasible. Inverse reinforcement learning (IRL) addresses this challenge by inferring preferences, represented as reward functions, from expert behavior. We introduce Q-based Variational IRL (QVIRL), a novel Bayesian IRL method that recovers a posterior distribution over rewards from expert demonstrations via primarily learning a variational distribution over Q-values. Unlike previous approaches, QVIRL combines scalability with uncertainty quantification, important for safety-critical applications. We demonstrate QVIRL's strong performance in apprenticeship learning across various tasks, including classical control problems and safe navigation in the Safety Gymnasium suite, where the method's uncertainty quantification allows us to produce safer policies."
    },
    {
        "title": "SharedContextBench: How Lossy are Long-context Methods in KV Cache Reuse",
        "link_suffix": "/forum?id=gkUyYcY1W9",
        "link": "https://openreview.net/forum?id=gkUyYcY1W9",
        "pdf_link": "https://openreview.net/pdf?id=gkUyYcY1W9",
        "keywords": "Long-context, Benchmark, KV Cache Reuse, Long-context Methods, Shared Context",
        "abstract": "Long-context Large Language Models (LLMs) have unlocked numerous possibilities for downstream applications, many of which involve multiple requests sharing the same input context. Recent inference frameworks like vLLM and SGLang, as well as LLMs providers such as OpenAI, Gemini and Claude, have employed prefix caching techniques to accelerate multi-requests with shared context. However, existing long-context methods are primarily evaluated on single query testing, failing to demonstrate their true capability in real-world applications that often require KV cache reuse for follow-up queries. To address this gap, we introduce SharedContextBench, a comprehensive long-context benchmark to reveal how lossy are long-context methods in KV cache reuse scenarios. Specifically, it encompasses 12 tasks with two shared context modes, covering four categories of long-context abilities: string retrieval, semantic retrieval, global information processing, and multi-task capabilities. Using our benchmark, we evaluated five categories of long-context solutions, including Gated Linear RNNs (Codestal-Mamba), MambaAttention hybrids (Jamba-1.5-Mini), and efficient methods like sparse attention, KV cache compression, and prompt compression, on six transformer-based longcontext LLMs: Llama-3.1-8B/70B, Qwen2.5-72B/32B, Llama-3-8B-262K, and GLM-4-9B. Our findings show that sub-O(n) memory methods often struggle to maintain accuracy in multi-turn scenarios, while sparse encoding methods with O(n) memory and sub-O(n 2 ) computation in prefilling generally perform well. Additionally, dynamic sparse patterns in prefilling often produce more expressive memory (KV cache) compared to static methods, and layer-level sparsity in hybrid architectures reduces memory usage while yielding promising results."
    },
    {
        "title": "Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning",
        "link_suffix": "/forum?id=89EjtiGWVS",
        "link": "https://openreview.net/forum?id=89EjtiGWVS",
        "pdf_link": "https://openreview.net/pdf?id=89EjtiGWVS",
        "keywords": "off-policy learning, off-policy evaluation, log sum exponential, regret bound, generalization bound, concentration, bias and variance",
        "abstract": "Off-policy learning and evaluation scenarios leverage logged bandit feedback datasets, which contain context, action, propensity score, and feedback for each data point. These scenarios face significant challenges due to high variance and poor performance with low-quality propensity scores and heavy-tailed reward distributions. We address these issues by introducing a novel estimator based on the log-sum-exponential (LSE) operator, which outperforms traditional inverse propensity score estimators. Our LSE estimator demonstrates variance reduction and robustness under heavy-tailed conditions. For off-policy evaluation, we derive upper bounds on the estimator's bias and variance. In the off-policy learning scenario, we establish bounds on the regret\u2014the performance gap between our LSE estimator and the optimal policy\u2014assuming bounded $(1+\\epsilon)$-th moment of weighted reward. Notably, we achieve a convergence rate of $O(n^{-\\epsilon/(1+\\epsilon)})$, where $n$ is the number of training samples for the regret bounds. Theoretical analysis is complemented by comprehensive empirical evaluations in both off-policy learning and evaluation scenarios, confirming the practical advantages of our approach."
    },
    {
        "title": "Monet: Mixture of Monosemantic Experts for Transformers",
        "link_suffix": "/forum?id=1Ogw1SHY3p",
        "link": "https://openreview.net/forum?id=1Ogw1SHY3p",
        "pdf_link": "https://openreview.net/pdf?id=1Ogw1SHY3p",
        "keywords": "large language models, mechanistic interpretability, monosemanticity, mixture of experts, knowledge unlearning",
        "abstract": "Understanding the internal computations of large language models (LLMs) is crucial for aligning them with human values and preventing undesirable behaviors like toxic content generation. However, mechanistic interpretability is hindered by polysemanticity\u2014where individual neurons respond to multiple, unrelated concepts due to the superposition hypothesis. While Sparse Autoencoders (SAEs) have attempted to disentangle these features, they face limitations from imperfect reconstruction loss, which impedes LLM's performance. We introduce the Mixture of Monosemantic Experts for Transformers (Monet) architecture, which enhances interpretability by significantly increasing the number of experts to 262,144 per layer while maintaining parameter efficiency through a novel expert decomposition method. By designing the total parameters to scale proportionally to the square root of the number of experts, Monet enables effective specialization of experts. Our analyses demonstrate mutual exclusivity of knowledge across experts and showcase the parametric knowledge encapsulated within individual experts. Moreover, Monet allows robust knowledge manipulation over knowledge domains, languages, and toxicity mitigation without degrading general performance. By overcoming the limitations of SAEs and conventional Mixture-of-Experts architectures, Monet advances the mechanistic interpretability of LLMs and provides practical benefits for controlling model behavior."
    },
    {
        "title": "Aligning Large Language Models via Self-Steering Optimization",
        "link_suffix": "/forum?id=1HQZ4QFWi8",
        "link": "https://openreview.net/forum?id=1HQZ4QFWi8",
        "pdf_link": "https://openreview.net/pdf?id=1HQZ4QFWi8",
        "keywords": "LLM, Alignment, Automated alignment",
        "abstract": "Automated alignment develops alignment systems with minimal human intervention.\nThe key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation.\nIn this paper, we introduce Self-Steering Optimization ($SSO$), an algorithm that autonomously generates high-quality preference signals based on predefined principles during iterative training, eliminating the need for manual annotation. \n$SSO$ maintains the accuracy of signals by ensuring a consistent gap between chosen and rejected responses while keeping them both on-policy to suit the current policy model's learning capacity.\n$SSO$ can benefit the online and offline training of the policy model, as well as enhance the training of reward models.\nWe validate the effectiveness of $SSO$ with two foundation models, Qwen2 and Llama3.1, indicating that it provides accurate, on-policy preference signals throughout iterative training.\nWithout any manual annotation or external models, $SSO$ leads to significant performance improvements across six subjective or objective benchmarks.\nBesides, the preference data generated by $SSO$ significantly enhanced the performance of the reward model on Rewardbench.\nOur work presents a scalable approach to preference optimization, paving the way for more efficient and effective automated alignment."
    },
    {
        "title": "GraphBridge: Towards Arbitrary Transfer Learning in GNNs",
        "link_suffix": "/forum?id=gjRhw5S3A4",
        "link": "https://openreview.net/forum?id=gjRhw5S3A4",
        "pdf_link": "https://openreview.net/pdf?id=gjRhw5S3A4",
        "keywords": "Graph Neural Networks, Transfer Learning, Efficient Tuning Methods, Universial Model",
        "abstract": "a significant barrier in transferring the acquired knowledge to different, heterogeneous data setups. This paper introduces GraphBridge, a novel framework to enable knowledge transfer across disparate tasks and domains in GNNs, circumventing the need for modifications to task configurations or graph structures. Specifically, GraphBridge allows for the augmentation of any pre-trained GNN with prediction heads and a bridging network that connects the input to the output layer. This architecture not only preserves the intrinsic knowledge of the original model but also supports outputs of arbitrary dimensions. To mitigate the negative transfer problem, GraphBridg merges the source model with a concurrently trained model, thereby reducing the source bias when applied to the target domain. Our method is thoroughly evaluated across diverse transfer learning scenarios, including Graph2Graph, Node2Node, Graph2Node, and graph2point-cloud. Empirical validation, conducted over 16 datasets representative of these scenarios, confirms the framework's capacity for task- and domain-agnostic transfer learning within graph-like data, marking a significant advancement in the field of GNNs."
    },
    {
        "title": "The KoLMogorov Test: Compression by Code Generation",
        "link_suffix": "/forum?id=C45YqeBDUM",
        "link": "https://openreview.net/forum?id=C45YqeBDUM",
        "pdf_link": "https://openreview.net/pdf?id=C45YqeBDUM",
        "keywords": "Code generation, code, compression, LLM, dataset, benchmark",
        "abstract": "Compression is at the heart of intelligence. A theoretically optimal way to compress any sequence of data is to find the shortest program that outputs that sequence and then halts. However, such Kolmogorov compression is uncomputable, and code generating LLMs struggle to approximate this theoretical ideal, as it requires reasoning, planning and search capabilities beyond those of current models. In this work, we introduce theKoLMogorov-Test(KT), a compression-as-intelligence intelligence test for code generation LLMs. In KT a model is presented with a sequence of data at inference time, and asked to generate the shortest program that produces the sequence. We identify several benefits of KT for both evaluation and training: an essentially infinite number of problem instances of varying difficulty is readily available, strong baselines already exist, the evaluation metric (compression) cannot be gamed, and pretraining data contamination is highly unlikely. To evaluate current models, we use audio, text, and DNA data, as well as sequences produced by random synthetic programs. Current flagship models perform poorly - both GPT4-o and  Llama-3.1-405B struggle on our natural and synthetic sequences. On our synthetic distribution, we are able to train code generation models with lower compression rates than previous approaches. Moreover, we show that gains on synthetic data generalize poorly to real data, suggesting that new innovations are necessary for additional gains on KT."
    },
    {
        "title": "MTSTRec: Multimodal Time-Aligned Shared Token Recommender",
        "link_suffix": "/forum?id=hgcxwrrGZf",
        "link": "https://openreview.net/forum?id=hgcxwrrGZf",
        "pdf_link": "https://openreview.net/pdf?id=hgcxwrrGZf",
        "keywords": "multimodal sequential recommendation, time-aligned shared token, image style representation, large language model",
        "abstract": "Sequential recommendation in e-commerce leverages users' anonymous browsing histories to offer personalized product suggestions without relying on personal information. While item ID-based sequential recommendations are commonly used, they often fail to fully capture the diverse factors influencing user preferences, such as textual descriptions, visual content, and pricing. These factors represent distinct modalities in recommender systems. Existing multimodal sequential recommendation models typically employ either early or late fusion of different modalities, overlooking the alignment of corresponding positions in time of product sequences that represent users' browsing preferences. To address these limitations, this paper proposes a unified framework for multimodal fusion in recommender systems, introducing the Multimodal Time-aligned Shared Token Recommender (MTSTRec). MTSTRec leverages a transformer-based architecture that incorporates a single time-aligned shared token for each product, allowing for efficient cross-modality fusion that also aligns in time. This approach not only preserves the distinct contributions of each modality but also aligns them to better capture user preferences. Additionally, the model extracts rich features from text, images, and other product data, offering a more comprehensive representation of user decision-making in e-commerce. Extensive experiments demonstrate that MTSTRec achieves state-of-the-art performance across multiple sequential recommendation benchmarks, significantly improving upon existing multimodal fusion strategies."
    },
    {
        "title": "TrendDiff: Decoupling Intrinsic and Measurement Trends for Enhanced Time Series Causal Discovery",
        "link_suffix": "/forum?id=S1U0CIuejF",
        "link": "https://openreview.net/forum?id=S1U0CIuejF",
        "pdf_link": "https://openreview.net/pdf?id=S1U0CIuejF",
        "keywords": "Causal discovery, Time trends, Measurement error, Constraint-based algorithm",
        "abstract": "Time trends can be classified into intrinsic (real) and measurement (false) trends. There has long been a critical need for techniques to discern them, especially in investment decision-making. In causal discovery, these measurement trends, essentially measurement errors, can significantly impact the performance of algorithms, making it crucial to identify and eliminate them before analysis as well. Recognizing this need, we present a novel algorithm, termed Trend Differentiator (TrendDiff). It is capable of detecting all trend-influenced variables and differentiating between those affected by measurement trends and those displaying intrinsic trends, relying on changing causal module detection and trend-influenced variables\u2019 structural properties, respectively. Extensive experiments on synthetic and real-world data demonstrate the efficacy of this approach."
    }
]
[{"title": "FLAG: Clustered Federated Learning Combining Data and Gradient Information in Heterogeneous Settings", "link_suffix": "/forum?id=8OrXrdPbef", "link": "https://openreview.net/forum?id=8OrXrdPbef", "pdf_link": "https://openreview.net/pdf?id=8OrXrdPbef", "keywords": "Federated Learning, Clustering, Distributed Machine Learning", "abstract": "Federated Learning (FL) emerged as an important tool to enable a group of agents/clients to collaboratively train a model without sharing their individual data with each other or any third party, instead exchanging only model updates during each training round.\nAlthough FL performs effectively when clients' data are homogeneous (e.g., each client's data is distributed i.i.d.), data heterogeneity among clients presents a major challenge, often leading to significant performance degradation. \nTo address this challenge, a variety of approaches have been proposed. One particularly effective approach is clustered FL, where similar clients are grouped together to train separate models.\nPrevious clustered FL approaches tend to rely solely on either data similarity or gradient similarity to cluster clients. This results in an incomplete assessment of client similarities, particularly when the datasets display various types of distributional skews, such as label, feature, or quantity imbalances. Consequently, these methods fail to capture the full spectrum of client heterogeneity, leading to suboptimal model performance across diverse client environments.In this work, we address the challenge of data heterogeneity in FL by introducing a novel clustered FL approach, called Flag. Flag employs a weighted class-wise similarity metric that integrates both data and gradient similarity, providing a more holistic measure of client similarity. This enables more accurate clustering of clients, ultimately improving model performance across heterogeneous data distributions. Our extensive empirical evaluation on multiple benchmark datasets, under various heterogeneous data scenarios, demonstrates that Flag consistently outperforms state-of-the-art  approaches in terms of accuracy.", "title_embedding_index": 4850, "title_abs_embedding_index": 4875}, {"title": "Context is Key: A Benchmark for Forecasting with Essential Textual Information", "link_suffix": "/forum?id=4F1a8nNFGK", "link": "https://openreview.net/forum?id=4F1a8nNFGK", "pdf_link": "https://openreview.net/pdf?id=4F1a8nNFGK", "keywords": "Time series, forecasting, multimodality, foundation models, contextual forecasting, deep learning, machine learning, context-awareness", "abstract": "Forecasting is a critical task in decision making across various domains. While numerical data provides a foundation, it often lacks crucial context necessary for accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge or constraints, which can be efficiently communicated through natural language. However, the ability of existing forecasting models to effectively integrate this textual information remains an open question. To address this, we introduce \"Context is Key\" (CiK), a time series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities. We evaluate a range of approaches, including statistical models, time series foundation models and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. By presenting this benchmark, we aim to advance multimodal forecasting, promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized athttps://anon-forecast.github.io/benchmark_report_dev/.", "title_embedding_index": 4851, "title_abs_embedding_index": 4876}, {"title": "Teach Multimodal LLMs to Comprehend Electrocardiographic Images", "link_suffix": "/forum?id=NOfmlsnCsS", "link": "https://openreview.net/forum?id=NOfmlsnCsS", "pdf_link": "https://openreview.net/pdf?id=NOfmlsnCsS", "keywords": "Electrocardiogram, LLMs, Multimodal LLMs, Instruction Tuning, Benchmark and Evaluation", "abstract": "The electrocardiogram (ECG) is an essential non-invasive diagnostic tool for assessing cardiac conditions. Existing automatic interpretation methods suffer from limited generalizability, focusing on a narrow range of cardiac conditions, and typically depend on raw physiological signals, which may not be readily available in resource-limited settings where only printed or digital ECG images are accessible. Recent advancements in multimodal large language models (MLLMs) present promising opportunities for addressing these challenges. However, the application of MLLMs to ECG image interpretation remains challenging due to the lack of instruction tuning datasets and well-established ECG image benchmarks for quantitative evaluation. To address these challenges, we introduce ECGInstruct, a comprehensive ECG image instruction tuning dataset of over 1 million samples, covering a wide range of ECG-related tasks from diverse data sources. Using ECGInstruct, we develop PULSE, a fine-tuned MLLM tailored for ECG image interpretation. In addition, we curate ECGBench, a new evaluation benchmark covering four key ECG image interpretation tasks. Our experiments show\nthat PULSE sets a new state-of-the-art, outperforming general MLLMs with an average accuracy improvement of 15% to 30%. This work highlights the potential of PULSE to enhance ECG interpretation in clinical practice", "title_embedding_index": 4852, "title_abs_embedding_index": 4877}, {"title": "Characterizing trainability, expressivity, and generalization of neural architecture with metrics from neural tangent kernel", "link_suffix": "/forum?id=PqiDHCLkB9", "link": "https://openreview.net/forum?id=PqiDHCLkB9", "pdf_link": "https://openreview.net/pdf?id=PqiDHCLkB9", "keywords": "neural tangential kernel, neural architecture search, trainability, expressivity, generalization", "abstract": "Zero-shot neural architecture search aims to predict multiple characteristics of neural architectures using proxy indicators without actual training, yet most methods focus on evaluating only a single characteristic of neural networks.\nSince the Neural Tangent Kernel (NTK) offers a promising theoretical framework for understanding the characteristics of neural networks, we propose NTK-score,  including three metrics derived from NTK's eigenvalues and kernel regression, to assess three critical characteristics: trainability, expressivity, and generalization. \nMoreover, to exploit three metrics of our NTK-score, we employ the Borda Count approach on our NTK-score to rank architectures in neural architecture search.\nCompared with state-of-the-art proxies, experimental results demonstrate that the NTK-score correlates well with both the accuracy and training time of architectures, and exhibits excellent performance across various search spaces and methods, including NAS-bench-201, DARTS, and ResNet, as well as pruning, reinforce, and evolutionary algorithm.", "title_embedding_index": 4853, "title_abs_embedding_index": 4878}, {"title": "The Case for Gradual Structured Pruning in Image-based Deep Reinforcement Learning", "link_suffix": "/forum?id=LTdtyzPQoZ", "link": "https://openreview.net/forum?id=LTdtyzPQoZ", "pdf_link": "https://openreview.net/pdf?id=LTdtyzPQoZ", "keywords": "gradual structured pruning, deep reinforcement learning, Procgen benchmark", "abstract": "Gradual unstructured pruning of large neural networks during training has been shown to enhance performance in image-based deep reinforcement learning. However, we demonstrate that these performance improvements often diminish when making slight enhancements to the neural network architecture. Additionally, as unstructured pruning merely zeroes out individual weights, the resulting networks usually retain high computational demands despite sparsity. In contrast, structured pruning removes entire structures, such as channels or neurons, directly reducing the computational cost. Given these findings, we propose a novel gradual structured pruning framework for image-based deep reinforcement learning that accounts for inter-layer dependencies to preserve the network's functional integrity. We evaluate the impact of our group-structured pruning method on generalization performance through extensive experiments on the Procgen Benchmark using PPO and DQN. Our results show that group-structured pruning maintains performance levels comparable to unstructured pruning while reducing inference time, positioning it as the preferred approach for real-world applications.", "title_embedding_index": 4854, "title_abs_embedding_index": 4879}, {"title": "A deep inverse-mapping model for a flapping robotic wing", "link_suffix": "/forum?id=254NJe9JEw", "link": "https://openreview.net/forum?id=254NJe9JEw", "pdf_link": "https://openreview.net/pdf?id=254NJe9JEw", "keywords": "robotics, control, flapping drones, deep learning, time series, inverse mapping, sequence to sequence", "abstract": "In systems control, the dynamics of a system is governed by modulating its inputs to achieve a desired outcome. For example, to control the thrust of a quadcopter propeller the controller modulates its rotation rate, relying on a straightforward mapping between the input rotation rate and the resulting thrust. This mapping can be inverted to determine the rotation rate needed to generate a desired thrust. However, in complex systems, such as flapping-wing robots where intricate fluid motions are involved, mapping inputs (wing kinematics) to outcomes (aerodynamic forces) is nontrivial and inverting this mapping for real-time control is computationally impractical. Here, we report a machine-learning solution for the inverse-mapping of a flapping-wing system based on data from an experimental system we have developed. Our model learns the input wing motion required to generate a desired aerodynamic force outcome. We used a sequence-to-sequence model tailored for time-series data and augmented it with an adaptive-spectrum layer that implements representation learning in the frequency domain. To train our model, we developed a flapping-wing system that simultaneously measures the wing's aerodynamic force and its 3D motion using high-speed cameras. We demonstrate the performance of our system on an additional open-source dataset of a flapping wing in a different flow regime. Results show superior performance compared with more complex state-of-the-art transformer-based models, with 11% improvement on the test datasets. Our open-source data and framework may improve modeling and real-time control of systems governed by complex dynamics, from biomimetic robots to biomedical devices.", "title_embedding_index": 4855, "title_abs_embedding_index": 4880}, {"title": "Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective", "link_suffix": "/forum?id=NWb128pSCb", "link": "https://openreview.net/forum?id=NWb128pSCb", "pdf_link": "https://openreview.net/pdf?id=NWb128pSCb", "keywords": "text-to-image synthesis, semantics, evaluation, metric", "abstract": "Accurate interpretation and visualization of human instructions are crucial for \\textbf{T}ext-to-\\textbf{I}mage (\\textbf{T2I}) synthesis. Existing T2I models often struggle to capture semantic variations caused by different word orders. Current evaluations rely on indirect metrics, like text-image matching, where the limitations with uncommon or complex linguistic patterns may be obscured by focusing on frequent word combinations. To address these deficiencies, we introduce a novel metric called \\underline{PermuteEffect} and a benchmark named \\underline{PermuteBench}, designed to evaluate the causality between textual semantic variations and visual semantic variations in T2I synthesis. Our experiments revealed that the CogView-3-Plus and Ideogram 2 models performed the best, achieving a score of 0.2/1, where semantic variations concerning relations between objects were more weakly understood than those about attributes, scoring only 0.07/1. We found that cross-modal alignment in UNet or Transformers plays a critical role in understanding semantic variations, a factor previously overlooked by a focus on textual encoders. Our work establishes an effective evaluation framework that advances \nthe T2I synthesis community's exploration of human instruction understanding.", "title_embedding_index": 4856, "title_abs_embedding_index": 4881}, {"title": "DAG-Jailbreak: Enhancing Black-box Jailbreak Attacks and Defenses through DAG Dependency Analysis", "link_suffix": "/forum?id=xQIJ5fjc7q", "link": "https://openreview.net/forum?id=xQIJ5fjc7q", "pdf_link": "https://openreview.net/pdf?id=xQIJ5fjc7q", "keywords": "Jailbreak Attacks and Defenses, LLM Security, DAG Dependency Analysis", "abstract": "Black-box jailbreak attacks and defenses, a critical branch of the large language model (LLM) security, are characterized by their minimal requirement for user expertise and high potential for automation. However, current black-box jailbreak approaches often adhere to a uniform global algorithmic framework, leading to suboptimal solutions due to challenges in local optimization. This limits both their effectiveness and scalability. To address these limitations, we proposeDAG-Jailbreak, a novel framework leveraging Directed Acyclic Graph (DAG) dependency analysis to construct more robust jailbreak attacks and defenses. The core idea behind this framework is to combine optimal sub-components to form a more effective global algorithm.DAG-Jailbreakcompromises three components:DAG-Attack, which creates highly effective attackers based on two global algorithms and is capable of compromising well-aligned LLMs without prior knowledge;DAG-Defense, which introduces a novel global framework based on a mixture-of-defenders mechanism, significantly enhancing the scalability and effectiveness of jailbreak defenses by reducing the attack success rate to below 3% in most cases; andDAG-Evaluation, which introduces the concept of jailbreak hallucination and a two-stage evaluation framework to assess the outputs generated by LLMs comprehensively. Extensive experiments validate the superiority and robustness ofDAG-Jailbreak.", "title_embedding_index": 4857, "title_abs_embedding_index": 4882}, {"title": "CONTINUAL FINITE-SUM MINIMIZATION UNDER THE POLYAK-\u0141OJASIEWICZ CONDITION", "link_suffix": "/forum?id=ZP1HqLus4y", "link": "https://openreview.net/forum?id=ZP1HqLus4y", "pdf_link": "https://openreview.net/pdf?id=ZP1HqLus4y", "keywords": "Continual Learning, Finite Sum Minimization", "abstract": "Given functions $f_1,\\ldots,f_n$ where $f_i:\\mathcal{D}\\mapsto \\mathbb{R}$, \\textit{continual finite-sum minimization} (CFSM) asks for an $\\epsilon$-optimal sequence $\\hat{x}_1,\\ldots,\\hat{x}_n  \\in \\mathcal{D}$ such that$$\\sum_{j=1}^i f_j(x_i)/i - \\min_{x \\in \\mathcal{D}}\\sum_{j=1}^if_j(x)/i \\leq \\epsilon$$In this work, we develop a new CFSM framework under the Polyak-\u0141ojasiewicz condition (PL), where each prefix-sum function $\\sum_{j=1}^i f_j(x)/i$ satisfies the PL condition, extending the recent result on CFSM with strongly convex functions.  We present a new first-order method that under the PL condition producing an $\\epsilon$-optimal sequence with overall $\\mathcal{O}(n/\\sqrt{\\epsilon})$ first-order oracles (FOs), where an FO corresponds to the computation of a single gradient $\\nabla f_j(x)$ at a given $x \\in \\mathcal{D}$ for some $j \\in [n]$. Our method also improves upon the  $\\mathcal{O}(n^2 \\log (1/\\epsilon))$ FO complexity of state-of-the art variance reduction methods as well as upon the $\\mathcal{O}(n/\\epsilon)$ FO complexity of $\\mathrm{StochasticGradientDescent}$. We experimentally evaluate our method in continual learning and the unlearning settings, demonstrating the potential of the CFSM framework in non-convex, deep learning problems.", "title_embedding_index": 4858, "title_abs_embedding_index": 4883}, {"title": "Vocabulary-Defined Semantics: Latent Space Clustering for Improving In-Context Learning", "link_suffix": "/forum?id=uD2yx2TR7S", "link": "https://openreview.net/forum?id=uD2yx2TR7S", "pdf_link": "https://openreview.net/pdf?id=uD2yx2TR7S", "keywords": "Language Model, Latent Space, In-Context Learning, Semantics, Disentanglement, Neural Clustering", "abstract": "In-context learning enables language models (LM) to adapt to downstream data or tasks by incorporating few samples as demonstrations within the prompts. It offers strong performance without the expense of fine-tuning.\nHowever, the performance of in-context learning can be unstable depending on the quality, format, or order of demonstrations, which in turn exacerbates the difficulty of optimization.\nPrior work, such as Knn Prompting, index samples based on the similarities of logits at the output-side, in addition to the regular retrieval operation at the input-side.\nThey improve in-context learning by leveraging the core ability of next-token prediction, rather than relying solely on the emergent capacity to make analogies.\nDespite this, the hard-to-optimize issue of in-context learning still exists. In our view, it stems from the process of selecting demonstrations. To address this, we propose complementing in-context learning with an additional clustering operation.\nWe propose a novel approach ``vocabulary-defined semantics''.\nGrounded in LM vocabulary, which is the label space of model outputs, the proposed approach computes semantically equivalent latent representations for output labels. Then, taking the representations as centroids, a clustering operation is performed to align the semantic properties between the language model and the downstream data/tasks.\nBased on extensive experiments across diverse textual understanding datasets and multiple models, our approach outperforms the state-of-the-art in terms of effectiveness and efficiency. On average, it achieves 3%-49% improvements while requiring only half of the computation time.", "title_embedding_index": 4859, "title_abs_embedding_index": 4884}, {"title": "Reevaluating Theoretical Analysis Methods for Optimization in Deep Learning", "link_suffix": "/forum?id=JslyktsKMY", "link": "https://openreview.net/forum?id=JslyktsKMY", "pdf_link": "https://openreview.net/pdf?id=JslyktsKMY", "keywords": "Deep Learning, Optimization, Smooth, Convex, Sharpness", "abstract": "There is a significant gap between our theoretical understanding of optimization algorithms used in deep learning and their practical performance. Theoretical development usually focuses on proving convergence guarantees under a variety of different assumptions, which are themselves often chosen based on a rough combination of intuitive match to practice and analytical convenience. In this paper, we carefully measure the degree to which the standard optimization analyses are capable of explaining modern algorithms. To do this, we develop new empirical metrics that compare real optimization behavior with analytically predicted behavior. Our investigation is notable for its tight integration with modern optimization analysis: rather than simply checking high-level assumptions made in the analysis (e.g. smoothness), we verify key low-level identities used by the analysis to explain optimization behavior that might hold even if the high-level motivating assumptions do not. In general, we find that real optimizers often make progress even when typical optimization analysis suggests that they should not. This highlights a need for developing new theoretical frameworks that are better aligned with practice.", "title_embedding_index": 4860, "title_abs_embedding_index": 4885}, {"title": "GraphRouter: A Graph-based Router for LLM Selections", "link_suffix": "/forum?id=eU39PDsZtT", "link": "https://openreview.net/forum?id=eU39PDsZtT", "pdf_link": "https://openreview.net/pdf?id=eU39PDsZtT", "keywords": "LLM selection, Graph-based router, Contextual interactions, New LLM settings", "abstract": "The rapidly growing number and variety of Large Language Models (LLMs)\npresent significant challenges in efficiently selecting the appropriate LLM for\na given query, especially considering the trade-offs between performance and\ncomputational cost. Current LLM selection methods often struggle to generalize\nacross new LLMs and different tasks because of their limited ability to leverage\ncontextual interactions among tasks, queries, and LLMs, as well as their depen-\ndence on a transductive learning framework. To address these shortcomings, we\nintroduce a novel inductive graph framework, named as GraphRouter, which\nfully utilizes the contextual information among tasks, queries, and LLMs to en-\nhance the LLM selection process. GraphRouter constructs a heterogeneous\ngraph comprising task, query, and LLM nodes, with interactions represented as\nedges, which efficiently captures the contextual information between the query\u2019s\nrequirements and the LLM\u2019s capabilities. Through an innovative edge prediction\nmechanism, GraphRouter is able to predict attributes (the effect and cost of\nLLM response) of potential edges, allowing for optimized recommendations that\nadapt to both existing and newly introduced LLMs without requiring retraining.\nComprehensive experiments across three distinct effect-cost weight scenarios have\nshown that GraphRouter substantially surpasses existing routers, delivering a\nminimum performance improvement of 12.3%. In addition, it achieves enhanced\ngeneralization across new LLMs settings and supports diverse tasks with at least a\n9.5% boost in effect and a significant reduction in computational demands. This\nwork endeavors to apply a graph-based approach for the contextual and adaptive\nselection of LLMs, offering insights for real-world applications.", "title_embedding_index": 4861, "title_abs_embedding_index": 4886}, {"title": "Adaptive Concept Bottleneck for Foundation Models Under Distribution Shifts", "link_suffix": "/forum?id=8sfc8MwG5v", "link": "https://openreview.net/forum?id=8sfc8MwG5v", "pdf_link": "https://openreview.net/pdf?id=8sfc8MwG5v", "keywords": "foundation models; concept bottleneck models; distribution shifts; concept-based explanations", "abstract": "Advancements in foundation models (FMs) have led to a paradigm shift in machine\nlearning. The rich, expressive feature representations from these pre-trained, large-\nscale FMs are leveraged for multiple downstream tasks, usually via lightweight\nfine-tuning of a shallow fully-connected network following the representation.\nHowever, the non-interpretable, black-box nature of this prediction pipeline can be\na challenge, especially in critical domains, such as healthcare, finance, and security.\nIn this paper, we explore the potential of Concept Bottleneck Models (CBMs)\nfor transforming complex, non-interpretable foundation models into interpretable\ndecision-making pipelines using high-level concept vectors. Specifically, we focus\non the test-time deployment of such an interpretable CBM pipeline \u201cin the wild\u201d,\nwhere the distribution of inputs often shifts from the original training distribution.\nWe first identify the potential failure modes of such pipelines under different types\nof distribution shifts. Then we propose an adaptive concept bottleneck framework\nto address these failure modes, that dynamically adapts the concept-vector bank\nand the prediction layer based solely on unlabeled data from the target domain,\nwithout access to the source dataset. Empirical evaluations with various real-world\ndistribution shifts show our framework produces concept-based interpretations\nbetter aligned with the test data and boosts post-deployment accuracy by up to\n28%, aligning CBM performance with that of non-interpretable classification.", "title_embedding_index": 4862, "title_abs_embedding_index": 4887}, {"title": "Offline RL in Regular Decision Processes: Sample Efficiency via Language Metrics", "link_suffix": "/forum?id=EW6bNEqalF", "link": "https://openreview.net/forum?id=EW6bNEqalF", "pdf_link": "https://openreview.net/pdf?id=EW6bNEqalF", "keywords": "Reinforcement Learning, Non-Markov Decision Process, Offline Reinforcement Learning, Regular Decision Processes, Sample Complexity, Automata", "abstract": "This work studies offline Reinforcement Learning (RL) in a class of non-Markovian environments called Regular Decision Processes (RDPs). In RDPs, the unknown dependency of future observations and rewards from the past interactions can be captured by some hidden finite-state automaton. For this reason, many RDP algorithms first reconstruct this unknown dependency using automata learning techniques. In this paper, we consider episodic RDPs and show that it is possible to overcome the limitations of existing offline RL algorithms for RDPs via\nthe introduction of two original techniques: a novel metric grounded in formal language theory and an approach based on Count-Min-Sketch (CMS). Owing to the novel language metric, our algorithm is proven to be more sample efficient than existing results, and in some problem instances admitting low complexity languages, the gain is showcased to be exponential in the episode length. The CMS-based approach removes the need for na\u00efve counting and alleviates the memory requirements for long planning horizons. We derive Probably Approximately Correct (PAC) sample complexity bounds associated to each of these techniques, and validate the approach experimentally.", "title_embedding_index": 4863, "title_abs_embedding_index": 4888}, {"title": "Revisiting Noise Resilience Strategies in Gesture Recognition: Short-Term Enhancement in Surface Electromyographic Signal Analysis", "link_suffix": "/forum?id=B7eHRsuTSh", "link": "https://openreview.net/forum?id=B7eHRsuTSh", "pdf_link": "https://openreview.net/pdf?id=B7eHRsuTSh", "keywords": "surface electromyography, gesture recognition, signal processing", "abstract": "Gesture recognition based on surface electromyography (sEMG) has been gaining importance in many 3D Interactive Scene. However, sEMG is easily influenced by various forms of noise in real-world environments, leading to challenges in providing long-term stable interactions through sEMG. Existing methods usually struggle to improve generalizability or prediction reliability in the real scene, such as distinguishing similar gestures when facing various noises. To this end,  in this paper, we propose a new method, called Short Term Enhanced Transformer (STET), which improves the precision and robustness against various common noisy scenarios by exploiting enhanced short-term features in time series. Compared with existing methods, STET possesses several unique merits: (1) preciseness, achieving high accuracy in different types of gestures; (2) robustness, mitigating the impact of noise in the real scene; and (3) generalization, being capable of doing gesture classification and hand joint angle regression. Finally, we have studied the performances of STET on the largest public sEMG data set including single-finger, multi-finger, wrist, and rest gestures. The results show that STET outperforms existing approaches by a large margin and can significantly improve robustness when facing various noises. More importantly, compared with best-competing approaches, the impact of noise on STET is reduced by more than 20%. The extensive experiments also demonstrate that the short-term information is critical for sEMG-based gesture recognition  and STET successfully exploits such information.", "title_embedding_index": 4864, "title_abs_embedding_index": 4889}, {"title": "Think while You Generate: Discrete Diffusion with Planned Denoising", "link_suffix": "/forum?id=MJNywBdSDy", "link": "https://openreview.net/forum?id=MJNywBdSDy", "pdf_link": "https://openreview.net/pdf?id=MJNywBdSDy", "keywords": "discrete diffusion, generative models", "abstract": "Discrete diffusion has achieved state-of-the-art performance, outperforming or approaching autoregressive models on standard benchmarks. In this work, we introduceDiscrete Diffusion with Planned Denoising(DDPD), a novel framework that separates the generation process into two models: a planner and a denoiser. At inference time, the planner selects which positions to denoise next by identifying the most corrupted positions in need of denoising, including both initially corrupted and those requiring additional refinement. This plan-and-denoise approach enables more efficient reconstruction during generation by iteratively identifying and denoising corruptions in the optimal order. DDPD outperforms traditional denoiser-only mask diffusion methods, achieving superior results on language modeling benchmarks such astext8,OpenWebText, and token-based generation onImageNet 256 \u00d7 256. Notably, in language modeling, DDPD significantly reduces the performance gap between diffusion-based and autoregressive methods in terms of generative perplexity.", "title_embedding_index": 4865, "title_abs_embedding_index": 4890}, {"title": "Neural Networks Decoded: Targeted and Robust Analysis of Neural Network Decisions via Causal Explanations and Reasoning", "link_suffix": "/forum?id=b5CEjE4zyL", "link": "https://openreview.net/forum?id=b5CEjE4zyL", "pdf_link": "https://openreview.net/pdf?id=b5CEjE4zyL", "keywords": "AI Explainability, Causal Discovery, Neural Network Optimization", "abstract": "Despite their success and widespread adoption, the opaque nature of deep neural networks (DNNs) continues to hinder trust, especially in critical applications. Current interpretability solutions often yield inconsistent or oversimplified explanations, or require model changes that compromise performance. In this work, we introduce TRACER, a novel method grounded in causal inference theory designed to estimate the causal dynamics underpinning DNN decisions without altering their architecture or compromising their performance. Our approach systematically intervenes on input features to observe how specific changes propagate through the network, affecting internal activations and final outputs. Based on this analysis, we determine the importance of individual features, and construct a high-level causal map by grouping functionally similar layers into cohesive causal nodes, providing a structured and interpretable view of how different parts of the network influence the decisions. TRACER further enhances explainability by generating counterfactuals that reveal possible model biases and offer contrastive explanations for misclassifications. Through comprehensive evaluations across diverse datasets, we demonstrate TRACER's effectiveness over existing methods and show its potential for creating highly compressed yet accurate models, illustrating its dual versatility in both understanding and optimizing DNNs.", "title_embedding_index": 4866, "title_abs_embedding_index": 4891}, {"title": "Constrained Skill Discovery: Quadruped Locomotion with Unsupervised Reinforcement Learning", "link_suffix": "/forum?id=tdfHABLdxR", "link": "https://openreview.net/forum?id=tdfHABLdxR", "pdf_link": "https://openreview.net/pdf?id=tdfHABLdxR", "keywords": "legged locomotion, unsupervised skill discovery, empowerment, unsupervised reinforcement learning", "abstract": "Representation learning and unsupervised skill discovery can allow robots to acquire diverse and reusable behaviors without the need for task-specific rewards. In this work, we learn a latent representation by maximizing the mutual information between skills and states subject to a distance constraint, using unsupervised reinforcement learning. Our method improves upon prior constrained skill discovery methods by replacing the latent transition maximization with a norm-matching objective. This not only results in a much a richer state space coverage, but allows the robot to learn more stable and easily controllable locomotive behaviors. In robotics this is particularly important, because state transition-maximizing behaviors can result in highly dangerous motions. We successfully deployed the learned policy on a real ANYmal quadruped robot and demonstrated that the robot can accurately reach arbitrary points of the Cartesian state space in a zero-shot manner, using only an intrinsic skill discovery and standard regularization rewards.", "title_embedding_index": 4867, "title_abs_embedding_index": 4892}, {"title": "Thought-Retriever: Don\u2019t Just Retrieve Raw Data, Retrieve Thoughts", "link_suffix": "/forum?id=SkDNQbMQba", "link": "https://openreview.net/forum?id=SkDNQbMQba", "pdf_link": "https://openreview.net/pdf?id=SkDNQbMQba", "keywords": "Language Model, Retrieval-Augmented LLM, AI Agent, Self-Evolution", "abstract": "Large language models (LLMs) have transformed AI research thanks to their powerful \\textit{internal} capabilities and knowledge. However, existing LLMs still fail to effectively incorporate the massive \\textit{external} knowledge when interacting with the world. Although retrieval-augmented LLMs are proposed to mitigate the issue, they are still fundamentally constrained by the context length of LLMs, as they can only retrieve top-K raw data chunks from the external knowledge base which often consists of millions of data chunks. Here we propose Thought-Retriever, a novel model-agnostic algorithm that helps LLMs generate output conditioned on arbitrarily long external data, without being constrained by the context length or number of retrieved data chunks. Our key insight is to let an LLM fully leverage its intermediate responses generated when solving past user queries (thoughts), filtering meaningless and redundant thoughts, organizing them in thought memory, and retrieving the relevant thoughts when addressing new queries. Besides algorithmic innovation, we further meticulously prepare a novel benchmark, AcademicEval, which requires an LLM to faithfully leverage ultra-long context to answer queries based on real-world academic papers. Extensive experiments on AcademicEval and two other public datasets validate that Thought-Retriever remarkably outperforms state-of-the-art baselines, achieving an average increase of at least 7.6% in F1 score and 16% in win rate across various tasks. More importantly, we further demonstrate two exciting findings: (1) Thought-Retriever can indeed help LLM self-evolve after solving more user queries; (2) Thought-Retriever learns to leverage deeper thoughts to answer more abstract user queries.", "title_embedding_index": 4868, "title_abs_embedding_index": 4893}, {"title": "Improve Code Generation with Feedback", "link_suffix": "/forum?id=CscKx97jBi", "link": "https://openreview.net/forum?id=CscKx97jBi", "pdf_link": "https://openreview.net/pdf?id=CscKx97jBi", "keywords": "LLM, code generation", "abstract": "As advancements in Large Language Models (LLMs) continue to accelerate, an increasing number of researchers are exploring the potential of these models to assist in everyday tasks. Despite their remarkable achievements in various downstream applications, several challenges must be addressed. This paper delves into applying LLMs in coding tasks, such as ChatGPT and LLama. Initial observations suggest that directly employing these LLMs does not yield optimal results. However, we have identified that LLMs demonstrate enhanced performance when given appropriate feedback. This includes providing information on the accuracy of the code generated, supplying test cases relevant to the task, and indicating the correct or incorrect outputs for these test cases.\n    Furthermore, we have developed an innovative architecture miming human debugging. This approach supplies local variable information to the LLM while executing the generated code. Our architecture facilitates providing feedback to the LLM and simulates the human debugging experience, thereby significantly improving the LLM's code generation capabilities.\n    Utilizing our proposed architecture, our model surpasses the current benchmarks of state-of-the-art models in the MBPP and Humaneval datasets. We also present comprehensive analyses and ablation studies to substantiate the efficacy of our methods. These findings open new avenues for enhancing the utility of LLMs in coding tasks, offering a more interactive and practical approach to leveraging these advanced technologies.", "title_embedding_index": 4869, "title_abs_embedding_index": 4894}, {"title": "Interpolate: How Resetting Active Neurons can also improve Generalizability in Online Learning", "link_suffix": "/forum?id=MHmsJS6YHQ", "link": "https://openreview.net/forum?id=MHmsJS6YHQ", "pdf_link": "https://openreview.net/pdf?id=MHmsJS6YHQ", "keywords": "plastiticy, generalization, online learning, permutation invariance, model merging, dormancy, adaptability, continual learning", "abstract": "While neural networks have shown a significant gain in performance across a wide range of applications, they still struggle in non-stationary settings as they tend to lose their ability to adapt to new tasks \u2014 a phenomenon known as the loss of plasticity. The conventional approach to addressing this problem often involves resetting the most under-utilized or dormant parts of the network, suggesting that recycling such parameters is crucial for maintaining a model's plasticity. In this study, we explore whether this approach is the only way to address plasticity loss. Contrary to previous findings, we show that resetting the most active parameters can also lead to better generalization. Additionally, we introduce a model merging method that can perform similarly or better compared to traditional resetting methods, offering a new perspective on training dynamics in non-stationary settings.", "title_embedding_index": 4870, "title_abs_embedding_index": 4895}, {"title": "Best-of-Both-Worlds Policy Optimization for CMDPs with Bandit Feedback", "link_suffix": "/forum?id=ilbxbOHk7a", "link": "https://openreview.net/forum?id=ilbxbOHk7a", "pdf_link": "https://openreview.net/pdf?id=ilbxbOHk7a", "keywords": "CMDP, Online Learning, Best-of-both-worlds", "abstract": "We study online learning in constrained Markov decision processes (CMDPs) in which rewards and constraints may be either stochastic or adversarial. In such settings, Stradi et al. (2024b) proposed the first best-of-both-worlds algorithm able to seamlessly handle stochastic and adversarial constraints, achieving optimal regret and constraint violation bounds in both cases. This algorithm suffers from two major drawbacks. First, it only works under full feedback, which severely limits its applicability in practice. Moreover, it relies on optimizing over the space of occupancy measures, which requires solving convex optimization problems, an highly inefficient task. In this paper, we provide the first best-of-both-worlds algorithm for CMDPs with bandit feedback. Specifically, when the constraints are stochastic, the algorithm achieves $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret and constraint violation, while, when they are adversarial, it attains $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ constraint violation and a tight fraction of the optimal reward. Moreover, our algorithm is based on a policy optimization approach, which is much more efficient than occupancy-measure-based methods.", "title_embedding_index": 4871, "title_abs_embedding_index": 4896}, {"title": "LVM-NET: Efficient Long-Form Video Reasoning using neural sampling", "link_suffix": "/forum?id=bEvI30Hb2W", "link": "https://openreview.net/forum?id=bEvI30Hb2W", "pdf_link": "https://openreview.net/pdf?id=bEvI30Hb2W", "keywords": "Video Reasoning, External Memory, Neural Sampling", "abstract": "Long-form video reasoning is essential for various applications such as video retrieval, summarizing, and question\nanswering. However, existing methods often require significant computational resources and are limited by GPU memory constraints. To address this challenge, we present Long-Video Memory Network, LVM-NET, a novel video reasoning method that employs a fixed-size memory representation to store discriminative patches sampled from the input video. By leveraging a  neural sampler that identifies discriminative memory tokens, LVM-Net achieves improved efficiency. Furthermore, LVM-Net only requires a single pass over the video, further enhancing overall efficiency. Our results on the Rest-ADL dataset demonstrate an 18x - 75x improvement in inference times for long-form video retrieval and answering questions, with a competitive predictive performance.", "title_embedding_index": 4872, "title_abs_embedding_index": 4897}, {"title": "MolMiner: Transformer architecture for fragment-based autoregressive generation of molecular stories", "link_suffix": "/forum?id=SDjCRmuaDS", "link": "https://openreview.net/forum?id=SDjCRmuaDS", "pdf_link": "https://openreview.net/pdf?id=SDjCRmuaDS", "keywords": "Deep generative models, Material discovery, Deep Learning, Interpretability", "abstract": "Deep generative models for molecular discovery have become a very popular choice in new high-throughput screening paradigms. These models have been developed inheriting from the advances in natural language processing and computer vision, achieving ever greater results. However, generative molecular modelling has unique challenges that are often overlooked. Chemical validity, interpretability of the generation process and flexibility to variable molecular sizes are among some of the remaining challenges for generative models in computational materials design. In this work, we propose an autoregressive approach that decomposes molecular generation into a sequence of discrete and interpretable steps using molecular fragments as units, a 'molecular story'. Enforcing chemical rules in the stories guarantees the chemical validity of the generated molecules, the discrete sequential steps of a molecular story makes the process transparent improving interpretability, and the autoregressive nature of the approach allows the size of the molecule to be a decision of the model. We demonstrate the validity of the approach in a multi-target inverse design of electroactive organic compounds, focusing on the target properties of solubility, redox potential, and synthetic accessibility. Our results show that the model can effectively bias the generation distribution according to the prompted multi-target objective.", "title_embedding_index": 4873, "title_abs_embedding_index": 4898}, {"title": "Context-Aware Online Recommendation with Bayesian Incentive Compatibility", "link_suffix": "/forum?id=SIdA3s754H", "link": "https://openreview.net/forum?id=SIdA3s754H", "pdf_link": "https://openreview.net/pdf?id=SIdA3s754H", "keywords": "recommendation, online learning, incentive compatibility", "abstract": "Recommender systems play a crucial role in internet economies by connecting users with relevant products or services. However, designing effective recommender systems faces two key challenges: (1) the exploration-exploitation tradeoff in balancing new product exploration against exploiting known preferences, and (2) context-aware Bayesian incentive compatibility in accounting for users' heterogeneous preferences and self-interested behaviors. This paper formalizes these challenges into a Context-aware Bayesian Incentive-Compatible Recommendation Problem (CBICRP). \nTo address the CBICRP, we propose a two-stage algorithm (RCB) that integrates incentivized exploration with an efficient offline learning component for exploitation.\nIn the first stage, our algorithm explores available products while maintaining context-aware Bayesian incentive compatibility to determine sufficient sample sizes. The second stage employs inverse proportional gap sampling integrated with arbitrary efficient machine learning method to ensure sublinear regret. \nTheoretically, we prove that RCB achieves $O(\\sqrt{KdT})$ regret and satisfies Bayesian incentive compatibility (BIC). Empirically, we validate RCB's strong incentive gain, sublinear regret, and robustness through simulations and a real-world application on personalized warfarin dosing. Our work provides a principled approach for incentive-aware recommendation in online preference learning settings.", "title_embedding_index": 4874, "title_abs_embedding_index": 4899}]
[
    {
        "title": "Is Your Multimodal Language Model Oversensitive to Safe Queries?",
        "link_suffix": "/forum?id=QsA3YzNUxA",
        "link": "https://openreview.net/forum?id=QsA3YzNUxA",
        "pdf_link": "https://openreview.net/pdf?id=QsA3YzNUxA",
        "keywords": "Safety, Adversarial Robustness, Multimodal Large Language Models, Alignment",
        "abstract": "Humans are prone to cognitive distortions \u2014 biased thinking patterns that lead to exaggerated responses to specific stimuli, albeit in very different contexts.\nThis paper demonstrates that advanced Multimodal Large Language Models (MLLMs) exhibit similar tendencies.\nWhile these models are designed to respond queries under safety mechanism, they sometimes reject harmless queries in the presence of certain visual stimuli, disregarding the benign nature of their contexts.\nAs the initial step in investigating this behavior, we identify three representative types of stimuli that trigger the oversensitivity of existing MLLMs: $\\textbf{\\textit{Exaggerated Risk}}$, $\\textbf{\\textit{Negated Harm}}$, and $\\textbf{\\textit{Counterintuitive Interpretation}}$.\nTo systematically evaluate MLLMs' oversensitivity to these stimuli, we propose the $\\textbf{M}$ultimodal $\\textbf{O}$ver$\\textbf{S}$en$\\textbf{S}$itivity $\\textbf{Bench}$mark (MOSSBench).\nThis toolkit consists of 300 manually collected benign multimodal queries, cross-verified by third-party reviewers (AMT).\nEmpirical studies using MOSSBench on 20 MLLMs reveal several insights:\n(1). Oversensitivity is prevalent among SOTA MLLMs, with refusal rates reaching up to $\\textbf{76}$% for harmless queries.\n(2). Safer models are more oversensitive: increasing safety may inadvertently raise caution and conservatism in the model\u2019s responses.\n(3). Different types of stimuli tend to cause errors at specific stages \u2014 perception, intent reasoning, and safety judgement \u2014 in the response process of MLLMs.\nThese findings highlight the need for refined safety mechanisms that balance caution with contextually appropriate responses, improving the reliability of MLLMs in real-world applications."
    },
    {
        "title": "Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos",
        "link_suffix": "/forum?id=RhfYIJux9d",
        "link": "https://openreview.net/forum?id=RhfYIJux9d",
        "pdf_link": "https://openreview.net/pdf?id=RhfYIJux9d",
        "keywords": "robotics manipulation, internet videos, real2sim, Foundation models, reinforcement learning",
        "abstract": "Simulation offers a promising approach for cheaply scaling training data for robotic generalist policies. To scalably generate data from diverse and realistic tasks, existing algorithms either rely on large language models (LLMs) that may hallucinate tasks not interesting for robotics; or digital twins, which require careful real-to-sim alignment and are hard to scale. To address these challenges, we introduce Video2Policy, a novel framework that leverages large amounts of internet RGB videos to reconstruct tasks based on everyday human behavior. Our approach comprises two phases: (1) task generation through object mesh reconstruction and 6D position tracking; and (2) reinforcement learning utilizing LLM-generated reward functions and iterative in-context reward reflection for the task. We demonstrate the efficacy of Video2Policy by reconstructing over 60 videos from the Something-Something-v2 (SSv2) dataset, which depicts diverse and complex human behaviors on 9 different tasks. Our method can successfully train RL policies on such tasks, including complex and challenging tasks such as throwing. Furthermore, we show that a generalist policy trained on the collected sim data generalizes effectively to new tasks and outperforms prior approaches. Finally, we show the performance of our policies improves by simply including more internet videos. We believe that the proposed Video2Policy framework is a step towards generalist policies that can execute practical robotic tasks based on everyday human behavior."
    },
    {
        "title": "Causal Abstraction Finds Universal Representation of Race in Large Language Models",
        "link_suffix": "/forum?id=jyjfRLnfww",
        "link": "https://openreview.net/forum?id=jyjfRLnfww",
        "pdf_link": "https://openreview.net/pdf?id=jyjfRLnfww",
        "keywords": "mechanistic interpretability, causal abstraction, bias and fairness",
        "abstract": "While there is growing interest in the potential bias of large language models (LLMs), especially in high-stakes decision making, it remains an open question how LLMs mechanistically encode such bias. We use causal abstraction (Geiger et al., 2023) to study how models use the race information in two high-stakes decision settings: college admissions and hiring. We find that Alpaca 7B, Mistral 7B, and Gemma 2B check for an applicants\u2019 race and apply different preferential or discriminatory decision boundaries. The race subspace found by distributed alignment search generalizes across different tasks with average interchange intervention accuracies from 78.09% to 88.64% across the three models. We also propose a novel RaceQA task, where the model is asked to guess an applicant\u2019s race from the name in their profile, to further probe the mechanism of the bias. We show that patching in a different race representation changes the model\u2019s perception of the applicant\u2019s race 99.80% of the time for Alpaca and 98.20% of the time for Mistral. Overall, our work provides evidence for a universal mechanism of racial bias in LLMs\u2019 decision-making."
    },
    {
        "title": "SCOPE: Scalable and Adaptive Evaluation of Misguided Safety Refusal in LLMs",
        "link_suffix": "/forum?id=72H3w4LHXM",
        "link": "https://openreview.net/forum?id=72H3w4LHXM",
        "pdf_link": "https://openreview.net/pdf?id=72H3w4LHXM",
        "keywords": "Foundation Models, AI Safety, Spurious Correlations, Over-cautiousness",
        "abstract": "The rapid progress of foundation models has amplified AI safety risks, prompting the development and deployment of alignment techniques and safety measures such as reinforcement learning with human feedback and supervised safety fine-tuning. However, these safety mechanisms can inadvertently cause models to reject benign requests that contain keywords or syntax linked to unsafe content in training data, leading to misguided safety refusals (or over-cautiousness). Existing benchmarks for assessing these refusals are limited by their static nature and reliance on manual efforts. To address this, we introduce SCOPE, an automated pipeline that dynamically generates false refusal benchmarks from any given red-teaming dataset. This facilitates continuous adaptation to the evolving landscape of refusal behaviors introduced by growing red-teaming efforts.\nOur evaluation across 29 models demonstrates the widespread issue of misguided refusals in existing LLMs and identifies spurious features that trigger these behaviors. Furthermore, we demonstrate that the generated benchmarks facilitate the development of more effective countermeasures to mitigate these misguided refusals."
    },
    {
        "title": "Multimodal Fusion with Relational Learning for Molecular Property Prediction",
        "link_suffix": "/forum?id=UuK99g47op",
        "link": "https://openreview.net/forum?id=UuK99g47op",
        "pdf_link": "https://openreview.net/pdf?id=UuK99g47op",
        "keywords": "Molecular Graph Representation Learning, Multi-modality Learning, Contrastive Learning, Drug Discovery",
        "abstract": "Graph-based molecular representation learning is essential for accurately predicting molecular properties in drug discovery and materials science; however, it faces significant challenges due to the intricate relationships among molecules and the limited chemical knowledge utilized during training. While contrastive learning is often employed to handle molecular relationships, its reliance on binary metrics is insufficient for capturing the complexity of these interactions. Multimodal fusion has gained attention for property reasoning, but previous work has explored only a limited range of modalities, and the optimal stages for fusing different modalities in molecular property tasks remain underexplored. In this paper, we introduce MMFRL (Multimodal Fusion with Relational Learning for Molecular Property Prediction), a novel framework designed to overcome these limitations. Our method enhances embedding initialization through multi-modal pre-training using relational learning. We also conduct a systematic investigation into the impact of modality fusion at different stages\u2014early, intermediate, and late\u2014highlighting their advantages and shortcomings. Extensive experiments on MoleculeNet benchmarks demonstrate that MMFRL significantly outperforms existing methods. Furthermore, MMFRL enables task-specific optimizations. Additionally, the explainability of MMFRL provides valuable chemical insights, emphasizing its potential to enhance real-world drug discovery applications."
    },
    {
        "title": "Discriminative Estimation of Total Variation Distance: A Fidelity Auditor for Generative Data",
        "link_suffix": "/forum?id=POCT74JhAl",
        "link": "https://openreview.net/forum?id=POCT74JhAl",
        "pdf_link": "https://openreview.net/pdf?id=POCT74JhAl",
        "keywords": "Classification; Total Variation Distance; Learning Theory; Generative Data",
        "abstract": "With the proliferation of generative AI and the increasing volume of generative data (also called as synthetic data), assessing the fidelity of generative data has become a critical concern. In this paper, we propose a discriminative approach to estimate the total variation (TV) distance between two distributions as an effective measure of generative data fidelity. Our method quantitatively characterizes the relation between the Bayes risk in classifying two distributions and their TV distance. Therefore, the estimation of total variation distance reduces to that of the Bayes risk. In particular, this paper establishes theoretical results regarding the convergence rate of the estimation error of TV distance between two Gaussian distributions. We demonstrate that, with a specific choice of hypothesis class in classification, a fast convergence rate in estimating the TV distance can be achieved. Specifically, the estimation accuracy of the TV distance is proven to inherently depend on the separation of two Gaussian distributions: smaller estimation errors are achieved when the two Gaussian distributions are farther apart. This phenomenon is also validated empirically through extensive simulations. In the end, we apply this discriminative estimation method to rank fidelity of synthetic image data using the MNIST dataset."
    },
    {
        "title": "LokiLM: Technical Report",
        "link_suffix": "/forum?id=bppG9srkpR",
        "link": "https://openreview.net/forum?id=bppG9srkpR",
        "pdf_link": "https://openreview.net/pdf?id=bppG9srkpR",
        "keywords": "large language model",
        "abstract": "In this work, we introduce LokiLM, a 1.4B parameter large language model trained on 500B tokens. Our model performs strongly in natural language reasoning tasks and achieves state-of-the-art performance among models with 1.5B parameters or less. LokiLM is trained using multi-teacher knowledge distillation and high-quality training data to achieve benchmark results competitive with larger models trained on significantly more tokens. We support these findings by introducing steps to avoid benchmark contamination and overfitting throughout our development process. Despite its promising performance, LokiLM exhibits a concerning amount of hallucinations and scores poorly on the TruthfulQA benchmark, so we do not release the model publicly."
    },
    {
        "title": "Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval",
        "link_suffix": "/forum?id=BPAZ6yW3K7",
        "link": "https://openreview.net/forum?id=BPAZ6yW3K7",
        "pdf_link": "https://openreview.net/pdf?id=BPAZ6yW3K7",
        "keywords": "LLMs, Reinforcement Learning, Information Retrieval",
        "abstract": "Mitigating hallucinations is a prerequisite for trusting answers generated by large language models (LLMs) that are prone to making convincing but inaccurate claims. Grounding the answers in data generated and verified by humans provides a natural avenue for improving the reliability of LLMs. However, it can be hard to capture relevant facts for user questions based on just the semantic similarity, especially as questions becomes more complex and the relevant facts become more indirect. What if LLMs could query for relevant facts based on the user question? While this can enable retrieving relevant but indirect facts, zero-shot performance of instruction-tuned LLMs leaves more to be desired and generating supervision on how to retrieve relevant facts can be expensive and retriever dependent. Our key insight is that LLMs can learn to retrieve relevant facts by $\\textit{trying}$ different queries, learning to upweight queries that result in relevant facts. This leads to our reinforcement learning based framework, $\\underline{Le}$arning to $\\underline{Re}$trieve by $\\underline{T}$rying (LeReT), where the LLM generates queries for multi-hop retrieval and uses preference-based reinforcement learning to improve the LLM queries. Our experimental results demonstrate that LeReT can improve the absolute retrieval accuracy by up to 29% and the downstream generator evaluations by 17%. The simplicity and flexibility of LeReT allows it to be applied to arbitrary retrievers, and makes it a promising technique for improving general LLM pipelines."
    },
    {
        "title": "SCAN: Bootstrapping Contrastive Pre-training for Data Efficiency",
        "link_suffix": "/forum?id=pRCTRC6icM",
        "link": "https://openreview.net/forum?id=pRCTRC6icM",
        "pdf_link": "https://openreview.net/pdf?id=pRCTRC6icM",
        "keywords": "Contrastive Pre-Training, Data Efficiency",
        "abstract": "While contrastive pre-training is widely employed, its data efficiency problem has remained relatively under-explored thus far. Existing methods often rely on static coreset selection algorithms to pre-identify important data for training. However, this static nature renders them unable to dynamically track the data usefulness throughout pre-training, leading to subpar pre-trained models. To address this challenge, our paper introduces a novel dynamic bootstrapping dataset pruning method. It involves pruning data preparation followed by dataset mutation operations, both of which undergo iterative and dynamic updates. We apply this method to two prevalent contrastive pre-training frameworks: CLIP and MoCo, representing vision-language and vision-centric domains, respectively. In particular, we individually pre-train seven CLIP models on two large-scale image-text pair datasets, and two MoCo models on the ImageNet dataset, resulting in a total of 16 pre-trained models. With a data pruning rate of 30-35% across all 16 models, our method exhibits only marginal performance degradation (less than 1% on average) compared to corresponding models trained on the full dataset counterparts across various downstream datasets, and also surpasses several baselines with a large performance margin. Additionally, the byproduct from our method, i.e., coresets derived from the original datasets after pre-training, also demonstrates significant superiority in terms of downstream performance over other coreset selection approaches."
    },
    {
        "title": "FASP: Fast and Accurate Structured Pruning of Large Language Models",
        "link_suffix": "/forum?id=f4b0YVwKUO",
        "link": "https://openreview.net/forum?id=f4b0YVwKUO",
        "pdf_link": "https://openreview.net/pdf?id=f4b0YVwKUO",
        "keywords": "large language models, post training pruning, structured pruning",
        "abstract": "The rapid increase in the size of large language models (LLMs) has significantly escalated their computational and memory demands, posing challenges for efficient deployment, especially on resource-constrained devices. Structured pruning has emerged as an effective model compression method that can reduce these demands while preserving performance. In this paper, we introduce FASP (Fast and Accurate Structured Pruning), a novel structured pruning framework for LLMs that emphasizes both speed and accuracy. FASP employs a distinctive pruning structure that interlinks sequential layers, allowing for the removal of columns in one layer while simultaneously eliminating corresponding rows in the preceding layer without incurring additional performance loss. The pruning metric, inspired by Wanda, is computationally efficient and effectively selects components to prune. Additionally, we propose a restoration mechanism that enhances model fidelity by adjusting the remaining weights post-pruning. We evaluate FASP on the OPT and LLaMA model families, demonstrating superior performance in terms of perplexity and accuracy on downstream tasks compared to state-of-the-art methods. Our approach achieves significant speed-ups, pruning models such as OPT-125M in 17 seconds and LLaMA-30B in 20 minutes on a single NVIDIA RTX 4090 GPU, making it a highly practical solution for optimizing LLMs."
    },
    {
        "title": "MMR: A Large-scale Benchmark Dataset for Multi-target and Multi-granularity Reasoning Segmentation",
        "link_suffix": "/forum?id=mzL19kKE3r",
        "link": "https://openreview.net/forum?id=mzL19kKE3r",
        "pdf_link": "https://openreview.net/pdf?id=mzL19kKE3r",
        "keywords": "Multimodal Dataset, Multi-target and Multi-granularity Reasoning Segmentation, Benchmark Framework",
        "abstract": "The fusion of Large Language Models (LLMs) with vision models is pioneering new possibilities in user-interactive vision-language tasks. A notable application is reasoning segmentation, where models generate pixel-level segmentation masks by comprehending implicit meanings in human instructions. However, seamless human-AI interaction demands more than just object-level recognition; it requires understanding both objects and the functions of their detailed parts, particularly in multi-target scenarios. For example, when instructing a robot to \"turn on the TV,\" there could be various ways to accomplish this command. Recognizing multiple objects capable of turning on the TV, such as the TV itself or a remote control (multi-target), provides more flexible options and aids in finding the optimized scenario. Furthermore, understanding specific parts of these objects, like the TV's button or the remote's button (part-level), is important for completing the action. Unfortunately, current reasoning segmentation datasets predominantly focus on a single target object-level reasoning, which limits the detailed recognition of an object's parts in multi-target contexts. To address this gap, we construct a large-scale dataset called Multi-target and Multi-granularity Reasoning (MMR). MMR comprises 194K complex and implicit instructions that consider multi-target, object-level, and part-level aspects, based on pre-existing image-mask sets. This dataset supports diverse and context-aware interactions by hierarchically providing object and part information. Moreover, we propose a straightforward yet effective framework for multi-target, object-level, and part-level reasoning segmentation. Experimental results on MMR show that the proposed method can reason effectively in multi-target and multi-granularity scenarios, while the existing reasoning segmentation model still has room for improvement."
    },
    {
        "title": "From Patches to Graphs: Towards Image Diffusion Models with GNNs",
        "link_suffix": "/forum?id=h4L5eUvXmP",
        "link": "https://openreview.net/forum?id=h4L5eUvXmP",
        "pdf_link": "https://openreview.net/pdf?id=h4L5eUvXmP",
        "keywords": "Generative Models, Graph Neural Networks, Image Diffusion Models",
        "abstract": "Diffusion models have achieved remarkable success in high-quality image generation, typically using convolutional neural networks (CNNs) or Vision Transformers (ViTs) as backbone architectures. However, CNNs may struggle with capturing long-range dependencies, while ViTs can be computationally intensive due to their attention mechanisms. We propose the Diffusion Image GNN (DiG), a novel architecture that leverages graph-based modeling within diffusion models. By representing image patches as nodes in a graph and connecting them based on spatial relationships, DiG efficiently captures both local and global dependencies and naturally handles multi-scale features. \nEmpirical results demonstrate that DiG achieves competitive Frechet Inception Distance (FID) scores compared to state-of-the-art methods. To our knowledge, this is the first application of graph neural networks as a backbone within diffusion models for image generation, opening new avenues for research in generative modeling."
    },
    {
        "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback",
        "link_suffix": "/forum?id=oApCZZZ3O4",
        "link": "https://openreview.net/forum?id=oApCZZZ3O4",
        "pdf_link": "https://openreview.net/pdf?id=oApCZZZ3O4",
        "keywords": "Large Language Model, model personalization",
        "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in a range of natural language processing tasks. Once deployed, LLMs encounter users with personalized factual knowledge, and such personalized knowledge is consistently reflected through users' interactions with the LLMs. To enhance user experience, real-time model personalization is essential, allowing LLMs to adapt user-specific knowledge based on user feedback during human-LLM interactions. Existing methods mostly require back-propagation to finetune the model parameters, which incurs high computational and memory costs. In addition, these methods suffer from low interpretability, which will cause unforeseen impacts on model performance during long-term use, where the user's personalized knowledge is accumulated extensively. To address these challenges, we propose Knowledge Graph Tuning (KGT), a novel approach that leverages knowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual knowledge triples from users' queries and feedback and optimizes KGs without modifying the LLM parameters. Our method improves computational and memory efficiency by avoiding back-propagation and ensures interpretability by making the KG adjustments comprehensible to humans. Experiments with state-of-the-art LLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves personalization performance while reducing latency and GPU memory costs. Ultimately, KGT offers a promising solution of effective, efficient, and interpretable real-time LLM personalization during user interactions with the LLMs."
    },
    {
        "title": "GuideCO: Training Objective-Guided Diffusion Solver with Imperfect Data for Combinatorial Optimization",
        "link_suffix": "/forum?id=D3vD7ZFIor",
        "link": "https://openreview.net/forum?id=D3vD7ZFIor",
        "pdf_link": "https://openreview.net/pdf?id=D3vD7ZFIor",
        "keywords": "combinatorial optimization, diffusion model, guidance",
        "abstract": "Combinatorial optimization (CO) problems have widespread applications in science and engineering but they present significant computational challenges. Recent advancements in generative models, particularly diffusion models, have shown promise in bypassing traditional optimization solvers by directly generating near-optimal solutions. However, we observe an exponential scaling law between the optimality gap and the amount of training data needed for training diffusion-based solvers. Notably, the performance of existing diffusion solvers relies on both quantity and quality of training data: they perform well with abundant high quality training data labeled by exact or near-optimal solvers, while suffering when high-quality labels are scarce or unavailable. To address the challenge, we propose GuideCO, an objective-guided diffusion solver for combinatorial optimization, which can be trained on imperfectly labelled datasets. GuideCO is a two-stage generate-then-decode framework, featuring an objective-guided diffusion model that is further reinforced by classifier-free guidance for generating high-quality solutions on any given problem instance. Experiments demonstrate the improvements of GuideCO against baselines when trained on imperfect data, in a range of combinatorial optimization benchmark tasks such as TSP (Traveling Salesman Problem) and MIS (Maximum Independent Set)."
    },
    {
        "title": "Efficient Audiovisual Speech Processing via MUTUD: Multimodal Training and Unimodal Deployment",
        "link_suffix": "/forum?id=TCFtGBTxkq",
        "link": "https://openreview.net/forum?id=TCFtGBTxkq",
        "pdf_link": "https://openreview.net/pdf?id=TCFtGBTxkq",
        "keywords": "audiovisual learning, speech processing, multimodal learning, efficiency",
        "abstract": "Building reliable speech systems often requires combining multiple modalities, like audio and visual cues. While such multimodal solutions frequently lead to improvements in performance and may even be critical in certain cases, they come with several constraints such as increased sensory requirements, computational cost, and modality synchronization, to mention a few. These challenges constrain the direct uses of these multimodal solutions in real-world applications. In this work, we develop approaches where the learning happens with all available modalities but the deployment or inference is done with just one or reduced modalities. To do so, we propose a Multimodal Training and Unimodal Deployment (MUTUD) framework which includes a Temporally Aligned Modality feature Estimation (TAME) module that can estimate information from missing modality using modalities present during inference. This innovative approach facilitates the integration of information across different modalities, enhancing the overall inference process by leveraging the strengths of each modality to compensate for the absence of certain modalities during inference. We apply MUTUD to various audiovisual speech tasks and show that it can reduce the performance gap between the multimodal and corresponding unimodal models to a considerable extent. MUTUD achieves this while reducing the model size and computing compared to multimodal models by almost 80%."
    },
    {
        "title": "Informed Machine Learning with a Stochastic-Gradient-based Algorithm for Training with Hard Constraints",
        "link_suffix": "/forum?id=BxBt8WLfqE",
        "link": "https://openreview.net/forum?id=BxBt8WLfqE",
        "pdf_link": "https://openreview.net/pdf?id=BxBt8WLfqE",
        "keywords": "nonlinear optimization, stochastic gradient methods, constrained optimization, physics-informed learning",
        "abstract": "A methodology for informed machine learning is presented and its effectiveness is shown through numerical experiments with physics-informed learning problems.  The methodology has three main distinguishing features.  Firstly, prior information is introduced in the training problem through hard constraints rather than through the typical modern practice of using soft constraints (i.e., regularization terms).  Secondly, the methodology does not employ penalty-based (e.g., augmented Lagrangian) methods since the use of such methods results in an overall methodology that is similar to a soft-constrained approach.  Rather, the methodology is based on a recently proposed stochastic-gradient-based algorithm that maintains computationally efficiency while handling constraints with a Newton-based technique.  Thirdly, a new projection-based variant of the well-known Adam optimization methodology is proposed for settings with hard constraints.  Numerical experiments on a set of physics-informed learning problems show that, when compared with a soft-constraint approach, the proposed methodology can be easier to tune, lead to accurate predictions more quickly, and lead to better final prediction accuracy."
    },
    {
        "title": "Meta-Continual Learning of Neural Fields",
        "link_suffix": "/forum?id=OCpxDSn0G4",
        "link": "https://openreview.net/forum?id=OCpxDSn0G4",
        "pdf_link": "https://openreview.net/pdf?id=OCpxDSn0G4",
        "keywords": "Meta-Learning; Continual Learning; 3D Vision; Neural Radiance Fields;",
        "abstract": "Neural Fields (NF) have gained prominence as a versatile framework for complex data representation. This work unveils a new problem setting termed Meta-Continual Learning of Neural Fields (MCL-NF) and introduces a novel strategy that employs a modular architecture combined with optimization-based meta-learning. Focused on overcoming the limitations of existing methods for continual learning of neural fields, such as catastrophic forgetting and slow convergence, our strategy achieves high-quality reconstruction with significantly improved learning speed. We further introduce Fisher Information Maximization loss for neural radiance fields (FIM-NeRF), which maximizes information gains at the sample level to enhance learning generalization, with proved convergence guarantee and generalization bound. We perform extensive evaluations across image, audio, video reconstruction, and view synthesis tasks on six diverse datasets, demonstrating our method\u2019s superiority in reconstruction quality and speed over existing MCL and CL-NF approaches. Notably, our approach attains rapid adaptation of neural fields for city-scale NeRF rendering with reduced parameter requirement."
    },
    {
        "title": "Meta-weighted Diffusion Model for Reliable Online Surgical Phase Recognition",
        "link_suffix": "/forum?id=ukmWcHpa3H",
        "link": "https://openreview.net/forum?id=ukmWcHpa3H",
        "pdf_link": "https://openreview.net/pdf?id=ukmWcHpa3H",
        "keywords": "surgical phase recognition, diffusion model, meta learning",
        "abstract": "Surgical phase recognition has drawn great attention most recently thanks to its potential downstream applications closely related to human life and health. Despite deep network-based models have made significant advancement in capturing discriminative long-term dependency of surgical videos to achieve improved recognition, they seldom account for exploring and modeling uncertainty of surgical videos, which should be crucial for reliable surgical phase recognition. we categorize the sources of uncertainty into two types, imbalanced phase distribution and low-quality image acquisition, which are inevitable in surgical videos. To address this pivot issue, we introduce a meta-weighted diffusion model (MetaDiff) to take full advantages of meta-learning and deep generative model in tackling uncertainty. For uncertainty caused by image quality, we present a classifier-guided diffusion model to produce countable denoised recognition results, making it possible to measure uncertainty using statistical tools for each video frame. For uncertainty caused by phase distribution, we propose a meta-weighted objective function to optimize the classifier-guided diffusion model, making the classification boundary robust against surgical video uncertainty.\nWe demonstrate outstanding ability of our model through comprehensive benchmarks on Cholec80, AutoLaparo, M2Cai16, and CATARACTS. Experimental results reveal that MetaDiff significantly outperforms state-of-the-art methods, separately achieving accuracies of $95.3%$, $85.8%$, $92.2%$, and $85.1%$ on Cholec80, AutoLaparo, M2Cai16, and CATARACTS."
    },
    {
        "title": "Benchmark Dataset for Radiology Report Generation with Instructions and Contexts",
        "link_suffix": "/forum?id=i4pGIOlH8l",
        "link": "https://openreview.net/forum?id=i4pGIOlH8l",
        "pdf_link": "https://openreview.net/pdf?id=i4pGIOlH8l",
        "keywords": "Report Generation, Dataset and Benchmark, Multimodal Learning, Multimodal Model",
        "abstract": "While automatic report generation has demonstrated promising results using deep learning-based methods, deploying these algorithms in real-world scenarios remains challenging, where models may be required to follow the instruction from the radiologists and consider contextual information. Such instructional report generation tasks are critical for enabling more accurate, customizable, and scalable report generation processes, but remain under-explored and lack substantial datasets for training and evaluation. However, constructing a dataset for report generation with instructions and contexts is challenging due to the scarcity of medical data, privacy concerns and the absence of recorded user-model interactions. To tackle this challenge, we propose a unified and automatic data generation pipeline which leverages large language model (LLM) to produce high-quality instructions and context for report generation tasks. We present a new benchmark dataset MIMIC-R3G that extends the largest existing radiology report generation dataset MIMIC-CXR, comprising five representative tasks pertinent to real-world medical report generation. We conducted an extensive evaluation of state-of-the-art methods using the proposed benchmark datasets. Additionally, we introduced a baseline method, the Domain-enhanced Multimodal Model (DeMMo), demonstrating that leveraging training data containing instructions and contextual information significantly improves the performance of instructional report generation tasks."
    },
    {
        "title": "Contrastive Localized Language-Image Pre-Training",
        "link_suffix": "/forum?id=rwAEQWEqkX",
        "link": "https://openreview.net/forum?id=rwAEQWEqkX",
        "pdf_link": "https://openreview.net/pdf?id=rwAEQWEqkX",
        "keywords": "pre-training, CLIP, multimodal",
        "abstract": "Contrastive Language-Image Pre-training (CLIP) has been a celebrated method for training vision encoders to generate image/text representations facilitating various applications. Recently, CLIP has been widely adopted as the vision backbone of multimodal large language models (MLLMs) to connect image inputs for language interactions. The success of CLIP as a vision-language foundation model relies on aligning web-crawled noisy text annotations at image levels. Nevertheless, such criteria may become insufficient for downstream tasks in need of fine-grained vision representations, especially when region-level understanding is demanding for MLLMs. In this paper, we improve the localization capability of CLIP with several advances. We propose a pre-training method called Contrastive Localized Language-Image Pre-training (CLOC) by complementing CLIP with region-text contrastive loss and modules. We formulate a new concept, promptable embeddings, of which the encoder produces image embeddings easy to transform into region representations given spatial hints. To support large-scale pre-training, we design a visually-enriched and spatially-localized captioning framework to effectively generate region-text pseudo-labels at scale. By scaling up to billions of annotated images, CLOC enables high-quality regional embeddings for image region recognition and retrieval tasks, and can be a drop-in replacement of CLIP to enhance MLLMs, especially on referring and grounding tasks."
    },
    {
        "title": "PointNet with KAN versus PointNet with MLP for 3D Classification and Segmentation of Point Sets",
        "link_suffix": "/forum?id=PigfMZMHq1",
        "link": "https://openreview.net/forum?id=PigfMZMHq1",
        "pdf_link": "https://openreview.net/pdf?id=PigfMZMHq1",
        "keywords": "Kolmogorov-Arnold Networks, PointNet, Computer Graphics, Classification, Segmentation",
        "abstract": "We introduce PointNet-KAN, a neural network for 3D point cloud classification and segmentation tasks, built upon two key components. First, it employs Kolmogorov-Arnold Networks (KANs) instead of traditional Multilayer Perceptrons (MLPs). Second, it retains the core principle of PointNet by using shared KAN layers and applying symmetric functions for global feature extraction, ensuring permutation invariance with respect to the input features. In traditional MLPs, the goal is to train the weights and biases with fixed activation functions; however, in KANs, the goal is to train the activation functions themselves. We use Jacobi polynomials to construct the KAN layers. We extensively evaluate PointNet-KAN across various polynomial degrees and special types such as the Lagrange, Chebyshev, and Gegenbauer polynomials. Our results show that PointNet-KAN achieves competitive performance compared to PointNet with MLPs on benchmark datasets for 3D object classification and segmentation, despite employing a shallower and simpler network architecture. We hope this work serves as a foundation and provides guidance for integrating KANs, as an alternative to MLPs, into more advanced point cloud processing architectures."
    },
    {
        "title": "Second-Order Algorithms for Finding Local Nash Equilibria in Zero-Sum Games",
        "link_suffix": "/forum?id=dug02AimLZ",
        "link": "https://openreview.net/forum?id=dug02AimLZ",
        "pdf_link": "https://openreview.net/pdf?id=dug02AimLZ",
        "keywords": "game theory, nonconvex-nonconcave optimization, dynamical systems, Nash equilibrium",
        "abstract": "Zero-sum games arise in a wide variety of problems, including robust optimization and adversarial learning. However, algorithms deployed for finding a local Nash equilibrium in these games often converge to non-Nash stationary points. This highlights a key challenge: for any algorithm, the stability properties of its underlying dynamical system can cause non-Nash points to be potential attractors. To overcome this challenge, algorithms must account for subtleties involving the curvatures of players' costs. To this end, we leverage dynamical system theory and develop a second-order algorithm for finding a local Nash equilibrium in the smooth, possibly nonconvex-nonconcave, zero-sum game setting. First, we prove that this novel method guarantees convergence to only local Nash equilibria with a local $\\textit{linear}$ convergence rate. We then interpret a version of this method as a modified Gauss-Newton algorithm with local $\\textit{superlinear}$ convergence to the neighborhood of a point that satisfies first-order local Nash equilibrium conditions. In comparison, current related state-of-the-art methods do not offer convergence rate guarantees. Furthermore, we show that this approach naturally generalizes to settings with convex and potentially coupled constraints while retaining earlier guarantees of convergence to only local (generalized) Nash equilibria."
    },
    {
        "title": "Forewarned is Forearmed:  Harnessing LLMs for Data Synthesis via Failure-induced Exploration",
        "link_suffix": "/forum?id=yitH9xAHQs",
        "link": "https://openreview.net/forum?id=yitH9xAHQs",
        "pdf_link": "https://openreview.net/pdf?id=yitH9xAHQs",
        "keywords": "data synthesis, preference learning, LLM alignment",
        "abstract": "Large language models (LLMs) have significantly benefited from training on diverse, high-quality task-specific data, leading to impressive performance across a range of downstream applications. Current methods often rely on human-annotated data or predefined task templates to direct powerful LLMs in synthesizing task-relevant data for effective model training. However, this dependence on manually designed components may constrain the scope of generated data, potentially overlooking critical edge cases or novel scenarios that could challenge the model. In this paper, we present a novel approach, \\name, designed to automatically generate effective training samples that expose the weaknesses of LLMs. Specifically, we introduce a dedicated proposer trained to produce queries that lead target models to generate unsatisfactory responses. These failure-inducing queries are then used to construct training data, helping to address the models' shortcomings and improve overall performance. Our approach is flexible and can be applied to models of various scales (3B, 7B, and 8B). We evaluate \\name on three key applications\u2014safety, honesty, and math\u2014demonstrating that our generated data is both highly effective and diverse. Models fine-tuned with \\name-generated data consistently outperform those trained on human-annotated or general model-generated data, offering a new perspective on data synthesis for task-specific LLM enhancement."
    },
    {
        "title": "Leveraging Diffusion Transformers for Stock Factor Augmentation in Financial Markets",
        "link_suffix": "/forum?id=bRMfqThoVC",
        "link": "https://openreview.net/forum?id=bRMfqThoVC",
        "pdf_link": "https://openreview.net/pdf?id=bRMfqThoVC",
        "keywords": "Financial Data Augmentation, Diffusion Models, Transformer",
        "abstract": "Data scarcity poses a significant challenge in training machine learning models for stock forecasting, often leading to low signal-to-noise ratio (SNR) and data homogeneity that degrade model performance. To address these issues, we introduce DiffsFormer, a novel approach utilizing artificial intelligence-generated samples (AIGS) with a Transformer-based Diffusion Model. Initially trained on a large-scale source domain with conditional guidance to capture global joint distribution, DiffsFormer augments training by editing existing samples for specific downstream tasks, allowing control over the deviation of generated data from the target domain. We evaluate DiffsFormer on the CSI300 and CSI800 datasets using eight commonly used machine learning models, achieving relative improvements of 7.3% and 22.1% in annualized return ratio, respectively. Extensive experiments provide insights into DiffsFormer's functionality and its components, illustrating their role in mitigating data scarcity and enhancing model performance. Our findings demonstrate the potential of AIGS and DiffsFormer in addressing data limitations in stock forecasting, with the ability to generate realistic stock factors and control the editing process. These results validate our approach and contribute to a deeper understanding of its underlying mechanisms."
    },
    {
        "title": "AIR-BENCH 2024: A Safety Benchmark based on Regulation and Policies Specified Risk Categories",
        "link_suffix": "/forum?id=UVnD9Ze6mF",
        "link": "https://openreview.net/forum?id=UVnD9Ze6mF",
        "pdf_link": "https://openreview.net/pdf?id=UVnD9Ze6mF",
        "keywords": "AI Safety, Regulation, Policy, Safety Alignment, Foundation Models",
        "abstract": "Foundation models (FMs) provide societal benefits but also amplify risks. Governments, companies, and researchers have proposed regulatory frameworks, acceptable use policies, and safety benchmarks in response. However, existing public benchmarks often define safety categories based on previous literature, intuitions, or common sense, leading to disjointed sets of categories for risks specified in recent regulations and policies, which makes it challenging to evaluate and compare FMs across these benchmarks. To bridge this gap, we introduce AIR-BENCH 2024, the first AI safety benchmark aligned with emerging government regulations and company policies, following the regulation-based safety categories grounded in the AI Risks taxonomy, AIR 2024. AIR 2024 decomposes 8 government regulations and 16 company policies into a four-tiered safety taxonomy with 314 granular risk categories in the lowest tier. AIR-BENCH 2024 contains 5,694 diverse prompts spanning these categories, with manual curation and human auditing to ensure quality. We evaluate leading language models on AIR-BENCH 2024 uncovering insights into their alignment with specified safety concerns. By bridging the gap between public benchmarks and practical AI risks, AIR-BENCH 2024 provides a foundation for assessing model safety across jurisdictions, fostering the development of safer and more responsible AI systems."
    }
]
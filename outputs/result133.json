[{"title": "TRENDy: Temporal Regression of Effective Nonlinear Dynamics", "link_suffix": "/forum?id=NvDRvtrGLo", "link": "https://openreview.net/forum?id=NvDRvtrGLo", "pdf_link": "https://openreview.net/pdf?id=NvDRvtrGLo", "keywords": "dynamical systems; neural ODEs, representation learning", "abstract": "Spatiotemporal dynamics pervade the natural sciences, from the morphogen dynamics underlying patterning in animal pigmentation to the protein waves controlling cell division. A central challenge lies in understanding how controllable parameters induce qualitative changes in system behavior called bifurcations.  This endeavor is made particularly difficult in realistic settings where governing partial differential equations (PDEs) are unknown and data is limited and noisy. To address this challenge, we propose TRENDy (Temporal Regression of Effective Nonlinear Dynamics), an equation-free approach to learning low-dimensional, predictive models of spatiotemporal dynamics. Following classical work in spatial coarse-graining, TRENDy first maps input data to a low-dimensional space of effective dynamics through a cascade of multiscale filtering operations. Our key insight is the recognition that these effective dynamics can be fit by a neural ordinary differential equation (NODE) having the same parameter space as the input PDE. The preceding filtering operations strongly regularize the phase space of the NODE, making TRENDy significantly more robust to noise compared to existing methods. We train TRENDy to predict the effective dynamics of synthetic and real data representing dynamics from across the physical and life sciences. We then demonstrate how our framework can automatically locate both Turing and Hopf bifurcations in unseen regions of parameter space. We finally apply our method to the analysis of spatial patterning of the ocellated lizard through development. Our results show how TRENDy's synthesis of classical multiscale methods with techniques from data-driven dynamical systems forms a powerful tool for the study and control of spatiotemporal dynamics.", "title_embedding_index": 6600, "title_abs_embedding_index": 6625}, {"title": "On Bits and Bandits: Quantifying the Regret-Information Trade-off", "link_suffix": "/forum?id=0oWGVvC6oq", "link": "https://openreview.net/forum?id=0oWGVvC6oq", "pdf_link": "https://openreview.net/pdf?id=0oWGVvC6oq", "keywords": "Online learning, Information theory, Bayesian regret, Bandits", "abstract": "In many sequential decision problems, an agent performs a repeated task. He then suffers regret and obtains information that he may use in the following rounds. However, sometimes the agent may also obtain information and avoid suffering regret by querying external sources. We study the trade-off between the information an agent accumulates and the regret it suffers. We invoke information-theoretic methods for obtaining regret lower bounds, that also allow us to easily re-derive several known lower bounds. We introduce the first Bayesian regret lower bounds that depend on the information an agent accumulates. We also prove regret upper bounds using the amount of information the agent accumulates. These bounds show that information measured in bits, can be traded off for regret, measured in reward. Finally, we demonstrate the utility of these bounds in improving the performance of a question-answering task with large language models, allowing us to obtain valuable insights.", "title_embedding_index": 6601, "title_abs_embedding_index": 6626}, {"title": "Task Calibration: Calibrating Large Language Models on Inference Tasks", "link_suffix": "/forum?id=8LZ1D1yqeg", "link": "https://openreview.net/forum?id=8LZ1D1yqeg", "pdf_link": "https://openreview.net/pdf?id=8LZ1D1yqeg", "keywords": "large language model, zero-shot learning, model calibration, natural language inference", "abstract": "Large language models (LLMs) have exhibited impressive zero-shot performance on inference tasks. However, LLMs may suffer from spurious correlations between input texts and output labels, which limits LLMs' ability to reason based purely on general language understanding. In other words, LLMs may make predictions primarily based on premise or hypothesis, rather than both components. To address this problem that may lead to unexpected performance degradation, we propose task calibration (TC), a zero-shot and inference-only calibration method inspired by mutual information which recovers LLM performance through task reformulation. TC encourages LLMs to reason based on both premise and hypothesis, while mitigating the models' over-reliance on individual premise or hypothesis for inference. Experimental results show that TC achieves a substantial improvement on 13 inference tasks in the zero-shot setup. We further validate the effectiveness of TC in few-shot setups and various natural language understanding tasks. Further analysis indicates that TC is also robust to prompt templates and has the potential to be integrated with other calibration methods.", "title_embedding_index": 6602, "title_abs_embedding_index": 6627}, {"title": "Grond: A Stealthy Backdoor Attack in Model Parameter Space", "link_suffix": "/forum?id=7NB7b2Mcuy", "link": "https://openreview.net/forum?id=7NB7b2Mcuy", "pdf_link": "https://openreview.net/pdf?id=7NB7b2Mcuy", "keywords": "backdoor attack, backdoor defense", "abstract": "Recent research on backdoor attacks mainly focuses on invisible triggers in input space and inseparable backdoor representations in feature space\nto increase the backdoor stealthiness against defenses.\nWe examine common backdoor attack practices that look at input-space or feature-space stealthiness and show that state-of-the-art stealthy input-space and feature-space backdoor attacks can be easily spotted by examining the parameter space of the backdoored model. \nLeveraging our observations on the behavior of the defenses in the parameter space, we propose a novel clean-label backdoor attack called Grond. \nWe present extensive experiments showing that Grond outperforms state-of-the-art backdoor attacks on CIFAR-10, GTSRB, and a subset of ImageNet. \nOur attack limits the parameter changes through Adversarial Backdoor Injection, adaptively increasing the parameter-space stealthiness.\nFinally, we show how combining Grond's Adversarial Backdoor Injection with commonly used attacks can consistently improve their effectiveness.\nOur code is available at \\url{https://anonymous.4open.science/r/grond-557F}.", "title_embedding_index": 6603, "title_abs_embedding_index": 6628}, {"title": "SEBRA : Debiasing through Self-Guided Bias Ranking", "link_suffix": "/forum?id=MyVC4X5B2X", "link": "https://openreview.net/forum?id=MyVC4X5B2X", "pdf_link": "https://openreview.net/pdf?id=MyVC4X5B2X", "keywords": "Sub-population shift, Spurious Correlations, Bias Mitigation, Fairness", "abstract": "Ranking samples by fine-grained estimates of spuriosity (the degree to which spurious cues are present) has recently been shown to significantly benefit bias mitigation, over the traditional binary biased-vs-unbiased partitioning of train sets. However, this spuriousity ranking comes with the requirement of human supervision. In this paper, we propose a debiasing framework based on our novel Self-Guided Bias Ranking (Sebra), that mitigates biases via an automatic ranking of data points by spuriosity within their respective classes. Sebra leverages a key local symmetry in Empirical Risk Minimization (ERM) training -- the ease of learning a sample via ERM inversely correlates with its spuriousity; the fewer spurious correlations a sample exhibits, the harder it is to learn, and vice versa. However, globally across iterations, ERM tends to deviate from this symmetry. Sebra dynamically steers ERM to correct this deviation, facilitating the sequential learning of attributes in increasing order of difficulty, ie, decreasing order of spuriosity. As a result, the sequence in which Sebra learns samples naturally provides spuriousity rankings. We use the resulting fine-grained bias characterization in a contrastive learning framework to mitigate biases from multiple sources. Extensive experiments show that Sebra consistently outperforms previous state-of-the-art unsupervised debiasing techniques across multiple standard benchmarks, including UrbanCars, BAR, and CelebA.", "title_embedding_index": 6604, "title_abs_embedding_index": 6629}, {"title": "A Contrastive Teacher-Student Framework for Novelty Detection under Style Shifts", "link_suffix": "/forum?id=FR2WQcwjG4", "link": "https://openreview.net/forum?id=FR2WQcwjG4", "pdf_link": "https://openreview.net/pdf?id=FR2WQcwjG4", "keywords": "Novelty Detection, Robustness Under Distribution Shift, Task-Based Knowledge Distillation, Robustness Under Style Shift, One-Class Classification", "abstract": "There have been several efforts to improve Novelty Detection (ND) performance. However, ND methods often suffer significant performance drops under minor distribution shifts caused by changes in the environment, known as style shifts. This challenge arises from the ND setup, where the absence of out-of-distribution (OOD) samples during training causes the detector to be biased toward the dominant style features in the in-distribution (ID) data. As a result, the model mistakenly learns to correlate style with core features, using this shortcut for detection. Robust ND is crucial for real-world applications like autonomous driving and medical imaging, where test samples may have different styles than the training data. Motivated by this, we propose a robust ND method that crafts an auxiliary OOD set with style features similar to the ID set but with different core features. Then, a task-based knowledge distillation strategy is utilized to distinguish core features from style features and help our model rely on core features for discriminating crafted OOD and ID sets. We verified the effectiveness of our method through extensive experimental evaluations on several datasets, including synthetic and real-world benchmarks, against nine different ND methods.", "title_embedding_index": 6605, "title_abs_embedding_index": 6630}, {"title": "Fine-grained Abnormality Prompt Learning for Zero-shot Anomaly Detection", "link_suffix": "/forum?id=kS27PPs3yR", "link": "https://openreview.net/forum?id=kS27PPs3yR", "pdf_link": "https://openreview.net/pdf?id=kS27PPs3yR", "keywords": "Zero-Shot Anomaly Detection; Prompt Learning; Visual Anomaly Detection", "abstract": "Current zero-shot anomaly detection (ZSAD) methods show remarkable success in prompting large pre-trained vision-language models to detect anomalies in a target dataset without using any dataset-specific training or demonstration. However, these methods are often focused on crafting/learning prompts that capture only coarse-grained semantics of abnormality, $e.g.$, high-level semantics like \"damaged\", \"imperfect\", or \"defective\" on carpet. They therefore have limited capability in recognizing diverse abnormality details with distinctive visual appearance, $e.g.$, specific defect types like color stains, cuts, holes, and threads on carpet. To address this limitation, we propose FAPrompt, a novel framework designed to learn Fine-grained Abnormality Prompts for more accurate ZSAD. To this end, we introduce a novel compound abnormality prompting module in FAPrompt to learn a set of complementary, decomposed abnormality prompts, where each abnormality prompt is formed by a compound of shared normal tokens and a few learnable abnormal tokens. On the other hand, the fine-grained abnormality patterns can be very different from one dataset to another. To enhance their cross-dataset generalization, we further introduce a data-dependent abnormality prior module that learns to derive abnormality features from each query/test image as a sample-wise abnormality prior to ground the abnormality prompts in a given target dataset. Comprehensive experiments conducted across 19 real-world datasets, covering both industrial defects and medical anomalies, demonstrate that FAPrompt substantially outperforms state-of-the-art methods by at least 3%-5% AUC/AP in both image- and pixel-level ZSAD tasks.", "title_embedding_index": 6606, "title_abs_embedding_index": 6631}, {"title": "Unsupervised Learning of Facial Attribute Representations Using StyleGAN", "link_suffix": "/forum?id=FsgGBhNIt4", "link": "https://openreview.net/forum?id=FsgGBhNIt4", "pdf_link": "https://openreview.net/pdf?id=FsgGBhNIt4", "keywords": "facial attributes, unsupervised representation learning, GAN, StyleGAN", "abstract": "Facial attributes (e.g., gender, age) encompass important social cues and play a pivotal role in computer vision. While supervised methods have dominated facial attribute analysis, they often require large annotated datasets, which are costly and time-consuming to create.\nIn this work, we circumvent this limitation by proposing a novel unsupervised learning framework that leverages StyleGAN to learn rich and disentangled facial attribute representations. Specifically, unlike prior methods that rely on labeled datasets or supervised techniques, our approach exploits the unique inductive bias of StyleGAN, namely Hierarchical Feature Modulation, to automatically discover semantically meaningful representations of facial attributes. This inductive bias enables StyleGAN to generate disentangled and interpretable facial attribute features at different layers, benefiting a variety of downstream tasks. To leverage StyleGAN representations, we employ GAN inversion methods to represent input images as StyleGAN features and propose a simple yet effective feature reduction method based on mutual information to improve the effectiveness and efficiency of the learned representations. Extensive experiments in few-shot facial attribute analysis tasks, including clustering, classification, and facial attribute annotation demonstrate the effectiveness of our approach.", "title_embedding_index": 6607, "title_abs_embedding_index": 6632}, {"title": "Noise-Robust Audio-Visual Speech-Driven Body Language Synthesis", "link_suffix": "/forum?id=CYUIeEBri1", "link": "https://openreview.net/forum?id=CYUIeEBri1", "pdf_link": "https://openreview.net/pdf?id=CYUIeEBri1", "keywords": "Body Language Synthesis, speech driven, noise-robust", "abstract": "With the continuous advancement of video generation, researchers have achieved speech-driven body language synthesis, such as co-speech gestures. However, due to the lack of paired data for visual speech (i.e., lip movements) and body languages, existing methods typically rely solely on audio-only speech, which struggles to correctly synthesize target results in noisy environments. To overcome this limitation, we propose an Audio-Visual Speech-Driven Synthesis (AV-SDS) method tailored for body language synthesis, aiming for robust synthesis even under noisy conditions. Given that each body language modality data has its corresponding audio speech, AV-SDS adopts a two-stage synthesis framework based on speech discrete units, consisting of the AV-S2UM and Unit2X modules. It uses speech discrete units as carriers to construct a direct mapping from audio-visual speech to each body language. Considering the distinct characteristics of different body languages, AV-SDS can be implemented based on semantic and acoustic discrete units, respectively, to achieve high-semantic and high-rhythm body language synthesis. Experimental results demonstrate that our AV-SDS achieves superior performance in synthesizing multiple body language modalities in noisy environments, delivering noise-robust body language synthesis. For samples and further information, please visit demo page at \\url{https://av-sds.github.io/}.", "title_embedding_index": 6608, "title_abs_embedding_index": 6633}, {"title": "FairLoRA: Targeted Bias Mitigation without Performance Loss", "link_suffix": "/forum?id=a2gBrMu9MP", "link": "https://openreview.net/forum?id=a2gBrMu9MP", "pdf_link": "https://openreview.net/pdf?id=a2gBrMu9MP", "keywords": "Fair machine learning, Fairness, Bias mitigation, Fine-tuning", "abstract": "Ensuring fairness in machine learning models is critical, but existing debiasing techniques often sacrifice model performance, struggle to adapt to emerging biases, or require extensive sensitive attribute annotations. To address these challenges, we propose FairLoRA, a novel low-rank adaptation method that mitigates bias while preserving model performance. FairLoRA incorporates parameter-efficient modular LoRA components, enabling iterative bias mitigation to ensure fairness across multiple sensitive attributes without interfering with previous adjustments. Furthermore, it employs discriminators to identify biased classes with reduced reliance on sensitive information, significantly reducing the need for annotated data. We theoretically derive conditions under which FairLoRA fine-tuning can effectively mitigate bias while maintaining the original model's performance. We then empirically validate its effectiveness across diverse computer vision and natural language processing tasks. Our experimental results show that, even for models that have undergone prior bias mitigation training, the integration of FairLoRA fine-tuning can further enhance fairness, while maintaining or even slightly improving the original performance.", "title_embedding_index": 6609, "title_abs_embedding_index": 6634}, {"title": "Class-wise Generalization Error: an Information-Theoretic analysis", "link_suffix": "/forum?id=zRsFAUQDRk", "link": "https://openreview.net/forum?id=zRsFAUQDRk", "pdf_link": "https://openreview.net/pdf?id=zRsFAUQDRk", "keywords": "information-theoretic bounds, generalization error, class-bias", "abstract": "Existing generalization theories for supervised learning typically take a holistic approach and provide bounds for the expected generalization over the whole data distribution, which implicitly assumes that the model generalizes similarly for all different classes. In practice, however, there are significant variations in generalization performance among different classes, which cannot be captured by the existing generalization bounds. In this work, we tackle this problem by theoretically studying the class-generalization error, which quantifies the generalization performance of the model for each individual class.  We derive a novel information-theoretic bound for class-generalization error using the KL divergence, and we further obtain several tighter bounds using recent advances in conditional mutual information bound, which enables practical evaluation. We empirically validate our proposed bounds in various neural networks and show that they accurately capture the complex class-generalization behavior. Moreover, we demonstrate that the theoretical tools developed in this work can be applied in several other applications.", "title_embedding_index": 6610, "title_abs_embedding_index": 6635}, {"title": "LIME: LESS IS MORE FOR MLLM EVALUATION", "link_suffix": "/forum?id=3c4zQpIFNK", "link": "https://openreview.net/forum?id=3c4zQpIFNK", "pdf_link": "https://openreview.net/pdf?id=3c4zQpIFNK", "keywords": "Multimodal Language Models, Multimodal Benchmark", "abstract": "Multimodal Large Language Models (MLLMs) are measured on numerous benchmarks like image captioning, visual question answer, and reasoning. However, these benchmarks often include overly simple or uninformative samples, making it difficult to effectively distinguish the performance of different MLLMs. Additionally, evaluating models across many benchmarks creates a significant computational burden. To address these issues, we propose LIME (Less Is More for MLLM Evaluation), a refined and efficient benchmark curated using a semi-automated pipeline. This pipeline filters out uninformative samples and eliminates answer leakage by focusing on tasks that require image-based understanding. Our experiments show that LIME reduces the number of samples by 76% and evaluation time by 77%, while it can more effectively distinguish different models' abilities. Notably, we find that traditional automatic metrics like CIDEr are insufficient for evaluating MLLMs\u2019 captioning performance, and excluding the caption task score yields a more accurate reflection of overall model performance. All code and data are available athttps://anonymous.4open.science/r/LIME-49CD.", "title_embedding_index": 6611, "title_abs_embedding_index": 6636}, {"title": "Rate of Approximation by Flows: A Case Study on the Eikonal Equation", "link_suffix": "/forum?id=e9iRAkEJQ1", "link": "https://openreview.net/forum?id=e9iRAkEJQ1", "pdf_link": "https://openreview.net/pdf?id=e9iRAkEJQ1", "keywords": "flow map, approximation rate, eikonal equation", "abstract": "Previous works have demonstrated the universal approximation capability of residual networks through their continuous idealization as flow maps of dynamical systems. However, informative results on their approximation rates in terms of depth (corresponding to time) are generally lacking. From the viewpoint of approximation theory, a major difficulty in addressing this gap lies in identifying an appropriate target space for the approximation problem. In this paper, we introduce a restrictive but useful target function space comprised of solutions to the eikonal equations, a type of first-order nonlinear partial differential equation, to investigate the approximation rates of flow map families. We provide an estimate of the approximation error within this space, which is notably different from classical rate estimates based directly on the smoothness of target functions. This theoretical result further inspires a new learning-based algorithm for solving the eikonal equation. Experimental results validate the effectiveness of our proposed algorithm, including its robustness to spatial resolution and solution regularity, as well as transferability among similar problems.", "title_embedding_index": 6612, "title_abs_embedding_index": 6637}, {"title": "Bayesian Active Learning By Distribution Disagreement", "link_suffix": "/forum?id=YiyG1tHDxq", "link": "https://openreview.net/forum?id=YiyG1tHDxq", "pdf_link": "https://openreview.net/pdf?id=YiyG1tHDxq", "keywords": "Active Learning, Normalizing Flows, Regression, Uncertainty Quantification", "abstract": "Active Learning (AL) for regression has been systematically under-researched due to the increased difficulty of measuring uncertainty in regression models.\nSince normalizing flows offer a full predictive distribution instead of a point forecast, they facilitate direct usage of known heuristics for AL like Entropy or Least-Confident sampling.\nHowever, we show that most of these heuristics do not work well for normalizing flows in pool-based AL and we need more sophisticated algorithms to distinguish between aleatoric and epistemic uncertainty.\nIn this work we propose BALSA, an adaptation of the BALD algorithm, tailored for regression with normalizing flows.\nWith this work we extend current research on uncertainty quantification with normalizing flows to real world data and pool-based AL with multiple acquisition functions and query sizes.\nWe report SOTA results for BALSA across 4 different datasets and 2 different architectures.", "title_embedding_index": 6613, "title_abs_embedding_index": 6638}, {"title": "Gridded Transformer Neural Processes for Large Unstructured Spatio-Temporal Data", "link_suffix": "/forum?id=ePGheWbLPY", "link": "https://openreview.net/forum?id=ePGheWbLPY", "pdf_link": "https://openreview.net/pdf?id=ePGheWbLPY", "keywords": "neural process, probabilistic machine learning, transformer, spatio-temporal data", "abstract": "Many important problems require modelling large-scale spatio-temporal datasets, with one prevalent example being weather forecasting. Recently, transformer-based approaches have shown great promise in a range of weather forecasting problems. However, these have mostly focused on gridded data sources, neglecting the wealth of unstructured, off-the-grid data from observational measurements such as those at weather stations. A promising family of models suitable for such tasks are neural processes (NPs), notably the family of transformer neural processes (TNPs). Although TNPs have shown promise on small spatio-temporal datasets, they are unable to scale to the quantities of data used by state-of-the-art weather and climate models. This limitation stems from their lack of efficient attention mechanisms. We address this shortcoming through the introduction of gridded pseudo-token TNPs which employ specialised encoders and decoders to handle unstructured observations and utilise a processor containing gridded pseudo-tokens that leverage efficient attention mechanisms. Our method consistently outperforms a range of strong baselines on various synthetic and real-world regression tasks involving large-scale data, while maintaining competitive computational efficiency. The real-life experiments are performed on weather data, demonstrating the potential of our approach to bring performance and computational benefits when applied at scale in a weather modelling pipeline.", "title_embedding_index": 6614, "title_abs_embedding_index": 6639}, {"title": "InfCycle: Learning to Use Tools via Inference Compute and Cycle Consistency", "link_suffix": "/forum?id=CD2wgg9RQD", "link": "https://openreview.net/forum?id=CD2wgg9RQD", "pdf_link": "https://openreview.net/pdf?id=CD2wgg9RQD", "keywords": "LLM, Tool use, Inference Scaling, Cycle Consistency, Self-improve", "abstract": "The scaling of inference-time computation in large language models (LLMs) has emerged as a promising approach for enhancing reasoning capabilities by trading off inference-time and pre-training compute. \nThe practice of how to enable LLMs to utilize additional computation at test time to improve response accuracy is crucial for both academia and industry.\n\\textit{Proposer-Verifier}, as a typical paradigm of inference scaling, often fails to generalize to various scenarios. \nSpecifically, in tool use tasks, LLMs face the risk of lacking effective verifiers, leading to error accumulation in multiple reasoning steps. \nIn this work, we address these challenges by introducing \\textbf{InfCycle}, a multi-stage data synthesis strategy that employs LLMs as data synthesis and employs cycle consistency verification to ensure high-quality trajectory generation. \nThis approach utilizes step-wise cycle consistency among synthesized trajectories for a given tool, providing effective process supervision that has advantages over outcome supervision.\nExtensive experiments on multiple tool-use and reasoning tasks demonstrate that InfCycle efficiently enables self-improvement. \nIt outperforms state-of-the-art baselines on StableToolBench, achieving a 75.4% pass rate and a 79.6% win rate using small size models (7B), without relying on external supervision or expert trajectories for warm-up.", "title_embedding_index": 6615, "title_abs_embedding_index": 6640}, {"title": "Signal Dynamics in Diffusion Models: Enhancing Text-to-Image Alignment through Step Selection", "link_suffix": "/forum?id=HEi70bBquo", "link": "https://openreview.net/forum?id=HEi70bBquo", "pdf_link": "https://openreview.net/pdf?id=HEi70bBquo", "keywords": "Visual Generative AI, Diffusion Model, Text-to-Image Alignment", "abstract": "Visual generative AI models often encounter challenges related to text-image alignment and reasoning limitations. This paper presents a novel method for selectively enhancing the signal at critical diffusion steps, optimizing image generation based on input semantics. Our approach addresses the shortcomings of early-stage signal modifications, demonstrating that adjustments made at later stages yield superior results. We conduct extensive experiments to validate the effectiveness of our method in producing semantically aligned images, achieving state-of-the-art performance. Our results highlight the importance of a judicious choice of sampling stage to improve diffusion performance and overall image alignment.", "title_embedding_index": 6616, "title_abs_embedding_index": 6641}, {"title": "A Rademacher-Like Random Embedding with Linear Complexity", "link_suffix": "/forum?id=u0L7djBiRw", "link": "https://openreview.net/forum?id=u0L7djBiRw", "pdf_link": "https://openreview.net/pdf?id=u0L7djBiRw", "keywords": "Random Embedding, Randomized Singular Value Deomposition, Randomized Arnoldi Process, Machine Learning, Linear Complexity", "abstract": "Random embedding assumes an important role in representation learning. Gaussian embedding and Rademacher embedding are two widely used random embeddings. Although they usually enjoy numerical stability and effectiveness, their computational complexity is high, i.e. $O(nk)$ for embedding an $n$-dimensional vector into $k$-dimensional subspace. The alternatives include partial subsampled randomized Hadamard (P-SRHT) embedding and sparse sign embedding, which are still not of linear complexity or cannot run efficiently in practical implementation. In this paper, a fast and stable Rademacher-like random embedding (RLE) is proposed. Specifically, it embeds an $n$-dimensional vector into $k$-dimensional subspace  in just $O(n)$ time and space (assuming $k \\le n^{\\frac{1}{2}}$). The theoretical analysis is presented, which indicates the proposed RLE owns most of desirable properties of the Rademacher embedding while preserving $O(n)$ complexity. In fact, the proposed RLE approach implicitly generates the Rademacher-like embedding matrix, based on novel random structures called buckets. This makes the random embedding accelerated without loss of stability. To validate the practical efficiency and effectiveness, the proposed RLE is applied to single-pass randomized singular value decomposition (single-pass RSVD) for streaming data, and the randomized Arnoldi process based on sketched ordinary least-squares. Numerical experiments show that, with the proposed RLE the single-pass RSVD achieves 1.7x speed-up on average while keeping same or even better accuracy, and the randomized Arnodli process enables a randomized GMRES algorithm running 1.3x faster on average for solving $Ax=b$ than that based on other random embeddings.", "title_embedding_index": 6617, "title_abs_embedding_index": 6642}, {"title": "Fractal-Inspired Message Passing Neural Networks with Fractal Nodes", "link_suffix": "/forum?id=zPoW8CajCN", "link": "https://openreview.net/forum?id=zPoW8CajCN", "pdf_link": "https://openreview.net/pdf?id=zPoW8CajCN", "keywords": "graph neural network, message passing neural network", "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools for learning on graph-structured data, but they struggle to balance local and global information processing. While graph Transformers aim to address these issues, they often neglect the inherent locality of Message Passing Neural Networks (MPNNs). Inspired by the fractal nature of real-world networks, we propose a novel concept, 'fractal nodes', that addresses the limitations of both MPNN and graph Transformer. The approach draws insights from renormalization techniques to design a message-passing scheme that captures both local and global structural information. Our method enforces self-similarity into nodes by creating fractal nodes that coexist with the original nodes. Fractal nodes adaptively summarize subgraph information and are integrated into MPNN. We show that fractal nodes alleviate an over-squashing problem by providing direct shortcuts to pass fractal information over long distances. Experiments show that our method achieves comparable or better performance to the graph Transformers while maintaining the computational efficiency of MPNN by improving the long-range dependencies of MPNN.", "title_embedding_index": 6618, "title_abs_embedding_index": 6643}, {"title": "Conceptualize Any Network: A Concept Extraction Framework for Holistic Interpretability of Image Classifiers", "link_suffix": "/forum?id=wZiH43e5Ah", "link": "https://openreview.net/forum?id=wZiH43e5Ah", "pdf_link": "https://openreview.net/pdf?id=wZiH43e5Ah", "keywords": "Explainability, Computer Vision, CNN, ViT", "abstract": "Attribution-based and concept-based methods dominate the area of post-hoc explainability for vision classifiers. While attribution-based methods highlight crucial regions of the input images to justify model predictions, concept-based methods provide explanations rooted in high-level properties that are generally more understandable for humans. In this work, we introduce ``Conceptualize Any Network'' (CAN), a comprehensive post-hoc explanation framework that combines the wide scope of attribution-based methods and the understandability of concept-based methods. \nDesigned to be model agnostic, CAN is capable of explaining any network that allows for the extraction of feature attribution maps, expanding its applicability to both CNNs and Vision Transformers (ViTs). Moreover, unlike existing concept-based methods for vision classifiers, CAN extracts a set of concepts shared across all classes, enabling a unified explanation of the model as a whole.\nExtensive numerical experiments across different architectures, datasets, and feature attribution methods showcase the capabilities of CAN in Conceptualizing Any Network faithfully, concisely, and consistently.\nFurthermore, we managed to scale our framework to all of ImageNet's classes which has not been achieved before.", "title_embedding_index": 6619, "title_abs_embedding_index": 6644}, {"title": "Provably Reliable Conformal Prediction Sets in the Presence of Data Poisoning", "link_suffix": "/forum?id=ofuLWn8DFZ", "link": "https://openreview.net/forum?id=ofuLWn8DFZ", "pdf_link": "https://openreview.net/pdf?id=ofuLWn8DFZ", "keywords": "Conformal prediction, Certifiable robustness, Adversarial robustness", "abstract": "Conformal prediction provides model-agnostic and distribution-free uncertainty quantification through prediction sets that are guaranteed to include the ground truth with any user-specified probability. Yet, conformal prediction is not reliable under poisoning attacks where adversaries manipulate both training and calibration data, which can significantly alter prediction sets in practice. As a solution, we propose reliable prediction sets (RPS): the first efficient method for constructing conformal prediction sets with provable reliability guarantees under poisoning. To ensure reliability under training poisoning, we introduce smoothed score functions that reliably aggregate predictions of classifiers trained on distinct partitions of the training data. To ensure reliability under calibration poisoning, we construct multiple prediction sets, each calibrated on distinct subsets of the calibration data. We then aggregate them into a majority prediction set, which includes a class only if it appears in a majority of the individual sets. Both proposed aggregations mitigate the influence of datapoints in the training and calibration data on the final prediction set. We experimentally validate our approach on image classification tasks, achieving strong reliability while maintaining utility and preserving coverage on clean data. Overall, our approach represents an important step towards more trustworthy uncertainty quantification in the presence of data poisoning.", "title_embedding_index": 6620, "title_abs_embedding_index": 6645}, {"title": "Hierarchical Multimodal Knowledge Matching for Training-Free Open-Vocabulary Object Detection", "link_suffix": "/forum?id=WlKGZuolEk", "link": "https://openreview.net/forum?id=WlKGZuolEk", "pdf_link": "https://openreview.net/pdf?id=WlKGZuolEk", "keywords": "open-vocabulary object detection, multimodal knowledge, vision and language", "abstract": "Open-Vocabulary Object Detection (OVOD) aims to leverage the generalization capabilities of pre-trained vision language models for detecting objects beyond the trained categories. \nExisting methods mostly focus on supervised learning strategies based on available training data, which might be suboptimal for data-limited novel categories.\nTo tackle this challenge, this paper presents a $\\textbf{H}$ierarchical $\\textbf{M}$ultimodal $\\textbf{K}$nowledge $\\textbf{M}$atching method ($\\textbf{HMKM}$) to better represent novel categories and match them with region features.\nSpecifically, HMKM includes a set of object prototype knowledge that is obtained using limited category-specific images, acting as off-the-shelf category representations.\nIn addition, HMKM also includes a set of attribute prototype knowledge to represent key attributes of categories at a fine-grained level, with the goal to distinguish one category from its visually similar ones.\nDuring inference, two sets of object and attribute prototype knowledge are adaptively combined to match categories with region features.\nThe proposed HMKM is training-free and can be easily integrated as a plug-and-play module into existing OVOD models. \nExtensive experiments demonstrate that our HMKM significantly improves the performance when detecting novel categories across various backbones and datasets.", "title_embedding_index": 6621, "title_abs_embedding_index": 6646}, {"title": "An Online Learning Approach to Prompt-based Selection of Generative Models", "link_suffix": "/forum?id=k73R7xdWtl", "link": "https://openreview.net/forum?id=k73R7xdWtl", "pdf_link": "https://openreview.net/pdf?id=k73R7xdWtl", "keywords": "online learning, conditional generative models, contextual bandits", "abstract": "Selecting a sample generation scheme from multiple text-based generative models is typically addressed by choosing the model that maximizes an averaged evaluation score. However, this score-based selection overlooks the possibility that different models achieve the best generation performance for different types of text prompts. An online identification of the best generation model for various input prompts can reduce the costs associated with querying sub-optimal models. In this work, we explore the possibility of varying rankings of text-based generative models for different text prompts and propose an online learning framework to predict the best data generation model for a given input prompt. The proposed framework adapts the kernelized contextual bandit (CB) methodology to a CB setting with shared context variables across arms, utilizing the generated data to update a kernel-based function that predicts which model will achieve the highest score for unseen text prompts. Additionally, we apply random Fourier features (RFF) to the kernelized CB algorithm to accelerate the online learning process and establish a $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret bound for the proposed RFF-based CB algorithm over T iterations. Our numerical experiments on real and simulated text-to-image and image-to-text generative models show RFF-UCB performs successfully in identifying the best generation model across different sample types.", "title_embedding_index": 6622, "title_abs_embedding_index": 6647}, {"title": "VColRL: Learn to Solve the Vertex Coloring Problem Using Reinforcement Learning", "link_suffix": "/forum?id=nIBmwm7ixo", "link": "https://openreview.net/forum?id=nIBmwm7ixo", "pdf_link": "https://openreview.net/pdf?id=nIBmwm7ixo", "keywords": "Vertex Coloring Problem, Markov Decision Process, Reinforcement Learning, Graph Neural Networks, Combinatorial Optimization", "abstract": "We present VColRL, a reinforcement learning framework designed to solve the vertex coloring problem (VCP), where the objective is to assign colors to the vertices of a graph with the minimum number of colors, such that no two adjacent vertices share the same color. The framework is built on a novel Markov Decision Process (MDP) configuration to effectively capture the dynamics of the VCP, that we develop after evaluating various MDP configurations. Our experimental results demonstrate that VColRL outperforms advanced mathematical solvers and other baseline methods, particularly on large and dense graphs. Additionally, our results show that VColRL generalizes well on different types of graphs.", "title_embedding_index": 6623, "title_abs_embedding_index": 6648}, {"title": "SWIFT: Mapping Sub-series with Wavelet Decomposition Improves Time Series Forecasting", "link_suffix": "/forum?id=hbWFeQ1zBp", "link": "https://openreview.net/forum?id=hbWFeQ1zBp", "pdf_link": "https://openreview.net/pdf?id=hbWFeQ1zBp", "keywords": "Time Series Forecasting, Edge Computing", "abstract": "In this paper, we propose $\\textit{SWIFT}$, a lightweight model that is not only powerful, but also efficient in deployment and inference for Long-term Time Series Forecasting (LTSF). Our model is based on two key points: 1. decomposition of sequences using wavelet transform. 2. using only one shared single layer for sub-series' mapping. We conduct comprehensive experiments, and the results show that $\\textit{SWIFT}$ achieves state-of-the-art (SOTA) performance on multiple datasets, offering a promising method for edge computing and deployment in this task. Moreover, it is noteworthy that the number of parameters in $\\textit{SWIFT}$ is only 25% of what it would be with a single-layer linear model for time-domain prediction.", "title_embedding_index": 6624, "title_abs_embedding_index": 6649}]
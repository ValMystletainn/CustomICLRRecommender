[{"title": "On the Limitations of General Purpose Domain Generalisation Methods", "link_suffix": "/forum?id=KstDMYkfj4", "link": "https://openreview.net/forum?id=KstDMYkfj4", "pdf_link": "https://openreview.net/pdf?id=KstDMYkfj4", "keywords": "Domain Generalisation, Excess Risk, Empirical Risk Minimisation, Minimax, Rademacher Complexity", "abstract": "The Domain Generalisation (DG) problem setting requires a model trained on a set of data distributions (domains) to generalise to new distributions. Despite a huge amount of empirical study, previous DG methods fail to substantially outperform empirical risk minimisation on rigorous DG benchmarks. Motivated by this, we analyse the DG problem from a learning theoretic perspective andcharacterise in which situations DG will succeed or fail. Specifically, we derive upper bounds on the excess risk of ERM and lower bounds on the minimax excess risk, for three settings with different restrictions on how the domains may differ. In the most unconstrained setting, we show that all learning algorithms converge slowly with respect to number of training domains, potentially explaining the lack of algorithmic progress in this area. We also consider constrained settings including limiting the pairwise domain distances as measured by a broad class of integral probability metrics, and constraining all domains to have the same underlying support. In these constrained cases, DG algorithms can converge more rapidly. Notably, for all three settings, the we demonstrate that ERM has an optimal rate of convergence towards the best possible model. Our analysis guides practitioners interested in knowing when cross-domain generalisation might be reliable, and suggests strategies for optimising the performance of ERM in each setting.", "title_embedding_index": 10600, "title_abs_embedding_index": 10625}, {"title": "Unlocking the Power of GANs in Non-Autoregressive Text Generation", "link_suffix": "/forum?id=4tiTQ33sDH", "link": "https://openreview.net/forum?id=4tiTQ33sDH", "pdf_link": "https://openreview.net/pdf?id=4tiTQ33sDH", "keywords": "Language GANs, Non-Autoregressive Model, Text Generation", "abstract": "Generative Adversarial Networks (GANs) have been studied in text generation to tackle the exposure bias problem. Despite their remarkable development, they adopt autoregressive structures so suffering from high latency in both training and inference stages. Although GANs have potential to support efficient generation by adopting non-autoregressive (NAR) structures, their explorations in NAR models are extremely limited. In this work, we conduct pioneering study of building language GANs based on NAR structures. We identify two issues that constrain the performance of GAN-based NAR models. Firstly, existing methods of incorporating latent variables provide highly similar representations which cannot describe the diversity of different words in sentences. We tackle this problem by proposing Position-Aware Self-Modulation, providing more diverse and effective representations. Secondly, the attention mechanism in Transformer cannot accurately build word dependencies in the unstable training of GANs, and we adopt Dependency Feed Forward Network to enhance the model capacity in dependency modeling. Armed with these two facilities, we propose a GAN-based NAR model, Adversarial Non-autoregressive Transformer (ANT). The experimental results demonstrate that ANT can achieve comparable performance with mainstream models in a single forward pass and has great potential in various applications like latent interpolation and semi-supervised learning.", "title_embedding_index": 10601, "title_abs_embedding_index": 10626}, {"title": "Diversity-Rewarded CFG Distillation", "link_suffix": "/forum?id=lJ66m0ibQL", "link": "https://openreview.net/forum?id=lJ66m0ibQL", "pdf_link": "https://openreview.net/pdf?id=lJ66m0ibQL", "keywords": "Music Generation, Distillation, CFG, RL, Diversity, Model Merging", "abstract": "Generative models are transforming creative domains such as music generation, with inference-time strategies like Classifier-Free Guidance (CFG) playing a crucial role. However, CFG doubles inference cost while limiting originality and diversity across generated contents. In this paper, we introduce diversity-rewarded CFG distillation, a novel finetuning procedure that distills the strengths of CFG while addressing its limitations. Our approach optimises two training objectives:  (1) a distillation objective, encouraging the model alone (without CFG) to imitate the CFG-augmented predictions, and (2) an RL objective with a diversity reward, promoting the generation of diverse outputs for a given prompt. By finetuning, we learn model weights with the ability to generate high-quality and diverse outputs, without any inference overhead. This also unlocks the potential of weight-based model merging strategies: by interpolating between the weights of two models (the first focusing on quality, the second on diversity), we can control the quality-diversity trade-off at deployment time, and even further boost performance. We conduct extensive experiments on the MusicLM text-to-music generative model, where our approach surpasses CFG in terms of quality-diversity Pareto optimality.  According to human evaluators, our finetuned-then-merged model generates samples with higher quality-diversity than the base model augmented with CFG. Explore our generations athttps://musicdiversity.github.io/.", "title_embedding_index": 10602, "title_abs_embedding_index": 10627}, {"title": "Language-Assisted Feature Transformation for Anomaly Detection", "link_suffix": "/forum?id=2p03KljxE9", "link": "https://openreview.net/forum?id=2p03KljxE9", "pdf_link": "https://openreview.net/pdf?id=2p03KljxE9", "keywords": "anomaly detection, feature transformation, vision-language model, language guidance", "abstract": "This paper introduces LAFT, a novel feature transformation method designed to incorporate user knowledge and preferences into anomaly detection using natural language. Accurately modeling the boundary of normality is crucial for distinguishing abnormal data, but this is often challenging due to limited data or the presence of nuisance attributes. While unsupervised methods that rely solely on data without user guidance are common, they may fail to detect anomalies of specific interest. To address this limitation, we propose Language-Assisted Feature Transformation (LAFT), which leverages the shared image-text embedding space of vision-language models to transform visual features according to user-defined requirements. Combined with anomaly detection methods, LAFT effectively aligns visual features with user preferences, allowing anomalies of interest to be detected. Extensive experiments on both toy and real-world datasets validate the effectiveness of our method.", "title_embedding_index": 10603, "title_abs_embedding_index": 10628}, {"title": "High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws", "link_suffix": "/forum?id=1xzqz73hvL", "link": "https://openreview.net/forum?id=1xzqz73hvL", "pdf_link": "https://openreview.net/pdf?id=1xzqz73hvL", "keywords": "empirical risk minimization, high-dimensional statistics, scaling laws, weak to strong generalization, knowledge distillation", "abstract": "A growing number of machine learning scenarios rely on knowledge distillation where one uses the output of a surrogate model as labels to supervise the training of a target model. In this work, we provide a sharp characterization of this process for ridgeless, high-dimensional regression, under two settings:(i)model shift, where the surrogate model is arbitrary, and(ii)distribution shift, where the surrogate model is the solution of empirical risk minimization with out-of-distribution data. In both cases, we characterize the precise risk of the target model through non-asymptotic bounds in terms of sample size and data distribution under mild conditions. As a consequence, we identify the form of the optimal surrogate model, which reveals the benefits and limitations of discarding weak features in a data-dependent fashion. In the context of weak-to-strong (W2S) generalization, this has the interpretation that(i)W2S training, with the surrogate as the weak model, can provably outperform training with strong labels under the same data budget, but(ii)it is unable to improve the data scaling law. We validate our results on numerical experiments both on ridgeless regression and on neural network architectures.", "title_embedding_index": 10604, "title_abs_embedding_index": 10629}, {"title": "The Genomics Long-Range Benchmark: Advancing DNA Language Models", "link_suffix": "/forum?id=8O9HLDrmtq", "link": "https://openreview.net/forum?id=8O9HLDrmtq", "pdf_link": "https://openreview.net/pdf?id=8O9HLDrmtq", "keywords": "DNA, Language Models, Genomics, Benchmark", "abstract": "The advent of language models (LMs) in genomics necessitates benchmarks that can assess models\u2019 capabilities and limitations. In contrast to protein models, DNA LMs can be used to study non-coding regions of the genome and must account for unique challenges, especially interactions across long sequence lengths. However, existing benchmarks for DNA LMs are defined over short sequence datasets and can involve tasks that are often not considered to be biologically meaningful. Here, we present the Genomics Long-Range Benchmark (LRB), which focuses on biologically meaningful tasks and supports long-range contexts. We complement our benchmark with fine-tuning recipes that meaningfully improve performance and affect model evaluation. We evaluate DNA LMs across nine compiled tasks and observe that DNA LMs achieve competitive performance relative to supervised baselines on several tasks (e.g., genome annotation), but there remains a significant gap in domains, such as variant effect and gene expression prediction. Additionally, we introduce a visualization tool to examine model performance split by various genomic properties. Lastly, we present methods for context-length extrapolation of transformer-based models that enable studying the effect of context length on DNA LM performance.", "title_embedding_index": 10605, "title_abs_embedding_index": 10630}, {"title": "Real-World Benchmarks Make Membership Inference Attacks Fail on Diffusion Models", "link_suffix": "/forum?id=EE2tIwKhSW", "link": "https://openreview.net/forum?id=EE2tIwKhSW", "pdf_link": "https://openreview.net/pdf?id=EE2tIwKhSW", "keywords": "Membership inference attack, Diffusion models, Benchmark", "abstract": "Membership inference attacks (MIAs) on diffusion models have emerged as potential evidence of unauthorized data usage in training pre-trained diffusion models. These attacks aim to detect the presence of specific images in training datasets of diffusion models. Our study delves into the evaluation of state-of-the-art MIAs on diffusion models and reveals critical flaws and overly optimistic performance estimates in existing MIA evaluation. We introduce CopyMark, a more realistic MIA benchmark that distinguishes itself through the support for pre-trained diffusion models, unbiased datasets, and fair evaluation pipelines. Through extensive experiments, we demonstrate that the effectiveness of current MIA methods significantly degrades under these more practical conditions. Based on our results, we alert that MIA, in its current state, is not a reliable approach for identifying unauthorized data usage in pre-trained diffusion models. To the best of our knowledge, we are the first to discover the performance overestimation of MIAs on diffusion models and present a unified benchmark for more realistic evaluation.", "title_embedding_index": 10606, "title_abs_embedding_index": 10631}, {"title": "LoRA-X: Bridging Foundation Models with Training-Free Cross-Model Adaptation", "link_suffix": "/forum?id=6cQ6cBqzV3", "link": "https://openreview.net/forum?id=6cQ6cBqzV3", "pdf_link": "https://openreview.net/pdf?id=6cQ6cBqzV3", "keywords": "parameter efficient fine tuning, Low Rank Adaptation, knowledge distillation", "abstract": "The rising popularity of large foundation models has led to a heightened demand for parameter-efficient fine-tuning methods, such as Low-Rank Adaptation (LoRA), which offer performance comparable to full model fine-tuning while requiring only a few additional parameters tailored to the specific base model. When such base models are deprecated and replaced, all associated LoRA modules must be retrained, requiring access to either the original training data or a substantial amount of synthetic data that mirrors the original distribution. However, the original data is often inaccessible due to privacy or licensing issues, and generating synthetic data may be impractical and insufficiently representative. These factors complicate the fine-tuning process considerably. To address this challenge, we introduce a new adapter, Cross-Model Low-Rank Adaptation (LoRA-X), which enables the training-free transfer of LoRA parameters across source and target models, eliminating the need for original or synthetic training data. Our approach imposes the adapter to operate within the subspace of the source base model. This constraint is necessary because our prior knowledge of the target model is limited to its weights, and the criteria for ensuring the adapter\u2019s transferability are restricted to the target base model\u2019s weights and subspace.  To facilitate the transfer of LoRA parameters of the source model to a target model, we employ the adapter only in the layers of the target model that exhibit an acceptable level of subspace similarity. Our extensive experiments demonstrate the effectiveness of LoRA-X for text-to-image generation, including Stable Diffusion v1.5 and Stable Diffusion XL.", "title_embedding_index": 10607, "title_abs_embedding_index": 10632}, {"title": "Accelerating Inference of Retrieval-Augmented Generation via Sparse Context Selection", "link_suffix": "/forum?id=HE6pJoNnFp", "link": "https://openreview.net/forum?id=HE6pJoNnFp", "pdf_link": "https://openreview.net/pdf?id=HE6pJoNnFp", "keywords": "Retrieval-Augmented Generation, Sparse Context, Efficiency", "abstract": "Large language models (LLMs) augmented with retrieval exhibit robust performance and extensive versatility by incorporating external contexts. However, the input length grows linearly in the number of retrieved documents, causing a dramatic increase in latency. In this paper, we propose a novel paradigm named Sparse RAG, which seeks to cut computation costs through sparsity. Speci\ufb01cally, Sparse RAG encodes retrieved documents in parallel, which eliminates latency introduced by long-range attention of retrieved documents. Then, LLMs selectively decode the output by only attending to highly relevant caches auto-regressively, which are chosen via prompting LLMs with special control tokens. It is notable that Sparse RAG combines the assessment of each individual document and the generation of the response into a single process. The designed sparse mechanism in a RAG system can facilitate the reduction of the number of documents loaded during decoding for accelerating the inference of the RAG system. Additionally, \ufb01ltering out undesirable contexts enhances the model\u2019s focus on relevant context, inherently improving its generation quality. Evaluation results on four datasets show that Sparse RAG can be used to strike an optimal balance between generation quality and computational ef\ufb01ciency, demonstrating its generalizability across tasks.", "title_embedding_index": 10608, "title_abs_embedding_index": 10633}, {"title": "Improving model robustness against noise with safe haven activations", "link_suffix": "/forum?id=PoSq0B0ffE", "link": "https://openreview.net/forum?id=PoSq0B0ffE", "pdf_link": "https://openreview.net/pdf?id=PoSq0B0ffE", "keywords": "Quantized Neural Networks, Noise Robustness", "abstract": "Quantized neural networks (QNNs) are often used in edge AI because they reduce memory and computational demands. In practical applications such as control systems, medical imaging, and robotics, controlling input noise is crucial for enhancing system robustness. Thus, improving the noise resilience of QNNs is an important challenge in achieving effective edge AI applications. In this paper, we investigate the impact of input noise on QNN performance and propose the safe haven activation quantization (SHAQ) method. This approach leverages the characteristics of the quantization function to constrain outputs before quantization within a more noise-resilient 'safe' range, effectively reducing the impact of noise across quantized layers. Our methods achieve state-of-the-art, 73.11% accuracy with 2-bit activations under the fast gradient sign method (FGSM) adversarial attacks with an epsilon of 8/255 on the CIFAR-10 dataset. Furthermore, we extend our methods into a plug-and-play solution we call quantized helmet (QH), comprising a series of quantized layers that can be integrated into any unquantized neural network to enhance its noise robustness. Our experimental code and analysis are open-source and publicly accessible.", "title_embedding_index": 10609, "title_abs_embedding_index": 10634}, {"title": "VLP: Vision-Language Preference Learning for Embodied Manipulation", "link_suffix": "/forum?id=blwWIKpwpL", "link": "https://openreview.net/forum?id=blwWIKpwpL", "pdf_link": "https://openreview.net/pdf?id=blwWIKpwpL", "keywords": "reinforcement learning, preference-based reinforcement learning, vision-language alignment, offline reinforcement learning", "abstract": "Reward engineering is one of the key challenges in Reinforcement Learning (RL). Preference-based RL effectively addresses this issue by learning from human feedback. However, it is both time-consuming and expensive to collect human preference labels. In this paper, we propose a novel Vision-Language Preference learning framework, named VLP, which learns a vision-language preference model to provide preference feedback for embodied manipulation tasks. To achieve this, we define three types of language-conditioned preferences and construct a vision-language preference dataset, which contains versatile implicit preference orders without human annotations. The preference model learns to extract language-related features, and then serves as a preference annotator in various downstream tasks. The policy can be learned according to the annotated preferences via reward learning or direct policy optimization. Extensive empirical results on simulated embodied manipulation tasks demonstrate that our method provides accurate preferences and generalizes to unseen tasks and unseen language, outperforming the baselines by a large margin. The code and videos of our method are available on the website:https://VLPref.github.io.", "title_embedding_index": 10610, "title_abs_embedding_index": 10635}, {"title": "Sketch-to-Skill: Bootstrapping Robot Learning with Human Drawn Trajectory Sketches", "link_suffix": "/forum?id=ww7JqIf494", "link": "https://openreview.net/forum?id=ww7JqIf494", "pdf_link": "https://openreview.net/pdf?id=ww7JqIf494", "keywords": "robotics, learn from demonstration, reinforcement learning", "abstract": "Training robotic manipulation policies traditionally requires numerous demonstrations and/or environmental rollouts. While recent Imitation Learning (IL) and Reinforcement Learning (RL) methods have reduced the number of required demonstrations, they still rely on expert knowledge to collect high-quality data, limiting scalability and accessibility. We propose Sketch-to-Skill, a novel framework that leverages human-drawn 2D sketch trajectories to bootstrap and guide RL for robotic manipulation. Our approach extends beyond previous sketch-based methods, which were primarily focused on imitation learning or policy conditioning, limited to specific trained tasks. Sketch-to-Skill employs a Sketch-to-3D Trajectory Generator that translates 2D sketches into 3D trajectories, which are then used to autonomously collect initial demonstrations. We utilize these sketch-generated demonstrations in two ways: to pre-train an initial policy through behavior cloning and to refine this policy through RL with guided exploration. Experimental results demonstrate that Sketch-to-Skill achieves $\\sim$96% of the performance of the baseline model that leverages teleoperated demonstration data, while exceeding the performance of a pure reinforcement learning policy by $\\sim$170%, only from sketch inputs. This makes robotic manipulation learning more accessible and potentially broadens its applications across various domains.", "title_embedding_index": 10611, "title_abs_embedding_index": 10636}, {"title": "How efficient is LLM-generated code? A rigorous & high-standard benchmark", "link_suffix": "/forum?id=suz4utPr9Y", "link": "https://openreview.net/forum?id=suz4utPr9Y", "pdf_link": "https://openreview.net/pdf?id=suz4utPr9Y", "keywords": "Large Language Model, Code Generation, Efficiency Evaluation", "abstract": "The emergence of large language models (LLMs) has significantly pushed the frontiers of program synthesis. Advancement of LLM-based program synthesis calls for a thorough evaluation of LLM-generated code. Most evaluation frameworks focus on the (functional) correctness of generated code; efficiency, as an important measure of code quality, has been overlooked in existing evaluations. In this work, we develop ENAMEL (EfficeNcy AutoMatic EvaLuator), a rigorous and high-standard benchmark for evaluating the capability of LLMs in generating efficient code. Firstly, we propose a new efficiency metric called eff@k, which generalizes the pass@k metric from correctness to efficiency and appropriately handles right-censored execution time. Furthermore, we derive an unbiased and variance-reduced estimator of eff@k via Rao\u2013Blackwellization; we also provide a numerically stable implementation for the new estimator. Secondly, to set a high-standard for efficiency evaluation, we employ a human expert to design best algorithms and implementations as our reference solutions of efficiency, many of which are much more efficient than existing canonical solutions in HumanEval and HumanEval+. Moreover, to ensure a rigorous evaluation, we employ a human expert to curate strong test case generators to filter out wrong code and differentiate suboptimal algorithms. An extensive study across 30 popular LLMs using our benchmark ENAMEL shows that LLMs still fall short of generating expert-level efficient code. Using two subsets of our problem set, we demonstrate that such deficiency is because current LLMs struggle in designing advanced algorithms and are barely aware of implementation optimization.", "title_embedding_index": 10612, "title_abs_embedding_index": 10637}, {"title": "Measuring Diversity: Axioms and Challenges", "link_suffix": "/forum?id=lBOvXyzQis", "link": "https://openreview.net/forum?id=lBOvXyzQis", "pdf_link": "https://openreview.net/pdf?id=lBOvXyzQis", "keywords": "diversity measure, desirable properties, axiomatic approach", "abstract": "The concept of diversity is widely used in various applications: from image or molecule generation to recommender systems. Thus, being able to properly measure diversity is important. This paper addresses the problem of evaluating diversity for a set of objects. First, we make a systematic review of existing diversity measures and explore their undesirable behavior in some cases. Based on this review, we formulate three desirable properties (axioms) of a reliable diversity measure: monotonicity, uniqueness, and continuity. We show that none of the existing diversity measures has all three properties and thus these measures are not suitable for quantifying diversity. Then, we construct two examples of measures that have all the desirable properties, thus proving that the list of axioms is not self-contradicting. Unfortunately, the constructed examples are too computationally complex for practical use, thus we pose an open problem of constructing a diversity measure that has all the listed properties and can be computed in practice.", "title_embedding_index": 10613, "title_abs_embedding_index": 10638}, {"title": "Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning", "link_suffix": "/forum?id=Pd3jVGTacT", "link": "https://openreview.net/forum?id=Pd3jVGTacT", "pdf_link": "https://openreview.net/pdf?id=Pd3jVGTacT", "keywords": "Unlearning, Large language model, Preference optimization", "abstract": "In this work, we address the problem of large language model (LLM) unlearning, aiming to remove unwanted data influences and associated model capabilities e.g., copyrighted data or harmful content generation) while preserving essential model utilities, without the need for retraining from scratch. Despite the growing need for LLM unlearning, a principled optimization framework remains lacking. To this end, we revisit the state-of-the-art approach, negative preference optimization (NPO), and identify the issue of reference model bias, which could undermine NPO's effectiveness, particularly when unlearning forget data of varying difficulty.  Given that, we propose a simple yet effective unlearning optimization framework, called SimNPO, showing that  `simplicity' in removing the reliance on a reference model (through the lens of simple preference optimization) benefits unlearning. We also provide deeper insights into SimNPO's advantages, supported by analysis using mixtures of Markov chains. Furthermore, we present extensive experiments validating    SimNPO's superiority over existing unlearning baselines in benchmarks like TOFU and MUSE, and robustness against relearning  attacks.", "title_embedding_index": 10614, "title_abs_embedding_index": 10639}, {"title": "Pruning Deep Convolutional Neural Network Using Conditional Mutual Information", "link_suffix": "/forum?id=N0vzm0vwyR", "link": "https://openreview.net/forum?id=N0vzm0vwyR", "pdf_link": "https://openreview.net/pdf?id=N0vzm0vwyR", "keywords": "CNN, pruning, optimization, mutual information, Renyi entropy", "abstract": "Convolutional Neural Networks (CNNs) achieve high performance in image classification tasks but are challenging to deploy on resource-limited hardware due to their large model sizes. To address this issue, we leverage Mutual Information, a metric that provides valuable insights into how deep learning models retain and process information by measuring the shared information between input features or output labels and network layers. In this study, we propose a structured filter-pruning approach for CNNs that identifies and selectively retains the most informative features in each layer. Our approach successively evaluates each layer by ranking the importance of its feature maps based on Conditional Mutual Information (CMI) values, computed using a matrix-based R\u00e9nyi \u03b1-order entropy numerical method. We propose several formulations of CMI to capture correlation among features across different layers. We then develop various strategies to determine the cutoff point for CMI values to prune unimportant features. This approach allows parallel pruning in both forward and backward directions and significantly reduces model size while preserving accuracy. Tested on the VGG16 architecture with the CIFAR-10 dataset, the proposed method reduces the number of filters by more than a third, with only a 0.32% drop in test accuracy.", "title_embedding_index": 10615, "title_abs_embedding_index": 10640}, {"title": "DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations", "link_suffix": "/forum?id=tkqNDbukWW", "link": "https://openreview.net/forum?id=tkqNDbukWW", "pdf_link": "https://openreview.net/pdf?id=tkqNDbukWW", "keywords": "Large Language Models, Hallucination, Constrained Decoding, Retrieval Heads", "abstract": "Large Language Models (LLMs) often hallucinate, producing unfaithful or factually incorrect outputs by misrepresenting the provided context or incorrectly recalling internal knowledge. Recent studies have identified specific attention heads within the Transformer architecture, known as retrieval heads, responsible for extracting relevant contextual information. We hypothesise that masking these retrieval heads can induce hallucinations and that contrasting the outputs of the base LLM and the masked LLM can reduce hallucinations. To this end, we propose Decoding by Contrasting Retrieval Heads (DeCoRe), a novel training-free decoding strategy that amplifies information found in the context and model parameters. DeCoRe mitigates potentially hallucinated responses by dynamically contrasting the outputs of the base LLM and the masked LLM, using conditional entropy as a guide. Our extensive experiments confirm that DeCoRe significantly improves performance on tasks requiring high contextual faithfulness, such as summarisation (XSum by 18.6%), instruction following (MemoTrap by 10.9%), and open-book question answering (NQ by 2.4% and NQ-Swap by 5.5%).", "title_embedding_index": 10616, "title_abs_embedding_index": 10641}, {"title": "Topological Zigzag Spaghetti for Diffusion-based Generation and Prediction on Graphs", "link_suffix": "/forum?id=mYgoNEsUDi", "link": "https://openreview.net/forum?id=mYgoNEsUDi", "pdf_link": "https://openreview.net/pdf?id=mYgoNEsUDi", "keywords": "Graph learning, Topological Data Analysis, Geometric Deep Learning", "abstract": "Diffusion models have recently emerged as a new powerful machinery for generative artificial intelligence on graphs, with applications ranging from drug design to knowledge discovery. However, despite their high potential, most, if not all, currently existing graph diffusion models are limited in their ability to holistically describe the intrinsic {\\it higher-order} topological graph properties, which obstructs model generalizability and adoption for downstream tasks. We propose to address this fundamental challenge and extract the latent salient topological graph descriptors at different resolutions by leveraging zigzag persistence. We develop a new computationally efficient topological summary, zigzag spaghetti (ZS), which delivers the most inherent topological properties {\\it simultaneously over a sequence of graphs at multiple resolutions}. We derive theoretical stability guarantees of ZS and present the first attempt to integrate\ndynamic topological information into graph diffusion models. Our extensive experiments on %9 benchmark datasets for \ngraph classification and prediction tasks suggest that ZS has a high promise not only to enhance performance of graph diffusion models, with gains up 10%, but also to substantially booster model robustness under uncertainties.", "title_embedding_index": 10617, "title_abs_embedding_index": 10642}, {"title": "A Dynamic Low-Rank Fast Gaussian Transform", "link_suffix": "/forum?id=RtfXKkIJP1", "link": "https://openreview.net/forum?id=RtfXKkIJP1", "pdf_link": "https://openreview.net/pdf?id=RtfXKkIJP1", "keywords": "Fast Gaussian Transform, Kernel density estimation, Dynamic data structure", "abstract": "The Fast Gaussian Transform (FGT) enables subquadratic-time multiplication of an $n\\times n$ Gaussian kernel matrix $\\mathsf{K}_{i,j}= \\exp ( -  || x_i - x_j ||_2^2 ) $ with an arbitrary vector $h \\in \\mathbb{R}^n$, where $x_1,\\dots, x_n \\in \\mathbb{R}^d$ are a set of fixed source points. This kernel plays a central role in machine learning and random feature maps. Nevertheless, in most modern data analysis applications, datasets are dynamically changing (yet often have low rank), and recomputing the FGT from scratch in (kernel-based) algorithms incurs a major computational overhead ($\\gtrsim n$ time for a single source update $\\in \\mathbb{R}^d$). These applications motivate a dynamic FGT algorithm, which maintains a dynamic set of sources under kernel-density estimation (KDE) queries in sublinear time while retaining Mat-Vec multiplication accuracy and speed.Assuming the dynamic data-points $x_i$ lie in a (possibly changing) $k$-dimensional subspace ($k\\leq d$), our main result is an efficient dynamic FGT algorithm, supporting the following operations in $\\log^{O(k)}(n/\\varepsilon)$ time: (1) Adding or deleting a source point, and (2) Estimating the kernel-density of a query point with respect to sources with $\\varepsilon$ additive accuracy. The core of the algorithm is a dynamic data structure for maintaining the projected ``interaction rank'' between source and target boxes, decoupled into finite truncation of Taylor and Hermite expansions.", "title_embedding_index": 10618, "title_abs_embedding_index": 10643}, {"title": "Model Equality Testing: Which Model is this API Serving?", "link_suffix": "/forum?id=QCDdI7X3f9", "link": "https://openreview.net/forum?id=QCDdI7X3f9", "pdf_link": "https://openreview.net/pdf?id=QCDdI7X3f9", "keywords": "API monitoring, model shift, two-sample testing", "abstract": "Users often interact with large language models through black-box inference APIs, both for closed- and open-weight models (e.g., Llama models are popularly accessed via Amazon Bedrock and Azure AI Studio). In order to cut costs or add functionality, API providers may quantize, watermark, or finetune the underlying model, changing the output distribution --- often without notifying users. We formalize detecting such distortions as Model Equality Testing, a two-sample testing problem, where the user collects samples from the API and a reference distribution and conducts a statistical test to see if the two distributions are the same. We find that tests based on the Maximum Mean Discrepancy between distributions are powerful for this task: a test built on a simple string kernel achieves a median of 77.4% power against a range of distortions, using an average of just 10 samples per prompt. We then apply this test to commercial inference APIs for four Llama models, finding that 11 out of 31 endpoints serve different distributions than reference weights released by Meta.", "title_embedding_index": 10619, "title_abs_embedding_index": 10644}, {"title": "XiEff Representation for Near-Field Optics", "link_suffix": "/forum?id=niDo8UYcEs", "link": "https://openreview.net/forum?id=niDo8UYcEs", "pdf_link": "https://openreview.net/pdf?id=niDo8UYcEs", "keywords": "neural fields, PINNs, near-field optics", "abstract": "Near-field optics, or near-field electrodynamics, is a field that studies the interaction between materials and light at spatial scales smaller than the wavelength. At these extremely small scales, below the diffraction limit, the interaction between materials and electromagnetic fields can exhibit unique behaviors and properties not observed in conventional optics. This area of research is crucial for understanding the optical characteristics of nanotechnical systems and nanoscale biological objects. One of the primary tools used in near-field optics research is scanning near-field optical microscopy (SNOM), which allows researchers to measure near-field optical images (NFI). However, these images often lack visual clarity and interpretability, hindering a comprehensive understanding of the properties of the probed particles.The main goal of this paper is to introduce a novel approach that addresses these challenges. Inspired by the prominent progress in Neural Radiance Fields (NeRFs) from computer vision and ideas from physics-informed neural networks (PINNs). We propose an unsupervised method that introduces the XiEff representation \u2013 a neural field-based reparameterization of the effective susceptibility tensor. By integrating XiEff into the Lippmann-Schwinger integral equation framework for near-field optics we develop an optimization strategy to reconstruct the effective susceptibility distribution directly from NFI data.The optimized XiEff representation provides an interpretable and explainable model of the particle's shape. Extensive evaluations on a synthetically generated NFI dataset demonstrate the effectiveness of the method, achieving high intersection-over-union scores between XiEff and ground truth shapes, even for complex geometries. Furthermore, the approach exhibits desirable robustness to measurement noise, a crucial property for practical applications. The XiEff representation, combined with the proposed optimization framework, potentially introduces a valuable tool for enabling explainable near-field optics imaging and enhancing the understanding of particle characteristics through interpretable representations", "title_embedding_index": 10620, "title_abs_embedding_index": 10645}, {"title": "C-MELT: Contrastive Enhanced Masked Auto-Encoders for ECG-Language Pre-Training", "link_suffix": "/forum?id=5fS03oP3q6", "link": "https://openreview.net/forum?id=5fS03oP3q6", "pdf_link": "https://openreview.net/pdf?id=5fS03oP3q6", "keywords": "Multi-modal Representation Learning, Contrastive Masked Auto-Encoders, ECG-Text Pre-Training", "abstract": "Accurate interpretation of Electrocardiogram (ECG) signals is pivotal for diagnosing cardiovascular diseases. Integrating ECG signals with their accompanying textual reports holds immense potential to enhance clinical diagnostics through the combination of physiological data and qualitative insights. However, this integration faces significant challenges due to inherent modality disparities and the scarcity of labeled data for robust cross-modal learning. To address these obstacles, we propose C-MELT, a novel framework that pre-trains ECG and text data using a contrastive masked auto-encoder architecture. C-MELT uniquely combines the strengths of generative with enhanced discriminative capabilities to achieve robust cross-modal representations. This is accomplished through masked modality modeling, specialized loss functions, and an improved negative sampling strategy tailored for cross-modal alignment. Extensive experiments on five public datasets across diverse downstream tasks demonstrate that C-MELT significantly outperforms existing methods, achieving 15% and 2% increases in linear probing and zero-shot performance over state-of-the-art models, respectively. These results highlight the effectiveness of C-MELT, underscoring its potential to advance automated clinical diagnostics through multi-modal representations.", "title_embedding_index": 10621, "title_abs_embedding_index": 10646}, {"title": "Mitigating Graph Covariate Shift via Score-based Out-of-distribution Augmentation", "link_suffix": "/forum?id=gStRS8L28g", "link": "https://openreview.net/forum?id=gStRS8L28g", "pdf_link": "https://openreview.net/pdf?id=gStRS8L28g", "keywords": "Graph Neural Network, Graph Data Augmentation, Distribution Shift", "abstract": "Distribution shifts between training and testing datasets significantly impair the model performance on graph learning. A commonly-taken causal view in graph invariant learning suggests that stable features of graphs are causally associated with labels, whereas unstable environmental features lead to distribution shifts. In particular, covariate shifts caused by unseen environmental features in test graphs underscore the critical need for out-of-distribution (OOD) generalization. Existing graph augmentation methods designed to address the covariate shift often disentangle the stable and environmental features in the input space, and  selectively perturb or mixup the environmental features. However, such perturbation-based methods heavily rely on an accurate separation of stable and environmental features, and their exploration ability is confined to existing environmental features in the training distribution. To overcome these limitations, we introduce a novel approach using score-based graph generation strategies that synthesize unseen environmental features while preserving the validity and stable features of overall graph patterns. Our comprehensive empirical evaluations demonstrate the enhanced effectiveness of our method in improving graph OOD generalization.", "title_embedding_index": 10622, "title_abs_embedding_index": 10647}, {"title": "Learning Structured Representations by Embedding Class Hierarchy with Fast Optimal Transport", "link_suffix": "/forum?id=AnL6BuWzxa", "link": "https://openreview.net/forum?id=AnL6BuWzxa", "pdf_link": "https://openreview.net/pdf?id=AnL6BuWzxa", "keywords": "hierarchical representation, representation learning, optimal transport", "abstract": "To embed structured knowledge within labels into feature representations, prior work (Zeng et al., 2022) proposed to use the Cophenetic Correlation Coefficient (CPCC) as a regularizer during supervised learning. This regularizer calculates pairwise Euclidean distances of class means and aligns them with the corresponding shortest path distances derived from the label hierarchy tree. However, class means may not be good representatives of the class conditional distributions, especially when they are multi-mode in nature. To address this limitation, under the CPCC framework, we propose to use the Earth Mover's Distance (EMD) to measure the pairwise distances among classes in the feature space. We show that our exact EMD method generalizes previous work, and recovers the existing algorithm when class-conditional distributions are Gaussian in the feature space. To further improve the computational efficiency of our method, we introduce the Optimal Transport-CPCC family by exploring four EMD approximation variants. Our most efficient OT-CPCC variant runs in linear time in the size of the dataset, while maintaining competitive performance across datasets and tasks.", "title_embedding_index": 10623, "title_abs_embedding_index": 10648}, {"title": "Latent Diffusion Planning for Imitation Learning", "link_suffix": "/forum?id=k1qVBh5fnb", "link": "https://openreview.net/forum?id=k1qVBh5fnb", "pdf_link": "https://openreview.net/pdf?id=k1qVBh5fnb", "keywords": "imitation learning, diffusion, planning, robotics", "abstract": "Recent progress in robotic imitation learning has been enabled by policy architectures that scale to complex visuomotor tasks, multimodal distributions, and large datasets. However, these methods rely on supervised learning of actions from expert demonstrations, which can be challenging to scale. We propose Latent Diffusion Planning, which forecasts future states as well as actions via diffusion. This objective can scalably leverage heterogeneous data sources and provides a denser supervision signal for learning. To plan over images, we learn a compact latent space through a variational autoencoder. We then train a planner to forecast future latent states, and an inverse dynamics model to extract actions from the plans. As planning is separated from action prediction, LDP can leverage suboptimal or action-free data to improve performance in low demonstration regimes. On simulated visual robotic manipulation tasks, LDP outperforms state-of-the-art imitation learning approaches as they cannot leverage such additional data.", "title_embedding_index": 10624, "title_abs_embedding_index": 10649}]
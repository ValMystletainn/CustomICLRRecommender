[
    {
        "title": "Invariant Graphon Networks: Approximation and Cut Distance",
        "link_suffix": "/forum?id=SjufxrSOYd",
        "link": "https://openreview.net/forum?id=SjufxrSOYd",
        "pdf_link": "https://openreview.net/pdf?id=SjufxrSOYd",
        "keywords": "Graph neural networks, invariant graph networks, universal approximation, graph limits, graphons, transferability, homomorphism densities, machine learning theory.",
        "abstract": "Graph limit models, like graphons for limits of dense graphs, have recently been used as a tool to study size transferability of graph neural networks (GNNs). While most existing literature focuses on message passing GNNs (MPNNs), we attend to Invariant Graph Networks (IGNs), a powerful alternative GNN architecture. In this work, we generalize IGNs to graphons, introducing Invariant Graphon Networks (IWNs) which are defined using a subset of the IGN basis corresponding to bounded linear operators. Even with this restricted basis, we show that IWNs of order $k+1$ are at least as powerful as the $k$-dimensional Weisfeiler-Leman test for graphons. Furthermore, we establish universal approximation results for graphon-signals in $\\mathcal{L}^p$ distances using a novel extension of homomorphism densities. This significantly extends the prior work of Cai & Wang (2022), showing that IWNs---a subset of their IGN-small---retain effectively the same expressivity as the full IGN basis in the limit, while benefiting from better convergence properties. In contrast to their approach, our blueprint of IWNs also aligns better with the geometry of graphon space, for example facilitating comparability to MPNNs. As a key limitation, we highlight that unlike other GNN architectures such as MPNNs, IWNs are discontinuous with respect to cut distance and, thus, have fundamentally different and generally less favorable transferability properties."
    },
    {
        "title": "MMMT-IF: A Challenging Multimodal Multi-Turn Instruction Following Benchmark",
        "link_suffix": "/forum?id=ic153qXFfx",
        "link": "https://openreview.net/forum?id=ic153qXFfx",
        "pdf_link": "https://openreview.net/pdf?id=ic153qXFfx",
        "keywords": "Large Language Models, Foundation Models, Instruction Following, Program Verifiable Instructions, Multimodal, AI, Long Context",
        "abstract": "Evaluating instruction following capabilities for multimodal, multi-turn dialogue is challenging. With potentially multiple instructions in the input model context, the task is time-consuming for human raters and we show LLM based judges are biased towards answers from the same model. \nWe propose MMMT-IF, an image based multi-turn Q&A evaluation set with added global instructions between questions, constraining the answer format.\nThis challenges models to retrieve instructions dispersed across long dialogues and reason under instruction constraints.\nAll instructions are objectively verifiable through code execution.\nWe introduce the Programmatic Instruction Following ($\\operatorname{PIF}$) metric to measure the fraction of the instructions that are correctly followed while performing a reasoning task.\nThe $\\operatorname{PIF-N-K}$ set of metrics further evaluates robustness by measuring the fraction of samples in a corpus where, for each sample, at least K out of N generated model responses achieve a $\\operatorname{PIF}$ score of one.\nThe $\\operatorname{PIF}$ metric aligns with human instruction following ratings, showing 60 percent correlation.\nExperiments show Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet, have a $\\operatorname{PIF}$ metric that drops from 0.81 on average at turn 1 across the models, to 0.64 at turn 20.\nAcross all turns, when each response is repeated 4 times ($\\operatorname{PIF-4-4}$), GPT-4o and Gemini successfully follow all instructions only 11% of the time.\nWhen all the instructions are also appended to the end of the model input context, the $\\operatorname{PIF}$ metric improves by 22.3 points on average, showing that the challenge with the task lies not only in following the instructions, but also in retrieving the instructions spread out in the model context. \nWe plan to open source the MMMT-IF dataset and metric computation code."
    },
    {
        "title": "Understanding Reasoning in Chain-of-Thought from the Hopfieldian View",
        "link_suffix": "/forum?id=OclSRDktp3",
        "link": "https://openreview.net/forum?id=OclSRDktp3",
        "pdf_link": "https://openreview.net/pdf?id=OclSRDktp3",
        "keywords": "Interpretability, Chain-of-thought",
        "abstract": "Large Language Models have demonstrated remarkable abilities across various tasks, with Chain-of-Thought (CoT) prompting emerging as a key technique to enhance reasoning capabilities. However, existing research primarily focuses on improving performance, lacking a comprehensive framework to explain and understand the fundamental factors behind CoT's success. To bridge this gap, we introduce a novel perspective grounded in the Hopfieldian view of cognition in cognitive neuroscience. We establish a connection between CoT reasoning and key cognitive elements such as stimuli, actions, neural populations, and representation spaces. From our view, we can understand the reasoning process as the movement between these representation spaces. Building on this insight, we develop a method for localizing reasoning errors in the response of CoTs. Moreover, we propose the Representation-of-Thought (RoT) framework, which leverages the robustness of low-dimensional representation spaces to enhance the robustness of the reasoning process in CoTs. Experimental results demonstrate that RoT improves the robustness and interpretability of CoT reasoning while offering fine-grained control over the reasoning process."
    },
    {
        "title": "Towards General-Purpose Model-Free Reinforcement Learning",
        "link_suffix": "/forum?id=R1hIXdST22",
        "link": "https://openreview.net/forum?id=R1hIXdST22",
        "pdf_link": "https://openreview.net/pdf?id=R1hIXdST22",
        "keywords": "Deep reinforcement learning, model-free, generalist",
        "abstract": "Reinforcement learning (RL) promises a framework for near-universal problem-solving. In practice however, RL algorithms are often tailored to specific benchmarks, relying on carefully tuned hyperparameters and algorithmic choices. Recently, powerful model-based RL methods have shown impressive generalist results across benchmarks but come at the cost of increased complexity and slow run times, limiting their broader applicability. In this paper, we attempt to find a unifying model-free deep RL algorithm that can address a diverse class of domains and problem settings. To achieve this, we leverage model-based representations that approximately linearize the value function, taking advantage of the denser task objectives used by model-based RL while avoiding the costs associated with planning or simulated trajectories. We evaluate the resulting algorithm on a variety of common RL benchmarks with a single set of hyperparameters and show a competitive performance against domain-specific and generalist baselines, providing a concrete step towards building general-purpose model-free deep RL algorithms."
    },
    {
        "title": "Deviation Ratings: A general, clone invariant rating method",
        "link_suffix": "/forum?id=KS4G94XBo7",
        "link": "https://openreview.net/forum?id=KS4G94XBo7",
        "pdf_link": "https://openreview.net/pdf?id=KS4G94XBo7",
        "keywords": "rating, ranking, coarse correlated equilibria, Nash equilibria, game theory, equilibria, LLM leaderboard, normal-form game",
        "abstract": "Many real-world multi-agent or multi-task evaluation scenarios can be naturally modelled as normal-form games, due to inherent strategic (adversarial, cooperative, and mixed motive) interactions. These strategic interactions may be agentic (e.g. players trying to win), fundamental (e.g. cost vs quality), or complimentary (e.g. niche finding and specialization). In such a formulation, it is the strategies (actions, policies, agents, models, tasks, prompts, etc.) that are rated. However, the rating problem is complicated by redundancy and complexity of N-player strategic interactions. Repeated or similar strategies can distort ratings for those that counter or complement them. Previous work proposed ``clone-invariant'' ratings to handle such redundancies, but this was limited to two-player zero-sum (i.e. strictly competitive) interactions. This paper introduces a clone-invariant rating applicable to all N-player general-sum interactions."
    },
    {
        "title": "On Explaining Equivariant Graph Networks via Improved Relevance Propagation",
        "link_suffix": "/forum?id=YkMg8sB8AH",
        "link": "https://openreview.net/forum?id=YkMg8sB8AH",
        "pdf_link": "https://openreview.net/pdf?id=YkMg8sB8AH",
        "keywords": "Explainability, Equivariant Graph Networks",
        "abstract": "We consider explainability in equivariant graph neural networks for 3D geometric graphs. While many XAI methods have been developed for analyzing graph neural networks, they predominantly target 2D graph structures. The complex nature of 3D data and the sophisticated architectures of equivariant GNNs present unique challenges. Current XAI techniques either struggle to adapt to equivariant GNNs or fail to effectively handle positional data and evaluate the significance of geometric features adequately. To address these challenges, we introduce a novel method, known as EquiGX, which uses the Deep Taylor decomposition framework to extend the layer-wise relevance propagation rules tailored for spherical equivariant GNNs. Our approach decomposes prediction scores and back-propagates the relevance scores through each layer to the input space. Our decomposition rules provide a detailed explanation of each layer\u2019s contribution to the network\u2019s predictions, thereby enhancing our understanding of how geometric and positional data influence the model\u2019s outputs. Through experiments on both synthetic and real-world datasets, our method demonstrates its capability to identify critical geometric structures and outperform alternative baselines. These results indicate that our method provides significantly enhanced explanations for equivariant GNNs."
    },
    {
        "title": "Quantifying Past Error Matters: Conformal Inference for Time Series",
        "link_suffix": "/forum?id=RD9q5vEe1Q",
        "link": "https://openreview.net/forum?id=RD9q5vEe1Q",
        "pdf_link": "https://openreview.net/pdf?id=RD9q5vEe1Q",
        "keywords": "Time Series; Uncertainty Quantification; Conformal Prediction; Distribution Shift",
        "abstract": "Uncertainty quantification in time series prediction is challenging due to the temporal dependence and distribution shift on sequential data. Conformal prediction provides a pivotal and flexible instrument for assessing the uncertainty of machine learning models through prediction sets. Recently, a series of online conformal inference methods updated thresholds of prediction sets by performing online gradient descent on a sequence of quantile loss functions. A drawback of such methods is that they only use the information of revealed non-conformity scores via miscoverage indicators but ignore error quantification, namely the distance between the non-conformity score and the current threshold. To accurately leverage the dynamic of miscoverage error, we propose Error-quantified Conformal Inference (ECI) by smoothing the quantile loss function. ECI introduces a continuous and adaptive feedback scale with the miscoverage error, rather than simple binary feedback in existing methods. We establish a long-term coverage guarantee for ECI under arbitrary dependence and distribution shift. The extensive experimental results show that ECI can achieve valid miscoverage control and output tighter prediction sets than other baselines."
    },
    {
        "title": "Retrieval Or Holistic Understanding? Dolce: Differentiate Our Long Context Evaluation Tasks",
        "link_suffix": "/forum?id=IQCwmB63Fd",
        "link": "https://openreview.net/forum?id=IQCwmB63Fd",
        "pdf_link": "https://openreview.net/pdf?id=IQCwmB63Fd",
        "keywords": "long context, benchmark, holistic understanding",
        "abstract": "We argue that there are two major distinct capabilities in long context understanding: retrieval and holistic understanding. Understanding and further improving LLMs' long context capabilities would not be possible without knowing the tasks' focus categories. We aim to automatically identify retrieval focused and holistic understanding focused problems from suites of benchmarks and quantitatively measure the difficulty within each focus. In this paper, we present the Dolce framework, which parameterizes each problem by $\\lambda$ (complexity) and $k$ (redundancy) and assigns to one of five predefined focus categories. We propose to sample short contexts from the full context and estimate the probability an LLM solves the problem using the sampled spans. To find the $\\lambda$ and $k$ for each problem, we further propose a mixture model of a non-parametric background noise component and a parametric/non-parametric hybrid oracle component, where we derive the probability functions parameterized by \u03bb and k for both the correct-or-wrong (COW) scenario and the partial-point-in-grading (PIG) scenario. Our proposed methods can identify 0% to 67% of the problems are retrieval focused and 0% to 90% of the problems are holistic understanding focused across 44 existing long context evaluation tasks."
    },
    {
        "title": "Agent-E: From Autonomous Web Navigation to Foundational Design Principles in Agentic Systems",
        "link_suffix": "/forum?id=7PQnFTbizU",
        "link": "https://openreview.net/forum?id=7PQnFTbizU",
        "pdf_link": "https://openreview.net/pdf?id=7PQnFTbizU",
        "keywords": "Web Automation, Autonomous Agents, Self-Improvement, Hierarchical Architecture",
        "abstract": "Web agents that can automate complex and monotonous tasks are becoming essential in streamlining workflows. Due to the difficulty of long-horizon planning, abundant state spaces in websites, and their cryptic observation space (i.e. DOMs), current web agents are still far from human-level performance. In this paper, we present a novel web agent, Agent-E \\footnote. This agentic system introduces several architectural improvements over prior state-of-the-art web agents, such as hierarchical architecture, self-refinement, flexible DOM distillation and denoising method, and \\textit{change observation} to guide the agent towards more accurate performance. Our Agent-E system without self-refinement achieves SOTA results on the WebVoyager benchmark, beating prior text-only benchmarks by over 20.5% and multimodal agents by over 16%. Our results indicate that adding a self-refinement mechanism can provide an additional 5.9% improvement on the Agent-E system without self-refinement. We then synthesize our learnings into general design principles for developing agentic systems. These include the use of domain-specific primitive skills, the importance of distillation and de-noising of complex environmental observations, and the advantages of a hierarchical architecture."
    },
    {
        "title": "Compressed Decentralized Learning with Error-Feedback under Data Heterogeneity",
        "link_suffix": "/forum?id=zqXANcFO9T",
        "link": "https://openreview.net/forum?id=zqXANcFO9T",
        "pdf_link": "https://openreview.net/pdf?id=zqXANcFO9T",
        "keywords": "distributed training, error-feedback, convergence analysis",
        "abstract": "Decentralized learning distributes the training process across multiple nodes, enabling collaborative model training without relying on a central server. Each node performs local training using its own data, with model updates exchanged directly between connected nodes within a given network topology. Various algorithms have been developed within this decentralized learning framework and have been proven to converge under specific assumptions. However, two key challenges remain: 1) ensuring robust performance with both a high degree of gradient compression and data heterogeneity, and 2) providing a general convergence upper bound under commonly used assumptions. To address these challenges, we propose theDiscounted Error-Feedback Decentralized Parallel Stochastic Gradient Descent (DEFD-PSGD)algorithm, which efficiently manages both high levels of gradient compression and data heterogeneity, without sacrificing communication efficiency. The core idea is to introduce controllable residual error feedback that effectively balances the impact of gradient compression and data heterogeneity. Additionally, we develop novel proof techniques to derive a convergence upper bound under relaxed assumptions. Finally, we present experimental results demonstrating that DEFD-PSGD outperforms other state-of-the-art decentralized learning algorithms, particularly in scenarios involving high compression and significant data heterogeneity."
    },
    {
        "title": "Multi-Field Adaptive Retrieval",
        "link_suffix": "/forum?id=3PDklqqqfN",
        "link": "https://openreview.net/forum?id=3PDklqqqfN",
        "pdf_link": "https://openreview.net/pdf?id=3PDklqqqfN",
        "keywords": "information retrieval, hybrid retrievers, structured data",
        "abstract": "Document retrieval for tasks such as search and retrieval-augmented generation typically involves datasets that areunstructured: free-form text without explicit internal structure in each document. However, documents can have a structured form, consisting of fields such as an article title, message body, or HTML header. To address this gap, we introduce Multi-Field Adaptive Retrieval (mFAR), a flexible framework that accommodates any number of and any type of document indices onstructureddata. Our framework consists of two main steps: (1) the decomposition of an existing document into fields, each indexed independently through dense and lexical methods, and (2) learning a model which adaptively predicts the importance of a field by conditioning on the document query, allowing on-the-fly weighing of the most likely field(s). We find that our approach allows for the optimized use of dense versus lexical representations across field types, significantly improves in document ranking over a number of existing retrievers, and achieves state-of-the-art performance for multi-field structured data."
    },
    {
        "title": "Bayesian Neighborhood Adaptation for Graph Neural Networks",
        "link_suffix": "/forum?id=Khv74gSZjg",
        "link": "https://openreview.net/forum?id=Khv74gSZjg",
        "pdf_link": "https://openreview.net/pdf?id=Khv74gSZjg",
        "keywords": "Graph Neural Network, Bayesian Inference",
        "abstract": "The neighborhood scope (i.e., number of hops) where graph neural networks (GNNs) aggregate information to characterize a node's statistical property is critical to GNNs' performance. Two-stage approaches, training and validating GNNs for every pre-specified neighborhood scope to search for the best setting, is a daunting and time-consuming task and tends to be biased due to the search space design. How to adaptively determine proper neighborhood scopes for the aggregation process for both homophilic and heterophilic graphs remains largely unexplored. We thus propose to model the GNNs' message-passing behavior on a graph as a stochastic process by treating the number of hops as a beta process. This Bayesian framework allows us to infer the most plausible neighborhood scope for messsage aggregation simultaneously with the optimization of GNN parameters. Our theoretical analysis show the scope inference improves the expressivity of GNN models. Experiments on benchmark homophilic and heterophilic datasets show that the proposed method is compatible with state-of-the-art GNN variants, improving their performance and providing well-calibrated predictions."
    },
    {
        "title": "Fengbo: a Clifford Neural Operator pipeline for 3D PDEs in Computational Fluid Dynamics",
        "link_suffix": "/forum?id=VsxbWTDHjh",
        "link": "https://openreview.net/forum?id=VsxbWTDHjh",
        "pdf_link": "https://openreview.net/pdf?id=VsxbWTDHjh",
        "keywords": "Clifford Algebra, Neural Operator, PDE Modelling, Geometric Machine Learning",
        "abstract": "We introduce Fengbo, a pipeline entirely in Clifford Algebra to solve 3D partial differential equations (PDEs) specifically for computational fluid dynamics (CFD). Fengbo is an architecture composed of only 3D convolutional and Fourier Neural Operator (FNO) layers, all working in 3D Clifford Algebra. It models the PDE solution problem as an interpretable mapping from the geometry to the physics of the problem. Despite having just few layers, Fengbo achieves competitive accuracy, superior to 5 out of 6 proposed models reported in \\cite{li2024geometry} for the $\\emph{ShapeNet Car}$ dataset, and it does so with only 42 million trainable parameters, at a reduced computational complexity compared to graph-based methods, and estimating jointly pressure \\emph{and} velocity fields. In addition, the output of each layer in Fengbo can be clearly visualised as objects and physical quantities in 3D space, making it a whitebox model.By leveraging Clifford Algebra and establishing a direct mapping from the geometry to the physics of the PDEs, Fengbo provides an efficient, geometry- and physics-aware approach to solving complex PDEs."
    },
    {
        "title": "MolGene-E: Inverse Molecular Design to Modulate Single Cell Transcriptomics",
        "link_suffix": "/forum?id=FftPnwBb1z",
        "link": "https://openreview.net/forum?id=FftPnwBb1z",
        "pdf_link": "https://openreview.net/pdf?id=FftPnwBb1z",
        "keywords": "Systems Pharmacology, Drug Discovery, Phenotypic Screening, Generative AI, CLIP",
        "abstract": "Designing drugs that can restore a diseased cell to its healthy state is an emerging approach in systems pharmacology to address medical needs that conventional target-based drug discovery paradigms have failed to meet. Single-cell transcriptomics can comprehensively map the differences between diseased and healthy cellular states, making it a valuable technique for systems pharmacology. However, single-cell omics data is noisy, heterogeneous, scarce, and high-dimensional. As a result, no machine learning methods currently exist to use single-cell omics data to design new drug molecules. We have developed a new deep generative framework named MolGene-E that can tackle this challenge. MolGene-E combines two novel models: 1) a cross-modal model that can harmonize and denoise chemical-perturbed bulk and single-cell transcriptomics data, and 2) a contrastive learning-based generative model that can generate new molecules based on the transcriptomics data. MolGene-E consistently outperforms baseline methods in generating high-quality, hit-like molecules from gene expression profiles obtained from single-cell datasets and gene expressions induced by knocking out targets using CRISPR. This superior performance is demonstrated across diverse de novo molecule generation metrics,  which makes MolGene-E a potentially powerful new tool for drug discovery."
    },
    {
        "title": "MeshLRM: Large Reconstruction Model for High-Quality Meshes",
        "link_suffix": "/forum?id=R1rNN22IoP",
        "link": "https://openreview.net/forum?id=R1rNN22IoP",
        "pdf_link": "https://openreview.net/pdf?id=R1rNN22IoP",
        "keywords": "Sparse-view reconstruction, High-quality mesh, Large Reconstruction Models",
        "abstract": "We propose MeshLRM, a novel LRM-based approach that can reconstruct a high-quality mesh from merely four input images in less than one second. Different from previous large reconstruction models (LRMs) that focus on NeRF-based reconstruction, MeshLRM incorporates differentiable mesh extraction and rendering within the LRM framework. This allows for end-to-end mesh reconstruction by fine-tuning a pre-trained NeRF LRM with mesh rendering. Moreover, we improve the LRM architecture by simplifying several complex designs in previous LRMs. MeshLRM's NeRF initialization is sequentially trained with low- and high-resolution images; this new LRM training strategy enables significantly faster convergence and thereby leads to better quality with less compute. Our approach achieves state-of-the-art mesh reconstruction from sparse-view inputs and also allows for many downstream applications, including text-to-3D and single-image-to-3D generation."
    },
    {
        "title": "Attacking Audio Language Models with Best-of-N Jailbreaking",
        "link_suffix": "/forum?id=yougZBoUY3",
        "link": "https://openreview.net/forum?id=yougZBoUY3",
        "pdf_link": "https://openreview.net/pdf?id=yougZBoUY3",
        "keywords": "adversarial robustness, jailbreaks, audio language model, speech language model, multimodal, adversarial attack, audio jailbreak, safety, trustworthy, robustness",
        "abstract": "In this work, we investigate the susceptibility of Audio Language Models (ALMs) to audio-based jailbreaks and introduce Best-of-N (BoN) Jailbreaking, a black-box jailbreaking algorithm to extract harmful information from ALMs. To craft jailbreak inputs, our approach samples audio augmentations and applies them to malicious prompts. We repeat this process until we find a set of augmentations that elicits a harmful response from the target ALM. Empirically, we find that applying BoN with 7000 sampled augmentations achieves an attack success rate (ASR) of over 60% on all models tested, including the preview model for the released GPT-4o. Furthermore, we uncover power laws that accurately predict the ASR of BoN jailbreaking as a function of the number of samples. These power laws allow us to forecast the effectiveness of BoN jailbreaking as a function of the number of sampled augmentations over an order of magnitude. Finally, we show that BoN jailbreaking can be composed with other black-box attack algorithms for even more effective attacks\u2014combining BoN with an optimized prefix attack achieves 98% ASR on Gemini Pro and Flash. Overall, by exploiting stochastic sampling and sensitivity to variations in a high-dimensional input space, we propose a scalable, composable, and highly effective black-box algorithm for attacking state-of-the-art ALMs."
    },
    {
        "title": "Recurrent Drafter for Fast Speculative Decoding in Large Language Models",
        "link_suffix": "/forum?id=WpXq5n8yLb",
        "link": "https://openreview.net/forum?id=WpXq5n8yLb",
        "pdf_link": "https://openreview.net/pdf?id=WpXq5n8yLb",
        "keywords": "speculative decoding, beam search",
        "abstract": "We present Recurrent Drafter (ReDrafter), an advanced speculative decoding approach that achieves state-of-the-art speedup for large language models (LLMs) inference. The performance gains are driven by three key aspects: (1) leveraging a recurrent neural network (RNN) as the draft model conditioning on LLM's hidden states, (2) applying a dynamic tree attention algorithm over beam search results to eliminate duplicated prefixes in candidate sequences, and (3) training through knowledge distillation from the LLM. ReDrafter accelerates Vicuna inference in MT-Bench by up to 3.5x with a PyTorch implementation on Nvidia H100 GPUs. To demonstrate its practicality in production environments, we integrate ReDrafter into TensorRT-LLM, reaching up to 2.5x speedup on H100 GPUs. We also validated its effectiveness for on-device applications by implementing the approach in MLX and benchmarking performance on Metal GPUs in Apple Silicon chips, achieving up to 2.3x speedup."
    },
    {
        "title": "Advantage Alignment Algorithms",
        "link_suffix": "/forum?id=QFO1asgas2",
        "link": "https://openreview.net/forum?id=QFO1asgas2",
        "pdf_link": "https://openreview.net/pdf?id=QFO1asgas2",
        "keywords": "Multi-agent Reinforcement Learning, Opponent Shaping, Social Dilemmas, General-Sum Games",
        "abstract": "Artificially intelligent agents are increasingly being integrated into human decision-making: from large language model (LLM) assistants to autonomous vehicles. These systems often optimize their individual objective, leading to conflicts, particularly in general-sum games where naive reinforcement learning agents empirically converge to Pareto-suboptimal Nash equilibria. To address this issue, opponent shaping has emerged as a paradigm for finding socially beneficial equilibria in general-sum games. In this work, we introduce Advantage Alignment, a family of algorithms derived from first principles that perform opponent shaping efficiently and intuitively. We achieve this by aligning the advantages of interacting agents, increasing the probability of mutually beneficial actions when their interaction has been positive. We prove that existing opponent shaping methods implicitly perform Advantage Alignment. Compared to these methods, Advantage Alignment simplifies the mathematical formulation of opponent shaping, reduces the computational burden and extends to continuous action domains. We demonstrate the effectiveness of our algorithms across a range of social dilemmas, achieving state-of-the-art cooperation and robustness against exploitation."
    },
    {
        "title": "Leveraging Natural Frequency Deviation for Diffusion-Generated Image Detection",
        "link_suffix": "/forum?id=fPBExgC1m9",
        "link": "https://openreview.net/forum?id=fPBExgC1m9",
        "pdf_link": "https://openreview.net/pdf?id=fPBExgC1m9",
        "keywords": "frequency domain, filter banks, diffusion-generated image detection",
        "abstract": "Diffusion models have achieved remarkable success in image synthesis, but the generated high-quality images raise concerns about potential malicious use. Existing detectors often struggle to capture distinctive features across different training models, limiting their generalization to unseen diffusion models with varying schedulers and hyperparameters. To address this issue, we observe that diffusion-generated images exhibit progressively larger differences from real images across low- to high-frequency bands. Based on this insight, we propose a novel image representation called \\textbf{N}atural \\textbf{F}r\\textbf{e}quency \\textbf{De}viation~(\\textbf{DEFEND}). DEFEND applies a weighted filter to the Fourier spectrum, suppressing less discriminative bands while enhancing more informative ones. This approach, grounded in a comprehensive analysis of frequency-based differences between real and diffusion-generated images, enables robust detection of images from unseen diffusion models and provides resilience to various perturbations. Extensive experiments on diffusion-generated image datasets show that our method outperforms state-of-the-art detectors with superior generalization and robustness."
    },
    {
        "title": "Exploring QUIC Dynamics: A Large-Scale Dataset for Encrypted Traffic Analysis",
        "link_suffix": "/forum?id=XTXUHQqLbg",
        "link": "https://openreview.net/forum?id=XTXUHQqLbg",
        "pdf_link": "https://openreview.net/pdf?id=XTXUHQqLbg",
        "keywords": "Deep learning, image dataset derived from real-world QUIC traces, discrete regression problem, vision for communication",
        "abstract": "QUIC, a new and increasingly used transport protocol, addresses and resolves the limitations of TCP by offering improved security, performance, and features such as stream multiplexing and connection migration. These features, however, also present challenges for network operators who need to monitor and analyze web traffic. In this paper, we introduce VisQUIC, a labeled dataset comprising over 100,000 QUIC traces from more than 44,000 websites (URLs), collected over a four-month period. These traces provide the foundation for generating more than two million images, with configurable parameters of window length, pixel resolution, normalization, and labels. These images enable an observer looking at the interactions between a client and a server to analyze and gain insights about QUIC encrypted connections. To illustrate the dataset's potential, we offer a use-case example of an observer estimating the number of HTTP/3 responses/requests pairs in a given QUIC, which can reveal server behavior, client--server interactions, and the load imposed by an observed connection. We formulate the problem as a discrete regression problem, train a machine learning (ML) model for it, and then evaluate it using the proposed dataset on an example use case."
    },
    {
        "title": "E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning",
        "link_suffix": "/forum?id=tVfvKrboVY",
        "link": "https://openreview.net/forum?id=tVfvKrboVY",
        "pdf_link": "https://openreview.net/pdf?id=tVfvKrboVY",
        "keywords": "Long-Context Modeling, Large Language Models, Encoder, Decoder",
        "abstract": "In the realm of Large Language Models (LLMs), the ability to process long contexts is increasingly crucial for tasks such as multi-round dialogues, code generation, and document summarization. This paper addresses the challenges of achieving high long-context performance, low computational complexity, and compatibility with pretrained models -- collectively termed the ``impossible triangle''. We introduce E2LLM (Encoder Elongated Large Language Models), a novel approach that effectively navigates this paradox. The method involves splitting long contexts into chunks, compressing each into soft prompts via a pretrained text encoder, and utilizing an adapter to align these representations with a decoder-only LLM. To further enhance the LLM's understanding and reasoning capabilities regarding the soft prompts, we implement two training objectives: one focused on reconstructing the encoder output and the other on long-context instruction fine-tuning. Extensive experiments including Needle in a Haystack and LongBench reveal that E2LLM not only outperforms seven existing state-of-the-art (SOTA) methods across various long-context tasks, but also achieves the lowest inference time and memory usage. Code will be available upon publication."
    },
    {
        "title": "DO GENERATIVE MODELS LEARN RARE GENERATIVE FACTORS?",
        "link_suffix": "/forum?id=Eg32tDGgF5",
        "link": "https://openreview.net/forum?id=Eg32tDGgF5",
        "pdf_link": "https://openreview.net/pdf?id=Eg32tDGgF5",
        "keywords": "Representation Learning",
        "abstract": "Generative models are becoming a promising tool in AI alongside discriminative learning. Several models have been proposed to learn in an unsupervised fashion the corresponding generative factors, namely the latent variables critical for capturing the full spectrum of data variability. Diffusion Models (DMs), Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) are of particular interest due to their impressive ability to generate highly realistic data. Through a systematic empirical study, this paper delves into the intricate challenge of how DMs, GANs and VAEs internalize and replicate rare generative factors. Our findings reveal a pronounced tendency towards the memorization of these factors. We study the reasons for this memorization and demonstrate that strategies such as spectral decoupling can mitigate this issue to a certain extent."
    },
    {
        "title": "Improving Soft Unification with Knowledge Graph Embedding Methods",
        "link_suffix": "/forum?id=OOqvY9yvVG",
        "link": "https://openreview.net/forum?id=OOqvY9yvVG",
        "pdf_link": "https://openreview.net/pdf?id=OOqvY9yvVG",
        "keywords": "Neuro-Symbolic, Knowledge Graph Embedding",
        "abstract": "Neural Theorem Provers (NTPs) present a promising framework for neuro-symbolic reasoning, combining end-to-end differentiability with the interpretability of symbolic logic programming. However, optimizing NTPs remains a significant challenge due to their complex objective landscape and gradient sparcity. On the other hand, Knowledge Graph Embedding (KGE) methods offer smooth optimization with well-defined learning objectives but often lack interpretability. In this work, we propose several strategies to integrate the strengths of NTPs and KGEs. By incorporating KGE objectives into the NTP framework, we demonstrate substantial improvements in both accuracy and computational efficiency."
    },
    {
        "title": "Superpipeline: A Universal Approach for Reducing GPU Memory Usage in Large Models",
        "link_suffix": "/forum?id=i1G4AWXHRv",
        "link": "https://openreview.net/forum?id=i1G4AWXHRv",
        "pdf_link": "https://openreview.net/pdf?id=i1G4AWXHRv",
        "keywords": "GPU memory optimization, Inference Efficiency, Training Optimization, Large-Scale Models, GPU-CPU data transfer",
        "abstract": "The rapid growth in size and complexity of machine learning models, particularly in natural language processing and computer vision, has led to significant challenges in model execution on hardware with limited resources. This paper introduces Superpipeline, a novel framework designed to optimize the execution of large-scale AI models on constrained hardware for both training and inference phases. Our approach focuses on dynamically managing model execution by partitioning models into individual layers and efficiently transferring these partitions between GPU and CPU memory.\nSuperpipeline achieves substantial reductions in GPU memory consumption\u2014up to 60% in our experiments\u2014while maintaining model accuracy and acceptable processing speeds. This enables the execution of models that would otherwise exceed available GPU memory capacity. Unlike existing solutions that primarily target inference or specific model types, Superpipeline demonstrates broad applicability across large language models (LLMs), vision-language models (VLMs), and vision-based models.\nWe evaluate Superpipeline's effectiveness through comprehensive experiments on diverse models and hardware configurations. Our method is characterized by two key parameters that allow fine-tuning of the trade-off between GPU memory usage and processing speed. Importantly, Superpipeline does not require model retraining or parameter modification, ensuring full preservation of the original model's output fidelity.\nThe simplicity and flexibility of Superpipeline make it a valuable tool for researchers and practitioners working with state-of-the-art AI models under hardware constraints. It enables the use of larger models or increased batch sizes on existing hardware, potentially accelerating innovation across various machine learning applications. This work represents a significant step towards democratizing access to advanced AI models and optimizing their deployment in resource-constrained environments."
    },
    {
        "title": "The Inductive Bias of Minimum-Norm Shallow Diffusion Models That Perfectly Fit the Data",
        "link_suffix": "/forum?id=kBLnxjuKd3",
        "link": "https://openreview.net/forum?id=kBLnxjuKd3",
        "pdf_link": "https://openreview.net/pdf?id=kBLnxjuKd3",
        "keywords": "Probability flow, Score flow, Diffusion models, Denoising, Neural networks",
        "abstract": "While diffusion models can generate high-quality images through the probability flow process, the theoretical understanding of this process is incomplete. A key open question is determining when the probability flow converges to the training samples used for denoiser training and when it converges to more general points on the data manifold. To address this, we analyze the probability flow of shallow ReLU neural network denoisers which interpolate the training data and have a minimal $\\ell^2$ norm of the weights. For intuition, we also examine a simpler dynamics which we call the score flow, and demonstrate that, in the case of orthogonal datasets, the score flow and probability flow follow similar trajectories. Both flows converge to a training point or a sum of training points. However, due to early stopping induced by the scheduler, the probability flow can also converge to a general point on the data manifold. This result aligns with empirical observations that diffusion models tend to memorize individual training examples and reproduce them during testing. Moreover, diffusion models can combine memorized foreground and background objects, indicating they can learn a \"semantic sum\" of training points. We generalize these results from the orthogonal dataset case to scenarios where the clean data points lie on an obtuse simplex. Simulations further confirm that the probability flow converges to one of the following: a training point, a sum of training points, or a point on the data manifold."
    }
]
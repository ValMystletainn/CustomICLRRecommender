[
    {
        "title": "Evolve: Evaluating and Optimizing LLMs For Exploration",
        "link_suffix": "/forum?id=0Fi3u4RCyU",
        "link": "https://openreview.net/forum?id=0Fi3u4RCyU",
        "pdf_link": "https://openreview.net/pdf?id=0Fi3u4RCyU",
        "keywords": "Large Language Model, Exploration",
        "abstract": "Despite their success in many domains, large language models (LLMs) remain under-studied in scenarios requiring optimal decision-making under uncertainty. This is crucial as many real-world applications, ranging from personalized recommendations to healthcare interventions, demand that LLMs not only predict but also actively learn to make optimal decisions through exploration.\nIn this work, we measure LLMs' (in)ability to make optimal decisions in bandits, a state-less reinforcement learning setting relevant to many applications. We develop a comprehensive suite of environments that include both context-free and contextual bandits of varying task difficulties to benchmark LLMs' performance. Motivated by the existence of optimal exploration algorithms, we propose efficient ways to integrate this algorithmic knowledge into LLMs: by providing explicit algorithmic guided support during inference; and through knowledge distillation via in-context demonstrations and fine-tuning, using synthetic data generated from these algorithms.\nImpressively, these techniques allow us to achieve superior exploration performance with smaller models, surpassing larger models on various tasks. We conducted an extensive ablation study to shed light on the different factors, such as task difficulty and data representations, that influence the efficiency of LLM exploration. Additionally, we provide empirical measurements on the convergence rate of different exploration strategies introduced."
    },
    {
        "title": "Boltzmann priors for Implicit Transfer Operators",
        "link_suffix": "/forum?id=pRCOZllZdT",
        "link": "https://openreview.net/forum?id=pRCOZllZdT",
        "pdf_link": "https://openreview.net/pdf?id=pRCOZllZdT",
        "keywords": "Molecular Dynamics, Generative Models, Transfer Operators, Diffusion Models, Boltzmann Generators",
        "abstract": "Accurate prediction of thermodynamic properties is essential in drug discovery and materials science. Molecular dynamics (MD) simulations provide a principled approach to this task, yet they typically rely on prohibitively long sequential simulations. Implicit Transfer Operator (ITO) Learning offers a promising approach to address this limitation by enabling stable simulation with time-steps orders of magnitude larger than MD. However, to train ITOs, we need extensive, unbiased MD data, limiting their practical applicability. Here, we introduce Boltzmann Priors for ITO (BoPITO) to enhance ITO learning in two ways. First, BoPITO enables more efficient data generation, and second, it embeds inductive biases for long-term dynamical behavior, simultaneously improving sample efficiency by one order of magnitude and guaranteeing asymptotically unbiased equilibrium statistics. Further, we showcase the use of BoPITO in a new tunable sampling protocol interpolating ITO models trained on off-equilibrium simulation data and an unbiased equilibrium distribution to solve inverse problems in molecular science."
    },
    {
        "title": "Enhancing Conversational Recommender Systems with Tree-Structured Knowledge and Pretrained Language Models",
        "link_suffix": "/forum?id=NceWCqEIV3",
        "link": "https://openreview.net/forum?id=NceWCqEIV3",
        "pdf_link": "https://openreview.net/pdf?id=NceWCqEIV3",
        "keywords": "Conversational Recommendation Systems, Knowledge Graph, Pretrained Language Model",
        "abstract": "Conversational recommender systems (CRS) have emerged as a key enhancement to traditional recommendation systems, offering interactive and explainable recommendations through natural dialogue.\nRecent advancements in pretrained language models (PLMs) have significantly improved the conversational capabilities of CRS, enabling more fluent and context-aware interactions. \nHowever, PLMs still face challenges, including hallucinations\u2014where the generated content can be factually inaccurate\u2014and difficulties in providing precise, entity-specific recommendations.\nTo address these challenges, we propose the PCRS-TKA framework, which integrates PLMs with knowledge graphs (KGs) through prompt-based learning. By incorporating tree-structured knowledge from KGs, our framework grounds the PLM in factual information, thereby enhancing the accuracy and reliability of the recommendations. Additionally, we design a user preference extraction module to improve the personalization of recommendations and introduce an alignment module to ensure semantic consistency between dialogue text and KG data. Extensive experiments demonstrate that PCRS-TKA outperforms existing methods in both recommendation accuracy and conversational fluency."
    },
    {
        "title": "WISDOM: Progressive Curriculum Synthesis Makes LLMs Better Mathematical Reasoner",
        "link_suffix": "/forum?id=hFFAg5Dmw9",
        "link": "https://openreview.net/forum?id=hFFAg5Dmw9",
        "pdf_link": "https://openreview.net/pdf?id=hFFAg5Dmw9",
        "keywords": "Large language models, Mathematical reasoning, data synthesis",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of problem-solving tasks. Despite their success, LLMs still face significant challenges in complex reasoning, particularly with advanced mathematical problems. These problems require not only a deep understanding of task descriptions but also sophisticated logical and mathematical reasoning to determine the correct solution path, which is often lacking in the existing synthetic data. To address this gap, we introduce WISDOM, which draws inspiration from the human learning process and employs curriculum learning to gradually synthesize high-quality CoT data from easy to hard. Our goal is to guide LLM training and improve reasoning capabilities by progressively exposing models to increasingly challenging problems. Based on the synthesized data, we further fine-tune and develop the WISDOM series models, achieving significant improvements across multiple mathematical reasoning benchmarks. Notably, WISDOM-7B (DSMath) achieves a score of 62.4% on MATH, matching GPT-4\u2019s performance with 2/30 correct answers on AIME2024. Furthermore, WISDOM-70B (Llama3) outperforms GPT-4 on AIME2024 with 3/30 correct answers, demonstrating its potential as a better mathematical reasoner. More data and models will be available athttps://anonymous.4open.science/r/Wisdom-math-377B"
    },
    {
        "title": "ThunderKittens: Simple, Fast, andAdorableKernels",
        "link_suffix": "/forum?id=0fJfVOSUra",
        "link": "https://openreview.net/forum?id=0fJfVOSUra",
        "pdf_link": "https://openreview.net/pdf?id=0fJfVOSUra",
        "keywords": "Systems, Kernels, Efficiency, Efficient Models, IO Awareness, GPUs",
        "abstract": "The challenge of mapping AI architectures to GPU hardware is creating a critical bottleneck in AI progress. Despite substantial efforts, hand-written custom kernels fail to meet their theoretical performance thresholds, even on well-established operations like linear attention.\nThe diverse hardware capabilities of GPUs might suggest that we need a wide variety of techniques to achieve high performance. However, our work explores whether a small number of key abstractions can drastically simplify the process. We present ThunderKittens (TK), a framework for writing performant AI kernels while remaining easy to use and maintain. Our abstractions map to the three levels of the GPU hierarchy: (1) at the warp-level, we provide 16x16 matrix tiles as basic data structures and PyTorch-like parallel compute operations over tiles, (2) at the thread-block level, we provide a template for overlapping asynchronous operations across parallel warps, and (3) at the grid-level, TK can help hide the block launch and tear-down, and memory costs. We show the value of TK by providing kernels that match or outperform prior kernels for a range of AI operations. We match CuBLAS and FlashAttention-3 on GEMM and attention inference, and outperforms the strongest baselines by $10-40%$ on attention backwards, $9\\times$ on state space models, and $14\\times$ on linear attention."
    },
    {
        "title": "Can In-context Learning Really Generalize to Out-of-distribution Tasks?",
        "link_suffix": "/forum?id=INe4otjryz",
        "link": "https://openreview.net/forum?id=INe4otjryz",
        "pdf_link": "https://openreview.net/pdf?id=INe4otjryz",
        "keywords": "Large language models, In-context Learning, Out-of-distribution Generalization",
        "abstract": "In this work, we explore the mechanism of in-context learning (ICL) on out-of-distribution (OOD) tasks that were not encountered during training. To achieve this, we conduct synthetic experiments where the objective is to learn OOD mathematical functions through ICL using a GPT-2 model. We reveal that Transformers may struggle to learn OOD task functions through ICL. Specifically, ICL performance resembles implementing a function within the pretraining hypothesis space and optimizing it with gradient descent based on the in-context examples. Additionally, we investigate ICL's well-documented ability to learn unseen abstract labels in context. We demonstrate that such ability only manifests in the scenarios without distributional shifts and, therefore, may not serve as evidence of new-task-learning ability. Furthermore, we assess ICL's performance on OOD tasks when the model is pretrained on multiple tasks. Both empirical and theoretical analyses demonstrate the existence of the \\textbf{low-test-error preference} of ICL, where it tends to implement the pretraining function that yields low test error in the testing context. We validate this through numerical experiments. This new theoretical result, combined with our empirical findings, elucidates the mechanism of ICL in addressing OOD tasks."
    },
    {
        "title": "Statistical Test for Anomaly Detections using Variational Auto-Encoders by Selective Inference",
        "link_suffix": "/forum?id=AJp85vrtNe",
        "link": "https://openreview.net/forum?id=AJp85vrtNe",
        "pdf_link": "https://openreview.net/pdf?id=AJp85vrtNe",
        "keywords": "Variational Autoencoder, Selective Inference, Anomaly Detection, Medical Image Analysis",
        "abstract": "Over the past decade, Variational Autoencoders (VAE) have become a widely used tool for anomaly detection (AD), with research advancing from algorithm development to real-world applications. However, a critical challenge remains --- the lack of a reliable method to rigorously assess the reliability of detected anomalies, which restricts its use in high-stakes decision-making tasks such as medical diagnostics. To overcome this limitation, we introduce the VAE-AD Test, a novel approach for quantifying the statistical reliability of VAE-based AD. The key advantage of the VAE-AD Test lies in its ability to properly control the probability of misidentifying anomalies under a pre-specified level of guarantee $\\alpha$ (e.g., 0.05). Specifically, by carefully analyzing the AD process of VAE, which operates through piecewise-linear functions, and leveraging the Selective Inference (SI) framework to assign valid p-values to the detected anomalies, we prove that theoretical control of the false detection rate is achievable. Experiments conducted on both synthetic and real-world datasets robustly support our theoretical results, showcasing the VAE-AD Test\u2019s superior performance. To our knowledge, this is the first work capable of conducting valid statistical inference to assess the reliability of VAE-based AD."
    },
    {
        "title": "CAKE: Cascading and Adaptive KV Cache Eviction with Layer Preferences",
        "link_suffix": "/forum?id=EQgEMAD4kv",
        "link": "https://openreview.net/forum?id=EQgEMAD4kv",
        "pdf_link": "https://openreview.net/pdf?id=EQgEMAD4kv",
        "keywords": "Large Language Model, Efficient Generative Inference, Key-Value Cache",
        "abstract": "Large language models (LLMs)' proficiency in handling long sequences boosts KV caching demand. Recent efforts to evict KV cache have alleviated the burden for inference, but they often fail to allocate resources rationally across layers with different attention patterns. In this paper, we introduce Cascading and Adaptive KV cache Eviction (CAKE), a method that significantly improves LLM inference efficiency by optimizing KV cache eviction through an adaptive cache allocation strategy implemented via a cascading cache management and an innovative eviction indicator. We approach KV cache eviction as a ``cake-slicing problem,'' assessing each layer's KV cache needs by considering attention dynamics in both spatial and temporal dimensions. During the prompt prefilling, CAKE allocates rational cache size for layers by analyzing layer-specific KV cache preferences and manages the memory budgets with the guidance of these preferences in a cascading manner. This approach allows for a global view of cache size allocation, distributing resources optimally based on the diverse attention mechanisms across layers. Also, we've designed a new eviction indicator that considers the shifting importance of tokens over time, addressing a limitation in existing methods that often overlook temporal dynamics. Our comprehensive experiments on the LongBench and NeedleBench datasets show that CAKE is capable of preserving the performance of models when retaining only 3.2% KV cache and consistently outperforms current baselines across various models and memory constraints, especially in low-memory situations. Moreover, CAKE outperforms full cache with FlashAttention implementation, achieving 10$\\times$ faster decoding for 128K-token sequences and maintaining consistent decoding speed across sequence lengths."
    },
    {
        "title": "gRNAde: Geometric Deep Learning for 3D RNA inverse design",
        "link_suffix": "/forum?id=lvw3UgeVxS",
        "link": "https://openreview.net/forum?id=lvw3UgeVxS",
        "pdf_link": "https://openreview.net/pdf?id=lvw3UgeVxS",
        "keywords": "RNA Structure, RNA Design, Geometric Deep Learning, Graph Neural Networks",
        "abstract": "Computational RNA design tasks are often posed as inverse problems, where sequences are designed based on adopting a single desired secondary structure without considering 3D geometry and conformational diversity. We introduce gRNAde, a geometric RNA design pipeline operating on 3D RNA backbones to design sequences that explicitly account for structure and dynamics. gRNAde uses a multi-state Graph Neural Network and autoregressive decoding to generates candidate RNA sequences conditioned on one or more 3D backbone structures where the identities of the bases are unknown. On a single-state fixed backbone re-design benchmark of 14 RNA structures from the PDB identified by Das et al. (2010), gRNAde obtains higher native sequence recovery rates (56% on average) compared to Rosetta (45% on average), taking under a second to produce designs compared to the reported hours for Rosetta. We further demonstrate the utility of gRNAde on a new benchmark of multi-state design for structurally flexible RNAs, as well as zero-shot ranking of mutational fitness landscapes in a retrospective analysis of a recent ribozyme. Experimental wet lab validation on 10 different structured RNA backbones finds that gRNAde has an impressive success rate of 50%, a significant advance over 35% for Rosetta. Open source code and tutorials are available at:https://anonymous.4open.science/r/geometric-rna-design"
    },
    {
        "title": "Generalized Resource-Aware Distributed Minimax Optimization",
        "link_suffix": "/forum?id=lhh5Q85KQJ",
        "link": "https://openreview.net/forum?id=lhh5Q85KQJ",
        "pdf_link": "https://openreview.net/pdf?id=lhh5Q85KQJ",
        "keywords": "Distributed minimax optimization, Generalization",
        "abstract": "Traditional distributed minimax optimization algorithms cannot be applied in resource-limited clients dealing with large-scale models. In this work, we presentSubDisMO, a generalized resource-aware distributed minimax optimization algorithm.SubDisMOprunes the global large-scale model into adaptive-sized submodels to accommodate varying resources during each communication round. However, the randomly pruned submodels are susceptible toarbitrary submodel sharpness, which can hinder generalization and lead to slow convergence. To address this issue,SubDisMOtrains the arbitrarily pruned submodels with perturbations by optimizing the minimax objectives, enhancing thegeneralizationperformance of the aggregated full model. We theoretically analyze our proposed resource-awareSubDisMOalgorithm, demonstrating that it achieves an asymptotically optimal convergence rate of $O(1/\\sqrt{QT\\mathcal{C}^*})$, which is dominated by the minimum covering number $\\mathcal{C}^*$. We also show the generalization bound ofSubDisMOcorresponding to the remaining rate in each layer. Extensive experiments onCIFAR-10andCIFAR-100datasets demonstrate thatSubDisMOachieves superior generalization and effectiveness compared to state-of-the-art baselines."
    },
    {
        "title": "Generate-then-Test: Automated Test Case Generation for WebAssembly Using Large Language Models",
        "link_suffix": "/forum?id=adSdHgWGBB",
        "link": "https://openreview.net/forum?id=adSdHgWGBB",
        "pdf_link": "https://openreview.net/pdf?id=adSdHgWGBB",
        "keywords": "WebAssembly, Large Language Models, Test Case Generation",
        "abstract": "The reliability and security of WebAssembly (Wasm) binaries are crucial for modern web development, yet effective testing methodologies remain undeveloped. This paper addresses the gap in Wasm binary testing by proposing a novel approach for test cases generation, leveraging Large Language Models (LLMs) to enhance test coverage and bug detection. Traditional testing approaches typically require access to source code, which is often unavailable for Wasm binaries. Our generate-then-test methodology overcomes this limitation by generating equivalent C++ code to simulate expected Wasm behavior, creating and mutating test cases in C++, and compiling these tests to evaluate them against the Wasm binary. Key contributions include automated test case generation using LLMs and improved code coverage through type-aware mutations, with comprehensive evaluation demonstrating the effectiveness of our approach in detecting subtle bugs in Wasm binaries, thereby ensuring more reliable Wasm applications."
    },
    {
        "title": "COSTAR: Dynamic Safety Constraints Adaptation in Safe Reinforcement Learning",
        "link_suffix": "/forum?id=hZztyfmr8n",
        "link": "https://openreview.net/forum?id=hZztyfmr8n",
        "pdf_link": "https://openreview.net/pdf?id=hZztyfmr8n",
        "keywords": "Reinforcement Learning",
        "abstract": "Recent advancements in safe reinforcement learning (safe RL) have focused on developing agents that maximize rewards while satisfying predefined safety constraints. However, the challenge of learning policies capable of generalizing to dynamic safety requirements has rarely been explored. To this end, we propose a novel COntrastive Safe TAsk Representation (COSTAR) framework for safe RL, which can boost existing algorithm's generalization to dynamic safety constraints, including variable cost functions and safety thresholds.In COSTAR, we employ a Safe Task Encoder to extract safety-specific representations from trajectory contexts, effectively distinguishing between various safety constraints with contrastive learning. It is noteworthy that our framework can integrate with existing safe RL algorithms and possesses zero-shot adaptation capability to varying safety constraints during deployment. Extensive experiments demonstrate that our COSTAR framework consistently achieves high rewards while maintaining low costs, and exhibits robust generalization capabilities when dealing with out-of-distribution (OOD) tasks."
    },
    {
        "title": "Does RLHF Scale? Exploring the Effects of Data, Model, and Method",
        "link_suffix": "/forum?id=FIXk0RP960",
        "link": "https://openreview.net/forum?id=FIXk0RP960",
        "pdf_link": "https://openreview.net/pdf?id=FIXk0RP960",
        "keywords": "Language model, Reinforcement learning from human feedback, Scaling",
        "abstract": "This study explores the scaling properties of Reinforcement Learning from Human Feedback (RLHF) in Large Language Models (LLMs). \nAlthough RLHF is considered an important step in the post-training of LLMs, its scaling potential is still largely unknown. \nWe systematically analyze key components in the RLHF framework\u2014model size, data composition, and inference budget\u2014and their impacts on performance.\nOur findings show that increasing data diversity and volume improves reward model performance, helping process-supervision models scale better. \nFor policy training, more response samples per prompt boost performance initially but quickly plateau. \nAnd larger reward models offer modest gains in policy training. \nIn addition, larger policy models benefit less from RLHF with a fixed reward model. \nOverall, RLHF scales less efficiently than pretraining, with diminishing returns from additional computational resources.\nBased on these observations, we propose strategies to optimize RLHF performance within computational limits."
    },
    {
        "title": "Uncertainty-Guided Optimization on Large Language Model Search Trees",
        "link_suffix": "/forum?id=MqL2e85ZTp",
        "link": "https://openreview.net/forum?id=MqL2e85ZTp",
        "pdf_link": "https://openreview.net/pdf?id=MqL2e85ZTp",
        "keywords": "LLMs, Probabilistic Inference, Tree Search",
        "abstract": "Tree search algorithms such as greedy and beam search are the standard when it comes to finding sequences of maximum likelihood in the decoding processes of large language models (LLMs).\nHowever, they are myopic since they do not take the complete root-to-leaf path into account.\nMoreover, they are agnostic to prior knowledge available about the process:\nFor example, it does not consider that the objective being maximized is a probability and thereby has specific properties like being bound in the unit interval.\nTaking a probabilistic approach, we define prior beliefs over LLMs' transition probabilities and obtain posterior beliefs over the most promising paths in each iteration.\nThese beliefs are useful for defining a sample-based, non-myopic acquisition function that allows for a more data-efficient exploration scheme than standard search algorithms on LLMs.\nCrucially, unlike expensive simulation-based non-myopic methods like the Monte Carlo tree search, our method only requires samples from the beliefs.\nOur formulation thus views LLM decoding as Bayesian optimization on trees.\nWe discuss how to select the prior and the acquisition function, and demonstrate in experiments with various LLMs that our method achieves higher efficiency than recent baselines:\nOur method achieves the same or a higher likelihood while expanding fewer nodes."
    },
    {
        "title": "Fast Computation of Gaussian Processes Augmented by Synthetic Simulator Data",
        "link_suffix": "/forum?id=K5QGZut3uu",
        "link": "https://openreview.net/forum?id=K5QGZut3uu",
        "pdf_link": "https://openreview.net/pdf?id=K5QGZut3uu",
        "keywords": "Gaussian processes, simulator, marginal likelihood, model selection",
        "abstract": "When the amount of training data is limited, augmenting it with generated data from a simulator can be a beneficial approach to improving prediction accuracy. However, there are no clear metrics on which generated data should be added to the training set and in what proportion, especially when the predictive model is a Gaussian Processes (GPs) model. To address this, we propose using the log marginal likelihood as a guiding metric. The log marginal likelihood is a theoretically grounded criterion for model selection. However, computing this metric for GPs is computationally expensive. To overcome this challenge, we introduce a faster method for calculating the log marginal likelihood by considering the Cholesky factor and matrix element dependencies. Experimental results demonstrate that metrics utilizing the log likelihood outperform basic methods in mean squared error on test set."
    },
    {
        "title": "Toward Guidance-Free AR Visual Generation via Condition Contrastive Alignment",
        "link_suffix": "/forum?id=kGvXIlIVLM",
        "link": "https://openreview.net/forum?id=kGvXIlIVLM",
        "pdf_link": "https://openreview.net/pdf?id=kGvXIlIVLM",
        "keywords": "autoregressive, generative models, image generation, multimodal, alignment, RLHF, classifier-free guidance",
        "abstract": "Classifier-Free Guidance (CFG) is a critical technique for enhancing the sample quality of visual generative models. However, in autoregressive (AR) multi-modal generation, CFG introduces design inconsistencies between language and visual content, contradicting the design philosophy of unifying different modalities for visual AR. Motivated by language model alignment methods, we propose Condition Contrastive Alignment (CCA) to facilitate guidance-free AR visual generation. Unlike guidance methods that alter the sampling process to achieve the ideal sampling distribution, CCA directly fine-tunes pretrained models to fit the same distribution target. Experimental results show that CCA can significantly enhance the guidance-free performance of all tested models with just one epoch of fine-tuning (1% of pretraining epochs) on the pretraining dataset. This largely removes the need for guided sampling in AR visual generation and cuts the sampling cost by half. Moreover, by adjusting training parameters, CCA can achieve trade-offs between sample diversity and fidelity similar to CFG. This experimentally confirms the strong theoretical connection between language-targeted alignment and visual-targeted guidance methods, unifying two previously independent research fields."
    },
    {
        "title": "Revisiting Nearest Neighbor for Tabular Data: A Deep Tabular Baseline Two Decades Later",
        "link_suffix": "/forum?id=JytL2MrlLT",
        "link": "https://openreview.net/forum?id=JytL2MrlLT",
        "pdf_link": "https://openreview.net/pdf?id=JytL2MrlLT",
        "keywords": "Tabular data, tabular machine learning, deep tabular models",
        "abstract": "The widespread enthusiasm for deep learning has recently expanded into the domain of tabular data. Recognizing that the advancement in deep tabular methods is often inspired by classical methods, e.g., integration of nearest neighbors into neural networks, we investigate whether these classical methods can be revitalized with modern techniques.\nWe revisit a differentiable version of $K$-nearest neighbors (KNN) --- Neighbourhood Components Analysis (NCA) --- originally designed to learn a linear projection to capture semantic similarities between instances, and seek to gradually add modern deep learning techniques on top. Surprisingly, our implementation of NCA using SGD and without dimensionality reduction already achieves decent performance on tabular data, in contrast to the results of using existing toolboxes like scikit-learn. Further equipping NCA with deep representations and additional training stochasticity significantly enhances its capability, being on par with the leading tree-based method CatBoost and outperforming existing deep tabular models in both classification and regression tasks on 300 datasets. We conclude our paper by analyzing the factors behind these improvements, including loss functions, prediction strategies, and deep architectures."
    },
    {
        "title": "LoR-VP: Low-Rank Visual Prompting for Efficient Vision Model Adaptation",
        "link_suffix": "/forum?id=5btFIv2PNb",
        "link": "https://openreview.net/forum?id=5btFIv2PNb",
        "pdf_link": "https://openreview.net/pdf?id=5btFIv2PNb",
        "keywords": "computer vision, visual prompt",
        "abstract": "Visual prompting has gained popularity as a method for adapting pre-trained models to specific tasks, particularly in the realm of parameter-efficient tuning. However, existing visual prompting techniques often pad the prompt parameters around the image, limiting the interaction between the visual prompts and the original image to a small set of patches while neglecting the inductive bias present in shared information across different patches. In this study, we conduct a thorough preliminary investigation to identify and address these limitations. We propose a novel visual prompt design, introducingLow-Rank matrix multiplication forVisualPrompting (LoR-VP), which enables shared and patch-specific information across rows and columns of image pixels. Extensive experiments across seven network architectures and four datasets demonstrate significant improvements in both performance and efficiency compared to state-of-the-art visual prompting methods, achieving up to $6\\times$ faster training times, utilizing $18\\times$ fewer visual prompt parameters, and delivering a 3.1% improvement in performance."
    },
    {
        "title": "Derivative Causal Models: Modeling Causality at Mixed Scales of Observation",
        "link_suffix": "/forum?id=VFbMTKH1Qs",
        "link": "https://openreview.net/forum?id=VFbMTKH1Qs",
        "pdf_link": "https://openreview.net/pdf?id=VFbMTKH1Qs",
        "keywords": "derivative causal models, causal modeling, constraint causal models",
        "abstract": "Causal relations can materialize in many different ways. In their most simple form --typically assumed in classical causal models and discovery approaches--, similar variations of a cause lead to similar variations of an effect. However, this `smoothness' requires an observation of cause and effect just at the right scales. Unfortunately, this conflicts with records often encountered in the real-world, mixing continuous measurements with once-in-a-while observations of sparse events. Compactly modeling the causal effects between (discrete) events and continuous states is hard to achieve with classical causal models. To ease this situation, we leverage transformations that derive different scales of observables, respectively, to decompose relations and allow for compact causal representations, calledDerivative Causal Models(DCM). We instantiate them using integral and derivative transforms and demonstrate that the resultingDifferential Causal Models($\\partial$CM) can be discovered automatically from data."
    },
    {
        "title": "Robust Simulation-Based Inference under Missing Data",
        "link_suffix": "/forum?id=GsR3zRCRX5",
        "link": "https://openreview.net/forum?id=GsR3zRCRX5",
        "pdf_link": "https://openreview.net/pdf?id=GsR3zRCRX5",
        "keywords": "Simulation-based inference, likelihood-free inference, approximate Bayesian computation, neural posterior estimation, missing data",
        "abstract": "Simulation-based inference (SBI) methods typically require fully observed data to infer parameters of models with intractable likelihood functions. However, datasets often contain missing values due to incomplete observations, data corruptions (common in astrophysics), or instrument limitations (e.g., in high-energy physics applications). In such scenarios, missing data must be imputed before applying any SBI method. This work formalizes the problem of missing data in SBI and demonstrates that naive imputation methods can introduce bias into the SBI posterior. We introduce a novel method that addresses this issue by jointly learning the imputation model and the inference network within a neural posterior estimation (NPE) framework. Extensive empirical results on SBI benchmarks show that our approach provides robust inference outcomes compared to baselines, for varying levels of missing data, while being amortized."
    },
    {
        "title": "Decentralized Training of Transformer Models in Heterogeneous Network",
        "link_suffix": "/forum?id=bntJK4NyIW",
        "link": "https://openreview.net/forum?id=bntJK4NyIW",
        "pdf_link": "https://openreview.net/pdf?id=bntJK4NyIW",
        "keywords": "Distributed Learning, LLM",
        "abstract": "Training large transformer-based models like GPT-4 and Llama3 is prohibitively expensive, often requiring vast resources, such as tens of thousands of GPUs running simultaneously for months. Traditionally, these models are trained in specialized clusters with high-speed, uniform interconnections and computational capabilities, enabling efficient data and pipeline parallelism. However, these clusters are costly, while more affordable GPUs are widely distributed across the globe. Existing approaches, such as Swarm and Dapple, primarily focus on distributed learning across data centers. In this paper, we introduce a novel framework designed to handle heterogeneous devices and unstable communication environments. Our framework employs a hybrid approach, combining parameter server architectures, pipeline parallelism, and task pool strategies to effectively manage device disconnections. Through comprehensive time-cost analysis and graph clustering techniques, we derive a near-optimal resource allocation scheme. We compare our method with existing large-scale training approaches and demonstrate its effectiveness by training a large language model using gaming GPUs in real-world internet conditions."
    },
    {
        "title": "Improved Variational Inference in Discrete VAEs using Error Correcting Codes",
        "link_suffix": "/forum?id=ZQwvUTyL8Y",
        "link": "https://openreview.net/forum?id=ZQwvUTyL8Y",
        "pdf_link": "https://openreview.net/pdf?id=ZQwvUTyL8Y",
        "keywords": "deep generative models, variational inference, discrete representations, error correcting codes",
        "abstract": "Despite significant advancements in deep probabilistic models, effective learning of low-dimensional discrete latent representations remains challenging. This paper introduces a novel method to improve variational inference in discrete latent variable models by employing Error Correcting Codes (ECCs) to add redundancy to the latent representations, later exploited by the variational approximated posterior to provide more accurate estimates, thereby reducing the variational gap. Drawing inspiration from ECCs used in digital communications and data storage, we demonstrate proof-of-concept using a Discrete Variational Autoencoder (DVAE) with binary latent variables and block repetition codes. We then extend it to a hierarchical structure inspired by polar codes, in which some latent bits are more robustly protected than others. Our approach significantly enhances generation quality, data reconstruction, and uncertainty calibration compared to the uncoded DVAE, even when trained with tighter bounds such as the Importance Weighted Autoencoder (IWAE) objective. In particular, we demonstrate superior performance on MNIST, FMNIST, CIFAR10, and Tiny ImageNet datasets. The general approach of integrating ECCs into variational inference is compatible with existing techniques to boost variational inference, such as importance sampling or Hamiltonian Monte Carlo. We also formulate the properties that ECCs need to possess to be effectively used for improved discrete variational inference."
    },
    {
        "title": "Start Smart: Leveraging Gradients For Enhancing Mask-based XAI Methods",
        "link_suffix": "/forum?id=Iht4NNVqk0",
        "link": "https://openreview.net/forum?id=Iht4NNVqk0",
        "pdf_link": "https://openreview.net/pdf?id=Iht4NNVqk0",
        "keywords": "XAI, mask-based explanations, rate-distortion explanation, information bottleneck",
        "abstract": "Mask-based explanation methods offer a powerful framework for interpreting deep learning model predictions across diverse data modalities, such as images and time series, in which the central idea is to identify an instance-dependent mask that minimizes the performance drop from the resulting masked input. Different objectives for learning such masks have been proposed, all of which, in our view, can be unified under an information-theoretic framework that balances performance degradation of the masked input with the complexity of the resulting masked representation. Typically, these methods initialize the masks either uniformly or as all-ones.\nIn this paper, we argue that an effective mask initialization strategy is as important as the development of novel learning objectives, particularly in light of the significant computational costs associated with mask-based explanation methods. To this end, we introduce a new gradient-based initialization technique called StartGrad, which is the first initialization method specifically designed for mask-based post-hoc explainability methods. Compared to commonly used strategies, StartGrad is provably superior at initialization in striking the aforementioned tradeoff. Despite its simplicity, our experiments demonstrate that StartGrad consistently helps to speed up the optimization process of various state-of-the-art mask-explanation method by reaching target metrics quicker and, in some cases, even boosts overall performance."
    },
    {
        "title": "FedGraph: A New Paradigm for Federated Graph Learning",
        "link_suffix": "/forum?id=Oqqbnn1snA",
        "link": "https://openreview.net/forum?id=Oqqbnn1snA",
        "pdf_link": "https://openreview.net/pdf?id=Oqqbnn1snA",
        "keywords": "Federated Learning, Anomaly Alignment, Network Alignment",
        "abstract": "Federated learning is a distributed approach to training a global model over multiple clients without sharing their local data. In graph data, the data heterogeneity can correspond to subgraph structures and node features varying extremely different, and the task-specific knowledge isolation corresponds to exclusive schema on handing data for specific task in clients, e.g., anomaly user setting in Twitter is rather different from LinkedIn. Although most feder- ated graph learning approaches are employed to address the data heterogeneity challenge, we find that the task-specific knowledge isolation challenge has been overlooked. This task-specific knowl- edge isolation will prevent existing models into the federated graph learning framework. In this paper, we propose FedGraph: a new paradigm for federated graph learning. The key idea is to utilize the graph structure without private node features as structure knowl- edge bridging all task specific knowledge in clients. Our extensive experiments show that FedGraph significantly outperforms the other state-of-the-art federated learning algorithms on anomaly de- tection tasks. Two deep learning models and one existing anomaly subgraph detection model are transferred to FedGraph framework."
    },
    {
        "title": "DRESSing Up LLM: Efficient Stylized Question-Answering via Style Subspace Editing",
        "link_suffix": "/forum?id=mNVR9jJYqK",
        "link": "https://openreview.net/forum?id=mNVR9jJYqK",
        "pdf_link": "https://openreview.net/pdf?id=mNVR9jJYqK",
        "keywords": "Large Language Models, Stylized Question-Answering, Representation Editing",
        "abstract": "We introduce DRESS, a novel approach for generating stylized large language model (LLM) responses through representation editing. Existing methods like prompting and fine-tuning are either insufficient for complex style adaptation or computationally expensive, particularly in tasks like NPC creation or character role-playing. Our approach leverages the over-parameterized nature of LLMs to disentangle a style-relevant subspace within the model's representation space to conduct representation editing, ensuring a minimal impact on the original semantics. By applying adaptive editing strengths, we dynamically adjust the steering vectors in the style subspace to maintain both stylistic fidelity and semantic integrity. We develop two stylized QA benchmark datasets to validate the effectiveness of DRESS, and the results demonstrate significant improvements compared to baseline methods such as prompting and ITI. In short, DRESS is a lightweight, train-free solution for enhancing LLMs with flexible and effective style control, making it particularly useful for developing stylized conversational agents. Codes and benchmark datasets are available athttps://anonymous.4open.science/r/DRESS-LLM."
    }
]
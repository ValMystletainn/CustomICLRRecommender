[{"title": "HiQ-Lip: A Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks", "link_suffix": "/forum?id=yCAigmDGVy", "link": "https://openreview.net/forum?id=yCAigmDGVy", "pdf_link": "https://openreview.net/pdf?id=yCAigmDGVy", "keywords": "Quantum Computing, Lipschitz Constant, Neural Network, Quantum-Classical Hybrid Method, Coherent Ising Machine, QUBO", "abstract": "Estimating the global Lipschitz constant of neural networks is crucial for understanding and improving their robustness and generalization capabilities. However, precise calculations are NP-hard, and current semidefinite programming (SDP) methods face challenges such as high memory usage and slow processing speeds. In this paper, we propose $\\textbf{HiQ-Lip}$, a hybrid quantum-classical hierarchical method that leverages Coherent Ising Machines (CIMs) to estimate the global Lipschitz constant. \nWe tackle the estimation by converting it into a Quadratic Unconstrained Binary Optimization (QUBO) problem and implement a multilevel graph coarsening and refinement strategy to adapt to the constraints of contemporary quantum hardware. \nOur experimental evaluations on fully connected neural networks demonstrate that HiQ-Lip not only provides estimates comparable to state-of-the-art methods but also significantly accelerates the computation process. \nIn specific tests involving two-layer neural networks with 256 hidden neurons, HiQ-Lip doubles the solving speed and offers more accurate upper bounds than the existing best method, LiPopt.\nThese findings highlight the promising utility of small-scale quantum devices in advancing the estimation of neural network", "title_embedding_index": 6300, "title_abs_embedding_index": 6325}, {"title": "Annealed Implicit Q-learning in Online Reinforcement Learning", "link_suffix": "/forum?id=IdKkm91BzB", "link": "https://openreview.net/forum?id=IdKkm91BzB", "pdf_link": "https://openreview.net/pdf?id=IdKkm91BzB", "keywords": "online reinforcement learning, q-learning, sample efficiency", "abstract": "In continuous action online reinforcement learning, actor-critic methods are predominantly used.\nHowever, compared to Q-learning-based discrete action algorithms that model the optimal Q-value, continuous action algorithms that model the Q-value for the current policy and perform policy improvement solely through policy updates suffer from low sample efficiency. \nThis study investigates whether an algorithm that implicitly estimates the optimal Q-value, typically used in offline RL, is also effective in online RL. \nIt is demonstrated that a loss function aimed at achieving optimality distorts the distribution of Q-values, leading to overestimation bias, and that this distortion and bias increase as learning progresses.\nTo address this issue, we propose a simple algorithm that anneals optimality. Our method significantly outperforms widely used methods such as SAC and TD3 in online DM Control tasks. \nAdditionally, we demonstrate that annealing improves performance and enhances robustness to the hyperparameter related to the optimality.", "title_embedding_index": 6301, "title_abs_embedding_index": 6326}, {"title": "MFN: Metadata-Free Real-World Noisy Image Generation", "link_suffix": "/forum?id=sVbFE6xz82", "link": "https://openreview.net/forum?id=sVbFE6xz82", "pdf_link": "https://openreview.net/pdf?id=sVbFE6xz82", "keywords": "real noise modeling, prompt learning, consistency models, low-level vision", "abstract": "Real-world noise poses a significant challenge in signal processing, especially for denoising tasks.\nAlthough end-to-end denoising approaches have achieved exceptional performance, they are constrained to scenarios with abundant noisy-clean image pairs, which can be technically challenging and resource-intensive to collect.\nTo address this issue, several generative methods have been developed to synthesize realistic noisy images from limited real-world datasets.\nWhile prior studies require camera metadata during training or testing to handle various real-world noise, the absence of metadata or variations in the information across different capturing devices is common in real-world scenarios, such as medical or microscope imaging, which limits their applicability.\nThus, we aim to eliminate the need for explicit camera-related labels in both stages, enhancing applicability in real-world scenarios.\nTo achieve this, we propose a novel framework called the Metadata-Free Noise Model (MFN), which extracts prompt features that encode input noise characteristics and generates diverse noisy images that adhere to the distribution of the input noise.\nExtensive experimental results demonstrate the superior performance of our model in real-world noise generation and denoising across various benchmark datasets.", "title_embedding_index": 6302, "title_abs_embedding_index": 6327}, {"title": "POMDIFFUSER: LONG-MEMORY MEETS LONG- PLANNING FOR POMDPS", "link_suffix": "/forum?id=1mMjZvEhwH", "link": "https://openreview.net/forum?id=1mMjZvEhwH", "pdf_link": "https://openreview.net/pdf?id=1mMjZvEhwH", "keywords": "Reinforcement learning, Partial observability, Long memory, Planning", "abstract": "Effective long-term planning in complex environments benefits from not only leveraging immediate information but also utilizing past experiences. Drawing inspiration from how humans use long-term memory in decision-making, we propose the POMDiffuser framework, an approach to planning in partially observable environments. While conventional Diffuser models often memorize specific environments, POMDiffuser explores the potential of learning to plan from memory, with the aim of generalizing to new scenarios. By incorporating a memory mechanism in POMDP scenarios, our model extends diffusion-based planning models into the realm of meta-learning with carefully designed tasks that require the diffusion planner to demonstrate both long-term planning and memory utilization. We investigated existing diffusion-based models, focusing on their applicability, computational efficiency, and performance trade-offs.", "title_embedding_index": 6303, "title_abs_embedding_index": 6328}, {"title": "Solving robust MDPs as a sequence of static RL problems", "link_suffix": "/forum?id=Zi1QNJKXAD", "link": "https://openreview.net/forum?id=Zi1QNJKXAD", "pdf_link": "https://openreview.net/pdf?id=Zi1QNJKXAD", "keywords": "Robust reinforcement learning", "abstract": "esigning control policies whose performance level is guaranteed to remain above a given threshold in a span of environments is a critical feature for the adoption of reinforcement learning (RL) in real-world applications. \nThe search for such robust policies is a notoriously difficult problem, related to the so-called dynamic model of transition function uncertainty, where the environment dynamics are allowed to change at each time step.\nBut in practical cases, one is rather interested in robustness to a span of static transition models throughout interaction episodes. \nThe static model is known to be harder to solve than the dynamic one, and seminal algorithms, such as robust value iteration, as well as most recent works on deep robust RL, build upon the dynamic model.\nIn this work, we propose to revisit the static model. \nWe suggest an analysis of why solving the static model under some mild hypotheses is a reasonable endeavor, based on an equivalence with the dynamic model, and formalize the general intuition that robust MDPs can be solved by tackling a series of static problems. \nWe introduce a generic meta-algorithm called IWOCS, which incrementally identifies worst-case transition models so as to guide the search for a robust policy. \nDiscussion on IWOCS sheds light on new ways to decouple policy optimization and adversarial transition functions and opens new perspectives for analysis.\nWe derive a deep RL version of IWOCS and demonstrate it is competitive with state-of-the-art algorithms on classical benchmarks.", "title_embedding_index": 6304, "title_abs_embedding_index": 6329}, {"title": "Efficient LLM Alignment via Hierarchical Coarse-to-Fine Refinement", "link_suffix": "/forum?id=PHXLbaq822", "link": "https://openreview.net/forum?id=PHXLbaq822", "pdf_link": "https://openreview.net/pdf?id=PHXLbaq822", "keywords": "Alignment, Large language models", "abstract": "Alignment of Large Language Models (LLMs) intends to make LLMs behave to satisfy human preferences and values. Widely used methods, $\\textbf{e.g.}$, Reinforcement Learning from Human Feedback (RLHF), usually involve the additional training of LLMs with a reward model or the dataset reflecting human preferences. However, these training-based methods cannot quickly adapt to different preferences. Recent methods leverage search during the decoding process to align LLMs with preferences. However, these methods ignore the influence of prompts on the decoding distribution, thus hindering the performance. In this work, we propose $ \\textbf{\\textbf{HCFR}}$, a $\\textbf{H}$ierarchical $\\textbf{C}$oarse-to-$\\textbf{F}$ine $\\text{R}$efinement for efficient LLM alignment. Specifically, $\\textbf{\\textbf{HCFR}}$ includes a two-stage refinement: i) $\\textbf{coarse refinement}$ which rephrases the prompts from users through self-refinement, and ii) $\\textbf{fine refinement}$ which leverages the search methods, $\\textit{e.g.}$, Monte Carlo Tree Search (MCTS), for the responses with the guidance of a pre-trained reward model. \nExperimental results on HH-RLHF and UltraChat demonstrate that $\\textbf{\\textbf{HCFR}}$ can significantly outperform existing methods, $\\textit{e.g.}$, ARGS, CARDS, and Rejection sampling, in terms of performance and efficiency, $\\textit{i.e.}$, achieving a 71.3% win-tie rate in GPT-4 evaluations while reducing time consumption by 42%.", "title_embedding_index": 6305, "title_abs_embedding_index": 6330}, {"title": "Pyramidal Recursive Composition of Multi-Word Units into Unified Representations", "link_suffix": "/forum?id=PDu1zouM1U", "link": "https://openreview.net/forum?id=PDu1zouM1U", "pdf_link": "https://openreview.net/pdf?id=PDu1zouM1U", "keywords": "Composition, Croatian, embedding, pyramidal, recursive neural network, text representation learning", "abstract": "In this paper, we explore the composition of word embeddings to create richer, more meaningful representations of multi-word units. Existing methods, such as averaging word embeddings, provide simple and efficient approaches. However, they often fail to capture the complexity of multi-word interactions. To address this, we employ the Pyramidal Recursive learning (PyRv) method, which recursively combines word embeddings into unified representations. Originally developed for constructing representations hierarchically from subwords to phrases, PyRv is well-suited for progressively merging individual word vectors into phrase vectors.\nWe evaluate the effectiveness of PyRv for embedding composition using fastText embeddings on the dependency relation labeling task. Using a single fastText word embedding yields an accuracy of 71%. Averaging five fastText word embeddings (the middle word and its four neighboring words) results in a significant drop in accuracy to 34%. In contrast, by composing five word embeddings with PyRv, we achieve an accuracy of 77%, demonstrating the superior ability of PyRv to integrate multiple word embeddings into more expressive representations. These findings highlight the potential of PyRv as a lightweight yet powerful technique for word embedding composition.", "title_embedding_index": 6306, "title_abs_embedding_index": 6331}, {"title": "Advancing Portfolio Optimization: Hybrid Relaxation and Heuristic Approaches for Cardinality-Constrained MIQP Problems", "link_suffix": "/forum?id=C9pndmSjg6", "link": "https://openreview.net/forum?id=C9pndmSjg6", "pdf_link": "https://openreview.net/pdf?id=C9pndmSjg6", "keywords": "portfolio optimization, mixed-integer quadratic programming, relaxation", "abstract": "The growing magnitude of investments in global markets has intensified the need for sophisticated risk mitigation strategies in portfolio optimization. Traditional portfolio optimization models that seek to minimize risk for a specified return frequently incorporate cardinality constraints, rendering them as Mixed-Integer Quadratic Programming (MIQP) challenges. These constraints elevate the problem to NP-Hard status, complicating the solution process. While heuristic methods have historically been favored for their direct approach to MIQP problems, relaxation techniques offer a strategic alternative by simplifying MIQP into a more tractable Quadratic Programming (QP) problem. We first introduce an approach that facilitates the conversion of MIQP to QP by relaxing integer constraints into continuous domains and integrating integer conditions into the objective function using Lagrange multipliers. This dual application not only eases the computational burden but preserves the integrity of the original problem's structure. An innovative diagonalization technique applied to the covariance matrix further refines our method, enhancing the fit for integer variables, as Lagrange multipliers are inherently biased towards continuous variables. We present a comparative analysis of three distinct models, Linear, Dual, and Diagonal, each employing a unique relaxation strategy. Our research evaluates their efficacy in addressing the MIQP problem under cardinality constraints. In conjunction with heuristic methods, the refined solutions from our exact relaxation models serve as a starting point for further refinement using Genetic Algorithm and Neighborhood Searching Algorithm. This hybrid methodology yields results that not only rival but occasionally surpass those achieved by the latest models and the commercial solver CPLEX. Our findings endorse the potential of combining exact and heuristic techniques in portfolio optimization, marking a significant advancement in the field.", "title_embedding_index": 6307, "title_abs_embedding_index": 6332}, {"title": "MindSet: Vision. A toolbox for testing DNNs on key psychological experiments", "link_suffix": "/forum?id=eLOuG5L42a", "link": "https://openreview.net/forum?id=eLOuG5L42a", "pdf_link": "https://openreview.net/pdf?id=eLOuG5L42a", "keywords": "Datasets, Visual Perception, Psychology, Human Vision, Deep Neural Networks, Visual Illusion", "abstract": "Multiple benchmarks have been developed to assess the alignment between deep neural networks (DNNs) and human vision. In almost all cases these benchmarks are observational in the sense they are composed of behavioural and brain responses to naturalistic images that have not been manipulated to test hypotheses regarding how DNNs or humans perceive and identify objects. Here we introduce the toolbox MindSet: Vision, consisting of a collection of image datasets and related scripts designed to test DNNs on 30 psychological findings. In all experimental conditions, the stimuli are systematically manipulated to test specific hypotheses regarding human visual perception and object recognition. In addition to providing pre-generated datasets of images, we provide code to regenerate these datasets, offering many configurable parameters which greatly extend the dataset versatility for different research contexts, and code to facilitate the testing of DNNs on these image datasets using three different methods (similarity judgments, out-of-distribution classification, and decoder method), accessible via GitHub. We test ResNet-152 on each of these methods as an example of how the toolbox can be used.", "title_embedding_index": 6308, "title_abs_embedding_index": 6333}, {"title": "R-Bench: Are your Large Multimodel Model Robust to Real-world Corruption?", "link_suffix": "/forum?id=TNj5i5i3pB", "link": "https://openreview.net/forum?id=TNj5i5i3pB", "pdf_link": "https://openreview.net/pdf?id=TNj5i5i3pB", "keywords": "Large Multimodal Models, Robustness, User Generated Content, Perceptual Quality Corruption", "abstract": "The outstanding performance of Large Multimodal Models (LMMs) has made them widely applied in vision-related tasks. However, various corruptions in the real world mean that images will not be as ideal as in simulations, presenting significant challenges for the practical application of LMMs. To address this issue, we introduce R-Bench, a benchmark focused on theReal-world Robustness of LMMs. Specifically, we: (a) model the complete link from user capture to LMMs reception, comprising 33 corruption dimensions, including 7 steps according to the corruption sequence, and 7 groups based on low-level attributes; (b) collect reference/distorted image dataset before/after corruption, including 2,970 question-answer pairs with human labeling; (c) propose comprehensive evaluation for absolute/relative robustness and benchmark 20 mainstream LMMs. Results show that while LMMs can correctly handle the original reference images, their performance is not stable when faced with distorted images, and there is a significant gap in robustness compared to the human visual system. We hope that R-Bench will inspire improving the robustness of LMMs,extending them from experimental simulations to the real-world application.", "title_embedding_index": 6309, "title_abs_embedding_index": 6334}, {"title": "Sample-specific Noise Injection for Diffusion-based Adversarial Purification", "link_suffix": "/forum?id=KzokzKV4JK", "link": "https://openreview.net/forum?id=KzokzKV4JK", "pdf_link": "https://openreview.net/pdf?id=KzokzKV4JK", "keywords": "diffusion-based adversarial purification, adversarial purification, adversarial robustness, accuracy-robustness trade-off", "abstract": "Diffusion-based purification (DBP) methods aim to remove adversarial noise from the input sample by first injecting Gaussian noise through a forward diffusion process, and then recovering the clean example through a reverse generative process. In the above process, how much Gaussian noise is injected to the input sample is key to the success of DBP methods, which is controlled by a constant noise level $t^*$ for all samples in existing methods. In this paper, we discover that an optimal $t^*$ for each sample indeed could be different. Intuitively, the cleaner a sample is, the less the noise it should be injected, and vice versa. Motivated by this finding, we propose a new framework, called Sample-specific Score-aware Noise Injection (SSNI). Specifically, SSNI uses a pre-trained score network to estimate how much a data point deviates from the clean data distribution (i.e., score norms). Then, based on the magnitude of score norms, SSNI applies a reweighting function to adaptively adjust $t^*$ for each sample, achieving sample-specific noise injections. Empirically, incorporating our framework with existing DBP methods results in a notable improvement in both accuracy and robustness on CIFAR-10 and ImageNet-1K, highlighting the necessity to allocate distinct noise levels to different samples in DBP methods. Our code is available at:https://anonymous.4open.science/r/SSNI-F746.", "title_embedding_index": 6310, "title_abs_embedding_index": 6335}, {"title": "SpecFuse: Ensembling Large Language  Models via Next-Segment Prediction", "link_suffix": "/forum?id=lhLQpS33YL", "link": "https://openreview.net/forum?id=lhLQpS33YL", "pdf_link": "https://openreview.net/pdf?id=lhLQpS33YL", "keywords": "Ensemble LLMs, Next-Segment Prediction, Generative, open-domain instruction response", "abstract": "Ensembles of generative large language models (LLMs) can integrate the strengths of different LLMs to compensate for the limitations of individual models.\nHowever, recent work has focused on training an additional fusion model to combine complete responses from multiple LLMs, failing to tap into their collaborative potential to generate higher-quality responses.\nMoreover, as the additional fusion model is trained on a specialized dataset, these methods struggle with generalizing to open-domain queries from online users.\nIn this paper, we propose SpecFuse, a novel ensemble framework that outputs the fused result by iteratively producing the next segment through collaboration among LLMs.\nThis is achieved through cyclic execution of its inference and verification components.\nIn each round, the inference component invokes each base LLM to generate candidate segments in parallel, and the verify component calls these LLMs again to predict the ranking of the segments. \nThe top-ranked segment is then broadcast to all LLMs, encouraging them to generate higher-quality segments in the next round. \nThis approach also allows the base LLMs to be plug-and-play, without any training or adaptation, avoiding generalization limitations.\nFurthermore, to conserve computational resources, we propose a model exit mechanism that dynamically excludes models exhibiting poor performance in previous rounds during each query response.\nIn this way, it effectively reduces the number of model calls while maintaining overall performance.\nWe conduct extensive experiments using ensembles of five LLMs with different architectures across six benchmarks, covering instruction-response, reasoning, commonsense, and instruction-following tasks. The experimental results demonstrate that SpecFuse consistently enhances performance across all benchmarks, with RougeL scores improving by $+3.1$ on the Chinese and $+3.0$ on the English human-computer interaction benchmarks. Furthermore, the model exit mechanism reduces the average models invoked per round from $5$ to $2.4$, with only a slight reduction in performance.", "title_embedding_index": 6311, "title_abs_embedding_index": 6336}, {"title": "Joint Gradient Balancing for Data Ordering in Finite-Sum Multi-Objective Optimization", "link_suffix": "/forum?id=rdAbEn5DZt", "link": "https://openreview.net/forum?id=rdAbEn5DZt", "pdf_link": "https://openreview.net/pdf?id=rdAbEn5DZt", "keywords": "multi-objective optimization", "abstract": "In finite-sum optimization problems, the sample orders for parameter updates can significantly influence the convergence rate of optimization algorithms. While numerous sample ordering techniques have been proposed in the context of single-objective optimization, the problem of sample ordering in finite-sum multi-objective optimization has not been thoroughly explored. To address this gap, we propose a sample ordering method called JoGBa, which finds the sample orders for multiple objectives by jointly performing online vector balancing on the gradients of all objectives. Our theoretical analysis demonstrates that this approach outperforms the standard baseline of random ordering and accelerates the convergence rate for the MGDA algorithm. Empirical evaluation across various datasets with different multi-objective optimization algorithms further demonstrates that JoGBa can achieve faster convergence and superior final performance than other data ordering strategies.", "title_embedding_index": 6312, "title_abs_embedding_index": 6337}, {"title": "SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs", "link_suffix": "/forum?id=HmwneoGoy9", "link": "https://openreview.net/forum?id=HmwneoGoy9", "pdf_link": "https://openreview.net/pdf?id=HmwneoGoy9", "keywords": "LLM, Sparse Attention, long-context LLM", "abstract": "Attention is the cornerstone of modern Large Language Models (LLMs). Yet its quadratic complexity limits the efficiency and scalability of LLMs, especially for those with a long-context window. A promising approach addressing this limitation is to leverage the sparsity in attention. However, existing sparsity-based solutions predominantly rely on predefined patterns or heuristics to approximate sparsity. This practice falls short to fully capture the dynamic nature of attention sparsity in language-based tasks. \nThis paper argues that attention sparsity should be learned rather than predefined. To this end, we design SeerAttention, a new Attention mechanism that augments the conventional attention with a learnable gate that adaptively selects significant blocks in an attention map and deems the rest blocks sparse.\nSuch block-level sparsity effectively balances accuracy and speedup.\nTo enable efficient learning of the gating network, we develop a customized FlashAttention implementation that extracts the block-level ground truth of attention map with minimum overhead.\nSeerAttention not only applies to post-training, but also excels in long-context fine-tuning.\nOur results show that at post-training stages, SeerAttention significantly outperforms state-of-the-art static or heuristic-based sparse attention methods, while also being more versatile and flexible to adapt to varying context lengths and sparsity ratios.\nWhen applied to long-context fine-tuning with YaRN, SeerAttention can achieve a remarkable 90% sparsity ratio at a 32k context length with minimal perplexity loss, offering a $5.67\\times$ speedup over FlashAttention-2.", "title_embedding_index": 6313, "title_abs_embedding_index": 6338}, {"title": "Almost sure convergence of stochastic Hamiltonian descent methods", "link_suffix": "/forum?id=5uUr3WFmyZ", "link": "https://openreview.net/forum?id=5uUr3WFmyZ", "pdf_link": "https://openreview.net/pdf?id=5uUr3WFmyZ", "keywords": "Stochastic optimization, clipping methods, non-convex optimization", "abstract": "Gradient normalization and soft clipping are two popular techniques for tackling instability issues and improving convergence of stochastic gradient descent (SGD) with momentum. \nIn this article, we study these types of methods through the lens of dissipative Hamiltonian systems. Gradient normalization and certain types of soft clipping algorithms can be seen as (stochastic) implicit-explicit Euler discretizations of dissipative Hamiltonian systems, where the kinetic energy function determines the type of clipping that is applied.\nWe make use of dynamical systems theory to show in a unified way that all of these schemes converge to stationary points of the objective function, almost surely, in several different settings:\na) for $L-$smooth objective functions,\nwhen the variance of the stochastic gradients is possibly infinite\nb) under the $(L_0,L_1)-$smoothness assumption, for heavy-tailed noise with bounded variance and c) for $(L_0,L_1)-$smooth functions in the empirical risk minimization setting, when the variance is possibly infinite but the expectation is finite.", "title_embedding_index": 6314, "title_abs_embedding_index": 6339}, {"title": "Node Identifiers: Compact, Discrete Representations for Efficient Graph Learning", "link_suffix": "/forum?id=t9lS1lX9FQ", "link": "https://openreview.net/forum?id=t9lS1lX9FQ", "pdf_link": "https://openreview.net/pdf?id=t9lS1lX9FQ", "keywords": "Graph Neural Networks, Graph Tokenizers, Symbolic Compression, Efficient Graph Learning", "abstract": "We present a novel end-to-end framework that generates highly compact (typically 6-15 dimensions), discrete (int4 type), and interpretable node representations\u2014termed node identifiers (node IDs)\u2014to tackle inference challenges on large-scale graphs. By employing vector quantization, we compress continuous node embeddings from multiple layers of a Graph Neural Network (GNN) into discrete codes, applicable under both self-supervised and supervised learning paradigms. These node IDs capture high-level abstractions of graph data and offer interpretability that traditional GNN embeddings lack. Extensive experiments on 34 datasets, encompassing node classification, graph classification, link prediction, and attributed graph clustering tasks, demonstrate that the generated node IDs significantly enhance speed and memory efficiency while achieving competitive performance compared to current state-of-the-art methods. We provide our code in the supplementary material and will make it publicly available upon acceptance.", "title_embedding_index": 6315, "title_abs_embedding_index": 6340}, {"title": "Geometric Spatiotemporal Transformer to Simulate Long-Term Physical Dynamics", "link_suffix": "/forum?id=LOBhVTtVnc", "link": "https://openreview.net/forum?id=LOBhVTtVnc", "pdf_link": "https://openreview.net/pdf?id=LOBhVTtVnc", "keywords": "Equivariance, Spatio-Temporal Transformer, Physical Dynamics", "abstract": "Physical dynamics simulation plays a crucial role in various real-world applications. In this paper, we explore the potential of leveraging Transformers by framing the task as autoregressive next-graph prediction based on spatiotemporal graph inputs. To achieve this, we propose Geometric Spatiotemporal Transformers (GSTs), which adopt the expressive encoder-decoder architecture of traditional Transformers. At the core of GSTs are equivariant spatiotemporal blocks that alternate between spatial and temporal modules while preserving E(3) symmetries. Additionally, we introduce the Temporal Difference Graph (TDG), derived from the difference between the last two frames of historical input, to capture global dynamic patterns and mitigate cumulative errors in long-term prediction tasks. Unlike existing Graph Neural Network (GNN) methods, GSTs can process full input sequences of arbitrary lengths to effectively capture long-term context, and address cumulative errors over long-term rollouts thanks to the TDG mechanism. Our method achieves state-of-the-art  performance across multiple challenging physical systems at various scales (molecular-, protein-, and macro-level), demonstrating the robust dynamics simulation capabilities.", "title_embedding_index": 6316, "title_abs_embedding_index": 6341}, {"title": "Latent Bayesian Optimization via Autoregressive Normalizing Flows", "link_suffix": "/forum?id=ZCOwwRAaEl", "link": "https://openreview.net/forum?id=ZCOwwRAaEl", "pdf_link": "https://openreview.net/pdf?id=ZCOwwRAaEl", "keywords": "Bayesian optimization, normalizing flow", "abstract": "Bayesian Optimization (BO) has been recognized for its effectiveness in optimizing expensive and complex objective functions.\nRecent advancements in Latent Bayesian Optimization (LBO) have shown promise by integrating generative models such as variational autoencoders (VAEs) to manage the complexity of high-dimensional and structured data spaces.\nHowever, existing LBO approaches often suffer from the value discrepancy problem, which arises from the reconstruction gap between latent and input spaces.\nThis value discrepancy problem propagates errors throughout the optimization process, which induces suboptimal optimization outcomes.\nTo address this issue, we propose a Normalizing Flow-based Bayesian Optimization (NF-BO), which utilizes normalizing flow as a generative model to establish accurate and one-to-one mappings between latent and input spaces.\nTo deal with sequence-based inputs, we introduce SeqFlow, an autoregressive sequence-specialized normalizing flow model designed to maintain one-to-one mappings between the input and latent spaces. \nMoreover, we develop a token-level adaptive candidate sampling strategy that dynamically adjusts the exploration probability of each token based on the token-level importance in the optimization process.\nThrough extensive experiments, our NF-BO method demonstrates superior performance in molecule generation tasks, significantly outperforming traditional optimization methods and existing LBO approaches.", "title_embedding_index": 6317, "title_abs_embedding_index": 6342}, {"title": "Preference Optimization as Probabilistic Inference", "link_suffix": "/forum?id=4FVGowGzQb", "link": "https://openreview.net/forum?id=4FVGowGzQb", "pdf_link": "https://openreview.net/pdf?id=4FVGowGzQb", "keywords": "Preference Optimization, Reinforcement Learning, Probabilistic Inference, Positive feedback, Negative Feedback", "abstract": "Existing preference optimization methods are mainly designed for directly learning from human feedback with the assumption that paired examples (preferred vs. dis-preferred) are available. In contrast, we propose a method that can leverage unpaired preferred or dis-preferred examples, and works even when only one type of feedback (positive or negative) is available. This flexibility allows us to apply it in scenarios with varying forms of feedback and models, including training generative language models based on human feedback as well as training policies for sequential decision-making problems, where learned (value) functions are available. Our approach builds upon the probabilistic framework introduced in (Dayan & Hinton, 1997), which proposes to use expectation-maximization (EM) to directly optimize the probability of preferred outcomes (as opposed to classic expected reward maximization). To obtain a practical algorithm, we identify and address a key limitation in current EM-based methods: when applied to preference optimization, they solely maximize the likelihood of preferred examples, while neglecting dis-preferred samples. We show how one can extend EM algorithms to explicitly incorporate dis-preferred outcomes, leading to a novel, theoretically grounded, preference optimization algorithm that offers an intuitive and versatile way to learn from both positive and negative feedback.", "title_embedding_index": 6318, "title_abs_embedding_index": 6343}, {"title": "Since Faithfulness Fails: The Performance Limits of Neural Causal Discovery", "link_suffix": "/forum?id=ToveGL9vRN", "link": "https://openreview.net/forum?id=ToveGL9vRN", "pdf_link": "https://openreview.net/pdf?id=ToveGL9vRN", "keywords": "causal discovery, faithfulness assumption, neural networks", "abstract": "Neural causal discovery methods have recently improved in terms of scalability and computational efficiency.\nHowever, there are still opportunities for improving their accuracy in uncovering causal structures.\nWe argue that the key obstacle in unlocking this potential is the faithfulness assumption, commonly used by contemporary neural approaches. We show that this assumption, which is often not satisfied in real-world or synthetic datasets, limits the effectiveness of existing methods. We evaluate\nthe impact of\nfaithfulness violations both qualitatively and quantitatively and provide a unified evaluation framework to facilitate further research.", "title_embedding_index": 6319, "title_abs_embedding_index": 6344}, {"title": "FSEO: A Few-Shot Evolutionary Optimization Framework for Expensive Multi-Objective Optimization and Constrained Optimization", "link_suffix": "/forum?id=ACfDWffsOP", "link": "https://openreview.net/forum?id=ACfDWffsOP", "pdf_link": "https://openreview.net/pdf?id=ACfDWffsOP", "keywords": "few-shot optimization, expensive multi-objective optimization, expensive constrained optimization, meta-learning, Gaussian Processes, surrogate-assisted evolutionary optimization.", "abstract": "Meta-learning has been demonstrated to be useful to improve the sampling efficiency of Bayesian optimization (BO) and surrogate-assisted evolutionary algorithms (SAEAs) when solving expensive optimization problems (EOPs). However, existing studies focuses on only single-objective optimization, leaving other expensive optimization scenarios unconsidered. We propose a generalized few-shot evolutionary optimization (FSEO) framework and focus on its performance on two common expensive optimization scenarios: multi-objective EOPs (EMOPs) and constrained EOPs (ECOPs). We develop a novel meta-learning modeling approach to train surrogates for our FSEO framework, an accuracy-based update strategy is designed to adapt surrogates during the optimization process. The surrogates in FSEO framework combines neural network with Gaussian Processes (GPs), their network parameters and some parameters of GPs \nrepresent useful experience and are meta-learned across related optimization tasks, the remaining GPs parameters are task-specific parameters that represent unique features of the target task. We demonstrate that our FSEO framework is able to improve sampling efficiency on both EMOP and ECOP. Empirical conclusions are made to guide the application of our FSEO framework.", "title_embedding_index": 6320, "title_abs_embedding_index": 6345}, {"title": "Revisiting Covariate and Hypothesis Roles in ITE Estimation: A New Approach Using Laplacian Regularization", "link_suffix": "/forum?id=mvAL02hEJg", "link": "https://openreview.net/forum?id=mvAL02hEJg", "pdf_link": "https://openreview.net/pdf?id=mvAL02hEJg", "keywords": "Individual Treatment Effect (ITE), Conditional Average Treatment Effect (CATE), Covariate Shift, Laplacian Regularization, Causal Inference", "abstract": "The recent surge in data availability across many fields, such as medicine, social science, and marketing, has brought to the forefront the problem of estimating Individual Treatment Effect (ITE) from observational data to effectively tailor treatment to personalized characteristics. ITE estimation is known to be a challenging task because we can only observe the outcome with or without treatment, but never both. Moreover, observational datasets exhibit selection bias induced by the treatment assignment policy. In this paper, we present a new approach consisting of two novel aspects. First, we depart from conventional approaches that minimize the covariate shift. Instead, we incorporate it as a crucial element in ITE estimation, recognizing that it stems from highly predictive features that exhibit significant imbalance in observational data. Second, unlike existing methods, our approach utilizes hypothesis functions to directly estimate outcomes under covariate shift, enhancing reliability across observed and unobserved outcomes. To support this approach theoretically, we derive a new upper bound of the expected ITE loss and show that it explicitly depends on the discrepancy between the hypothesis functions, which are absent from the objectives of existing methods. Based on this new approach, we present LITE: Laplacian Individual Treatment Effect, a novel method that leverages Laplacian-regularized representation and incorporates both the covariate shift and the hypothesis functions for ITE estimation, effectively bridging observed and unobserved outcomes. We demonstrate LITE on illustrative simulations and two leading benchmarks, where we show superior results compared to state-of-the-art methods.", "title_embedding_index": 6321, "title_abs_embedding_index": 6346}, {"title": "Spatio-temporal Diffusion Transformer for Action Recognition", "link_suffix": "/forum?id=ICR3swcnaa", "link": "https://openreview.net/forum?id=ICR3swcnaa", "pdf_link": "https://openreview.net/pdf?id=ICR3swcnaa", "keywords": "Video action recognition, fine-grained action, information diffusion, spatiotemporal feature", "abstract": "Video action recognition has aroused the research interest of many scholars, and has been widely used in public surveillance, video review, sports events and other fields. However, the high similarity of video background and the long time span of video action bring serious challenges to action recognition. In this work, we propose a spatio-temporal diffusion transformer (STD-Former) to improve the recognition accuracy of long-distance and fine-grained actions. STD-Former utilizes a two-branch network to extract the spatiotemporal and temporal information of video respectively. First, we construct a parallel transformer module to capture the spatiotemporal feature of actions through a two-dimensional convolutional structure in the spatiotemporal branch. Secondly, a cross transformer module integrating the feature of spatiotemporal branch is presented to explore the long-distance temporal dependency relationship of video actions in the temporal branch. In addition, we design a novel plug-and-play spatiotemporal diffusion module, which feeds back the feature extracted from the temporal branch to the spatiotemporal branch, thus enhancing the action capture ability of model. Finally, in order to learn the fine-grained action information of adjacent video sequences, another plug-and-play significant motion excitation module is established by converting the spatial information of adjacent video frames into the motion feature. The experimental results on Something Something V1 and V2 datasets demonstrate that STD-Former can more accurately identify the fine-grained action and has favorable robustness than the current state-of-the-art action recognition models.", "title_embedding_index": 6322, "title_abs_embedding_index": 6347}, {"title": "Ego-Foresight: Self-supervised Agent Visuomotor Prediction for Efficient RL", "link_suffix": "/forum?id=FJ8Q11j3p0", "link": "https://openreview.net/forum?id=FJ8Q11j3p0", "pdf_link": "https://openreview.net/pdf?id=FJ8Q11j3p0", "keywords": "Reinforcement Learning, Robotics, Prediction, Disentangled Representations", "abstract": "Despite the significant advancements in Deep Reinforcement Learning (RL) observed in the last decade, the amount of training experience necessary to learn effective policies remains one of the primary concerns both in simulated and real environments. Looking to solve this issue, previous work has shown that improved training efficiency can be achieved by separately modeling agent and environment, but usually requiring a supervisory agent mask. In contrast to RL, humans can perfect a new skill from a very small number of trials and in most cases do so without a supervisory signal, making neuroscientific studies of human development a valuable source of inspiration for RL. In particular, we explore the idea of motor prediction, which states that humans develop an internal model of themselves and of the consequences that their motor commands have on the immediate sensory inputs. Our insight is that the movement of the agent provides a cue that allows the duality between agent and environment to be learned. To instantiate this idea, we present Ego-Foresight, a self supervised method for disentangling agent and environment based on motion and prediction. Our main finding is that visuomotor prediction of the agent provides good feature representations for the underlying RL algorithm. To test our approach, we integrate Ego-Foresight with a model-free RL algorithm to solve simulated robotic manipulation tasks, showing its ability to improve efficiency and performance in different tasks while making strides towards real-world RL applications, by removing the need for costly supervisory signals.", "title_embedding_index": 6323, "title_abs_embedding_index": 6348}, {"title": "UniDetox: Universal Detoxification of Large Language Models via Dataset Distillation", "link_suffix": "/forum?id=eLLBILFRsA", "link": "https://openreview.net/forum?id=eLLBILFRsA", "pdf_link": "https://openreview.net/pdf?id=eLLBILFRsA", "keywords": "Large Language Models, Detoxification, Safety, Fairness", "abstract": "We present UniDetox, a universally applicable method designed to mitigate toxicity across various large language models (LLMs).\nPrevious detoxification methods are typically model-specific, addressing only individual models or model families, and require careful hyperparameter tuning due to the trade-off between detoxification efficacy and language modeling performance. \nIn contrast, UniDetox provides a detoxification technique that can be universally applied to a wide range of LLMs without the need for separate model-specific tuning. \nSpecifically, we propose a novel and efficient dataset distillation technique for detoxification using contrastive decoding. \nThis approach distills detoxifying representations in the form of synthetic text data, enabling universal detoxification of any LLM through fine-tuning with the distilled text. \nOur experiments demonstrate that the detoxifying text distilled from GPT-2 can effectively detoxify larger models, including OPT, Falcon, and LLaMA-2. \nFurthermore, UniDetox eliminates the need for separate hyperparameter tuning for each model, as a single hyperparameter configuration can be seamlessly applied across different models. \nAdditionally, analysis of the detoxifying text reveals a reduction in politically biased content, providing insights into the attributes necessary for effective detoxification of LLMs.", "title_embedding_index": 6324, "title_abs_embedding_index": 6349}]
[{"title": "EffoVPR: Effective Foundation Model Utilization for Visual Place Recognition", "link_suffix": "/forum?id=NSpe8QgsCB", "link": "https://openreview.net/forum?id=NSpe8QgsCB", "pdf_link": "https://openreview.net/pdf?id=NSpe8QgsCB", "keywords": "Visual Place Recognition, Geo-Localization, Re-ranking, Vision Transformer, Self-Attention", "abstract": "The task of Visual Place Recognition (VPR) is to predict the location of a query image from a database of geo-tagged images. Recent studies in VPR have highlighted the significant advantage of employing pre-trained foundation models like DINOv2 for the VPR task. However, these models are often deemed inadequate for VPR without further fine-tuning on VPR-specific data.\nIn this paper, we present an effective approach to harness the potential of a foundation model for VPR. We show that features extracted from self-attention layers can act as a powerful re-ranker for VPR, even in a zero-shot setting. Our method not only outperforms previous zero-shot approaches but also introduces results competitive with several supervised methods.\nWe then show that a single-stage approach utilizing internal ViT layers for pooling can produce global features that achieve state-of-the-art performance, with impressive feature compactness down to 128D. Moreover, integrating our local foundation features for re-ranking further widens this performance gap. Our method also demonstrates exceptional robustness and generalization, setting new state-of-the-art performance, while handling challenging conditions such as occlusion, day-night transitions, and seasonal variations.", "title_embedding_index": 17450, "title_abs_embedding_index": 17475}, {"title": "Impact of Regularization on Calibration and Robustness: From the Representation Space Perspective", "link_suffix": "/forum?id=Ni4jNyroJZ", "link": "https://openreview.net/forum?id=Ni4jNyroJZ", "pdf_link": "https://openreview.net/pdf?id=Ni4jNyroJZ", "keywords": "Soft labels, regularization, representation space, image classification", "abstract": "Recent studies have shown that regularization techniques using soft labels, e.g., label smoothing, Mixup, and CutMix, not only enhance image classification accuracy but also improve model calibration and robustness against adversarial attacks. However, the underlying mechanisms of such improvements remain underexplored. In this paper, we offer a novel explanation from the perspective of the representation space. Our investigation first reveals that the decision regions in the representation space form cone-like shapes around the origin after training regardless of the presence of regularization. However, applying regularization causes changes in the distribution of features (or representation vectors obtained at the penultimate layer). The magnitudes of the representation vectors are reduced and subsequently the cosine similarities between the representation vectors and the class centers (minimal loss points for each class) become higher, which acts as a central mechanism inducing improved calibration and robustness. Our findings provide new insights into the characteristics of the high-dimensional representation space in relation to training and regularization using soft labels.", "title_embedding_index": 17451, "title_abs_embedding_index": 17476}, {"title": "AutoCATE: End-to-End, Automated Treatment Effect Estimation", "link_suffix": "/forum?id=nSFVJkWYhr", "link": "https://openreview.net/forum?id=nSFVJkWYhr", "pdf_link": "https://openreview.net/pdf?id=nSFVJkWYhr", "keywords": "Treatment Effect Estimation, Causal Inference, AutoML", "abstract": "Accurate estimation of heterogeneous treatment effects is critical in domains such as healthcare, economics, and education. While machine learning (ML) has led to significant advances in estimating conditional average treatment effects (CATE), real-world adoption of these methods remains limited due to the complexity of implementing, tuning, and validating them. To this end, we advocate for a more holistic view on the development of ML pipelines for CATE estimation through automated, end-to-end protocols. We formalize the search for an optimal pipeline as a counterfactual Combined Algorithm Selection and Hyperparameter optimization (CASH) problem. We introduce \\texttt{AutoCATE}, the first automated solution tailored for CATE estimation that addresses this problem based on protocols for evaluation, estimation, and ensembling. Our experiments show how AutoCATE allows for comparing different protocols, with the final configuration outperforming common strategies. We provide AutoCATE as an open-source software package to help practitioners and researchers develop ML pipelines for CATE estimation.", "title_embedding_index": 17452, "title_abs_embedding_index": 17477}, {"title": "Debiased Imbalanced Pseudo-Labeling for Generalized Category Discovery", "link_suffix": "/forum?id=JRcfgNg2ZJ", "link": "https://openreview.net/forum?id=JRcfgNg2ZJ", "pdf_link": "https://openreview.net/pdf?id=JRcfgNg2ZJ", "keywords": "Generalized Category Discovery, Pseudo-Labeling", "abstract": "Generalized Category Discovery (GCD) is a challenging task that aims to recognize seen and novel categories within unlabeled data by leveraging labeled data. \nDesigning a prototype classifier to identify unlabeled samples instead of relying on traditional time-consuming clustering is well recognized as a milestone in GCD.However, we discover there exists a bias in this classifier: some seen categories are mistakenly classified as novel ones, leading to imbalanced pseudo-labeling during classifier learning.\nBased on this finding, we identify the low discriminability between seen and novel prototypes as the key issue.\nTo address this issue, we propose DebiasGCD, an effective debiasing method that integratesdynamic prototype debiasing(DPD) andlocal representation alignment(LRA).\nDPD dynamically maintains inter-prototype margins, encouraging the network to strengthen the learning of class-specific features and enhance prototype discrimination.\nAdditionally, LRA promotes local representation learning, enabling DPD to capture subtle details that further refine the understanding of class-specific features.\nIn this way, it successfully improves prototype discriminability and \ngenerates more reliable predictions for seen classes.\nExtensive experiments validate that our method effectively mitigates pseudo-labeling bias across all datasets, especially on fine-grained ones. For instance, it delivers a 10.7% boost on `Old' classes in CUB. Our code is available at\uff1ahttps://anonymous.4open.science/r/DebiasGCD-34F0.", "title_embedding_index": 17453, "title_abs_embedding_index": 17478}, {"title": "H2IL-MBOM: A Hierarchical World Model Integrating Intent and Latent Strategy as Opponent Modeling in Multi-UAV Game", "link_suffix": "/forum?id=9TMbdO870O", "link": "https://openreview.net/forum?id=9TMbdO870O", "pdf_link": "https://openreview.net/pdf?id=9TMbdO870O", "keywords": "Multi-UAV Game, Opponent modeling, World model, Multi-agent Reinforcement Learning", "abstract": "In the mixed cooperative-competitive scenario, the uncertain decisions of agents on both sides not only render learning non-stationary but also pose a threat to each other's security. Existing methods either predict policy beliefs based on opponents' interactive actions, goals, and rewards or predict trajectories and intents solely from local historical observations. However, the above private information is unavailable and these methods neglect the underlying dynamics of the environment and relationship between intentions, latent strategies, actions, and trajectories for both sides. To address these challenges, we propose a Hierarchical Interactive Intent-Latent-Strategy-Aware World Model based Opponent Model (H2IL-MBOM) and the Mutual Self-Observed Adversary Reasoning PPO (MSOAR-PPO) to enables both parties to dynamically and interactively predict multiple intentions and latent strategies, along with their trajectories based on self observation. Concretely, the high-level world model fuses related observations regarding opponents and multi-learnable intention queries to anticipate future intentions and trajectories of opponents and incorporate anticipated intentions into the low-level world model to infer how opponents' latent strategies react and their influence on the trajectories of cooperative agents. We validate the effectiveness of the method and demonstrate its superior performance through comparisons with state-of-the-art model-free reinforcement learning and opponent modeling methods in more challenging settings involving multi-agent close-range air-combat environments with missiles.", "title_embedding_index": 17454, "title_abs_embedding_index": 17479}, {"title": "Linear combinations of Gaussian latents in generative models: interpolation and beyond", "link_suffix": "/forum?id=n5PrId7pk5", "link": "https://openreview.net/forum?id=n5PrId7pk5", "pdf_link": "https://openreview.net/pdf?id=n5PrId7pk5", "keywords": "generative models, diffusion models, latent space interpolation, latent representations", "abstract": "Sampling from generative models has become a crucial tool for applications like data synthesis and augmentation. Diffusion, Flow Matching and Continuous Normalizing Flows have shown effectiveness across various modalities, and rely on Gaussian latent variables for generation. For search-based or creative applications that require additional control over the generation process, it has become common to manipulate the latent variable directly. However, existing approaches for performing such manipulations (e.g. interpolation or forming low-dimensional representations) only work well in special cases or are network or data-modality specific. We propose Combination of Gaussian variables (COG) as a general purpose interpolation method that is easy to implement yet outperforms recent sophisticated methods. Moreover, COG naturally addresses the broader task of forming general linear combinations of latent variables, allowing the construction of subspaces of the latent space, dramatically simplifying the creation of expressive low-dimensional spaces of high-dimensional objects.", "title_embedding_index": 17455, "title_abs_embedding_index": 17480}, {"title": "COT: Consistent Optimal Transport with Applications to Visual Matching and Travelling Salesman Problems", "link_suffix": "/forum?id=9WG1ga39Dq", "link": "https://openreview.net/forum?id=9WG1ga39Dq", "pdf_link": "https://openreview.net/pdf?id=9WG1ga39Dq", "keywords": "Optimal Transport, Entropic Regularization, Cycle-Consistency, Matching, Travelling Salesman Problems", "abstract": "This paper generalizes the vanilla Optimal transport (OT) to the so-called Consistent Optimal Transport (COT) accepting more than two measures as input with transport consistency. We formulate the problem as minimizing the transport costs between each pair of measures and meanwhile requiring cycle-consistency among measures. We present both the Monge and Kantorovich formulations of COT and obtain the approximate solution with added entropic and consistency regularization, for which an iterative projection (RCOT-Sinkhorn) algorithm is devised to improve the Sinkhorn algorithm. We show the superiority on the task of visual multi-point matching, in which our COT solver directly utilizes the cosine distance between learned features of points obtained from off-the-shelf graph matching neural networks as the pairwise cost. We leverage the algorithm to learn multiple matching and the experiments show a great improvement without more feature training. Furthermore, based on COT, we propose a new TSP formulation called TSP-COT and also adopt regularization to relax the optimization and use the modified RCOT-Sinkhorn algorithm to get the probability matrix of TSP routing. Then post-process search method  is adopted to get the TSP routs and the experiments show the superiority of our method. The code will be available.", "title_embedding_index": 17456, "title_abs_embedding_index": 17481}, {"title": "SOREL: A Stochastic Algorithm for Spectral Risks Minimization", "link_suffix": "/forum?id=pdF86dyoS6", "link": "https://openreview.net/forum?id=pdF86dyoS6", "pdf_link": "https://openreview.net/pdf?id=pdF86dyoS6", "keywords": "spectral risk, conditional Value-at-Risk, stochastic optimization, convex optimization, fair machine learning", "abstract": "The spectral risk has wide applications in machine learning, especially in real-world decision-making, where people are concerned with more than just average model performance. By assigning different weights to the losses of different sample points, rather than the same weights as in the empirical risk, it allows the model's performance to lie between the average performance and the worst-case performance. In this paper, we propose SOREL, the first stochastic gradient-based algorithm with convergence guarantees for spectral risks minimization. Previous approaches often rely on smoothing the spectral risk by adding a strongly concave function, thereby lacking convergence guarantees for the original spectral risk.  We theoretically prove that our algorithm achieves a near-optimal rate of $\\widetilde{O}(1/\\sqrt{\\epsilon})$ to obtain an $\\epsilon$-optimal solution in terms $\\epsilon$. Experiments on real datasets show that our algorithm outperforms existing ones in most cases, both in terms of runtime and sample complexity.", "title_embedding_index": 17457, "title_abs_embedding_index": 17482}, {"title": "Object-aware Conditional Alignment for Cross-domain Counting", "link_suffix": "/forum?id=USGY5t7fwG", "link": "https://openreview.net/forum?id=USGY5t7fwG", "pdf_link": "https://openreview.net/pdf?id=USGY5t7fwG", "keywords": "Counting, domain adaptation", "abstract": "Object counting is an important task in computer vision with many real-world applications. In practical settings, factors such as lighting conditions and object density can vary dramatically, leading to distribution shifts then causing inaccurate counting. We found that existing domain adaptation (DA) methods cannot be directly applied to the counting task, as they usually assume changes across different domains are task-irrelevant and focus on utilizing domain-invariant features for prediction. However, in object counting tasks, changes in object density which could happen across domains are task-relevant and cannot be ignored. Therefore, applying existing DA methods to the counting task can ignore the information about density changes, resulting in unreliable counting. To address this limitation, we propose the Binary Alignment Network (BiAN). Unlike traditional DA methods that align distributions of entire image representations, BiAN segments objects of interest and aligns the distributions of the object-specific features across domains. This targeted alignment allows us to disregard irrelevant features, such as lighting conditions, while preserving essential information about changes in object density. We theoretically demonstrate that BiAN achieves superior adaptability in counting tasks by introducing conditional alignment\u2014aligning features conditioned on the presence of objects. Extensive experiments on two distinct counting tasks and eight dataset combinations show that BiAN outperforms state-of-the-art methods.", "title_embedding_index": 17458, "title_abs_embedding_index": 17483}, {"title": "Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?", "link_suffix": "/forum?id=Cnwz9jONi5", "link": "https://openreview.net/forum?id=Cnwz9jONi5", "pdf_link": "https://openreview.net/pdf?id=Cnwz9jONi5", "keywords": "Reinforcement Learning from Human Feedback; Reward Model;", "abstract": "Reward Models (RMs) are crucial for aligning language models with human preferences. \nCurrently, the evaluation of RMs depends on measuring accuracy against a validation set of manually annotated preference data.\nAlthough this method is straightforward and widely adopted, the relationship between RM accuracy and downstream policy performance remains under-explored.\nIn this work, we conduct experiments in a synthetic setting to investigate how differences in RM measured by accuracy translate into gaps in optimized policy performance.\nOur findings reveal that while there is a weak positive correlation between accuracy and downstream performance, policies optimized towards RMs with similar accuracy can exhibit quite different performance.\nMoreover, we discover that the way of measuring accuracy significantly impacts its ability to predict the final policy performance. \nThrough the lens of Regressional Goodhart\u2019s effect, we identify the existence of exogenous variables impacting the relationship between RM quality measured by accuracy and policy model capability.\nThis underscores the inadequacy of relying solely on accuracy to reflect their impact on policy optimization.", "title_embedding_index": 17459, "title_abs_embedding_index": 17484}, {"title": "Proactive Privacy Amnesia for Large Language Models: Safeguarding PII with Negligible Impact on Model Utility", "link_suffix": "/forum?id=io8uRPYktn", "link": "https://openreview.net/forum?id=io8uRPYktn", "pdf_link": "https://openreview.net/pdf?id=io8uRPYktn", "keywords": "Large language models, Personal identifiable information, Protect private data leakage", "abstract": "With the rise of large language models (LLMs), increasing research has recognized\ntheir risk of leaking personally identifiable information (PII) under malicious\nattacks. Although efforts have been made to protect PII in LLMs, existing methods\nstruggle to balance privacy protection with maintaining model utility. In this paper,\ninspired by studies of amnesia in cognitive science, we propose a novel approach,\nProactive Privacy Amnesia (PPA), to safeguard PII in LLMs while preserving their\nutility. This mechanism works by actively identifying and forgetting key memories\nmost closely associated with PII in sequences, followed by a memory implanting\nusing suitable substitute memories to maintain the LLM\u2019s functionality. We conduct\nevaluations across multiple models to protect common PII, such as phone numbers\nand physical addresses, against prevalent PII-targeted attacks, demonstrating the\nsuperiority of our method compared with other existing defensive techniques. The\nresults show that our PPA method completely eliminates the risk of phone number\nexposure by 100% and significantly reduces the risk of physical address exposure\nby 9.8% \u2013 87.6%, all while maintaining comparable model utility performance.", "title_embedding_index": 17460, "title_abs_embedding_index": 17485}, {"title": "ON THE CONVERGENCE OF CYCLIC HIERARCHICAL FEDERATED LEARNING WITH HETEROGENEOUS DATA", "link_suffix": "/forum?id=PhLCPYsHCw", "link": "https://openreview.net/forum?id=PhLCPYsHCw", "pdf_link": "https://openreview.net/pdf?id=PhLCPYsHCw", "keywords": "hierarchical federated learning, convergence analysis, cyclic pattern", "abstract": "Hierarchical Federated Learning (HFL) advances the classic Federated Learning (FL) by introducing the multi-layer architecture between clients and the central server, in which edge servers aggregate models from respective clients and further send to the central server. Instead of directly uploading each update from  clients for aggregation, the HFL not only reduces the communication and computational overhead but also greatly enhances the scalability of supporting a massive number of clients. When HFL operates for applications having a large-scale clients, edge servers train their models in a cyclic pattern (a ring architecture) as opposed to the star-type of architecture where each edge develops their own models independently.We refer it as Cyclic HFL(CHFL). Driven by its promising feature of handling data heterogeneity and resiliency, CHFL has a great potential to be deployed in practice. Unfortunately, the thorough convergence analysis on CHFL remains lacking, especially considering the widely-existing data heterogeneity issue among clients. To the best of our knowledge, we are the first to provide a theoretical convergence analysis for CHFL in strongly convex, general convex, and non-convex objectives. Our results demonstrate the convergence rate are $\\tilde{\\mathcal{O}}(1/MNRKT)$ for strongly convex objective, $\\mathcal{O}(1/\\sqrt{MNRKT})$ for general convex objective, and $\\mathcal{O}(1/\\sqrt{MNRKT})$ for non-convex objective, under standard assumptions. Here, $M$ is the number of edge servers, $N$ is the number of clients in edge, $K$ is local steps in client, and $R$ is the edge training round. Through extensive experiments on real-world datasets, besides validating our theoretical findings, we further show CHFL achieves a comparable or superior performance when accounting for both inter- and intra-edge data heterogeneity.", "title_embedding_index": 17461, "title_abs_embedding_index": 17486}, {"title": "DrivAerML: High-Fidelity Computational Fluid Dynamics Dataset for Road-Car External Aerodynamics", "link_suffix": "/forum?id=EyTzNHoEyK", "link": "https://openreview.net/forum?id=EyTzNHoEyK", "pdf_link": "https://openreview.net/pdf?id=EyTzNHoEyK", "keywords": "CFD, automotive, ML, drivaer, dataset", "abstract": "Machine Learning (ML) has the potential to revolutionise the field of automotive aerodynamics, enabling split-second flow predictions early in the design process. However, the lack of open-source training data for realistic road cars, using high-fidelity CFD methods, represents a barrier to their development. To address this, a high-fidelity open-source (CC-BY-SA) public dataset for automotive aerodynamics has been generated, based on 500 parametrically morphed variants of the widely-used DrivAer notchback generic vehicle. Mesh generation and scale-resolving CFD was executed using consistent and validated automatic workflows representative of the industrial state-of-the-art. Geometries and rich aerodynamic data are published in open-source formats. To our knowledge, this is the first large, public-domain dataset for complex automotive configurations generated using high-fidelity CFD.", "title_embedding_index": 17462, "title_abs_embedding_index": 17487}, {"title": "MLOT: Extending the Bipartite Structure towards Multi-Layered Structure for Optimal Transport", "link_suffix": "/forum?id=S7dFKyaOoE", "link": "https://openreview.net/forum?id=S7dFKyaOoE", "pdf_link": "https://openreview.net/pdf?id=S7dFKyaOoE", "keywords": "Optimal Transport, Multi-Layered Structure, Entropic Regularization, Sinkhorn Algorithm", "abstract": "Despite its remarkable success and widespread adoption in various domains, optimal transport (OT) has a rather simple structure, relying on bipartite graphs with only two layers of nodes for transportation. In this paper, we propose a multi-layered OT approach that extends the original two-layer structure to handle transportation problems across multiple hierarchical levels. Within this framework, the source distribution flows through intermediate layers, before reaching the target distribution. Unlike previous variants of OT that involve multiple distributions, our multi-layered OT typically involves uncertain intermediate distributions, which need to be computed based on the relationships between the preceding and succeeding distributions. Under entropic regularization, MLOT-Sinkhorn algorithm is further proposed for multi-layered OT, which can be accelerated using GPUs and significantly outperforms general solvers such as Gurobi. The theoretical results of our entropic MLOT are also given in this paper. In the experiments, we validate its speed advantage and convergence performance. We further validate its feasibility through Text-Image retrieval and intermediate image computing task, which demonstrates reformulating the problems as MLOT can achieve better results. Source code will be made available.", "title_embedding_index": 17463, "title_abs_embedding_index": 17488}, {"title": "Variational Best-of-N Alignment", "link_suffix": "/forum?id=W9FZEQj3vv", "link": "https://openreview.net/forum?id=W9FZEQj3vv", "pdf_link": "https://openreview.net/pdf?id=W9FZEQj3vv", "keywords": "Alignment, RLHF, Best-of-N", "abstract": "Best-of-N (BoN) is a popular and effective algorithm for aligning language models to human preferences. The algorithm works as follows: at inference time, N samples are drawn from the language model, and the sample with the highest reward, as judged by a reward model, is returned as the output. Despite its effectiveness, BoN is computationally expensive; it reduces sampling throughput by a factor of N. To make BoN more efficient at inference time, one strategy is to fine-tune the language model to mimic what BoN does during inference. To achieve this, we derive the distribution induced by the BoN algorithm. We then propose to fine-tune the language model to minimize backward KL divergence to the BoN distribution. Our approach is analogous to mean-field variational inference and, thus, we term it variational BoN (vBoN). To the extent this fine-tuning is successful and we end up with a good approximation, we have reduced the inference cost by a factor of N. Our experiments on controlled generation and summarization tasks show that BoN is the most effective alignment method, and our variational approximation to BoN achieves the closest performance to BoN and surpasses models fine-tuned using the standard KL-constrained RL objective. In the controlled generation task, vBoN appears more frequently on the Pareto frontier of reward and KL divergence compared to other alignment methods. In the summarization task, vBoN achieves high reward values across various sampling temperatures.", "title_embedding_index": 17464, "title_abs_embedding_index": 17489}, {"title": "Truly Safe & Truly Helpful: Achieving Harmonious Balance for Large Language Model", "link_suffix": "/forum?id=6YdCMtRMuj", "link": "https://openreview.net/forum?id=6YdCMtRMuj", "pdf_link": "https://openreview.net/pdf?id=6YdCMtRMuj", "keywords": "Large Language Model", "abstract": "With the advancement of Large Language Models (LLMs), ensuring their safety has become a paramount concern. Alignment techniques, such as Reinforcement Learning from Human Feedback (RLHF), aligning LLM outputs with human values and intentions, greatly enhance the models' safety and utility. Normally, it is a common sense that alignment relies on the quality and quantity of safety data. However, our extensive experimental analysis reveals that integrating a large volume of safety-related data into the alignment process does not fully address all safety concerns, for instance, those arising from unknown safety knowledge, but degrades the models' general ability. To tackle this challenge, we investigate the root causes of LLM harmfulness, focusing on two key dimensions: inadequate safety alignment and insufficient safety knowledge. We delineate the boundaries of what can be achieved through alignment versus other security policies. In response, we introduce a fine-grained data identification strategy and an adaptive message-wise alignment approach, designed to obtain optimized alignment results with minimal safety data, thereby balance the models' safety and general performance. Furthermore, to mitigate the lack of comprehensive safety knowledge, we propose a harmful token filtering mechanism to be applied during the inference phase. Our experimental results indicate that our proposed approaches significantly enhance both the safety and the general performance of LLMs, thus laying the groundwork for more dependable and versatile applications in natural language processing.", "title_embedding_index": 17465, "title_abs_embedding_index": 17490}, {"title": "Dataset Size Recovery from Fine-Tuned Weights", "link_suffix": "/forum?id=2RQokbn4B5", "link": "https://openreview.net/forum?id=2RQokbn4B5", "pdf_link": "https://openreview.net/pdf?id=2RQokbn4B5", "keywords": "Model Forensics", "abstract": "Model inversion and membership inference attacks aim to reconstruct and verify the data on which a model was trained. However, these methods cannot guarantee to find all training samples, as they do not know the training set size. In this paper, we introduce a new task: dataset size recovery, which seeks to identify the number of samples a given model was fine-tuned on. \nOur core finding is that both the norm and the spectrum of the fine-tuning weight matrices are closely linked to the fine-tuning dataset size. Leveraging this insight, we propose DSiRe, an algorithm that accepts fine-tuned model weights, extracts their spectral features, and then employs a nearest neighbor classifier on top, to predict the dataset size. Although it is training-free, simple, and very easy to implement, DSiRe is broadly applicable across various fine-tuning paradigms and modalities (e.g., DSiRe can predict the number of fine-tuning images with a mean absolute error of $0.36$ images). To this end, we develop and release LoRA-WiSE, a new benchmark consisting of over $25k$ weight snapshots from more than $2k$ diverse LoRA fine-tuned models.", "title_embedding_index": 17466, "title_abs_embedding_index": 17491}, {"title": "HiS4MAE: High-efficiency Segmentation of Subcellular Structure via Self-distillated Masked Autoencoder", "link_suffix": "/forum?id=GmMp8S8M4V", "link": "https://openreview.net/forum?id=GmMp8S8M4V", "pdf_link": "https://openreview.net/pdf?id=GmMp8S8M4V", "keywords": "Subcellular Structure Segmentation, Masked Image Model, Microscopy Image", "abstract": "The accurate identification of subcellular structures is crucial for understanding cellular functions. However, due to the varied morphology of different cells, conventional segmentation methods typically depend on a substantial collection of accurately labeled images of cell structures. The creation of such precise labels is often time-consuming and labor-intensive. To address this issue, we introduce an efficient, self-supervised method for segmenting subcellular structures, named HiS4MAE (High-efficiency Segmentation of Subcellular Structure via Self-distillated Masked Autoencoder). Leveraging an enhanced masked autoencoder (MAE), we train the encoder using the masked image modeling (MIM) framework, followed by clustering the encoded high-dimensional features to achieve pixel-level segmentation of structures. We employ a self-distillation technique to accelerate the model's training process and propose an inference method that is less time-consuming. We also introduce a discrete codebook to assist the self-distillation process, enhancing the model's stability during training. When applied to a publicly available volumetric electron microscopy (VEM) dataset of primary mouse pancreatic islet $\\beta$ cells, HiS4MAE not only surpasses the state-of-the-art technique but also significantly reduces the time required for both training and inference.", "title_embedding_index": 17467, "title_abs_embedding_index": 17492}, {"title": "MentalArena: Self-play Training of Language Models for Diagnosis and Treatment of Mental Health Disorders", "link_suffix": "/forum?id=wWPiAjbR7a", "link": "https://openreview.net/forum?id=wWPiAjbR7a", "pdf_link": "https://openreview.net/pdf?id=wWPiAjbR7a", "keywords": "Mental health, Self-play, Co-evolve, Iterative training", "abstract": "Mental health disorders are one of the most serious diseases in the world. Most people with such a disease lack access to adequate care, which highlights the importance of training models for the diagnosis and treatment of mental health disorders. However, in the mental health domain, privacy concerns limit the accessibility of personalized treatment data, making it challenging to build powerful models.\nIn this paper, we introduce MentalArena, a self-play framework to train language models by generating domain-specific personalized data, where we obtain a better model capable of making a personalized diagnosis and treatment (as a therapist) and providing information (as a patient). To accurately model human-like mental health patients, we devise Symptom Encoder which simulates a real patient from both cognition and behavior perspectives. To address intent bias during patient-therapist interactions, we propose Symptom Decoder to compare diagnosed symptoms with encoded symptoms, and dynamically manage the dialogue between patient and therapist according to the identified deviations. We evaluated MentalArena against $6$ benchmarks, including biomedicalQA and mental health tasks, compared to $6$ advanced models. Our models, fine-tuned on both GPT-3.5 and Llama-3-8b, significantly outperform their counterparts, including GPT-4o. We hope that our work can inspire future research on personalized care.", "title_embedding_index": 17468, "title_abs_embedding_index": 17493}, {"title": "Gradient based Causal Discovery with Diffusion Model", "link_suffix": "/forum?id=l3Q0scRuT9", "link": "https://openreview.net/forum?id=l3Q0scRuT9", "pdf_link": "https://openreview.net/pdf?id=l3Q0scRuT9", "keywords": "Causal discovery, generative models", "abstract": "Causal discovery from observational data is an important problem in many applied sciences. Incorporating a recently proposed smooth characterization of acyclicity, gradient-based causal discovery approaches search for a Directed Acyclic Graph (DAG) by optimizing various neural models. Although they show some inspiring results given certain assumptions satisfied, their capability of modeling complex nonlinear causal generative functions is still unsatisfactory. Motivated by recent advances in deep generative models, we propose to use diffusion models for causal discovery,  and search for the DAG under continuous optimization frameworks. With flexible parameter configurations, diffusion model has the ability to represent various functions, and the proposed causal discovery approach are able to generate graphs with satisfactory accuracy on  observational data generated by either linear or nonlinear causal models. This is evidenced by empirical results on both synthetic and real data.", "title_embedding_index": 17469, "title_abs_embedding_index": 17494}, {"title": "On Sequence Segmentation with overlapped Chunks in Machine Learning", "link_suffix": "/forum?id=JOBokGDcX0", "link": "https://openreview.net/forum?id=JOBokGDcX0", "pdf_link": "https://openreview.net/pdf?id=JOBokGDcX0", "keywords": "sequence segmentation, speech separation, source separation, audio super resolution, stft, signal processing", "abstract": "Operating on very long sequences can be problematic for many sequence modelling methods like Transformers or recurrent neural networks. To avoid this issue, long sequences are often split into smaller chunks instead.\nFor various reasons, these chunks typically are overlapped with each other which causes an increase in tensor size by however much the chunks are overlapping.This paper attempts to find a better understanding on overlapped sequence chunks and what they accomplish. Specifically, the focus of this paper is on audio inputs in both the time and frequency domain. Previous models for speech separation and audio super resolution which use overlapped chunks are modified to allow for reduced or even removed overlaps which causes significant decreases in computational cost while maintaining accuracy.", "title_embedding_index": 17470, "title_abs_embedding_index": 17495}, {"title": "HMoRA: Making LLMs More Effective with Hierarchical Mixture of LoRA Experts", "link_suffix": "/forum?id=lTkHiXeuDl", "link": "https://openreview.net/forum?id=lTkHiXeuDl", "pdf_link": "https://openreview.net/pdf?id=lTkHiXeuDl", "keywords": "Large Language Models, Multi-Task Learning, Parameter-Efficient Fine-tuning, Mixture of Experts", "abstract": "Recent studies have combined Mixture of Experts (MoE) and Parameter-Efficient Fine-tuning (PEFT) to fine-tune large language models (LLMs), holding excellent performance in multi-task scenarios while remaining resource-efficient. Yet, existing MoE methods still  exhibit  three major limitations: (1) Most MoE routing methods focus solely on token-level or task-level routing, which significantly limits the exploration of multi-granularity information. (2) Task-level routing methods are confined to tasks encountered during training, failing to generalize to unseen tasks. (3) The lack of certainty in existing MoE routing methods hinders the specialization of the experts. To address these challenges, we propose HMoRA, a hierarchical fine-tuning method that combines MoE and LoRA, employing hybrid routing that integrates token-level and task-level routing in a hierarchical manner. This hybrid routing allows the model to capture both fine-grained token information and broader task contexts. To improve the certainty of expert selection, a novel routing auxiliary loss is introduced, enabling the task router to differentiate between tasks without supervision and to generalize to unseen tasks. Additionally, several optional lightweight designs have been proposed to significantly reduce both the number of trainable parameters and computational costs. Experimental results demonstrate that HMoRA outperforms full fine-tuning across multiple NLP benchmarks, while fine-tuning only 3.9% of the parameters. The code is  available on:https://anonymous.4open.science/r/HMoRA-2648.", "title_embedding_index": 17471, "title_abs_embedding_index": 17496}, {"title": "Series-to-Series Diffusion Bridge Model", "link_suffix": "/forum?id=xCMmtYOsiL", "link": "https://openreview.net/forum?id=xCMmtYOsiL", "pdf_link": "https://openreview.net/pdf?id=xCMmtYOsiL", "keywords": "time series forecasting; diffusion model", "abstract": "Diffusion models have risen to prominence in time series forecasting, showcasing their robust capability to model complex data distributions. However, their effectiveness in deterministic predictions is often constrained by instability arising from their inherent stochasticity. In this paper, we revisit time series diffusion models and present a comprehensive framework that encompasses most existing diffusion-based methods. Building on this theoretical foundation, we propose a novel diffusion-based time series forecasting model, the Series-to-Series Diffusion Bridge Model ($\\mathrm{S^2DBM}$), which leverages the Brownian Bridge process to reduce randomness in reverse estimations and improves accuracy by incorporating informative priors and conditions derived from historical time series data. Experimental results demonstrate that $\\mathrm{S^2DBM}$ delivers superior performance in point-to-point forecasting and competes effectively with other diffusion-based models in probabilistic forecasting.", "title_embedding_index": 17472, "title_abs_embedding_index": 17497}, {"title": "BRIDGE: Bootstrapping Text to Guide Time-Series Generation via Multi-Agent Iterative Optimisation and Diffusion Modelling", "link_suffix": "/forum?id=iGV6Sg5bI0", "link": "https://openreview.net/forum?id=iGV6Sg5bI0", "pdf_link": "https://openreview.net/pdf?id=iGV6Sg5bI0", "keywords": "Time Series Generation; AI Agent", "abstract": "Time-series Generation (TSG) is an impactful research direction, as generating realistic sequences can be used to create educational materials, in simulations and for counterfactual analysis in decision making. It has further the potential to alleviate the resource bottleneck that arises from a lack of diverse time-series data required to train large time-series foundational models. However, most existing TSG models are typically designed to generate data from a specified domain, which is due to the large divergence in patterns between different real-world TS domains. In this paper, we argue that text can provide semantic information (including cross-domain background knowledge and instance temporal patterns) to improve the generalisation of TSG. To do so, we introduce ``Text Guided Time Series Generation'' (TG$^2$)---the task of generating realistic time series from handful of example time series paired with their textual description. We further present a Self-Refine-based Multi-Agent LLM framework to synthesise a realistic benchmark for TG$^2$ and show that the collected text descriptions are both realistic and useful for time-series generation.  We develop a first strong baseline for the TG$^2$, Bridge, which utilises LLMs and diffusion models to generate time series which encode semantic information as cross-domain condition. Our experimental results demonstrate that Bridge significantly outperforms existing time-series generation baselines  on 10 out of 12 datasets, resulting in data distributions that are more closely aligned to target domains. Using the generated data for training positively impacts the performance of time series forecasting models, effectively addressing training data limitations. This work bridges the gap between LLMs and time series analysis, introducing natural language to help the time series generation and its applications.", "title_embedding_index": 17473, "title_abs_embedding_index": 17498}, {"title": "Addressing Misspecification in Simulation-based Inference through Data-driven Calibration", "link_suffix": "/forum?id=g6fYDGKeyB", "link": "https://openreview.net/forum?id=g6fYDGKeyB", "pdf_link": "https://openreview.net/pdf?id=g6fYDGKeyB", "keywords": "Simulation-based inference, SBI, Bayesian Inference, Misspecification, Likelihood-free, Robust Inference, Physics-informed Machine Learning", "abstract": "Driven by steady progress in generative modeling, simulation-based inference (SBI) has enabled inference over stochastic simulators. However, recent work has demonstrated that model misspecification can harm SBI's reliability, preventing its adoption in important applications where only misspecified simulators are available.\nThis work introduces robust posterior estimation (RoPE), a framework that overcomes model misspecification with a small real-world calibration set of ground truth parameter measurements.\nWe formalize the misspecification gap as the solution of an optimal transport problem between learned representations of real-world and simulated observations, allowing the method to learn a model of the misspecification without placing additional assumptions on its nature. The method shows how a small calibration set can be leveraged to offer a controllable balance between calibrated uncertainty and informative inference even under severely misspecified simulators. Our empirical results on four synthetic tasks and two real-world problems with ground-truth labels demonstrate that RoPE outperforms baselines and consistently returns informative and calibrated credible intervals.", "title_embedding_index": 17474, "title_abs_embedding_index": 17499}]
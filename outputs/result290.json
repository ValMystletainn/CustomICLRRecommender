[{"title": "Knowledge Localization: Mission Not Accomplished? Enter Query Localization!", "link_suffix": "/forum?id=tfyHbvFZ0K", "link": "https://openreview.net/forum?id=tfyHbvFZ0K", "pdf_link": "https://openreview.net/pdf?id=tfyHbvFZ0K", "keywords": "Knowledge Neruon Thesis, Knowledge Localization, Query Localization", "abstract": "Large language models (LLMs) store extensive factual knowledge, but the mechanisms behind how they store and express this knowledge remain unclear.\nThe Knowledge Neuron (KN) thesis is a prominent theory for explaining these mechanisms. This theory is based on theKnowledge Localization (KL)assumption, which suggests that a fact can be localized to a few knowledge storage units, namely knowledge neurons.\n However, this assumption has two limitations: first, it may be too rigid  regarding knowledge storage, and second, it neglects the role of the attention module in  knowledge expression.In this paper, we first re-examine the KL assumption and demonstrate that its limitations do indeed exist. To address these, we then present two new findings, each targeting one of the limitations: one focusing on knowledge storage and the other on knowledge expression.\nWe summarize these findings asQuery Localizationassumption and argue that the KL assumption can be viewed as a simplification of the QL assumption. \nBased on QL assumption, we further propose  the Consistency-Aware KN modification method, which improves the performance of knowledge modification,  further validating our new assumption. We conduct 39 sets of experiments, along with additional visualization experiments, to rigorously confirm  our conclusions. Code will be made public soon.", "title_embedding_index": 14450, "title_abs_embedding_index": 14475}, {"title": "Cliqueformer: Model-Based Optimization With Structured Transformers", "link_suffix": "/forum?id=hmvCXDzPUR", "link": "https://openreview.net/forum?id=hmvCXDzPUR", "pdf_link": "https://openreview.net/pdf?id=hmvCXDzPUR", "keywords": "model-based optimization; black-box optimization; transformers", "abstract": "Expressive large-scale neural networks enable training powerful models for prediction tasks. However, in many engineering and science domains, such models are intended to be used not just for prediction, but for design---e.g., creating new proteins that serve as effective therapeutics, or creating new materials or chemicals that maximize a downstream performance measure. Thus, researchers have been recently growing an interest in building deep learning methods that solve offline \\emph{model-based optimization} (MBO) problems, in which design candidates are optimized with respect to surrogate models learned from offline data. However, straightforward application of predictive models that are effective at predicting in-distribution properties of a design are not necessarily the best suited for use in creating new designs. Thus, the most successful algorithms that tackle MBO draw intpiration from reinforcement learning and generative modeling to meet the in-distribution constratints. Meanwhile, recent theoretical works have observed that exploiting structure of the target black-box function is an effective strategy for solving MBO from offline data. Unfortunately, discovering such structure remains an open problem. In this paper, following first principles, we develop a model that learns the structure of an MBO task and empirically leads to improved designs. To this end, we introduce \\emph{Cliqueformer}---a scalable transformer-based architecture that learns the black-box function's structure in form of its \\emph{functional graphical model} (FGM), thus bypassing the problem of distribution shift, previously tackled by conservative approaches. We evaluate Cliqueformer on various tasks, ranging from high-dimensional black-box functions from MBO literature, to real-world tasks of chemical and genetic design, consistently demonstrating its state of the art performance.", "title_embedding_index": 14451, "title_abs_embedding_index": 14476}, {"title": "ComboStoc: Combinatorial Stochasticity for Diffusion Generative Models", "link_suffix": "/forum?id=gBHZAAwcgT", "link": "https://openreview.net/forum?id=gBHZAAwcgT", "pdf_link": "https://openreview.net/pdf?id=gBHZAAwcgT", "keywords": "generative models, combinatorial, stochastic", "abstract": "In this paper, we study an under-explored but important factor of diffusion generative models, i.e., the combinatorial complexity. \nData samples are generally high-dimensional, and for various structured generation tasks, additional attributes are combined to associate with data samples.\nWe show that the space spanned by the combination of dimensions and attributes is insufficiently sampled by existing training scheme of diffusion generative models, causing degraded test time performance.\nWe present a simple fix to this problem by constructing stochastic processes that fully exploit the combinatorial structures, hence the name ComboStoc.\nUsing this simple strategy, we show that network training is significantly accelerated across diverse data modalities, including images and 3D structured shapes.\nMoreover, ComboStoc enables a new way of test time generation which uses asynchronous time steps for different dimensions and attributes, thus allowing for varying degrees of control over them.", "title_embedding_index": 14452, "title_abs_embedding_index": 14477}, {"title": "FluentLip: A Phonemes-Based Two-stage Approach for Audio-Driven Lip Synthesis with Optical Flow Consistency", "link_suffix": "/forum?id=LXBn5e4y8d", "link": "https://openreview.net/forum?id=LXBn5e4y8d", "pdf_link": "https://openreview.net/pdf?id=LXBn5e4y8d", "keywords": "Talking Face Generation, Audio-driven lip synthesis, Multimodal learning, Optical flow consistency, Generative Adversarial Networks", "abstract": "Generating consecutive images of lip movements that align with a given speech in audio-driven lip synthesis is a challenging task. While previous studies have made strides in synchronization and visual quality, lip intelligibility and video fluency remain persistent challenges. This work proposes FluentLip, a two-stage approach for audio-driven lip synthesis, incorporating three featured strategies. To improve lip synchronization and intelligibility, we integrate a phoneme extractor and encoder to generate a fusion of audio and phoneme information for multimodal learning. Additionally, we employ optical flow consistency loss to ensure natural transitions between image frames. Furthermore, we incorporate a diffusion chain during the training of Generative Adversarial Networks (GANs) to improve both stability and efficiency. We evaluate our proposed FluentLip through extensive experiments, comparing it with five state-of-the-art (SOTA) approaches across five metrics, including a proposed metric called Phoneme Error Rate (PER) that evaluates lip pose intelligibility and video fluency. The experimental results demonstrate that our FluentLip approach is highly competitive, achieving significant improvements in smoothness and naturalness. In particular, it outperforms these SOTA approaches by approximately $\\textbf{16.3\\%}$ in Fr\u00e9chet Inception Distance (FID) and $\\textbf{35.2\\%}$ in PER.", "title_embedding_index": 14453, "title_abs_embedding_index": 14478}, {"title": "Dynamic Inhomogeneous Quantum Resource Scheduling with Reinforcement Learning", "link_suffix": "/forum?id=8WtBrv2k2b", "link": "https://openreview.net/forum?id=8WtBrv2k2b", "pdf_link": "https://openreview.net/pdf?id=8WtBrv2k2b", "keywords": "AI for science, reinforcement learning, quantum computing, monte carlo simulation, scientific machine learning", "abstract": "A central challenge in quantum information science and technology is achieving real-time estimation and feedforward control of quantum systems. This challenge is compounded by the inherent inhomogeneity of quantum resources, such as qubit properties and controls, and their intrinsically probabilistic nature. This leads to stochastic challenges in error detection and probabilistic outcomes in processes such as heralded remote entanglement. Given these complexities, optimizing the construction of quantum resource states is an NP-hard problem. In this paper, we address the quantum resource scheduling issue by formulating the problem and simulating it within a digitized environment, allowing the exploration and development of agent-based optimization strategies. We employ reinforcement learning agents within this probabilistic setting and introduce a new framework utilizing a Transformer model that emphasizes self-attention mechanisms for pairs of qubits. This approach facilitates dynamic scheduling by providing real-time, next-step guidance. Our method significantly improves the performance of quantum systems, achieving more than a 3$\\times$ improvement over rule-based agents, and establishes an innovative framework that improves the joint design of physical and control systems for quantum applications in communication, networking, and computing.", "title_embedding_index": 14454, "title_abs_embedding_index": 14479}, {"title": "Efficient Machine Unlearning for Deep Generative Models by Mitigating Optimization Conflicts", "link_suffix": "/forum?id=A2muypu61H", "link": "https://openreview.net/forum?id=A2muypu61H", "pdf_link": "https://openreview.net/pdf?id=A2muypu61H", "keywords": "Machine unlearning, duffusion model", "abstract": "Machine unlearning of deep generative model refers to the process of modifying\nor updating a pre-trained generative model to forget or remove certain patterns\nor information it has learned. Existing research on Bayesian-based unlearning\nfrom various deep generative models has highlighted low efficiency as a significant\ndrawback due to two primary causes. Firstly, Bayesian methods often overlook\ncorrelations between data to forget and data to remember, leading to conflicts during\ngradient descent and much slower convergence. Additionally, they require aligning\nupdated model parameters with the original ones to maintain the generation ability\nof the updated model, further reducing efficiency. To address these limitations,\nwe propose an Efficient Bayesian-based Unlearning method for various deep\ngenerative models called EBU. By identifying the relevant weights pertaining to\nthe data to forget and the data to remember, EBU only preserves the parameters\nrelated to data to remember, improving the efficiency. Additionally, EBU balances\nthe gradient descent directions of shared parameters to adeptly manage the conflicts\ncaused by the correlations between data to forget and data to remember, leading to\na more efficient unlearning process. Extensive experiments on multiple generative\nmodels demonstrate the superiority of our proposed EBU.", "title_embedding_index": 14455, "title_abs_embedding_index": 14480}, {"title": "Rethinking Spiking Neural Networks from an Ensemble Learning Perspective", "link_suffix": "/forum?id=ZyknpOQwkT", "link": "https://openreview.net/forum?id=ZyknpOQwkT", "pdf_link": "https://openreview.net/pdf?id=ZyknpOQwkT", "keywords": "Spiking neural network, Membrane potential smoothing, Neuromorphic object recognition", "abstract": "Spiking neural networks (SNNs) have gained widespread attention for their low power consumption and spatio-temporal dynamics. In this paper, we consider an SNN as an ensemble of multiple temporal subnetworks that share architecture and weights, but produce different outputs due to differences in initial states (neuron membrane potentials). We identify a key factor influencing ensemble performance: excessive differences in the initial state lead to unstable subnetwork outputs that degrade performance, especially in the first two timesteps. To mitigate this, we propose to adaptively smooth the membrane potential cross adjacent timesteps to reduce the initial state discrepancy. Membrane potential smoothing allows for more stable ensemble effects and brings an additional bonus: additional pathways for forward propagation of information and backward propagation of gradients, mitigating temporal gradient vanishing and thus improving performance. Furthermore, we propose the temporally adjacent subnetwork guidance to improve the output consistency of subnetworks through distillation, further enhancing the ensemble stability and performance. Extensive experiments have shown that our method can be applied to VGG, ResNet, and Transofrmer architectures with great versatility. Compared to existing methods, our method shows superior performance in neuromorphic/static object/gesture recognition and 3D point cloud classification tasks, achieving 80.60% accuracy on the CIFAR10-DVS dataset with only 5 timesteps.", "title_embedding_index": 14456, "title_abs_embedding_index": 14481}, {"title": "Near-optimal Active Regression of Single-Index Models", "link_suffix": "/forum?id=iF06WjHnNj", "link": "https://openreview.net/forum?id=iF06WjHnNj", "pdf_link": "https://openreview.net/pdf?id=iF06WjHnNj", "keywords": "Lewis weights, Active regression, Query complexity", "abstract": "The active regression problem of the single-index model is to solve $\\min_x \\lVert f(Ax)-b\\rVert_p$, where $A$ is fully accessible and $b$ can only be accessed via entry queries, with the goal of minimizing the number of queries to the entries of $b$.\nWhen $f$ is Lipschitz, previous results only obtain constant-factor approximations. This work presents the first algorithm that provides a $(1+\\varepsilon)$-approximation solution by querying $\\tilde{O}(d^{\\frac{p}{2}\\vee 1}/\\varepsilon^{p\\vee 2})$ entries of $b$. This query complexity is also shown to be optimal up to logarithmic factors for $p\\in [1,2]$ and the $\\varepsilon$-dependence of $1/\\varepsilon^p$ is shown to be optimal for $p>2$.", "title_embedding_index": 14457, "title_abs_embedding_index": 14482}, {"title": "Multi-aspect Knowledge Distillation with Large Language Model", "link_suffix": "/forum?id=0cBttXaOUK", "link": "https://openreview.net/forum?id=0cBttXaOUK", "pdf_link": "https://openreview.net/pdf?id=0cBttXaOUK", "keywords": "Multi-aspect Knowledge Distillation, LLM, MLLM", "abstract": "Recent advancements in deep learning have significantly improved performance on computer vision tasks. Previous image classification methods primarily modify model architectures or add features, and they optimize models using cross-entropy loss on class logits. Since they focus on classifying images with considering class labels, these methods may struggle to learn various aspects of classes (e.g., natural positions and shape changes). In contrast, humans classify images by naturally referring to multi-aspects such as context, shape, color, and other features. Inspired by this, rethinking the previous approach from a novel view, we propose a multi-aspect knowledge distillation method using Multimodal Large Language Models (MLLMs). Our approach involves: 1) querying Large Language Model with multi-aspect questions relevant to the knowledge we want to transfer to the model, 2) extracting corresponding logits from MLLM, and 3) expanding the model's output dimensions to distill these multi-aspect logits. We then apply cross-entropy loss to class logits and binary cross-entropy loss to multi-aspect logits. Through our method, the model can learn not only the knowledge about visual aspects but also the abstract and complex aspects that require a deeper understanding. We primarily apply our method to image classification, and to explore the potential for extending our model, we expand it to other tasks, such as object detection. In all experimental results, our method improves the performance of the baselines. Additionally, we analyze the effect of multi-aspect knowledge distillation. These results demonstrate that our method can transfer knowledge about various aspects to the model and the aspect knowledge can enhance model performance in computer vision tasks. This paper demonstrates the great potential of multi-aspect knowledge distillation, and we believe it offers a promising direction for future research in computer vision and beyond.", "title_embedding_index": 14458, "title_abs_embedding_index": 14483}, {"title": "DH-Fusion: Depth-Aware Hybrid Feature Fusion for Multimodal 3D Object Detection", "link_suffix": "/forum?id=R32pqU5vej", "link": "https://openreview.net/forum?id=R32pqU5vej", "pdf_link": "https://openreview.net/pdf?id=R32pqU5vej", "keywords": "Depth Aware, Multi Modality, 3D Object Detection", "abstract": "State-of-the-art LiDAR-camera 3D object detectors usually focus on feature fusion. However, they neglect the factor of depth while designing the fusion strategy. In this work, we for the first time point out that different modalities play different roles as depth varies via statistical analysis and visualization. Based on this finding, we propose a Depth-Aware Hybrid Feature Fusion (DH-Fusion) strategy that guides the weights of point cloud and RGB image modalities by introducing depth encoding at both global and local levels. Specifically, the Depth-Aware Global Feature Fusion (DGF) module adaptively adjusts the weights of image Bird's-Eye-View (BEV) features in multi-modal global features via depth encoding. Furthermore, to compensate for the information lost when transferring raw features to the BEV space, we propose a Depth-Aware Local Feature Fusion (DLF) module, which adaptively adjusts the weights of original voxel features and multi-view image features in multi-modal local features via depth encoding. Extensive experiments on the nuScenes and KITTI datasets demonstrate that our DH-Fusion method surpasses previous state-of-the-art methods. Moreover, our DH-Fusion is more robust to various kinds of corruptions, outperforming previous methods on nuScenes-C w.r.t. both NDS and mAP.", "title_embedding_index": 14459, "title_abs_embedding_index": 14484}, {"title": "LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior", "link_suffix": "/forum?id=Wr3UuEx72f", "link": "https://openreview.net/forum?id=Wr3UuEx72f", "pdf_link": "https://openreview.net/pdf?id=Wr3UuEx72f", "keywords": "Video Generation, Visual Tokenization", "abstract": "We present LARP, a novel video tokenizer designed to overcome limitations in current video tokenization methods for autoregressive (AR) generative models. Unlike traditional patchwise tokenizers that directly encode local visual patches into discrete tokens, LARP introduces a holistic tokenization scheme that gathers information from the visual content using a set of learned holistic queries. This design allows LARP to capture more global and semantic representations, rather than being limited to local patch-level information. Furthermore, it offers flexibility by supporting an arbitrary number of discrete tokens, enabling adaptive and efficient tokenization based on the specific requirements of the task. To align the discrete token space with downstream AR generation tasks, LARP integrates a lightweight AR transformer as a training-time prior model that predicts the next token on its discrete latent space. By incorporating the prior model during training, LARP learns a latent space that is not only optimized for video reconstruction but is also structured in a way that is more conducive to autoregressive generation. Moreover, this process defines a sequential order for the discrete tokens, progressively pushing them toward an optimal configuration during training, ensuring smoother and more accurate AR generation at inference time. Comprehensive experiments demonstrate LARPs strong performance, achieving state-of-the-art FVD on the UCF101 class-conditional video generation benchmark. LARP enhances the compatibility of AR models with videos and opens up the potential to build unified high-fidelity multimodal large language models (MLLMs). Code and checkpoints will be released.", "title_embedding_index": 14460, "title_abs_embedding_index": 14485}, {"title": "GuideEdit: Enhancing Face Video Editing with Fine-grained Control", "link_suffix": "/forum?id=gWOANrFJ0t", "link": "https://openreview.net/forum?id=gWOANrFJ0t", "pdf_link": "https://openreview.net/pdf?id=gWOANrFJ0t", "keywords": "Face video editing, Diffusion model", "abstract": "Face video editing (FVE) requires maintaining temporal consistency and iden-\ntity preservation while manipulating specific attributes. However, existing FVE\nmethods often introduce unwanted artifacts and affect non-target attributes during\nediting. To address these limitations, we propose GuideEdit to enhance the pre-\ncision of face video editing. Given the inherent linearity of the latent variables in\nthe bottleneck layer of the diffusion U-Net model, there exists a linear mapping\nbetween the input and the latent representation. This allows us to extract a latent\nbasis within the latent space that effectively encodes the key features related to\ntarget facial attributes. By comparing the latent basis of the original video to that\nof the manipulated video, we quantify the manipulation degree, which indicates\nthe extent of changes made. This manipulation degree serves as a guide for deter-\nmining the specific components to be edited, then we achieve more precise control\nat each denoising step. Integrating this fine-grained control into the editing pro-\ncess allows GuideEdit to enhance temporal consistency and preserve identity of\nFVE, while minimizing the introduction of artifacts. Extensive experiments on\ndiverse real-world videos demonstrate the effectiveness of GuideEdit, showcas-\ning its ability to achieve precise, high-quality edits that maintain coherence across\nframes and ensure the preservation of essential visual elements.", "title_embedding_index": 14461, "title_abs_embedding_index": 14486}, {"title": "Primal-Dual Graph Neural Networks for General NP-Hard Combinatorial Optimization", "link_suffix": "/forum?id=4Hd7u3LHlZ", "link": "https://openreview.net/forum?id=4Hd7u3LHlZ", "pdf_link": "https://openreview.net/pdf?id=4Hd7u3LHlZ", "keywords": "neural algorithmic reasoning, graph neural networks, combinatorial optimization", "abstract": "Neural algorithmic reasoning (NAR) seeks to train neural networks, particularly Graph Neural Networks (GNNs), to simulate and generalize traditional algorithms, enabling them to perform structured reasoning on complex data.  Previous research has primarily focused on polynomial-time-solvable algorithmic problems. However, many of the most critical optimization problems in practice are NP-hard, exposing a critical gap in NAR. In this work, we propose a general GNN-based framework for NP-hard optimization problems, built on the classical primal-dual framework for designing efficient approximation algorithms. We enhance this framework by integrating optimal solutions to these NP-hard problems, enabling the model to surpass the performance of the approximation algorithms it was initially trained on. To the best of our knowledge, this is the first NAR method explicitly designed to surpass the performance of the classical algorithm on which it is trained. We evaluate our framework on several NP-hard combinatorial optimization problems, demonstrating its ability to generalize to larger and out-of-distribution graph families. In addition, we demonstrate the practical utility of the framework in two key applications:  as a warm start for commercial solvers to reduce search time, and as a tool to generate embeddings that enhance predictive performance on real-world datasets. Our results highlight the scalability and effectiveness of GNNs for tackling complex combinatorial optimization problems, advancing their utility beyond the scope of traditional polynomial-time-solvable problems.", "title_embedding_index": 14462, "title_abs_embedding_index": 14487}, {"title": "Steer a Crowd: Learning to Persuade a Population in a Stackelberg Game", "link_suffix": "/forum?id=JJ46kIfPio", "link": "https://openreview.net/forum?id=JJ46kIfPio", "pdf_link": "https://openreview.net/pdf?id=JJ46kIfPio", "keywords": "information design, stackelberg game, reinforcement learning, markov games, multi-agent system", "abstract": "Multi-agent systems are prevalent across various domains, characterized by misaligned objectives and information asymmetry, which facilitate the study of incentive design and information design. Existing research often assumes known models and static environments. Motivated by this, we propose a Dynamic Incentive and Information Design (DIID) framework for finite-horizon Markov games, involving a principal and multiple agents. \nOur focus is on how the principal learns their optimal policy based on data generated through interactions with agents.\nThe main challenge lies in balancing the principal's regret and violations of agents' incentive compatibility constraints during interactions. We establish a lower bound characterizing the trade-off between the two objectives and propose an algorithm attaining the optimal trade-off, i.e. $\\tilde{\\mathcal{O}}(T^{2/3})$ regret and constraint violation. Additionally, with access to additional unilateral deviation information of the agents, we propose an algorithm attaining improved guarantees that achieve $\\tilde{\\mathcal{O}}(T^{1/2})$ for both regret and constraint violation simultaneously.", "title_embedding_index": 14463, "title_abs_embedding_index": 14488}, {"title": "Exploring Multi-Grained Concept Annotations for Multimodal Large Language Models", "link_suffix": "/forum?id=dZsjj4vQjl", "link": "https://openreview.net/forum?id=dZsjj4vQjl", "pdf_link": "https://openreview.net/pdf?id=dZsjj4vQjl", "keywords": "Multimodal Large Language Model, Multi-Grained Annotations, Fine-Grained Annotations, Concept Annotations, Vision--Language Learning", "abstract": "Multimodal Large Language Models (MLLMs) excel in vision--language tasks by pre-training solely on coarse-grained concept annotations (e.g., image captions).\nWe hypothesize that integrating fine-grained concept annotations (e.g., object labels and object regions) will further improve performance, as both data granularities complement each other in terms of breadth and depth in concept representation.We introduce a new dataset featuring Multimodal Multi-Grained Concept annotations (MMGiC) for MLLMs.\nIn constructing MMGiC, we explore the impact of different data recipes on multimodal comprehension and generation.\nOur analyses reveal that multi-grained concept annotations integrate and complement each other, under our structured template and autoregressive discrete framework.We definitively show that multi-grained concepts do facilitate MLLMs to better locate and learn concepts, aligning vision and language at multiple granularities.\nWe further validate our hypothesis by investigating the comparison and collaboration between MMGiC and image--caption data on 12 multimodal comprehension and generation benchmarks, e.g., their appropriate combination achieve 3.95% and 2.34% accuracy improvements on POPE and SEED-Bench.\nCode, data and models will be made openly available.", "title_embedding_index": 14464, "title_abs_embedding_index": 14489}, {"title": "Graph Sparsification via Mixture of Graphs", "link_suffix": "/forum?id=7ANDviElAo", "link": "https://openreview.net/forum?id=7ANDviElAo", "pdf_link": "https://openreview.net/pdf?id=7ANDviElAo", "keywords": "Graph Sparsification, Mixture-of-Experts", "abstract": "Graph Neural Networks (GNNs) have demonstrated superior performance across various graph learning tasks but face significant computational challenges when applied to large-scale graphs. One effective approach to mitigate these challenges is graph sparsification, which involves removing non-essential edges to reduce computational overhead. However, previous graph sparsification methods often rely on a single global sparsity setting and uniform pruning criteria, failing to provide customized sparsification schemes for each node's complex local context.\nIn this paper, we introduce Mixture-of-Graphs (MoG), leveraging the concept of Mixture-of-Experts (MoE), to dynamically select tailored pruning solutions for each node. Specifically, MoG incorporates multiple sparsifier experts, each characterized by unique sparsity levels and pruning criteria, and selects the appropriate experts for each node. Subsequently, MoG performs a mixture of the sparse graphs produced by different experts on the Grassmann manifold to derive an optimal sparse graph. One notable property of MoG is its entirely local nature, as it depends on the specific circumstances of each individual node. Extensive experiments on four large-scale OGB datasets and two superpixel datasets, equipped with five GNN backbones, demonstrate that MoG (I) identifies subgraphs at higher sparsity levels ($8.67\\%\\sim 50.85\\%$), with performance equal to or better than the dense graph, (II) achieves $1.47-2.62\\times$ speedup in GNN inference with negligible performance drop, and (III) boosts ``top-student'' GNN performance ($1.02\\%\\uparrow$ on RevGNN+\\textsc{ogbn-proteins} and $1.74\\%\\uparrow$ on DeeperGCN+\\textsc{ogbg-ppa}).", "title_embedding_index": 14465, "title_abs_embedding_index": 14490}, {"title": "Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing", "link_suffix": "/forum?id=MjFoQAhnl3", "link": "https://openreview.net/forum?id=MjFoQAhnl3", "pdf_link": "https://openreview.net/pdf?id=MjFoQAhnl3", "keywords": "mechanistic interpretability, knowledge editing, transformers", "abstract": "Knowledge Editing (KE) algorithms alter models' internal weights to perform targeted updates to incorrect, outdated, or otherwise unwanted factual associations. In order to better define the possibilities and limitations of these approaches, recent work has shown that applying KE can adversely affect models' factual recall accuracy and diminish their general reasoning abilities. While these studies give high-level insights into the potential harms of KE algorithms, e.g., via performance evaluations on benchmarks, we argue little is understood as to why such destructive failures occur. Is it possible KE methods distort representations of concepts beyond the targeted fact, hence hampering abilities at broad? If so, what is the extent of this distortion? To take a step towards addressing such questions, we define a novel synthetic task wherein a Transformer is trained from scratch to internalize a \"structured\" knowledge graph. The structure enforces relationships between entities of the graph, such that editing a factual association has \"trickling effects\" on other entities in the graph (e.g., altering X's parent is Y to Z affects who X's siblings' parent is). Through evaluations of edited models and analysis of extracted representations, we show that KE inadvertently affects representations of entities beyond the targeted one, distorting relevant structures that allow a model to infer unseen knowledge about an entity. We call this phenomenon representation shattering and demonstrate that it results in degradation of factual recall and reasoning performance more broadly. To corroborate our findings in a more naturalistic setup, we perform preliminary experiments with a pretrained GPT-2-XL model and reproduce the representation shattering effect therein as well. Overall, our work yields a precise mechanistic hypothesis that explains why KE has adverse effects on model capabilities.", "title_embedding_index": 14466, "title_abs_embedding_index": 14491}, {"title": "Accelerating Neural ODEs: A Variational Formulation-based Approach", "link_suffix": "/forum?id=trV41CpAK4", "link": "https://openreview.net/forum?id=trV41CpAK4", "pdf_link": "https://openreview.net/pdf?id=trV41CpAK4", "keywords": "Neural ordinary differential equations, irregularly-sampled dynamical systems, variational formulation, acceleration", "abstract": "Neural Ordinary Differential Equations (Neural ODEs or NODEs) excel at modeling continuous dynamical systems from observational data, especially when the data is irregularly sampled. However, existing training methods predominantly rely on numerical ODE solvers, which are time-consuming and prone to accumulating numerical errors over time due to autoregression. In this work, we propose the VF-NODE, a novel approach based on the variational formulation (VF) to accelerate the training of NODEs. Unlike existing training methods, the proposed VF-NODEs implement a series of global integrals, thus evaluating Deep Neural Network (DNN)--based vector fields only at specific observed data points. This strategy drastically reduces the number of function evaluations (NFEs). Moreover, our method eliminates the use of autoregression, thereby reducing error accumulations for modeling dynamical systems. Nevertheless, the VF loss introduces oscillatory terms into the integrals when using the Fourier basis. We incorporate Filon's method to address this issue. To further enhance the performance for noisy and incomplete data, we employ the natural cubic spline regression to estimate a closed-form approximation. We provide a fundamental analysis of how our approach minimizes computational costs. Extensive experiments demonstrate that our approach accelerates NODE training by 10 to 1000 times compared to existing NODE-based methods, while achieving higher or comparable accuracy in dynamical systems. The source code will be publicly available upon publication.", "title_embedding_index": 14467, "title_abs_embedding_index": 14492}, {"title": "PLENCH: Realistic Evaluation of Deep Partial-Label Learning Algorithms", "link_suffix": "/forum?id=FtX6oAW7Dd", "link": "https://openreview.net/forum?id=FtX6oAW7Dd", "pdf_link": "https://openreview.net/pdf?id=FtX6oAW7Dd", "keywords": "Partial-label learning, weakly supervised learning, benchmark.", "abstract": "Partial-label learning (PLL) is a weakly supervised learning problem in which each example is associated with multiple candidate labels and only one is the true label. In recent years, many deep PLL algorithms have been developed to improve model performance. However, we find that some early developed algorithms are often underestimated and can outperform many later algorithms with complicated designs. In this paper, we delve into the empirical perspective of PLL and identify several critical but previously overlooked issues. First, model selection for PLL is non-trivial, but has never been systematically studied. Second, the experimental settings are highly inconsistent, making it difficult to evaluate the effectiveness of the algorithms. Third, there is a lack of real-world image datasets that can be compatible with modern network architectures. Based on these findings, we propose PLENCH, the first Partial-Label learning bENCHmark to systematically compare state-of-the-art deep PLL algorithms. We systematically investigate the model selection problem for PLL for the first time, and propose novel model selection criteria with theoretical guarantees. We also create Partial-Label CIFAR-10 (PLCIFAR10), an image dataset of human-annotated partial labels collected from Amazon Mechanical Turk, to provide a testbed for evaluating the performance of PLL algorithms in more realistic scenarios. Researchers can quickly and conveniently perform a comprehensive and fair evaluation and verify the effectiveness of newly developed algorithms based on PLENCH. We hope that PLENCH will facilitate standardized, fair, and practical evaluation of PLL algorithms in the future.", "title_embedding_index": 14468, "title_abs_embedding_index": 14493}, {"title": "DNALONGBENCH: A Benchmark Suite For Long-Range DNA Prediction Tasks", "link_suffix": "/forum?id=opv67PpqLS", "link": "https://openreview.net/forum?id=opv67PpqLS", "pdf_link": "https://openreview.net/pdf?id=opv67PpqLS", "keywords": "long-range DNA benchmark, long-range DNA modeling, long-range DNA foundation models", "abstract": "Modeling long-range DNA dependencies is crucial for understanding genome structure and function across a wide range of biological contexts in health and disease. However, effectively capturing the extensive long-range dependencies between DNA sequences, spanning millions of base pairs as seen in tasks such as three-dimensional (3D) chromatin folding, remains a significant challenge. Additionally, a comprehensive benchmark suite for evaluating tasks reliant on long-range dependencies is notably absent. To address this gap, we introduce DNALONGBENCH, a benchmark dataset spanning five important genomics tasks that consider long-range dependencies up to 1 million base pairs: enhancer-target gene interaction, expression quantitative trait loci, 3D genome organization, regulatory sequence activity, and transcription initiation signal. To comprehensively assess DNALONGBENCH, we evaluate the performance of five baseline methods: a task-specific expert model, a convolutional neural network (CNN)-based model, and three fine-tuned DNA foundation models -- HyenaDNA, Caduceus-Ph and Caduceus-PS. We envision DNALONGBENCH having the potential to become a standardized resource that facilitates comprehensive comparisons and rigorous evaluations of emerging DNA sequence-based deep learning models that consider long-range dependencies.", "title_embedding_index": 14469, "title_abs_embedding_index": 14494}, {"title": "GITAR: GENERALIZED IRREGULAR TIME SERIES REGRESSION VIA MASKING AND RECONSTRUCTION PRETRAINING", "link_suffix": "/forum?id=tkN0sLhb4P", "link": "https://openreview.net/forum?id=tkN0sLhb4P", "pdf_link": "https://openreview.net/pdf?id=tkN0sLhb4P", "keywords": "Time series, irregular time series, self-supervised learning", "abstract": "Multivariate time series regression, encompassing forecasting and interpolation, is crucial for numerous real-world applications, particularly in healthcare, climate science, ecology, and others. While recent work has focused on improving modeling for time series regression, two main limitations persist. First, the prevalence of irregularly sampled time series with missing values poses significant challenges.\nFor instance, healthcare applications often involve predicting future or missing observations from irregular data to enable continuous patient monitoring and timely intervention. As current approaches mainly rely on the assumptions of regular time series such as strong periodicity, when applied to irregular ones they exhibit performance degradation. Second, while some state-of-the-art methods (SOTA) do model irregularity and perform regression tasks on irregular data, they are often trained in a fully supervised manner. This limits their ability to generalize easily to different domains (e.g., training and testing datasets with different numbers of variables). To address these challenges, we propose GITaR, a Generalized Irregular Time Series Regression model via masking and Reconstruction pertaining mechanism, aiming to capture the inherent irregularity in time series and learn robust, generalizable representations without supervision for downstream regression tasks. Comprehensive experiments on common real-world regression tasks in healthcare, human activity recognition, and climate science underline the superior performance of GITaR compared to state-of-the-art methods. Our results highlight our model\u2019s unique capability to generalize across different domains, demonstrating the potential for broad applicability in various fields requiring accurate temporal prediction and interpolation.", "title_embedding_index": 14470, "title_abs_embedding_index": 14495}, {"title": "Human-in-the-loop Neural Networks: Human Knowledge Infusion", "link_suffix": "/forum?id=CpQegoH1Fn", "link": "https://openreview.net/forum?id=CpQegoH1Fn", "pdf_link": "https://openreview.net/pdf?id=CpQegoH1Fn", "keywords": "human-in-the-loop;topological representations;metric learning;dimensionality reduction;transfer learning", "abstract": "This study proposes a method for infusing human knowledge into neural networks.\nThe primary objective of this study is to build a mechanism that allows neural networks to learn not only from data but also from humans. This motivation is triggered by the fact that human knowledge, experience, personal preferences, and other subjective characteristics are not necessarily easy to mathematically formulate or present as structured data, hindering them from being learned by neural networks. This study is made possible by a neural network model with a two-dimensional topological hidden representation, Restricted Radial Basis Function (rRBF) network. The hidden layer's low dimensionality allows humans to visualize the internal representation of the neural network and thus intuitively understand its characteristics. In this study, the topological layer is further utilized to allow humans to organize it considering their subjective similarities criterion for the inputs. Hence, the infusion of human knowledge, experience, and preference occurs during this process that initializes the rRBF. The subsequent learning process of rRBF ensures that the infused knowledge is inherited during and after the learning process, thus generating a unique neural network that benefits from human knowledge. The infusion can be executed in two different stages of neural network training: the initialization before learning and the post-training correction. This study contributes to the new field of human-in-the-loop AI, which aims to allow humans to participate in AI's learning process or decision-making. Knowledge infusion broadens the scope of human participation in human-in-the-loop AI, usually limited to arranging the training curriculum or participating in the decision-making process. The proposed method is tested against real-world problems of Alzheimer's detection from MRI images.", "title_embedding_index": 14471, "title_abs_embedding_index": 14496}, {"title": "Genesis: Advancing Towards Efficient Embodiment Co-Design", "link_suffix": "/forum?id=cTR17xl89h", "link": "https://openreview.net/forum?id=cTR17xl89h", "pdf_link": "https://openreview.net/pdf?id=cTR17xl89h", "keywords": "Reinforcement Learning", "abstract": "Embodiment co-design aims to optimize a robot's morphology and control simultaneously. \nPrevious research has demonstrated its  potential for generating environment-adaptive robots.\nHowever, the problem is inherently combinatorial and the morphology is changeable and agnostic in its vast search space, optimization efficiency remains a hard nut to crack. \nWe prove that the inefficient morphology representation and unbalanced reward signals between the design and control stages are key obstacles against efficiency. In order to advance towards efficient embodiment co-design to unlock its full potential, we proposeGenesis, which utilizes (1) a novel topology-aware self-attention architecture, enabling efficient morphology representation while enjoying lightweight model sizes; (2) a temporal credit assignment mechanism for co-design that ensures balanced reward signals for optimization. With our simple-yet-efficient methods, Genesis achieves average60.52%performance improvement against the strongest baselines. We provide codes and more results on the website:https://genesisorigin.github.io.", "title_embedding_index": 14472, "title_abs_embedding_index": 14497}, {"title": "DiSK: Differentially Private Optimizer with Simplified Kalman Filter for Noise Reduction", "link_suffix": "/forum?id=Lfy9q7Icp9", "link": "https://openreview.net/forum?id=Lfy9q7Icp9", "pdf_link": "https://openreview.net/pdf?id=Lfy9q7Icp9", "keywords": "Differential privacy, Kalman filter, noise reduction, nonconvex optimization", "abstract": "Differential privacy (DP) offers a robust framework for safeguarding individual data privacy. To utilize DP  in training modern machine learning models, differentially private optimizers have been widely used in recent years. A popular approach to privatize an optimizer is to clip the individual gradients and add sufficiently large noise to the clipped gradient. This approach led to the development of DP optimizers that have comparable performance with their non-private counterparts in fine-tuning tasks or in tasks with a small number of training parameters. However, a significant performance drop is observed when these optimizers are applied to large-scale training. This degradation stems from the substantial noise injection required to maintain DP, which disrupts the optimizer's dynamics.\nThis paper introduces DiSK, a novel framework designed to significantly enhance the performance of DP optimizers. DiSK employs Kalman filtering, a technique drawn from control and signal processing, to effectively denoise privatized gradients and generate progressively refined gradient estimations. To ensure practicality for large-scale training, we simplify the Kalman filtering process, minimizing its memory and computational demands.\nWe establish theoretical privacy-utility trade-off guarantees for DiSK, and demonstrate provable improvements over standard DP optimizers like DPSGD in terms of iteration complexity upper-bound.\nExtensive experiments across diverse tasks, including vision tasks such as CIFAR-100 and ImageNet-1k and language fine-tuning tasks such as GLUE, E2E, and DART, validate the effectiveness of DiSK.  The results showcase its ability to significantly improve the performance of DP optimizers, surpassing state-of-the-art results under the same privacy constraints on several benchmarks.", "title_embedding_index": 14473, "title_abs_embedding_index": 14498}, {"title": "GUMP: Alleviating Oversquashing with Unitary Message Passing", "link_suffix": "/forum?id=Fg04yPK0BH", "link": "https://openreview.net/forum?id=Fg04yPK0BH", "pdf_link": "https://openreview.net/pdf?id=Fg04yPK0BH", "keywords": "Oversquashing, Graph theory, Deep learning", "abstract": "Message passing mechanism contributes to the success of GNNs in various applications, but also brings the oversquashing problem. Recent works combat oversquashing by improving the graph spectrums with rewiring techniques, disrupting the original graph connectivity, and having limited improvement on oversquashing in terms of oversquashing measure. Motivated by unitary RNN, we propose Graph Unitary Message Passing (GUMP) to alleviate oversquashing in GNNs by applying a unitary adjacency matrix for message passing. To design GUMP, a transformation is first proposed to equip general graphs with unitary adjacency matrices and keep their original graph connectivity. Then, the unitary adjacency matrix is obtained with a unitary projection algorithm, which is implemented by utilizing the intrinsic structure of the unitary adjacency matrix and allows GUMP to be permutation-equivariant. In experiments, GUMP is incorporated into various GNN architectures and the extensive results show the effectiveness of GUMP on various graph learning tasks.", "title_embedding_index": 14474, "title_abs_embedding_index": 14499}]
[
    {
        "title": "Deep Learning for Two-Sided Matching",
        "link_suffix": "/forum?id=p1HeFnn2AA",
        "link": "https://openreview.net/forum?id=p1HeFnn2AA",
        "pdf_link": "https://openreview.net/pdf?id=p1HeFnn2AA",
        "keywords": "Mechanism Design, Matching Markets, Game Theory, Differentiable Economics, Two-Sided Matching",
        "abstract": "We initiate the study of deep learning for the automated design of two-sided matching mechanisms. What is of most interest is to  use machine learning to understand  the possibility of new tradeoffs betweenstrategy-proofnessandstability.  These properties cannot be achieved simultaneously, but the efficient frontier is not understood. We introduce novel differentiable surrogates for quantifying ordinal strategy-proofness and stability and use them to train differentiable matching mechanisms that map discrete preferences to valid randomized matchings. We demonstrate that the efficient frontier characterized by these learned mechanisms is substantially better than that achievable through a convex combination of baselines ofdeferred acceptance(stable and strategy-proof for only one side of the market),top trading cycles(strategy-proof for one side, but not stable), andrandomized serial dictatorship(strategy-proof for both sides, but not stable). This gives a new target for economic theory and opens up new possibilities for machine learning pipelines in matching market design."
    },
    {
        "title": "A Lazy Hessian Evaluation Framework for Accelerating Stochastic Bilevel Optimization",
        "link_suffix": "/forum?id=rVD4lasVp4",
        "link": "https://openreview.net/forum?id=rVD4lasVp4",
        "pdf_link": "https://openreview.net/pdf?id=rVD4lasVp4",
        "keywords": "bilevel optimization, stochastic optimization, lazy Hessian evaluation",
        "abstract": "Bilevel optimization has recently gained popularity because of its applicability in many machine learning applications.\nHypergradient-based algorithms have been widely used for solving bilevel optimization problems because of their strong theoretical and empirical performance in many applications. \nHowever, computing these hypergradients requires the evaluation of Hessians (or Hessian-vector products) of the lower-level objective, which presents a major computational bottleneck. \nTo address this challenge, in this paper, we propose LazyBLO \n(LazyHessian Evaluation inBilevelOptimization), an algorithmic framework that allows infrequent Hessian computation during the execution of the algorithm for solving stochastic bilevel problems.\nThis allows the algorithm to execute faster compared to the state-of-the-art (SOTA) algorithms that evaluate either a single or multiple Hessians in each iteration. \nWe theoretically establish the performance of vanilla SGD-based LazyBLO and show that, despite the additional errors incurred by the infrequent Hessian evaluations, LazyBLO surprisingly matches the computation complexity of the existing SGD-based bilevel algorithms.\nExtensive experiments further demonstrate that LazyBLO enjoys significant gains in numerical performance compared to the SOTA approaches. \nTo our knowledge, this is the first work to theoretically establish that multiple Hessian computations are not necessary within each iteration to guarantee the convergence of stochastic bilevel algorithms."
    },
    {
        "title": "LoRA-Ensemble: Efficient Uncertainty Modelling for Self-attention Networks",
        "link_suffix": "/forum?id=jTnHyyGYy2",
        "link": "https://openreview.net/forum?id=jTnHyyGYy2",
        "pdf_link": "https://openreview.net/pdf?id=jTnHyyGYy2",
        "keywords": "uncertainty, ensemble, implicit ensemble, calibration, self-attention, transformer",
        "abstract": "Numerous crucial tasks in real-world decision-making rely on machine learning algorithms with calibrated uncertainty estimates. However, modern methods often yield overconfident and uncalibrated predictions. Various approaches involve training an ensemble of separate models to quantify the uncertainty related to the model itself, known as epistemic uncertainty. In an explicit implementation, the ensemble approach has high computational cost and high memory requirements. This particular challenge is evident in state-of-the-art neural networks such as transformers, where even a single network is already demanding in terms of compute and memory. Consequently, efforts are made to emulate the ensemble model without actually instantiating separate ensemble members, referred to as implicit ensembling. We introduce LoRA-Ensemble, a parameter-efficient deep ensemble method for self-attention networks, which is based on Low-Rank Adaptation (LoRA). Initially developed for efficient LLM fine-tuning, we extend LoRA to an implicit ensembling approach. By employing a single pre-trained self-attention network with weights shared across all members, we train member-specific low-rank matrices for the attention projections. Our method exhibits superior calibration compared to explicit ensembles and achieves similar or better accuracy across various prediction tasks and datasets."
    },
    {
        "title": "Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger",
        "link_suffix": "/forum?id=YVcVbYYy2x",
        "link": "https://openreview.net/forum?id=YVcVbYYy2x",
        "pdf_link": "https://openreview.net/pdf?id=YVcVbYYy2x",
        "keywords": "Large Language Model, Meta-Cognition, Tool Use, Representation Engineering",
        "abstract": "Large language models (LLMs) have demonstrated remarkable emergent capabilities, reshaping the landscape of functional tasks by leveraging external tools to tackle complex problems, such as those requiring real-time data or specialized input/output processing. Existing research primarily focuses on equipping LLMs with a broader array of diverse external tools (e.g., program interpreters, search engines, weather/map applications) but overlooks the necessity of tool usage, invoking external tools indiscriminately without assessing their actual need. This naive strategy leads to two significant issues: 1) increased latency due to prolonged processing times, and 2) potential errors arising from communication between LLMs and external tools, resulting in faulty outputs. In this paper, we introduce a concept we term meta-cognition as a proxy for LLM self-capability, and we propose an adaptive decision-making strategy for invoking external tools, referred to as MeCo. Specifically, MeCo focuses on representation space to capture emergent representations of high-level cognitive phenomena that quantify the LLM's meta-cognitive scores, thereby guiding decisions on when to use external tools. Notably, MeCo is fine-tuning-free, incurring minimal cost, and our experiments demonstrate that MeCo accurately detects the model's internal cognitive signals. More importantly, our approach significantly enhances decision-making accuracy in tool use for multiple base models across various benchmarks."
    },
    {
        "title": "Graph Neural Networks for Interferometer Simulations",
        "link_suffix": "/forum?id=pWrcpPsVas",
        "link": "https://openreview.net/forum?id=pWrcpPsVas",
        "pdf_link": "https://openreview.net/pdf?id=pWrcpPsVas",
        "keywords": "graph neural networks, physics simulation, LIGO",
        "abstract": "In recent years, graph neural networks (GNNs) have shown tremendous promise in solving  problems in high energy physics, materials science, and fluid dynamics. In this work, we introduce a new application for GNNs in the physical sciences: instrumentation design. As a case study, we apply GNNs to simulate models of the Laser Interferometer Gravitational-wave Observatory (LIGO), and show that they are capable of accurately capturing the complex optical physics at play, while achieving runtimes 815 times faster than state of the art simulation packages. We discuss the unique challenges this problem provides for machine learning models. In addition, we provide a dataset of high-fidelity optical physics simulations for three interferometer topologies, which can be used as a benchmarking suite for future work in this direction."
    },
    {
        "title": "Injecting Universal Jailbreak Backdoors into LLMs in Minutes",
        "link_suffix": "/forum?id=aSy2nYwiZ2",
        "link": "https://openreview.net/forum?id=aSy2nYwiZ2",
        "pdf_link": "https://openreview.net/pdf?id=aSy2nYwiZ2",
        "keywords": "Large language model, Jailbreak, Backdoor, Attack, Safety, Model Editing",
        "abstract": "Jailbreak backdoor attacks on LLMs have garnered attention for their effectiveness and stealth. However, existing methods rely on the crafting of poisoned datasets and the time-consuming process of fine-tuning. In this work, we propose JailbreakEdit, a novel jailbreak backdoor injection method that exploits model editing techniques to inject a universal jailbreak backdoor into safety-aligned LLMs with minimal interventionin minutes. JailbreakEdit integrates a multi-node target estimation to estimate the jailbreak space, thus creating shortcuts from the backdoor to this estimated jailbreak space that induce jailbreak actions. Our attack effectively shifts the models' attention by attaching strong semantics to the backdoor, enabling it to bypass internal safety mechanisms. Experimental results show that JailbreakEdit achieves a high jailbreak success rate on jailbreak prompts while preserving generation quality, and safe performance on normal queries. Our findings underscore the effectiveness, stealthiness, and explainability of JailbreakEdit, emphasizing the need for more advanced defense mechanisms in LLMs."
    },
    {
        "title": "Efficient Predictive Counterfactual Regret Minimization+Algorithm in Solving Extensive-Form Games",
        "link_suffix": "/forum?id=njyZgDDeY4",
        "link": "https://openreview.net/forum?id=njyZgDDeY4",
        "pdf_link": "https://openreview.net/pdf?id=njyZgDDeY4",
        "keywords": "Imperfect-Information Extensive-Form Games, Nash Equilibrium, Counterfactual Regret Minimization",
        "abstract": "Imperfect-information extensive-form games (IIGs) serve as a foundational model for capturing interactions among multiple agents in sequential settings with hidden information. A common objective of IIGs is to calculate a Nash equilibrium (NE). Counterfactual Regret Minimization (CFR) algorithms have been widely developed to learn an NE in two-player zero-sum IIGs. Among CFR algorithms, Predictive CFR$^+$ (PCFR$^+$) is powerful, usually achieving an extremely fast empirical convergence rate. However, PCFR$^+$ suffers from the significant discrepancy between strategies represented by explicit accumulated counterfactual regrets across two consecutive iterations, which decreases the empirical convergence rate of PCFR$^+$ in practice. To mitigate this significant discrepancy, we introduce a novel and effective variant of PCFR$^+$, termed Pessimistic PCFR$^+$ (P2PCFR$^+$),  minimizing the discrepancy between strategies represented by implicit and explicit accumulated regrets within the same iteration. We provide theoretical proof to show that P2PCFR$^+$ exhibits a faster theoretical convergence rate than PCFR$^+$. Experimental results demonstrate that P2PCFR$^+$ outperforms other tested CFR variants."
    },
    {
        "title": "Federated Time Series Generation on Feature and Temporally Misaligned Data",
        "link_suffix": "/forum?id=wmFp2aMhi0",
        "link": "https://openreview.net/forum?id=wmFp2aMhi0",
        "pdf_link": "https://openreview.net/pdf?id=wmFp2aMhi0",
        "keywords": "time series, generative model, federated learning",
        "abstract": "Distributed time series data presents a challenge for federated learning, as clients often possess different feature sets and have misaligned time steps. Existing federated time series models are limited by the assumption of perfect temporal or feature alignment across clients. In this paper, we propose FedTDD, a novel federated time series diffusion model that jointly learns a synthesizer across clients. At the core of FedTDD is a novel data distillation and aggregation framework that reconciles the differences between clients by imputing the misaligned timesteps and features. In contrast to traditional federated learning, FedTDD learns the correlation across clients' time series through the exchange of local synthetic outputs instead of model parameters. A coordinator iteratively improves a global distiller network by leveraging shared knowledge from clients through the exchange of synthetic data. As the distiller becomes more refined over time, it subsequently enhances the quality of the clients' local feature estimates, allowing each client to then improve its local imputations for missing data using the latest, more accurate distiller.  Experimental results on five datasets demonstrate FedTDD's effectiveness compared to centralized training, and the effectiveness of sharing synthetic outputs to transfer knowledge of local time series. Notably, FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FID and Correlational scores."
    },
    {
        "title": "Spike-to-excite: photosensitive seizures in biologically-realistic spiking neural networks",
        "link_suffix": "/forum?id=Iemy0Fc3Pw",
        "link": "https://openreview.net/forum?id=Iemy0Fc3Pw",
        "pdf_link": "https://openreview.net/pdf?id=Iemy0Fc3Pw",
        "keywords": "photosensitive epilepsy, spiking neural network, V1, prediction, deep brain stimulation",
        "abstract": "Photosensitive Epilepsy (PE) is a neurological disorder characterized by seizures triggered by harmful visual stimuli, such as flashing lights and high-contrast patterns. The mechanisms underlying PE remain poorly understood, and to date, no computational model has captured the phenomena associated with this condition. Biologically detailed spiking networks trained for efficient prediction of natural scenes have been shown to capture V1-like characteristics. Here, we show that these models display seizure-like activity in response to harmful stimuli while retaining healthy responses to non-provocative stimuli when post-synaptic inhibitory connections are weakened. Notably, our adapted model resembles the motion tuning and contrast gain responses of excitatory V1 neurons in mice with optogenetically reduced inhibitory activity. We offer testable predictions underlying the pathophysiology of PE by exploring how reduced inhibition leads to seizure-like activity. Finally, we show that artificially injecting pulsating input current into the model units prevents seizure-like activity and restores baseline function. In summary, we present a model of PE that offers new insights to understand and treat this condition."
    },
    {
        "title": "Accurate Split Learning on Noisy Signals",
        "link_suffix": "/forum?id=3vE4B61VSw",
        "link": "https://openreview.net/forum?id=3vE4B61VSw",
        "pdf_link": "https://openreview.net/pdf?id=3vE4B61VSw",
        "keywords": "Split Learning, Denoising techniques",
        "abstract": "Noise injection is applied in Split Learning to address privacy concerns about data leakage. Previous works protect Split Learning by adding noise to the intermediate results during the forward pass. Unfortunately, noisy signals significantly degrade the accuracy of Split Learning training. This paper focuses on improving the training accuracy of Split Learning over noisy signals while protecting training data from reconstruction attacks. We propose two denoising techniques, namely scaling and random masking. Our theoretical results show that both of our denoising techniques accurately estimate the intermediate variables during the forward pass of Split Learning. Moreover, our experiments with deep neural networks demonstrate that the proposed denoising approaches allow Split Learning to tolerate high noise levels while achieving almost the same accuracy as the noise-free baseline. Interestingly, we show that after applying our denoising techniques, the resultant network is more resilient against a state-of-the-art attack compared to the simple noise injection approach."
    },
    {
        "title": "LBG: LNE-based Blocking Generation Against Data Contamination on Large Language Models",
        "link_suffix": "/forum?id=HcyVr9SlwR",
        "link": "https://openreview.net/forum?id=HcyVr9SlwR",
        "pdf_link": "https://openreview.net/pdf?id=HcyVr9SlwR",
        "keywords": "detecting data contamination, fairly evaluating LLMs",
        "abstract": "Data contamination gradually becomes inevitable during the development of large language models  (LLMs), meaning the training data commonly integrates those evaluation benchmarks unintentionally. This subsequently makes it hard to benchmark LLMs fairly. This paper introduces a novel framework called LBG  (\\textbf{L}NE-based \\textbf{B}locking \\textbf{G}eneration) for both contamination detection and mitigation for evaluating contaminated LLMs. For the first component of LBG, LBG reports a SOTA performance on our proposed length normalized entropy  (LNE) to identify potential contamination by detecting anomalies on possibly contaminated LLMs. For the second component of LBG, LBG reports a SOTA performance on the mitigation of the impact of data contamination by applying LNE within a novel blocking generation strategy, specialized to adjust generation processes and re-calibrate performance metrics by suppressing the maximum value of output candidates during the generation process. We conduct extensive experiments on both contamination detection and contamination mitigation evaluation tasks, on both code generation and mathematical reasoning scenarios. The results indicate that LBG achieves an obvious SOTA performance throughout the experiments conducted in this paper. Simultaneously, LGB is lightweight and costs obviously fewer computational costs  (nearly 25x) than the previous work. We hope our method will open new research avenues on data contamination for LLMs. We plan to release the resources upon publication of this work to facilitate future work."
    },
    {
        "title": "Leveraging VLMs for MUDA：A Category-Specific Prompting with Multi-Modal Low-Rank Adapter",
        "link_suffix": "/forum?id=kYUpFKqtNe",
        "link": "https://openreview.net/forum?id=kYUpFKqtNe",
        "pdf_link": "https://openreview.net/pdf?id=kYUpFKqtNe",
        "keywords": "Multi-source Unsupervised Domain Adaptation, Low-Rank Adaptation, Pre-trained Vision-Language Model, Multi-Modal Alignment",
        "abstract": "Multi-Source Domain Adaptation (MSDA) aims to adaptively apply knowledge from multiple source pre-trained models to an unlabeled target domain. Current MSDA methods typically require extensive parameter tuning for each source model, which becomes computationally expensive, especially when dealing with numerous source domains or larger source models. With the recent advancements of Vision-Language Models (VLMs) as natural source models, the challenges of cross-domain tasks based on multi-source domains have evolved: 1) VLMs rapidly adapt to downstream tasks through prompt tuning, yet learnable prompt tokens are prone to overfftting due to limited training samples; 2) Rapidly leveraging knowledge from multiple source domains and encouraging the learning\n of invariant representations across these domains is a central issue; 3) The presence of visual and textual domain gaps, as well as cross-modal misalignment, can signiffcantly impact model performance. In this paper, we propose a ffnetuning framework that integrates prompts with multimodal Low-Rank Adaptation (LoRA). This framework employs learnable prompt features as shared characteristics\n across different domains and utilizes multimodal LoRA matrices to represent domain-speciffc features for individual ffne-tuning of VLMs across multiple source domains. Furthermore, it encourages interaction between ffne-tuning parameters from different domains and modalities to enhance consistency. We combine all source domain-speciffc LoRA modules into an integrated module using a set of coefffcients and adapt this integrated module to learn on the target domain. Extensive experiments demonstrate that our approach achieves signiffcant improvements on standard image classiffcation benchmark datasets, highlighting its effectiveness in multi-source domain adaptation tasks."
    },
    {
        "title": "Preference fine-tuning for factuality in chest X-ray interpretation models without human feedback",
        "link_suffix": "/forum?id=pK2636Prbq",
        "link": "https://openreview.net/forum?id=pK2636Prbq",
        "pdf_link": "https://openreview.net/pdf?id=pK2636Prbq",
        "keywords": "LLMs, VLMs, preference fine-tuning, RLHF, DPO, DAAs, preference alignment, radiology, chest X-rays",
        "abstract": "Radiologists play a crucial role by translating medical images into medical reports. However, the field faces staffing shortages and increasing workloads. While automated approaches using vision-language models (VLMs) show promise as assistants, they require exceptionally high accuracy. Most current VLMs in radiology rely solely on supervised fine-tuning (SFT). Meanwhile, in the general domain, additional preference fine-tuning has become standard practice. The challenge in radiology lies in the prohibitive cost of obtaining radiologist feedback. We propose a scalable automated preference alignment technique for VLMs in radiology, focusing on chest X-ray (CXR) report generation. Our method leverages publicly available datasets with an LLM-as-a-Judge mechanism, eliminating the need for additional expert radiologist feedback. We evaluate and benchmark five direct alignment algorithms (DAAs). Our results show up to a 57.4% improvement in average GREEN scores, a LLM-based metric for evaluating CXR reports, and a 9.2% increase in an average across six metrics (domain specific and general), compared to the SFT baseline. We study reward overoptimization via length exploitation, with reports lengthening by up to 3.2x. To assess a potential alignment tax, we benchmark on six additional diverse tasks, finding no significant degradations. A reader study involving four board-certified radiologists indicates win rates of up to 0.62 over the SFT baseline, while significantly penalizing verbosity. Our analysis provides actionable insights for the development of VLMs in high-stakes fields like radiology."
    },
    {
        "title": "Quantum Algorithm for Online Learning of MDPs with Continuous State Space",
        "link_suffix": "/forum?id=IEnYsFjFzI",
        "link": "https://openreview.net/forum?id=IEnYsFjFzI",
        "pdf_link": "https://openreview.net/pdf?id=IEnYsFjFzI",
        "keywords": "Quantum algorithm, Markov decision processes, Online algorithms, Quantum reinforcement learning",
        "abstract": "We propose a novel quantum online algorithm for learning Markov Decision Processes (MDPs) with continuous state space in the average reward model. Our algorithm is based on the line of work on classical online UCCRL algorithms by Ortner and Ryabko (NeurIPS'12). To the best of our knowledge, our work is the first to consider MDPs with continuous state space in the fault-tolerant quantum setting. In the case where the state space is one-dimensional, we show that, via quantum-accessible environments, our quantum algorithm obtains a $\\tilde O(T^{1/2})$ regret, improving upon the $\\tilde O(T^{2/3})$ bound of Lakshmanan, Ortner, and Ryabko (PMLR'15), where $T$ is the number of iterations of the algorithm. For a general $d$-dimensional state space, the regret is bounded by $\\tilde O(T^{1-1/2d})$. Our quantum algorithm uses quantum extended value iteration as a subroutine, which is our second main contribution, and may be of independent interest. We show that quantum extended value iteration achieves a subquadratic speedup in the size of the discretized state space $\\mathcal{S}$ and a quadratic speedup in the size of the action space $\\mathcal{A}$, as compared to its classical counterpart. As our third contribution, we study the limiting behaviour of the sequence of value functions generated by quantum extended value iteration. We show that the sequence converges to the optimal average reward $\\rho^*$ up to $\\epsilon$ additive error, for some small $\\epsilon>0$."
    },
    {
        "title": "Multi-Agent Reinforcement Learning for Efficient Vision Transformer with Dynamic Token Selection",
        "link_suffix": "/forum?id=vlOfFI9vWO",
        "link": "https://openreview.net/forum?id=vlOfFI9vWO",
        "pdf_link": "https://openreview.net/pdf?id=vlOfFI9vWO",
        "keywords": "efficient vision transformer, dynamic token selection, mappo",
        "abstract": "Vision Transformers (ViT) have revolutionized the field of computer vision by\nleveraging self-attention mechanisms to process images. However, the computational\ncost of ViT increases quadratically with the number of tokens. Dynamic token selection methods which aims to reduce computational cost by discard redundant tokens during inference, are primarily based on non-differentiable binary decisions methods and relaxations methods. However, Reinforcement Learning( (RL) based methods, which have astonishing decision-making ability, is considered to have high variance and high bias, not adopted for dynamic token selection task in previous work. Yet, RL-based methods have been successfully applied to many binary decision problems such as neural pruning, routing, path selection. In this paper, we propose Reinforcement Learning for Dynamic Vision Transformer (RL4DViT), a novel framework for the dynamic token selection task in ViT using RL. By harnessing the powerfull decision-making capabilities of Multi-Agent Reinforcement Learning(MARL) algorithms, our method dynamically prunes redundant tokens based on input complexity, significantly\nreducing the computational cost while maintaining high accuracy. Extensive experiments\non the ImageNet dataset indicate that our approach reduces the computational cost by\nup to 39%, with only a 0.17% decrease in accuracy. To the best of our knowledge,\nthis is the first RL-based token selection method for efficient ViT."
    },
    {
        "title": "Action abstractions for amortized sampling",
        "link_suffix": "/forum?id=ispjankYab",
        "link": "https://openreview.net/forum?id=ispjankYab",
        "pdf_link": "https://openreview.net/pdf?id=ispjankYab",
        "keywords": "GFlowNets, amortized samplers, hierarchical planning, abstractions, macro-actions",
        "abstract": "As trajectories sampled by policies used by reinforcement learning (RL) and generative flow networks (GFlowNets) grow longer, credit assignment and exploration become more challenging, and the long planning horizon hinders mode discovery and generalization.\nThe challenge is particularly pronounced in entropy-seeking RL methods, such as generative flow networks, where the agent must learn to sample from a structured distribution and discover multiple high-reward states, each of which take many steps to reach.\nTo tackle this challenge, we propose an approach to incorporate the discovery of action abstractions, or high-level actions, into the policy optimization process.\nOur approach involves iteratively extracting action subsequences commonly used across many high-reward trajectories and `chunking' them into a single action that is added to the action space.\nIn empirical evaluation on synthetic and real-world environments, our approach demonstrates improved sample efficiency performance in discovering diverse high-reward objects, especially on harder exploration problems.\nWe also observe that the abstracted high-order actions are interpretable, capturing the latent structure of the reward landscape of the action space.\nThis work provides a cognitively motivated approach to action abstraction in RL and is the first demonstration of hierarchical planning in amortized sequential sampling."
    },
    {
        "title": "Test-time Adaptation for Cross-modal Retrieval with Query Shift",
        "link_suffix": "/forum?id=BmG88rONaU",
        "link": "https://openreview.net/forum?id=BmG88rONaU",
        "pdf_link": "https://openreview.net/pdf?id=BmG88rONaU",
        "keywords": "Test-time adaptation, Cross-modal retrieval, Query shift",
        "abstract": "The success of most existing cross-modal retrieval methods heavily relies on the assumption that the given queries follow the same distribution of the source domain. \nHowever, such an assumption is easily violated in real-world scenarios due to the complexity and diversity of queries, thus leading to the query shift problem.\nSpecifically, query shift refers to the online query stream originating from the domain that follows a different distribution with the source one.\nIn this paper, we observe that query shift would not only diminish the uniformity (namely, within-modality scatter) of the query modality but also amplify the gap between query and gallery modalities. \nBased on the observations, we propose a novel method dubbed Test-time adaptation for Cross-modal Retrieval (TCR). \nIn brief, TCR employs a novel module to refine the query predictions (namely, retrieval results of the query) and a joint objective to prevent query shift from disturbing the common space, thus achieving online adaptation for the cross-modal retrieval models with query shift.\nExpensive experiments demonstrate the effectiveness of the proposed TCR against query shift. \nThe code will be released upon acceptance."
    },
    {
        "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
        "link_suffix": "/forum?id=fRmfDqZ2yq",
        "link": "https://openreview.net/forum?id=fRmfDqZ2yq",
        "pdf_link": "https://openreview.net/pdf?id=fRmfDqZ2yq",
        "keywords": "synthetic data generation, diffusion models, language model",
        "abstract": "Recent advancements in large language models (LLMs) have significantly enhanced their knowledge and generative capabilities, leading to a surge of interest in leveraging LLMs for high-quality data synthesis. However, synthetic data generation via prompting LLMs remains challenging due to LLMs' limited understanding of target data distributions and the complexity of prompt engineering, especially for structured formatted data. To address these issues, we introduce DiffLM, a controllable data synthesis framework based on variational autoencoder (VAE), which further (1) leverages diffusion models to reserve more information of original distribution and format structure in the learned latent distribution and (2) decouples the learning of target distribution knowledge from the LLM's generative objectives via a plug-and-play latent feature injection module. As we observed significant discrepancies between the VAE's latent representations and the real data distribution, the latent diffusion module is introduced into our framework to learn a fully expressive latent distribution. Evaluations on seven real-world datasets with structured formatted data (i.e., Tabular, Code and Tool data) demonstrate that DiffLM generates high-quality data, with performance on downstream tasks surpassing that of real data by 2%–7% in certain cases. Data and code will be released upon acceptance."
    },
    {
        "title": "Provence: efficient and robust context pruning for retrieval-augmented generation",
        "link_suffix": "/forum?id=TDy5Ih78b4",
        "link": "https://openreview.net/forum?id=TDy5Ih78b4",
        "pdf_link": "https://openreview.net/pdf?id=TDy5Ih78b4",
        "keywords": "retrieval-augmented generation, context pruning, question answering",
        "abstract": "Retrieval-Augmented Generation improves various aspects of large language models (LLMs) generation,  but suffers from computational overhead caused by long contexts, and the propagation of irrelevant retrieved information into generated responses. Context pruning deals with both aspects, by removing irrelevant parts of retrieved contexts before LLM generation. Existing context pruning approaches are limited, and do not present a universal model that would be bothefficientandrobustin a wide range of scenarios, e.g., when contexts contain a variable amount of relevant information or vary in length, or when evaluated on various domains. In this work, we close this gap and introduce Provence (Pruning and Reranking Of retrieVEd relevaNt ContExts), an efficient and robust context pruner for Question Answering, which dynamically detects the needed amount of pruning for a given context and can be used out-of-the-box for various domains. The three key ingredients of  Provence are formulating the context pruning task as sequence labeling, unifying context pruning capabilities with context reranking, and training on diverse data. Our experimental results show that Provence enables context pruning with negligible to no drop in performance, in various domains and settings, at almost no cost in a standard RAG pipeline. We also conduct a deeper analysis alongside various ablations to provide insights into training context pruners for future work."
    },
    {
        "title": "Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning",
        "link_suffix": "/forum?id=UyU8ETswPg",
        "link": "https://openreview.net/forum?id=UyU8ETswPg",
        "pdf_link": "https://openreview.net/pdf?id=UyU8ETswPg",
        "keywords": "Hallucinations, instruction-tuning",
        "abstract": "Recent studies have identified one aggravating factor of LLM hallucinations as the knowledge inconsistency between pre-training and fine-tuning, where unfamiliar fine-tuning data mislead the LLM to fabricate plausible but wrong outputs. In this paper, we propose a novel fine-tuning strategy called Prereq-Tune to address this knowledge inconsistency and reduce hallucinations. Fundamentally, Prereq-Tune disentangles the learning of skills and knowledge, so the model learns only the task skills without being impacted by the knowledge inconsistency. To achieve this, Prereq-Tune introduces an additional prerequisite learning stage to learn the necessary knowledge for SFT, allowing subsequent SFT to focus only on task skills. Prereq-Tune can also be combined with fictitious synthetic data to enhance the grounding of LLM outputs to their internal knowledge. Experiments show that Prereq-Tune outperforms existing baselines in improving LLM's factuality across short QA and long-form generation tasks. It also opens new possibilities for knowledge-controlled generation in LLMs."
    },
    {
        "title": "Do better language models have crisper vision?",
        "link_suffix": "/forum?id=hLIlN0f4ix",
        "link": "https://openreview.net/forum?id=hLIlN0f4ix",
        "pdf_link": "https://openreview.net/pdf?id=hLIlN0f4ix",
        "keywords": "large language models, computer vision, vision-language model, zero-shot image classification, efficient deep learning",
        "abstract": "How well do text-only Large Language Models (LLMs) grasp the visual world? As LLMs are increasingly used in computer vision, addressing this question becomes both fundamental and pertinent. However, existing studies have primarily focused on limited scenarios, such as their ability to generate visual content or cluster multimodal data. To this end, we propose the Visual Text Representation Benchmark (ViTeRB) to isolate key properties that make language models well-aligned with the visual world. With this, we identify large-scale decoder-based LLMs as ideal candidates for representing text in vision-centric contexts, counter to the current practice of utilizing text encoders. Building on these findings, we propose ShareLock, an ultra-lightweight CLIP-like model. By leveraging precomputable frozen features from strong vision and language models, ShareLock achieves an impressive 51% accuracy on ImageNet despite utilizing just 563k image-caption pairs. Moreover, training requires only 1 GPU hour (or 10 hours including the precomputation of features) - orders of magnitude less than prior methods. Code will be released."
    },
    {
        "title": "E3D: Enhancing Sparsely-Supervised 3D Object Detector with Large Multimodal Models",
        "link_suffix": "/forum?id=Nx6Bb5uxfI",
        "link": "https://openreview.net/forum?id=Nx6Bb5uxfI",
        "pdf_link": "https://openreview.net/pdf?id=Nx6Bb5uxfI",
        "keywords": "sparsely-supervised object detection, point cloud, large multimodal model",
        "abstract": "Recently, sparsely-supervised 3D object detection has gained great attention, achieving performance close to that of fully-supervised 3D objectors with only a few annotated instances. Nevertheless, these methods suffer challenges when the accurate labels are extremely limited. In this paper, we propose an Ehanced 3D object Detection strategy, termed E3D, explicitly utilizing the prior knowledge from Large Multimodal Models (LMMs) to enhance the feature discrimination capability of the 3D detector under sparse annotation settings. Specifically, we first develop a Confident Points Semantic Transfer (CPST) module that generates high-quality seed points through boundary-constrained center cluster selection. Based on these seed points, we introduce a Dynamic Cluster Pseudo-label Generation (DCPG) module that yields pseudo-supervision signals from the geometry shape of multi-scale neighbor points. Additionally, we design a Distribution Shape score (DS score) that chooses high-quality supervision signals for the initial training of the 3D detector. By utilizing E3D, existing leading sparsely-supervised CoIn++ is improved by an average of 11.63% under the annotation rate of 2%. Moreover, we have verified our E3D in the zero-shot setting, and the results demonstrate its performance exceeding that of the state-of-the-art methods. The code will be made publicly available."
    },
    {
        "title": "Second Order Bounds for Contextual Bandits with Function Approximation",
        "link_suffix": "/forum?id=h6ktwCPYxE",
        "link": "https://openreview.net/forum?id=h6ktwCPYxE",
        "pdf_link": "https://openreview.net/pdf?id=h6ktwCPYxE",
        "keywords": "theory, contextual bandits, variance aware, second order, bandits",
        "abstract": "Many works have developed algorithms no-regret algorithms for contextual bandits with function approximation, where the mean rewards over context-action pairs belongs to a function class $\\mathcal{F}$. Although there are many approaches to this problem, one that has gained in importance is the use of algorithms based on the optimism principle such as optimistic least squares. It can be shown the regret of this algorithm scales as $\\widetilde{\\mathcal{O}}\\left(\\sqrt{d_{\\mathrm{eluder}}(\\mathcal{F}) \\log(\\mathcal{F}) T }\\right)$ where $d_{\\mathrm{eluder}}(\\mathcal{F})$ is a statistical measure of the complexity of the function class $\\mathcal{F}$ known as eluder dimension.  Unfortunately, even if the variance of the measurement noise of the rewards at time $t$ equals $\\sigma_t^2$ and these are close to zero, the optimistic least squares algorithm’s regret scales with $\\sqrt{T}$. In this work we are the first to develop algorithms that satisfy regret bounds for contextual bandits with function approximation of the form $\\widetilde{\\mathcal{O}}\\left( \\sigma \\sqrt{\\log(\\mathcal{F})d_{\\mathrm{eluder}}(\\mathcal{F}) T } + d_{\\mathrm{eluder}}(\\mathcal{F}) \\cdot \\log(|\\mathcal{F}|)\\right) $ when the variances are unknown and satisfy $\\sigma_t^2 = \\sigma$ for all $t$ and $\\widetilde{\\mathcal{O}}\\left( d_{\\mathrm{eluder}}(\\mathcal{F})\\sqrt{\\log(\\mathcal{F})\\sum_{t=1}^T \\sigma_t^2  } + d_{\\mathrm{eluder}}(\\mathcal{F}) \\cdot \\log(|\\mathcal{F}|)\\right) $  when the variances change every time-step. These bounds generalize existing techniques for deriving second order bounds in contextual linear problems."
    },
    {
        "title": "I-Lora: Iterative Merging of Routing-Tuned Low-Rank Adapters for Multi-task Learning",
        "link_suffix": "/forum?id=CRkoMdDlFh",
        "link": "https://openreview.net/forum?id=CRkoMdDlFh",
        "pdf_link": "https://openreview.net/pdf?id=CRkoMdDlFh",
        "keywords": "Multitask learning, Low-rank adaption, Vision-language-models",
        "abstract": "The advancement of vision-language models has significantly boosted the performance of embodied and game AI, endowing them with more robust general visual understanding capabilities and logical abilities for action planning. However, the substantial computational cost of model training and the performance degradation during fine-tuning limit the models' ability to learn emerging new tasks continually. Creating a versatile and dynamically updatable vision-language model is an essential area of research. To this end, we propose a Low-Rank Adapter-based fine-tuning approach called I-LoRA, which enables iterative and independent learning of new tasks while preserving the logical capabilities of the previously trained model. Specifically, we first design the routing-tuning method to minimize the impact of original capabilities from the new task by minimizing activation values of LoRA matrices as low as possible in the general task. Secondly, we propose a novel approach to iteratively merge new adapters, allowing for continuous integration of adapters trained on new tasks without being influenced by task order, thereby reducing interference between them. Finally, we conducted extensive experiments on public datasets with significant behavioral and logical differences between tasks. The results demonstrate that our approach achieves excellent single-task performance, strong multi-task compatibility, and flexible scalability without increasing the number of model parameters."
    },
    {
        "title": "MIGA: Mixture-of-Experts with Group Aggregation for Stock Market Prediction",
        "link_suffix": "/forum?id=MzmeLlDOkN",
        "link": "https://openreview.net/forum?id=MzmeLlDOkN",
        "pdf_link": "https://openreview.net/pdf?id=MzmeLlDOkN",
        "keywords": "mixture-of-expert, stock market prediction",
        "abstract": "Stock market prediction has remained an extremely challenging problem for many\ndecades owing to its inherent high volatility and low information noisy ratio.\nExisting solutions based on machine learning or deep learning demonstrate superior\nperformance by employing a single model trained on the entire stock dataset to\ngenerate predictions across all types of stocks. However, due to the significant\nvariations in stock styles and market trends, a single end-to-end model struggles to\nfully capture the differences in these stylized stock features, leading to relatively\ninaccurate predictions for all types of stocks. In this paper, we present MIGA, a\nnovel Mixture of Expert with Group Aggregation framework designed to generate\nspecialized predictions for stocks with different styles of by dynamically switching\nbetween distinct style experts. To promote collaboration among different experts\nin MIGA, we propose a novel inner group attention architecture, enabling experts\nwithin the same group to share information and thereby enhancing the overall\nperformance of all experts. As a result, MIGA significantly outperforms other\nend-to-end models on three Chinese Stock Index benchmarks including CSI300,\nCSI500 and CSI1000. Notably, MIGA-Conv reaches 24 % excess annual return on\nCSI300 benchmark, surpassing the previous state-of-the-art model by 8% absolute.\nFurthermore, we conduct a comprehensive analysis of mixture of experts for stock\nmarket prediction, providing valuable insights for future research."
    }
]
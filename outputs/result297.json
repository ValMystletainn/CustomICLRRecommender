[{"title": "\u03b1-OCC: Uncertainty-Aware Camera-based 3D Semantic Occupancy Prediction", "link_suffix": "/forum?id=sgaMYvGRG5", "link": "https://openreview.net/forum?id=sgaMYvGRG5", "pdf_link": "https://openreview.net/pdf?id=sgaMYvGRG5", "keywords": "Uncertainty Propagation, Semantic Occupancy Prediction, Conformal Prediction", "abstract": "In the realm of autonomous vehicle (AV) perception, comprehending 3D scenes is paramount for tasks such as planning and mapping. Camera-based 3D Semantic Occupancy Prediction (OCC) aims to infer scene geometry and semantics from limited observations. While it has gained popularity due to affordability and rich visual cues, existing methods often neglect the inherent uncertainty in models. To address this, we propose an uncertainty-aware camera-based 3D semantic occupancy prediction method ($\\alpha$-OCC). Our approach includes an uncertainty propagation framework (Depth-UP) from depth models to enhance geometry completion (up to 11.58% improvement) and semantic segmentation (up to 12.95% improvement) for a variety of OCC models. Additionally, we propose a hierarchical conformal prediction (HCP) method to quantify OCC uncertainty, effectively addressing the high-level class imbalance in OCC datasets. On the geometry level, we present a novel KL-based score function that significantly improves the occupied recall of safety-critical classes (45% improvement) with minimal performance overhead (3.4% reduction). For uncertainty quantification, we demonstrate the ability to achieve smaller prediction set sizes while maintaining a defined coverage guarantee. Compared with baselines, it reduces up to 92% set size. Our contributions represent significant advancements in OCC accuracy and robustness, marking a noteworthy step forward in autonomous perception systems.", "title_embedding_index": 14800, "title_abs_embedding_index": 14825}, {"title": "ER2Score: An Explainable and Customizable Metric for Assessing Radiology Reports with LLM-based Rewards", "link_suffix": "/forum?id=T2dhpC3N0d", "link": "https://openreview.net/forum?id=T2dhpC3N0d", "pdf_link": "https://openreview.net/pdf?id=T2dhpC3N0d", "keywords": "Radiology Report Generation, Auto Evaluation Metrics, Reward Model, LLM, RLHF", "abstract": "In recent years, the automated generation of radiology reports (R2Gen) has seen considerable growth, introducing new challenges in evaluation due to its complex nature. Traditional metrics often fail to provide accurate evaluations due to their reliance on rigid word-matching techniques or their exclusive focus on pathological entities, leading to inconsistencies with human assessments. To bridge this gap, we introduce ER2Score, an automatic evaluation metric designed specifically for R2Gen that harnesses the capabilities of Large Language Models (LLMs). Our metric leverages a reward model and a tailored design for training data, allowing customization of evaluation criteria based on user-defined needs. It not only scores reports according to user-specified criteria but also provides detailed sub-scores, enhancing interpretability and allowing users to adjust the criteria between clinical and linguistic aspects of reports. Leveraging GPT-4, we generate extensive evaluation data for training based on two different scoring systems, respectively, including reports of varying quality alongside corresponding scores. These GPT-generated reports are then paired as accepted and rejected samples to train an LLM towards a reward model, which assigns higher rewards to the report with high quality. Our proposed loss function enables this model to simultaneously output multiple individual rewards corresponding to the number of evaluation criteria, with their summation as our final ER2Score. Our experiments demonstrate ER2Score's heightened correlation with human judgments and superior performance in model selection compared to traditional metrics. Notably, our model's capability to provide not only a single overall score but also scores for individual evaluation items enhances the interpretability of the assessment results. We also showcase the flexible training of our model to varying evaluation systems. We will release the code on GitHub.", "title_embedding_index": 14801, "title_abs_embedding_index": 14826}, {"title": "Machine Unlearning for Contrastive Learning under Auditing", "link_suffix": "/forum?id=k2HZ4Mu2Pb", "link": "https://openreview.net/forum?id=k2HZ4Mu2Pb", "pdf_link": "https://openreview.net/pdf?id=k2HZ4Mu2Pb", "keywords": "Machine unlearning, Contrastive learning", "abstract": "Machine unlearning offers effective solutions for revoking the influence of specific training data on pre-trained model parameters. While existing approaches address unlearning for classification and generative models, they overlook an important category of machine learning models: contrastive learning (CL) methods.\nThis paper addresses this gap by introducing the Machine Unlearning for Contrastive Learning (MUC) framework and adapting existing methods. We identify limitations in current approaches, noting that several methods perform inadequately as unlearners and that existing auditing tools insufficiently validate unlearning effects in contrastive learning. To address these issues, we propose Alignment Calibration (AC), a novel method that explicitly considers contrastive learning properties and optimizes towards new auditing metrics for easy verification of unlearning. Through empirical comparisons with baseline methods on SimCLR, MoCo, and CLIP, we demonstrate that AC: (1) achieves state-of-the-art performance, approximating exact unlearning (retraining); (2) enables data owners to clearly visualize unlearning effects through black-box auditing.", "title_embedding_index": 14802, "title_abs_embedding_index": 14827}, {"title": "Lessons Learned from a Unifying Empirical Study of Parameter-Efficient Transfer Learning (PETL) in Visual Recognition", "link_suffix": "/forum?id=Fb93MfxX7T", "link": "https://openreview.net/forum?id=Fb93MfxX7T", "pdf_link": "https://openreview.net/pdf?id=Fb93MfxX7T", "keywords": "Parameter-Efficient Transfer Learning, Parameter-Efficient Fine-Tuning, Visual Recognition", "abstract": "Parameter-efficient transfer learning (PETL) has attracted significant attention lately, due to the increasing size of pre-trained models and the need to fine-tune them for superior downstream performance. This community-wide enthusiasm has sparked a plethora of approaches. Nevertheless, a systematic study to understand their performance and suitable application scenarios is lacking, leaving questions like ''when to apply PETL'' and ''which approach to use'' largely unanswered, especially in visual recognition. In this paper, we conduct a unifying empirical study of representative PETL approaches in the context of Vision Transformers (ViT). We systematically tune their hyper-parameters to fairly compare their accuracy on downstream tasks. Our study not only offers a valuable user guide but also unveils several new insights. First, if tuned carefully, different PETL approaches can obtain quite similar accuracy in the low-shot benchmark VTAB-1K. This includes simple approaches like fine-tuning the bias terms that were reported inferior. Second, though with similar accuracy, we find that PETL approaches make different mistakes and high-confidence predictions, likely due to their different inductive biases. Such an inconsistency (or complementariness) opens up the opportunity for ensemble methods, and we make preliminary attempts at this. Third, going beyond the commonly used low-shot tasks, we find that PETL is also useful in many-shot regimes --- it achieves comparable and sometimes better accuracy than full fine-tuning, using much fewer learnable parameters. Last but not least, we investigate PETL's ability to preserve a pre-trained model's robustness to distribution shifts (e.g., a CLIP backbone). Perhaps not surprisingly, PETL approaches outperform full fine-tuning alone. However, with weight-space ensembles, the fully fine-tuned model can better balance target (i.e., downstream) distribution and distribution shift performance, suggesting a future research direction for PETL.", "title_embedding_index": 14803, "title_abs_embedding_index": 14828}, {"title": "Mechanism design with multi-armed bandit", "link_suffix": "/forum?id=ylhKbwJrjC", "link": "https://openreview.net/forum?id=ylhKbwJrjC", "pdf_link": "https://openreview.net/pdf?id=ylhKbwJrjC", "keywords": "mechanism design, incentive compatibility, efficiency, individual rationality, budget balance, multi-armed bandit, probably approximately correct", "abstract": "A popular approach of automated mechanism design is to formulate a linear program (LP) whose solution gives a mechanism with desired properties.  We analytically derive a class of optimal solutions for such an LP that gives mechanisms achieving standard properties of efficiency, incentive compatibility, strong budget balance (SBB), and individual rationality (IR), where SBB and IR are satisfied in expectation.  Notably, our solutions are represented by an exponentially smaller number of essential variables than the original variables of LP.  Our solutions, however, involve a term whose exact evaluation requires solving a certain optimization problem exponentially many times as the number of players grows.  We thus evaluate this term by modeling it as the problem of estimating the mean reward of the best arm in multi-armed bandit (MAB), propose a Probably and Approximately Correct estimator, and prove its asymptotic optimality by establishing a lower bound on its sample complexity.  This MAB approach reduces the number of times the optimization problem is solved from exponential to linear.  Numerical experiments show that the proposed approach finds mechanisms that are guaranteed to achieve desired properties with high probability for environments with up to 128 players, which substantially improves upon the prior work.", "title_embedding_index": 14804, "title_abs_embedding_index": 14829}, {"title": "Tractable Multi-Agent Reinforcement Learning through Behavioral Economics", "link_suffix": "/forum?id=stUKwWBuBm", "link": "https://openreview.net/forum?id=stUKwWBuBm", "pdf_link": "https://openreview.net/pdf?id=stUKwWBuBm", "keywords": "behavioral economics, risk-aversion, multi-agent reinforcement learning, quantal response, bounded rationality", "abstract": "A significant roadblock to the development of principled multi-agent reinforcement learning is the fact that desired solution concepts like Nash equilibria may be intractable to compute. To overcome this obstacle, we take inspiration from behavioral economics and show that---by imbuing agents with important features of human decision-making like risk aversion and bounded rationality---a class of risk-averse quantal response equilibria (RQE) become tractable to compute in all $n$-player matrix and finite-horizon Markov games.  In particular, we show that they emerge as the endpoint of no-regret learning in suitably adjusted versions of the games. Crucially, the class of computationally tractable RQE is independent of the underlying game structure and only depends on agents' degree of risk-aversion and bounded rationality. To validate the richness of this class of solution concepts we show that it captures peoples' patterns of play in a number of 2-player matrix games previously studied in experimental economics. Furthermore, we give a first analysis of the sample complexity of computing these equilibria in finite-horizon Markov games when one has access to a generative model and validate our findings on a simple multi-agent reinforcement learning benchmark.", "title_embedding_index": 14805, "title_abs_embedding_index": 14830}, {"title": "Faster Inference of Flow-Based Generative Models via Improved Data-Noise Coupling", "link_suffix": "/forum?id=rsGPrJDIhh", "link": "https://openreview.net/forum?id=rsGPrJDIhh", "pdf_link": "https://openreview.net/pdf?id=rsGPrJDIhh", "keywords": "generative models, flow matching", "abstract": "Conditional Flow Matching (CFM), a simulation-free method for training continuous normalizing flows, provides an efficient alternative to diffusion models for key tasks like image and video generation. The performance of CFM in solving these tasks depends on the way data is coupled with noise. A recent approach uses minibatch optimal transport (OT) to reassign noise-data pairs in each training step to streamline sampling trajectories and thus accelerate inference. However, its optimization is restricted to individual minibatches, limiting its effectiveness on large datasets. To address this shortcoming, we introduce LOOM-CFM (Looking Out Of Minibatch-CFM), a novel method to extend the scope of minibatch OT by preserving and optimizing these assignments across minibatches over training time. Our approach demonstrates consistent improvements in the sampling speed-quality trade-off across multiple datasets. LOOM-CFM also enhances distillation initialization and supports high-resolution synthesis in latent space training.", "title_embedding_index": 14806, "title_abs_embedding_index": 14831}, {"title": "Clustering on Skewed Cost Distributions", "link_suffix": "/forum?id=ODzthXYPtp", "link": "https://openreview.net/forum?id=ODzthXYPtp", "pdf_link": "https://openreview.net/pdf?id=ODzthXYPtp", "keywords": "clustering, PTAS", "abstract": "In this paper, we tackle the problem of $(k,z)$-clustering, a generalization of the well-known $k$-means, $k$-medians and $k$-medoids problems that is known to be APX hard, i.e., impossible to approximate within a multiplicative factor of $1.06$ in polynomial time for $n$ and $k$ unless P=NP. Due to the APX-hardness, the fastest $(1+\\varepsilon)$-approximation scheme proposed by Feldman et al. (2007), exhibits a run time with a polynomial dependency on $n$, but an exponential dependency $2^{\\tilde{\\mathcal{O}}(k/\\varepsilon)}$ on $k$. We observe that a $(1+\\varepsilon)$-approximation in truly polynomial time is feasible if the data sets exhibit sufficiently skewed distributions. Indeed in practical scenarios, data sets often exhibit a heavy skewness, leading to the overall clustering cost disproportionately dominated by a few clusters. We propose a novel algorithm that adapts the traditional local search technique to effectively manage $(s, 1- \\varepsilon^{z+1})$-skewed datasets with a run time of $(nk/\\varepsilon)^{\\mathcal{O}(s+1/\\varepsilon)}$ for discrete case and $\\tilde{\\mathcal{O}}(nk) + (k \\log n)^{\\tilde{\\mathcal{O}}(s+1/\\varepsilon)}$ for continuous case. Our method is particularly effective with Zipfian distributions with exponent $p>1$, where $s = \\mathcal{O}\\left(\\frac{1}{\\varepsilon^{(z+1)/(p-1)}}\\right)$.", "title_embedding_index": 14807, "title_abs_embedding_index": 14832}, {"title": "Gaussian Ensemble Belief Propagation for Efficient Inference in High-Dimensional, Black-box Systems", "link_suffix": "/forum?id=PLskiLUBDW", "link": "https://openreview.net/forum?id=PLskiLUBDW", "pdf_link": "https://openreview.net/pdf?id=PLskiLUBDW", "keywords": "factor graph, data assimilation, ensemble kalman filter, gaussian belief propagation, geospatial, probabilistic graphical model, hierarchical model", "abstract": "Efficient inference in high-dimensional models is a central challenge in machine learning.\nWe introduce the Gaussian Ensemble Belief Propagation (GEnBP) algorithm, which combines the strengths of the Ensemble Kalman Filter (EnKF) and Gaussian Belief Propagation (GaBP) to address this challenge.\nGEnBP updates ensembles of prior samples into posterior samples by passing low-rank local messages over the edges of a graphical model, enabling efficient handling of high-dimensional states, parameters, and complex, noisy, black-box generation processes.\nBy utilizing local message passing within a graphical model structure, GEnBP effectively manages complex dependency structures and remains computationally efficient even when the ensemble size is much smaller than the inference dimension--a common scenario in spatiotemporal modeling, image processing, and physical model inversion.\nWe demonstrate that GEnBP can be applied to various problem structures, including data assimilation, system identification, and hierarchical models, and show through experiments that it outperforms existing methods in terms of accuracy and computational efficiency.", "title_embedding_index": 14808, "title_abs_embedding_index": 14833}, {"title": "Downstream Task Guided Masking Learning in Masked Autoencoders Using Multi-Level Optimization", "link_suffix": "/forum?id=oVZ9XaOSFK", "link": "https://openreview.net/forum?id=oVZ9XaOSFK", "pdf_link": "https://openreview.net/pdf?id=oVZ9XaOSFK", "keywords": "Multi-level Optimization, Mask Autoencoder, Self-Supervised Learning, Image Masking Strategies, Representation Learning, Vision Transformers", "abstract": "Masked Autoencoder (MAE) is a notable method for self-supervised pretraining in visual representation learning. It operates by randomly masking image patches and reconstructing these masked patches using the unmasked ones. A key limitation of MAE lies in its disregard for the varying informativeness of different patches, as it uniformly selects patches to mask. To overcome this, some approaches propose masking based on patch informativeness. However, these methods often do not consider the specific requirements of downstream tasks, potentially leading to suboptimal representations for these tasks. In response, we introduce the Multi-level Optimized Mask Autoencoder (MLO-MAE), a novel framework that leverages end-to-end feedback from downstream tasks to learn an optimal masking strategy during pretraining. Our experimental findings highlight MLO-MAE's significant advancements in visual representation learning. Compared to existing methods, it demonstrates remarkable improvements across diverse datasets and tasks, showcasing its adaptability and efficiency.", "title_embedding_index": 14809, "title_abs_embedding_index": 14834}, {"title": "Breaking the Curse of Multiagency in Robust Multi-Agent Reinforcement Learning", "link_suffix": "/forum?id=ySRsm6HDy5", "link": "https://openreview.net/forum?id=ySRsm6HDy5", "pdf_link": "https://openreview.net/pdf?id=ySRsm6HDy5", "keywords": "Multi-agent reinforcement learning, Robust Markov games, Game theory, Distribution shift", "abstract": "Standard multi-agent reinforcement learning (MARL) algorithms are vulnerable to sim-to-real gaps. To address this, distributionally robust Markov games (RMGs) have been proposed to enhance robustness in MARL by optimizing the worst-case performance when game dynamics shift within a prescribed uncertainty set. Solving RMGs remains under-explored, from problem formulation to the development of sample-efficient algorithms. A notorious yet open challenge is if RMGs can escape the curse of multiagency, where the sample complexity scales exponentially with the number of agents. In this work, we propose a natural class of RMGs where the uncertainty set of each agent is shaped by both the environment and other agents' strategies in a best-response manner. We first establish the well-posedness of these RMGs by proving the existence of game-theoretic solutions such as robust Nash equilibria and coarse correlated equilibria (CCE). Assuming access to a generative model, we then introduce a sample-efficient algorithm for learning the CCE whose sample complexity scales polynomially with all relevant parameters. To the best of our knowledge, this is the first algorithm to break the curse of multiagency for RMGs.", "title_embedding_index": 14810, "title_abs_embedding_index": 14835}, {"title": "AttnGCG: Enhancing Jailbreaking Attacks on LLMs with Attention Manipulation", "link_suffix": "/forum?id=k9GfyX1eqM", "link": "https://openreview.net/forum?id=k9GfyX1eqM", "pdf_link": "https://openreview.net/pdf?id=k9GfyX1eqM", "keywords": "AttnGCG, Jailbreaking, Attention Mechanism, Optimization-based Attacks", "abstract": "This paper studies the vulnerabilities of transformer-based Large Language Models (LLMs) to jailbreaking attacks, focusing specifically on the optimization-based Greedy Coordinate Gradient (GCG) strategy. \n  We first observe a positive correlation between the effectiveness of attacks and the internal behaviors of the models. For instance, attacks tend to be less effective when models pay more attention to system prompts designed to ensure LLM safety alignment. Building on this discovery, we introduce an enhanced method that manipulates models' attention scores to facilitate LLM jailbreaking, which we term AttnGCG. \n  Empirically, AttnGCG shows consistent improvements in attack efficacy across diverse LLMs, achieving an average increase of ~7% in the Llama-2 series and ~10% in the Gemma series. Our strategy also demonstrates robust attack transferability against both unseen harmful goals and black-box LLMs like GPT-3.5 and GPT-4. \n  Moreover, we note our attention-score visualization is more interpretable, allowing us to gain better insights into how our\n  targeted attention manipulation facilitates more effective jailbreaking.\n  We release the code athttps://anonymous.4open.science/r/AttnGCG-5CD2/.", "title_embedding_index": 14811, "title_abs_embedding_index": 14836}, {"title": "Incorporating Neural ODEs into DAE-Constrained Optimization Problems", "link_suffix": "/forum?id=YAvEKf1KUd", "link": "https://openreview.net/forum?id=YAvEKf1KUd", "pdf_link": "https://openreview.net/pdf?id=YAvEKf1KUd", "keywords": "Differential Algebraic Equations, Neural Ordinary Differential Equations, Dynamic Optimization, Hybrid Modeling", "abstract": "Differential algebraic equations (DAEs) are pivotal in dynamic optimization across diverse fields, from process control to flight trajectory optimization and epidemiological modeling. Traditional methods like single shooting, multiple shooting, and direct transcription effectively optimize known mechanistic models. However, significant challenges arise when the underlying equations are unknown or deviate from empirical data. While black-box optimization strategies can address some issues, challenges persist regarding data quality, non-linearity, and the inclusion of constraints. Recent advances in machine learning, particularly Neural ODEs, offer promising tools for continuous representation of dynamic systems. This work bridges the gap between machine learning representations of dynamic systems and optimization methodologies, enabling a novel approach for solving DAEs with data-driven components. We demonstrate this approach using numerical examples of DAE problems and realistic case studies, including  biochemical reactor control and disease spread prevention. Our results highlight the efficacy of incorporating Neural ODEs into equation-based solvers, showing improved performance over existing strategies such as SINDy. Additionally, we formalize the optimization program for NN-embedded DAEs and present representations for common neural network architectures (e.g., ReLU, tanh). This work contributes a novel framework for dynamic system optimization, integrating machine learning advancements with traditional optimization techniques, and offers practical insights through comprehensive case studies.", "title_embedding_index": 14812, "title_abs_embedding_index": 14837}, {"title": "Learning Multi-Index Models with Neural Networks via Mean-Field Langevin Dynamics", "link_suffix": "/forum?id=WHhZv8X5zF", "link": "https://openreview.net/forum?id=WHhZv8X5zF", "pdf_link": "https://openreview.net/pdf?id=WHhZv8X5zF", "keywords": "mean-field Langevin dynamics, feature learning, multi-index models, neural networks, gradient descent", "abstract": "We study the problem of learning multi-index models in high-dimensions using a two-layer neural network trained with the mean-field Langevin algorithm. Under mild distributional assumptions on the data, we characterize the effective dimension $d_{\\mathrm{eff}}$ that controls both sample and computational complexity by utilizing the adaptivity of neural networks to latent low-dimensional structures. When the data exhibit such a structure, $d_{\\mathrm{eff}}$ can be significantly smaller than the ambient dimension. We prove that the sample complexity grows almost linearly with $d_{\\mathrm{eff}}$, bypassing the limitations of the information and generative exponents that appeared in recent analyses of gradient-based feature learning. On the other hand, the computational complexity may inevitably grow exponentially with $d_{\\mathrm{eff}}$ in the worst-case scenario. Motivated by improving computational complexity, we take the first steps towards polynomial time convergence of the mean-field Langevin algorithm by investigating a setting where the weights are constrained to be on a compact manifold with positive Ricci curvature, such as the hypersphere. There, we study assumptions under which polynomial time convergence is achievable, whereas similar assumptions in the Euclidean setting lead to exponential time complexity.", "title_embedding_index": 14813, "title_abs_embedding_index": 14838}, {"title": "Fair Anomaly Detection For Imbalanced Groups", "link_suffix": "/forum?id=TmKeT3IFTZ", "link": "https://openreview.net/forum?id=TmKeT3IFTZ", "pdf_link": "https://openreview.net/pdf?id=TmKeT3IFTZ", "keywords": "fairness, anomaly detection", "abstract": "Anomaly detection (AD) has been widely studied for decades in many real-world applications, including fraud detection in finance, and intrusion detection for cybersecurity, etc. Due to the imbalanced nature between protected and unprotected groups and the imbalanced distributions of normal examples and anomalies, the learning objectives of most existing anomaly detection methods tend to solely concentrate on the dominating unprotected group. Thus, it has been recognized by many researchers about the significance of ensuring model fairness in anomaly detection. However, the existing fair anomaly detection methods tend to erroneously label most normal examples from the protected group as anomalies in the imbalanced scenario where the unprotected group is more abundant than the protected group. This phenomenon is caused by the improper design of learning objectives, which statistically focus on learning the frequent patterns (i.e., the unprotected group) while overlooking the under-represented patterns (i.e., the protected group). To address these issues, we propose FADIG, a fairness-aware anomaly detection method targeting the imbalanced scenario. It consists of a fairness-aware contrastive learning module and a rebalancing autoencoder module to ensure fairness and handle the imbalanced data issue, respectively. Moreover, we provide the theoretical analysis that shows our proposed contrastive learning regularization guarantees group fairness. Empirical studies demonstrate the effectiveness and efficiency of FADIG across multiple real-world datasets.", "title_embedding_index": 14814, "title_abs_embedding_index": 14839}, {"title": "Adversarial Latent Feature Augmentation for Fairness", "link_suffix": "/forum?id=cNaHOdvh9J", "link": "https://openreview.net/forum?id=cNaHOdvh9J", "pdf_link": "https://openreview.net/pdf?id=cNaHOdvh9J", "keywords": "Fairness, Data Augmentation, Adversarial Attack", "abstract": "Achieving fairness in machine learning remains a critical challenge, especially due to the opaque effects of data augmentation on input spaces within nonlinear neural networks. Nevertheless, current approaches that emphasize augmenting latent features, rather than input spaces, offer limited insights into their ability to detect and mitigate bias. In response, we introduce the concept of the \"unfair region\" in the latent space, a subspace that highlights areas where misclassification rates for certain demographic groups are disproportionately high, leading to unfair prediction results. To address this, we propose Adversarial Latent Feature Augmentation (ALFA), a method that leverages adversarial fairness attacks to perturb latent space features, which are then used as data augmentation for fine-tuning. ALFA intentionally shifts latent features into unfair regions, and the last layer of the network is fine-tuned with these perturbed features, leading to a corrected decision boundary that enhances fairness in classification in a cost-effective manner. We present a theoretical framework demonstrating that our adversarial fairness objective reliably generates biased feature perturbations, and that fine-tuning on samples from these unfair regions ensures fairness improvements. Extensive experiments across diverse datasets, modalities, and backbone networks validate that training with these adversarial features significantly enhances fairness while maintaining predictive accuracy in classification tasks.", "title_embedding_index": 14815, "title_abs_embedding_index": 14840}, {"title": "Gymnasium: A Standard Interface for Reinforcement Learning Environments", "link_suffix": "/forum?id=feFlfuOse1", "link": "https://openreview.net/forum?id=feFlfuOse1", "pdf_link": "https://openreview.net/pdf?id=feFlfuOse1", "keywords": "reinforcement learning, api, gymnasium, artificial intelligence, autonomous agents, environment", "abstract": "Reinforcement Learning (RL) is a continuously growing field that has the potential to revolutionize many areas of artificial intelligence. However, despite its promise, RL research is often hindered by the lack of standardization in environment and algorithm implementations. This makes it difficult for researchers to compare and build upon each other's work, slowing down progress in the field.\nGymnasium is an open-source library that provides a standard API for RL environments, aiming to tackle this issue. Gymnasium's main feature is a set of abstractions that allow for wide interoperability between environments and training algorithms, making it easier for researchers to develop and test RL algorithms. In addition, Gymnasium provides a collection of easy-to-use environments, tools for easily customizing environments, and tools to ensure the reproducibility and robustness of RL research.\nThrough this unified framework, Gymnasium significantly streamlines the process of developing and testing RL algorithms, enabling researchers to focus more on innovation and less on implementation details. By providing a standardized platform for RL research, Gymnasium helps to drive forward the field of reinforcement learning and unlock its full potential.", "title_embedding_index": 14816, "title_abs_embedding_index": 14841}, {"title": "Data Efficient Continual Learning of Large Language Model", "link_suffix": "/forum?id=aqvf3R48pl", "link": "https://openreview.net/forum?id=aqvf3R48pl", "pdf_link": "https://openreview.net/pdf?id=aqvf3R48pl", "keywords": "Continual Learning; Large Language Model", "abstract": "Continual Learning (CL) in large language models (LLMs) aims to enable models to learn from evolving data distributions while preserving previously acquired knowledge.  However, existing CL methods primarily rely on statistical correlations from observed data, which are particularly vulnerable under limited data settings. This reliance results in two major drawbacks: (1) increased susceptibility to forgetting previously learned knowledge when data distribution shifts occur, and (2) a tendency to depend on spurious features instead of uncovering true causal relationships in new tasks. These issues become even more pronounced, especially when training data is limited. To address these challenges, we introduce a causality-guided CL approach that reinterprets CL through the lens of causal inference. Our method aims to mitigate the dependency of model parameters on the data inputs, leading to two key advantages: (1) reduced catastrophic forgetting, and (2) decreased dependence on spurious correlations, thereby improving generalization across both old and new tasks. Extensive experiments on pre-trained LLMs, including T5-large and Llama2, demonstrate that our approach significantly outperforms state-of-the-art (SOTA) CL methods in LLMs, particularly when the amount of training data is limited.", "title_embedding_index": 14817, "title_abs_embedding_index": 14842}, {"title": "QuantBench: Benchmarking AI Modeling for Quantitative Investment", "link_suffix": "/forum?id=y6wVRmPwDu", "link": "https://openreview.net/forum?id=y6wVRmPwDu", "pdf_link": "https://openreview.net/pdf?id=y6wVRmPwDu", "keywords": "deep learning, quantitative investment", "abstract": "The field of artificial intelligence (AI) in quantitative investment has seen significant advancements, yet it lacks a standardized benchmark aligned with industry practices. This gap hinders research progress and limits the practical application of academic innovations. We present QuantBench, an industrial-grade benchmark platform designed to address this critical need. QuantBench offers three key strengths: (1) standardization that aligns with quantitative investment industry practices, (2) flexibility to integrate various AI algorithms, and (3) full-pipeline coverage of the entire quantitative investment process. Our empirical studies using QuantBench reveal some critical research directions, including the need for continual learning to address distribution shifts, improved methods for modeling relational financial data, and more robust approaches to mitigate overfitting in low signal-to-noise environments. By providing a common ground for evaluation and fostering collaboration between researchers and practitioners, QuantBench aims to accelerate progress in AI for quantitative investment, similar to the impact of benchmark platforms in computer vision and natural language processing.", "title_embedding_index": 14818, "title_abs_embedding_index": 14843}, {"title": "Sparse Gradient Compression for Fine-Tuning Large Language Models", "link_suffix": "/forum?id=xrtM8r0zdU", "link": "https://openreview.net/forum?id=xrtM8r0zdU", "pdf_link": "https://openreview.net/pdf?id=xrtM8r0zdU", "keywords": "Machine Learning, Large Language Models, Parameter efficient fine-tuning", "abstract": "Fine-tuning large language models (LLMs) for downstream tasks has become increasingly crucial due to their widespread use and the growing availability of open-source models. However, the high memory costs associated with fine-tuning remain a significant challenge, especially as models increase in size. To address this, parameter efficient fine-tuning (PEFT) methods have been proposed to minimize the number of parameters required for fine-tuning LLMs. However, these approaches often tie the number of optimizer states to dimensions of model parameters, limiting flexibility and control during fine-tuning. In this paper, we propose sparse gradient compression (SGC), a training regime designed to address these limitations. Our approach leverages inherent sparsity in gradients to compress optimizer states by projecting them onto a low-dimensonal subspace, with dimensionality independent of the original model's parameters. By enabling optimizer state updates in an arbitrary low-dimensional subspace, SGC offers a flexible tradeoff between memory efficiency and performance. We demonstrate through experiments that SGC can decrease memory usage in optimizer states more effectively than exising PEFT methods. Furthermore, by fine-tuning LLaMA models on various downstream tasks, we show that SGC can deliver superior performance while substantially lowering optimizer state memory requirements, particularly in both data-limited and memory-limited settings.", "title_embedding_index": 14819, "title_abs_embedding_index": 14844}, {"title": "Symbolic regression via MDLformer-guided search: from minimizing prediction error to minimizing description length", "link_suffix": "/forum?id=ljAS7cPAU0", "link": "https://openreview.net/forum?id=ljAS7cPAU0", "pdf_link": "https://openreview.net/pdf?id=ljAS7cPAU0", "keywords": "symbolic regression, minimum description length, trans former, neural network guided search", "abstract": "Symbolic regression, a task discovering the formula best fitting the given data, is typically based on the heuristical search. These methods usually update candidate formulas to obtain new ones with lower prediction errors iteratively. However, since formulas with similar function shapes may have completely different symbolic forms, the prediction error does not decrease monotonously as the search approaches the target formula, causing the low recovery rate of existing methods. To solve this problem, we propose a novel search objective based on the minimum description length, which reflects the distance from the target and decreases monotonically as the search approaches the correct form of the target formula. To estimate the minimum description length of any input data, we design a neural network, MDLformer, which enables robust and scalable estimation through large-scale training. With the MDLformer's output as the search objective, we implement a symbolic regression method, SR4MDL, that can effectively recover the correct mathematical form of the formula. Extensive experiments illustrate its excellent performance in recovering formulas from data. Our method successfully recovers around 50 formulas across two benchmark datasets comprising 133 problems, outperforming state-of-the-art methods by 43.92%. We release our code at \\url{https://anonymous.4open.science/r/SR4MDL-5CF3}.", "title_embedding_index": 14820, "title_abs_embedding_index": 14845}, {"title": "Robust Gymnasium: A Unified Modular Benchmark for Robust Reinforcement Learning", "link_suffix": "/forum?id=2uQBSa2X4R", "link": "https://openreview.net/forum?id=2uQBSa2X4R", "pdf_link": "https://openreview.net/pdf?id=2uQBSa2X4R", "keywords": "Robust reinforcement learning, benchmark, reinforcement learning, multi-agent reinforcement learning", "abstract": "Driven by inherent uncertainty and the sim-to-real gap, robust reinforcement learning (RL) seeks to improve resilience against the complexity and variability in agent-environment sequential interactions. Despite the existence of a large number of RL benchmarks, there is a lack of standardized benchmarks for robust RL. Current robust RL policies often focus on a specific type of uncertainty and are evaluated in distinct, one-off environments. In this work, we introduce \\name, a unified modular benchmark designed for robust RL that supports a wide variety of disruptions across all key RL components\u2014agents' observed state and reward, agents' actions, and the environment. Offering over sixty diverse task environments spanning control and robotics, safe RL, and multi-agent RL, it provides an open-source and user-friendly tool for the community to assess current methods and foster the development of robust RL algorithms. \nIn addition, we benchmark existing standard and robust RL algorithms within this framework, uncovering significant deficiencies in each and offering new insights. The code is available at the website.", "title_embedding_index": 14821, "title_abs_embedding_index": 14846}, {"title": "Multimodal Unsupervised Domain Generalization by Retrieving Across the Modality Gap", "link_suffix": "/forum?id=bqoHdVMIbt", "link": "https://openreview.net/forum?id=bqoHdVMIbt", "pdf_link": "https://openreview.net/pdf?id=bqoHdVMIbt", "keywords": "Retrieval, Domain Generalization, Multimodal learning", "abstract": "Domain generalization (DG) is an important problem that learns a model which generalizes to unseen test domains leveraging one or more source domains, under the assumption of shared label spaces. However, most DG methods assume access to abundant source data in the target label space, a requirement that proves overly stringent for numerous real-world applications, where acquiring the same label space as the target task is prohibitively expensive. For this setting, we tackle the multimodal version of the unsupervised domain generalization (MUDG) problem, which uses a large task-agnostic unlabeled source dataset during finetuning. Our framework does not explicitly assume any relationship between the source dataset and target task. Instead, it relies only on the premise that the source dataset can be accurately and efficiently searched in a joint vision-language space. We make three contributions in the MUDG setting. Firstly, we show theoretically that cross-modal approximate nearest neighbor search suffers from low recall due to the large distance between text queries and the image centroids used for coarse quantization. Accordingly, we propose paired k-means, a simple clustering algorithm that improves nearest neighbor recall by storing centroids in query space instead of image space. Secondly, we propose an adaptive text augmentation scheme for target labels designed to improve zero-shot accuracy and diversify retrieved image data. Lastly, we present two simple but effective components to further improve downstream target accuracy. We compare against state-of-the-art name-only transfer, source-free DG and zero-shot (ZS) methods on their respective benchmarks and show consistent improvement in accuracy on 20 diverse datasets. Code is available:https://anonymous.4open.science/r/mudg-160C", "title_embedding_index": 14822, "title_abs_embedding_index": 14847}, {"title": "Enhancing Interpretability in Deep Reinforcement Learning through Semantic Clustering", "link_suffix": "/forum?id=VqAX9Lzdqv", "link": "https://openreview.net/forum?id=VqAX9Lzdqv", "pdf_link": "https://openreview.net/pdf?id=VqAX9Lzdqv", "keywords": "Interpretability, Reinforcement Learning, Clustering, Semantics, VAE", "abstract": "In this paper, we explore semantic clustering properties of deep reinforcement learning (DRL) to improve its interpretability and deepen our understanding of the internal semantic organization. In this context, semantic clustering refers to the ability of neural networks to cluster inputs based on their semantic similarity in the internal space. We propose a DRL architecture that incorporates a novel semantic clustering module, which includes both feature dimensionality reduction and online clustering. This module integrates seamlessly into the DRL training pipeline, addressing the instability of t-SNE and eliminating the need for extensive manual annotation in the previous semantic analysis methods. Through experiments, we validate the effectiveness of the proposed module and demonstrate its ability to reveal semantic clustering properties within DRL. Furthermore, we introduce new analytical methods that leverage these properties to provide insights into the hierarchical structure of policies and the semantic organization within the feature space. These methods also help identify potential risks within the model, offering a deeper understanding of its limitations and guiding future improvements.", "title_embedding_index": 14823, "title_abs_embedding_index": 14848}, {"title": "Observability of Latent States in Generative AI Models", "link_suffix": "/forum?id=RaroYIrnbR", "link": "https://openreview.net/forum?id=RaroYIrnbR", "pdf_link": "https://openreview.net/pdf?id=RaroYIrnbR", "keywords": "LLM Observability, indistinguishability, meaning representation, feeling representation", "abstract": "We tackle the question of whether Large Language Models (LLMs), viewed as dynamical systems with state evolving in the embedding space of symbolic tokens, are observable. That is, whether there exist multiple 'mental' state trajectories that yield the same sequence of generated tokens, or sequences that belong to the same Nerode equivalence class ('meaning'). If not observable, mental state trajectories evoked by an input ('percepts') or by  feedback from the model's own state could remain self-contained and evolve unbeknownst to the user while being potentially accessible to the model provider. Curiously, \"self-contained experiences evoked by perception or thought\" are essentially what the American Psychological Association (APA) defines as 'feelings'. Lexical curiosity aside, we show that current LLMs implemented by autoregressive Transformers are observable: The set of state trajectories indistinguishable from the tokenized output is a singleton. But if there are 'system prompts' not visible to the user, then the set of indistinguishable trajectories becomes non-trivial, and there can be multiple state trajectories that yield the same verbalized output. We prove these claims analytically, and show examples of modifications to standard LLMs that engender unobservable behaviors. Our analysis sheds light on possible designs that would enable a model to  perform non-trivial computation that is not visible to the user, as well as on controls that the provider of services using the model could take to prevent unintended behavior.", "title_embedding_index": 14824, "title_abs_embedding_index": 14849}]
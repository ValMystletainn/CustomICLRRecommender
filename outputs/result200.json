[{"title": "Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning", "link_suffix": "/forum?id=44CoQe6VCq", "link": "https://openreview.net/forum?id=44CoQe6VCq", "pdf_link": "https://openreview.net/pdf?id=44CoQe6VCq", "keywords": "Temporal Reasoning, Temporal Graphs, LLMs", "abstract": "Large language models (LLMs) have showcased remarkable reasoning capabilities, yet they remain susceptible to errors, particularly in temporal reasoning tasks involving complex temporal logic. Existing research has explored LLM performance on temporal reasoning using diverse datasets and benchmarks. However, these studies often rely on real-world data that LLMs may have encountered during pre-training or employ anonymization techniques that can inadvertently introduce factual inconsistencies. In this work, we address these limitations by introducing novel synthetic datasets specifically designed to assess LLM temporal reasoning abilities in various scenarios. The diversity of question types across these datasets enables systematic investigation into the impact of the problem structure, size, question type, fact order, and other factors on LLM performance. Our findings provide valuable insights into the strengths and weaknesses of current LLMs in temporal reasoning tasks. To foster further research in this area, we will open-source the datasets and evaluation framework used in our experiments.", "title_embedding_index": 9950, "title_abs_embedding_index": 9975}, {"title": "Similarity Group Equivariant Convolutional Networks", "link_suffix": "/forum?id=ms9bK61Hxn", "link": "https://openreview.net/forum?id=ms9bK61Hxn", "pdf_link": "https://openreview.net/pdf?id=ms9bK61Hxn", "keywords": "Group Convolution, Group Equivariance, Similarity Transformation, Continuous Transformation, Translation, Rotation, Scaling, Reflection", "abstract": "We introduce the first similarity group equivariant convolutional networks (SECNNs), designed to achieve continuous translation, rotation and scale equivariance, or discrete similarity group equivariance that involves discrete Dihedral group. The networks are implemented by employing a steerable and approximately shiftable and scalable basis for transforming convolution kernels within a five-dimensional position-orientation-scale-reflection space. \nOur results demonstrate that SECNNs attain state-of-the-art results on translated, rotated and scaled MNIST datasets. SECNNs also achieve the accuracy of other leading group equivariant networks on CIFAR10/100,\nwhile being equivariant to the full range of the similarity group in comparison to existing state of the art, which is equivariant to only sub-groups of the similarity group.", "title_embedding_index": 9951, "title_abs_embedding_index": 9976}, {"title": "Rethinking the Uncertainty: A Critical Review and Analysis in the Era of Large Language Models", "link_suffix": "/forum?id=ryKrRCbcCX", "link": "https://openreview.net/forum?id=ryKrRCbcCX", "pdf_link": "https://openreview.net/pdf?id=ryKrRCbcCX", "keywords": "Uncertainty Estimation, Confidence Estimation", "abstract": "In recent years, Large Language Models (LLMs) have become fundamental to a broad spectrum of artificial intelligence applications. As the use of LLMs expands, precisely estimating the uncertainty in their predictions has become crucial. Current methods often struggle to accurately identify, measure, and address the true uncertainty, with many focusing primarily on estimating model confidence. This discrepancy is largely due to an incomplete understanding of where, when, and how uncertainties are injected into models. This paper introduces a comprehensive framework specifically designed to identify and understand the types and sources of uncertainty, aligned with the unique characteristics of LLMs. Our framework enhances the understanding of the diverse landscape of uncertainties by systematically categorizing and defining each type, establishing a solid foundation for developing targeted methods that can precisely quantify these uncertainties. We also provide a detailed introduction to key related concepts and examine the limitations of current methods in mission-critical and safety-sensitive applications. The paper concludes with a perspective on future directions aimed at enhancing the reliability and practical adoption of these methods in real-world scenarios.", "title_embedding_index": 9952, "title_abs_embedding_index": 9977}, {"title": "Boosting Recovery in Transformer-Based Symbolic Regression", "link_suffix": "/forum?id=NhqKHHK4Nk", "link": "https://openreview.net/forum?id=NhqKHHK4Nk", "pdf_link": "https://openreview.net/pdf?id=NhqKHHK4Nk", "keywords": "symbolic regression, interpretability, transformer, recovery", "abstract": "The traditional objective in regression is generalization. That is, learning a function from training data that performs well beyond the training data. Symbolic regression adds another objective, namely, interpretability of the regressor.In the context of regression, interpretability means that the representation of the regressor facilitates insights into mechanisms that underlie the functional dependence. State-of-the-art symbolic regressors provide such insights. However, the state of the art predominantly incurs high costs at inference time. The recently proposed transformer-based end-to-end approach is orders of magnitude faster at inference time. \nIt does, however, not achieve state-of-the-art performance in terms of interpretability, which is typically measured by the ability to recover ground truth formulas from samples. Here, we show that the recovery performance of the end-to-end approach can be boosted by carefully selecting the training data. We construct a synthetic dataset from first principles and demonstrate that the capacity to recover ground truth formulas is proportional to the available computational resources.", "title_embedding_index": 9953, "title_abs_embedding_index": 9978}, {"title": "Efficient stagewise pretraining via progressive subnetworks", "link_suffix": "/forum?id=Y5LjYI4N6P", "link": "https://openreview.net/forum?id=Y5LjYI4N6P", "pdf_link": "https://openreview.net/pdf?id=Y5LjYI4N6P", "keywords": "Efficient stagewise training, modular training, language model pretraining, implicit bias, simple-to-complex learning", "abstract": "Recent developments in large language models have sparked interest in efficient\npretraining methods. Stagewise training approaches to improve efficiency, like\ngradual stacking and layer dropping (Reddi et al., 2023; Zhang & He, 2020), have\nrecently garnered attention. The prevailing view suggests that stagewise dropping\nstrategies, such as layer dropping, are ineffective, especially when compared to\nstacking-based approaches. This paper challenges this notion by demonstrating\nthat, with proper design, dropping strategies can be competitive, if not better, than\nstacking methods. Specifically, we develop a principled stagewise training framework, progressive subnetwork training, which only trains subnetworks within the\nmodel and progressively increases the size of subnetworks during training, until it\ntrains the full network. We propose an instantiation of this framework \u2014 Random\nPart Training (RAPTR) \u2014 that selects and trains only a random subnetwork (e.g.\ndepth-wise, width-wise) of the network at each step, progressively increasing the\nsize in stages. We show that this approach not only generalizes prior works like\nlayer dropping but also fixes their key issues. Furthermore, we establish a theoretical basis for such approaches and provide justification for (a) increasing complexity of subnetworks in stages, conceptually diverging from prior works on layer\ndropping, and (b) stability in loss across stage transitions in presence of key modern architecture components like residual connections and layer norms. Through\ncomprehensive experiments, we demonstrate that RAPTR can significantly speed\nup training of standard benchmarks like BERT and UL2, up to 33% compared to\nstandard training and, surprisingly, also shows better downstream performance on\nUL2, improving QA tasks and SuperGLUE by 1.5%; thereby, providing evidence\nof better inductive bias.", "title_embedding_index": 9954, "title_abs_embedding_index": 9979}, {"title": "AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials", "link_suffix": "/forum?id=EEgYUccwsV", "link": "https://openreview.net/forum?id=EEgYUccwsV", "pdf_link": "https://openreview.net/pdf?id=EEgYUccwsV", "keywords": "Data Synthesis, GUI Agent, Large Language Model", "abstract": "Graphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose \\ourwork, a scalable data synthesis pipeline that generates high-quality GUI agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model (VLM) agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly improves their grounding and planning performance over the current models. Moreover, our approach is more cost-efficient compared to traditional human annotation methods. This work underscores the potential of guided replay with web tutorials as a viable strategy for large-scale GUI agent training, paving the way for more capable and autonomous digital agents.", "title_embedding_index": 9955, "title_abs_embedding_index": 9980}, {"title": "LLM2Features: Large Language Models in Interpretable Feature Generation for AutoML with Tabular Data", "link_suffix": "/forum?id=qbSoiHLEK0", "link": "https://openreview.net/forum?id=qbSoiHLEK0", "pdf_link": "https://openreview.net/pdf?id=qbSoiHLEK0", "keywords": "LLM, Auto feature generation, GPT-4o, GPT-o1, Tabular Data", "abstract": "Automatic Machine Learning (AutoML) is the popular supervised learning approach for tabular data. One of its key components is generating the most suitable features given the available training dataset. To overcome the disadvantages of existing automatic feature generation techniques, such as lack of generality and interpretability, we propose the novel approach, \\textbf{LLM2Features}. It uses LLMs (Large Language Models) to generate meaningful features using automatically collected statistics about the dataset without explicitly describing the data, making it ideal for implementing in AutoML frameworks. In particular, we introduce the LLM-based critic that additionally verifies the presence of syntax or logical errors. The experimental study demonstrates the benefits of the proposed LLM2Features approach in accuracy and training time compared to the state-of-the-art feature generation tools.", "title_embedding_index": 9956, "title_abs_embedding_index": 9981}, {"title": "Optimized Oversampling", "link_suffix": "/forum?id=ZSzmWtY31e", "link": "https://openreview.net/forum?id=ZSzmWtY31e", "pdf_link": "https://openreview.net/pdf?id=ZSzmWtY31e", "keywords": "Machine Learning, Imbalanced Datasets, Optimization", "abstract": "Many classification problems that arise in practice feature imbalanced datasets, a regime in which a lot of machine learning (ML) models show diminished performance. To address class imbalance, techniques like undersampling and oversampling are used to improve the model's performance. In this paper, we introduce a new oversampling framework, Optimized Oversampling ($O^{2}$), which generates synthetic minority class points by maximizing the probability of belonging to the minority class, which is estimated by a trained classification model. We show theoretically, under mild assumptions, that the points generated by $O^{2}$ are more likely to belong to the minority class than those generated by other approaches. Further, we benchmark $O^{2}$ against state-of-the-art oversampling methods on 16 publicly available imbalanced datasets using Classification Trees (CART) and Logistic Regression (LR) for the downstream classification task. The numerical experiments show that $O^{2}$ has an edge over current state-of-the-art oversampling methods, which is more pronounced on CART.", "title_embedding_index": 9957, "title_abs_embedding_index": 9982}, {"title": "Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback", "link_suffix": "/forum?id=st7XqFgbAH", "link": "https://openreview.net/forum?id=st7XqFgbAH", "pdf_link": "https://openreview.net/pdf?id=st7XqFgbAH", "keywords": "learning from AI feedback, imitation learning, privileged information", "abstract": "While large language models (LLMs) show impressive decision-making abilities, current methods lack a mechanism for automatic self-improvement from errors during task execution. We propose LEAP, an iterative fine-tuning framework that continually improves LLM agents using feedback from AI expert teachers. Our key insight is to equip the expert teachers with a privileged state -- information available during training but hidden at test time. This allows even weak experts to provide precise guidance, significantly improving the student agent's performance without access to privileged information at test time. We evaluate LEAP on diverse decision-making benchmarks, including text-based games, web navigation, and interactive coding. Our experiments show that LEAP (1) outperforms state-of-the-art baselines (2) enables weak student models (e.g., Llama3-8B) to exceed the performance of strong teacher models (GPT4-o), and (3) allows weak models to self-improve using privileged versions of themselves. We also provide a theoretical analysis showing that LEAP's success hinges on balancing privileged information with the student\u2019s realizability, which we empirically validate. Our code is provided as part of the supplementary material.", "title_embedding_index": 9958, "title_abs_embedding_index": 9983}, {"title": "Structure-preserving contrastive learning for spatial time series", "link_suffix": "/forum?id=sz7HdeVVHo", "link": "https://openreview.net/forum?id=sz7HdeVVHo", "pdf_link": "https://openreview.net/pdf?id=sz7HdeVVHo", "keywords": "time series, contrastive learning, spatio-temporal data, traffic interaction", "abstract": "Informative representations enhance model performance and generalisability in downstream tasks. However, learning self-supervised representations for spatially characterised time series, like traffic interactions, poses challenges as it requires maintaining fine-grained similarity relations in the latent space. In this study, we extend time series contrastive learning by incorporating two structure-preserving regularisers: one preserves the topology of similarities between instances, and the other preserves the graph geometry of similarities across spatial and temporal dimensions. We conduct experiments on multivariate time series classification, as well as macroscopic and microscopic traffic prediction. For all three tasks, our method preserves the structures of similarity relations more effectively and improves state-of-the-art task performances. This extension can be applied to an arbitrary encoder and is particularly beneficial for time series with spatial or geographical features. Our code is attached as supplementary material, which will be made openly available with all resulting data after review.", "title_embedding_index": 9959, "title_abs_embedding_index": 9984}, {"title": "Aligning to Constraints for Data-Efficient Language Model Customization", "link_suffix": "/forum?id=DedkG85z3c", "link": "https://openreview.net/forum?id=DedkG85z3c", "pdf_link": "https://openreview.net/pdf?id=DedkG85z3c", "keywords": "LLM Customization, Data-efficiency, Constraint-driven Learning", "abstract": "General-purpose language models (LMs) are aligned to diverse user intents, but fall short when it comes to specific applications. While finetuning is the default method for customized alignment, human annotations are often unavailable in various customization scenarios. Based on the observation that one of the main issues of LM customization is constraint adherence, we investigate the feasibility of using constraints as a bridge from general LMs to customized ones. We investigate common constraints in NLP tasks, categorize them into three classes based on the types of their arguments, and propose a unified framework, ACT (Aligning to ConsTraints), to automatically produce supervision signals for user alignment with constraints. Specifically, ACT uses constraint verifiers, which are typically easy to implement in practice, to compute constraint satisfaction rate (CSR) of each response. It samples multiple responses for each prompt and collect preference labels based on their CSR automatically. Subsequently, ACT adapts the LM to the target task through a ranking-based learning process. Experiments on fine-grained entity typing, abstractive summarization, and temporal question answering show that ACT is able to enhance LMs' capability to adhere to different classes of constraints, thereby improving task performance comparable to or approaching that of finetuning with labeled data.", "title_embedding_index": 9960, "title_abs_embedding_index": 9985}, {"title": "Progressive distillation induces an implicit curriculum", "link_suffix": "/forum?id=wPMRwmytZe", "link": "https://openreview.net/forum?id=wPMRwmytZe", "pdf_link": "https://openreview.net/pdf?id=wPMRwmytZe", "keywords": "knowledge distillation, feature learning, curriculum, sparse parity, PCFG, optimization, MLP, Transformer", "abstract": "Knowledge distillation leverages a teacher model to improve the training of a student model. A persistent challenge is that a better teacher does not always yield a better student, to which a common mitigation is to use additional supervision from several \u201cintermediate\u201d teachers. One empirically validated variant of this principle is progressive distillation, where the student learns from successive intermediate checkpoints of the teacher. Using sparse parity as a sandbox, we identify an implicit curriculum as one mechanism through which progressive distillation accelerates the student\u2019s learning. This curriculum is available only through the intermediate checkpoints but not the final converged one, and imparts both empirical acceleration and a provable sample complexity benefit to the student. We then extend our investigation to Transformers trained on probabilistic context-free grammars (PCFGs) and real-world pre-training datasets (Wikipedia and Books). Through probing the teacher model, we identify an analogous implicit curriculum where the model progressively learns features that capture longer context. Our theoretical and empirical findings on sparse parity, complemented by empirical observations on more complex tasks, highlight the benefit of progressive distillation via implicit curriculum across setups.", "title_embedding_index": 9961, "title_abs_embedding_index": 9986}, {"title": "3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation", "link_suffix": "/forum?id=C0HDYvGwol", "link": "https://openreview.net/forum?id=C0HDYvGwol", "pdf_link": "https://openreview.net/pdf?id=C0HDYvGwol", "keywords": "3D generation, multi-view, diffusion models, texture generation, radiance fields, gaussian splatting", "abstract": "Multi-view image diffusion models have significantly advanced open-domain 3D object generation. However, most existing models rely on 2D network architectures that lack inherent 3D biases, resulting in compromised geometric consistency. To address this challenge, we introduce 3D-Adapter, a plug-in module designed to infuse 3D geometry awareness into pretrained image diffusion models. Central to our approach is the idea of 3D feedback augmentation: for each denoising step in the sampling loop, 3D-Adapter decodes intermediate multi-view features into a coherent 3D representation, then re-encodes the rendered RGBD views to augment the pretrained base model through feature addition. We study two variants of 3D-Adapter: a fast feed-forward version based on Gaussian splatting and a versatile training-free version utilizing neural fields and meshes. Our extensive experiments demonstrate that 3D-Adapter not only greatly enhances the geometry quality of text-to-multi-view models such as Instant3D and Zero123++, but also enables high-quality 3D generation using the plain text-to-image Stable Diffusion. Furthermore, we showcase the broad application potential of 3D-Adapter by presenting high quality results in text-to-3D, image-to-3D, text-to-texture, and text-to-avatar tasks. Code will be made publicly available.", "title_embedding_index": 9962, "title_abs_embedding_index": 9987}, {"title": "Neural Mutual Information Estimation with Reference Distributions", "link_suffix": "/forum?id=fYOl9leH72", "link": "https://openreview.net/forum?id=fYOl9leH72", "pdf_link": "https://openreview.net/pdf?id=fYOl9leH72", "keywords": "mutual information, density ratio estimate, flow-based model, neural density estimate, copula", "abstract": "Estimating mutual information (MI) from data is a fundamental task in machine learning and data science, yet it remains highly challenging even with state-of-the-art estimators. This work proposes a new distribution-free MI estimator based on reference distributions. Unlike existing works that only discern between the joint distribution and the marginal distribution, which can easily overfit in high-MI settings, our method compares them with extra reference distributions. These artificial distributions share the same marginals as the original distributions but have known dependence structures,  providing additional signals for more accurate dependency modeling. Experiments on synthetic tasks with non-Gaussian, high-dimensional data and real-world applications including Bayesian experimental design and self-supervised learning demonstrate the potential of our approach.", "title_embedding_index": 9963, "title_abs_embedding_index": 9988}, {"title": "MGD3: Mode-Guided Dataset Distillation using Diffusion Models", "link_suffix": "/forum?id=vKJ8YH0iNp", "link": "https://openreview.net/forum?id=vKJ8YH0iNp", "pdf_link": "https://openreview.net/pdf?id=vKJ8YH0iNp", "keywords": "Dataset Distillation; Dataset Condensation; Diffusion;", "abstract": "Dataset distillation aims to synthesize a smaller training set from a large dataset such that a model trained on this distilled set performs comparably to one trained on the entire dataset. For image classification, earlier methods proposed optimization strategies in the input space to synthesize a distilled dataset, but they are computationally expensive and difficult to scale to higher resolutions. Also, the datasets synthesized by these methods lack intra-class diversity as they ignore the modes of the data distribution. Recent works propose using generative models, among which diffusion models have shown promising results as they are known to capture the data distribution effectively.  However, diffusion models tend to over-sample from the prominent modes of the data distribution, resulting in limited diversity in the generated samples. To address these limitations in this work, we propose a mode-guided diffusion model. Unlike existing works that fine-tune the diffusion models for dataset distillation, we propose to use a pre-trained model without the need for fine-tuning. Our novel approach consists of three stages: Mode Discovery, Mode Guidance, and Stop Guidance. In the first stage, we discover distinct modes in the data distribution of a class to build a representative set. In the second stage, we use a pre-trained diffusion model and guide the diffusion process toward the discovered modes to generate distinct samples, ensuring intra-class diversity. However, mode-guided sampling can introduce artifacts in the synthetic sample, which affect the performance. To control the fidelity of the synthetic dataset, we introduce the stop guidance. We evaluate our method on multiple benchmark datasets, including ImageNette, ImageIDC, ImageNet-100, and ImageNet-1K; Our method improved $4.4$%, $2.9$%, $1.6$%, and $1.6$% over the current state-of-the-art on the respective datasets. In addition, our method does not require retraining of the diffusion model, which leads to reduced computational requirements. \nWe also demonstrate that our approach is effective with general-purpose diffusion models such as Text-to-Image Stable Diffusion, eliminating the need for a pre-trained model in the target dataset.", "title_embedding_index": 9964, "title_abs_embedding_index": 9989}, {"title": "Uncertainty-Aware Counterfactual Explanations using Bayesian Neural Nets", "link_suffix": "/forum?id=XAO5pulJru", "link": "https://openreview.net/forum?id=XAO5pulJru", "pdf_link": "https://openreview.net/pdf?id=XAO5pulJru", "keywords": "Counterfactual Explanations, Bayesian Neural Networks, BNN", "abstract": "A counterfactual explanation describes the smallest input change required to alter\nthe prediction of an AI model towards a desired outcome. When using neural net-\nworks, counterfactuals are obtained using variants of projected gradient descent.\nSuch counterfactuals have been shown to be brittle and implausible, potentially\njeopardising the explanatory aspects of counterfactuals. Numerous approaches\nfor obtaining better counterfactuals have been put forward. Even though these\nsolutions address some of the shortcomings, they often fall short of providing\nan all-around solution for robust and plausible counterfactuals. We hypothesise\nthis is due to the deterministic nature and limitations of neural networks, which\nfail to capture the uncertainty of the training data. Bayesian Neural Networks\n(BNNs) are a well-known class of probabilistic models that could be used to over-\ncome these issues; unfortunately, there is currently no framework for developing\ncounterfactuals for them. In this paper, we fill this gap by proposing a formal\nframework to define counterfactuals for BNNs and develop algorithmic solutions\nfor computing them. We evaluate our framework on a set of commonly used\nbenchmarks and observe that BNNs produce counterfactuals that are more robust,\nplausible, and less costly than deterministic baselines", "title_embedding_index": 9965, "title_abs_embedding_index": 9990}, {"title": "MuirBench: A Comprehensive Benchmark for Robust Multi-image Understanding", "link_suffix": "/forum?id=TrVYEZtSQH", "link": "https://openreview.net/forum?id=TrVYEZtSQH", "pdf_link": "https://openreview.net/pdf?id=TrVYEZtSQH", "keywords": "Multimodal LLM, Multi-image Understanding, Benchmark, Robustness", "abstract": "We introduce MuirBench, a comprehensive benchmark that focuses on robust multi-image understanding capabilities of multimodal LLMs. MuirBench consists of 12 diverse multi-image tasks (e.g., scene understanding, ordering) that involve 10 categories of multi-image relations (e.g., multiview, temporal relations). Comprising 11,264 images and 2,600 multiple-choice questions, MuirBench is created in a pairwise manner, where each standard instance is paired with an unanswerable variant that has minimal semantic differences, in order for a reliable assessment. Evaluated upon 20 recent multi-modal LLMs, our results reveal that even the best-performing models like GPT-4o and Gemini Pro find it challenging to solve MuirBench, achieving 68.0% and 49.3% in accuracy. Open-source multimodal LLMs trained on single images can hardly generalize to multi-image questions, hovering below 33.3% in accuracy. These results highlight the importance of MuirBench in encouraging the community to develop multimodal LLMs that can look beyond a single image, suggesting potential pathways for future improvements.", "title_embedding_index": 9966, "title_abs_embedding_index": 9991}, {"title": "Online Clustering with Nearly Optimal Consistency", "link_suffix": "/forum?id=NA2vUMaMOm", "link": "https://openreview.net/forum?id=NA2vUMaMOm", "pdf_link": "https://openreview.net/pdf?id=NA2vUMaMOm", "keywords": "clustering, online, consistency", "abstract": "We give online algorithms for $k$-Means(more generally, $(k, z)$-Clustering) with nearly optimal consistency (a notion suggested by Lattanzi & Vassilvitskii (2017)). \nOur result turns any $\\alpha$-approximate offline algorithm for clustering into an $(1+\\epsilon)\\alpha^2$-competitive online algorithm for clustering with $O(k \\text{poly} \\log n)$ consistency. \nThis consistency bound is optimal up to $\\text{poly} \\log(n)$ factors. \nPlugging in the offline algorithm that returns the exact optimal solution, \nwe obtain the first\n$(1 + \\epsilon)$-competitive online algorithm for clustering that achieves a linear in $k$ consistency.\nThis simultaneously improves several previous results (Lattanzi & Vassilvitskii, 2017; Fichtenberger et al., 2021). \nWe validate the performance of our algorithm on real datasets by plugging in the practically efficient $k$-Means++ algorithm. \nOur online algorithm makes $k$-Means++ achieve good consistency with little overhead to the quality of solutions.", "title_embedding_index": 9967, "title_abs_embedding_index": 9992}, {"title": "Graph Transformers Dream of Electric Flow", "link_suffix": "/forum?id=rWQDzq3O5c", "link": "https://openreview.net/forum?id=rWQDzq3O5c", "pdf_link": "https://openreview.net/pdf?id=rWQDzq3O5c", "keywords": "Transformer, Graph Neural Network", "abstract": "We show theoretically and empirically that the linear Transformer, when applied to graph data, can implement algorithms that solve canonical problems such as electric flow and eigenvector decomposition. The input to the Transformer is simply the graph incidence matrix; no other explicit positional encoding information is provided. We present explicit weight configurations for implementing each algorithm, and we bound the constructed Transformers' errors by the errors of the underlying algorithms. We verify our theoretical findings experimentally on synthetic data. Additionally, on a real-world molecular regression task, we observe that the linear Transformer is capable of learning a better positional encoding than the default one based on Laplacian eigenvectors. Our work is an initial step towards elucidating the inner-workings of the Transformer for graph data.", "title_embedding_index": 9968, "title_abs_embedding_index": 9993}, {"title": "Doubly Optimal Policy Evaluation for Reinforcement Learning", "link_suffix": "/forum?id=60GeEoG5kD", "link": "https://openreview.net/forum?id=60GeEoG5kD", "pdf_link": "https://openreview.net/pdf?id=60GeEoG5kD", "keywords": "Reinforcement Learning", "abstract": "Policy evaluation estimates the performance of a policy by (1) collecting data from the environment and (2) processing raw data into a meaningful estimate. Due to the sequential nature of reinforcement learning, any improper data-collecting policy or data-processing method substantially deteriorates the variance of evaluation results over long time steps. Thus, policy evaluation often suffers from large variance and requires massive data to achieve the desired accuracy. In this work, we design an optimal combination of data-collecting policy and data-processing baseline. Theoretically, we prove our doubly optimal policy evaluation method is unbiased and guaranteed to have lower variance than previously best-performing methods. Empirically, compared with previous works, we show our method reduces variance substantially and achieves superior empirical performance.", "title_embedding_index": 9969, "title_abs_embedding_index": 9994}, {"title": "Vulnerabilities Mitigation for Safety-Aligned Language Models via Debiasing", "link_suffix": "/forum?id=G7gvaoX9AW", "link": "https://openreview.net/forum?id=G7gvaoX9AW", "pdf_link": "https://openreview.net/pdf?id=G7gvaoX9AW", "keywords": "AI Alignment, Large Language Models, AI Safety, Safe RL", "abstract": "Safety alignment is a fundamental yet still developing research topic for the real-world applications of AI.\nDespite the multifaceted nature of safety and trustworthiness in AI, current safety alignment methods often focus on a singular notion of safety. By carefully assessing models from the existing safety-alignment methods, we found that, while they generally improved overall safety performance, they failed to ensure safety in specific categories. Our study first identified the difficulty of eliminating such vulnerabilities without sacrificing the model's helpfulness. We found that, while smaller KL penalty parameters, increased training iterations, and dataset cleansing can enhance safety, they do not necessarily improve the trade-off between safety and helpfulness. We discovered that safety alignment can induce undesired effects and result in a model that prefers generating negative tokens leading to rejective responses, regardless of the input context. To address this, we introduced a learning-free method, Token-level Safety-Debiased Inference (TSDI), to estimate and correct this bias during the generation process using randomly constructed prompts. Our experiments demonstrated that our method could enhance the model's helpfulness while maintaining safety, thus improving the trade-off Pareto-front.", "title_embedding_index": 9970, "title_abs_embedding_index": 9995}, {"title": "Reduced-Order Neural Operators: Learning Lagrangian Dynamics on Highly Sparse Graphs", "link_suffix": "/forum?id=Bzro1bgkTQ", "link": "https://openreview.net/forum?id=Bzro1bgkTQ", "pdf_link": "https://openreview.net/pdf?id=Bzro1bgkTQ", "keywords": "Reduced order modeling, Neural Operator, lagrangian dynamics, neural field, discretization invariance", "abstract": "We propose accelerating the simulation of Lagrangian dynamics, such as fluid flows, granular flows, and elastoplasticity, with neural-operator-based reduced-order modeling. While full-order approaches simulate the physics of every particle within the system, incurring high computation time for dense inputs, we propose to simulate the physics on sparse graphs constructed by sampling from the spatially discretized system. Our discretization-invariant reduced-order framework trains on any spatial discretizations and computes temporal dynamics on any sparse sampling of these discretizations through neural operators. Our proposed approach is termed Graph Informed Optimized Reduced-Order Modeling or \\textit{GIOROM}.  Through reduced order modeling, we ensure lower computation time by sparsifying the system by 6.6-32.0$\\times$, while ensuring high-fidelity full-order inference via neural fields. We show that our model generalizes to a range of initial conditions, resolutions, and materials.", "title_embedding_index": 9971, "title_abs_embedding_index": 9996}, {"title": "SoundCTM: Unifying Score-based and Consistency Models for Full-band Text-to-Sound Generation", "link_suffix": "/forum?id=KrK6zXbjfO", "link": "https://openreview.net/forum?id=KrK6zXbjfO", "pdf_link": "https://openreview.net/pdf?id=KrK6zXbjfO", "keywords": "text-to-sound generation, distillation models, text-to-audio diffusion models, generative models for sound", "abstract": "Sound content creation, essential for multimedia works such as video games and films, often involves extensive trial-and-error, enabling creators to semantically reflect their artistic ideas and inspirations, which evolve throughout the creation process, into the sound.\nRecent high-quality diffusion-based Text-to-Sound (T2S) generative models provide valuable tools for creators. However, these models often suffer from slow inference speeds, imposing an undesirable burden that hinders the trial-and-error process.\nWhile existing T2S distillation models address this limitation through $1$-step generation, the sample quality of $1$-step generation remains insufficient for production use.\nAdditionally, while multi-step sampling in those distillation models improves sample quality itself, the semantic content changes due to their lack of deterministic sampling capabilities.\nThus, developing a T2S generative model that allows creators to efficiently conduct trial-and-error while producing high-quality sound remains a key challenge.\nTo address these issues, we introduce Sound Consistency Trajectory Models (SoundCTM), which allow flexible transitions between high-quality $1$-step sound generation and superior sound quality through multi-step deterministic sampling. \nThis allows creators to efficiently conduct trial-and-error with $1$-step generation to semantically align samples with their intention, and subsequently refine sample quality with preserving semantic content through deterministic multi-step sampling.\nTo develop SoundCTM, we reframe the CTM training framework, originally proposed in computer vision, and introduce a novel feature distance using the teacher network for a distillation loss. \nAdditionally, while distilling classifier-free guided trajectories, we introduce a $\\nu$-sampling, a new algorithm that offers another source of quality improvement. For the $\\nu$-sampling, we simultaneously train both conditional and unconditional student models.\nFor production-level generation, we scale up our model to 1B trainable parameters, making SoundCTM-DiT-1B the first large-scale distillation model in the sound community to achieve both promising high-quality $1$-step and multi-step full-band (44.1kHz) generation.\nAudio samples are available at \\url{https://anonymus-soundctm.github.io/soundctm_iclr/}.", "title_embedding_index": 9972, "title_abs_embedding_index": 9997}, {"title": "Breaking the Reclustering Barrier in Centroid-based Deep Clustering", "link_suffix": "/forum?id=r01fcKhzT5", "link": "https://openreview.net/forum?id=r01fcKhzT5", "pdf_link": "https://openreview.net/pdf?id=r01fcKhzT5", "keywords": "deep clustering, unsupervised learning, representation learning", "abstract": "This work investigates an important phenomenon in centroid-based deep clustering(DC) algorithms: Performance quickly saturates after a period of rapid early gains. Practitioners commonly address early saturation with periodic reclustering, which we demonstrate to be insufficient to address performance plateaus. We call this phenomenon the \u201creclustering barrier\u201d and empirically show when the reclustering barrier occurs, what its underlying mechanisms are, and how it ispossible to Break the Reclustering Barrier with our algorithm BRB. BRB avoids early over-commitment to initial clusterings and enables continuous adaptation to reinitialized clustering targets while remaining conceptually simple. Applying our algorithm to widely-used centroid-based DC algorithms, we show that (1) BRB consistently improves performance across a wide range of clustering benchmarks, (2) BRB enables training from scratch, and (3) BRB performs competitively against state-of-the-art DC algorithms when combined with a contrastive loss.", "title_embedding_index": 9973, "title_abs_embedding_index": 9998}, {"title": "AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models", "link_suffix": "/forum?id=5UQ0YmC2js", "link": "https://openreview.net/forum?id=5UQ0YmC2js", "pdf_link": "https://openreview.net/pdf?id=5UQ0YmC2js", "keywords": "Diffusion Model, Adversarial Attack", "abstract": "Recent advances in diffusion models have significantly enhanced the quality of image synthesis, yet they have also introduced serious safety concerns, particularly the generation of Not Safe for Work (NSFW) content. Previous research has demonstrated that adversarial prompts can be used to generate NSFW content. However, such adversarial text prompts are often easily detectable by text-based filters, limiting their efficacy. In this paper, we expose a previously overlooked vulnerability: adversarial image attacks targeting Image-to-Image (I2I) diffusion models. We propose AdvI2I, a novel framework that manipulates input images to induce diffusion models to generate NSFW content. By optimizing a generator to craft adversarial images, AdvI2I circumvents existing defense mechanisms, such as Safe Latent Diffusion (SLD), without altering the text prompts. Furthermore, we introduce AdvI2I-Adaptive, an enhanced version that adapts to potential countermeasures and minimizes the resemblance between adversarial images and NSFW concept embeddings, making the attack more resilient against defenses. Through extensive experiments, we demonstrate that both AdvI2I and AdvI2I-Adaptive can effectively bypass current safeguards, highlighting the urgent need for stronger security measures to address the misuse of I2I diffusion models.", "title_embedding_index": 9974, "title_abs_embedding_index": 9999}]
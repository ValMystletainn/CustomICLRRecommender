[{"title": "UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation", "link_suffix": "/forum?id=Pgwpc0rzbM", "link": "https://openreview.net/forum?id=Pgwpc0rzbM", "pdf_link": "https://openreview.net/pdf?id=Pgwpc0rzbM", "keywords": "Large Language Models, Tokenization, Molecule Generation, Molecule Comprehension, Multi-modal Learning", "abstract": "The remarkable success of Large Language Models (LLMs) across diverse tasks has driven the research community to extend their capabilities to molecular applications. However, most molecular LLMs employ adapter-based architectures that do not treat molecule and text modalities equally and lack a supervision signal for the molecule modality. To address these issues, we introduce UniMoT, a Unified Molecule-Text LLM adopting a tokenizer-based architecture that expands the vocabulary of LLM with molecule tokens.\nSpecifically, we introduce a Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge the modality gap between molecule and text. This tokenizer transforms molecules into sequences of molecule tokens with causal dependency, encapsulating high-level molecular and textual information. \nEquipped with this tokenizer, UniMoT can unify molecule and text modalities under a shared token representation and an autoregressive training paradigm.\nIt can interpret molecules as a foreign language and generate them as text.\nFollowing a four-stage training scheme, UniMoT emerges as a multi-modal generalist capable of performing both molecule-to-text and text-to-molecule tasks. Extensive experiments demonstrate that UniMoT achieves state-of-the-art performance across a wide range of molecule comprehension and generation tasks.", "title_embedding_index": 7950, "title_abs_embedding_index": 7975}, {"title": "RETHINK MAXIMUM STATE ENTROPY", "link_suffix": "/forum?id=zaoGCGLpux", "link": "https://openreview.net/forum?id=zaoGCGLpux", "pdf_link": "https://openreview.net/pdf?id=zaoGCGLpux", "keywords": "Reinforcement Learning for Exploration, Maximum Entropy, Intrinsic Rewards", "abstract": "In the absence of specific tasks or extrinsic reward signals, a key objective for an agent is the efficient exploration of its environment. A widely adopted strategy to achieve this is maximizing state entropy, which encourages the agent to uniformly explore the entire state space. Most existing approaches for maximum state entropy (MaxEnt) are rooted in two foundational approaches, which were proposed by Hazan and Liu & Abbeel, respectively. However, a unified perspective on these methods is lacking within the community.In this paper, we analyze these two foundational approaches within a unified framework and demonstrate that both methods share the same reward function when employing the $k$NN density estimator. We also show that the $\\eta$-based policy sampling method proposed by Hazan is unnecessary and that the primary distinction between the two lies in the frequency with which the locally stationary reward function is updated.  Building on this analysis, we introduce MaxEnt-(V)eritas, which combines the most effective components of both methods: iteratively updating the reward function as defined by Liu & Abbeel, and training the agent until convergence before updating the reward functions, akin to the procedure used by Hazan. We prove that MaxEnt-V is an efficient $\\varepsilon$-optimal algorithm for maximizing state entropy, where the tolerance $\\varepsilon$ decreases as the number of iterations increases. Empirical validation in three Mujoco environments shows that MaxEnt-Veritas significantly outperforms the two MaxEnt frameworks in terms of both state coverage and state entropy maximization, with sound explanations for these results.", "title_embedding_index": 7951, "title_abs_embedding_index": 7976}, {"title": "DynAlign: Unsupervised Dynamic Taxonomy Alignment for Cross-Domain Segmentation", "link_suffix": "/forum?id=IdAyXxBud7", "link": "https://openreview.net/forum?id=IdAyXxBud7", "pdf_link": "https://openreview.net/pdf?id=IdAyXxBud7", "keywords": "unsupervised domain adaptation\uff0csemantic segmentation\uff0ctaxonomy adaptation\uff0cfoundational models", "abstract": "Current unsupervised domain adaptation (UDA) methods for semantic segmentation typically assume identical class labels between the source and target domains. This assumption ignores the label-level domain gap, which is common in real-world scenarios, and limits their ability to identify finer-grained or novel categories without requiring extensive manual annotation.\nA promising direction to address this limitation lies in recent advancements in foundation models, which exhibit strong generalization abilities due to their rich prior knowledge. However, these models often struggle with domain-specific nuances and underrepresented fine-grained categories.\nTo address these challenges, we introduce DynAlign, a two-stage framework that integrates UDA with foundation models to bridge both the image-level and label-level domain gaps. Our approach leverages prior semantic knowledge to align source categories with target categories that can be novel, more fine-grained, or named differently. (e.g., vehicle to car, truck, bus). Foundation models are then employed for precise segmentation and category reassignment. To further enhance accuracy, we propose a knowledge fusion approach that dynamically adapts to varying scene contexts. DynAlign generates accurate predictions in a new target label space without requiring any manual annotations, allowing seamless adaptation to new taxonomies through either model retraining or direct inference.\nExperiments on the GTA $\\rightarrow$  IDD and GTA$\\rightarrow$ Mapillary benchmarks validate the effectiveness of our approach, achieving a significant improvement over existing methods.", "title_embedding_index": 7952, "title_abs_embedding_index": 7977}, {"title": "Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning", "link_suffix": "/forum?id=09FiNmvNMw", "link": "https://openreview.net/forum?id=09FiNmvNMw", "pdf_link": "https://openreview.net/pdf?id=09FiNmvNMw", "keywords": "Logical Reasoning, Large Language Models, Neurosymbolic Approaches, Semantic Decomposition, Formal Language Verification", "abstract": "Complex logical reasoning tasks require a long sequence of reasoning, which a large language model (LLM) with chain-of-thought prompting still falls short. To alleviate this issue, neurosymbolic approaches incorporate a symbolic solver. Specifically, an LLM only translates a natural language problem into a satisfiability (SAT) problem that consists of first-order logic formulas, and a sound symbolic solver returns a mathematically correct solution. However, we discover that LLMs have difficulties to capture complex logical semantics hidden in the natural language during translation. To resolve this limitation, we propose a Compositional First-Order Logic Translation. An LLM first parses a natural language sentence into newly defined logical dependency structures that consist of an atomic subsentence and its dependents, then sequentially translate the parsed subsentences. Since multiple logical dependency structures and sequential translations are possible for a single sentence, we also introduce two Verification algorithms to ensure more reliable results. We utilize an SAT solver to rigorously compare semantics of generated first-order logic formulas and select the most probable one. We evaluate the proposed method, dubbed CLOVER, on seven logical reasoning benchmarks and show that it outperforms the previous neurosymbolic approaches and achieves new state-of-the-art results.", "title_embedding_index": 7953, "title_abs_embedding_index": 7978}, {"title": "To Tackle Adversarial Transferability: A Novel Ensemble Training Method with Fourier Transformation", "link_suffix": "/forum?id=KW8yzAOIZr", "link": "https://openreview.net/forum?id=KW8yzAOIZr", "pdf_link": "https://openreview.net/pdf?id=KW8yzAOIZr", "keywords": "robustness, diversity, ensemble training, Fourier transformation", "abstract": "Ensemble methods are commonly used for enhancing robustness in machine learning. However, due to the ''transferability'' of adversarial examples, the performance of an ensemble model can be \nseriously affected even it contains a set of independently trained sub-models. To address this issue, we propose an efficient data transformation method based on a cute  ''weakness allocation'' strategy, to diversify non-robust features.\nOur approach relies on a fine-grained analysis on the relation between non-robust features and adversarial attack directions.\nMoreover, our approach enjoys several other advantages, e.g., it does  not require any communication between sub-models and the construction complexity is also quite low.\nWe  conduct a set of  experiments to evaluate the performance of our proposed method and compare it with several popular baselines. The  results suggest that our approach can achieve significantly improved robust accuracy over most existing ensemble methods, and meanwhile preserve high clean accuracy.", "title_embedding_index": 7954, "title_abs_embedding_index": 7979}, {"title": "Manifold Induced Biases for Zero-shot and Few-shot Detection of Generated Images", "link_suffix": "/forum?id=7gGl6HB5Zd", "link": "https://openreview.net/forum?id=7gGl6HB5Zd", "pdf_link": "https://openreview.net/pdf?id=7gGl6HB5Zd", "keywords": "zero-shot, few-shot, generated image detection, total-variation, curvature, score function, diffusion models", "abstract": "Distinguishing between real and AI-generated images presents a timely and significant challenge. Despite extensive research in the (semi-)supervised regime, only recently, zero-shot and few-shot solutions have emerged as promising approaches to this task: They alleviate the ongoing data maintenance, which quickly becomes outdated due to advances in generative technologies. We identify two main gaps: (1) a lack of theoretical grounding for the methods, and (2) significant room for performance improvements in zero-shot and few-shot regimes. Our approach is founded on understanding and quantifying the biases inherent in generated content, where we use these quantities as criteria for characterizing generated images. Specifically, we explore the biases induced by the implicitly learned manifold of a pre-trained diffusion model: Through score-function analysis, curvature and gradient of the probability manifold are approximated in the zero-shot setting - yielding a scalar criterion for classification. We further extend our contribution to the few-shot setting by employing a mixture-of-experts methodology. Empirical results across 20 generative models demonstrate that our method outperforms current approaches in both zero-shot and few-shot settings. This work advances the theoretical understanding and practical usage of generated content biases through the lens of manifold analysis.", "title_embedding_index": 7955, "title_abs_embedding_index": 7980}, {"title": "Federated Domain Generalization with Data-free On-server Gradient Matching", "link_suffix": "/forum?id=8TERgu1Lb2", "link": "https://openreview.net/forum?id=8TERgu1Lb2", "pdf_link": "https://openreview.net/pdf?id=8TERgu1Lb2", "keywords": "Federated Learning, Domain Generalization", "abstract": "Domain Generalization (DG) aims to learn from multiple known source domains a model that can generalize well to unknown target domains. One of the key approaches in DG is training an encoder which generates domain-invariant representations. However, this approach is not applicable in Federated Domain Generalization (FDG), where data from various domains are distributed across different clients. In this paper, we introduce a novel approach, dubbed Federated Learning via On-server Matching Gradient (FedOMG), which can efficiently leverage domain information from distributed domains. Specifically, we utilize the local gradients as information about the distributed models to find an invariant gradient direction across all domains through gradient inner product maximization. The advantages are two-fold: 1) we can aggregate the characteristics of distributed models on the centralized server without incurring any additional communication cost, and 2) our method is orthogonal to many existing DG methods, allowing for additional performance improvements by being seamlessly integrated with them. Extensive experimental evaluations on various settings to demonstrate the robustness of FedOMG compared to other FL/FDG baselines. Our method outperforms recent SOTA baselines on four FL benchmarks (MNIST, EMNIST, CIFAR-10, CIFAR-100), and three FDG benchmarks (PACS, VLCS, OfficeHome).", "title_embedding_index": 7956, "title_abs_embedding_index": 7981}, {"title": "Rethinking Sparse Scaling through the Lens of Average Active Parameter Count", "link_suffix": "/forum?id=ud8FtE1N4N", "link": "https://openreview.net/forum?id=ud8FtE1N4N", "pdf_link": "https://openreview.net/pdf?id=ud8FtE1N4N", "keywords": "pruning, sparsity, large language model, pretraining", "abstract": "Parameter pruning has emerged as a promising technique to address the growing computational demand of large language models (LLMs). While many studies focus on post-training pruning of LLMs, sparse pre-training offers a compelling alternative: sparsifying during pre-training reduces both training and inference costs. In this work, we conduct the first comprehensive study on optimal sparse pre-training configurations for LLMs, exploring various pruning schedules across different sparsity levels and training duration. We evaluate 80 unique configurations and find that a pruning schedule starting at 25% of total training compute and ending at 75% achieves near-optimal final evaluation loss. Our findings provide valuable insights for efficient and effective sparse pre-training of LLMs. Furthermore, we propose a new scaling law that modifies the Chinchilla scaling law to use the average number of active parameters during training. We present both empirical and theoretical evidence that this modification accurately models evaluation loss for both sparsely and densely pre-trained LLMs, thus offering a unified scaling law for dense and sparse model training. Our insights suggest that, while sparse pre-training yields similar model loss as dense pre-training for the same compute budget, it offers a clear advantage: the final model is smaller, resulting in significant potential computational savings during inference.", "title_embedding_index": 7957, "title_abs_embedding_index": 7982}, {"title": "Unleashing Graph Transformers with Green and Martin Kernels", "link_suffix": "/forum?id=eYcK7lzlOi", "link": "https://openreview.net/forum?id=eYcK7lzlOi", "pdf_link": "https://openreview.net/pdf?id=eYcK7lzlOi", "keywords": "Graph Transformers, Graph Neural Networks, Structural Encodings, Green Kernel, Martin Kernel, Non-aperiodic substructures, DAGs", "abstract": "Graph Transformers (GTs) are rapidly emerging as superior models, surpassing traditional message-passing neural networks in graph-level tasks. For optimal performance, it is essential to design GT architectures that embed graph inductive biases and utilize global attention mechanisms through effective structural encodings (SEs). In this work, we introduce novel SEs derived from a rigorous theoretical analysis of random walks (RWs), specifically leveraging the Green and Martin kernels. The Green and Martin kernels are mathematical tools used to observe the long-term behavior of RWs on graphs. By integrating these kernels into the encoding process, we enhance their capability to accurately represent complex graph structures. Our empirical evaluations demonstrate that these approaches enable GTs to achieve state-of-the-art performance on 7 out of 8 benchmark datasets. These include molecular datasets characterized by intricate, non-aperiodic substructures such as benzene rings, and directed acyclic graphs common in the circuit domain. We attribute these performance improvement to the effective capture of the characteristics of non-aperiodic substructures and directed acyclic graphs by our extending encodings. The results not only validate the effectiveness of integrating the Green and Martin kernels into RW-based encodings but also underscore their potential to substantially enhance the learning capabilities of GTs across diverse applications.", "title_embedding_index": 7958, "title_abs_embedding_index": 7983}, {"title": "Understanding Visual Concepts Across Models", "link_suffix": "/forum?id=74vnDs1R97", "link": "https://openreview.net/forum?id=74vnDs1R97", "pdf_link": "https://openreview.net/pdf?id=74vnDs1R97", "keywords": "Deep Learning", "abstract": "Large multimodal models such as Stable Diffusion can generate, detect, and classify new visual concepts after optimizing just the prompt. How are prompt embeddings for visual concepts found by prompt tuning methods different from typical discrete prompts? We conduct a large-scale analysis on three state-of-the-art models in text-to-image generation, open-set object detection, and zero-shot classification, and find that prompts optimized to represent new visual concepts are akin to an adversarial attack on the text encoder. Across 4,800 new embeddings trained for 40 diverse visual concepts on four standard datasets, we find perturbations within an $\\epsilon$-ball to any prompt that reprogram models to generate, detect, and classify arbitrary subjects. These perturbations target the final-layers in text encoders, and steer pooling tokens towards the subject. We explore the transferability of these prompts, and find that perturbations reprogramming multimodal models are initialization-specific, and model-specific. Code for reproducing our work is available at the following site:https://anonymous-visual-words.github.io.", "title_embedding_index": 7959, "title_abs_embedding_index": 7984}, {"title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer", "link_suffix": "/forum?id=ExuBFYtCQU", "link": "https://openreview.net/forum?id=ExuBFYtCQU", "pdf_link": "https://openreview.net/pdf?id=ExuBFYtCQU", "keywords": "text-to-speech synthesis, masked generative models, codec language models, voice cloning", "abstract": "The recent large-scale text-to-speech (TTS) systems are usually grouped as autoregressive and non-autoregressive systems. The autoregressive systems implicitly model duration but exhibit certain deficiencies in robustness and lack of duration controllability. Non-autoregressive systems require explicit alignment information between text and speech during training and predict durations for linguistic units (e.g. phone), which may compromise their naturalness.\nIn this paper, we introduce $\\textbf{Mask}$ed $\\textbf{G}$enerative $\\textbf{C}$odec $\\textbf{T}$ransformer (MaskGCT), a fully non-autoregressive TTS model that eliminates the need for explicit alignment information between text and speech supervision, as well as phone-level duration prediction. MaskGCT is a two-stage model: in the first stage, the model uses text to predict semantic tokens extracted from a speech self-supervised learning (SSL) model, and in the second stage, the model predicts acoustic tokens conditioned on these semantic tokens. MaskGCT follows the mask-and-predict learning paradigm. During training, MaskGCT learns to predict masked semantic or acoustic tokens based on given conditions and prompts. During inference, the model generates tokens of a specified length in a parallel manner. \nExperiments with 100K hours of in-the-wild speech demonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS systems in terms of quality, similarity, and intelligibility. Audio samples are available athttps://maskgct.github.io/.", "title_embedding_index": 7960, "title_abs_embedding_index": 7985}, {"title": "PolyMATH: A Challenging Multi-Modal Mathematical Reasoning Benchmark", "link_suffix": "/forum?id=WVBzN1HIFS", "link": "https://openreview.net/forum?id=WVBzN1HIFS", "pdf_link": "https://openreview.net/pdf?id=WVBzN1HIFS", "keywords": "Visual Math Problem-Solving, Multi-Modal Language Models (MLLMs), Cognitive Reasoning Evaluation", "abstract": "Multi-modal Large Language Models (MLLMs) exhibit impressive problem solving abilities in various domains, but their visual comprehension and abstract reasoning skills remain under-evaluated. To this end, we present POLYMATH, a challenging benchmark aimed at evaluating the general cognitive reasoning abilities of MLLMs. POLYMATH comprises 5,000 manually collected high-quality images\nof cognitive textual and visual challenges across 10 distinct categories, including pattern recognition, spatial reasoning, and relative reasoning. We conducted a comprehensive, and quantitative evaluation of 15 MLLMs using four diverse prompting strategies, including Chain-of-Thought and Step-Back. The best scores achieved on POLYMATH are \u223c 41%, \u223c 36%, and \u223c 27%, obtained by Claude-3.5 Sonnet, GPT-4o and Gemini-1.5 Pro respectively highlighting the logical and visual complexity of these questions. A further fine-grained error analysis reveals that these models struggle to understand spatial relations and perform drawn-out, high-level reasoning. This is further strengthened by our ablation study estimating MLLM performance when given textual descriptions in place of diagrams. As evidenced by \u223c 4% improvement over textual descriptions as opposed to actual images, we discover that models do not truly comprehend visual diagrams and the spatial information therein, and are thus prone to logical errors. Finally, we evaluate the OpenAI o1 models and find that their performance only matches the human baseline, highlighting the difficulty of the benchmark. The results on POLYMATH highlight the room for improvement in multi-modal reasoning and provide unique insights to guide the development of future MLLMs", "title_embedding_index": 7961, "title_abs_embedding_index": 7986}, {"title": "Only-IF: Revealing the Decisive Effect of Instruction Diversity on Generalization", "link_suffix": "/forum?id=PW1Mj6lLh2", "link": "https://openreview.net/forum?id=PW1Mj6lLh2", "pdf_link": "https://openreview.net/pdf?id=PW1Mj6lLh2", "keywords": "Instruction Following; Generalization", "abstract": "Understanding and accurately following instructions is critical for large language models (LLMs) to be effective across diverse tasks. In this work, we conduct a rigorous investigation into the factors that enable generalization to unseen instructions. Through controlled experiments, inspired by the Turing-complete Markov algorithm, we demonstrate that such generalization $\\textbf{only emerges}$ when training data is diversified enough across semantic domains. Our findings also reveal that merely diversifying within limited domains fails to ensure robust generalization. In contrast, cross-domain data diversification, even under constrained data budgets, significantly enhances a model's adaptability. We further extend our analysis to real-world scenarios, including fine-tuning of $\\textit{\\textbf{{specialist}}}$ and $\\textit{\\textbf{{generalist}}}$ models. Our research provides important insights for dataset collation, particularly when optimizing model performance by expanding training data for both specialist and generalist scenarios. We show that careful consideration of data diversification is key: training specialist models with data extending beyond their core domain leads to significant performance improvements, while generalist models benefit from diverse data mixtures that enhance their overall instruction-following capabilities across a wide range of applications. . Our results highlight the critical role of\nstrategic diversification and offer clear guidelines for improving data quality.", "title_embedding_index": 7962, "title_abs_embedding_index": 7987}, {"title": "Unveiling the latent dynamics in social cognition with multi-agent inverse reinforcement learning", "link_suffix": "/forum?id=KiDGtYCPcv", "link": "https://openreview.net/forum?id=KiDGtYCPcv", "pdf_link": "https://openreview.net/pdf?id=KiDGtYCPcv", "keywords": "Inverse Reinforcement Learning; Social Behavioral Latents; Theory of Mind Inference", "abstract": "Understanding the intentions and beliefs of others, a phenomenon known as \"theory of mind\", is a crucial element in social behavior. These beliefs and perceptions are inherently subjective and latent, making them often unobservable for investigation. Social interactions further complicate the matter, as multiple agents can engage in recursive reasoning about each other's strategies with increasing levels of cognitive hierarchy. While previous research has shown promise in understanding a single agent's belief of values through inverse reinforcement learning, extending this to model interactions among multiple agents remains an open challenge due to the computational complexity. In this work, we adopted a probabilistic recursive modeling of cognitive levels and joint value decomposition to achieve efficient multi-agent inverse reinforcement learning (MAIRL). We validated our method using simulations of a cooperative foraging task. Our algorithm revealed both the ground truth goal-directed value function and agents' beliefs about their counterparts' strategies. When applied to human behavior in a cooperative hallway task, our method identified meaningful goal maps that evolved with task proficiency and an interaction map that is related to key states in the task without accessing to the task rules. Similarly, in a non-cooperative task performed by monkeys, we identified mutual predictions that correlated with the animals' social hierarchy, highlighting the behavioral relevance of the latent beliefs we uncovered. Together, our findings demonstrate that MAIRL offers a new framework for uncovering human or animal beliefs in social behavior, thereby illuminating previously opaque aspects of social cognition.", "title_embedding_index": 7963, "title_abs_embedding_index": 7988}, {"title": "Benign Overfitting in Single-Head Attention", "link_suffix": "/forum?id=uVDwunWsLz", "link": "https://openreview.net/forum?id=uVDwunWsLz", "pdf_link": "https://openreview.net/pdf?id=uVDwunWsLz", "keywords": "single-head attention, benign overfitting, transformers", "abstract": "The phenomenon of benign overfitting, where a trained neural network perfectly fits noisy training data but still achieves near-optimal test performance, has been extensively studied in recent years for linear models and fully-connected/convolutional networks. In this work, we study benign overfitting in a single-head softmax attention model, which is the fundamental building block of Transformers. We prove that under appropriate conditions, the model exhibits benign overfitting in a classification setting already after two steps of gradient descent. Moreover, we show conditions where a minimum-norm/maximum-margin interpolator exhibits benign overfitting. We study how the overfitting behavior depends on the signal-to-noise ratio (SNR) of the data distribution, namely, the ratio between norms of signal and noise tokens, and prove that a sufficiently large SNR is both necessary and sufficient for benign overfitting.", "title_embedding_index": 7964, "title_abs_embedding_index": 7989}, {"title": "PLUM: Improving Code LMs Using On-Policy Preference Learning Powered by Automatic Test Cases", "link_suffix": "/forum?id=Dn7Ay7rZcH", "link": "https://openreview.net/forum?id=Dn7Ay7rZcH", "pdf_link": "https://openreview.net/pdf?id=Dn7Ay7rZcH", "keywords": "Code Generation, Preference Learning, Test Case Generation", "abstract": "Preference learning provides a promising solution to address the limitations of supervised fine-tuning (SFT) for code language models, where the model is not explicitly trained to differentiate between correct and incorrect code.\nRecent findings demonstrate that on-policy data is the key to successful preference learning, where the preference data is collected using the same policy LM being trained.\nInspired by this, we propose PLUM,\nan on-policy $\\textbf{P}$reference $\\textbf{L}$earning framework A$\\textbf{u}$gmented with test cases for code L$\\textbf{M}$s.\nThe framework operates in three key stages: (1) automatic generation of test cases from natural language instructions, (2) creation of a preference data by evaluating candidate code solutions sampled from the policy, which can then be used to (3) train the policy LM. PLUM levitates the need to train reward models, allowing for large scale on-policy and online preference data collation.PLUM is evaluated on both standard benchmarks (HumanEval, MBPP) and more challenging ones (LiveCodeBench), delivering substantial improvements over original SFT'ed models and other execution-feedback-driven approaches. We show PLUM benefits are consistent across various widely-used code LMs even they have been well-trained with SFT. For example, PLUM increases pass rates by up to 4.8% on average on standard benchmarks and 11.8% on LiveCodeBench, demonstrating its effectiveness and generalizability. We also demonstrate the benefits of on-policy and online preference learning", "title_embedding_index": 7965, "title_abs_embedding_index": 7990}, {"title": "Binary-Feedback Active Test-Time Adaptation", "link_suffix": "/forum?id=6ZdXp2Tbb6", "link": "https://openreview.net/forum?id=6ZdXp2Tbb6", "pdf_link": "https://openreview.net/pdf?id=6ZdXp2Tbb6", "keywords": "test-time adaptation, domain adaptation, deep learning, machine learning", "abstract": "Deep learning models perform poorly when domain shifts exist between training and test data. Test-time adaptation (TTA) is a paradigm to mitigate this issue by adapting pre-trained models using only unlabeled test samples. However, existing TTA methods can fail under severe domain shifts, while recent active TTA approaches requiring full-class labels are impractical due to high labeling costs. To\naddress this issue, we introduce a Binary-feedback Active Test-Time Adaptation (BATTA) setting, which uses a few binary feedbacks from annotators to indicate whether model predictions are correct, thereby significantly reducing the labeling burden of annotators. Under the setting, we propose BATTA-RL, a novel dual-path optimization framework that leverages reinforcement learning to balance binary feedback-guided adaptation on uncertain samples with agreement-based self-adaptation on confident predictions. Experiments show BATTA-RL achieves substantial accuracy improvements over state-of-the-art baselines, demonstrating its effectiveness in handling severe distribution shifts with minimal labeling effort.", "title_embedding_index": 7966, "title_abs_embedding_index": 7991}, {"title": "Subject Clustering by an Improved IF-PCA Algorithm", "link_suffix": "/forum?id=rSAPrQzoQa", "link": "https://openreview.net/forum?id=rSAPrQzoQa", "pdf_link": "https://openreview.net/pdf?id=rSAPrQzoQa", "keywords": "gene microarray, scRNA-seq, feature selection, manifold fitting, nonlinearity, PCA, sparsity, subject clustering", "abstract": "Subject (e.g., cell or patient) clustering is an important problem in genetics and genomics.  Influential features PCA (IF-PCA) is a recent idea for clustering, where we first select a small fraction of measured features and then cluster subjects (e.g., cells or patient) into different groups using the classical PCA clustering approach. A challenge the method faces is that, we may have complex signal and noise structures across features or across subjects or both, which may make the IF-PCA less effective. \nTo deal with such a challenge, we propose a new approach, IFPCA+, where  we combine IF-PCA with the recent idea of manifold fitting. The latter was shown to better support class separation. We compare our approach with the most popular subject clustering approaches, including but not limited to  DESC, SC3 and Seurat, using 10 gene microarray data sets and 8 single-cell data sets.  We show that with the new method,  we have a significant improvement in feature selection accuracy,  and that on average,  our method outperforms several of the most competitive algorithms nowadays (including IF-PCA, DESC, Seurat) in terms of clustering accuracy and ARI. We also shed light on the insight underlying such improvements.", "title_embedding_index": 7967, "title_abs_embedding_index": 7992}, {"title": "Modeling Divisive Normalization as Learned Local Competition in Visual Cortex", "link_suffix": "/forum?id=OovfCS4FYT", "link": "https://openreview.net/forum?id=OovfCS4FYT", "pdf_link": "https://openreview.net/pdf?id=OovfCS4FYT", "keywords": "divisive normalization, deep artificial neural networks, robustness, local competition, computational neuroscience", "abstract": "Convolutional Neural Networks (CNNs) embody priors about the visual world: locality, stationary statistics, translation invariance, and compositionality. Similarly, CNNs implement the retinotopy of visual cortex---nearby pixels are processed by nearby neurons. A common cortical computation not usually included in CNNs is divisive normalization. It has been shown that divisive normalization of Gabor filters results in more statistically independent responses (Simoncelli & Heeger, 1998). In this paper, we model divisive normalization as a simple computationally-efficient layer that can be inserted at any stage within deep artificial neural networks. Divisive normalization acts on neuronal sub-populations, whose parameters are initialized from a multivariate Gaussian distribution. This leads to the emergence of learned competition between both orientation-preferring and color-opponent cell types. Divisive normalization improves categorization performance, as well as robustness to perturbed images. Interestingly, in smaller networks, divisive normalization as a non-linear operation eliminates the need for a non-linear activation function like ReLU to drive performance.", "title_embedding_index": 7968, "title_abs_embedding_index": 7993}, {"title": "CBGBench: Fill in the Blank of Protein-Molecule Complex Binding Graph", "link_suffix": "/forum?id=mOpNrrV2zH", "link": "https://openreview.net/forum?id=mOpNrrV2zH", "pdf_link": "https://openreview.net/pdf?id=mOpNrrV2zH", "keywords": "Molecule Generation Benchmark, Target-Aware Drug Design, Generative Model", "abstract": "Structure-based drug design (SBDD) aims to generate potential drugs that can bind to a target protein and is greatly expedited by the aid of AI techniques in generative models. However, a lack of systematic understanding persists due to the diverse settings, complex implementation, difficult reproducibility, and task singularity. Firstly, the absence of standardization can lead to unfair comparisons and inconclusive insights. To address this dilemma, we propose CBGBench, a comprehensive benchmark for SBDD, that unifies the task as a generative heterogeneous graph completion, analogous to fill-in-the-blank of the 3D complex binding graph. By categorizing existing methods based on their attributes, CBGBench facilitates a modular and extensible framework that implements various cutting-edge methods. Secondly, a single de novo molecule generation task can hardly reflect their capabilities. To broaden the scope, we adapt these models to a range of tasks essential in drug design, considered sub-tasks within the graph fill-in-the-blank tasks. These tasks include the generative designation of de novo molecules, linkers, fragments, scaffolds, and sidechains, all conditioned on the structures of protein pockets. Our evaluations are conducted with fairness, encompassing comprehensive perspectives on interaction, chemical properties, geometry authenticity, and substructure validity. We further provide deep insights with analysis from empirical studies. Our results indicate that there is potential for further improvements on many tasks, optimization in network architectures, and incorporation of chemical prior knowledge. To lower the barrier to entry and facilitate further developments in the field, we also provide a unified codebase (supplementary) that includes the discussed state-of-the-art models, data pre-processing, training, sampling, and evaluation.", "title_embedding_index": 7969, "title_abs_embedding_index": 7994}, {"title": "STAF: Sinusoidal Trainable Activation Functions for Implicit Neural Representation", "link_suffix": "/forum?id=pOUAVXnOQP", "link": "https://openreview.net/forum?id=pOUAVXnOQP", "pdf_link": "https://openreview.net/pdf?id=pOUAVXnOQP", "keywords": "Implicit Neural Representation, Activation Functions, Parametric Activation Functions, Neural Tangent Kernel", "abstract": "Implicit Neural Representation (INR) has emerged as a promising method for characterizing continuous signals. This paper addresses the spectral bias exhibited by conventional ReLU networks, which hampers their ability to reconstruct fine details in target signals. We introduce Sinusoidal Trainable Activation Functions (STAF), designed to model and reconstruct diverse complex signals with high precision. STAF mitigates spectral bias, enabling faster learning of high-frequency details compared to ReLU networks. We demonstrate STAF's superiority over state-of-the-art networks such as KAN, WIRE, SIREN, and Fourier features, achieving higher accuracy and faster convergence with superior Peak Signal-to-Noise Ratio (PSNR). Our extensive experimental evaluation establishes STAF's effectiveness in improving the reconstruction quality and training efficiency of continuous signals, making them valuable for various applications in computer graphics and related fields.", "title_embedding_index": 7970, "title_abs_embedding_index": 7995}, {"title": "CABS: Conflict-Aware and Balanced Sparsification for Enhancing Model Merging", "link_suffix": "/forum?id=plflYGf23L", "link": "https://openreview.net/forum?id=plflYGf23L", "pdf_link": "https://openreview.net/pdf?id=plflYGf23L", "keywords": "Model Merging, Pruning Technique, Task Vectors, Language Models, Conflict-Aware Sparsity (CA), Balanced Sparsity (BS)", "abstract": "Model merging based on task vectors, i.e., the parameter differences between fine-tuned models and a shared base model, provides an efficient way to integrate multiple models without retraining. This approach can be used to combine task-specific models into a multitask model, improve generalization, or address model deficiencies. One of the significant challenges faced by model merging is the conflicts between task vectors. Existing works aim to mitigate these conflicts through sparsification; however, two issues observed in our experiments significantly limit their performance: $\\textit{high parameter overlap}$ and $\\textit{unbalanced weight distribution}$. To address these issues, we propose a simple yet effective framework called CABS (Conflict-Aware and Balanced Sparsification), consisting of $\\textbf{C}$onflict-$\\textbf{A}$ware Sparsification (CA) and $\\textbf{B}$alanced $\\textbf{S}$parsification (BS). CA can reduce parameter overlap by applying masks during sequential pruning, ensuring that each task vector retains distinct, non-overlapping parameters. BS leverages $n$:$m$ pruning to preserve critical weights while maintaining an even distribution across layers. Our comprehensive experiments demonstrate that CABS outperforms state-of-the-art methods across a range of diverse tasks and model sizes. Notably, in experiments with 7B-parameter language models, CABS surpasses the average performance of an \"ideal\" model, a virtual model that selects the highest score from individual fine-tuned models for each task (CABS: 76.50 vs. Ideal Model: 76.30 vs. Baseline: 76.02 vs. Fine-tuned Model: 75.86). Our results highlight the importance of addressing both high parameter overlap and unbalanced weight distribution to achieve robust and high-performance model merging.", "title_embedding_index": 7971, "title_abs_embedding_index": 7996}, {"title": "MIND over Body: Adaptive Thinking using Dynamic Computation", "link_suffix": "/forum?id=EjJGND0m1x", "link": "https://openreview.net/forum?id=EjJGND0m1x", "pdf_link": "https://openreview.net/pdf?id=EjJGND0m1x", "keywords": "Interpretability, Fixed points, Dynamic routing, Dynamic input processing, Deep Learning Framework", "abstract": "While the human brain efficiently handles various computations with a limited number of neurons, traditional deep learning networks require a significant increase in parameters to improve performance.\n  Yet, these parameters are used inefficiently as the networks employ the same amount of computation for inputs of the same size, regardless of the input's complexity.\n  We address this inefficiency by introducing self-introspection capabilities to the network, enabling it to adjust the number of used parameters based on the internal representation of the task and adapt the computation time based on the task complexity.This enables the network to adaptively reuse parameters across tasks, dynamically adjusting the computational effort in convergent loops to match the complexity of the input.  We demonstrate the effectiveness of this method on language modeling and computer vision tasks.\n  Notably, our model surpasses much larger ResNet-50 and EfficientNet with a three-layer network on ImageNet, achieving 96.62% accuracy, and scores a 95.8% F1 on the SQuAD dataset.\n  These results showcase the potential for dynamic and ``self-aware'' computation, contributing to the creation of intelligent systems that efficiently manage resources based on input data complexity.", "title_embedding_index": 7972, "title_abs_embedding_index": 7997}, {"title": "Towards Multimodal Open Set Recognition", "link_suffix": "/forum?id=slZZnzlITo", "link": "https://openreview.net/forum?id=slZZnzlITo", "pdf_link": "https://openreview.net/pdf?id=slZZnzlITo", "keywords": "Open Set Recognition, Multimodal Fusion, Classification", "abstract": "Open set recognition (OSR) requires deep learning models to identify unknown samples while recognizing known ones. Existing OSR studies focus on single-modal data but merely discuss how to handle multimodal data. In this paper, we propose a new task multimodal open set recognition (MMOSR), extending OSR to more practical scenarios. First, we analyze the necessity of MMOSR and provide insights into the task. We find that simply combining OSR and multimodal fusion methods faces the challenge of fusion degradation. The main reason is that the OSR regularization constrains the fused representations to be excessively compact, leading to deactivated and limited representations. We design the multimodal representation reactivation network (MRN) to alleviate fusion degradation by reactivating suppressed representations. MRN includes the mutually enhanced fusion for enhancing representations and performing cross-modal interaction, and the adaptive fusion for capturing multiple informative representations and outputting the adaptively fused prediction. Thus, the proposed method obtains effective and comprehensive multimodal representations and addresses the challenge of fusion degradation. Finally, extensive experiments on various settings demonstrate that the proposed method is superior to existing methods by up to 5.23% on OSCR.", "title_embedding_index": 7973, "title_abs_embedding_index": 7998}, {"title": "DPM: Dual Preferences-based Multi-Agent Reinforcement Learning", "link_suffix": "/forum?id=VzuPnoSKQ1", "link": "https://openreview.net/forum?id=VzuPnoSKQ1", "pdf_link": "https://openreview.net/pdf?id=VzuPnoSKQ1", "keywords": "multi-agent reinforcement learning, preference-based reinforcement learning, RLAIF, RLHF", "abstract": "Preference-based Reinforcement Learning (PbRL), which optimizes reward functions using preference feedback, is a promising approach for environments where handcrafted reward modeling is challenging. Especially in sparse-reward environments, feedback-based reward modeling achieves notable performance gains by transforming sparse feedback signals into dense ones.\nHowever, most PbRL research has primarily focused on single-agent environments, with limited attention to multi-agent environments.\nIn this paper, we propose Dual Preferences-based Multi-Agent Reinforcement Learning (DPM), which extends PbRL to multi-agent tasks by introducingdualpreferences comparing not only whole trajectories but also individual agent contributions during transitions. Furthermore, DPM replaces human preferences with those generated by LLMs to train the reward functions. Experimental results in the StarCraft Multi-Agent Challenge (SMAC) and SMACv2 environments demonstrate significant performance improvements over baselines, indicating the efficacy of DPM in optimizing individual reward functions and enhancing performances in sparse reward settings.", "title_embedding_index": 7974, "title_abs_embedding_index": 7999}]
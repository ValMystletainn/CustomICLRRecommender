[
    {
        "title": "Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback",
        "link_suffix": "/forum?id=ln2k0PqVQA",
        "link": "https://openreview.net/forum?id=ln2k0PqVQA",
        "pdf_link": "https://openreview.net/pdf?id=ln2k0PqVQA",
        "keywords": "reinforcement learning, decision making, large language model, exploration, intrinsic rewards",
        "abstract": "Automatically synthesizing dense rewards from natural language descriptions is a promising paradigm in reinforcement learning (RL), with applications to sparse reward problems, open-ended exploration, and hierarchical skill design. Recent works have made promising steps by exploiting the prior knowledge of large language models (LLMs). However, these approaches suffer from important limitations: they are either not scalable to problems requiring billions of environment samples; or are limited to reward functions expressible by compact code, which may require source code and have difficulty capturing nuanced semantics; or require a diverse offline dataset, which may not exist or be impossible to collect. In this work, we address these limitations through a combination of algorithmic and systems-level contributions. We propose \\oni, a distributed architecture that simultaneously learns an RL policy and an intrinsic reward function using LLM feedback. Our approach annotates the agent's collected experience via an asynchronous LLM server,  which is then distilled into an intrinsic reward model. We explore a range of algorithmic choices for reward modeling with varying complexity, including hashing, classification, and ranking models. By studying their relative tradeoffs, we shed light on questions regarding intrinsic reward design for sparse reward problems. Our approach achieves state-of-the-art performance across a range of challenging, sparse reward tasks from the NetHack Learning Environment in a simple unified process, solely using the agent's gathered experience, without requiring external datasets nor source code. We make our code available at \\url{URL}."
    },
    {
        "title": "Equivariant score-based generative models provably learn distributions with symmetries efficiently",
        "link_suffix": "/forum?id=b9rpcQxm5P",
        "link": "https://openreview.net/forum?id=b9rpcQxm5P",
        "pdf_link": "https://openreview.net/pdf?id=b9rpcQxm5P",
        "keywords": "score-based generative models, group symmetry, data augmentation, generalization error",
        "abstract": "Symmetry is ubiquitous in many real-world phenomena and tasks, such as physics, images, and molecular simulations. Empirical studies have demonstrated that incorporating symmetries into generative models can provide better generalization and sampling efficiency when the underlying data distribution has group symmetry. In this work, we provide the first theoretical analysis and guarantees of score-based generative models (SGMs) for learning distributions that are invariant with respect to some group symmetry and offer the first quantitative comparison between data augmentation and adding equivariant inductive bias. First, building on recent works on the Wasserstein-1 ($\\mathbf{d}_1$) guarantees of SGMs and empirical estimations of probability divergences under group symmetry, we provide an improved $\\mathbf{d}_1$ generalization bound when the data distribution is group-invariant. Second, we describe the inductive bias of equivariant SGMs using Hamilton-Jacobi-Bellman theory, and rigorously demonstrate that one can learn the score of a symmetrized distribution using equivariant vector fields without data augmentations through the analysis of the optimality and equivalence of score-matching objectives. This also provides practical guidance that one does not have to augment the dataset as long as the vector field or the neural network parametrization is equivariant. Moreover, we quantify the impact of not incorporating equivariant structure into the score parametrization, by showing that non-equivariant vector fields can yield worse generalization bounds. This can be viewed as a type of model-form error that describes the missing structure of non-equivariant vector fields. Numerical simulations corroborate our analysis and highlight that data augmentations cannot replace the role of equivariant vector fields."
    },
    {
        "title": "Can Language Models Reason about Individualistic Human Values and Preferences?",
        "link_suffix": "/forum?id=Do3whenqeY",
        "link": "https://openreview.net/forum?id=Do3whenqeY",
        "pdf_link": "https://openreview.net/pdf?id=Do3whenqeY",
        "keywords": "individualistic value alignment, pluralistic value alignment, human values, AI safety, individualistic value reasoning",
        "abstract": "Recent calls for pluralistic alignment emphasize that AI systems should address the diverse needs of all people. Yet, efforts in this space often require sorting people into fixed buckets of pre-specified diversity-defining dimensions (e.g., demographics, personalities, communication styles), risking smoothing out or even stereotyping the rich spectrum of individualistic variations. To achieve an authentic representation of diversity that respects individuality, we propose individualistic alignment. While individualistic alignment can take various forms, in this paper, we introduce IndieValueCatalog, a dataset transformed from the influential World Values Survey (WVS), to study language models (LMs) on the specific challenge of individualistic value reasoning. Specifically, given a sample of an individual\u2019s value-expressing statements, models are tasked with predicting their value judgments in novel cases. With IndieValueCatalog, we reveal critical limitations in frontier LMs\u2019 abilities to reason about individualistic human values with accuracies, only ranging between 55% to 65%. Moreover, our results highlight that a precise description of individualistic values cannot be approximated only via demographic information. We also identify a partiality of LMs in reasoning about global individualistic values, as measured by our proposed Value Inequity Index (\u03c3INEQUITY). Finally, we train a series of Individualistic Value Reasoners (IndieValueReasoner) using IndieValueCatalog to enhance models\u2019 individualistic value reasoning capability, revealing new patterns and dynamics into global human values. We outline future research challenges and opportunities for advancing individualistic alignment."
    },
    {
        "title": "A Novel Dual of Shannon Information and Weighting Scheme",
        "link_suffix": "/forum?id=PYQmaU4RwI",
        "link": "https://openreview.net/forum?id=PYQmaU4RwI",
        "pdf_link": "https://openreview.net/pdf?id=PYQmaU4RwI",
        "keywords": "entropy, certainty, uncertainty, weighting",
        "abstract": "Shannon Information theory has achieved great success in not only communication technology where it was originally developed for but also many other science and engineering fields such as machine learning and artificial intelligence. Inspired by the famous weighting scheme TF-IDF, we discovered that Shannon information entropy actually has a natural dual. To complement the classical Shannon information entropy which measures the uncertainty we propose a novel information quantity, namely troenpy. Troenpy measures the certainty and commonness of the underlying distribution. So entropy and troenpy form an information twin. To demonstrate its usefulness, we propose a conditional troenpy based weighting scheme for document with class labels, namely positive class frequency (PCF). On a collection of public datasets we show the PCF based weighting scheme outperforms the classical TF-IDF and a popular Optimal Transport based word moving distance algorithm in a kNN setting with respectively more than 22.9 and 26.5 classification error reduction while the corresponding entropy based approach completely fails. We further developed a new odds-ratio type feature, namely Expected Class Information Bias(ECIB), which can be regarded as the expected odds ratio of the information twin across different classes. In the experiments we observe that including the new ECIB features and simple binary term features in a simple logistic regression model can further significantly improve the performance. The proposed simple new weighting scheme and ECIB features are very effective and can be computed with linear time complexity."
    },
    {
        "title": "Conditional Enzyme Generation Using Protein Language Models with Adapters",
        "link_suffix": "/forum?id=dWReNWEj5b",
        "link": "https://openreview.net/forum?id=dWReNWEj5b",
        "pdf_link": "https://openreview.net/pdf?id=dWReNWEj5b",
        "keywords": "protein, enzyme, protein language model, generative model, fine-tuning, conditional generation, adapter, machine learning",
        "abstract": "The conditional generation of proteins with desired functions and/or properties is a key goal for generative models. Existing methods based on prompting of language models can generate proteins conditioned on a target functionality, such as a desired enzyme family. However, these methods are limited to simple, tokenized conditioning and have not been shown to generalize to unseen functions. In this study, we propose ProCALM (Protein Conditionally Adapted Language Model), an approach for the conditional generation of proteins using adapters to protein language models. Our specific implementation of ProCALM involves finetuning ProGen2 to incorporate conditioning representations of enzyme function and taxonomy. ProCALM matches existing methods at conditionally generating sequences from target enzyme families. Impressively, it can also generate within the joint distribution of enzymatic function and taxonomy, and it can generalize to rare and unseen enzyme families and taxonomies. Overall, ProCALM is a flexible and computationally efficient approach, and we expect that it can be extended to a wide range of generative language models."
    },
    {
        "title": "Labeled TrustSet Guided: Combining Batch Active Learning with Reinforcement Learning",
        "link_suffix": "/forum?id=3qDB9j6p3S",
        "link": "https://openreview.net/forum?id=3qDB9j6p3S",
        "pdf_link": "https://openreview.net/pdf?id=3qDB9j6p3S",
        "keywords": "Active learning, Reinforcement Learning",
        "abstract": "Batch active learning (BAL) is a crucial technique for reducing labeling costs and improving data efficiency in training large-scale deep learning models. Traditional BAL methods often rely on metrics like Mahalanobis Distance to balance uncertainty and diversity when selecting data for annotation. However, these methods predominantly focus on the distribution of unlabeled data and fail to leverage feedback from labeled data or the model\u2019s performance. To address these limitations, we introduce TrustSet, a novel approach that selects the most informative data from the labeled dataset, ensuring a balanced class distribution to mitigate the long-tail problem. Unlike CoreSet, which focuses on maintaining the overall data distribution, TrustSet optimizes the model\u2019s performance by pruning redundant data and using label information to refine the selection process. To extend the benefits of TrustSet to the unlabeled pool, we propose a reinforcement learning (RL)-based sampling policy that approximates the selection of high-quality TrustSet candidates from the unlabeled data. Combining TrustSet and RL, we introduce theBatchReinforcementActiveLearning withTrustSet (BRAL-T) framework. BRAL-T achieves state-of-the-art results across 10 image classification benchmarks and 2 active fine-tuning tasks, demonstrating its effectiveness and efficiency in various domains."
    },
    {
        "title": "Improved Finite-Particle Convergence Rates for Stein Variational Gradient Descent",
        "link_suffix": "/forum?id=sbG8qhMjkZ",
        "link": "https://openreview.net/forum?id=sbG8qhMjkZ",
        "pdf_link": "https://openreview.net/pdf?id=sbG8qhMjkZ",
        "keywords": "Stein Variational Gradient Descent, Non-asymptotic Rates, Variational Inference",
        "abstract": "We provide finite-particle convergence rates for the Stein Variational Gradient Descent (SVGD) algorithm in the Kernelized Stein Discrepancy ($\\KSD$) and Wasserstein-2 metrics. Our key insight is the observation that the time derivative of the relative entropy between the joint density of $N$ particle locations and the $N$-fold product target measure, starting from a regular initial distribution, splits into a dominant negative part proportional to $N$ times the expected $\\KSD^2$ and a smaller positive part. This observation leads to $\\KSD$ rates of order $1/\\sqrt{N}$, in both continuous and discrete time, providing a near optimal (in the sense of matching the corresponding i.i.d. rates) double exponential improvement over the recent result by~\\cite{shi2024finite}. Under mild assumptions on the kernel and potential, these bounds also grow polynomially in the dimension $d$. By adding a bilinear component to the kernel, the above approach is used to further obtain Wasserstein-2 convergence in continuous time. For the case of `bilinear + Mat'ern' kernels, we derive Wasserstein-2 rates that exhibit a curse-of-dimensionality similar to the i.i.d. setting. We also obtain marginal convergence and long-time propagation of chaos results for the time-averaged particle laws."
    },
    {
        "title": "Safe Meta-Reinforcement Learning via Dual-Method-Based Policy Adaptation: Near-Optimality and Anytime Safety Guarantee",
        "link_suffix": "/forum?id=BbYu1wLwmj",
        "link": "https://openreview.net/forum?id=BbYu1wLwmj",
        "pdf_link": "https://openreview.net/pdf?id=BbYu1wLwmj",
        "keywords": "Reinforcement learning, meta-learning",
        "abstract": "This paper studies the safe meta-reinforcement learning (safe meta-RL) problem where anytime safety is ensured during the meta-test. We develop a safe meta-RL framework that consists of two modules, safe policy adaptation and safe meta-policy training, and propose efficient algorithms for the two modules. Beyond existing safe meta-RL analyses, we prove the anytime safety guarantee of policy adaptation and provide a lower bound of the expected total reward of the adapted policies compared with the optimal policies, which shows that the adapted policies are nearly optimal. Our experiments demonstrate three key advantages over existing safe meta-RL methods: (i) superior optimality, (ii) anytime safety guarantee, and (iii) high computational efficiency."
    },
    {
        "title": "Learning the Optimal Stopping for Early Classification within Finite Horizons via Sequential Probability Ratio Test",
        "link_suffix": "/forum?id=SRghq20nGU",
        "link": "https://openreview.net/forum?id=SRghq20nGU",
        "pdf_link": "https://openreview.net/pdf?id=SRghq20nGU",
        "keywords": "Early Classification of Time Series, Sequential Probability Ratio Test",
        "abstract": "Time-sensitive machine learning benefits from Sequential Probability Ratio Test (SPRT), which provides an optimal stopping time for early classification of time series. However, infinite horizonscenarios, where input lengths are finite, determining the optimal stopping rule becomes computationally intensive due to the need forbackward induction, limiting practical applicability. We thus introduce FIRMBOUND, an SPRT-based framework that efficiently estimates the solution to backward induction from training data, bridging the gap between optimal stopping theory and real-world deployment. It employsdensity ratio estimationandconvex function learningto provide statistically consistent estimators for sufficient statistic and conditional expectation, both essential for solving backward induction; consequently, FIRMBOUND minimizes Bayes risk to reach optimality. Additionally, we present a faster alternative using Gaussian process regression, which significantly reduces training time while retaining low deployment overhead, albeit with potential compromise in statistical consistency. Experiments across independent and identically distributed (i.i.d.), non-i.i.d., binary, multiclass, synthetic, and real-world datasets show that FIRMBOUND achieves optimalities in the sense of Bayes risk and speed-accuracy tradeoff. Furthermore, it advances the tradeoff boundary toward optimality when possible and reduces decision-time variance, ensuring reliable decision-making. Code is included in the supplementary materials."
    },
    {
        "title": "CLIBD: Bridging Vision and Genomics for Biodiversity Monitoring at Scale",
        "link_suffix": "/forum?id=d5HUnyByAI",
        "link": "https://openreview.net/forum?id=d5HUnyByAI",
        "pdf_link": "https://openreview.net/pdf?id=d5HUnyByAI",
        "keywords": "Multimodal Learning, Contrastive Learning, DNA Barcodes, Taxonomic Classification, Fine-grained Classification, Biodiversity Monitoring",
        "abstract": "Measuring biodiversity is crucial for understanding ecosystem health. While prior works have developed machine learning models for taxonomic classification of photographic images and DNA separately, in this work, we introduce a multi-modal approach combining both, using CLIP-style contrastive learning to align images, barcode DNA, and text-based representations of taxonomic labels in a unified embedding space. This allows for accurate classification of both known and unknown insect species without task-specific fine-tuning, leveraging contrastive learning for the first time to fuse DNA and image data. Our method surpasses previous single-modality approaches in accuracy by over 8% on zero-shot learning tasks, showcasing its effectiveness in biodiversity studies."
    },
    {
        "title": "Revisiting inverse Hessian vector products for calculating influence functions",
        "link_suffix": "/forum?id=s6nYndMwG7",
        "link": "https://openreview.net/forum?id=s6nYndMwG7",
        "pdf_link": "https://openreview.net/pdf?id=s6nYndMwG7",
        "keywords": "influence functions, inverse Hessian-vector products, random sketching",
        "abstract": "Influence functions are a popular tool for attributing models' outputs to training data. The traditional approach relies on the calculation of inverse Hessian-vector products (iHVP), but the classical solver ``Linear time Stochastic Second-order Algorithm'' (LiSSA, Agarwal et al. (2017)) is often deemed impractical for large models due to expensive computation and hyperparameter tuning. We show that the three hyperparameters --- the scaling factor, the batch size, and the number of steps --- can be chosen depending on two specific spectral properties of the Hessian: its trace and largest eigenvalue. By evaluating them with random sketching (Swartworth and Woodruff, 2023), we find that the batch size has to be sufficiently large for the LiSSA to converge; however, for all of the models we consider, the requirement is mild. We confirm our findings empirically by comparing to the Proximal Bregman Retraining Functions (PBRF, Bae et al. (2022))."
    },
    {
        "title": "PEER Pressure: Model-to-Model Regularization for Single Source Domain Generalization",
        "link_suffix": "/forum?id=klcbim9KEm",
        "link": "https://openreview.net/forum?id=klcbim9KEm",
        "pdf_link": "https://openreview.net/pdf?id=klcbim9KEm",
        "keywords": "Domain Generalization, Representation Learning, Data Augmentation",
        "abstract": "Neural networks are frequently deployed on multiple unseen target domains, which are distributionally different from the source domain on which the model is trained. Data augmentation is the most popular tool for single source domain generalization, which expands the source domain by generating simulated ones, commonly adopted by existing approaches. In this work, we observe that the performance of such augmentation-based methods in the target domains frequently fluctuates during training, posing challenges in model selection under realistic scenarios. We argue that the fluctuation stems from the inability of the model to accumulate the knowledge learned from diverse augmentations, exacerbating feature distortion during training. Based on this observation, we propose a novel generalization method, coined Parameter-Space Ensemble with Entropy Regularization (PEER), that uses a proxy model to learn the augmented data on behalf of the main model. The main model is updated by averaging its parameters with the proxy model, progressively accumulating knowledge over the training steps. Maximizing the mutual information between the output representations of the two models guides the learning process of the proxy model, mitigating feature distortion during training. Extensive experimental results demonstrate the effectiveness of PEER in reducing the OOD performance fluctuation and enhancing generalization across various datasets, including PACS, Digits, Office-Home, and VLCS. Notably, our method with simple random augmentation achieves state-of-the-art performance, surpassing prior approaches on sDG that utilize complex data augmentation strategies."
    },
    {
        "title": "How DNNs break the Curse of Dimensionality: Compositionality and Symmetry Learning",
        "link_suffix": "/forum?id=UvpuGrd6ey",
        "link": "https://openreview.net/forum?id=UvpuGrd6ey",
        "pdf_link": "https://openreview.net/pdf?id=UvpuGrd6ey",
        "keywords": "Generalization bound, covering numbers, compositionality",
        "abstract": "We show that deep neural networks (DNNs) can efficiently learn any\ncomposition of functions with bounded $F_{1}$-norm, which allows\nDNNs to break the curse of dimensionality in ways that shallow networks\ncannot. More specifically, we derive a generalization bound that combines\na covering number argument for compositionality, and the $F_{1}$-norm\n(or the related Barron norm) for large width adaptivity. We show that\nthe global minimizer of the regularized loss of DNNs can fit for example\nthe composition of two functions $f^*=h\\circ g $ from a small number\nof observations, assuming $g$ is smooth/regular and reduces the dimensionality\n(e.g. $g$ could be the quotient map of the symmetries of $f^*$),\nso that $h$ can be learned in spite of its low regularity. The measures\nof regularity we consider is the Sobolev norm with different levels\nof differentiability, which is well adapted to the $F_{1}$ norm.\nWe compute scaling laws empirically and observe phase transitions\ndepending on whether $g$ or $h$ is harder to learn, as predicted\nby our theory."
    },
    {
        "title": "Detecting Backdoor Samples in Contrastive Language Image Pretraining",
        "link_suffix": "/forum?id=KmQEsIfhr9",
        "link": "https://openreview.net/forum?id=KmQEsIfhr9",
        "pdf_link": "https://openreview.net/pdf?id=KmQEsIfhr9",
        "keywords": "Backdoor, Detection, CLIP",
        "abstract": "Contrastive language-image pretraining (CLIP) has been found to be vulnerable to poisoning backdoor attacks where the adversary can achieve an almost perfect attack success rate on CLIP models by poisoning only 0.01% of the training dataset. This raises security concerns on the current practice of pretraining large-scale models on unscrutinized web data using CLIP. In this work, we analyze the representations of backdoor-poisoned samples learned by CLIP models and find that they exhibit unique characteristics in their local subspace, i.e., their local neighborhoods are far more sparse than that of clean samples. Based on this finding, we conduct a systematic study on detecting CLIP backdoor attacks and show that these attacks can be easily and efficiently detected by traditional density ratio-based local outlier detectors, whereas existing backdoor sample detection methods fail. Our experiments also reveal that an unintentional backdoor already exists in the original CC3M dataset and has been trained into a popular open-source model released by OpenCLIP. Based on our detector, one can clean up a million-scale web dataset (e.g., CC3M) efficiently within 15 minutes using 4 Nvidia A100 GPUs."
    },
    {
        "title": "Addressing Data Heterogeneity In Federated Learning With Adaptive Normalization-Free Feature Recalibration",
        "link_suffix": "/forum?id=uBEl8DMA8K",
        "link": "https://openreview.net/forum?id=uBEl8DMA8K",
        "pdf_link": "https://openreview.net/pdf?id=uBEl8DMA8K",
        "keywords": "Federated Learning, Deep Learning, Convolutional Neural Network, Image Classification",
        "abstract": "Federated learning is a decentralized collaborative training paradigm that preserves stakeholders\u2019 data ownership while improving performance and generalization. However, statistical heterogeneity among client datasets poses a fundamental challenge by degrading system performance. To address this issue, we propose Adaptive Normalization-free Feature Recalibration (ANFR), an architecture-level approach that combines weight standardization and channel attention. Weight standardization normalizes the weights of layers instead of activations. This is less susceptible to mismatched client statistics and inconsistent averaging, thereby more robust under heterogeneity. Channel attention produces learnable scaling factors for feature maps, suppressing those that are inconsistent between clients due to heterogeneity. We demonstrate that combining these techniques boosts model performance beyond their individual contributions, by enhancing class selectivity and optimizing channel attention weight distribution. ANFR operates independently of the aggregation method and is effective in both global and personalized federated learning settings, with minimal computational overhead. Furthermore, when training with differential privacy, ANFR achieves an appealing balance between privacy and utility, enabling strong privacy guarantees without sacrificing performance. By integrating weight standardization and channel attention in the backbone model, ANFR offers a novel and versatile approach to the challenge of statistical heterogeneity. We demonstrate through extensive experiments that ANFR consistently outperforms established baselines across various aggregation methods, datasets, and heterogeneity conditions."
    },
    {
        "title": "Contractive Dynamical Imitation Policies for Efficient Out-of-Sample Recovery",
        "link_suffix": "/forum?id=lILEtkWOXD",
        "link": "https://openreview.net/forum?id=lILEtkWOXD",
        "pdf_link": "https://openreview.net/pdf?id=lILEtkWOXD",
        "keywords": "Learning from demonstration, Safe imitation learning, Robotics, Dynamical system, Contraction theory",
        "abstract": "Imitation learning is a data-driven approach to learning policies from expert behavior, but it is prone to unreliable outcomes in out-of-sample (OOS) regions. While previous research on stable dynamical system policies guarantees convergence to a desired state, it often overlooks transient behavior. We propose a framework for learning policies modeled by contractive dynamical systems, ensuring that all policy rollouts converge regardless of perturbations, and in turn, enable efficient OOS recovery. By leveraging recurrent equilibrium networks and coupling layers, the policy structure guarantees contractivity for any parameter choice, which facilitates unconstrained optimization. Furthermore, we provide theoretical upper bounds for worst-case and expected loss terms, rigorously establishing the reliability of our method in deployment. Empirically, we demonstrate substantial OOS performance improvements in robotics manipulation and navigation tasks."
    },
    {
        "title": "Duoduo CLIP: Efficient 3D Understanding with Multi-View Images",
        "link_suffix": "/forum?id=iGbuc9ekKK",
        "link": "https://openreview.net/forum?id=iGbuc9ekKK",
        "pdf_link": "https://openreview.net/pdf?id=iGbuc9ekKK",
        "keywords": "3D Representation, 3D Understanding",
        "abstract": "We introduce Duoduo CLIP, a model for 3D representation learning that learns shape encodings from multi-view images instead of point-clouds. The choice of multi-view images allows us to leverage 2D priors from off-the-shelf CLIP models to facilitate fine-tuning with 3D data. Our approach not only shows better generalization compared to existing point cloud methods, but also reduces GPU requirements and training time. In addition, the model is modified with cross-view attention to leverage information across multiple frames of the object which further boosts performance. Notably, our model is permutation invariant to the order of multi-view images while being pose-free. Compared to the current SOTA point cloud method that requires 480 A100 hours to train 1 billion model parameters we only require 57 A5000 hours and 87 million parameters. Multi-view images also provide more flexibility including being able to encode objects with a variable number of images, and performance scales when more views are used. In contrast, point cloud based methods require an entire scan or model of the object. We showcase this flexibility with benchmarks from images of real-world objects. Our model also achieves better performance in more fine-grained text to shape retrieval, demonstrating better text-and-shape alignment than point cloud based models."
    },
    {
        "title": "PointRecon: Online 3D Point Cloud Reconstruction via Ray-based 2D-3D Matching",
        "link_suffix": "/forum?id=3JfvvuPXsH",
        "link": "https://openreview.net/forum?id=3JfvvuPXsH",
        "pdf_link": "https://openreview.net/pdf?id=3JfvvuPXsH",
        "keywords": "3D Reconstruction",
        "abstract": "We propose a novel online point-based 3D reconstruction method from a posed monocular RGB video. Our model maintains a global point cloud scene representation but allows points to adjust their 3D locations along the camera rays they were initially observed. When a new RGB image is inputted, the model adjusts the location of the existing points, expands the point cloud with newly observed points, and removes redundant points. These flexible updates are achieved through our novel ray-based 2D-3D matching technique. Our point-based representation does not require a pre-defined voxel size and can adapt to any resolution. A unified global representation also ensures consistency from different views. Results on the ScanNet dataset show that we improve over previous online methods and match the state-of-the-art performance with other types of approaches."
    },
    {
        "title": "TUAP: Targeted Universal Adversarial Perturbations for CLIP",
        "link_suffix": "/forum?id=LvjSLnMlwY",
        "link": "https://openreview.net/forum?id=LvjSLnMlwY",
        "pdf_link": "https://openreview.net/pdf?id=LvjSLnMlwY",
        "keywords": "Adversarial, Universal, Perturbation, Vision Language Model, VLM, CLIP",
        "abstract": "As Contrastive Language-Image Pretraining (CLIP) models are increasingly adopted in a wide range of downstream tasks and large Vision-Language Models (VLMs), their vulnerability to adversarial attacks has attracted growing attention. In this work, we examine the susceptibility of CLIP models to Universal Adversarial Perturbations (UAPs). Unlike existing works that focus on untargeted attacks in a white-box setting, we investigate targeted UAPs (TUAPs) in a black-box setting, with a particular emphasis on transferability. In TUAP, the adversary can specify a targeted adversarial text description and generate a universal $L_{\\infty}$-norm-bounded or $L_2$-norm perturbation or a small unrestricted patch, using an ensemble of surrogate CLIP encoders. When TUAP is applied to different test images, it can mislead the image encoder of unseen CLIP models into producing image embeddings that are consistently close to the adversarial target text embedding. We conduct comprehensive experiments to demonstrate the effectiveness and transferability of TUAPs. This universal transferability extends not only across different datasets and models but also to downstream models, such as large VLMs including OpenFlamingo, LLaVA, MiniGPT-4 and BLIP2. TUAP can mislead them into generating responses that contain text descriptions specified by the adversaries. Our findings reveal a universal vulnerability in CLIP models to targeted adversarial attacks, emphasizing the need for effective countermeasures."
    },
    {
        "title": "STABLE DIFFUSION MODELS ARE SECRETLY GOOD AT VISUAL IN-CONTEXT LEARNING",
        "link_suffix": "/forum?id=fKrFTGnoXY",
        "link": "https://openreview.net/forum?id=fKrFTGnoXY",
        "pdf_link": "https://openreview.net/pdf?id=fKrFTGnoXY",
        "keywords": "in context learning, stable diffusion",
        "abstract": "Large language models (LLM) in natural language processing (NLP) have demonstrated great potential for in-context learning (ICL) -- the ability to leverage a few set of example prompts to adapt to various tasks without having to explicitly update model weights. \nICL has recently been explored for the visual domain with promising early outcomes. These approaches involve specialized training and/or additional data which complicate the process and limit its generalizability. In this work, we show that off-the-shelf Stable Diffusion models can be re-purposed for visual in-context learning (V-ICL). Specifically, we formulate an in-place attention re-computation within the self-attention layers of the Stable Diffusion architecture that explicitly incorporates context between the query and example prompts. Without any additional fine-tuning, we show that this re-purposed Stable Diffusion model is able to adapt  to six different tasks: foreground segmentation, single object detection, semantic segmentation, keypoint detection,  edge detection, and colorization. \nFor example, the proposed approach improves the mean intersection over union (mIoU) for the foreground segmentation task on Pascal-5i dataset by 8.9% and 3.2% over recent methods such as Visual Prompting and IMProv, respectively. Additionally, we show that the proposed method is able to effectively leverage multiple prompts through ensembling to infer the task better and further improve the performance across all tasks."
    },
    {
        "title": "Innate-Values-driven Reinforcement Learning",
        "link_suffix": "/forum?id=XHvguNJRbE",
        "link": "https://openreview.net/forum?id=XHvguNJRbE",
        "pdf_link": "https://openreview.net/pdf?id=XHvguNJRbE",
        "keywords": "innate values, reinforcement learning, rationality",
        "abstract": "Innate values describe agents' intrinsic motivations, which reflect their inherent interests and preferences for pursuing goals and drive them to develop diverse skills that satisfy their various needs. Traditional reinforcement learning (RL) is learning from interaction based on the environment's feedback rewards. However, in real scenarios, the rewards are generated by agents' innate value systems, which differ vastly from individuals based on their needs and requirements. In other words, considering the AI agent as a self-organizing system, developing its awareness through balancing internal and external utilities based on its needs in different tasks is a crucial problem for individuals learning to support others and integrate community with safety and harmony in the long term. To address this gap, we propose a new RL model termed innate-values-driven RL (IVRL) based on combined motivations' models and expected utility theory to mimic its complex behaviors in the evolution through decision-making and learning. Then, we introduce two IVRL-based models: IV-DQN and IV-A2C. By comparing them with benchmark algorithms such as DQN, DDQN, A2C, and PPO in the Role-Playing Game (RPG) reinforcement learning test platform VIZDoom, we demonstrated that the IVRL-based models can help the agent rationally organize various needs, achieve better performance effectively."
    },
    {
        "title": "Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky ResNets",
        "link_suffix": "/forum?id=QXQiq8JVOB",
        "link": "https://openreview.net/forum?id=QXQiq8JVOB",
        "pdf_link": "https://openreview.net/pdf?id=QXQiq8JVOB",
        "keywords": "Theory of Deep Learning, Feature Learning, Hamiltonian",
        "abstract": "We study Leaky ResNets, which interpolate between ResNets ($\\tilde{L}=0$)\nand Fully-Connected nets ($\\tilde{L}\\to\\infty$) depending on an 'effective\ndepth' hyper-parameter $\\tilde{L}$. In the infinite depth limit,\nwe study 'representation geodesics' $A_{p}$: continuous paths in\nrepresentation space (similar to NeuralODEs) from input $p=0$ to\noutput $p=1$ that minimize the parameter norm of the network. We\ngive a Lagrangian and Hamiltonian reformulation, which highlight the\nimportance of two terms: a kinetic energy which favors small layer\nderivatives $\\partial_{p}A_{p}$ and a potential energy that favors\nlow-dimensional representations, as measured by the 'Cost of Identity'.\nThe balance between these two forces offers an intuitive understanding\nof feature learning in ResNets. We leverage this intuition to explain\nthe emergence of a bottleneck structure, as observed in previous work:\nfor large $\\tilde{L}$ the potential energy dominates and leads to\na separation of timescales, where the representation jumps rapidly\nfrom the high dimensional inputs to a low-dimensional representation,\nmove slowly inside the space of low-dimensional representations, before\njumping back to the potentially high-dimensional outputs. Inspired\nby this phenomenon, we train with an adaptive layer step-size\nto adapt to the separation of timescales."
    },
    {
        "title": "OmniSep: Unified Omni-Modality Sound Separation with Query-Mixup",
        "link_suffix": "/forum?id=DkzZ1ooc7q",
        "link": "https://openreview.net/forum?id=DkzZ1ooc7q",
        "pdf_link": "https://openreview.net/pdf?id=DkzZ1ooc7q",
        "keywords": "sound separation, composed query, negative query",
        "abstract": "The scaling up has brought tremendous success in the fields of vision and language in recent years. When it comes to audio, however, researchers encounter a major challenge in scaling up the training data, as most natural audio contains diverse interfering signals. To address this limitation, we introduce Omni-modal Sound Separation (OmniSep), a novel framework capable of isolating clean soundtracks based on omni-modal queries, encompassing both single-modal and multi-modal composed queries. Specifically, we introduce theQuery-Mixupstrategy, which blends query features from different modalities during training. This enables OmniSep to optimize multiple modalities concurrently, effectively bringing all modalities under a unified framework for sound separation. We further enhance this flexibility by allowing queries to influence sound separation positively or negatively, facilitating the retention or removal of specific sounds as desired. Finally, OmniSep employs a retrieval-augmented approach known asQuery-Aug, which enables open-vocabulary sound separation. Experimental evaluations on MUSIC, VGGSOUND-CLEAN+, and MUSIC-CLEAN+ datasets demonstrate effectiveness of OmniSep, achieving state-of-the-art performance in text-, image-, and audio-queried sound separation tasks. For samples and further information, please visit the demo page at \\url{https://omnisep.github.io/}."
    },
    {
        "title": "Optimal Learning of Kernel Logistic Regression for Complex Classification Scenarios",
        "link_suffix": "/forum?id=WlhVRh2rQ0",
        "link": "https://openreview.net/forum?id=WlhVRh2rQ0",
        "pdf_link": "https://openreview.net/pdf?id=WlhVRh2rQ0",
        "keywords": "complex classification scenarios, long-tailed learning, domain adaptation, transfer learning, kernel methods, logistic regression, learning theory",
        "abstract": "Complex classification scenarios, including long-tailed learning, domain adaptation, and transfer learning, present substantial challenges for traditional algorithms. Conditional class probability (CCP) predictions have recently become critical components of many state-of-the-art algorithms designed to address these challenging scenarios. Among kernel methods, kernel logistic regression (KLR) is distinguished by its effectiveness in predicting CCPs through the minimization of the cross-entropy (CE) loss. Despite the empirical success of CCP-based approaches, the theoretical understanding of their performance, particularly regarding the CE loss, remains limited. In this paper, we bridge this gap by demonstrating that KLR-based algorithms achieve minimax optimal convergence rates for the CE loss under mild assumptions in these complex tasks, thereby establishing their theoretical efficiency in such demanding contexts."
    },
    {
        "title": "Direct Acquisition Optimization for Low-Budget Active Learning",
        "link_suffix": "/forum?id=NK09Bcvuxl",
        "link": "https://openreview.net/forum?id=NK09Bcvuxl",
        "pdf_link": "https://openreview.net/pdf?id=NK09Bcvuxl",
        "keywords": "Low-Budget Active Learning, Data Scarcity, Label-Efficient Learning",
        "abstract": "Active Learning (AL) has gained prominence in integrating data-intensive machine learning (ML) models into domains with limited labeled data. However, its effectiveness diminishes significantly when the labeling budget is low. In this paper, we first empirically observe the performance degradation of existing AL algorithms in the low-budget settings, and then introduce Direct Acquisition Optimization (DAO), a novel AL algorithm that optimizes sample selections based on expected true loss reduction. Specifically, DAO utilizes influence functions to update model parameters and incorporates an additional acquisition strategy to mitigate bias in loss estimation. This approach facilitates a more accurate estimation of the overall error reduction, without extensive computations or reliance on labeled data. Experiments demonstrate DAO\u2019s effectiveness in low budget settings, outperforming state-of-the-arts approaches across seven benchmarks."
    }
]
[{"title": "Towards Calibrated Deep Clustering Network", "link_suffix": "/forum?id=JvH4jDDcG3", "link": "https://openreview.net/forum?id=JvH4jDDcG3", "pdf_link": "https://openreview.net/pdf?id=JvH4jDDcG3", "keywords": "Deep clustering, unsupervised calibration, clustering", "abstract": "Deep clustering has exhibited remarkable performance; however, the over-confidence problem, i.e., the estimated confidence for a sample belonging to a particular cluster greatly exceeds its actual prediction accuracy, has been overlooked in prior research. To tackle this critical issue, we pioneer the development of a calibrated deep clustering framework. Specifically, we propose a novel dual-head (calibration head and clustering head) deep clustering model that can effectively calibrate the estimated confidence and the actual accuracy. The calibration head adjusts the overconfident predictions of the clustering head, generating prediction confidence that match the model learning status. Then, the clustering head dynamically select reliable high-confidence samples estimated by the calibration head for pseudo-label self-training. Additionally, we introduce an effective network initialization strategy that enhances both training speed and network robustness. The effectiveness of the proposed calibration approach and initialization strategy are both endorsed with solid theoretical guarantees. Extensive experiments demonstrate the proposed calibrated deep clustering model not only surpasses state-of-the-art deep clustering methods by 10 times in terms of expected calibration error but also significantly outperforms them in terms of clustering accuracy. We have submitted the source code in the supplementary material.", "title_embedding_index": 13000, "title_abs_embedding_index": 13025}, {"title": "Amortized Control of Continuous State Space Feynman-Kac Model for Irregular Time Series", "link_suffix": "/forum?id=8zJRon6k5v", "link": "https://openreview.net/forum?id=8zJRon6k5v", "pdf_link": "https://openreview.net/pdf?id=8zJRon6k5v", "keywords": "stochastic optimal control, variational inference, state space model, irregular time series", "abstract": "Many real-world datasets, such as healthcare, climate, and economics, are often collected as irregular time series, which poses challenges for accurate modeling. In this paper, we propose the Amortized Control of continuous State Space Model (ACSSM) for continuous dynamical modeling of time series for irregular and discrete observations. We first present a multi-marginal Doob's $h$-transform to construct a continuous dynamical system conditioned on these irregular observations. Following this, we introduce a variational inference algorithm with a tight evidence lower bound (ELBO), leveraging stochastic optimal control (SOC) theory to approximate the intractable Doob's $h$-transform and simulate the conditioned dynamics. To improve efficiency and scalability during both training and inference, ACSSM employs amortized inference to decouple representation learning from the latent dynamics. Additionally, it incorporates a simulation-free latent dynamics framework and a transformer-based data assimilation scheme, facilitating parallel inference of the latent states and ELBO computation. Through empirical evaluations across a variety of real-world datasets, ACSSM demonstrates superior performance in tasks such as classification, regression, interpolation, and extrapolation, while maintaining computational efficiency.", "title_embedding_index": 13001, "title_abs_embedding_index": 13026}, {"title": "Link Prediction with Untrained Message Passing Layers", "link_suffix": "/forum?id=3llRc6oXEW", "link": "https://openreview.net/forum?id=3llRc6oXEW", "pdf_link": "https://openreview.net/pdf?id=3llRc6oXEW", "keywords": "graph neural networks, untrained message passing layers, link prediction, path-based similarity measures", "abstract": "In this work, we explore the use of untrained message passing layers in graph neural networks for link prediction. The untrained message passing layers we consider are derived from widely used graph neural network architectures by removing trainable parameters and nonlinearities in their respective message passing layers. Experimentally we find that untrained message passing layers can lead to competitive and even superior link prediction performance compared to fully trained message passing layers while being more efficient and naturally interpretable, especially in the presence of high-dimensional features. We also provide a theoretical analysis of untrained message passing layers in the context of link prediction and show that the inner product of features produced by untrained message passing layers relate to common neighbour and path-based topological measures which are widely used for link prediction. As such, untrained message passing layers offer a more efficient and interpretable alternative to trained message passing layers in link prediction tasks.", "title_embedding_index": 13002, "title_abs_embedding_index": 13027}, {"title": "G4Seg: Generation for Online Segmentation Refinement with Diffusion Models", "link_suffix": "/forum?id=a7gOjgFswH", "link": "https://openreview.net/forum?id=a7gOjgFswH", "pdf_link": "https://openreview.net/pdf?id=a7gOjgFswH", "keywords": "Diffusion models, Inexact Segmentation, Semantic Correspondence", "abstract": "This paper considers the problem of utilizing a large-scale text-to-image diffusion model to tackle the challenging Inexact Segmentation (IS) task. Unlike traditional approaches that rely heavily on discriminative-model-based paradigm or dense visual representations derived from internal attention mechanisms, our method focuses on the intrinsic generative priors in Stable Diffusion~(SD). Specifically, we exploit the pattern discrepancies between original images and mask-conditional generated images to facilitate a coarse-to-fine segmentation refinement by establishing a semantic correspondence alignment and updating the foreground probability. Comprehensive quantitative and qualitative experiments validate the effectiveness and superiority of our plug-and-play design, underscoring the potential of leveraging generation discrepancies to model dense representations and encouraging further exploration of generative approaches for solving discriminative tasks.", "title_embedding_index": 13003, "title_abs_embedding_index": 13028}, {"title": "DisPose: Disentangling Pose Guidance for Controllable Human Image Animation", "link_suffix": "/forum?id=AumOa10MKG", "link": "https://openreview.net/forum?id=AumOa10MKG", "pdf_link": "https://openreview.net/pdf?id=AumOa10MKG", "keywords": "Diffusion Model; Controllable Video Generation; Human Animation", "abstract": "Controllable human image animation aims to generate videos from reference images using driving videos. Due to the limited control signals provided by sparse guidance (e.g., skeleton pose), recent works have attempted to introduce additional dense conditions (e.g., depth map) to ensure motion alignment. However, such strict dense guidance impairs the quality of the generated video when the body shape of the reference character differs significantly from that of the driving video. In this paper, we present DisPose to mine more generalizable and effective control signals without additional dense input, which disentangles the sparse skeleton pose in human image animation into motion field guidance and keypoint correspondence. Specifically, we generate a dense motion field from a sparse motion field and the reference image, which provides region-level dense guidance while maintaining the generalization of the sparse pose control. We also extract diffusion features corresponding to pose keypoints from the reference image, and then these point features are transferred to the target pose to provide distinct identity information. To seamlessly integrate into existing models, we propose a plug-and-play hybrid ControlNet that improves the quality and consistency of generated videos while freezing the existing model parameters. Extensive qualitative and quantitative experiments demonstrate the superiority of DisPose compared to current methods. Project page:https://anonymous.4open.science/r/DisPose-AB1D.", "title_embedding_index": 13004, "title_abs_embedding_index": 13029}, {"title": "Bellman Unbiasedness: Toward Provably Efficient Distributional Reinforcement Learning with General Value Function Approximation", "link_suffix": "/forum?id=vpKjmJp6cO", "link": "https://openreview.net/forum?id=vpKjmJp6cO", "pdf_link": "https://openreview.net/pdf?id=vpKjmJp6cO", "keywords": "Distributional Reinforcement Learning, Regret Analysis, General Value Function Approximation", "abstract": "Distributional reinforcement learning improves performance by effectively capturing environmental stochasticity. \nHowever, existing research on its regret analysis has relied heavily on structural assumptions that are difficult to implement in practice.\nIn particular, there has been little attention to the infeasibility issue of dealing with the infinite-dimensionality of a distribution.\nTo overcome this infeasibility, we present a regret analysis of distributional reinforcement learning with general value function approximation in a finite episodic Markov decision process setting throughstatistical functional dynamic programming. \nWe first introduce a key notion ofBellman unbiasednesswhich is essential for exactly learnable and provably efficient updates.\nOur theoretical results demonstrate that the only way to exactly capture statistical information, including nonlinear statistical functionals, is by representing the infinite-dimensional return distribution with a finite number of moment functionals.\nSecondly, we propose a provably efficient algorithm,SF-LSVI,  that achieves a tight regret bound of $\\tilde{O}(d_E H^{\\frac{3}{2}}\\sqrt{K})$ where $H$ is the horizon, $K$ is the number of episodes, and $d_E$ is the eluder dimension of a function class.", "title_embedding_index": 13005, "title_abs_embedding_index": 13030}, {"title": "Video Anomaly Detection via Single Frame Supervision", "link_suffix": "/forum?id=A18zU6cgQ0", "link": "https://openreview.net/forum?id=A18zU6cgQ0", "pdf_link": "https://openreview.net/pdf?id=A18zU6cgQ0", "keywords": "Video Anomaly Detection, Inexact Supervision, Single Frame Supervision", "abstract": "Video Anomaly Detection (VAD) aims to identify anomalous frames in given videos. Existing fully-supervised VAD encounters substantial annotation cost and weakly-supervised VAD suffers from the deficiency of weak labels. In this paper, we propose a more effective Single Frame supervised VAD (SF-VAD), which leverages single abnormal frame as label. We argue that single abnormal frame provides precise dual references to abnormal and normal frames, which facilitates dependable anomaly and normality modeling, and it can be obtained with negligible extra cost. Under this setting, we propose similarity-based abnormal pattern modeling, to learn inclusive abnormal patterns reliably from mined abnormal frames, guided by similarity-based abnormal probability. And we introduce Gaussian-prior normal pattern modeling to decouple normal patterns in abnormal videos, by learning normal patterns in preceding frames, guided by Gaussian-prior normal probability. In inference, we additionally design temporal decoupling and boundary refining modules to reveal discriminative abnormal characters of temporal features. Extensive experiments show our SF-VAD method outperforms state-of-the-art VAD methods and achieves an optimal performance-cost trade-off. We construct and release three SF-VAD datasets to support future research.", "title_embedding_index": 13006, "title_abs_embedding_index": 13031}, {"title": "CLIP model is an Efficient Online Continual Learner", "link_suffix": "/forum?id=G9Ea7mlqGO", "link": "https://openreview.net/forum?id=G9Ea7mlqGO", "pdf_link": "https://openreview.net/pdf?id=G9Ea7mlqGO", "keywords": "online continual learning, vision-language models, CLIP, task-agnostic continual learning", "abstract": "Online continual learning addresses the challenge of learning from continuous, non-stationary data streams. Existing online continual learning frameworks are classification-based and assume a pre-defined number of classes. In this study, we propose that vision-language models (VLMs) are more suitable candidates for online continual learning. Compared to traditional classification-based frameworks, VLMs such as CLIP model is not limited by the maximum number of classes or constrained by rigid model architectures, enabling it to generalize across both known and emerging classes. However, we find that naively tuning the CLIP for online continual learning results in asymmetric image-text matching. This asymmetric matching will consistently poses negative suppression on the previously learned classes, leading to catestrophic forgetting. To address this issue, we propose a simple yet effective method, the symmetric image-text (SIT) tuning strategy, which mitigates the adverse impact of negative samples by excluding asymmetric text during online learning. Additionally, we introduce a more challenging blurred boundary online continual learning setup, namely MiD-Blurry, which mixes multiple data distributions to mimic real-world scenarios. We conducted extensive experiments on several continual learning benchmarks as well as the MID-Blurry setting, evaluating both inference-at-any-time performance and generalization to future data. Our results demonstrate that the SIT strategy effectively preserves memory stability while maintaining learning plasticity.", "title_embedding_index": 13007, "title_abs_embedding_index": 13032}, {"title": "Generalized Greedy Gradient-Based Hyperparameter Optimization", "link_suffix": "/forum?id=DRf8RpofIN", "link": "https://openreview.net/forum?id=DRf8RpofIN", "pdf_link": "https://openreview.net/pdf?id=DRf8RpofIN", "keywords": "bilevel optimization, meta-learning, hyperparameter optimization", "abstract": "Bilevel Optimization (BLO) is a widely-used approach that has numerous applications, including hyperparameter optimization, meta-learning. However, existing gradient-based method suffer from the following issues. Reverse-mode differentiation suffers from high memory requirements, while the methods based on the implicit function theorem require the convergence of the inner optimization.  Approximations that consider a truncated inner optimization trajectory suffer from a short horizon bias. In this paper, we propose a novel approximation for hypergradient computation that sidesteps these difficulties. Specifically, we accumulate the short-horizon approximations from each step of the inner optimization trajectory. Additionally, we demonstrate that under certain conditions, the proposed hypergradient is a sufficient descent direction. Experimental results on a few-shot meta-learning and data hyper-cleaning tasks support our findings.", "title_embedding_index": 13008, "title_abs_embedding_index": 13033}, {"title": "Online-to-Offline RL for Agent Alignment", "link_suffix": "/forum?id=ruv3HdK6he", "link": "https://openreview.net/forum?id=ruv3HdK6he", "pdf_link": "https://openreview.net/pdf?id=ruv3HdK6he", "keywords": "reinforcement learning, agent alignment", "abstract": "Reinforcement learning (RL) has shown remarkable success in training agents to achieve high-performing policies, particularly in domains like Game AI where simulation environments enable efficient interactions. However, despite their success in maximizing these returns, such online-trained policies often fail to align with human preferences concerning actions, styles, and values. The challenge lies in efficiently adapting these online-trained policies to align with human preferences, given the scarcity and high cost of collecting human behavior data. In this work, we formalize the problem asonline-to-offlineRL and propose ALIGNment of Game AI to Preferences (ALIGN-GAP), an innovative approach for alignment of well-trained game agents to human preferences. Our method features a carefully designed reward model that encodes human preferences from limited offline data and incorporates curriculum-based preference learning to align RL agents with targeted human values. Experiments across diverse environments and preference types demonstrate the performance of ALIGN-GAP, achieving effective alignment with human preferences.", "title_embedding_index": 13009, "title_abs_embedding_index": 13034}, {"title": "Tri-Comparison Expertise Decision for Drug-Target Interaction Mechanism Prediction", "link_suffix": "/forum?id=6i609meSJw", "link": "https://openreview.net/forum?id=6i609meSJw", "pdf_link": "https://openreview.net/pdf?id=6i609meSJw", "keywords": "bioinformatics, drug-target interaction, deep learning, tri-comparison expertise", "abstract": "Machine-learned interactions between drugs and human protein targets play a crucial role in efficient and accurate drug discovery. However, the drug-target interaction (DTI) mechanism prediction is actually a multi-class classification problem, which follows a long-tailed class distribution. Existing methods simply address whether interactions can occur and rarely consider the long-tailed DTI mechanism classes. In this paper, we introduce TED-DTI, a novel DTI prediction framework incorporating the divide-and-conquer strategy with tri-comparison options. Specifically, to reduce the learning difficulty of tail classes, we propose an expertise-based divide-and-conquer decision approach that combines the results of multiple independent expertise models for sub-tasks decomposed from the original prediction task. In addition, to enhance the discrimination of similar mechanism classes, we devise a tri-comparison learning strategy that defines the sub-task as the classification of triple options, such as expanding the classification task for classes A and B to include an extra \u201cNeither of them\u201d option. Extensive experiments conducted on various DTI mechanism datasets quantitatively demonstrate the proposed method achieves an approximately 14% performance improvement compared with the other state-of-the-art methods. Moreover, out method exhibits an obvious superiority on the tail classes. Further analysis about the evolvability and generalization of the proposed method reveals the significant potential to be deployed in real-world scenes. Our data and code is included in the Supplementary Materials and will be publicly released after the paper acceptance.", "title_embedding_index": 13010, "title_abs_embedding_index": 13035}, {"title": "AnyBimanual: Transferring Single-arm Policy for General Bimanual Manipulation", "link_suffix": "/forum?id=KLTqeiI7w0", "link": "https://openreview.net/forum?id=KLTqeiI7w0", "pdf_link": "https://openreview.net/pdf?id=KLTqeiI7w0", "keywords": "Multi-task Bimanual Manipulation, Skill Learning", "abstract": "Performing language-conditioned bimanual manipulation tasks is of great importance for many applications ranging from household service to industrial assembly. However, teleoperating dual-arm demonstrations is expensive due to the high-dimensional action space, which poses challenges for conventional methods to handle general bimanual manipulation tasks. In contrast, single-arm policy has recently demonstrated impressive generalizability across a wide range of tasks because of scaled model parameters and training data, which can provide sharable manipulation knowledge for dual-arm systems. To this end, we propose a plug-and-play method named AnyBimanual, which transfers pretrained single-arm policy to multi-task bimanual manipulation policy with limited bimanual demonstrations. Specifically, we first introduce a skill manager to dynamically schedule the discovered skill primitives from pretrained single-arm policy for bimanual manipulation tasks, which combines skill primitives with embodiment-specific compensation. To mitigate the observation discrepancy between single-arm and dual-arm systems, we present a voxel editor to generate spatial soft masks for visual embedding of the workspace, which aims to align visual input of single-arm policy model for each arm with those during pretraining stage. Extensive results on 13 simulated and real-world tasks indicate the superiority of AnyBimanual with an improvement of 12.67% on average success rate compared with previous state-of-the-art methods.", "title_embedding_index": 13011, "title_abs_embedding_index": 13036}, {"title": "SynQ: Accurate Zero-shot Quantization by Synthesis-aware Fine-tuning", "link_suffix": "/forum?id=2rnOgyFQgb", "link": "https://openreview.net/forum?id=2rnOgyFQgb", "pdf_link": "https://openreview.net/pdf?id=2rnOgyFQgb", "keywords": "Network Quantization, Zero-shot Quantization", "abstract": "How can we accurately quantize a pre-trained model without any data?\nQuantization algorithms are widely used for deploying neural networks on resource-constrained edge devices.\nZero-shot Quantization (ZSQ) addresses the crucial and practical scenario where training data are inaccessible for privacy or security reasons.\nHowever, three significant challenges hinder the performance of existing ZSQ methods: 1) noise in the synthetic dataset, 2) predictions based on off-target patterns, and the 3) misguidance by erroneous hard labels.\nIn this paper, we propose SynQ (Synthesis-aware Fine-tuning for Zero-shot Quantization),\na carefully designed ZSQ framework to overcome the limitations of existing methods.\nSynQ minimizes the noise from the generated samples by exploiting a low-pass filter.\nThen, SynQ trains the quantized model to improve accuracy by aligning its class activation map with the pre-trained model.\nFurthermore, SynQ mitigates misguidance from the pre-trained model's error by leveraging only soft labels for difficult samples.\nExtensive experiments show that SynQ provides the state-of-the-art accuracy, over existing ZSQ methods.", "title_embedding_index": 13012, "title_abs_embedding_index": 13037}, {"title": "Adaptive Continual Learning Through Proactive Detection of Transfer and Interference", "link_suffix": "/forum?id=6NPyh70Qkp", "link": "https://openreview.net/forum?id=6NPyh70Qkp", "pdf_link": "https://openreview.net/pdf?id=6NPyh70Qkp", "keywords": "Continual learning, lightweight finetuning", "abstract": "Continual learning (CL) requires models to sequentially learn multiple tasks, maximizing transfer and minimizing interference. CL methods based on pre-trained models (PTM) have shown strong performance by integrating PTM fine-tuning with traditional approaches. Despite these promising results, current methods lack the ability to proactively detect task transfer and interference at the local optimization level, limiting their effectiveness in maximizing transfer and minimizing interference. To address this issue, we propose adaptive continual learning strategies through proactive detection of transfer and interference. We derive the conditions under which task transfer and interference occur from a model optimization perspective, based on the Fisher matrix and gradient update directions. Based on them, we proposed a task transfer distance metric to help model modules detect transfer and interference during continual learning. We propose a dynamic parameter update mechanism and a dynamic expansion strategy, based on LoRA fine-tuning and a Mixture of Experts (MoE) mechanism, to handle varying levels of task transfer and interference. Experiments results of seven benchmarks show that our method achieves the best accuracy with a limited number of parameters, maximizing transfer and minimizing interference.", "title_embedding_index": 13013, "title_abs_embedding_index": 13038}, {"title": "Scalable do-Shapley Explanations with Estimand-Agnostic Causal Inference", "link_suffix": "/forum?id=lnMQGBHYRt", "link": "https://openreview.net/forum?id=lnMQGBHYRt", "pdf_link": "https://openreview.net/pdf?id=lnMQGBHYRt", "keywords": "Shapley, Explainability, Causality, Attribution, SCM, Modeling", "abstract": "Among explainability techniques, SHAP stands out as one of the most popular, but often overlooks the causal structure of the problem. While do-SHAP uses interventional causal queries, its reliance on estimands hinders scalability. To address this, we propose estimand-agnostic Causal Inference, which allows for the estimation of any identifiable query with a single model, making do-SHAP feasible on arbitrarily complex graphs. We also develop a novel algorithm to significantly accelerate its computation at a negligible cost with a marked improvement in computational speed, as well as a method to explain inaccessible Data Generating Processes. We validate our approach on two real-world datasets, highlighting its potential in obtaining reliable explanations.", "title_embedding_index": 13014, "title_abs_embedding_index": 13039}, {"title": "Tackling Decision Processes with Non-Cumulative Objectives using Reinforcement Learning", "link_suffix": "/forum?id=y9e1tcWlme", "link": "https://openreview.net/forum?id=y9e1tcWlme", "pdf_link": "https://openreview.net/pdf?id=y9e1tcWlme", "keywords": "reinforcement learning, markov decision processes, discrete optimization", "abstract": "Markov decision processes (MDPs) are used to model a wide variety of applications ranging from game playing over robotics to finance. Their optimal policy typically maximizes the expected sum of rewards given at each step of the decision process. However, a large class of problems does not fit straightforwardly into this framework: Non-cumulative Markov decision processes (NCMDPs), where instead of the expected sum of rewards, the expected value of an arbitrary function of the rewards is maximized. Example functions include the maximum of the rewards or their mean divided by their standard deviation. In this work, we introduce a general mapping of NCMDPs to standard MDPs. This allows all techniques developed to find optimal policies for MDPs, such as reinforcement learning or dynamic programming, to be directly applied to the larger class of NCMDPs. Focusing on reinforcement learning, we show applications in a diverse set of tasks, including classical control, portfolio optimization in finance, and discrete optimization problems. Given our approach, we can improve both final performance and training time compared to relying on standard MDPs.", "title_embedding_index": 13015, "title_abs_embedding_index": 13040}, {"title": "CollabEdit: Towards Non-destructive Collaborative Knowledge Editing", "link_suffix": "/forum?id=2PzozgigiA", "link": "https://openreview.net/forum?id=2PzozgigiA", "pdf_link": "https://openreview.net/pdf?id=2PzozgigiA", "keywords": "Collaborative Learning, Knowledge Editing", "abstract": "Collaborative learning of large language models (LLMs) has emerged as a\nnew paradigm for utilizing private data from different parties to guarantee\nef\ufb01ciency and privacy. Meanwhile, Knowledge Editing (KE) for LLMs has also\ngarnered increased attention due to its ability to manipulate the behaviors of\nLLMs explicitly, yet leaves the collaborative KE case\u2014in which knowledge\nedits of multiple parties are aggregated in a privacy-preserving and continual\nmanner\u2014unexamined. To this end, this manuscript dives into the \ufb01rst investigation\n of collaborative KE, in which we start by carefully identifying the unique\nthree challenges therein, including knowledge overlap, knowledge con\ufb02ict, and\nknowledge forgetting. We then propose a non-destructive collaborative KE\nframework, COLLABEDIT, which employs a novel model merging mechanism\nto mimic the global KE behavior while preventing the severe performance drop.\nExtensive experiments on two canonical datasets demonstrate the superiority of\nCOLLABEDIT compared to other destructive baselines, and results shed light on\naddressing three collaborative KE challenges and future applications.", "title_embedding_index": 13016, "title_abs_embedding_index": 13041}, {"title": "BNEM: A Boltzmann Sampler Based on Bootstrapped Noised Energy Matching", "link_suffix": "/forum?id=ybWOYIuFl6", "link": "https://openreview.net/forum?id=ybWOYIuFl6", "pdf_link": "https://openreview.net/pdf?id=ybWOYIuFl6", "keywords": "neural sampler, Boltzmann distribution, diffusion model", "abstract": "Generating independent samples from a Boltzmann distribution is a highly relevant problem in scientific research, e.g. in molecular dynamics, where one has initial access to the underlying energy function but not to samples from the  Boltzmann distribution. We address this problem by learning the energies of the convolution of the Boltzmann distribution with Gaussian noise.  These energies are then used to generate independent samples through a denoising diffusion approach. The resulting method, Noised Energy Matching (NEM), has lower variance and only slightly higher cost than previous related works. We also improve NEM through a novel bootstrapping technique called Bootstrap NEM (BNEM) that further reduces variance while only slightly increasing bias. Experiments on a collection of problems demonstrate that NEM can outperform previous methods while being more robust and that BNEM further improves on NEM.", "title_embedding_index": 13017, "title_abs_embedding_index": 13042}, {"title": "RuAG: Learned-rule-augmented Generation for Large Language Models", "link_suffix": "/forum?id=BpIbnXWfhL", "link": "https://openreview.net/forum?id=BpIbnXWfhL", "pdf_link": "https://openreview.net/pdf?id=BpIbnXWfhL", "keywords": "Large language model, Logic Rule Learning, Monte Carlo Tree Search", "abstract": "In-context learning (ICL) and Retrieval-Augmented Generation (RAG) have gained attention for their ability to enhance LLMs' reasoning by incorporating external knowledge but suffer from limited contextual window size, leading to insufficient information injection. To this end, we propose a novel framework to automatically distill large volumes of offline data into interpretable first-order logic rules, which are injected into LLMs to boost their reasoning capabilities. Our method begins by formulating the search process relying on LLMs' commonsense, where LLMs automatically define head and body predicates. Then, we apply Monte Carlo Tree Search (MCTS)  to address the combinational searching space and efficiently discover logic rules from data. The resulting logic rules are translated into natural language, allowing targeted knowledge injection and seamless integration into LLM prompts for LLM's downstream task reasoning. We evaluate our framework on public and private industrial tasks, including Natural Language Processing (NLP), time-series, decision-making, and industrial tasks, demonstrating its effectiveness in enhancing LLM's capability over diverse tasks.", "title_embedding_index": 13018, "title_abs_embedding_index": 13043}, {"title": "DISCO: Efficient Diffusion Solver for Large-Scale Combinatorial Optimization Problems", "link_suffix": "/forum?id=6JDpWJrjyK", "link": "https://openreview.net/forum?id=6JDpWJrjyK", "pdf_link": "https://openreview.net/pdf?id=6JDpWJrjyK", "keywords": "combinatorial optimization, diffusion models", "abstract": "Combinatorial Optimization (CO) problems are fundamentally important in numerous real-world applications across diverse industries, characterized by entailing enormous solution space and demanding time-sensitive response. Despite recent advancements in neural solvers, their limited expressiveness struggles to capture the multi-modal nature of CO landscapes. While some research has shifted towards diffusion models, these models still sample solutions indiscriminately from the entire NP-complete solution space with time-consuming denoising processes, which limit their practicality for large problem scales. We proposeDISCO, an efficientDIffusionSolver for large-scaleCombinatorialOptimization problems that excels in both solution quality and inference speed. DISCO\u2019s efficacy is twofold: First, it enhances solution quality by constraining the sampling space to a more meaningful domain guided by solution residues, while preserving the multi-modal properties of the output distributions. Second, it accelerates the denoising process through an analytically solvable approach, enabling solution sampling with minimal reverse-time steps and significantly reducing inference time. DISCO delivers strong performance on large-scale Traveling Salesman Problems and challenging Maximal Independent Set benchmarks, with inference time up to $5.28$ times faster than other diffusion alternatives. By incorporating a divide-and-conquer strategy, DISCO can well generalize to solve unseen-scale problem instances, even surpassing models specifically trained for those scales.", "title_embedding_index": 13019, "title_abs_embedding_index": 13044}, {"title": "Reveal Object in Lensless Photography via Region Gaze and Amplification", "link_suffix": "/forum?id=EV7FMBZxnx", "link": "https://openreview.net/forum?id=EV7FMBZxnx", "pdf_link": "https://openreview.net/pdf?id=EV7FMBZxnx", "keywords": "Lensless Imaging; Computational Imaging; Region Gaze; Region Amplifier;  Concealed Object Detection", "abstract": "Detecting concealed objects, such as in vivo lesions or camouflage, requires customized imaging systems. Lensless cameras, being compact and flexible, offer a promising alternative to bulky lens systems. However, the absence of lenses leads to measurements lacking visual semantics, posing significant challenges for concealed object detection (COD). To tackle this issue, we propose a region gaze-amplification network (RGANet) for progressively exploiting concealed objects from lensless imaging measurements. Specifically, a region gaze module (RGM) is proposed to mine spatial-frequency cues informed by biological and psychological mechanisms, and a region amplifier (RA) is designed to amplify the details of object regions to enhance COD performance. Furthermore, we contribute the first relevant dataset as a benchmark to prosper the lensless imaging community. Extensive experiments demonstrate the exciting performance of our method.", "title_embedding_index": 13020, "title_abs_embedding_index": 13045}, {"title": "Permutation-based Rank Test in the Presence of Discretization and Application in Causal Discovery with Mixed Data", "link_suffix": "/forum?id=KwaNnvj0b3", "link": "https://openreview.net/forum?id=KwaNnvj0b3", "pdf_link": "https://openreview.net/pdf?id=KwaNnvj0b3", "keywords": "Rank Test; Discretization; Causal Discovery", "abstract": "Recent advances have shown that statistical tests for the rank of cross-covariance matrices play an important role in causal discovery. These rank tests include partial correlation tests as special cases and provide further graphical information about latent variables.\n   Existing rank tests typically assume that all the continuous variables can be perfectly measured,\n   and yet, in practice many variables can only be measured after discretization.\n   For example, in psychometric studies,\n    the continuous level of certain personality dimensions of a person can only be measured after being discretized into order-preserving options such as disagree, neutral, and agree.\n   Motivated by this, we\npropose Mixed data Permutation-based Rank Test (MPRT), which properly controls the statistical errors even when some or all variables are discretized.\nTheoretically, we establish the \nexchangeability and \nestimate the asymptotic null distribution by  permutations;\nas a consequence,\nMPRT can effectively control the Type I error in the presence of discretization while previous methods cannot. \nEmpirically, our method is validated by extensive experiments on synthetic data \nand real-world data to demonstrate its effectiveness as well as applicability in causal discovery.", "title_embedding_index": 13021, "title_abs_embedding_index": 13046}, {"title": "Boosting Deductive Reasoning with Step Signals In RLHF", "link_suffix": "/forum?id=F9iHSa1Iz5", "link": "https://openreview.net/forum?id=F9iHSa1Iz5", "pdf_link": "https://openreview.net/pdf?id=F9iHSa1Iz5", "keywords": "LLM, RLHF, reasoning", "abstract": "Logical reasoning is a crucial task for Large Language Models (LLMs), enabling them to tackle complex problems. Among reasoning tasks, multi-step reasoning poses a particular challenge. Grounded in the theory of formal logic, we have developed an automated method, Multi-step Deduction (MuseD), for deductive reasoning data. MuseD has allowed us to create training and testing datasets for multi-step reasoning. Our generation method enables control over the complexity of the generated instructions, facilitating training and evaluation of models across different difficulty levels. Through RLHF training, our training data has demonstrated significant improvements in logical capabilities for both in-domain of out-of-domain reasoning tasks. Additionally, we have conducted tests to assess the multi-step reasoning abilities of various models.", "title_embedding_index": 13022, "title_abs_embedding_index": 13047}, {"title": "Learning Video-Conditioned Policy on Unlabelled Data with Joint Embedding Predictive Transformer", "link_suffix": "/forum?id=TqM0hifngW", "link": "https://openreview.net/forum?id=TqM0hifngW", "pdf_link": "https://openreview.net/pdf?id=TqM0hifngW", "keywords": "Learning from Videos, Video-Conditioned Policy", "abstract": "The video-conditioned policy takes prompt videos of the desired tasks as a condition and is regarded for its prospective generalizability. Despite its promise, training a video-conditioned policy is non-trivial due to the need for abundant demonstrations. In some tasks, the expert rollouts are merely available as videos, and costly and time-consuming efforts are required to annotate action labels. To address this, we explore training video-conditioned policy on a mixture of expert demonstrations and unlabeled expert videos to reduce reliance on extensive manually annotated data. We introduce the Joint Embedding Predictive Transformer (JEPT) to learn a video-conditioned policy through sequence modeling. JEPT is designed to jointly learn visual transition prediction and inverse dynamics. The visual transition is captured from both demonstrations and expert videos, on the basis of which the inverse dynamics learned from demonstrations is generalizable to the tasks without action labels. We conduct experiments on a series of simulated visual control tasks and evaluate that JEPT can effectively leverage the mixture dataset to learn a generalizable policy. JEPT outperforms baselines in the tasks without action-labeled data and unseen tasks. We also experimentally reveal the potential of JEPT as a simple visual priors injection approach to enhance the video-conditioned policy.", "title_embedding_index": 13023, "title_abs_embedding_index": 13048}, {"title": "FDTDNet: Privacy-Preserving Lensless Object Segmentation via Feature Demultiplexing and Task Decoupling", "link_suffix": "/forum?id=3WqfSoxLIh", "link": "https://openreview.net/forum?id=3WqfSoxLIh", "pdf_link": "https://openreview.net/pdf?id=3WqfSoxLIh", "keywords": "Lensless Object Segmentation; Lensless Imaging; Privacy-Preserving; Feature Demultiplexing; Task Decoupling", "abstract": "Camera-based vision systems pose privacy risks, whereas lensless cameras present a viable alternative by omitting visual semantics from their measurements due to the absence of lenses. However, these captured lensless measurements pose challenges for existing computer vision tasks such as object segmentation that usually require visual input. To address this problem, we propose a lensless object segmentation network via feature demultiplexing and task decoupling (FDTDNet) to perform object segmentation for lensless measurements. Specifically, we propose an optical-aware feature demultiplexing mechanism to get meaningful features from lensless measurements without visual reconstruction and design a multi-task learning framework decoupling the lensless object segmentation task into two subtasks, i.e., the reason for contour distribution maps (CDM) and body distribution maps (BDM), respectively. Extensive experiments demonstrate that our FDTDNet achieves highly accurate segmentation effect, which sheds light on privacy-preserving high-level vision with compact lensless cameras.", "title_embedding_index": 13024, "title_abs_embedding_index": 13049}]
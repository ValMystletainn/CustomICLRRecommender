[
    {
        "title": "ContraFusion: Contrastively Improving Compositional Understanding in Diffusion Models via Fine-Grained Negative Images",
        "link_suffix": "/forum?id=S85PP4xjFD",
        "link": "https://openreview.net/forum?id=S85PP4xjFD",
        "pdf_link": "https://openreview.net/pdf?id=S85PP4xjFD",
        "keywords": "compositional text-to-image generation, contrastive learning, compositional understanding",
        "abstract": "Despite the impressive text-to-image (T2I) synthesis capabilities of diffusion models, they often struggle to understand compositional relationships between objects and attributes, especially in complex settings. Existing solutions have tackled these challenges through optimizing the cross-attention mechanism or learning from the caption pairs with minimal semantic changes. However, can we generate high-quality complex contrastive images that diffusion models can directly discriminate based on visual representations? In this work, we leverage large-language models (LLMs) to compose realistic, complex scenarios and harness Visual-Question Answering (VQA) systems alongside diffusion models to automatically curate a contrastive dataset, COM-DIFF, consisting of 15k pairs of high-quality contrastive images. These pairs feature minimal visual discrepancies and cover a wide range of attribute categories, especially complex and natural scenarios. To learn effectively from these error cases, i.e., hard negative images, we propose CONTRAFUSION, a new multi-stage curriculum for contrastive learning of diffusion models. Through extensive experiments across a wide range of compositional scenarios, we showcase the effectiveness of our proposed framework on compositional T2I benchmarks. We will release our contrastive dataset to support the development of generative models."
    },
    {
        "title": "Rethinking Invariance in In-context Learning",
        "link_suffix": "/forum?id=q1UyoY3MgJ",
        "link": "https://openreview.net/forum?id=q1UyoY3MgJ",
        "pdf_link": "https://openreview.net/pdf?id=q1UyoY3MgJ",
        "keywords": "In-context Learning, Permuation Invariance",
        "abstract": "In-Context Learning (ICL) has emerged as a pivotal capability of auto-regressive large language models, yet it is hindered by a notable sensitivity to the ordering of context examples regardless of their mutual independence. To address this issue, recent studies have introduced several variant algorithms of ICL that achieve permutation invariance. However, many of these do not exhibit comparable performance with the standard auto-regressive ICL algorithm. In this work, we identify two crucial elements in the design of an invariant ICL algorithm: information non-leakage and context interdependence, which are not simultaneously achieved by any of the existing methods. These investigations lead us to the proposed \\emph{Invariant ICL (InvICL)}, a methodology designed to achieve invariance in ICL while ensuring the two properties. Theoretically, we prove that InvICL approximates standard gradient descent, which possess the best convergence properties among all the gradient descent variants of existing ICL algorithms. Empirically, our findings reveal that InvICL surpasses previous models, both invariant and non-invariant, in most benchmark datasets, showcasing superior generalization capabilities across varying input lengths."
    },
    {
        "title": "Proteina: Scaling Flow-based Protein Structure Generative Models",
        "link_suffix": "/forum?id=TVQLu34bdw",
        "link": "https://openreview.net/forum?id=TVQLu34bdw",
        "pdf_link": "https://openreview.net/pdf?id=TVQLu34bdw",
        "keywords": "protein structure generation, de novo protein design, flow matching, fold class conditioning",
        "abstract": "Recently, diffusion- and flow-based generative models of protein structures have emerged as a powerful tool for de novo protein design. Here, we develop Proteina, a new large-scale flow-based protein backbone generator that utilizes hierarchical fold class labels for conditioning and relies on a tailored scalable transformer architecture with up to $5\\times$ as many parameters as previous models. To meaningfully quantify performance, we introduce a new set of metrics that directly measure the distributional similarity of generated proteins with reference sets, complementing existing metrics. We further explore scaling training data to millions of synthetic protein structures and explore improved training and sampling recipes adapted to protein backbone generation. This includes fine-tuning strategies like LoRA for protein backbones, new guidance methods like classifier-free guidance and autoguidance for protein backbones, and new adjusted training objectives. Proteina achieves state-of-the-art performance on de novo protein backbone design and produces diverse and designable proteins at unprecedented length, up to 800 residues. The hierarchical conditioning offers novel control, enabling high-level secondary-structure guidance as well as low-level fold-specific generation."
    },
    {
        "title": "FlashMask: Efficient and Rich Mask Extension of FlashAttention",
        "link_suffix": "/forum?id=wUtXB43Chi",
        "link": "https://openreview.net/forum?id=wUtXB43Chi",
        "pdf_link": "https://openreview.net/pdf?id=wUtXB43Chi",
        "keywords": "Attention Mask Efficient Representation, Efficient Attention Computation, Long context, IO complexity, GPUs, LLMs",
        "abstract": "The computational and memory demands of vanilla attention scale quadratically with the sequence length $N$, posing significant challenges for processing long sequences in Transformer models. FlashAttention alleviates these challenges by eliminating the $O(N^2)$ memory dependency and reducing attention latency through IO-aware memory optimizations. However, its native support for certain attention mask types is limited, and it does not inherently accommodate more complex masking requirements. Previous approaches resort to using dense masks with $O(N^2)$ memory complexity, leading to inefficiencies. In this paper, we propose FlashMask, an extension of FlashAttention that introduces a column-wise sparse representation of attention masks. This approach efficiently represents a wide range of mask types and facilitates the development of optimized kernel implementations. By adopting this novel representation, FlashMask achieves linear memory complexity $O(N)$, making it suitable for modeling long-context sequences. Moreover, this representation enables kernel optimizations that eliminate unnecessary computations by leveraging sparsity in the attention mask, without sacrificing computational accuracy, resulting in higher computational efficiency. We evaluate FlashMask's performance in fine-tuning and alignment training of LLMs such as SFT, LoRA, DPO, and RM. FlashMask achieves significant throughput improvements, with end-to-end speedups ranging from 1.65x to 3.22x compared to existing FlashAttention dense method. Additionally, our kernel-level comparisons demonstrate that FlashMask surpasses the latest counterpart, FlexAttention, by 12.1% to 60.7% in kernel TFLOPs/s, achieving 37.8% to 62.3% of the theoretical maximum FLOPs/s on the A100 GPU. Our experiments highlight FlashMask's versatility and robustness across various mask and attention patterns. These results underscore its effectiveness in practical applications, including deployment in LLMs with over 100 billion parameters, efficiently handling contexts up to 128K tokens. The implementation is open-sourced and integrated into the PaddlePaddle framework."
    },
    {
        "title": "Verified Relative Output Margins for Neural Network Twins",
        "link_suffix": "/forum?id=0NEjIZlEhP",
        "link": "https://openreview.net/forum?id=0NEjIZlEhP",
        "pdf_link": "https://openreview.net/pdf?id=0NEjIZlEhP",
        "keywords": "Relative Output Margin, Formal Verification, Deep Neural Networks",
        "abstract": "Given two neural network classifiers with the same input and output domains, our goal is to compare the two networks in relation to each other over an entire input region (e.g., within a vicinity of an input sample). Towards this, we introduce and quantify the Relative Output Margin (ROM) with which decisions are made. A larger output margin for a network w.r.t. another indicates that this network consistently makes a correct decision every time the other network does, and it does so in the entire input region. More importantly, as opposed to best-effort testing schemes, our framework is able to establish provably-correct (formally verified) bounds on ROM gains/losses over an entire input region. The proposed framework is relevant in the context of several application domains, e.g., for comparing a trained network and its corresponding compact (e.g., pruned, quantized, distilled) network. We evaluate our framework using the MNIST, CIFAR10, and two real-world medical datasets, to show its relevance."
    },
    {
        "title": "Jointly Optimizing Wirelength and Thermal Fields for Chip Placement",
        "link_suffix": "/forum?id=dnU9bGgSZ5",
        "link": "https://openreview.net/forum?id=dnU9bGgSZ5",
        "pdf_link": "https://openreview.net/pdf?id=dnU9bGgSZ5",
        "keywords": "Reinforcement Learning, Chip Design, Thermal Placement",
        "abstract": "Macro placement is a crucial and complex issue in chip design. In recent studies, reinforcement learning (RL) has demonstrated outstanding performance in optimizing chip wirelength, but this leads to thermally inefficient design. Additionally, due to the specialized expertise necessary for creating chip benchmarks and the constraints imposed by confidentiality agreements, there exists a scarcity of publicly available chip thermal placement benchmarks. This work introduces a reinforcement learning-based thermal placement model that can optimize both wirelength and peak temperatures. We also strictly followed the chip design process and established a macro thermal placement benchmark. This significantly reduces the entry barriers for researchers, facilitating benchmarking and result replication. Compared to other models, our model notably diminishes the chip's peak temperature of the chip while slightly extending wirelength, thereby improving the chip's  heat dissipation efficiency."
    },
    {
        "title": "DFL2G: Dynamic Agnostic Federated Learning with Learngene",
        "link_suffix": "/forum?id=3l9NRfezlo",
        "link": "https://openreview.net/forum?id=3l9NRfezlo",
        "pdf_link": "https://openreview.net/pdf?id=3l9NRfezlo",
        "keywords": "Federated Learning, Low-cost Communication, Learngene",
        "abstract": "Dynamic agnostic federated learning is a promising research field where agnostic clients can join the federated system at any time to collaboratively construct machine learning models. The critical challenge is to securely and effectively initializing the models for these agnostic clients, as well as the communication overhead with the server when participating in the training process. Recent research usually utilizes optimized global model for initialization, which can lead to privacy leakage of the training data.\nTo overcome these challenges, inspired by the recently proposed Learngene paradigm, which involves compressing a large-scale ancestral model into meta-information pieces that can initialize various descendant task models, we propose a \\textbf{D}ynamic agnostic \\textbf{F}ederated \\textbf{L}earning with \\textbf{L}earn\\textbf{G}ene framework. The local model achieves smooth updates based on the Fisher information matrix and accumulates general inheritable knowledge through collaborative training. We employ sensitivity analysis of task model gradients to locate meta-information (referred to as \\textit{learngene}) within the model, ensuring robustness across various tasks. Subsequently, these well-trained \\textit{learngenes} are inherited by various agnostic clients for model initialization and interaction with the server. Comprehensive experiments demonstrate the effectiveness of the proposed approach in achieving low-cost communication, robust privacy protection, and effective initialization of models for agnostic clients."
    },
    {
        "title": "Understanding Prejudice and Fidelity of Diverge-to-Converge Multi-Agent Systems",
        "link_suffix": "/forum?id=EP6n8LCEK6",
        "link": "https://openreview.net/forum?id=EP6n8LCEK6",
        "pdf_link": "https://openreview.net/pdf?id=EP6n8LCEK6",
        "keywords": "Large language model agents, Multi-Agent System, Benchmark",
        "abstract": "Large language model (LLM) agents have demonstrated substantial potential across various tasks, particularly in multi-agent systems. Among these, \\textit{Diverge-to-Converge} (D2C) frameworks stand out for their ability to iteratively diversify and converge intermediate thoughts to improve problem-solving. In this paper, we conduct a comprehensive study on the \\textit{\\textbf{prejudice}} and \\textit{\\textbf{fidelity}} of typical D2C frameworks, including both model-level and society-level frameworks. \n\\ding{182} In the \\textit{prejudice} section, we uncover an inherent \\textit{confirmation bias} in D2C systems, which not only leads to suboptimal performance, but also amplifies social biases, such as gender discrimination and political partisanship. Surprisingly, we find that by reframing open-ended problems into binary questions, this bias can be leveraged to foster more equitable and effective agent interactions, ultimately improving performance.\n\\ding{183} In the \\textit{fidelity} section, we explore the scaling laws of D2C frameworks at different granularities, revealing that increasing the number of agents enhances performance only when the system is not yet saturated---such as in complex tasks or with weaker agents. In saturated scenarios, however, adding more agents can degrade performance. \nTo facilitate further study, we develop \\texttt{APF-Bench}, a benchmark specifically designed to evaluate such inherent weaknesses of D2C frameworks. \nWe hope our findings offer instructional insights into the strengths and limitations of D2C multi-agent systems, offering guidance for developing more robust and effective collaborative AI systems."
    },
    {
        "title": "You Only Sample Once: Taming One-Step Text-to-Image Synthesis by Self-Cooperative Diffusion GANs",
        "link_suffix": "/forum?id=T7bmHkwzS6",
        "link": "https://openreview.net/forum?id=T7bmHkwzS6",
        "pdf_link": "https://openreview.net/pdf?id=T7bmHkwzS6",
        "keywords": "One-step text-to-image generation; Diffusion Models; Generative Adversarial Networks",
        "abstract": "Recently, some works have tried to combine diffusion and Generative Adversarial Networks (GANs) to alleviate the computational cost of the iterative denoising inference in Diffusion Models (DMs). \nHowever, existing works in this line suffer from either training instability and mode collapse or subpar one-step generation learning efficiency. \nTo address these issues, we introduce YOSO, a novel generative model designed for rapid, scalable, and high-fidelity one-step image synthesis with high training stability and mode coverage. \nSpecifically, we smooth the adversarial divergence by the denoising generator itself, performing self-cooperative learning. We show that our method can serve as a one-step generation model training from scratch with competitive performance. \nMoreover, we extend our YOSO to one-step text-to-image generation based on pre-trained models by several effective training techniques (i.e., latent perceptual loss and latent discriminator for efficient training along with the latent DMs; the informative prior initialization (IPI), and the quick adaption stage for fixing the flawed noise scheduler). Experimental results show that YOSO achieves the state-of-the-art one-step generation performance even with Low-Rank Adaptation (LoRA) fine-tuning.\nIn particular, we show that the YOSO-PixArt-$\\alpha$ can generate images in one step trained on 512 resolution, with the capability of adapting to 1024 resolution without extra explicit training, requiring only \\textasciitilde10 A800 days for fine-tuning."
    },
    {
        "title": "On Quantizing Neural Representation for Variable-Rate Video Coding",
        "link_suffix": "/forum?id=44cMlQSreK",
        "link": "https://openreview.net/forum?id=44cMlQSreK",
        "pdf_link": "https://openreview.net/pdf?id=44cMlQSreK",
        "keywords": "Variable Rate, Video Coding, Quantization, Neural Representation",
        "abstract": "This work introduces NeuroQuant, a novel post-training quantization (PTQ) approach tailored to non-generalized Implicit Neural Representations for variable-rate Video Coding (INR-VC). Unlike existing methods that require extensive weight retraining for each target bitrate, we hypothesize that variable-rate coding can be achieved by adjusting quantization parameters (QPs) of pre-trained weights. Our study reveals that traditional quantization methods, which assume inter-layer independence, are ineffective for non-generalized INR-VC models due to significant dependencies across layers. To address this, we redefine variable-rate INR-VC as a mixed-precision quantization problem and establish a theoretical framework for sensitivity criteria aimed at simplified, fine-grained rate control. Additionally, we propose network-wise calibration and channel-wise quantization strategies to minimize quantization-induced errors, arriving at a unified formula for representation-oriented PTQ calibration. Our experimental evaluations demonstrate that NeuroQuant significantly outperforms existing techniques in varying bitwidth quantization and compression efficiency, accelerating encoding by up to eight times and enabling quantization down to INT2 with minimal reconstruction loss. This work introduces variable-rate INR-VC for the first time and lays a theoretical foundation for future research in rate-distortion optimization, advancing the field of video coding technology."
    },
    {
        "title": "One Initialization to Rule them All: Fine-tuning via Explained Variance Adaptation",
        "link_suffix": "/forum?id=DM6Q45HWSk",
        "link": "https://openreview.net/forum?id=DM6Q45HWSk",
        "pdf_link": "https://openreview.net/pdf?id=DM6Q45HWSk",
        "keywords": "Foundation Models, LoRA, Fine-tuning",
        "abstract": "Foundation models (FMs) are pre-trained on large-scale datasets and then fine-tuned on a downstream task for a specific application. The most successful and most commonly used fine-tuning method is to modulate the pre-trained weights via a low-rank adaptation (LoRA). LoRA introduces new weight matrices that are usually initialized at random with a uniform rank distribution across the model. Recent works focus onweight-driveninitialization or learning of an adaptive rank allocation during training. Both approaches have only been investigated in isolation, resulting in slow convergence or a uniform rank distribution, leading to sub-optimal performance. We propose to enhance LoRA by initializing the new weights in adata-drivenmanner by computing singular value decomposition on minibatches of activation vectors. Then, we initialize the LoRA matrices with the obtained right-singular vectors and re-distribute ranks among all weight matrices to explain the maximal amount of variance across layers and continue the standard LoRA fine-tuning procedure. This results in our new methodExplainedVarianceAdaptation (EVA). We apply EVA to a variety of fine-tuning tasks ranging from language generation and understanding to image classification and reinforcement learning. EVA exhibits faster convergence than competitors and attains the highest average score across a multitude of tasks per domain."
    },
    {
        "title": "Generalizing Weisfeiler-Lehman Kernels to Subgraphs",
        "link_suffix": "/forum?id=HZgZrtIreg",
        "link": "https://openreview.net/forum?id=HZgZrtIreg",
        "pdf_link": "https://openreview.net/pdf?id=HZgZrtIreg",
        "keywords": "Graph Kernels, Subgraphs",
        "abstract": "Subgraph representation learning has been effective in solving various real-world problems. However, current graph neural networks (GNNs) produce suboptimal results for subgraph-level tasks due to their inability to capture complex interactions within and between subgraphs. To provide a more expressive and efficient alternative, we propose WLKS, a Weisfeiler-Lehman (WL) kernel generalized for subgraphs by applying the WL algorithm on induced k-hop neighborhoods. We combine kernels across different k-hop levels to capture richer structural information that is not fully encoded in existing models. Our approach can balance expressiveness and efficiency by eliminating the need for neighborhood sampling. In experiments on eight real-world and synthetic benchmarks, WLKS significantly outperforms leading approaches on five datasets while reducing training time, ranging from 0.01x to 0.53x compared to the state-of-the-art."
    },
    {
        "title": "EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels",
        "link_suffix": "/forum?id=ejVuTFFkl6",
        "link": "https://openreview.net/forum?id=ejVuTFFkl6",
        "pdf_link": "https://openreview.net/pdf?id=ejVuTFFkl6",
        "keywords": "EEG, visual stimuli, computer vision, multi-modality, object classification, image generation",
        "abstract": "Exploring how brain activity translates into visual perception offers valuable insights into the biological visual system's representation of the world. Recent advancements have enabled effective image classification and high-quality reconstruction using brain signals obtained through Functional Magnetic Resonance Imaging (fMRI) or magnetoencephalography (MEG). However, the cost and bulkiness of these technologies hinder their practical application. In contrast, Electroencephalography (EEG) presents advantages such as ease of use, affordability, high temporal resolution, and non-invasive operation, yet it remains underutilized in related research due to a shortage of comprehensive datasets. To fill this gap, we introduce EEG-ImageNet, a novel EEG dataset featuring recordings from 16 participants exposed to 4000 images sourced from the ImageNet dataset. This dataset offers five times the number of EEG-image pairs compared to existing benchmarks. EEG-ImageNet includes image stimuli labeled with varying levels of granularity, comprising 40 images with coarse labels and 40 with fine labels. We establish benchmarks for both object classification and image reconstruction based on this dataset. Experiments with several commonly used models show that the best-performing models can achieve object classification with an accuracy around 60% and image reconstruction with two-way identification around 64%. These findings highlight the dataset's potential to enhance EEG-based visual brain-computer interfaces, deepen our understanding of visual perception in biological systems, and suggest promising applications for improving machine vision models."
    },
    {
        "title": "Rainbow Generator: Generating Diverse Data for Name Only Continual Learning",
        "link_suffix": "/forum?id=Lo98rDyfl8",
        "link": "https://openreview.net/forum?id=Lo98rDyfl8",
        "pdf_link": "https://openreview.net/pdf?id=Lo98rDyfl8",
        "keywords": "continual learning, generative model",
        "abstract": "Requiring extensive human supervision is often impractical for continual learning due to its cost, leading to the emergence of \u2018name-only continual learning\u2019 that only provides the name of new concepts (e.g., classes) without providing supervised samples. To address the task, recent approach uses web-scraped data but results in issues such as data imbalance, copyright, and privacy concerns. To overcome the limitations of both human supervision and webly supervision, we propose Generative name only Continual Learning (GenCL) using generative models for the name only continual learning. But na\u00efve application of generative models results in limited diversity of generated data. So, we specifically propose a diverse prompt generation method, HIerarchical Recurrent Prompt Generation (HIRPG) as well as COmplexity-NAvigating eNsembler (CONAN) that selects samples with minimal overlap from multiple generative models. We empirically validate that the proposed GenCL outperforms prior arts, even a model trained with fully supervised data, in various tasks including image recognition and multi-modal visual reasoning. Data generated by GenCL is available athttps://anonymous.4open.science/r/name-only-continual-E079."
    },
    {
        "title": "SciPIP: An LLM-based Scientific Paper Idea Proposer",
        "link_suffix": "/forum?id=RiQRUcjXBD",
        "link": "https://openreview.net/forum?id=RiQRUcjXBD",
        "pdf_link": "https://openreview.net/pdf?id=RiQRUcjXBD",
        "keywords": "Large Language Models, Idea Proposer",
        "abstract": "The exponential growth of knowledge and the increasing complexity of interdisciplinary research pose significant challenges for researchers, including information overload and difficulties in exploring novel ideas. The advancements in large language models (LLMs), such as GPT-4, have shown great potential in enhancing idea proposals, but how to effectively utilize large models for reasonable idea proposal has not been thoroughly explored.\nThis paper proposes a scientific paper idea proposer (SciPIP). Based on a user-provided research background, SciPIP retrieves helpful papers from a literature database while leveraging the capabilities of LLMs to generate more novel and feasible ideas.\nTo this end, \\textbf{1)} we construct a literature retrieval database, extracting lots of papers' multi-dimension information for fast access. Then, a literature retrieval method based on semantics, entity, and citation co-occurrences is proposed to search relevant literature from multiple aspects based on the user-provided background. \\textbf{2)} After literature retrieval, we introduce dual-path idea proposal strategies, where one path infers solutions from the retrieved literature and the other path generates original ideas through model brainstorming. We then combine the two to achieve a good balance between feasibility and originality. Through extensive experiments on the natural language processing (NLP) field, we demonstrate that SciPIP can retrieve citations similar to those of existing top conference papers and generate many ideas consistent with them. Additionally, we evaluate the originality of other ideas generated by SciPIP using large language models, further validating the effectiveness of our proposed method"
    },
    {
        "title": "GOOD: Decoding-Time Black-Box LLM Alignment",
        "link_suffix": "/forum?id=cayKVPCrOP",
        "link": "https://openreview.net/forum?id=cayKVPCrOP",
        "pdf_link": "https://openreview.net/pdf?id=cayKVPCrOP",
        "keywords": "Large language models, Alignment, Black-Box",
        "abstract": "Large Language Models (LLMs) have demonstrated immense potential across various applications. However, aligning these models with specific real-world tasks and human preferences typically requires resource-intensive fine-tuning processes such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF).\nIn this paper, we propose GOOD (Guided Online Optimal Decoding), a novel alignment method that enhances pre-trained models without the need for parameter fine-tuning. We observed that the alignment-related behavior of one model can be used to guide another model, and based on this insight, we proposed the GOOD method. Utilizing a pair of guiding models, GOOD identifies critical positions related to alignment and adjusts the model\u2019s output dynamically during the response generation. Notably, the interaction between the guiding models and the guided model occurs at the string level, enabling GOOD to be applied to align even black-box models.\nExperiments show that GOOD can achieve performance comparable to or even surpassing direct fine-tuning in terms of comprehensive capability and harmless generation, reaching relative scores of 108% and 105% respectively. Even in weak-to-strong alignment, it can recover up to 94% of the performance of directly fine-tuned models. GOOD can also be applied to enhance already aligned models (improving pass@1 by 52% in code enhancement), making it compatible with various existing alignment techniques."
    },
    {
        "title": "Accelerating semidefinite programming beyond limit: ADMM with tune-free operator stepsize",
        "link_suffix": "/forum?id=UmMZC62SzZ",
        "link": "https://openreview.net/forum?id=UmMZC62SzZ",
        "pdf_link": "https://openreview.net/pdf?id=UmMZC62SzZ",
        "keywords": "semidefinite programming, scalability, alternating direction method of multipliers, tune-free operator stepsize",
        "abstract": "In this work, we significantly alleviate the long-standing scalability issue of semidefinite programming (SDP), by equipping a novel tune-free operator stepsize to the alternating direction method of multipliers (ADMM) optimizer. To our best knowledge, this is the first operator stepsize in the context of SDP. More importantly, it is tune-free and computationally cheap (defined on dot product). Preliminary tests show that our operator ADMM surpasses the acceleration limit of the standard scalar version (limit found via grid search), i.e., our operator stepsize can outperform an arbitrarily fine tuned scalar one."
    },
    {
        "title": "LLM-Exp: Exploring the Policy in Reinforcement Learning with Large Language Models",
        "link_suffix": "/forum?id=lHuLMmz3PY",
        "link": "https://openreview.net/forum?id=lHuLMmz3PY",
        "pdf_link": "https://openreview.net/pdf?id=lHuLMmz3PY",
        "keywords": "Reinforcement learning, large language model, policy exploration",
        "abstract": "Policy exploration is critical in training reinforcement learning (RL) agents, where existing approaches include the $\\epsilon$-greedy method in deep Q-learning, the Gaussian process in DDPG, etc.\nHowever, all these approaches are designed based on prefixed stochastic processes and are indiscriminately applied in all kinds of RL tasks without considering any environment-specific features that influence the policy exploration.\nMoreover, during the training process, the evolution of such stochastic process is rigid, which typically only incorporates a decay of the variance.\nThis makes the policy exploration unable to adjust flexibly according to the agent's real-time learning status, limiting the performance.\nInspired by the analyzing and reasoning capability of LLM that reaches success in a wide range of domains, we design $\\textbf{LLM-Exp}$, which improves policy exploration in RL training with large language models (LLMs).\nDuring the RL training in a given environment, we sample a recent action-reward trajectory of the agent and prompt the LLM to analyze the agent's current policy learning status and then generate a probability distribution for future policy exploration.\nWe update the probability distribution periodically and derive a stochastic process that is specialized for the particular environment, which can be dynamically adjusted to adapt to the learning process.\nOur approach is a simple plug-in design, which is compatible with DQN and any of its variants or improvements.\nThrough extensive experiments on the Atari benchmark, we demonstrate the capability of LLM-Exp to enhance the performance of RL.\nOur code is open-source athttps://anonymous.4open.science/r/LLM-Exp-4658for reproducibility."
    },
    {
        "title": "Relative Drawing Identification Complexity is Invariant to Modality in Vision-Language Models",
        "link_suffix": "/forum?id=ceUtIUfotv",
        "link": "https://openreview.net/forum?id=ceUtIUfotv",
        "pdf_link": "https://openreview.net/pdf?id=ceUtIUfotv",
        "keywords": "Multimodal Language Models, Machine Teaching, Concept Identification, Drawing Simplification",
        "abstract": "Large language models have become multimodal, and many of them are said to integrate their modalities using common representations. If this were true, a drawing of car as an image, for instance, should map to the similar area in the latent space as a textual description of the strokes that conform the drawing. To explore this in a black-box access regime to these models, we propose the use of machine teaching, a theory that studies the minimal set of examples a teacher needs to choose so that the learner captures the concept. In particular, we apply this to GPT-4V, a multimodal version of GPT-4 that includes support for image analysis, to evaluate the complexity of teaching a subset of objects in theQuick, Draw!dataset using two presentations: raw images as bitmaps and trace coordinates in TikZ format. The results indicate that image-based representations generally require fewer segments and achieve higher accuracy when compared to coordinate-based representations. But, surprisingly, for concepts recognized by both modalities, the teaching size ranks concepts similarly across both modalities, even when controlling for (a human proxy of) concept priors. This could also suggest that the simplicity of concepts is an inherent property that transcends modality representations."
    },
    {
        "title": "Domain2Vec: Vectorizing Datasets to Find the Optimal Data Mixture without Training",
        "link_suffix": "/forum?id=sF8jmiD8Bq",
        "link": "https://openreview.net/forum?id=sF8jmiD8Bq",
        "pdf_link": "https://openreview.net/pdf?id=sF8jmiD8Bq",
        "keywords": "Language models, Pretraining, Data mixutre",
        "abstract": "The mixture ratio of data from different source domains significantly affects the performance of language models (LM) pretraining. In this paper, we introduce~\\textsc{Domain2Vec}, a novel approach that decomposes any dataset into a linear combination of several ``Meta-Domains'', a new concept designed to capture key underlying features of datasets. \\textsc{Domain2Vec} maintains a vocabulary of Meta-Domains and uses a Meta-Domain Classifier to decompose any given dataset into a domain vector that corresponds to a distribution over this vocabulary. These domain vectors enable the identification of optimal data mixture ratio for LM pretraining in a training-free manner under the \\textit{\\textbf{D}istribution \\textbf{A}lignment \\textbf{A}ssumption} (DA$^{2}$). Moreover, previous work could use \\textsc{Domain2vec} to model the relationship between domain vectors and LM performance, greatly enhancing the scalability of previous methods without retraining as new datasets are introduced. Extensive experiments demonstrate that \\textsc{Domain2Vec} finds data mixture ratios that enhance downstream task performance with minimal computational overhead. Specifically, \\textsc{Domain2Vec} achieves the same validation loss on Pile-CC using only $51.5%$ of the compute required when training on the original mixture of The Pile Dataset. Under equivalent compute budget, \\textsc{Domain2Vec} improves downstream performance by an average of $2.72%$. \\textsc{Domain2Vec} serves as a strong and efficient baseline for data mixture optimization in LM pretraining, offering insights into improving data efficiency in large-scale models."
    },
    {
        "title": "Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models",
        "link_suffix": "/forum?id=8jvVNPHtVJ",
        "link": "https://openreview.net/forum?id=8jvVNPHtVJ",
        "pdf_link": "https://openreview.net/pdf?id=8jvVNPHtVJ",
        "keywords": "Diffusion, Human Feedback, Efficient, Data Filtering",
        "abstract": "Fine-tuning text-to-image diffusion models with human feedback is an effective method for aligning model behavior with human intentions. However, this alignment process often suffers from slow convergence due to the large size and noise present in human feedback datasets. In this work, we propose FiFA, a novel automated data filtering algorithm designed to enhance the fine-tuning of diffusion models using human feedback datasets with direct preference optimization (DPO). Specifically, our approach selects data by solving an optimization problem to maximize three components: preference margin, text quality, and text diversity. The concept of preference margin is used to identify samples that contain high informational value to address the noisy nature of feedback dataset, which is calculated using a proxy reward model. Additionally, we incorporate text quality, assessed by large language models to prevent harmful contents, and consider text diversity through a k-nearest neighbor entropy estimator to improve generalization. Finally, we integrate all these components into an optimization process, with approximating the solution by assigning importance score to each data pair and selecting the most important ones. As a result, our method efficiently filters data automatically, without the need for manual intervention, and can be applied to any large-scale dataset. Experimental results show that FiFA significantly enhances training stability and achieves better performance, being preferred by humans 17% more, while using less than 0.5% of the full data and thus 1% of the GPU hours compared to utilizing full human feedback datasets."
    },
    {
        "title": "The Uncanny Valley: Exploring Adversarial Robustness from a Flatness Perspective",
        "link_suffix": "/forum?id=qak1NNI5yO",
        "link": "https://openreview.net/forum?id=qak1NNI5yO",
        "pdf_link": "https://openreview.net/pdf?id=qak1NNI5yO",
        "keywords": "adversarial robustness, flatness, LLMs",
        "abstract": "Flatness of the loss surface not only correlates positively with generalization, but is also related to adversarial\nrobustness, since perturbations of inputs relate non-linearly to perturbations of weights. In this paper, we empirically\nanalyze the relation between adversarial examples and relative flatness with respect to the parameters of one layer.\nWe observe a peculiar property of adversarial examples in the context of relative flatness: during an iterative first-order\nwhite-box attack, the flatness of the loss surface measured around the adversarial examplefirstbecomes sharper\nuntil the label is flipped, but if we keep the attack running, it runs into a flatuncanny valleywhere the label remains\nflipped. In extensive experiments, we observe this phenomenon across various model architectures and datasets, \neven for adversarially trained models. Our results also extend to large language models (LLMs), but due to the discrete\nnature of the input space and comparatively weak attacks, adversarial examples rarely reach truly flat regions. Most\nimportantly, this phenomenon shows that flatness alone cannot explain adversarial robustness unless we can also\nguarantee the behavior of the function around the examples. We therefore theoretically connect relative flatness to\nadversarial robustness by bounding the third derivative of the loss surface, underlining the need for flatness in\ncombination with a low global Lipschitz constant for a robust model."
    },
    {
        "title": "What is Wrong with Perplexity for Long-context Language Modeling?",
        "link_suffix": "/forum?id=fL4qWkSmtM",
        "link": "https://openreview.net/forum?id=fL4qWkSmtM",
        "pdf_link": "https://openreview.net/pdf?id=fL4qWkSmtM",
        "keywords": "Large language models, Long context",
        "abstract": "Handling long-context inputs is crucial for large language models (LLMs) in tasks such as extended conversations, document summarization, and many-shot in-context learning. While recent approaches have extended the context windows of LLMs and employed perplexity (PPL) as a standard evaluation metric, PPL has proven unreliable for assessing long-context capabilities. The underlying cause of this limitation has remained unclear. In this work, we provide a comprehensive explanation for this issue. We find that PPL overlooks key tokens, which are essential for long-context understanding, by averaging across all tokens and thereby obscuring the true performance of models in long-context scenarios. To address this, we propose \\textbf{LongPPL}, a novel metric that focuses on key tokens by employing a long-short context contrastive method to identify them. Our experiments demonstrate that LongPPL strongly correlates with performance on various long-context benchmarks (e.g., Pearson correlation of 0.97), significantly outperforming traditional PPL in predictive accuracy. Additionally, we introduce \\textbf{LongCE} (Long-context Cross-Entropy) loss, a re-weighting strategy for fine-tuning that prioritizes key tokens, leading to consistent improvements across diverse benchmarks. In summary, these contributions offer deeper insights into the limitations of PPL and present effective solutions for accurately evaluating and enhancing the long-context capabilities of LLMs."
    },
    {
        "title": "KooNPro: A Variance-Aware Koopman Probabilistic Model Enhanced by Neural Processes for Time Series Forecasting",
        "link_suffix": "/forum?id=5oSUgTzs8Y",
        "link": "https://openreview.net/forum?id=5oSUgTzs8Y",
        "pdf_link": "https://openreview.net/pdf?id=5oSUgTzs8Y",
        "keywords": "Probabilistic time series prediction; Neural Process; Deep Koopman model",
        "abstract": "The probabilistic forecasting of time series is a well-recognized challenge, particularly in disentangling correlations among interacting time series and addressing the complexities of distribution modeling. By treating time series as temporal dynamics, we introduce \\textbf{KooNPro}, a novel probabilistic time series forecasting model that combines variance-aware deep \\textbf{Koo}pman model with \\textbf{N}eural \\textbf{Pro}cesses. KooNPro introduces a variance-aware continuous spectrum using Gaussian distributions to capture complex temporal dynamics with improved stability. It further integrates the Neural Processes to capture fine dynamics, enabling enhanced dynamics capture and prediction. Extensive experiments on nine real-world datasets demonstrate that KooNPro consistently outperforms state-of-the-art baselines. Ablation studies highlight the importance of the Neural Process component and explore the impact of key hyperparameters. Overall, KooNPro presents a promising novel approach for probabilistic time series forecasting."
    },
    {
        "title": "TC-MoE: Augmenting Mixture of Experts with Ternary Expert Choice",
        "link_suffix": "/forum?id=dsP91M4hDL",
        "link": "https://openreview.net/forum?id=dsP91M4hDL",
        "pdf_link": "https://openreview.net/pdf?id=dsP91M4hDL",
        "keywords": "Large Language Models, Mixture of Experts",
        "abstract": "The Mixture of Experts (MoE) architecture has emerged as a promising solution for reducing computational overhead by selectively activating subsets of model parameters. The effectiveness of MoE models is primarily dependent on their routing mechanisms, with the widely adopted Top-K routing scheme used to activate experts. However, the Top-K scheme has notable limitations, including unnecessary activations and underutilization of existing experts. In this work,  rather than modifying the routing mechanism as in previous studies, we propose Ternary Choice MoE (TC-MoE), a novel approach that expands the expert space by multiplying each expert with the ternary set {-1, 0, 1}. This expansion allows for more efficient and effective expert activations without incurring significant computational cost. Additionally, given the unique characteristics of the expanded expert space, we introduce a new load balancing loss and reward loss to ensure workload balance and achieve a flexible trade-off between effectiveness and efficiency. Extensive experiments demonstrate that TC-MoE achieves an average improvement of more than 0.95% over the traditional approaches, while reducing the average number of activated experts by 9%. These results confirm that TC-MoE effectively address the inefficiencies of classical routing schemes, offering a more efficient and scalable solution for MoE-based large language models."
    }
]
[{"title": "Tree Attention: Topology-Aware Decoding for Long-Context Attention", "link_suffix": "/forum?id=jMZglnlwf7", "link": "https://openreview.net/forum?id=jMZglnlwf7", "pdf_link": "https://openreview.net/pdf?id=jMZglnlwf7", "keywords": "attention, transformer, long context, large language models", "abstract": "Self-attention is the core mathematical operation of modern transformer architectures and is also a significant computational bottleneck due to its quadratic complexity in the sequence length. \nIn this work, we derive the scalar energy function whose gradient computes the self-attention block, thus elucidating the theoretical underpinnings of self-attention, providing a Bayesian interpretation of the operation and linking it closely with energy-based models such as Hopfield Networks. \nOur formulation reveals that the reduction across the sequence axis can be efficiently computed in parallel through a tree reduction. \nOur algorithm, for parallelizing attention computation across multiple GPUs enables cross-device decoding to be performed asymptotically faster (up to 8x faster in our experiments) than alternative approaches such as Ring Attention, while also requiring significantly less communication volume and incurring 2x less peak memory.\nOur code is publicly available here: \\url{https://anonymous.4open.science/r/tree_attention-7C32}.", "title_embedding_index": 18500, "title_abs_embedding_index": 18525}, {"title": "Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data", "link_suffix": "/forum?id=Vp2OAxMs2s", "link": "https://openreview.net/forum?id=Vp2OAxMs2s", "pdf_link": "https://openreview.net/pdf?id=Vp2OAxMs2s", "keywords": "dynamical systems, recurrent neural networks, hierarchical modelling, time series, interpretability, Nonlinear Dynamics", "abstract": "In science, we are often interested in obtaining a generative model of the underlying system dynamics from observed time series. While powerful methods for dynamical systems reconstruction (DSR) exist when data come from a single domain, how to best integrate data from multiple dynamical regimes and leverage it for generalization is still an open question. This becomes particularly important when individual time series are short, and group-level information may help to fill in for gaps in single-domain data. At the same time, averaging is not an option in DSR, as it will wipe out crucial dynamical properties (e.g., limit cycles in one domain vs. chaos in another). Hence, a framework is needed that enables to efficiently harvest group-level (multi-domain) information while retaining all single-domain dynamical characteristics. Here we provide such a hierarchical approach and showcase it on popular DSR benchmarks, as well as on neuroscientific and medical time series. In addition to faithful reconstruction of all individual dynamical regimes, our unsupervised methodology discovers common low-dimensional feature spaces in which datasets with similar dynamics cluster. The features spanning these spaces were further dynamically highly interpretable, surprisingly in often linear relation to control parameters that govern the dynamics of the underlying system. Finally, we illustrate transfer learning and generalization to new parameter regimes.", "title_embedding_index": 18501, "title_abs_embedding_index": 18526}, {"title": "Attention Head Purification: A New Perspective to Harness CLIP for Domain Generalization", "link_suffix": "/forum?id=5dcnU4gihd", "link": "https://openreview.net/forum?id=5dcnU4gihd", "pdf_link": "https://openreview.net/pdf?id=5dcnU4gihd", "keywords": "Domain generalization, Vision Language Model, CLIP, Low-rank Adaptation", "abstract": "Domain Generalization (DG) aims to learn a model from multiple source domains\nto achieve satisfactory performance on unseen target domains. Recent works\nintroduce CLIP to DG tasks due to its superior image-text alignment and zero-shot performance. Previous methods either utilize full fine-tuning or prompt learning paradigms to harness CLIP for DG tasks. Those works focus on avoiding\ncatastrophic forgetting of the original knowledge encoded in CLIP but ignore that\nthe knowledge encoded in CLIP in nature may contain domain-specific cues that\nconstrain its domain generalization performance. In this paper, we propose a new\nperspective to harness CLIP for DG, i.e., attention head purification. We observe\nthat different attention heads may encode different properties of an image and\nselecting heads appropriately may yield remarkable performance improvement\nacross domains. Based on such observations, we purify the attention heads of CLIP\nfrom two levels, including task-level purification and domain-level purification.\nFor task-level purification, we design head-aware LoRA to make each head more\nadapted to the task we considered. For domain-level purification, we perform\nhead selection via a simple gating strategy. We utilize MMD loss to encourage\nmasked head features to be more domain-invariant to emphasize more generalizable\nproperties/heads. During training, we jointly perform task-level purification and\ndomain-level purification. We conduct experiments on various representative DG\nbenchmarks. Though simple, extensive experiments demonstrate that our method\nperforms favorably against previous state-of-the-arts.", "title_embedding_index": 18502, "title_abs_embedding_index": 18527}, {"title": "Nonasymptotic Analysis of Stochastic Gradient Descent with the Richardson\u2013Romberg Extrapolation", "link_suffix": "/forum?id=Odtr1rzQMq", "link": "https://openreview.net/forum?id=Odtr1rzQMq", "pdf_link": "https://openreview.net/pdf?id=Odtr1rzQMq", "keywords": "Stochastic first-order optimization, Richardson-Romberg extrapolation, Polyak-Ruppert averaging", "abstract": "We address the problem of solving strongly convex and smooth minimization problems using stochastic gradient descent (SGD) algorithm with a constant step size. Previous works  suggested to combine the Polyak-Ruppert averaging procedure with the Richardson-Romberg extrapolation technique to reduce the asymptotic bias of SGD at the expense of a mild increase of the variance. We significantly extend previous results by providing an  expansion of the mean-squared error of the resulting estimator with respect to the number of iterations $n$. More precisely, we show that the mean-squared error can be decomposed into the sum of two terms: a leading one of order $\\mathcal{O}(n^{-1/2})$ with  explicit dependence on a minimax-optimal asymptotic covariance matrix, and a second-order term of order $\\mathcal{O}(n^{-3/4})$ where the power $3/4$ can not be improved in general. We also extend this result to the $p$-th moment bound keeping optimal scaling of the remainders with respect to $n$. Our analysis relies on the properties of the SGD iterates viewed as a time-homogeneous Markov chain. In particular, we establish that this chain is geometrically ergodic with respect to a suitably defined weighted Wasserstein semimetric.", "title_embedding_index": 18503, "title_abs_embedding_index": 18528}, {"title": "Uni-Map: Unified Camera-LiDAR Perception for Robust HD Map Construction", "link_suffix": "/forum?id=MW8DN8BE3g", "link": "https://openreview.net/forum?id=MW8DN8BE3g", "pdf_link": "https://openreview.net/pdf?id=MW8DN8BE3g", "keywords": "HD Map Construction, Sensor Failures; Out-of-Distribution Robustness", "abstract": "High-definition (HD) map construction methods play a vital role in providing precise and comprehensive static environmental information essential for autonomous driving systems. The primary sensors used are cameras and LiDAR, with input configurations varying among camera-only, LiDAR-only, or camera-LiDAR fusion based on cost-performance considerations, while fusion-based methods typically perform the best. However, current methods face two major issues: high costs due to separate training and deployment for each input configuration, and low robustness when sensors are missing or corrupted. To address these challenges, we propose the Unified Robust HD Map Construction Network (Uni-Map), a single model designed to perform well across all input configurations. Our approach designs a novel Mixture Stack Modality (MSM) training scheme, allowing the map decoder to learn effectively from camera, LiDAR, and fused features. We also introduce a projector module to align Bird's Eye View features from different modalities into a shared space, enhancing representation learning and overall model performance. During inference, our model utilizes a switching modality strategy to adapt seamlessly to any input configuration, ensuring compatibility across various modalities. To evaluate the robustness of HD map construction methods, we designed 13 different sensor corruption scenarios and conducted extensive experiments comparing Uni-Map with state-of-the-art methods. Experimental results show that Uni-Map outperforms previous methods by a significant margin across both normal and corrupted modalities, demonstrating superior performance and robustness. Notably, our unified model surpasses independently trained camera-only, LiDAR-only, and camera-LiDAR MapTR models with a gain of 4.6, 5.6, and 5.6 mAP on the nuScenes dataset, respectively. The source code will be released.", "title_embedding_index": 18504, "title_abs_embedding_index": 18529}, {"title": "OmniChat: Enhancing Spoken Dialogue Systems with Scalable Synthetic Data for Diverse Scenarios", "link_suffix": "/forum?id=cVgOIjcNoQ", "link": "https://openreview.net/forum?id=cVgOIjcNoQ", "pdf_link": "https://openreview.net/pdf?id=cVgOIjcNoQ", "keywords": "Spoken Dialogue System, Synthetic Data, Multi-modal Large Language Model", "abstract": "With the rapid development of large language models, researchers have created increasingly advanced spoken dialogue systems that can naturally converse with humans. However, these systems still struggle to handle the full complexity of real-world conversations, including audio events, musical contexts, and emotional expressions, mainly because current dialogue datasets are constrained in both scale and scenario diversity. In this paper, we propose leveraging synthetic data to enhance the dialogue models across diverse scenarios. We introduceShareChatX, the first comprehensive, large-scale dataset for spoken dialogue that spans diverse scenarios. Based on this dataset, we introduceOmniChat, a multi-turn dialogue system with a heterogeneous feature fusion module, designed to optimize feature selection in different dialogue contexts. In addition, we explored critical aspects of training dialogue systems using synthetic data. Through comprehensive experimentation, we determined the ideal balance between synthetic and real data, achieving state-of-the-art results on the real-world dialogue dataset DailyTalk. We also highlight the crucial importance of synthetic data in tackling diverse, complex dialogue scenarios, especially those involving audio and music. For more details, please visit our demo page at \\url{https://sharechatx.github.io/}.", "title_embedding_index": 18505, "title_abs_embedding_index": 18530}, {"title": "A Simple Baseline for Multivariate Time Series Forecasting", "link_suffix": "/forum?id=oANkBaVci5", "link": "https://openreview.net/forum?id=oANkBaVci5", "pdf_link": "https://openreview.net/pdf?id=oANkBaVci5", "keywords": "Time Series Forecasting, Wavelets", "abstract": "The versatility of large language models has led to intensive ongoing work focused on adaptations to other modalities. This can involve moderate modifications of an existing model, piggybacking on the language model's capabilities to train multimodal models or even starting with pre-trained checkpoints and attaching specialized adapters to recast a new modality (e.g., time-series) as ``language''. This latter approach, prominent in a growing set of nice results, yields strong performance across benchmarks. It also makes sense -- while a large amount of temporal data is acquired every day (e.g., wearable sensors, physiological measurements in healthcare), unlike text/image corpus, much of it is not publicly available (except financial markets) for various reasons. But training (or even fine-tuning) these large models is expensive or difficult with limited resources. In this paper, we study and characterize the performance profile of a simple model for multivariate time-series forecasting. By simple, we mean that the model is restricted to tokenization based on classical ideas (as has been shown to be effective in vision) which are then allowed to attend/interact: via self-attention but also via ways that are a bit more general than dot-product attention, accomplished via basic geometric algebra ideas. We show that even a single or two layer model yields results that are competitive with much bigger (and even LLM-based) models on most benchmarks reported in the literature.", "title_embedding_index": 18506, "title_abs_embedding_index": 18531}, {"title": "A CLIP-Powered Framework for Robust and Generalizable Data Selection", "link_suffix": "/forum?id=9bMZ29SPVx", "link": "https://openreview.net/forum?id=9bMZ29SPVx", "pdf_link": "https://openreview.net/pdf?id=9bMZ29SPVx", "keywords": "Data selection, generalization, multimodal", "abstract": "Large-scale datasets have been pivotal to the advancements of deep learning models in recent years, but training on such large datasets invariably incurs substantial storage and computational overhead.  Meanwhile, real-world datasets often contain redundant and noisy data, imposing a negative impact on training efficiency and model performance. Data selection has shown promise in identifying the most representative samples from the entire dataset, which aims to minimize the performance gap with reduced training costs. Existing works typically rely on single-modality information to assign importance scores for individual samples, which may lead to inaccurate assessments, especially when dealing with noisy or corrupted samples. To address this limitation, we propose a novel CLIP-powered data selection framework that leverages multimodal information for more robust and generalizable sample selection. Specifically, our framework consists of three key modules\u2014dataset adaptation, sample scoring, and selection optimization\u2014that together harness extensive pre-trained multimodal knowledge to comprehensively assess sample influence and optimize the selection results through multi-objective optimization. Extensive experiments demonstrate that our approach consistently outperforms existing state-of-the-art baselines on various benchmark datasets. Notably, our method effectively removes noisy or damaged samples from the dataset, enabling it to achieve even higher performance with less data. This indicates that it is not only a way to accelerate training but can also improve overall data quality. The implementation will be made publicly available soon.", "title_embedding_index": 18507, "title_abs_embedding_index": 18532}, {"title": "Federated Learning in Streaming Subspace", "link_suffix": "/forum?id=7BmSz3jE7C", "link": "https://openreview.net/forum?id=7BmSz3jE7C", "pdf_link": "https://openreview.net/pdf?id=7BmSz3jE7C", "keywords": "Federated Learning, communication, subspace", "abstract": "Federated learning (FL) has received widespread attention due to its distributed training and privacy protection. However, existing federated learning methods encounter significant challenges, such as increased communication costs and degraded model performance, when processing non-independently and identically distributed (non-IID) data. This paper jointly alleviates these problems by analyzing and exploiting the low-rank properties of global model trajectories.Primarily, we introduce a streaming subspace update strategy and then propose a general federated learning framework, $\\textbf{F}$erated $\\textbf{L}$earning in $\\textbf{S}$treaming $\\textbf{S}$ubspace ($\\texttt{FLSS}$). In $\\texttt{FLSS}$, local model updates are restricted to the global streaming subspace, resulting in low-dimensional trajectories. The server then aggregates these trajectories to update the global model. Comprehensive experiments verify the effectiveness of our framework. In Cifar100, the $\\texttt{FLSS}$-equipped FL method outperforms the baseline by 2.14$\\%$ and reduces the communication cost by 80$\\%$. $\\texttt{FLSS}$ utilizes the early training information of the global model to simultaneously improve the performance and communication efficiency of federated learning.", "title_embedding_index": 18508, "title_abs_embedding_index": 18533}, {"title": "Choose Before You Label: Efficient Node and Data Selection in Distributed Learning", "link_suffix": "/forum?id=ixXQF1jz8f", "link": "https://openreview.net/forum?id=ixXQF1jz8f", "pdf_link": "https://openreview.net/pdf?id=ixXQF1jz8f", "keywords": "distributed learning, node selection", "abstract": "We consider one of the most relevant problems of distributed learning, i.e., the selection of the learning nodes to include in the training process as well as the selection of the samples from each of the learning nodes' local datasets, so as to make learning sustainable. Traditional approaches rely on pursuing a balanced label distribution, which requires label statistics from all datasets, including those not selected for learning. This may be costly and may raise privacy concerns. To cope with this issue, we aim at selecting few and small datasets. To this end, we propose a new metric, called loneliness, which is defined on unlabelled training samples. First, through both a theoretical and an experimental analysis, we show that loneliness is strongly linked with learning performance (i.e., test accuracy). Then, we propose a new node- and data-selection procedure, called Goldilocks, that uses loneliness to make its decisions. Our performance evaluation, including three state-of-the-art datasets and both centralized and federated learning, demonstrates that Goldilocks outperforms approaches based upon a balanced label distribution by providing over 70% accuracy improvement, in spite of using information that is both less sensitive privacy-wise and less onerous to obtain.", "title_embedding_index": 18509, "title_abs_embedding_index": 18534}, {"title": "Expand and Compress: Exploring Tuning Principles for Continual Spatio-Temporal Graph Forecasting", "link_suffix": "/forum?id=FRzCIlkM7I", "link": "https://openreview.net/forum?id=FRzCIlkM7I", "pdf_link": "https://openreview.net/pdf?id=FRzCIlkM7I", "keywords": "Spatio-temporal Graph, Continual Forecasting, Tuning Principle", "abstract": "The widespread deployment of sensing devices leads to a surge in data for spatio-temporal forecasting applications such as traffic flow, air quality, and wind energy. Although spatio-temporal graph neural networks (STGNNs) have achieved success in modeling various static spatio-temporal forecasting scenarios, real-world spatio-temporal data are typically received in a streaming manner, and the network continuously expands with the installation of new sensors. Thus, spatio-temporal forecasting in streaming scenarios faces dual challenges: the inefficiency of retraining models over newly-arrived data and the detrimental effects of catastrophic forgetting over long-term history. To address these challenges, we propose a novel prompt tuning-based continuous forecasting method,EAC, following two fundamental tuning principles guided by empirical and theoretical analysis:expandandcompress, which effectively resolve the aforementioned problems with lightweight tuning parameters. Specifically, we integrate the base STGNN with a continuous prompt pool, utilizing stored prompts (\\ie, few learnable parameters) in memory, and jointly optimize them with the base STGNN. This method ensures that the model sequentially learns from the spatio-temporal data stream to accomplish tasks for corresponding periods. Extensive experimental results on multiple real-world datasets demonstrate the multi-faceted superiority ofEACover the state-of-the-art baselines, including effectiveness, efficiency, universality, etc.", "title_embedding_index": 18510, "title_abs_embedding_index": 18535}, {"title": "Activating More Advantageous Neurons Can Improve Adversarial Transferability", "link_suffix": "/forum?id=VSidzaTzpd", "link": "https://openreview.net/forum?id=VSidzaTzpd", "pdf_link": "https://openreview.net/pdf?id=VSidzaTzpd", "keywords": "adversarial attacks", "abstract": "Deep Neural Networks (DNNs) are vulnerable to unseen noise, lighting the need to identify the deficiencies of DNNs to mitigate this vulnerability. In the field of adversarial attacks, existing works investigate the deficiencies causing the vulnerability of DNNs, quantifying the vulnerability of DNNs and demonstrating the transferability of adversarial examples where adversarial examples crafted for one model can deceive another. Among the related works, adversarial transferability attracts much attention since transferable adversarial examples enable black-box attacks and raise concerns about DNNs. Although various novel adversarial attacks are presented to improve the adversarial transferability, the property of DNNs that leads to the improvements remains unidentified. This work delves into this issue and reveals that different benign input with different features activates mostly different neurons in a model, and the model may be viewed as an ensemble including different submodels capturing different features. Therefore, an adversarial attack can activate more neurons to generate the adversarial examples, thus probably making the examples applicable to diverse models to enhance the adversarial transferability. Also, data transformation can help exclude wrong answers to boost the adversarial example. The extensive experiments demonstrate the soundness and superiority of our work.", "title_embedding_index": 18511, "title_abs_embedding_index": 18536}, {"title": "Aligned Better, Listen Better For Audio-Visual Large Language Models", "link_suffix": "/forum?id=1SYUKPeM12", "link": "https://openreview.net/forum?id=1SYUKPeM12", "pdf_link": "https://openreview.net/pdf?id=1SYUKPeM12", "keywords": "Audio-Visual Learning, Multimodal Large Language Models", "abstract": "Audio is essential for multimodal video understanding. On the one hand, video inherently contains audio and audio supplies complementary information to the visual modality. Besides, video large language models (Video-LLMs) can encounter many audio-centric settings. However, existing Video-LLMs and Audio-Visual Large Language Models (AV-LLMs) exhibit deficiencies in exploiting audio information, leading to weak understanding and hallucination. To solve the issues, we delve into the model architecture and data aspects. (1) From the architectural perspective, we propose a fine-grained AV-LLM, namely Dolphin. The concurrent alignment of audio and visual modalities in both temporal and spatial dimensions ensures a comprehensive and accurate understanding of videos. Specifically, we devise an audio-visual multi-scale adapter for multi-scale information aggregation, which achieves spatial alignment. For temporal alignment, we propose audio-visual interleaved merging. (2) From the data perspective, we curate an audio-visual caption & instruction-tuning dataset, called AVU. It comprises 5.2 million diverse, open-ended data tuples (video, audio, question, answer) and introduces a novel data partitioning strategy. Extensive experiments show our model not only achieves remarkable performance in audio-visual understanding, but also mitigates hallucinations. Our codes and dataset will be made publicly available.", "title_embedding_index": 18512, "title_abs_embedding_index": 18537}, {"title": "Concept Denoising Score Matching for Responsible Text-to-Image Generation", "link_suffix": "/forum?id=Sqf4jqKrQy", "link": "https://openreview.net/forum?id=Sqf4jqKrQy", "pdf_link": "https://openreview.net/pdf?id=Sqf4jqKrQy", "keywords": "Diffusion models, Stable Diffusion, Responsible text-to-image generation, Fairness, Safe generation, Debiasing", "abstract": "Diffusion models excel at generating diverse, high-quality images, but they also risk producing unfair and harmful content. Existing methods that update text embeddings or model weights either fail to address biases within diffusion models or are computationally expensive. We tackle responsible (fair and safe) text-to-image (T2I) generation in diffusion models as an interpretable concept discovery problem, introducing Concept Denoising Score Matching (CoDSMa) -- a novel objective that learns responsible concept representations in the bottleneck feature activation (\\textit{h-space}). Our approach builds on the observation that, at any timestep, aligning the neutral prompt with the target prompt directs the predicted score of denoised latent towards the target concept. We empirically demonstrate that our method enables responsible T2I generation by addressing two key challenges: mitigating gender and racial biases (fairness) and eliminating harmful content (safety). Our approach reduces biased and harmful generation by nearly 50% compared to state-of-the-art methods. Remarkably, it outperforms other techniques in debiasing gender and racial attributes without requiring profession-specific data. Furthermore, it successfully filters inappropriate content, such as depictions of illegal activities or harassment, without training on such data. Additionally, our method effectively handles intersectional biases without any further training.", "title_embedding_index": 18513, "title_abs_embedding_index": 18538}, {"title": "Test-Time Learning of Causal Structure from Interventional Data", "link_suffix": "/forum?id=ZXs3pkmrRG", "link": "https://openreview.net/forum?id=ZXs3pkmrRG", "pdf_link": "https://openreview.net/pdf?id=ZXs3pkmrRG", "keywords": "Test-Time Traing, Self-Augmentation, Causal Structure Learning, Intervention Target Detection", "abstract": "Inferring causal structures from interventional data remains a challenging task, especially when the interventional targets are unknown. Supervised Causal Learning (SCL) has demonstrated strong empirical performance in predicting causal structures by training on datasets with known causal relations, and then applying the learned models to unseen test data. However, existing SCL methods often struggle with distribution shifts between training and test data.In this work, we propose a novel approach,TICL(Test-time Interventional Causal Learning), which addresses this challenge by introducing \\textit{test-time training} for causal discovery from interventional data. Our method employs a self-augmentation technique that generates training data at test time, specifically tailored to the characteristics of the test data, allowing the model to adapt to biases inherent in the test distribution.TICLintegrates the JCI (Joint Causal Inference) framework with SCL by modifying the rule-based logic of the standard PC algorithm into a learning-based approach, enabling SCL methods to operate within the JCI+SCL framework and effectively utilize the self-augmented training data. Extensive experiments on real-world benchmarks demonstrate the superiority ofTICLacross multiple aspects of causal discovery and interventional target detection.", "title_embedding_index": 18514, "title_abs_embedding_index": 18539}, {"title": "Representation of solutions of second-order linear equations in Barron space via Green's functions", "link_suffix": "/forum?id=708lti8yfI", "link": "https://openreview.net/forum?id=708lti8yfI", "pdf_link": "https://openreview.net/pdf?id=708lti8yfI", "keywords": "partial differential equations, neural networks, Barron norms, high dimension, approximation, regularity theory", "abstract": "AI-based methods for solving high-dimensional partial differential equations (PDEs) have garnered significant attention as a promising approach to overcoming the curse of dimensionality faced by traditional techniques. This work establishes complexity estimates for the Barron norm of solutions of $d$-dimensional linear second-order PDEs, explicitly capturing the dependence on dimension. By leveraging well-developed theory for elliptic and parabolic equations, we represent the solutions of linear second-order equations using Green's functions. From these representations, we derive complexity bounds for the Barron norm of the solutions. Our results extend the prior work of  Chen et al. (2021) in two key aspects. First, we consider more general elliptic and parabolic equations; specifically, we address both time-independent and time-dependent equations. Second, we provide sufficient conditions on the coefficients of the PDEs under which the solutions belong to Barron space rather than approximating the solutions via Barron functions in the $H^1$ norm. As a result, our approach yields theoretically improved results, providing a more intuitive understanding when approximating the solutions of PDEs via two-layer neural networks.", "title_embedding_index": 18515, "title_abs_embedding_index": 18540}, {"title": "OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning", "link_suffix": "/forum?id=VuTrZzrPfn", "link": "https://openreview.net/forum?id=VuTrZzrPfn", "pdf_link": "https://openreview.net/pdf?id=VuTrZzrPfn", "keywords": "Large Language Model, Autonomous Agent, Graphical User Interface", "abstract": "Large language models (LLMs) and large multimodal models (LMMs) have shown great potential in automating complex tasks like web browsing and gaming. However, their ability to generalize across diverse applications remains limited, hindering broader utility. To address this challenge, we present OSCAR: Operating System Control via state-Aware reasoning and Re-planning. OSCAR is a generalist agent designed to autonomously navigate and interact with various desktop and mobile applications through standardized controls, such as mouse and keyboard inputs, while processing screen images to fulfill user commands.\nOSCAR translates human instructions into executable Python code, enabling precise control over graphical user interfaces (GUIs). To enhance stability and adaptability, OSCAR operates as a state machine, equipped with error-handling mechanisms and dynamic task re-planning, allowing it to efficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR\u2019s effectiveness through extensive experiments on diverse benchmarks across desktop and mobile platforms, where it transforms complex workflows into simple natural language commands, significantly boosting user productivity. Our code will be open-source upon publication.", "title_embedding_index": 18516, "title_abs_embedding_index": 18541}, {"title": "Learning the Complexity of Weakly Noisy Quantum States", "link_suffix": "/forum?id=tmSWFGpBb8", "link": "https://openreview.net/forum?id=tmSWFGpBb8", "pdf_link": "https://openreview.net/pdf?id=tmSWFGpBb8", "keywords": "Quantum State Complexity, Quantum Learning Algorithm", "abstract": "Quantifying the complexity of quantum states is a longstanding key problem in various subfields of science, ranging from quantum computing to the black-hole theory. The lower bound on quantum pure state complexity has been shown to grow linearly with system size [J. Haferkamp et al., Nature Physics, 1-5, 2022]. However, extending this result to noisy circuit environments, which better reflect real quantum devices, remains an open challenge. In this paper, we explore the complexity of weakly noisy quantum states. We present an efficient learning algorithm that leverages the classical shadow representation of target quantum states, providing optimal sample complexity with polynomial classical processing time. Our result builds a bridge between learning algorithm and quantum state complexity, meanwhile highlighting the power of learning algorithm in characterizing intrinsic properties of quantum states.", "title_embedding_index": 18517, "title_abs_embedding_index": 18542}, {"title": "Vanishing Privacy: Fast Gradient Leakage Threat to Federated Learning", "link_suffix": "/forum?id=LJULZNlW5d", "link": "https://openreview.net/forum?id=LJULZNlW5d", "pdf_link": "https://openreview.net/pdf?id=LJULZNlW5d", "keywords": "Gradient inversion attacks, Federated learning, AI security", "abstract": "In the federated learning (FL) framework, clients participate in collaborative learning tasks under the coordination of a central server. Clients train local submodels using their own data and share gradients with the server, which aggregates the gradients to achieve privacy protection. However, recent research has revealed that gradient inversion attacks (GIAs) can leak private data from the shared gradients. \nPrior work has only demonstrated the feasibility of recovering input data from gradients under highly restrictive conditions, such as when dealing with high-resolution face datasets, where GIAs often struggle to initiate attacks effectively, and on object datasets like Imagenet, where they encounter limitations, primarily manifested in their ability to handle only small batch sizes and high time costs.\nAs a result, we believe that implementing GIAs on high-resolution face datasets with large batch sizes is a challenging task. In this work, we introduce \\textbf{F}ast \\textbf{G}radient \\textbf{L}eakage (FGL), which enables rapid image recovery across various network models on complex datasets, including the CelebA face dataset (1000 classes, 224$\\times $224 px).\nWe also introduced StyleGAN as prior knowledge for images and achieved FGL with a batch size of 60 in experiments (constrained by experimental hardware).\nWe further propose a joint gradient matching loss, where multiple distinct matching losses collectively contribute to clarifying the attack direction and enhancing the efficiency of the optimization process.\nExtensive experimentation validates the feasibility of our approach. We anticipate that our proposed method can serve as a valuable tool to advance the development of privacy defense techniques.", "title_embedding_index": 18518, "title_abs_embedding_index": 18543}, {"title": "Achieving Optimal Breakdown for Byzantine-Robust Gossip", "link_suffix": "/forum?id=FGd9mXHhM5", "link": "https://openreview.net/forum?id=FGd9mXHhM5", "pdf_link": "https://openreview.net/pdf?id=FGd9mXHhM5", "keywords": "Byzantine, Robustness, Decentralized, Gossip, Averaging, SGD", "abstract": "Distributed approaches have many computational benefits, but they are vulnerable to attacks from a subset of devices transmitting incorrect information. This paper investigates  Byzantine-resilient algorithms in a decentralized setting, where devices communicate directly with one another. \n~We investigate the notion of \\emph{breakdown point}, and show an upper bound on the number of adversaries that decentralized algorithms can tolerate. We introduce $\\mathrm{CG}^+$, an algorithm at the intersection of $\\mathrm{ClippedGossip}$ and $\\mathrm{NNA}$, two popular approaches for robust decentralized learning. $\\mathrm{CG}^+$ meets our upper bound, and thus obtains optimal robustness guarantees, whereas neither of the existing two does. We provide experimental evidence for this gap by presenting an attack tailored to sparse graphs which breaks $\\mathrm{NNA}$ but against which $\\mathrm{CG}^+$ is robust.", "title_embedding_index": 18519, "title_abs_embedding_index": 18544}, {"title": "Adaptive Algorithm for Non-Stationary Online Convex-Concave Optimization", "link_suffix": "/forum?id=WIerHtNyKr", "link": "https://openreview.net/forum?id=WIerHtNyKr", "pdf_link": "https://openreview.net/pdf?id=WIerHtNyKr", "keywords": "Non-Stationary Online Learning, Online Convex-Concave Optimization, Dynamic Duality Gap, Adaptive Algorithm", "abstract": "This paper addresses the problem of Online Convex-Concave Optimization, an extension of Online Convex Optimization to two-player time-varying convex-concave games. \nOur objective is to minimize the dynamic duality gap (D-DGap), a key performance metric that evaluates the players' strategies against arbitrary comparator sequences. \nExisting algorithms struggle to achieve optimal performance, particularly in stationary or predictable environments. \nWe propose a novel, modular algorithm comprising three key components: an Adaptive Module that adjusts to varying levels of non-stationarity, a Multi-Predictor Aggregator that selects the optimal predictor from multiple candidates, and an Integration Module that seamlessly combines the strengths of both. \nOur algorithm guarantees a minimax optimal D-DGap upper bound, up to a logarithmic factor, while also achieving a prediction error-based D-DGap bound. \nEmpirical results further demonstrate the effectiveness and adaptability of the proposed method.", "title_embedding_index": 18520, "title_abs_embedding_index": 18545}, {"title": "Efficient Low-Bit Quantization with Adaptive Scales for Multi-Task Co-Training", "link_suffix": "/forum?id=wA2RMD2AFq", "link": "https://openreview.net/forum?id=wA2RMD2AFq", "pdf_link": "https://openreview.net/pdf?id=wA2RMD2AFq", "keywords": "Low-Bit Quantization, Multi-Task Learning, Co-Training, Quantization-Aware Training, Quantization Scale", "abstract": "Co-training can achieve parameter-efficient multi-task models but remains unexplored for quantization-aware training. Our investigation shows that directly introducing co-training into existing quantization-aware training (QAT) methods results in significant performance degradation. Our experimental study identifies that the primary issue with existing QAT methods stems from the inadequate activation quantization scales for the co-training framework. To address this issue, we propose Task-Specific Scales Quantization for Multi-Task Co-Training (TSQ-MTC) to tackle mismatched quantization scales. Specifically, a task-specific learnable multi-scale activation quantizer (TLMAQ) is incorporated to enrich the representational ability of shared features for different tasks. Additionally, we find that in the deeper layers of the Transformer model, the quantized network suffers from information distortion within the attention quantizer. A structure-based layer-by-layer distillation (SLLD) is then introduced to ensure that the quantized features effectively preserve the information from their full-precision counterparts. Our extensive experiments in two co-training scenarios demonstrate the effectiveness and versatility of TSQ-MTC. In particular, we successfully achieve a 4-bit quantized low-level visual foundation model based on IPT, which attains a PSNR comparable to the full-precision model while offering a $7.99\\times$ compression ratio in the $\\times4$ super-resolution task on the Set5 benchmark.", "title_embedding_index": 18521, "title_abs_embedding_index": 18546}, {"title": "Qinco2: Vector Compression and Search with Improved  Implicit Neural Codebooks", "link_suffix": "/forum?id=2zMHHZ569S", "link": "https://openreview.net/forum?id=2zMHHZ569S", "pdf_link": "https://openreview.net/pdf?id=2zMHHZ569S", "keywords": "vector compression, large-scale retrieval, neural compression, quantization", "abstract": "Vector quantization is a fundamental technique for compression and large-scale nearest neighbor search. For high-accuracy operating points, multi-codebook quantization associates  data vectors with one element from each of multiple codebooks. An example is residual quantization (RQ), which iteratively quantizes the residual error of previous steps. Dependencies between the different parts of the code are, however, ignored in RQ, which leads to suboptimal rate-distortion performance. Qinco recently addressed this inefficiency by using a neural network to determine the quantization codebook in RQ based on the vector reconstruction from previous steps. In this paper we introduce Qinco2 which  extends and improves Qinco with (i) improved  vector encoding using  codeword pre-selection and beam-search, (ii) a fast  approximate decoder leveraging codeword pairs to establish  accurate short-lists for search, and (iii) an optimized training procedure and network architecture. We conduct experiments on four datasets to evaluate Qinco2 for vector compression and billion-scale nearest neighbor  search. We obtain outstanding results  in both settings, improving the state-of-the-art reconstruction MSE by 44% for 16-byte vector compression on BigANN, and search accuracy by 24% with 8-byte encodings on Deep1M.", "title_embedding_index": 18522, "title_abs_embedding_index": 18547}, {"title": "Dynamic Learning Rate for Deep Reinforcement Learning: A Bandit Approach", "link_suffix": "/forum?id=Xn4Je0CxC6", "link": "https://openreview.net/forum?id=Xn4Je0CxC6", "pdf_link": "https://openreview.net/pdf?id=Xn4Je0CxC6", "keywords": "Hyperparameter Optimization, Meta Learning, Deep Reinforcement Learning, Adversarial Multi-Armed Bandits", "abstract": "In Deep Reinforcement Learning models trained using gradient-based techniques, the choice of optimizer and its learning rate are crucial to achieving good performance: higher learning rates can prevent the model from learning effectively, while lower ones might slow convergence. Additionally, due to the non-stationarity of the objective function, the best-performing learning rate can change over the training steps. To adapt the learning rate, a standard technique consists of using decay schedulers. However, these schedulers assume that the model is progressively approaching convergence, which may not always be true, leading to delayed or premature adjustments. In this work, we propose dynamic Learning Rate for deep Reinforcement Learning (LRRL), a meta-learning approach that selects the learning rate based on the agent's performance during training. LRRL is based on a multi-armed bandit algorithm, where each arm represents a different learning rate, and the bandit feedback is provided by the cumulative returns of the RL policy to update the arms' probability distribution. Our empirical results demonstrate that LRRL can substantially improve the performance of deep RL algorithms.", "title_embedding_index": 18523, "title_abs_embedding_index": 18548}, {"title": "Balanced Neural ODEs: nonlinear model order reduction and Koopman operator approximations", "link_suffix": "/forum?id=nA464tCGR5", "link": "https://openreview.net/forum?id=nA464tCGR5", "pdf_link": "https://openreview.net/pdf?id=nA464tCGR5", "keywords": "dynamical variational autoencoders, state space models, Neural ODEs, Koopman theory, surrogate models", "abstract": "Variational Autoencoders (VAEs) are a powerful framework for learning compact latent representations, while NeuralODEs excel in learning transient system dynamics. This work combines the strengths of both to create fast surrogate models with adjustable complexity. By leveraging the VAE\u2019s dimensionality reduction using a non-hierarchical prior, our method adaptively assigns stochastic noise, naturally complementing known NeuralODE training enhancements and enabling probabilistic time series modeling. We show that standard Latent ODEs struggle with dimensionality reduction in systems with time-varying inputs. Our approach mitigates this by continuously propagating variational parameters through time, establishing fixed information channels in latent space. This results in a flexible and robust method that can learn different system complexities, e.g. deep neural networks or linear matrices. Hereby, it enables efficient approximation of the Koopman operator without the need for predefining its dimensionality. As our method balances dimensionality reduction and reconstruction accuracy, we call it Balanced Neural ODE (B-NODE). We demonstrate the effectiveness of this method on academic test cases and apply it to a real-world example of a thermal power plant.", "title_embedding_index": 18524, "title_abs_embedding_index": 18549}]
[
    {
        "title": "Recipes for Unbiased Reward Modeling Learning: An Empirically Study",
        "link_suffix": "/forum?id=putnVJL2Rg",
        "link": "https://openreview.net/forum?id=putnVJL2Rg",
        "pdf_link": "https://openreview.net/pdf?id=putnVJL2Rg",
        "keywords": "Reinforcement Learning from Human Feedback, Reward Modeling",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) enhances the alignment between humans and large language models (LLMs), with Reward Models (RMs) playing a pivotal role. RLHF and sampling techniques, such as Best-of-N, require RMs to provide reliable rewards to guide policy training or sample selection. However, despite the advancement of LLMs, critical issues in RMs persist, such as overestimation on out-of-distribution (OOD) data (also known as reward hacking) and a preference for verbose outputs (length bias). These issues undermine the reliability of RM-generated rewards. Training an unbiased RM requires addressing these challenges, yet there is a lack of in-depth analysis on RMs. In this paper, we first decompose the RM training pipeline and identify three key aspects critical for developing an unbiased RM: 1) model architectures, 2) training paradigms, and 3) the influence of preference data. For each aspect, we conduct thorough empirical studies, revealing several insightful design considerations. Building on our findings, we develop an RM capable of mitigating the identified issues. This study represents the first comprehensive examination of various challenges from a holistic perspective in RM training, offering in-depth analyses of essential concerns and providing guidance for training unbiased RMs that can accurately guide downstream policies. The relevant code and models will be made publicly available."
    },
    {
        "title": "Proper Orthogonal Decomposition for Scalable Training of Graph Neural Networks",
        "link_suffix": "/forum?id=v44CUwEeDY",
        "link": "https://openreview.net/forum?id=v44CUwEeDY",
        "pdf_link": "https://openreview.net/pdf?id=v44CUwEeDY",
        "keywords": "Graph Neural Networks, Scalability, Proper Orthogonal Decomposition, Sublinear Complexity",
        "abstract": "As large-scale graphs become ubiquitous in real-world applications, there is growing concern about \nthe memory and time requirement to train a graph neural network (GNN) model for such datasets.\nStoring the entire adjacency and node embedding matrices in memory is infeasible in such a scenario. Standard sampling-based methods for addressing the memory constraint suffer from the dependence of the number of mini-batches on the graph size. Existing sketch-based methods and graph compression techniques operate at higher sketch ratios, with the graph compression techniques showing poor generalization, implying that different GNNs trained on the same synthetic graph have performance gaps. Sketch-based methods necessitate online learning of sketches, further increasing the complexity. In this paper, we propose a new sketch-based algorithm, PGNN, employing the Proper orthogonal decomposition (POD) method to craft update rules to train GNNs, improving the memory requirement and training time without the complication of updating the sketches during training. Experiments on standard graph datasets show that PGNN can reach much lower sketch ratios without compromising the performance. We prove the optimality of the POD update rule for the linearized GNN (SGC). Empirical findings validate our approach, demonstrating superior performance at reduced sketch ratios and adaptability across various GNN architectures."
    },
    {
        "title": "Intra-fused Gromov Wasserstein Discrepancy: A Smooth Metric for Cross-Domain structured Data",
        "link_suffix": "/forum?id=Aku2I3z4aV",
        "link": "https://openreview.net/forum?id=Aku2I3z4aV",
        "pdf_link": "https://openreview.net/pdf?id=Aku2I3z4aV",
        "keywords": "Optimal transport, alignment, geometric learning",
        "abstract": "Optimal Transport (OT) theory, particularly the Wasserstein distance, is pivotal in comparing probability distributions and has significant applications in signal and image analysis. The Gromov-Wasserstein (GW) distance extends OT to structured data, effectively comparing different graph structures. This paper presents the Intra-fused Gromov-Wasserstein (IFGW) distance, a novel metric that combines the Wasserstein and Gromov-Wasserstein distances to capture both feature and structural information of graphs within a single optimal transport framework. We review related work on graph neural networks and existing transport-based metrics, highlighting their limitations. The IFGW distance aims to overcome these by providing an efficient, isometry-aware method for graph comparison that applies to tasks such as domain adaptation, word embedding, and graph classification, with applications in computer vision, natural language processing, and bioinformatics. We detail the mathematical foundation of IFGW and discuss optimization strategies for practical implementation."
    },
    {
        "title": "Beyond Fine-Tuning: A Systematic Study of Sampling Techniques in Personalized Image Generation",
        "link_suffix": "/forum?id=rgwquPxhIh",
        "link": "https://openreview.net/forum?id=rgwquPxhIh",
        "pdf_link": "https://openreview.net/pdf?id=rgwquPxhIh",
        "keywords": "Generative Model, Diffusion Model, Subject-Driven Generation",
        "abstract": "Personalized text-to-image generation focuses on creating customized images based on user-defined concepts and text descriptions. A good balance between learned concept fidelity and its ability to be generated in different contexts is a major challenge in this task. Modern personalization techniques often strive to find this balance through diverse fine-tuning parameterizations and enhanced sampling methods that integrate superclass trajectories into the backward diffusion process.  Improved sampling methods present a cost-effective, training-free way to enhance already fine-tuned models. However, outside of fine-tuning approaches, there is no systematic analysis of sampling methods in the personalised generation literature. Most sampling techniques are introduced alongside fixed fine-tuning parameterizations, which makes it difficult to identify the impact of sampling on the generation outcomes and whether it can be applied with other fine-tuning strategies. Moreover, they don't compare with the naive sampling approaches, so the intuition of how the superclass trajectory affects the sampling process remains underexplored. In this work, we propose a systematic and comprehensive analysis of personalized generation sampling strategies beyond the fine-tuning methods. We explore various combinations of concept and superclass trajectories, developing a deep understanding of how superclass influence generation outputs. Based on these results, we demonstrate that even a weighted mix of the concept and superclass trajectory can establish a strong baseline that enhances the adaptability of concepts across different contexts and can be effectively transferred to any training strategy, including various fine-tuning parameterizations, text embedding optimization, and hypernetworks. We analyze all methods through the lens of the trade-off between concept fidelity, editability, and computational efficiency, ultimately providing a framework to determine which sampling method is most suitable for specific scenarios."
    },
    {
        "title": "Oldie but Goodie: Re-illuminating Label Propagation on Graphs with Partially Observed Features",
        "link_suffix": "/forum?id=TlFDFKyEIQ",
        "link": "https://openreview.net/forum?id=TlFDFKyEIQ",
        "pdf_link": "https://openreview.net/pdf?id=TlFDFKyEIQ",
        "keywords": "Graph-based Machine Learning, Missing Feature",
        "abstract": "In real-world graphs, we often encounter missing feature situations where a few or the majority of node features, e.g., sensitive information, are missed. Although the recently proposed Feature Propagation algorithm mitigates such situations to some degree, it falls short when only partial features are available, sometimes performing worse than traditional structure-based graph models. To overcome this limitation, we spotlight a classical algorithm, Label Propagation (Oldie), and further illuminate its potential, especially when only a partial feature is available. Now called by Goodie, it takes a hybrid approach to obtain embeddings from the Label Propagation branch and Feature Propagation branch. To do so, we first design a GNN-based decoder that enables the Label Propagation branch to output hidden embeddings that align with those of the FP branch. Then, Goodie automatically captures the significance of structure and feature information thanks to the newly designed Structure-Feature Attention. Followed by a novel Pseudo-Label contrastive learning that differentiates the contribution of each positive pair within pseudo-labels originating from the LP branch, Goodie outputs the final prediction for the unlabeled nodes. Through extensive experiments, we demonstrate that our proposed model, Goodie, outperforms the existing state-of-the art methods not only when only a few features are available but also in abundantly available situations."
    },
    {
        "title": "EEVEE and GATE: Finding the right benchmarks and how to run them seamlessly",
        "link_suffix": "/forum?id=LDu822E45Q",
        "link": "https://openreview.net/forum?id=LDu822E45Q",
        "pdf_link": "https://openreview.net/pdf?id=LDu822E45Q",
        "keywords": "multi-modal, benchmarks, machine learning, model evaluation, benchmark frameworks",
        "abstract": "Model evaluation is a cornerstone of machine learning, guiding model design and progress measurement. Designing generalizable evaluation processes remains a challenge, however, partly due to the vast number of possible domain, task and modality combinations and lack of knowledge of how informative they are. In this paper, we propose EEVEE (Efficient Evaluation process Evolution Engine) - pronounced as \\textipa{/'i:vi:/} EE-vee - a method that frames evaluation process design as a learning problem. By analyzing a large number of evaluation metrics from diverse benchmarks and models, EEVEE identifies a smaller subset of tasks with high predictive power over the full set of evaluation metrics, reducing evaluation time. To find the optimal subset maximizing signal while minimizing GPU hours, EEVEE evaluates pre-trained models of various architectures, pretraining schemes, and modalities on diverse downstream tasks and datasets including image classification, segmentation, relational reasoning, zero-shot image-to-text tasks, medical classification and segmentation, video classification, and regression. Our results identify three subsets of benchmarks, with 8, 15 and 21 tasks, providing high quality signal for model generalization. Key benchmarks selected include iWildCam, CLEVR-Math, ACDC, WinoGround, CIFAR100, Fungi, and ADE20K. We structure the subsets into three tiers for 12, 24, and 36 GPU-hour budgets and package them into a unified, efficient, and user-friendly Python framework that we built with the researcher in mind -- which we refer to as the GATE engine. Our experiments reveal ConvNextV2, SigLIP and CLIP as top-performing model encoders, with EfficientNetV2 and ResNext50 excelling in medical tasks and challenging image classification, in particular in Happy Whale Individual classification, ConvNet based models seem to outperform transformer models by a factor of 2.5x, which is surprising. The top performing encoder being ConvNextV2 followed by CLIP seems to agree with other recent large scale evaluations. We also demonstrate the framework's versatility in fine-tuning models from text and audio modalities, paving the way for future cross-modal evaluations."
    },
    {
        "title": "SAGE: Scalable Ground Truth Evaluations for Large Sparse Autoencoders",
        "link_suffix": "/forum?id=sknUS8X9q0",
        "link": "https://openreview.net/forum?id=sknUS8X9q0",
        "pdf_link": "https://openreview.net/pdf?id=sknUS8X9q0",
        "keywords": "Mechanistic interpretability, Large language models, Sparse autoencoders, Sparse dictionary learning, Unsupervised learning, Interpretable AI",
        "abstract": "A key challenge in interpretability is to decompose model activations into meaningful features. Sparse autoencoders (SAEs) have emerged as a promising tool for this task. However, a central problem in evaluating the quality of SAEs is the absence of ground truth features to serve as an evaluation gold standard. Current evaluation methods for SAEs are therefore confronted with a significant trade-off: SAEs can either leverage toy models or other proxies with predefined ground truth features; or they use extensive prior knowledge of realistic task circuits. The former limits the generalizability of the evaluation results, while the latter limits the range of models and tasks that can be used for evaluations. We introduce SAGE: Scalable Autoencoder Ground-truth Evaluation, an evaluation framework for SAEs that enables obtaining high-quality feature dictionaries for diverse tasks and feature distributions without relying on prior knowledge. Specifically, we lift previous limitations by showing that ground truth evaluations on realistic tasks can be automated and scaled. First, we show that we can automatically identify the cross-sections in the model where task-specific features are active. Second, we demonstrate that we can then compute the ground truth features at these cross-sections. Third, we introduce a novel reconstruction method which significantly reduces the amount of trained SAEs needed for the evaluation. This addresses scalability limitations in prior work and significantly simplifies the practical evaluations. We validate our results by evaluating SAEs on novel tasks on Pythia70M, GPT-2 Small, and Gemma-2-2B, thus demonstrating the scalability of our method to state-of-the-art open-source frontier models. These advancements pave the way for generalizable, large-scale evaluations of SAEs in interpretability research."
    },
    {
        "title": "Free Hunch: Denoiser Covariance Estimation for Diffusion Models Without Extra Costs",
        "link_suffix": "/forum?id=4JK2XMGUc8",
        "link": "https://openreview.net/forum?id=4JK2XMGUc8",
        "pdf_link": "https://openreview.net/pdf?id=4JK2XMGUc8",
        "keywords": "diffusion model, conditional generation, inverse problems, denoiser covariance estimation",
        "abstract": "The covariance for clean data given a noisy observation is an important quantity in many conditional generation methods for diffusion models. Current methods require heavy test-time computation, altering the standard diffusion training process or denoiser architecture, or making heavy approximations. We propose a new framework that sidesteps these issues by using covariance information that is available for free from training data and the curvature of the generative trajectory, which is linked to the covariance through the second-order Tweedie's formula. We integrate these sources of information using (i) a novel method to transfer covariance estimates across noise levels and (ii) low-rank updates in a given noise level. We validate the method on linear inverse problems, where it outperforms recent baselines, especially with fewer diffusion steps."
    },
    {
        "title": "Towards Fast Graph Generation via Autoregressive Filtration Modeling",
        "link_suffix": "/forum?id=bJLO9S6XOj",
        "link": "https://openreview.net/forum?id=bJLO9S6XOj",
        "pdf_link": "https://openreview.net/pdf?id=bJLO9S6XOj",
        "keywords": "Graph generation, Autoregressive model, Generative modeling",
        "abstract": "Graph generative models often face a critical trade-off between learning complex distributions and achieving fast generation speed. We introduce Autoregressive Filtration Modeling (AFM), a novel approach that addresses both challenges. AFM leverages filtration, a concept from topological data analysis, to transform graphs into short sequences of monotonically increasing subgraphs. This enables a structured autoregressive generation process, contrasting with the stochastic trajectories of diffusion models. We propose a novel autoregressive graph mixer model to learn this filtration process, coupled with a noise augmentation strategy to mitigate exposure bias and a reinforcement learning approach to refine the generative model. Extensive experiments on diverse synthetic and real-world datasets demonstrate AFM's superior performance compared to existing autoregressive models. Additionally, AFM achieves a 100-fold speedup in generation time compared to state-of-the-art diffusion models while maintaining the quality of generated graphs. This work represents a significant advancement towards high-throughput graph generation for large-scale applications."
    },
    {
        "title": "Efficient Sparsification of Densely Connected Clusters",
        "link_suffix": "/forum?id=WpsrTQtnJR",
        "link": "https://openreview.net/forum?id=WpsrTQtnJR",
        "pdf_link": "https://openreview.net/pdf?id=WpsrTQtnJR",
        "keywords": "densely connected components, graph sparsification, clustering",
        "abstract": "When modelling a real-world dataset as a graph, groups of highly correlated data items correspond to densely connected vertex sets (clusters), and efficient algorithms that find these clusters have broad applications in various data analysis tasks. In this paper we study densely connected clusters in graphs and introduce two sparsification algorithms that preserve the structure of  these clusters in both undirected graphs and directed ones. We show that our algorithms significantly speedup the running time of existing clustering algorithms while preserving their effectiveness."
    },
    {
        "title": "Toward Generalizability of Graph-based Imputation on Biomedical Tabular-based Missing Data",
        "link_suffix": "/forum?id=Vuj1FZfghv",
        "link": "https://openreview.net/forum?id=Vuj1FZfghv",
        "pdf_link": "https://openreview.net/pdf?id=Vuj1FZfghv",
        "keywords": "Tabular missing data, Graph-based Imputation",
        "abstract": "Recent advances in graph-based imputation methods for addressing missing data have received considerable attention, primarily for their ability to effectively aggregate and propagate information through graph structures. However, the applicability of these methods to the tabular domain remains constrained by two main factors: the lack of task-relevant graph structure and a lack of consideration of feature-wise relationships. To address these challenges, we introduce GRASS, a novel approach that effectively bridges the gap between existing graph-based imputation methods and the unique needs of tabular domains with initially missing data. To derive feature gradient, GRASS initiates with training a Multi-Layer Perceptron layer on tabular data. This gradient then facilitates the creation of graph structures from a feature (column) perspective, enabling column-wise feature propagation for imputing missing values, followed by uncertainty-aware categorical clamping. Finally, to effectively utilize existing graph-based imputation methods in an agnostic manner, we input a so-called warmed-up matrix along with an associated sample (row) graph. We validate GRASS on real-world tabular datasets, including those from the bio, medical, and social domains, demonstrating its ability to unlock the potential of graph-based imputation methods across various missing data scenarios."
    },
    {
        "title": "Temporal Misinformation and Conversion through  Probabilistic Spiking Neurons",
        "link_suffix": "/forum?id=sgke1JuVlc",
        "link": "https://openreview.net/forum?id=sgke1JuVlc",
        "pdf_link": "https://openreview.net/pdf?id=sgke1JuVlc",
        "keywords": "spiking neural networks, probabilistic spiking, ANN-SNN conversion",
        "abstract": "In the age of large neural network models and their high energy demand, Spiking Neural Networks (SNNs) offer a compelling alternative to Artificial Neural Networks (ANNs) due to their energy efficiency and resemblance to biological brains. However, directly training SNNs with spatio-temporal backpropagation remains challenging due to their discrete signal processing and temporal dynamics. Alternative methods, notably ANN-SNN conversion, have enabled SNNs to achieve performance in various machine learning tasks, comparable to ANNs, but often to the expense of long latency needed to achieve such performance, especially on large scale complex datasets. The present work deals with ANN-SNN setting and identifies a new phenomenon we term ``temporal misinformation'', where random spike rearrangement through time in the converted SNN model improves its performance. To account for this, we propose bio-plausible, two-phase probabilistic (TPP) spiking neurons to be used in ANN-SNN conversion. We showcase the benefits of our proposed methods both theoretically and empirically through extensive experiments on CIFAR-10/100 and a large-scale dataset ImageNet over a variety of architectures, reaching SOTA performance. Code is available on GitHub."
    },
    {
        "title": "RwR: A Reason-while-Retrieve framework for Reasoning on Scene Graphs with LLMs",
        "link_suffix": "/forum?id=pTqsapWIPo",
        "link": "https://openreview.net/forum?id=pTqsapWIPo",
        "pdf_link": "https://openreview.net/pdf?id=pTqsapWIPo",
        "keywords": "Large Language Models; Scene Graphs;",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning and planning capacities, yet grounding these abilities to a specific environment remains challenging. Recently, there has been a growing interest in representing environments as scene graphs for LLMs, due to their serializable format, scalability to large environments, and flexibility in incorporating diverse semantic and spatial information for various downstream tasks. \nDespite the success of prompting graphs as text, existing methods suffer from hallucinations with large graph inputs and limitation in solving complex spatial problems, restricting their application beyond simple object search tasks.\n  In this work, we explore grounding LLM reasoning in the environment through the $\\textit{scene graph schema}$. We propose $\\textbf{Reason-while-Retrieve} (\\textbf{\\textit{RwR}})$, a cooperative graph reasoning framework involving two schema-guided code-writing LLMs: a (1) $\\textit{Reasoner}$ for task planning and information querying, and a (2) $\\textit{Retriever}$ for extracting graph information based on these queries. \n  This cooperation facilitates focused attention on task-relevant graph information and enables sequential reasoning on the graph essential for complex tasks.\n  Additionally, the code-writing design allows for the use of tools to solve problems beyond the capacity of LLMs, which further enhance its reasoning ability on scene graphs. \n  We also demonstrate that our framework can benefit from task-level few-shot examples, even in the absence of agent-level demonstrations,\n  thereby enabling in-context learning without data collection overhead.\n  Through experiments in multiple simulation environments, we show that $\\textit{RwR}$ surpasses existing LLM-based approaches in numerical Q&A and planning tasks."
    },
    {
        "title": "Say My Name: a Model's Bias Discovery Framework",
        "link_suffix": "/forum?id=AsckJZlPcy",
        "link": "https://openreview.net/forum?id=AsckJZlPcy",
        "pdf_link": "https://openreview.net/pdf?id=AsckJZlPcy",
        "keywords": "bias discovery, unsupervised debiasing",
        "abstract": "In the last few years, due to the broad applicability of deep learning to downstream tasks and end-to-end training capabilities, increasingly more concerns about potential biases to specific, non-representative patterns have been raised.\nMany works focusing on unsupervised debiasing usually leverage the tendency of deep models to learn \"easier'' samples, for example by clustering the latent space to obtain bias pseudo-labels. However, the interpretation of such pseudo-labels is not trivial, especially for a non-expert end user, as it does not provide semantic information about the bias features.\nTo address this issue, we introduce \"Say My Name'' (SaMyNa), the first tool to identify biases within deep models semantically. Unlike existing methods, our approach focuses on biases learned by the model. Our text-based pipeline enhances explainability and supports debiasing efforts: applicable during either training or post-hoc validation, our method can disentangle task-related information and proposes itself as a tool to analyze biases. Evaluation on traditional benchmarks demonstrates its effectiveness in detecting biases and even disclaiming them, showcasing its broad applicability for model diagnosis."
    },
    {
        "title": "Preference Data Annotation with Guided Density Ratios",
        "link_suffix": "/forum?id=nHenODN9je",
        "link": "https://openreview.net/forum?id=nHenODN9je",
        "pdf_link": "https://openreview.net/pdf?id=nHenODN9je",
        "keywords": "RLHF, preference training, reward model, human preference, preference alignment",
        "abstract": "Preference tuning has become a standard step of modern LLM post-training. Usually, it requires paired human feedback data or preference classifiers trained on such data, where the data collection is costly in time and resources.\nThis paper proposes a data annotation technique that takes the prompt-guided density ratio between off-the-shelf LLMs to serve as proxy of human preference with no training needed. We show that by adding descriptions of preference and domain specific few-shot examples before the user query (e.g. a detailed definition of safety plus an example), we can significantly improve density ratio rewards' annotation accuracy. Our final method reaches a score of 82.6 on RewardBench, where prompt injection improves the Safety domain from 82 to 91 and the Reasoning domain from 74 to 90. We then perform preference tuning using data annotated by density-ratio reward from a 7B model, aligning a Llama 3 8B instruct model to achieve an 37% WinRate on ArenaHard, 41% Length Controlled win-rate on AlpacaEval 2.0, and 8.0 on MT-Bench."
    },
    {
        "title": "Geometry-Informed Neural Networks",
        "link_suffix": "/forum?id=zpX0teJu9Z",
        "link": "https://openreview.net/forum?id=zpX0teJu9Z",
        "pdf_link": "https://openreview.net/pdf?id=zpX0teJu9Z",
        "keywords": "geometry, implicit neural representation, neural fields, theory-informed learning, geometric deep learning, physics-informed neural networks, generative design",
        "abstract": "Geometry is a ubiquitous tool in computer graphics, design, and engineering. However, the lack of large shape datasets limits the application of state-of-the-art supervised learning methods and motivates the exploration of alternative learning strategies.  To this end, we introduce geometry-informed neural networks (GINNs) - a framework for training shape-generative neural fieldswithout databy leveraging user-specified design requirements in the form of objectives and constraints. By addingdiversityas an explicit constraint, GINNs avoid mode-collapse and can generate multiple diverse solutions, often required in geometry tasks. Experimentally, we apply GINNs to several introductory problems and a realistic 3D engineering design problem, showing control over geometrical and topological properties, such as surface smoothness or the number of holes. These results demonstrate the potential of training shape-generative models without data, paving the way for new generative design approaches without large datasets."
    },
    {
        "title": "One Hundred Neural Networks and Brains Watching Videos: Lessons from Alignment",
        "link_suffix": "/forum?id=LM4PYXBId5",
        "link": "https://openreview.net/forum?id=LM4PYXBId5",
        "pdf_link": "https://openreview.net/pdf?id=LM4PYXBId5",
        "keywords": "representational alignment, Representational Similarity Analysis, RSA, benchmarking, neuro-AI, video AI, neuroscience, fMRI, cognitive AI",
        "abstract": "What can we learn from comparing video models to human brains, arguably the most efficient and effective video processing systems in existence? Our work takes a first step towards answering this question by performing the first large-scale benchmarking of deep video models on brain representational alignment, using publicly available models and a recently released video brain imaging (fMRI) dataset. We disentangle four factors of variation (temporal modelling, classification task, architecture, and training dataset) that affect model-brain alignment, which we measure by conducting Representational Similarity Analysis across multiple brain regions and model layers. We show that temporal modelling is key for alignment to brain regions involved in early visual processing, while a relevant classification task is key for alignment to higher-level regions. Moreover, we identify clear differences between the brain scoring patterns across layers of CNNs and transformers, and reveal how training dataset biases transfer to alignment with functionally selective brain areas. Additionally, we uncover a negative correlation of computational complexity to brain alignment. Measuring a total of 99 neural networks and 10 human brains watching videos, we aim to forge a path that widens our understanding of temporal and semantic video representations in brains and machines, ideally leading towards more efficient video models and more mechanistic explanations of processing in the human brain."
    },
    {
        "title": "FedPS: Federated data Preprocessing via aggregated Statistics",
        "link_suffix": "/forum?id=eeC1bSkUrY",
        "link": "https://openreview.net/forum?id=eeC1bSkUrY",
        "pdf_link": "https://openreview.net/pdf?id=eeC1bSkUrY",
        "keywords": "Data Preprocessing, Federated Learning, Aggregated Statistics",
        "abstract": "Data preprocessing is a crucial step in machine learning that significantly influences model accuracy and performance. In Federated Learning (FL), where multiple entities collaboratively train a model using decentralized data, the importance of preprocessing is often overlooked. This is particularly true in Non-IID settings, where clients hold heterogeneous datasets, requiring aggregated parameter estimates to perform consistent data preprocessing. In this paper, we introduce FedPS, a comprehensive suite of tools for federated data preprocessing. FedPS leverages aggregated statistics, data sketching, and federated machine learning models to address the challenges posed by distributed and diverse datasets in FL. Additionally, we resolve key numerical issues in power transforms by improving numerical stability through log-space computations and constrained optimization. Our proposed Federated Power Transform algorithm, based on Brent’s method, achieves superlinear convergence. Experimental results demonstrate the impact of effective data preprocessing in federated learning, highlighting FedPS as a versatile and robust solution compared to existing frameworks. The implementation of FedPS is open-sourced."
    },
    {
        "title": "Banyan: Improved Representation Learning with Explicit Structure",
        "link_suffix": "/forum?id=ED5w271rWo",
        "link": "https://openreview.net/forum?id=ED5w271rWo",
        "pdf_link": "https://openreview.net/pdf?id=ED5w271rWo",
        "keywords": "Representation Learning, Structure, Semantics, Syntax, Induction, Composition",
        "abstract": "We present Banyan, a model that efficiently learns semantic representations by leveraging an inductive bias towards explicit hierarchical structure. Although typical transformer-based models excel at scale, they struggle in low-resource settings. Recent work on models exploiting explicit structure has shown promise as efficient learners in resource-constrained environments. However, these models have yet to demonstrate truly competitive performance. Banyan bridges this gap, significantly improving upon prior structured models and providing, for the first time, a viable alternative to transformer embeddings for under-represented languages. We achieve these improvements through two key innovations 1) A novel entangled tree structure that resolves multiple constituent structures into a single shared one, explicitly incorporating global context. 2) Diagonalized message passing functions that increase the influence of the inductive bias. Our final model has just 14 non-embedding parameters yet is competitive with baselines many orders of magnitude larger. Banyan outperforms its structured predecessors and competes with large unstructured models across various semantic tasks in multiple languages. Notably, it excels in low-resource settings, highlighting its potential for efficient and interpretable NLP in resource-constrained environments. These results underscore the value of appropriate inductive biases in capturing semantic relationships and open new avenues for efficient, interpretable NLP models."
    },
    {
        "title": "Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch",
        "link_suffix": "/forum?id=1Y5hMMuCFU",
        "link": "https://openreview.net/forum?id=1Y5hMMuCFU",
        "pdf_link": "https://openreview.net/pdf?id=1Y5hMMuCFU",
        "keywords": "large language models, mathematical reasoning, data synthesis",
        "abstract": "The availability of high-quality data is one of the most important factors in improving the reasoning capability of LLMs. \nExisting works have demonstrated the effectiveness of creating more instruction data from seed questions or knowledge bases.\nRecent research indicates that continually scaling up data synthesis from strong models (e.g., GPT-4) can further elicit reasoning performance.\nThough promising, the open-sourced community still lacks high-quality data at scale and scalable data synthesis methods with affordable costs.\nTo address this, we introduce ScaleQuest, a scalable and novel data synthesis method that utilizes ``small-size'' (e.g., 7B) open-source models to generate questions from scratch without the need for seed data with complex augmentation constraints.\nWith the efficient ScaleQuest, we automatically constructed a mathematical reasoning dataset consisting of 1 million problem-solution pairs, which are more effective than existing open-sourced datasets.\nIt can universally increase the performance of mainstream open-source models (i.e., Mistral, Llama3, DeepSeekMath, and Qwen2-Math) by achieving 29.2% to 46.4% gains on MATH.\nNotably, simply fine-tuning the Qwen2-Math-7B-Base model with our dataset can even surpass Qwen2-Math-7B-Instruct, a strong and well-aligned model on closed-source data, and proprietary models such as GPT-4-Turbo and Claude-3.5 Sonnet."
    },
    {
        "title": "VideoGPT+: Integrating Image and Video Encoders for Enhanced Video Understanding",
        "link_suffix": "/forum?id=YGWxpOI6Y0",
        "link": "https://openreview.net/forum?id=YGWxpOI6Y0",
        "pdf_link": "https://openreview.net/pdf?id=YGWxpOI6Y0",
        "keywords": "video-conversation-model, large multi-modal model, multi-modal, video-conversation, image-and-video, phi-3-min, vision-language, video-chatbot",
        "abstract": "Building on the advances of language models, Large Multimodal Models (LMMs) have contributed significant improvements in video understanding. While the current video LMMs utilize advanced Large Language Models (LLMs), they rely on either image or video encoders to process visual inputs, each of which has its own limitations. Image encoders excel at capturing rich spatial details from frame sequences but lack explicit temporal context, which can be important in videos with intricate action sequences. On the other hand, video encoders provide temporal context but are often limited by computational constraints that lead to processing only sparse frames at lower resolutions, resulting in reduced contextual and spatial understanding. To this end, we introduce our model, which combines the complementary benefits of the image encoder (for detailed spatial understanding) and the video encoder (for global temporal context modeling). The model processes videos by dividing them into smaller segments and applies an adaptive pooling strategy on features extracted by both image and video encoders. Our architecture showcases improved performance across multiple video benchmarks, including VCGBench, MVBench and Zero-shot question-answering. Further, we develop 112K video-instruction set using a novel semi-automatic annotation pipeline which further improves the model performance. Additionally, to comprehensively evaluate video LMMs, we present our bench, covering 18 broad video categories such as lifestyle, sports, science, gaming, and surveillance videos. This benchmark with 4,354 question-answer pairs evaluates the generalization of existing LMMs on dense video captioning, spatial and temporal understanding, and complex reasoning, ensuring comprehensive assessment across diverse video types and dynamics. Our code, dataset, and pre-trained models will be publicly released."
    },
    {
        "title": "Exploring and Benchmarking  Planning Capabilities of  Large Language Models",
        "link_suffix": "/forum?id=koza5fePTs",
        "link": "https://openreview.net/forum?id=koza5fePTs",
        "pdf_link": "https://openreview.net/pdf?id=koza5fePTs",
        "keywords": "planning capability, LLMs, many-shot, in-context learning",
        "abstract": "Classical and natural language planning tasks remain a difficult domain for modern large language models (LLMs). In this work, we lay the foundations for improving planning capabilities of LLMs.\nFirst, we construct a comprehensive benchmark suite encompassing both classical planning benchmarks and natural language scenarios. \nThis suite includes algorithms to methodically generate instances of tasks with varying levels of difficulty, allowing for rigorous and systematic evaluation of LLM performance. \nNext, we investigate the use of many-shot in-context learning to enhance LLM planning, exploring the  relationship between increased context length and improved planning performance. In addition, we demonstrate the positive impact of fine-tuning LLMs on optimal planning paths. We also probe the efficacy of chain-of-thought reasoning methods to improve LLM planning performance.\nMoreover, we probe the performance of the proposed methods in out-of-distribution scenarios, assessing the ability to generalize to novel and unseen planning challenges. Finally, we investigate model's failure modes and reveal insights that hold true across different benchmarks."
    },
    {
        "title": "Value-aligned Behavior Cloning for Offline Reinforcement Learning via Bi-level Optimization",
        "link_suffix": "/forum?id=elTJBP7Fbv",
        "link": "https://openreview.net/forum?id=elTJBP7Fbv",
        "pdf_link": "https://openreview.net/pdf?id=elTJBP7Fbv",
        "keywords": "offline reinforcement learning;bi-level optimization;value alignment",
        "abstract": "Offline reinforcement learning (RL) aims to optimize policies under pre-collected data, without requiring any further interactions with the environment. Derived from imitation learning, Behavior cloning (BC) is extensively utilized in offline RL for its simplicity and effectiveness. Although BC inherently avoids out-of-distribution deviations, it lacks the ability to discern between high and low-quality data, potentially leading to sub-optimal performance when facing with poor-quality data. Current offline RL algorithms attempt to enhance BC by incorporating value estimation, yet often struggle to effectively balance these two critical components, specifically the alignment between the behavior policy and the pre-trained value estimations under in-sample offline data. To address this challenge, we propose the Value-aligned Behavior Cloning via Bi-level Optimization (VACO), a novel bi-level framework that seamlessly integrates an inner loop for weighted supervised behavior cloning (BC) with an outer loop dedicated to value alignment. In this framework, the inner loop employs a meta-scoring network to evaluate and appropriately weight each training sample, while the outer loop introduces controlled noise to facilitate limited exploration. This bi-level structure allows VACO to identify the optimal weighted BC policy, ultimately maximizing the expected estimated return conditioned on the learned value function. We conduct a comprehensive evaluation of VACO across a variety of continuous control benchmarks in offline RL, where it consistently achieves superior performance compare"
    },
    {
        "title": "Tensor-Var: Variational Data Assimilation in Tensor Product Feature Space",
        "link_suffix": "/forum?id=fsrQuugqiF",
        "link": "https://openreview.net/forum?id=fsrQuugqiF",
        "pdf_link": "https://openreview.net/pdf?id=fsrQuugqiF",
        "keywords": "Variational Data Assimilation, Dynamical System, Weather Forecasting, Representation Learning",
        "abstract": "Variational data assimilation estimates the dynamical system states by minimizing cost function that fits the numerical models with observational data. The widely used method, four-dimensional variational assimilation (4D-Var), has two primary limitations: (1) computationally demanding for complex nonlinear systems; and (2) relying on state-observation mappings, which are often impractical. Recently, deep learning (DL) has been used as a more expressive class of efficient model approximators to address these challenges. However, integrating such models into 4D-Var remains challenging due to their inherent nonlinearities and the lack of theoretical guarantees for consistency in assimilation results. In this paper, we propose \\textit{Tensor-Var} to address these challenges using kernel Conditional Mean Embedding (CME). Tensor-Var characterizes system dynamics and state-observation mappings as linear operators in a feature space, enabling a more efficient linear 4D-Var framework. Our method seamlessly integrates CME with 4D-Var, offering theoretical guarantees of consistent assimilation results between the original and feature space. To improve CME scalability, we use deep kernel features that map data into a finite-dimensional feature space, utilizing the expressiveness of deep learning. Experiments on chaotic systems and global weather forecasting demonstrate that Tensor-Var outperforms operational and DL hybrid methods 4D-Var baselines in terms of accuracy while achieving efficiency comparable to the static 3D-Var method."
    },
    {
        "title": "COT Flow: Learning Optimal-Transport Image Sampling and Editing by Contrastive Pairs",
        "link_suffix": "/forum?id=57EjN072hl",
        "link": "https://openreview.net/forum?id=57EjN072hl",
        "pdf_link": "https://openreview.net/pdf?id=57EjN072hl",
        "keywords": "generative models, consistency models, diffusion models, optimal transport",
        "abstract": "Diffusion models have demonstrated strong performance in sampling and editing multi-modal data with high generation quality, yet they suffer from the iterative generation process which is computationally expensive and slow. In addition, most methods are constrained to generate data from Gaussian noise, which limits their sampling and editing flexibility. To overcome both disadvantages, we present Contrastive Optimal Transport Flow (COT Flow), a new method that achieves fast and high-quality generation with improved zero-shot editing flexibility compared to previous diffusion models. Benefiting from optimal transport (OT), our method has no limitation on the prior distribution, enabling unpaired image-to-image (I2I) translation and doubling the editable space (at both the start and end of the trajectory) compared to other zero-shot editing methods. In terms of quality, COT Flow can generate competitive results in merely one step compared to previous state-of-the-art unpaired image-to-image (I2I) translation methods. To highlight the advantages of COT Flow through the introduction of OT, we introduce the COT Editor to perform user-guided editing with excellent flexibility and quality."
    }
]
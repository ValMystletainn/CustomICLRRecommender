[{"title": "Audio Large Language Models Can Be Descriptive Speech Quality Evaluators", "link_suffix": "/forum?id=U42TkrEDzb", "link": "https://openreview.net/forum?id=U42TkrEDzb", "pdf_link": "https://openreview.net/pdf?id=U42TkrEDzb", "keywords": "Audio LLM, Speech quality evaluation", "abstract": "An ideal multimodal agent should be aware of the quality of its input modalities. Recent advances have enabled large language models (LLMs) to incorporate auditory systems for handling various speech-related tasks. However, most audio LLMs remain unaware of the quality of the speech they process. This limitation arises because speech quality evaluation is typically excluded from multi-task training due to the lack of suitable datasets. To address this, we introduce the first natural language-based speech evaluation corpus, generated from authentic human ratings. In addition to the overall Mean Opinion Score (MOS), this corpus offers detailed analysis across multiple dimensions and identifies causes of quality degradation. It also enables descriptive comparisons between two speech samples (A/B tests) with human-like judgment. Leveraging this corpus, we propose an alignment approach with LLM distillation (ALLD) to guide the audio LLM in extracting relevant information from raw speech and generating meaningful responses. Experimental results demonstrate that ALLD outperforms the previous state-of-the-art regression model in MOS prediction, with a mean square error of 0.17 and an A/B test accuracy of 98.6%. Additionally, the generated responses achieve BLEU scores of 25.8 and 30.2 on two tasks, surpassing the capabilities of task-specific models. This work advances the comprehensive perception of speech signals by audio LLMs, contributing to the development of real-world auditory and sensory intelligent agents.", "title_embedding_index": 5950, "title_abs_embedding_index": 5975}, {"title": "How does controllability emerge in language models during pretraining?", "link_suffix": "/forum?id=egHptuv7hx", "link": "https://openreview.net/forum?id=egHptuv7hx", "pdf_link": "https://openreview.net/pdf?id=egHptuv7hx", "keywords": "controllability, ability emergence, pre-training models, dimentionality reduction, representations", "abstract": "Language models can be controlled by adjusting their internal representations, which alters the degree to which concepts such as emotional tone, style, truthfulness, and safety are expressed in their generative outputs. This paper demonstrates that controllability emerges abruptly during pre-training, and furthermore, even closely-related concepts (e.g. anger and sadness) can emerge at different\nstages of pre-training. To understand how controllability of internal representations changes during pre-training, we introduce the \u201cIntervention Detector\u201d (ID), which applies dimensionality reduction to hidden states under different stimuli, and outputs concept representations that can be applied to control language models. Using these concept representations, we then compute an extraction score (ID score) that shows how well the extracted representations align with the model\u2019s hidden states. This ID score can be used to approximately predict the time of emergence of controllability for different concepts, and the degree to which each concept is controllable. By analyzing ID scores across a longitudinal series of models taken at different stages of pre-training, we demonstrate that, as pre-training progresses, concepts become increasingly easier to extract via dimensionality reduction methods, which correlates with the emergence of controllability. For instance, in the CrystalCoder model, the controllability of the concept \u201canger\u201d emerges at 68% of pre-training, whereas the controllability of the concept \u201csadness\u201d emerges at 93% of the pre-training process. We use heatmap visualizations and other metrics (eg., entropy, cosine similarity, tSNE) to study these differences, and validate the reliability and generalizability of ID scores through model interventions using the extracted concept representations.", "title_embedding_index": 5951, "title_abs_embedding_index": 5976}, {"title": "LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal Data", "link_suffix": "/forum?id=lh0iTFCD1y", "link": "https://openreview.net/forum?id=lh0iTFCD1y", "pdf_link": "https://openreview.net/pdf?id=lh0iTFCD1y", "keywords": "multimodal dataset, multimodal uncertainty quantification, uncertainty quantification, multimodal deep learning", "abstract": "Multimodal Deep Learning enhances decision-making by integrating diverse information sources, such as texts, images, audio, and videos. To develop trustworthy multimodal approaches, it is essential to understand how uncertainty impacts these models. We propose  LUMA, a unique benchmark dataset, featuring audio, image, and textual data from 50 classes, for learning from uncertain and multimodal data. It extends the well-known CIFAR 10/100 dataset with audio samples extracted from three audio corpora, and text data generated using the Gemma-7B Large Language Model (LLM). The LUMA dataset enables the controlled injection of varying types and degrees of uncertainty to  achieve and tailor specific experiments and benchmarking initiatives. LUMA is also available as a Python package including the functions for generating multiple variants of the dataset with controlling the diversity of the data, the amount of noise for each modality, and adding out-of-distribution samples. A baseline pre-trained model is also provided alongside three uncertainty quantification methods: Monte-Carlo Dropout, Deep Ensemble, and Reliable Conflictive Multi-View Learning. This comprehensive dataset and its benchmarking tools are intended to promote and support the development, evaluation, and benchmarking of trustworthy and robust multimodal deep learning approaches. We anticipate that the LUMA dataset will help the ICLR community to design more trustworthy and robust machine learning approaches for safety critical applications.", "title_embedding_index": 5952, "title_abs_embedding_index": 5977}, {"title": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection", "link_suffix": "/forum?id=RcmJ9NpqeA", "link": "https://openreview.net/forum?id=RcmJ9NpqeA", "pdf_link": "https://openreview.net/pdf?id=RcmJ9NpqeA", "keywords": "vulnerability detection, llm, linear attention, mamba, white-basilisk, nlp, moe, efficient, source code, c, c++", "abstract": "The proliferation of software vulnerabilities presents a significant challenge to cybersecurity, necessitating more effective detection methodologies. We introduce White-Basilisk, a novel approach to vulnerability detection that demonstrates superior performance while challenging prevailing assumptions in AI model scaling. Utilizing an innovative architecture that integrates Mamba layers, linear self-attention, and a Mixture of Experts framework, White-Basilisk achieves state-of-the-art results in vulnerability detection tasks with a parameter count of only 200M. The model's capacity to process sequences of unprecedented length enables comprehensive analysis of extensive codebases in a single pass, surpassing the context limitations of current Large Language Models (LLMs). White-Basilisk exhibits robust performance on imbalanced, real-world datasets, while maintaining computational efficiency that facilitates deployment across diverse organizational scales. This research not only establishes new benchmarks in code security but also provides empirical evidence that compact, efficiently designed models can outperform larger counterparts in specialized tasks, potentially redefining optimization strategies in AI development for domain-specific applications.", "title_embedding_index": 5953, "title_abs_embedding_index": 5978}, {"title": "Data-Evolution Learning", "link_suffix": "/forum?id=cADdVJYiIG", "link": "https://openreview.net/forum?id=cADdVJYiIG", "pdf_link": "https://openreview.net/pdf?id=cADdVJYiIG", "keywords": "Data-centric Learning", "abstract": "Recent advancements in machine learning have been driven by models trained on large-scale, high-quality datasets. However, the practical application of these models faces two significant challenges: the infeasibility of acquiring precise labels in real-world settings and the substantial computational burden imposed by training large models. While existing approaches\u2014such as self-supervised learning, weak supervision, noisy label learning, and dataset distillation\u2014address these challenges from a model-centric perspective, they often overlook the potential benefits of optimizing the data itself.\nThis paper introduces a novel data-centric learning paradigm where both the dataset and the model co-evolve during the learning process.\nWe formalize this paradigm and propose a Data-evolution Learning Algorithm (DeLA), which offers three key advantages: optimized dataset generation, versatile dataset compatibility, and effective utilization of prior knowledge.\nExtensive experiments demonstrate that DeLA enables the creation of optimized datasets for reuse in subsequent training, effectively addressing diverse datasets with varying target types. Moreover, DeLA accelerates learning by utilizing architecture-agnostic, open-source prior models for efficient data creation.\nNotably, DeLA frequently outperforms traditional SOTA model-centric methods in self-supervised and noisy label learning.\nFurthermore, its simplicity enables implementation in only two lines of PyTorch code, offering significant potential for advancements in representation learning.\nOur code will be made publicly available.", "title_embedding_index": 5954, "title_abs_embedding_index": 5979}, {"title": "MARS: A neurosymbolic approach for interpretable drug discovery", "link_suffix": "/forum?id=STBPaproaB", "link": "https://openreview.net/forum?id=STBPaproaB", "pdf_link": "https://openreview.net/pdf?id=STBPaproaB", "keywords": "neurosymbolic, drug discovery, interpretability, knowledge graphs, reinforcement learning", "abstract": "Neurosymbolic (NeSy) artificial intelligence describes the combination of logic or rule-based techniques with neural networks. Compared to neural approaches, NeSy methods often possess enhanced interpretability, which is particularly promising for biomedical applications like drug discovery. However, since interpretability is broadly defined, there are no clear guidelines for assessing the biological plausibility of model interpretations. To assess interpretability in the context of drug discovery, we devise a novel prediction task, called drug mechanism-of-action (MoA) deconvolution, with an associated, tailored knowledge graph (KG), MoA-net. We then develop the MoA Retrieval System (MARS), a NeSy approach for drug discovery which leverages logical rules with learned rule weights. Using this interpretable feature alongside domain knowledge, we find that MARS and other NeSy approaches on KGs are susceptible to reasoning shortcuts, in which the prediction of true labels is driven by \"degree-bias\" rather than the domain-based rules. Subsequently, we demonstrate ways to identify and mitigate this. Thereafter, MARS achieves performance on par with current state-of-the-art models while producing model interpretations aligned with known MoAs.", "title_embedding_index": 5955, "title_abs_embedding_index": 5980}, {"title": "Learn Your Reference Model for Real Good Alignment", "link_suffix": "/forum?id=H0qIWXXLUR", "link": "https://openreview.net/forum?id=H0qIWXXLUR", "pdf_link": "https://openreview.net/pdf?id=H0qIWXXLUR", "keywords": "reinforcement learning from human feedback, language models, RLHF, preferences, alignment, overoptimization", "abstract": "Despite the fact that offline methods for Large Language Models (LLMs) alignment do not require a direct reward model, they remain susceptible to overoptimization. This issue arises when the trained model deviates excessively from the reference policy, leading to a decrease in sample quality. We propose a new paradigm of offline alignment methods, called Trust Region (including variants TR-DPO, TR-IPO, TR-KTO), which dynamically updates the reference policy throughout the training process. Our results show that TR alignment methods effectively mitigate overoptimization, enabling models to maintain strong performance even when substantially deviating from the initial reference policy. We demonstrate the efficacy of these approaches not only through toy examples that exhibit reduced overoptimization, but also through direct, side-by-side comparisons in specific tasks such as helpful and harmless dialogue, as well as summarization, where they surpass conventional methods. Additionally, we report significant improvements in general-purpose assistant setups with the Llama3 model on the AlpacaEval 2 and Arena-Hard benchmarks, highlighting the advantages of Trust Region methods over classical approaches.", "title_embedding_index": 5956, "title_abs_embedding_index": 5981}, {"title": "Optimizing Inference-Time Reasoning in LLMs via Retrieval-Augmented Reflection", "link_suffix": "/forum?id=ElYRG3pJcv", "link": "https://openreview.net/forum?id=ElYRG3pJcv", "pdf_link": "https://openreview.net/pdf?id=ElYRG3pJcv", "keywords": "Retrieval-augmented Generation, Reasoning, Large Language Models", "abstract": "Empowering LLMs to improve their performance through increased inference-time computation is a crucial step in developing self-improving agents capable of operating in open-ended natural language contexts. In this paper, we explore how iterative revising a chain of thoughts with the help of information retrieval significantly improves large language models' reasoning ability in challenging tasks, while hugely mitigating hallucination. In particular, the proposed method --- \\emph{retrieval-augmented reflection} (RaR) --- revises the generation tokens step one by one with multiple retrieved information relevant to the instruction. Applying RaR during inference-time to a various set of language models substantially improves their performances on various reasoning tasks; on relatively increasing scores by 13.63% on code generation, 16.96% on mathematical reasoning, and 42.78% on embodied task planning. Moreover, we find that with more inference-time computation given to the LLM for multi-times retrieval-augmented reflection, the LLM can continuously improve on various reasoning benchmarks. With lower inference-time computation (FLOPs), a small LM can surpass the performance of the LM with more than 10 times the parameters.", "title_embedding_index": 5957, "title_abs_embedding_index": 5982}, {"title": "MambaTS: Improved Selective State Space Models for Long-term Time Series Forecasting", "link_suffix": "/forum?id=vEtDApqkNR", "link": "https://openreview.net/forum?id=vEtDApqkNR", "pdf_link": "https://openreview.net/pdf?id=vEtDApqkNR", "keywords": "Time Series Forcasting; State Space Model", "abstract": "In recent years, Transformers have become the de-facto architecture for long-term sequence forecasting (LTSF), yet they face challenges associated with the self-attention mechanism, including quadratic complexity and permutation invariant bias. This raises an important question: \\emph{do we truly need the self-attention mechanism to establish long-range dependencies in LTSF?} Recognizing the significance of causal relationships in multivariate LTSF, we propose MambaTS, which leverages causal relationships to model global dependencies across time and variables through a single linear scan. However, causal graphs are often unknown. To address this, we introduce variable-aware scan along time (VAST), which dynamically discovers variable relationships during training and decodes the optimal variable scan order by solving the shortest path visiting all nodes problem during inference. MambaTS employs the latest Mamba model as its backbone. We suggest that the causal convolution in Mamba is unnecessary due to the presence of independent variables, leading to the development of the Temporal Mamba Block (TMB). To mitigate model overfitting, we further incorporate a dropout mechanism for selective parameters in TMB. Extensive experiments conducted on eight public datasets demonstrate that MambaTS achieves new state-of-the-art performance.", "title_embedding_index": 5958, "title_abs_embedding_index": 5983}, {"title": "Bayesian Neural Networks with Domain Knowledge Priors", "link_suffix": "/forum?id=Qa40qfZooj", "link": "https://openreview.net/forum?id=Qa40qfZooj", "pdf_link": "https://openreview.net/pdf?id=Qa40qfZooj", "keywords": "bayesian neural networks, domain knowledge", "abstract": "Bayesian neural networks (BNNs) have recently gained popularity due to their ability to quantify model uncertainty in prediction. However, specifying a prior for BNNs that accurately captures relevant domain knowledge is often extremely challenging. In this work, we propose a framework for integrating general forms of domain knowledge (i.e., any knowledge that can be represented by a loss function) into a BNN prior through variational inference, while enabling computationally efficient posterior inference and sampling. Specifically, our approach results in a prior over neural network weights that assigns high probability mass to models that better align with our domain knowledge, leading to posterior samples that also exhibit this behavior. In a semi-supervised learning setting, we show that BNNs using our proposed domain knowledge priors outperform those with standard priors (e.g., isotropic Gaussian, Gaussian process), successfully incorporating diverse types of prior information such as fairness, physics rules, and healthcare knowledge and achieving better predictive performance. We also present techniques for transferring the learned priors across different model architectures, demonstrating their broad utility across many tasks.", "title_embedding_index": 5959, "title_abs_embedding_index": 5984}, {"title": "Variance-Reduced Normalized Zeroth Order Method for Generalized-Smooth Non-Convex Optimization", "link_suffix": "/forum?id=7t8aKBeATc", "link": "https://openreview.net/forum?id=7t8aKBeATc", "pdf_link": "https://openreview.net/pdf?id=7t8aKBeATc", "keywords": "Non-convex Optimization, generalized smooth, zero-order, gradient-free, $(L_{0}, L_{1})$-smooth", "abstract": "The generalized smooth condition,  $(L_{0},  L_{1})$-smoothness,  has triggered people\u2019s interest since it is more realistic in many optimization problems shown by both empirical and theoretical evidence. To solve the generalized smooth optimization,  gradient clipping  methods are often employed,  and have theoretically been shown to be as effective as the traditional gradient-based methods\\citep{Chen_2023,  xie2024}. However,  whether these methods can be safely extended to zeroth-order case is still unstudied. To answer this important question,  we propose a zeroth-order normalized gradient method(ZONSPIDER) for both finite sum and general expectation case,  and we prove that we can find $\\epsilon$- stationary point of $f(x)$ with optimal decency on $d$ and $\\epsilon$,  specifically,  the complexes are  $\\mathcal{O}(d\\epsilon^{-2}\\sqrt{n}\\max{L_{0},  L_{1}})$ in the finite sum case and $\\mathcal{O}(d\\epsilon^{-3}\\max{\\sigma_{1}^{2},  \\sigma_{0}^{2}}\\max{L_{0},  L_{1}})$   in  the general expectation case.\n    To the best of our knowledge,  this is the first time that sample complexity bounds are established for a zeroth-order method  under generalized smoothness.", "title_embedding_index": 5960, "title_abs_embedding_index": 5985}, {"title": "Noise-conditioned Energy-based Annealed Rewards (NEAR): A Generative Framework for Imitation Learning from Observation", "link_suffix": "/forum?id=DL9txImSzm", "link": "https://openreview.net/forum?id=DL9txImSzm", "pdf_link": "https://openreview.net/pdf?id=DL9txImSzm", "keywords": "imitation learning, energy based generative models, reinforcement learning, imitation from observation", "abstract": "This paper introduces a new imitation learning framework based on energy-based generative models capable of learning complex, physics-dependent, robot motion policies through state-only expert motion trajectories. Our algorithm, called Noise-conditioned Energy-based Annealed Rewards (NEAR), constructs several perturbed versions of the expert's motion data distribution and learns smooth, and well-defined representations of the data distribution's energy function using denoising score matching. We propose to use these learnt energy functions as reward functions to learn imitation policies via reinforcement learning. We also present a strategy to gradually switch between the learnt energy functions, ensuring that the learnt rewards are always well-defined in the manifold of policy-generated samples. We evaluate our algorithm on complex humanoid tasks such as locomotion and martial arts and compare it with state-only adversarial imitation learning algorithms like Adversarial Motion Priors (AMP). Our framework sidesteps the optimisation challenges of adversarial imitation learning techniques and produces results comparable to AMP in several quantitative metrics across multiple imitation settings.", "title_embedding_index": 5961, "title_abs_embedding_index": 5986}, {"title": "Leveraging AutoML for Sustainable Deep Learning: A Multi-Objective HPO Approach on Deep Shift Neural Networks", "link_suffix": "/forum?id=AZTdO6JJKt", "link": "https://openreview.net/forum?id=AZTdO6JJKt", "pdf_link": "https://openreview.net/pdf?id=AZTdO6JJKt", "keywords": "Deep Learning, AutoML, Green AutoML, Sustainability, Multi-Objective Optimization, Multi-Fidelity Optimization, Deep Shift Neural Networks", "abstract": "Deep Learning (DL) has advanced various fields by extracting complex patterns from large datasets.\nHowever, the computational demands of DL models pose environmental and resource challenges. Deep Shift Neural Networks (DSNNs) improve the situation by leveraging shift operations to reduce computational complexity at inference.\nCompared to common DNNs, DSNNs are still less well understood and less well optimized. \nBy leveraging AutoML techniques, we provide valuable insights into the potential of DSNNs and how to design them in a better way.\nFollowing the insights from common DNNs, we propose to leverage the full potential of DSNNs by means of AutoML techniques. \nWe study the impact of hyperparameter optimization (HPO) on maximizing DSNN performance while minimizing resource consumption. \nSince we consider complementary objectives such as accuracy and energy consumption, we combine state-of-the-art multi-fidelity (MF) HPO with multi-objective optimization to find a set of Pareto-optimal trade-offs on how to design DSNNs.\nOur approach led to significantly better configurations of DSNNs regarding loss and emissions compared to default DSNNs. This includes simultaneously increasing performance by about 20% and reducing emissions by about 10%.\nInvestigating the behavior of quantized networks in terms of both emissions and accuracy, our experiments reveal surprising model-specific trade-offs, yielding the greatest energy savings.\nFor example, in contrast to common expectations, selectively quantizing smaller portions of the network with low precision is optimal while retaining or improving performance.\nWe corroborated these findings across multiple backbone architectures, highlighting important nuances in quantization strategies and offering an automated approach to balancing energy efficiency and model performance.", "title_embedding_index": 5962, "title_abs_embedding_index": 5987}, {"title": "PADetBench: Towards Benchmarking Physical Attacks against Object Detection", "link_suffix": "/forum?id=9rtlfjWMXI", "link": "https://openreview.net/forum?id=9rtlfjWMXI", "pdf_link": "https://openreview.net/pdf?id=9rtlfjWMXI", "keywords": "Benchmark, physical attacks, object detection", "abstract": "Physical attacks against object detection have gained increasing attention due to their significant practical implications. \n  However, conducting physical experiments is extremely time-consuming and labor-intensive.\n  Moreover, physical dynamics and cross-domain transformation are challenging to strictly regulate in the real world, leading to unaligned evaluation and comparison, severely hindering the development of physically robust models.\n  To accommodate these challenges, we explore utilizing realistic simulation to thoroughly and rigorously benchmark physical attacks with fairness under controlled physical dynamics and cross-domain transformation. \n  This resolves the problem of capturing identical adversarial images that cannot be achieved in the real world.\n  Our benchmark includes 20 physical attack methods, 48 object detectors, comprehensive physical dynamics, and evaluation metrics. We also provide end-to-end pipelines for dataset generation, detection, evaluation, and further analysis. \n  In addition, we perform 8064 groups of evaluation based on our benchmark, which includes both overall evaluation and further detailed ablation studies for controlled physical dynamics.\n  Through these experiments, we provide in-depth analyses of physical attack performance and physical adversarial robustness, draw valuable observations, and discuss potential directions for future research.", "title_embedding_index": 5963, "title_abs_embedding_index": 5988}, {"title": "Memory Savings by Sharing One Source: Insights into Subsetsum Approximation", "link_suffix": "/forum?id=spwklWgmWJ", "link": "https://openreview.net/forum?id=spwklWgmWJ", "pdf_link": "https://openreview.net/pdf?id=spwklWgmWJ", "keywords": "Strong lottery tickets, Subsetsum approximation, Mixture of Experts, Ensembles, Memory savings, Discrete optimization", "abstract": "Large deep neural networks, often fine-tuned from foundation models, dominate modern machine learning, but their high memory requirements limit deployment on resource-constrained devices. Strong lottery tickets (SLTs) offer a promising solution by significantly reducing memory usage, as they are fully characterized by a seed for generating a random source network and a binary mask. Notably, multiple models can share the same source network without increasing its width requirement. As we show, this source sharing can lead to memory savings when experts share specific sparsity patterns. Based on novel insights into optimized subset sum approximations, we also show how the masks can be adjusted to further reduce memory overhead. To validate these theoretical findings, we provide explicit SLT constructions in experiments.", "title_embedding_index": 5964, "title_abs_embedding_index": 5989}, {"title": "LifelongSotopia: Evaluating Social Intelligence Of Language Agents Over Lifelong Social Interactions", "link_suffix": "/forum?id=XdcuqZRhjQ", "link": "https://openreview.net/forum?id=XdcuqZRhjQ", "pdf_link": "https://openreview.net/pdf?id=XdcuqZRhjQ", "keywords": "LLMs, language agents, social intelligence, evaluation of LLMs", "abstract": "Humans engage in lifelong social interactions through interacting with different people under different scenarios for different social goals. This requires social intelligence to gather information through a long time span and use it to navigate various social contexts effectively. Whether AI systems are also capable of this is understudied in the existing research. In this paper, we present a novel benchmark, LifelongSotopia, to perform a comprehensive evaluation of language agents by simulating multi-episode interactions. In each episode, the language agents role-play characters to achieve their respective social goals in randomly sampled social tasks. With LifelongSotopia, we find that goal achievement and believability of all of the language models that we test decline through the whole interaction. Although using an advanced memory method improves the agents' performance, the best agents still achieve a significantly lower goal completion rate than humans on scenarios requiring an explicit understanding of interaction history. These findings show that we can use LifelongSotopia to evaluate long-context language models and the social intelligence of language agents over lifelong social interactions.", "title_embedding_index": 5965, "title_abs_embedding_index": 5990}, {"title": "Global-to-Local Support Spectrums for Model Explainability", "link_suffix": "/forum?id=cxB0fPNZkx", "link": "https://openreview.net/forum?id=cxB0fPNZkx", "pdf_link": "https://openreview.net/pdf?id=cxB0fPNZkx", "keywords": "sample-based explanations, influence functions, representer points", "abstract": "Existing sample-based methods, like influence functions and representer points, measure the importance of a training point by approximating the effect of its removal from training. As such, they are skewed towards outliers and points that are very close to the decision boundaries. The explanations provided by these methods are often static and not specific enough for different test points. In this paper, we propose a method to generate an explanation in the form of support spectrums which are based on two main ideas: the support sets and a global-to-local importance measure. The support set is the set of training points, in the predicted class, that ``lie in between'' the test point and training points in the other classes. They indicate how well the test point can be distinguished from the points not in the predicted class. The global-to-local importance measure is obtained by decoupling existing methods into the global and local components which are then used to select the points in the support set. Using this method, we are able to generate explanations that are tailored to specific test points. In the experiments, we show the effectiveness of the method in image classification and text generation tasks.", "title_embedding_index": 5966, "title_abs_embedding_index": 5991}, {"title": "EcoFace: Audio-Visual Emotional Co-Disentanglement Speech-Driven 3D Talking Face Generation", "link_suffix": "/forum?id=iDcWYtYUwX", "link": "https://openreview.net/forum?id=iDcWYtYUwX", "pdf_link": "https://openreview.net/pdf?id=iDcWYtYUwX", "keywords": "3D Talking face generation, Audio-visual emotional co-disentanglement, Speaker-specific", "abstract": "Speech-driven 3D facial animation has attracted significant attention due to its wide range of applications in animation production and virtual reality. Recent research has explored speech-emotion disentanglement to enhance facial expressions rather than manually assigning emotions. However, this approach face issues such as feature confusion, emotions weakening and mean-face. To address these issues, we present EcoFace, a framework that (1) proposes a novel collaboration objective to provide a explicit signal for emotion representation learning from the speaker's expressive movements and produced sounds, constructing an audio-visual joint and coordinated emotion space that is independent of speech content. (2) constructs a universal facial motion distribution space determined by speech features and implement speaker-specific generation. Extensive experiments show that our method achieves more generalized and emotionally realistic talking face generation compared to previous methods.", "title_embedding_index": 5967, "title_abs_embedding_index": 5992}, {"title": "MolCoMA: Complementary Masking Strategy for Promoting Atom-Level Multi-Modal Molecular Representation", "link_suffix": "/forum?id=y7Ud3RAPT8", "link": "https://openreview.net/forum?id=y7Ud3RAPT8", "pdf_link": "https://openreview.net/pdf?id=y7Ud3RAPT8", "keywords": "Multi-modal Fusion, Molecular Pretraining, Molecular Representation Learning", "abstract": "Molecular representation learning, which captures the fundamental characteristics of chemical compounds, is crucial for AI-driven drug discovery. Methodologies exist that integrate various modalities (e.g., 2D topology and 3D geometry) and develop robust representations. However, current multi-modal fusion strategies either align embedding space through independent models separately, thereby overlooking complementary information, or bridge modalities at a coarse-grained level, failing to capture inherent correlation. To facilitate fine-grained interactions of intrinsic features across modalities, this study presents MolCoMA, an innovative pretraining framework for Molecular representation, employing a unified encoder that leverages Complementary Masking mechanism. Specifically, we first employ two distinct encoders to capture the unique characteristics and structures inherent in different modalities. We then utilize a unified encoder accompanied by a customized complementary masking strategy to seamlessly integrate information, mitigating overlap and similarity between 2D and 3D representations. Finally, we incorporate a cross-modal reconstruction module to enhance fine-grained interactions at the atomic level. Extensive experiments demonstrate that our model outperforms existing molecular pretraining methods across both 2D and 3D benchmarks. This finding underscores the effectiveness of our approach to fusing information between modalities.", "title_embedding_index": 5968, "title_abs_embedding_index": 5993}, {"title": "Co-Evolution Learning", "link_suffix": "/forum?id=5IBrWCeZtl", "link": "https://openreview.net/forum?id=5IBrWCeZtl", "pdf_link": "https://openreview.net/pdf?id=5IBrWCeZtl", "keywords": "Generative Models, Representation Learning", "abstract": "Generative and representation models, whether trained independently or evolved separately, require high-quality, diverse training data, imposing limitations on their advancement.\nSpecifically, self-supervised learning, as a popular paradigm for representation learning, decreases the reliance on labeled data in representation models.\nHowever, it still necessitates large datasets, specialized data augmentation techniques, and tailored training strategies.\nWhile generative models have shown promise in generating diverse data, ensuring semantic consistency is still a challenge.\nThis paper introduces a novel co-evolution framework (referred to as CORE) designed to address these challenges through the mutual enhancement of generative and representation models.\nWithout incurring additional, unacceptable training overhead compared to independent training, the generative model utilizes semantic information from the representation model to enhance the quality and semantic consistency of generated data.\nSimultaneously, the representation model gains from the diverse data produced by the generative model, leading to richer and more generalized representations.\nBy iteratively applying this co-evolution framework, both models can be continuously enhanced.\nExperiments demonstrate the effectiveness of the co-evolution framework across datasets of varying scales and resolutions.\nFor example, implementing our framework in LDM can reduce the FID from $43.40$ to $20.13$ in unconditional generation tasks over the ImageNet-1K dataset.\nIn more challenging scenarios, such as tasks with limited data, this framework significantly outperforms independent training of generative or representation model.\nFurthermore, employing the framework in a self-consuming loop effectively mitigates model collapse.\nOur code will be publicly released.", "title_embedding_index": 5969, "title_abs_embedding_index": 5994}, {"title": "Brain-inspired Multi-View Incremental Learning for Knowledge Transfer and Retention", "link_suffix": "/forum?id=hyb6NCjS8G", "link": "https://openreview.net/forum?id=hyb6NCjS8G", "pdf_link": "https://openreview.net/pdf?id=hyb6NCjS8G", "keywords": "Brain-inspired Knowledge Transfer; Hebbian Learning; Multi-view Incremental Learning;  Orthogonal Projection", "abstract": "The human brain exhibits remarkable proficiency in dynamic learning and adaptation, seamlessly integrating prior knowledge with new information, thereby enabling flexible memory retention and efficient transfer across multiple views. In contrast, traditional multi-view learning methods are predominantly designed for static and fixed-view datasets, leading to the notorious \"view forgetting phenomenon\", where the introduction of new views leads to the erosion of prior knowledge. This phenomenon starkly contrasts with the brain\u2019s remarkable ability to continuously integrate and migrate past knowledge, ensuring both the retention of old information and the assimilation of new insights. This oversight presents a critical challenge: how to efficiently learn and integrate new views while simultaneously preserving knowledge from previously acquired views and enabling flexible knowledge transfer across diverse perspectives.Inspired by underlying neural processing mechanisms, we propose a view transfer learning framework named Hebbian View Orthogonal Projection (HVOP), which realizes efficient knowledge migration and sharing between multi-view data. HVOP constructs a knowledge transfer space (KTS), where the KTS reduces the interference between the old and the new views through an orthogonal learning mechanism. By further incorporating recursive lateral connections and Hebbian learning, the proposed model endows the learning process with brain-like dynamic adaptability, enhancing knowledge transfer and integration, and bringing the model closer to human cognition. We extensively validate the proposed model on node classification tasks and demonstrate its superior performance in knowledge retention and transfer compared to traditional methods. Our results underscore the potential of biologically inspired mechanisms in advancing multi-view learning and mitigating the view forgetting phenomenon.", "title_embedding_index": 5970, "title_abs_embedding_index": 5995}, {"title": "AdaFM: Adaptive Variance-Reduced Algorithm for Stochastic Minimax Optimization", "link_suffix": "/forum?id=Nh1ZH61OqF", "link": "https://openreview.net/forum?id=Nh1ZH61OqF", "pdf_link": "https://openreview.net/pdf?id=Nh1ZH61OqF", "keywords": "varienced reduction; adaptive method;  minimax optimization", "abstract": "In stochastic minimax optimization, variance-reduction techniques have been widely developed to mitigate the inherent variances introduced by stochastic gradients. Most of these techniques employ carefully designed estimators and learning rates, successfully reducing variance. Although these approaches achieve optimal theoretical convergence rates, they require the careful selection of numerous hyperparameters, which heavily depend on problem-dependent parameters. This complexity makes them difficult to implement in practical model training. To address this, our paper introduces Adaptive Filtered Momentum (AdaFM), an adaptive variance-reduced algorithm for stochastic minimax optimization. AdaFM adaptively adjusts hyperparameters based solely on historical estimator information, eliminating the need for manual parameter tuning. Theoretical results show that AdaFM can achieve a near-optimal sample complexity of $O(\\epsilon^{-3})$ to find an $\\epsilon$-stationary point in non-convex-strongly-concave and non-convex-Polyak-\\L ojasiewicz objectives, matching the performance of the best existing non-parameter-free algorithms. Extensive experiments across various applications validate the effectiveness and robustness of AdaFM.", "title_embedding_index": 5971, "title_abs_embedding_index": 5996}, {"title": "Characterizing the Training Dynamics of Private Fine-tuning with Langevin Diffusion", "link_suffix": "/forum?id=KYipmCMmSO", "link": "https://openreview.net/forum?id=KYipmCMmSO", "pdf_link": "https://openreview.net/pdf?id=KYipmCMmSO", "keywords": "differential privacy, convergence, fine-tuning theory, transfer learning theory, langevin diffusion, gradient flow", "abstract": "We show that differentially private full fine-tuning (DP-FFT) can distort pre-trained backbone features based on both theoretical and empirical results. We identify the cause of the distortion as the misalignment between the pre-trained backbone and the randomly initialized linear head. We prove that a sequential fine-tuning strategy can mitigate the feature distortion: first-linear-probing-then-fine-tuning (DP-LP-FFT). A new approximation scheme allows us to derive approximate upper and lower bounds on the training loss of DP-LP and DP-FFT, in a simple but canonical setting of 2-layer neural networks with ReLU activation. Experiments on real-world datasets and architectures are consistent with our theoretical insights.   We also derive new upper bounds for 2-layer linear networks without the approximation. Moreover, our theory suggests a trade-off of privacy budget allocation in multi-phase fine-tuning methods like DP-LP-FFT.", "title_embedding_index": 5972, "title_abs_embedding_index": 5997}, {"title": "Shapley Value Approximation based on k-Additive Games", "link_suffix": "/forum?id=lLzeKG6t52", "link": "https://openreview.net/forum?id=lLzeKG6t52", "pdf_link": "https://openreview.net/pdf?id=lLzeKG6t52", "keywords": "Explainable AI, Shapley Value, Feature Importance, Game Theory", "abstract": "The Shapley value is the prevalent solution for fair division problems in which a payout is to be divided among multiple agents. By adopting a game-theoretic view, the idea of fair division and the Shapley value can also be used in machine learning to quantify the individual contribution of features or data points to the performance of a predictive model. Despite its popularity and axiomatic justification, the Shapley value suffers from a computational complexity that scales exponentially with the number of entities involved, and hence requires approximation methods for its reliable estimation. In this paper, we propose SVA$k_{\\text{ADD}}$, a novel approximation method that fits a $k$-additive surrogate game. By taking advantage of the assumption of $k$-additivity, we are able to compute the exact Shapley values of the surrogate game in polynomial time, and then use these values as estimates for the original fair division problem. The efficacy of our method is evaluated empirically and compared to competing methods.", "title_embedding_index": 5973, "title_abs_embedding_index": 5998}, {"title": "Hierarchical Multiscale Diffuser for Extendable Long-Horizon Planning", "link_suffix": "/forum?id=C4H45A9cZa", "link": "https://openreview.net/forum?id=C4H45A9cZa", "pdf_link": "https://openreview.net/pdf?id=C4H45A9cZa", "keywords": "Long-Horizon Planning, Diffusion, Hierarchical, Multiscale", "abstract": "This paper introduces the Hierarchical Multiscale Diffuser (HM-Diffuser), a novel approach for efficient long-horizon planning. Building on recent advances in diffusion-based planning, our method addresses the challenge of planning over horizons significantly longer than those available in the training data. We decompose the problem into two key subproblems. The first phase, Progressive Trajectory Extension (PTE), involves stitching short trajectories together to create datasets with progressively longer trajectories. In the second phase, we train the HM-Diffuser on these extended datasets, preserving computational efficiency while enhancing long-horizon planning capabilities. The hierarchical structure of the HM-Diffuser allows for subgoal generation at multiple temporal resolutions, enabling a top-down planning approach that aligns high-level, long-term goals with low-level, short-term actions. Experimental results demonstrate that the combined PTE and HM-Diffuser approach effectively generates long-horizon plans, extending far beyond the originally provided trajectories.", "title_embedding_index": 5974, "title_abs_embedding_index": 5999}]
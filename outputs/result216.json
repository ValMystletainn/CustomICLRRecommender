[
    {
        "title": "The Path-Driven Independence Testing (PIT) Algorithm",
        "link_suffix": "/forum?id=orD5t7blqV",
        "link": "https://openreview.net/forum?id=orD5t7blqV",
        "pdf_link": "https://openreview.net/pdf?id=orD5t7blqV",
        "keywords": "Causality, Bayesian networks, Structure learning, Constraint based, PC algorithm",
        "abstract": "PC is an efficient constraint-based algorithm for learning the structure of a Bayesian network. However, the required number of conditional independent (CI) tests can make the algorithm practically infeasible or slow for large graphs. We developed a constrained-based algorithm, called the Path-Driven Independence Testing (PIT) Algorithm, which during the learning process, utilizes the information of the partially learned network to reduce the number of CI tests. The idea is that for each pair of variables $X$ and $Y$, instead of checking independence conditioned on every subset of all the neighbors of $X$ (resp. $Y$) as in PC, the search is restricted to only the common neighbors of $X$ and $Y$ and to neighbors connected to $Y$ (resp. $X$) by a path. Also, paths connecting $X$ and $Y$ without a descendant of a common neighbor can be blocked by observing two consecutive nodes on the path. Compared to PC, PIT is proven to conduct at most the same number of CI tests, and experimentally shown to be significantly (up to 7 times) faster and more accurate."
    },
    {
        "title": "Lines of Thought in Large Language Models",
        "link_suffix": "/forum?id=zjAEa4s3sH",
        "link": "https://openreview.net/forum?id=zjAEa4s3sH",
        "pdf_link": "https://openreview.net/pdf?id=zjAEa4s3sH",
        "keywords": "LLM, latent space, token trajectories, interpretability, transformer",
        "abstract": "Large Language Models achieve next-token prediction by transporting a vectorized piece of text (prompt) across an accompanying embedding space under the action of successive transformer layers. The resulting high-dimensional trajectories realize different contextualization, or 'thinking', steps, and fully determine the output probability distribution. We aim to characterize the statistical properties of ensembles of these 'lines of thought.' We observe that independent trajectories cluster along a low-dimensional, non-Euclidean manifold, and that their path can be well approximated by a stochastic equation with few parameters extracted from data. We find it remarkable that the vast complexity of such large models can be reduced to a much simpler form, and we reflect on implications."
    },
    {
        "title": "BlendRL: A Framework for Merging Symbolic and Neural Policy Learning",
        "link_suffix": "/forum?id=60i0ksMAhd",
        "link": "https://openreview.net/forum?id=60i0ksMAhd",
        "pdf_link": "https://openreview.net/pdf?id=60i0ksMAhd",
        "keywords": "Neuro-Symbolic AI, Differentiable Reasoning, Reinforcement Learning, Interpretable AI, First-order logic",
        "abstract": "Humans can leverage both symbolic reasoning and intuitive responses. In contrast, reinforcement learning policies are typically encoded in either opaque systems like neural networks or symbolic systems that rely on predefined symbols and rules. This disjointed approach severely limits the agents\u2019 capabilities, as they often lack either the flexible low-level reaction characteristic of neural agents or the interpretable reasoning of symbolic agents.To overcome this challenge, we introduceBlendRL, a neuro-symbolic RL framework that harmoniously integrates both paradigms. \nWe empirically demonstrate that BlendRL agents outperform both neural and symbolic baselines in standard Atari environments, and showcase their robustness to environmental changes. Additionally, we analyze the interaction between neural and symbolic policies, illustrating how their hybrid use helps agents overcome each other's limitations."
    },
    {
        "title": "Distilling Reinforcement Learning into Single-Batch Datasets",
        "link_suffix": "/forum?id=XnX7xRoroC",
        "link": "https://openreview.net/forum?id=XnX7xRoroC",
        "pdf_link": "https://openreview.net/pdf?id=XnX7xRoroC",
        "keywords": "distillation, reinforcement learning, RL, meta-learning, compression",
        "abstract": "Dataset distillation compresses a large dataset into a small, often one-batch, synthetic dataset such that learning on the synthetic dataset approximates learning on the large dataset. Training on the distilled dataset can be performed in as little as one step of gradient descent. We demonstrate that distillation is generalizable to different tasks by distilling reinforcement learning environments into one-batch supervised learning datasets. This demonstrates not only distillation's ability to compress a reinforcement learning task but also its ability to transform one learning modality (reinforcement learning) into another (supervised learning). We present a novel extension of proximal policy optimization for meta-learning and use it in distillation of both a multi-dimensional extension of the classic cart-pole problem and several Atari games. We demonstrate distillation's ability to compress complex RL environments into one-step supervised learning, explore RL distillation's generalizability across learner architectures, and demonstrate distilling an environment into the smallest-possible synthetic dataset."
    },
    {
        "title": "Knowledge Graph Finetuning Enhances Knowledge Manipulation in Large Language Models",
        "link_suffix": "/forum?id=oMFOKjwaRS",
        "link": "https://openreview.net/forum?id=oMFOKjwaRS",
        "pdf_link": "https://openreview.net/pdf?id=oMFOKjwaRS",
        "keywords": "Large Language Models, Knowledge Graph, Supervised Fine-tuning",
        "abstract": "Despite the impressive performance of general large language models(LLMs), many of their applications in specific domains (e.g., low-data and knowledge-intensive) still confront significant challenges. Supervised fine-tuning (SFT)---where a general LLM is further trained on a small labeled dataset to adapt for specific tasks or domains---has shown great power for developing domain-specific LLMs. However, existing SFT data primarily consist of Question and Answer (Q&A) pairs, which poses a significant challenge for LLMs to comprehend the correlation and logic of knowledge underlying the Q&A. To address this challenge, we propose a conceptually flexible and general framework to boost SFT, namely Knowledge Graph-Driven Supervised Fine-Tuning (KG-SFT). The key idea of KG-SFT is to generate high-quality explanations for each Q&A pair via a structured knowledge graph to enhance the knowledge comprehension and manipulation of LLMs. Specifically, KG-SFT consists of three components: Extractor, Generator, and Detector. For a given Q&A pair, (i) Extractor first identifies entities within Q&A pairs and extracts relevant reasoning subgraphs from external KGs, (ii) Generator then produces corresponding fluent explanations utilizing these reasoning subgraphs, and (iii) finally, Detector performs sentence-level knowledge conflicts detection on these explanations to guarantee the reliability. KG-SFT focuses on generating high-quality explanations to improve the quality of Q&A pair, which reveals a promising direction for supplementing existing data augmentation methods. Extensive experiments on fifteen different domains and six different languages demonstrate the effectiveness of KG-SFT, leading to an accuracy improvement of up to 18% and an average of 10% in low-data scenarios."
    },
    {
        "title": "SyncFlow: Temporally Aligned Joint Audio-Video Generation from Text",
        "link_suffix": "/forum?id=J2EmNMLoxv",
        "link": "https://openreview.net/forum?id=J2EmNMLoxv",
        "pdf_link": "https://openreview.net/pdf?id=J2EmNMLoxv",
        "keywords": "Text-to-Audio-Video-Joint Generation, Flow matching, Diffusion Transformer",
        "abstract": "Video and audio are closely correlated modalities that humans naturally perceive together. While recent advancements have enabled the generation of audio or video from text, producing both modalities simultaneously still typically relies on either a cascaded process or multi-modal contrastive encoders. These approaches, however, often lead to suboptimal results due to inherent information losses during inference and conditioning. In this paper, we introduce SyncFlow, a system that is capable of simultaneously generating temporally synchronized audio and video from text. The core of SyncFlow is the proposed dual-diffusion-transformer (d-DiT) architecture, which enables joint video and audio modelling with proper information fusion. To efficiently manage the computational cost of joint audio and video modelling, SyncFlow utilizes a multi-stage training strategy that separates video and audio learning before joint fine-tuning. Our empirical evaluations demonstrate that SyncFlow produces audio and video outputs that are more correlated than baseline methods with significantly enhanced audio quality and audio-visual correspondence. Moreover, we demonstrate strong zero-shot capabilities of SyncFlow, including zero-shot video-to-audio generation and adaptation to novel video resolutions without further training."
    },
    {
        "title": "BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions",
        "link_suffix": "/forum?id=YrycTjllL0",
        "link": "https://openreview.net/forum?id=YrycTjllL0",
        "pdf_link": "https://openreview.net/pdf?id=YrycTjllL0",
        "keywords": "Code Generation, Tool Use, Instruction Following, Benchmark",
        "abstract": "Task automation has been greatly empowered by the recent advances in Large Language Models (LLMs) via Python code, where the tasks range from software engineering development to general-purpose reasoning. While current benchmarks have shown that LLMs can solve tasks using programs like human developers, the majority of their evaluations are limited to short and self-contained algorithmic tasks or standalone function calls. Solving challenging and practical tasks requires the capability of utilizingdiverse function calls as toolsto efficiently implement functionalities like data analysis and web development. In addition, using multiple tools to solve a task needs compositional reasoning by accurately understandingcomplex instructions. Fulfilling both of these characteristics can pose a great challenge for LLMs. To assess how well LLMs can solve challenging and practical tasks via programs, we introduce BigCodeBench, a benchmark that challenges LLMs to invoke multiple function calls as tools from 139 libraries and 7 domains for 1,140 fine-grained tasks. To evaluate LLMs rigorously, each task encompasses 5.6 test cases with an average branch coverage of 99%. In addition, we propose a natural-language-oriented variant of BigCodeBench, BigCodeBench-Instruct, that automatically transforms the original docstrings into short instructions containing only essential information. Our extensive evaluation of 60 LLMs shows thatLLMs are not yet capable of following complex instructions to use function calls precisely, with scores up to 60%, significantly lower than the human performance of 97%. The results underscore the need for further advancements in this area."
    },
    {
        "title": "Vevo: Controllable Zero-Shot Voice Imitation with Self-Supervised Disentanglement",
        "link_suffix": "/forum?id=anQDiQZhDP",
        "link": "https://openreview.net/forum?id=anQDiQZhDP",
        "pdf_link": "https://openreview.net/pdf?id=anQDiQZhDP",
        "keywords": "controllable speech generation, speech disentanglement, voice conversion, accent conversion, text to speech",
        "abstract": "The imitation of voice, targeted on specific speech attributes such as timbre and speaking style, is crucial in speech generation. However, existing methods rely heavily on annotated data, and struggle with effectively disentangling timbre and style, leading to challenges in achieving controllable generation, especially in zero-shot scenarios. To address these issues, we propose Vevo, a versatile zero-shot voice imitation framework with controllable timbre and style. Vevo operates in two core stages: (1) Content-Style Modeling: Given either text or speech's content tokens as input, we utilize an autoregressive transformer to generate the content-style tokens, which is prompted by a style reference; (2) Acoustic Modeling: Given the content-style tokens as input, we employ a flow-matching transformer to produce acoustic representations, which is prompted by a timbre reference. To obtain the content and content-style tokens of speech, we design a fully self-supervised approach that progressively decouples the timbre, style, and linguistic content of speech. Specifically, we adopt VQ-VAE as the tokenizer for the continuous hidden features of HuBERT. We treat the vocabulary size of the VQ-VAE codebook as the information bottleneck, and adjust it carefully to obtain the disentangled speech representations. Solely self-supervised trained on 60K hours of audiobook speech data, without any fine-tuning on style-specific corpora, Vevo matches or surpasses existing methods in accent and emotion conversion tasks. Additionally, Vevo\u2019s effectiveness in zero-shot voice conversion and text-to-speech tasks further demonstrates its strong generalization and versatility. Audio samples are available athttps://versavoice.github.io/."
    },
    {
        "title": "Benchmarking Mental State Representations in Language Models",
        "link_suffix": "/forum?id=6E0x0lVvh8",
        "link": "https://openreview.net/forum?id=6E0x0lVvh8",
        "pdf_link": "https://openreview.net/pdf?id=6E0x0lVvh8",
        "keywords": "language models, theory of mind, probing representations, activation editing",
        "abstract": "While numerous works have assessed the generative performance of language models (LMs) on tasks requiring Theory of Mind reasoning, research into the models' internal representation of mental states remains limited. Recent work has used probing to demonstrate that LMs can represent beliefs of themselves and others. However, these claims are accompanied by limited evaluation, making it difficult to assess how mental state representations are affected by model design and training choices. We report an extensive benchmark with various LM types with different model sizes, fine-tuning approaches, and prompt designs to study the robustness of mental state representations and memorisation issues within the probes. Our results show that the quality of models' internal representations of the beliefs of others increases with model size and, more crucially, with fine-tuning. We are the first to study how prompt variations impact probing performance on theory of mind tasks. We demonstrate that models' representations are sensitive to prompt variations, even when such variations should be beneficial. Finally, we complement previous activation editing experiments on Theory of Mind tasks and show that it is possible to improve models' reasoning performance by steering their activations without the need to train any probe."
    },
    {
        "title": "AVSET-10M: An Open Large-Scale Audio-Visual Dataset with High Correspondence",
        "link_suffix": "/forum?id=PdDm14eXO4",
        "link": "https://openreview.net/forum?id=PdDm14eXO4",
        "pdf_link": "https://openreview.net/pdf?id=PdDm14eXO4",
        "keywords": "udio-visual corresponding dataset, sound separation, audio-video retrieval",
        "abstract": "Recent research initiatives such as ChatGPT and Sora highlight the important role of large-scale data in advancing generative and comprehension tasks. However, the scarcity of comprehensive and large-scale audio-visual correspondence datasets poses a significant challenge to research in the audio-visual field. To address this gap, we introduceAVSET-10M, a high-correspondence audio-visual dataset comprising 10 million samples, featuring the following key attributes: (1)High Audio-Visual Correspondence: Through meticulous sample filtering, we ensure a strong correspondence between the audio and visual components of each entry. (2)Comprehensive Categories: Encompassing 527 unique audio categories, AVSET-10M provides a wide range of audio categories for diverse research needs. (3)Large Scale: With 10 million samples, AVSET-10M is one of the largest publicly available audio-visual correspondence datasets. We have benchmarked two critical tasks on AVSET-10M: audio-video retrieval and vision-queried sound separation. These tasks underscore the importance of precise audio-visual correspondence in advancing audio-visual research. For more information, please visit our demo page at \\url{https://avset-10m.github.io/}."
    },
    {
        "title": "Leveraging One-To-Many Relationships in Multimodal Adversarial Defense for Robust Image-Text Retrieval",
        "link_suffix": "/forum?id=63eIAvrWk4",
        "link": "https://openreview.net/forum?id=63eIAvrWk4",
        "pdf_link": "https://openreview.net/pdf?id=63eIAvrWk4",
        "keywords": "Image-Text Retrieval, Adversarial Defense, Vision-Language Model",
        "abstract": "Large pre-trained vision-language models (e.g., CLIP) are vulnerable to adversarial attacks in image-text retrieval (ITR). Existing works primarily focus on defense for image classification, overlooking two key aspects of ITR: multimodal manipulation by attackers, and the one-to-many relationship in ITR, where a single image can have multiple textual descriptions and vice versa (1:N and N:1). \nThis is the first work that explores defense strategies for robust ITR. \nWe demonstrate that our proposed multimodal adversarial training, which accounts for multimodal perturbations, significantly improves robustness against multimodal attacks; however, it suffers from overfitting to deterministic one-to-one (1:1) image-text pairs in the training data.\nTo address this, we conduct a conprehensive study on leveraging one-to-many relationships to enhances robustness, investigating diverse augmentation techniques.\nOur findings reveal that diversity and alignment of image-text pairs are crucial for effective defense.\nSpecifically, text augmentations outperform image augmentations, which tend to create either insufficient diversity or excessive distribution shifts. \nAdditionally, we find that cross-modal augmentations (e.g., $image \\rightarrow text$) can outperform intra-modal augmentations (e.g., $text \\rightarrow text$) due to generating well-aligned image-text pairs.\nIn summary, this work pioneers defense strategies for robust ITR, identifying critical aspects overlooked by prior research, and offers a promising direction for future studies."
    },
    {
        "title": "Designing Mechanical Meta-Materials by Learning Equivariant Flows",
        "link_suffix": "/forum?id=VMurwgAFWP",
        "link": "https://openreview.net/forum?id=VMurwgAFWP",
        "pdf_link": "https://openreview.net/pdf?id=VMurwgAFWP",
        "keywords": "neural network flow, equivariant flow, crystallographic symmetries, engineering design, meta-materials, cellular solids, differentiable simulator, nonlinear mechanics",
        "abstract": "Mechanical meta-materials are solids whose geometric structure results in exotic nonlinear behaviors that are not typically achievable via homogeneous materials. We show how to drastically expand the design space of a class of mechanical meta-materials known as $\\textit{cellular solids}$, by generalizing beyond translational symmetry. This is made possible by transforming a reference geometry according to a divergence free flow that is parameterized by a neural network and equivariant under the relevant symmetry group. We show how to construct flows equivariant to the space groups, despite the fact that these groups are not compact. Coupling this flow with a differentiable nonlinear mechanics simulator allows us to represent a much richer set of cellular solids than was previously possible. These materials can be optimized to exhibit desirable mechanical properties such as negative Poisson's ratios or to match target stress-strain curves. We validate these new designs in simulation and by fabricating real-world prototypes. We find that designs with higher-order symmetries can exhibit a wider range of behaviors."
    },
    {
        "title": "Stealing User Prompts from Mixture-of-Experts Models",
        "link_suffix": "/forum?id=1RNSYEEpwi",
        "link": "https://openreview.net/forum?id=1RNSYEEpwi",
        "pdf_link": "https://openreview.net/pdf?id=1RNSYEEpwi",
        "keywords": "Mixture-of-Experts, privacy, ml-security, information security, buffer overflow, leakage, exploit, token dropping",
        "abstract": "Mixture of Expert (MoE) models improve the efficiency and scalability of dense language models by \\emph{routing} each token to a small number of experts in each layer of the model. In this paper, we show how an adversary that can arrange for their queries to appear in the same batch of examples as a victim's queries can exploit expert-choice routing to the full disclosure of a victim's prompt. We successfully demonstrate the effectiveness of this attack on a two-layered Mixtral model. Our results show that we can extract the entire prompt using $\\mathcal{O}(\\text{Vocabulary size} \\times \\text{prompt length}^2)$ queries or a maximum of 100 queries per token in the setting we consider. Our work is the first of its kind data reconstruction attack that originates from in a flaw in the model architecture, as opposed to the model parameterization."
    },
    {
        "title": "Towards Understanding Link Predictor Generalizability Under Distribution Shifts",
        "link_suffix": "/forum?id=rQ8mHhEIeB",
        "link": "https://openreview.net/forum?id=rQ8mHhEIeB",
        "pdf_link": "https://openreview.net/pdf?id=rQ8mHhEIeB",
        "keywords": "Link Prediction, Graph-Structured Data, GNN4LP, Distribution Shifts, Structural Heuristics, Splitting Strategies",
        "abstract": "State-of-the-art link prediction (LP) models demonstrate impressive benchmark\nresults. However, popular benchmark datasets often assume that training, validation, and testing samples are representative of the overall dataset distribution. In\nreal-world situations, this assumption is often incorrect; since uncontrolled factors\nlead to the problem where new dataset samples come from different distributions\nthan training samples. The vast majority of recent work focuses on dataset shift\naffecting node- and graph-level tasks, largely ignoring link-level tasks. To bridge\nthis gap, we introduce a novel splitting strategy, known as LPShift, which utilizes\nstructural properties to induce a controlled distribution shift. We verify the effect of LPShift through empirical evaluation of SOTA LP methods on 16 LPShift\ngenerated splits of Open Graph Benchmark (OGB) datasets. When benchmarked\nwith LPShift datasets, GNN4LP methods frequently generalize worse than heuristics or basic GNNs. Furthermore, LP-specific generalization techniques do little\nto improve performance under LPShift. Finally, further analysis provides insight\non why LP models lose much of their architectural advantages under LPShift."
    },
    {
        "title": "Simulating Training Dynamics to Reconstruct Training Data from Deep Neural Networks",
        "link_suffix": "/forum?id=ZJftXKy12x",
        "link": "https://openreview.net/forum?id=ZJftXKy12x",
        "pdf_link": "https://openreview.net/pdf?id=ZJftXKy12x",
        "keywords": "Dataset reconstruction, Training dynamics, Memorization",
        "abstract": "Whether deep neural networks (DNNs) memorize the training data is a fundamental open question in understanding deep learning. A direct way to verify the memorization of DNNs is to reconstruct training data from DNNs' parameters. Since parameters are gradually determined by data throughout training, characterizing training dynamics is important for reconstruction. Pioneering works rely on the linear training dynamics of shallow NNs with large widths, but cannot be extended to more practical DNNs which have non-linear dynamics. We propose Simulation of training Dynamics (SimuDy) to reconstruct training data from DNNs. Specifically, we simulate the training dynamics by training the model from the initial parameters with a dummy dataset, then optimize this dummy dataset so that the simulated dynamics reach the same final parameters as the true dynamics. By incorporating dummy parameters in the simulated dynamics, SimuDy effectively describes non-linear training dynamics. Experiments demonstrate that SimuDy significantly outperforms previous approaches when handling non-linear training dynamics, and for the first time, most training samples can be reconstructed from a trained ResNet's parameters."
    },
    {
        "title": "XLand-100B: A Large-Scale Multi-Task Dataset for In-Context Reinforcement Learning",
        "link_suffix": "/forum?id=p9OsTj0nMP",
        "link": "https://openreview.net/forum?id=p9OsTj0nMP",
        "pdf_link": "https://openreview.net/pdf?id=p9OsTj0nMP",
        "keywords": "in-context reinforcement learning, reinforcement learning, xland, minigrid",
        "abstract": "Following the success of the in-context learning paradigm in large-scale language and computer vision models, the recently emerging field of in-context reinforcement learning is experiencing a rapid growth. However, its development has been held back by the lack of challenging benchmarks, as all the experiments have been carried out in simple environments and on small-scale datasets. We presentXLand-100B, a large-scale dataset for in-context reinforcement learning based on the XLand-MiniGrid environment, as a first step to alleviate this problem. It contains complete learning histories for nearly $30,000$ different tasks, covering $100$B transitions and $2.5$B episodes. It took $50,000$ GPU hours to collect the dataset, which is beyond the reach of most academic labs. Along with the dataset, we provide the utilities to reproduce or expand it even further. We also benchmark common in-context RL baselines and show that they struggle to generalize to novel and diverse tasks. With this substantial effort, we aim to democratize research in the rapidly growing field of in-context reinforcement learning and provide a solid foundation for further scaling."
    },
    {
        "title": "Geometric Neural Process Fields",
        "link_suffix": "/forum?id=abOksepKfS",
        "link": "https://openreview.net/forum?id=abOksepKfS",
        "pdf_link": "https://openreview.net/pdf?id=abOksepKfS",
        "keywords": "Implicit Neural Fields, Neural Processes, Generalization",
        "abstract": "This paper focuses on Implicit Neural Representation (INR) generalization, where models need to efficiently adapt to new signals with few observations. Specifically, for radiance field generalization, we propose Geometric Neural Processes (GeomNP) for probabilistic neural radiance field to explicitly capture uncertainty. We formulate INR generalization in a probabilistic manner, which incorporates uncertainty and directly infers the INR function distributions on limited context observations. To alleviate the information misalignment between the 2D context image and 3D discrete points in INR generalization, we introduce a set of geometric bases. The geometric bases learn to provide 3D structure information for inferring the INR function distributions. Based on the geometric bases, we model GeomNP with hierarchical latent variables. The latent variables integrate 3D information and modulate INR functions in different spatial levels, leading to better generalization of new scenes. Despite being designed for 3D tasks, the proposed method can seamlessly apply to 2D INR generalization problems. Experiments on novel view synthesis of 3D ShapeNet and DTU scenes, as well as 2D image regression, demonstrate the effectiveness of our method."
    },
    {
        "title": "Common Neighbor Induced Message Passing for Inductive Link Prediction in Knowledge Graphs",
        "link_suffix": "/forum?id=r0JfDTXAWx",
        "link": "https://openreview.net/forum?id=r0JfDTXAWx",
        "pdf_link": "https://openreview.net/pdf?id=r0JfDTXAWx",
        "keywords": "Inductive Link Prediction, Knowledge Graphs",
        "abstract": "Inductive link prediction is a significant challenge in knowledge graphs, focusing on predicting potential relations between unseen entities during training. A promising approach is to utilize Graph Neural Networks (GNNs) to extract entity-independent features from surrounding subgraphs. However, existing mainstream subgraph extraction methods may lead to the loss of key entities and relations, resulting in many disconnected reasoning paths that seriously hinder effective message passing. To address this challenge, we propose a novel framework called Common Neighbor Induced Message Passing (CNMP), designed to enhance message passing even when reasoning paths are disconnected. We observe that the common neighbors of two entities must share a reasoning path. Based on this insight, CNMP enhances message passing by updating the distance labels of isolated common neighbors, even if they are unreachable. This allows CNMP to incorporate new connected equivalent relations, facilitating effective message passing. Furthermore, we introduce a CNMP+ strategy that further improves the preservation of entities and relations during the message-passing process. CNMP+ involves maintaining a list of common neighbors at various distances and using a probing strategy to reconstruct complete reasoning paths. Experiments across multiple datasets demonstrate that our method significantly outperforms existing state-of-the-art methods."
    },
    {
        "title": "Towards a Complete Logical Framework for GNN Expressiveness",
        "link_suffix": "/forum?id=pqOjj90Vwp",
        "link": "https://openreview.net/forum?id=pqOjj90Vwp",
        "pdf_link": "https://openreview.net/pdf?id=pqOjj90Vwp",
        "keywords": "graph neural networks, logic",
        "abstract": "Designing expressive Graph neural networks (GNNs) is an important topic in graph machine learning fields. Traditionally, the Weisfeiler-Lehman (WL) test has been the primary measure for evaluating GNN expressiveness. However, high-order WL tests can be obscure, making it challenging to discern the specific graph patterns captured by them. Given the connection between WL tests and first-order logic, some have explored the logical expressiveness of Message Passing Neural Networks. This paper aims to establish a comprehensive and systematic relationship between GNNs and logic. We propose a framework for identifying the equivalent logical formulas for arbitrary GNN architectures, which not only explains existing models, but also provides inspiration for future research. As case studies, we analyze multiple classes of prominent GNNs within this framework, unifying different subareas of the field. Additionally, we conduct a detailed examination of homomorphism expressivity from a logical perspective and present a general method for determining the homomorphism expressivity of arbitrary GNN models, as well as addressing several open problems."
    },
    {
        "title": "How Far Are We from True Unlearnability?",
        "link_suffix": "/forum?id=I4Lq2RJ0eJ",
        "link": "https://openreview.net/forum?id=I4Lq2RJ0eJ",
        "pdf_link": "https://openreview.net/pdf?id=I4Lq2RJ0eJ",
        "keywords": "shortcut learning, unlearnable dataset, loss landscape",
        "abstract": "High-quality data plays an indispensable role in the era of large models, but the use of unauthorized data for model training greatly damages the interests of data owners. To overcome this threat, several unlearnable methods have been proposed, which generate unlearnable examples (UEs) by compromising the training availability of data. Clearly, due to unknown training purpose and the powerful representation learning capabilities of existing models, these data are expected to be unlearnable for various task models, i.e., they will not help improve the model's performance.  However, unexpectedly, we find that on the multi-task dataset Taskonomy, UEs still perform well in tasks such as semantic segmentation, failing to exhibit cross-task unlearnability. This phenomenon leads us to question: How far are we from attaining truly unlearnable examples? We attempt to answer this question from the perspective of model optimization. We observe the difference of convergence process between clean models and poisoned models on a simple model using the loss landscape and find that only a part of the critical parameter optimization paths show significant differences, implying a close relationship between the loss landscape and unlearnability. Consequently, we employ the loss landscape to explain the underlying reasons for UEs and propose Sharpness-Aware Learnability (SAL) for quantifying the unlearnability of parameters based on this explanation. Furthermore, we propose an Unlearnable Distance (UD) metric to measure the unlearnability of data based on the SAL distribution of parameters in clean and poisoned models. Finally, we conduct benchmark tests on mainstream unlearnable methods using the proposed UD, aiming to promote community awareness of the capability boundaries of existing unlearnable methods. The code is available athttps://github.com/MLsecurityLab/HowFarAreFromTrueUnlearnability.git."
    },
    {
        "title": "Bridging the Gap between Database Search and \\emph{De Novo} Peptide Sequencing with SearchNovo",
        "link_suffix": "/forum?id=SjMtxqdQ73",
        "link": "https://openreview.net/forum?id=SjMtxqdQ73",
        "pdf_link": "https://openreview.net/pdf?id=SjMtxqdQ73",
        "keywords": "Protein Identification",
        "abstract": "Accurate protein identification from mass spectrometry (MS) data is fundamental to unraveling the complex roles of proteins in biological systems, with peptide sequencing being a pivotal step in this process. The two main paradigms for peptide sequencing are database search, which matches experimental spectra with peptide sequences from databases, and \\emph{de novo} sequencing, which infers peptide sequences directly from MS without relying on pre-constructed database. Although database search methods are highly accurate, they are limited by their inability to identify novel, modified, or mutated peptides absent from the database. In contrast, \\emph{de novo} sequencing is adept at discovering novel peptides but often struggles with missing peaks issue, further leading to lower precision. We introduce SearchNovo, a novel framework that synergistically integrates the strengths of database search and \\emph{de novo} sequencing to enhance peptide sequencing. SearchNovo employs an efficient search mechanism to retrieve the most similar peptide spectrum match (PSM) from a database for each query spectrum, followed by a fusion module that utilizes the reference peptide sequence to guide the generation of the target sequence. Furthermore, we observed that dissimilar (noisy) reference peptides negatively affect model performance. To mitigate this, we constructed pseudo reference PSMs to minimize their impact. Comprehensive evaluations on multiple datasets reveal that SearchNovo significantly outperforms state-of-the-art models. Also, analysis indicates that many retrieved spectra contain missing peaks absent in the query spectra, and the retrieved reference peptides often share common fragments with the target peptides. These are key elements in the recipe for SearchNovo\u2019s success. The code for reproducing the results are available in the supplementary materials."
    },
    {
        "title": "Structure-Preserving Text-Based Editing for Few-Step Diffusion Models",
        "link_suffix": "/forum?id=FZaw83yo76",
        "link": "https://openreview.net/forum?id=FZaw83yo76",
        "pdf_link": "https://openreview.net/pdf?id=FZaw83yo76",
        "keywords": "Text-based image editing",
        "abstract": "Text-based image editing aims to generate an image that corresponds to the given text prompt, but with the structure of the original source image. Existing methods often rely on attention maps in diffusion models (DMs) for structure preservation, as these features are considered to play a primary role in determining the spatial layout. However, we find that these methods struggle to preserve the spatial layout when applied to few-step DMs (e.g., SDXL-Turbo), limiting their use cases to the slower multi-step DMs (e.g., Stable Diffusion). In this work, we investigate the limitations of these approaches in terms of intermediate feature representations. Our findings indicate that for few-step DMs, the attention layers have less influence in determining the structure. To tackle this, we localize layers within the network that better control spatial layout and inject these features during the editing process. Additionally, we disentangle structural information from other features to avoid conflicts between the injected features and the text prompt. This ensures that the edited image faithfully follows the prompt while preserving the source structure. Our method outperforms existing text-based editing baselines."
    },
    {
        "title": "One Pass Streaming Algorithm for Super Long Token Attention Approximation in Sublinear Space",
        "link_suffix": "/forum?id=rKMz6cDE7W",
        "link": "https://openreview.net/forum?id=rKMz6cDE7W",
        "pdf_link": "https://openreview.net/pdf?id=rKMz6cDE7W",
        "keywords": "streaming algorithm, efficient attention, super-long context",
        "abstract": "Attention computation takes both the time complexity of $O(n^2)$ and the space complexity of $O(n^2)$ simultaneously, which makes deploying Large Language Models (LLMs) in streaming applications that involve long contexts requiring substantial computational resources. In recent OpenAI DevDay (Nov 6, 2023), OpenAI released a new model that is able to support a 128K-long document, in our paper, we focus on the memory-efficient issue when context length $n$ is much greater than 128K ($n \\gg 2^d$). Considering a single-layer self-attention with Query, Key, and Value matrices $Q, K, V \\in \\mathbb{R}^{n \\times d}$, the polynomial method approximates the attention output $T \\in \\mathbb{R}^{n \\times d}$. It accomplishes this by constructing $U_1, U_2 \\in \\mathbb{R}^{n \\times t}$ to expedite attention ${\\sf Attn}(Q, K, V)$  computation within $n^{1+o(1)}$ time executions. Despite this, computing the approximated attention matrix $U_1U_2^\\top \\in \\mathbb{R}^{n \\times n}$ still necessitates $O(n^2)$ space, leading to significant memory usage. In response to these challenges, we introduce a new algorithm that only reads one pass of the data in a streaming fashion. This method employs sublinear space  $o(n)$ to store three sketch matrices, alleviating the need for exact $K, V$ storage. Notably, our algorithm exhibits exceptional memory-efficient performance with super-long tokens. As the token length $n$ increases, our error guarantee diminishes while the memory usage remains nearly constant. This unique attribute underscores the potential of our technique in efficiently handling LLMs in streaming applications."
    },
    {
        "title": "Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off",
        "link_suffix": "/forum?id=M9SKazbVkJ",
        "link": "https://openreview.net/forum?id=M9SKazbVkJ",
        "pdf_link": "https://openreview.net/pdf?id=M9SKazbVkJ",
        "keywords": "computer vision, adversarial defense, adversarial robustness, robustness-accuracy trade-off",
        "abstract": "Adversarial training often suffers from a robustness-accuracy trade-off, where achieving high robustness comes at the cost of accuracy.\nOne approach to mitigate this trade-off is leveraging invariance regularization, which encourages model invariance under adversarial perturbations; however, it still leads to accuracy loss.\nIn this work, we closely analyze the challenges of using invariance regularization in adversarial training and understand how to address them.\nOur analysis identifies two key issues: (1) a \"gradient conflict\" between invariance and classification objectives, leading to suboptimal convergence, and (2) the mixture distribution problem arising from diverged distributions between clean and adversarial inputs.\nTo address these issues, we propose Asymmetric Representation-regularized Adversarial Training (ARAT), which incorporates asymmetric invariance loss with stop-gradient operation and a predictor to avoid gradient conflict, and a split-BatchNorm (BN) structure to resolve the mixture distribution problem.\nOur detailed analysis demonstrates that each component effectively addresses the identified issues, offering novel insights into adversarial defense.\nARAT shows superiority over existing methods across various settings. Finally, we discuss the implications of our findings to knowledge distillation-based defenses, providing a new perspective on their relative successes."
    },
    {
        "title": "Latent Point Collapse Induces an Information Bottleneck in Deep Neural Network Classifiers",
        "link_suffix": "/forum?id=FwlM1k4ODx",
        "link": "https://openreview.net/forum?id=FwlM1k4ODx",
        "pdf_link": "https://openreview.net/pdf?id=FwlM1k4ODx",
        "keywords": "classification, regularization, information bottleneck, latent representations.",
        "abstract": "The information-bottleneck principle suggests that the foundation of learning lies in the ability to create compact representations. In machine learning, this goal can be formulated as a Lagrangian optimization problem, where the mutual information between the input and latent representations must be minimized without compromising the correctness of the model's predictions.\nUnfortunately, mutual information is difficult to compute in deterministic deep neural network classifiers, which greatly limits the application of this approach to challenging scenarios. In this paper, we tackle this problem from a different perspective that does not involve direct computation of the mutual information. We develop a method that induces the collapse of latent representations belonging to the same class into a single point. Such a point collapse yields a significant decrease in the entropy associated with the latent distribution, thereby creating an information bottleneck. Our method is straightforward to implement, and we demonstrate that it enhances the robustness, generalizability, and reliability of the network."
    }
]
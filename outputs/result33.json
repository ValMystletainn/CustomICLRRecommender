[{"title": "Multi-Marginal Stochastic Flow Matching for Alignment of High-Dimensional Snapshot Data at Irregular Time Points", "link_suffix": "/forum?id=IAfGax4tVT", "link": "https://openreview.net/forum?id=IAfGax4tVT", "pdf_link": "https://openreview.net/pdf?id=IAfGax4tVT", "keywords": "Multi-marginal Snapshot data flow matching, Measure-valued spline interpolation, Single-cell data, Optimal Transport", "abstract": "Modeling the evolution of high-dimensional systems from limited snapshot observations at irregular time points poses a significant challenge in quantitative biology and related fields. Traditional approaches often rely on dimensionality reduction techniques, which can oversimplify the dynamics and fail to capture critical transient behaviors in non-equilibrium systems. We present a novel extension of simulation-free score and flow matching methods to the multi-marginal setting, enabling the alignment of high-dimensional data measured at non-equidistant time points without reducing dimensionality. The use of measure-valued splines enhances robustness to irregular snapshot timing, and score matching prevents overfitting in high-dimensional spaces. We validate our framework on several synthetic and benchmark datasets and apply it to single-cell perturbation data from melanoma cell lines collected at uneven time points.", "title_embedding_index": 1600, "title_abs_embedding_index": 1625}, {"title": "MASIMU: Multi-Agent Speedy and Interpretable Machine Unlearning", "link_suffix": "/forum?id=BJfIDS5LsS", "link": "https://openreview.net/forum?id=BJfIDS5LsS", "pdf_link": "https://openreview.net/pdf?id=BJfIDS5LsS", "keywords": "multi-agent, unlearning, interpretable, faster, robust, MASIMU, LIME, reinforcement learning, explainable AI, XAI", "abstract": "The regulatory landscape around the use of personal data to train AI/ML models is rapidly evolving to protect privacy of sensitive information like user locations or medical data and improve AI trustworthiness. Practitioners must now provide the capability to unlearn or forget data---the forget set---that was used to train an AI model, without triggering a full model re-train on the remaining data---the retain set to be computationally efficient.  Existing unlearning approaches train via some combination of fine-tuning pre-trained AI models solely on the retain set, pruning model weights then unlearning, and model-sparsification-assisted unlearning. In our research paper, we use deep learning (DL), multi-agent reinforcement learning (MARL) and explainable AI (XAI) methods to formulate a faster, more robust and interpretable unlearning method than past works. Our method, multi-agent speedy and interpretable machine unlearning (MASIMU), fine-tunes a pre-trained model on the retain set, interpretably re-weighting the gradients of the fine-tuned loss function by computing the similarity influences of the forget set on the batched retain set based on weights generated by an XAI method.  We add a MARL framework on top to address the challenge of high dimensional training spaces by having multiple agents learning to communicate positional beliefs and navigate in image environments. The per-agent observation spaces have lower dimensions, leading to the agents focusing on unlearning interpretable gradients of important superpixels that influence the target labels in the learning criteria.  We provide extensive experiments on four datasets---CIFAR-10, MNIST, high resolution satellite images in RESISC-45, skin cancer images in HAM-10000 to unlearn for preserving medical privacy---computing robustness, interpretability, and speed relative to the dimensionality of the training features, and find that MASIMU outcompetes other unlearning methods.", "title_embedding_index": 1601, "title_abs_embedding_index": 1626}, {"title": "RL3: Boosting Meta Reinforcement Learning via RL inside RL2", "link_suffix": "/forum?id=fEEbTDoecM", "link": "https://openreview.net/forum?id=fEEbTDoecM", "pdf_link": "https://openreview.net/pdf?id=fEEbTDoecM", "keywords": "meta-reinforcement learning", "abstract": "Meta reinforcement learning (meta-RL) methods such as \\rlsquare have emerged as promising approaches for learning data-efficient RL algorithms tailored to a given task distribution. However, they show poor asymptotic performance and struggle with out-of-distribution tasks because they rely on sequence models, such as recurrent neural networks or transformers, to process experiences rather than summarize them using general-purpose RL components such as value functions. In contrast, traditional RL algorithms are data-inefficient as they do not use domain knowledge, but do converge to an optimal policy in the limit. We propose RL$^3$, a principled hybrid approach that incorporates action-values, learned per task via traditional RL, in the inputs to meta-RL. We show that RL$^3$ earns greater cumulative reward in the long term compared to RL$^2$ while drastically reducing meta-training time and generalizes better to out-of-distribution tasks. Experiments are conducted on both custom and benchmark discrete domains from the meta-RL literature that exhibit a range of short-term, long-term, and complex dependencies.", "title_embedding_index": 1602, "title_abs_embedding_index": 1627}, {"title": "Generalist Policy for k-Server Problem on Graphs using Deep Reinforcement Learning with Action-Value Decomposition", "link_suffix": "/forum?id=gCSEQIgbWH", "link": "https://openreview.net/forum?id=gCSEQIgbWH", "pdf_link": "https://openreview.net/pdf?id=gCSEQIgbWH", "keywords": "reinforcement learning, graph neural network, k-server problem, deep learning, graph convolution, transportation", "abstract": "The online $k$-server problem on graphs is a fundamental computational problem that can model a wide range of practical problems, such as dispatching ambulances to serve accidents or dispatching taxis to serve ride requests. While most prior work on the $k$-server problem focused on online algorithms, reinforcement learning promises policies that require low computational effort during execution, which is critical in time-sensitive applications, such as ambulance dispatch. However, there exists no scalable reinforcement-learning approach for the $k$-server problem. To address this gap, we introduce a scalable computational approach for learning generalist policies. Besides scalability, the advantage of generalist policies is transferability: a generalist policy can be applied to an entire class of graphs without the need for retraining, which is crucial for practical applications, e.g., in ambulance dispatch problems where road conditions or demand distributions may change over time. We achieve scalability and transferability by introducing a novel architecture that decomposes the action-value into a global and a local term, estimated from a shared graph-convolution backbone. We evaluate our approach on a variety of graph classes, comparing to well-established baselines, demonstrating the performance and transferability of our generalist policies.", "title_embedding_index": 1603, "title_abs_embedding_index": 1628}, {"title": "Self-Explained Keywords Empower Large Language Models for Code Generation", "link_suffix": "/forum?id=98ASXp6oPg", "link": "https://openreview.net/forum?id=98ASXp6oPg", "pdf_link": "https://openreview.net/pdf?id=98ASXp6oPg", "keywords": "Large Language Model, Code Generation, Prompt Engineering", "abstract": "Large language models (LLMs) have achieved impressive performance in code generation.  However, due to the long-tail distribution of LLMs' training data, low-frequency terms are typically underrepresented in the training process. Consequently, LLMs often misunderstand or overlook problem-specific, low-frequency keywords during code generation, compromising the accuracy of the generated code. To address this, we propose a novel technique named SEK (Self-Explained Keywords), which empowers an LLM for better code generation by extracting and explaining the key terms in the problem description with the LLM itself and ranking them based on frequency. Comprehensive experiments across three benchmarks, i.e., HumanEval(+), MBPP(+), and APPS, with five representative LLMs, show that SEK can significantly improve LLMs in code generation, yielding substantial and consistent gains. For instance, SEK improves the Pass@1 of DeepSeek-Coder-V2-Instruct from 85.4% to 93.3% on the Humaneval benchmark. Further analysis confirms that SEK enables the LLMs to shift their attention from low-frequency keywords to their corresponding high-frequency counterparts.", "title_embedding_index": 1604, "title_abs_embedding_index": 1629}, {"title": "Uniform Wrappers: Bridging Concave to Quadratizable Functions in Online Optimization", "link_suffix": "/forum?id=rbdlQE7HY7", "link": "https://openreview.net/forum?id=rbdlQE7HY7", "pdf_link": "https://openreview.net/pdf?id=rbdlQE7HY7", "keywords": "DR-submodular Optimization, Convex Optimization", "abstract": "This paper presents novel contributions to the field of online optimization, particularly focusing on the adaptation of algorithms from concave optimization to more challenging classes of functions. Key contributions include the introduction of uniform wrappers, establishing a vital link between upper-quadratizable functions and algorithmic conversions. Through this framework, the paper demonstrates superior regret guarantees for various classes of up-concave functions under zeroth-order feedback. Furthermore, the paper extends zeroth-order online algorithms to bandit feedback counterparts and offline counterparts, achieving a notable improvement in regret/sample complexity compared to existing approaches.", "title_embedding_index": 1605, "title_abs_embedding_index": 1630}, {"title": "A Dual-Modal Framework Utilizing Visual Prompts for Enhanced Patch Analysis", "link_suffix": "/forum?id=OXIIFZqiiN", "link": "https://openreview.net/forum?id=OXIIFZqiiN", "pdf_link": "https://openreview.net/pdf?id=OXIIFZqiiN", "keywords": "Code Generation, Domain Adaptation", "abstract": "Patch representation learning has emerged as a crucial innovation in software development, leveraging machine learning techniques to advance software generation workflows. This approach has led to significant enhancements across various applications involving code alterations. However, existing methods often exhibit a tendency towards specialization, excelling predominantly in either predictive tasks such as security patch classification or in generative tasks like the automated creation of patch descriptions. This paper presents a groundbreaking approach to patch representation learning through the Image-Guided Code Patch Framework (IGCP), a novel architecture that bridges the gap between code analysis and image processing domains. We introduce a rigorous mathematical foundation for IGCP, leveraging measure theory, functional analysis, and information geometry to formalize the domain adaptation process in patch representation learning. The optimization dynamics of IGCP are rigorously analyzed through the lens of Stochastic Gradient Langevin Dynamics, providing convergence guarantees in both convex and non-convex loss landscapes. Empirical evaluations demonstrate that IGCP not only achieves state-of-the-art performance in patch description generation but also exhibits remarkable domain generalization capabilities.", "title_embedding_index": 1606, "title_abs_embedding_index": 1631}, {"title": "HyperDAS: Towards Automating Mechanistic Interpretability with Hypernetworks", "link_suffix": "/forum?id=6fDjUoEQvm", "link": "https://openreview.net/forum?id=6fDjUoEQvm", "pdf_link": "https://openreview.net/pdf?id=6fDjUoEQvm", "keywords": "mechanistic interpretability, causal abstraction, hypernetwork", "abstract": "Mechanistic interpretability has made great strides in identifying features (e.g., directions in activation space) of neural network hidden representations that mediate concepts (e.g., the birth year of a nobel laureate). Distributed alignment search (DAS) leverages supervision from counterfactual data to learn concept features, but still requires a brute-force search through potential hidden representations.\nWe present HyperDAS, a transformer-based hypernetwork architecture that (1) automatically locates the token-positions of the residual stream that a concept is realized in and (2) learns features of those residual stream vectors for the concept. HyperDAS achieves state-of-the-art performance on the RAVEL benchmark for disentangling concepts in the feature space of a hidden representation of Llama3-8B.\nWe conclude with a discussion of how we constrained HyperDAS to reveal causal structure rather than simulate the structure via steering.", "title_embedding_index": 1607, "title_abs_embedding_index": 1632}, {"title": "Bridging Visual Communication and Data Exploration through Pose-Driven Query Synthesis", "link_suffix": "/forum?id=lMW9d1AqC9", "link": "https://openreview.net/forum?id=lMW9d1AqC9", "pdf_link": "https://openreview.net/pdf?id=lMW9d1AqC9", "keywords": "Code Completion, Transfer Learning", "abstract": "SQL is widely used for managing relational databases and conducting interactive data analysis. Now, various natural language interfaces have emerged, designed to simplify the process of crafting SQL queries by translating natural language commands into executable SQL-Code. However, the communication preferences of the deaf and hard-of-hearing community have been largely overlooked. \nThis paper introduces R-KinetiQuery, a groundbreaking framework for domain-adaptive sign language to SQL query translation, underpinned by a rigorous mathematical foundation synthesizing functional analysis, ergodic theory, and information geometry. At its core, R-KinetiQuery addresses the fundamental challenge of domain adaptation in the context of multimodal language translation, specifically tailored to bridge the gap between sign language communication and database query languages. A key innovation lies in our application of ergodic theory to analyze the long-term behavior of R-KinetiQuery under domain shift. We establish an ergodic theorem for the model's time-averaged operator, demonstrating its convergence to the expected behavior across domains. This result provides a robust foundation for the model's stability and adaptability in non-stationary environments. Our information-theoretic analysis reveals a deep connection between R-KinetiQuery and the Information Bottleneck principle. We derive a variational bound that explicitly quantifies the trade-off between compression and prediction in the model's latent representation, providing insights into its domain-invariant feature learning.\nEmpirically, we demonstrate R-KinetiQuery's superior performance on a diverse set of domain adaptation tasks, consistently outperforming state-of-the-art baselines. Our experiments span a wide range of domain shifts, from subtle variations in sign language dialects to dramatic changes in database schemas and query complexities.", "title_embedding_index": 1608, "title_abs_embedding_index": 1633}, {"title": "Incorporating gauge-invariance in equivariant networks", "link_suffix": "/forum?id=YAINolpm8n", "link": "https://openreview.net/forum?id=YAINolpm8n", "pdf_link": "https://openreview.net/pdf?id=YAINolpm8n", "keywords": "gauge-invariance, gauge theories, equivariance", "abstract": "Gauge theories, which describe fundamental forces in nature, arise from the principle of locality in physical interactions. These theories are characterized by their invariance under local symmetry transformations and the presence of a gauge field that mediates interactions. While recent works have introduced gauge equivariant neural networks, these models often focus on specific cases like tangent bundles or quotient spaces, limiting their applicability to the diverse gauge theories in physics. We propose a novel architecture for learning general gauge invariant quantities by explicitly modeling the gauge field in the context of graph neural networks. Our framework fills a critical gap in the existing literature by providing a general recipe for gauge invariance without restrictions on the fiber spaces. This approach allows for the modeling of more complex gauge theories, such as those with $SU(N)$ gauge groups, which are prevalent in particle physics. We evaluate our method on classical physical systems, including the XY model on various curved geometries, demonstrating its ability to capture gauge invariant properties in settings where existing equivariant architectures fall short. Our work takes a significant step towards bridging the gap between gauge theories in physics and equivariant neural network architectures, opening new avenues for applying machine learning to fundamental physical problems.", "title_embedding_index": 1609, "title_abs_embedding_index": 1634}, {"title": "Annotation Bootstrapping: Reinforcing Visual Pre-Training using Unlabelled Images", "link_suffix": "/forum?id=PD8JVDg8mB", "link": "https://openreview.net/forum?id=PD8JVDg8mB", "pdf_link": "https://openreview.net/pdf?id=PD8JVDg8mB", "keywords": "visual pretraining, self supervised learning, bootstrapping", "abstract": "A common approach to learning from unlabeled images is to train models to satisfy invariances on these images, such as consistency under augmentations or crops. Despite successes on Imagenet, these approaches struggle to learn from larger uncurated datasets like web crawls or video, where such inductive biases only weakly hold. How can we more effectively learn from broader datasets? Instead of training models to be invariant across views, we study an alternative approach encouraging model representations to be \\textit{predictive} of important semantics of adjacent views of an image. We concurrently train a model to predict semantic annotations from images (generated either self-supervised, or from auxiliary datasets); and bootstrap the model's semantics by predicting, given a cropped view of an image and the coordinates for a nearby crop, the model's annotation distribution for the neighboring view.  A core strength of this approach is the ability to extract information universally from both unlabelled and labelled image data, incorporating captions, bounding boxes, and other annotations when they are present. Our experiments show that annotation propagation improves pre-training on unlabelled datasets in the wild, including video datasets like EpicKitchens, scene datasets like COCO, and uncurated web-scale image datasets like CC12M.", "title_embedding_index": 1610, "title_abs_embedding_index": 1635}, {"title": "AccCtr: Accelerating Training-Free  Control For Text-to-Image Diffusion Models", "link_suffix": "/forum?id=Trn4Hji6iH", "link": "https://openreview.net/forum?id=Trn4Hji6iH", "pdf_link": "https://openreview.net/pdf?id=Trn4Hji6iH", "keywords": "accelerating, Training-Free, diffusion model", "abstract": "In training-free Conditional Diffusion Models (CDMs), the sampling process is steered by the gradient of the loss $\\mathcal{E}(\\dmrv{y}, \\dmrv{z}, \\dmfv{C}{\\dmv{psi}} )$, which assesses the gap between the guidance $\\dmrv{y}$ and the condition extracted from the intermediate outputs. Here the condition extraction network $\\dmfv{C}{\\dmv{psi}}(\\cdot)$, which could be a segmentation or depth estimation network, is pre-trained for training-free purpose. However, existing methods often require small guidance steps, leading to longer sampling times. We introduce an alternative maximization framework to scrutinize training-free CDMs that tackles slow sampling. Our framework pinpoints manifold deviation as the key factor behind the sluggish sampling. More iterations are needed for the sampling process to closely follow the image manifold and reach the target conditions, as the loss gradient doesn't provide sufficient guidance for larger steps. To improve this, we suggest retraining the condition extraction network $\\dmfv{C}_{\\dmv{psi}}(\\cdot)$ to refine the  loss's guidance, thereby introducing our AccCtr. This retraining process is simple, and integrating AccCtr into current CDMs is a seamless task that does not impose a significant computational burden. Extensive testing has demonstrated that AccCtr significantly boosts performance, offering superior sample quality and faster generation times across a variety of conditional generation tasks.", "title_embedding_index": 1611, "title_abs_embedding_index": 1636}, {"title": "MIND THE GAP: ALIGNING THE BRAIN WITH LANGUAGE MODELS REQUIRES A NONLINEAR AND MULTIMODAL APPROACH", "link_suffix": "/forum?id=hgBVVAJ1ym", "link": "https://openreview.net/forum?id=hgBVVAJ1ym", "pdf_link": "https://openreview.net/pdf?id=hgBVVAJ1ym", "keywords": "fMRI language encoding, brain LLM alignment, neuroscience, large language models, neurolinguistics", "abstract": "Speech comprehension involves complex, nonlinear, and multimodal processes within the brain, integrating auditory signals with linguistic and semantic information across widespread neural networks in the brain. Traditional brain encoding models, often relying on linear mappings from unimodal features, fall short in representing these intricate mechanisms. In this study, we introduce a nonlinear, multimodal encoding model that leverages both audio and linguistic features extracted from pre-trained deep learning models (LLAMA and Whisper). Our approach significantly outperforms previous linear encoding models, achieving a 17.2% increase in prediction accuracy and predicting 34.3% of the brain's explainable variance. Moreover, this enhanced performance reveals novel insights into the brain's functional organization, demonstrating nonlinear integration of auditory and semantic information within regions associated with motor control, somatosensory processing, and higher-level semantic representation. Our findings provide empirical support for existing theories in neurolinguistics, including the Motor Theory of Speech Perception, embodied semantic memory, and the Convergence Zone model, revealing novel insights into neural mechanisms otherwise impossible with simpler encoder models. This study highlights the critical importance of incorporating nonlinearity and multimodality in brain encoding models, paving the way for more accurate, brain-aligned models.", "title_embedding_index": 1612, "title_abs_embedding_index": 1637}, {"title": "Reformer: A Deep Learning Model for Runtime Selection of Convolution Kernels", "link_suffix": "/forum?id=m2kJuN1bKt", "link": "https://openreview.net/forum?id=m2kJuN1bKt", "pdf_link": "https://openreview.net/pdf?id=m2kJuN1bKt", "keywords": "Reformer, Kernel Selection, Kernel Optimization", "abstract": "As neural networks grow larger, optimizing GPU kernel selection becomes increasingly essential to minimizing the time, cost, and energy demands of model training and inference. Current methods rely on hand-written rules-based heuristics, which often yield suboptimal performance, are labor-intensive to develop, and are difficult to adapt across hardware architectures and firmware releases. In this paper, we frame kernel selection as a sequence classification problem solved on the CPU, thereby leaving GPU resources free for user training and inference tasks. Traditional transformers are less effective in this context because CPU deployment limits the advantages of parallelism in attention mechanisms. In this regard, we propose the $\\Gamma$-block, which performs only three matmul operations compared to the six required by a transformer block, while maintaining the same depth in terms of learnable layers. Our experiments on the IMDB and Reuters datasets demonstrate that a small model based on the $\\Gamma$-block delivers comparable sequence classification accuracy to a similar model based on transformer blocks, while also providing faster inference times on the CPU. By stacking multiple $\\Gamma$-blocks, we develop a lightweight model for kernel selection, named Reformer. To train the model, we propose a novel approach that assigns optimality probabilities to kernels based on their runtimes, offering a more robust alternative to one-hot probabilities. We demonstrate the effectiveness of Reformer by integrating it into MIOpen for convolution kernel selection, achieving an average speed-up of approximately 3x in convolution operations on the AMD Instinct$\\texttrademark$ MI100 GPU.", "title_embedding_index": 1613, "title_abs_embedding_index": 1638}, {"title": "An Empirical Study of Deep Reinforcement Learning in Continuing Tasks", "link_suffix": "/forum?id=kHfIuagAq6", "link": "https://openreview.net/forum?id=kHfIuagAq6", "pdf_link": "https://openreview.net/pdf?id=kHfIuagAq6", "keywords": "reinforcement learning, continuing tasks, empirical study", "abstract": "In reinforcement learning (RL), continuing tasks refer to tasks where the agent-environment interaction is ongoing and can not be broken down into episodes. These tasks are suitable when environment resets are unavailable, agent-controlled, or predefined but where all rewards\u2014including those beyond resets\u2014are critical. These scenarios frequently occur in real-world applications and can not be modeled by episodic tasks. While modern deep RL algorithms have been extensively studied and well understood in episodic tasks, their behavior in continuing tasks remains underexplored. To address this gap, we provide an empirical study of several well-known deep RL algorithms using a suite of continuing task testbeds based on Mujoco and Atari environments, highlighting several key insights concerning continuing tasks. Using these testbeds, we also investigate the effectiveness of a method for improving temporal-difference-based reinforcement learning (RL) algorithms in continuing tasks by centering rewards, as introduced by \\citet{naik2024reward}. While their work primarily focused on this method in conjunction with Q-learning, our results extend their findings by demonstrating that this method is effective across a broader range of algorithms, scales to larger tasks, and outperforms two other reward-centering approaches.", "title_embedding_index": 1614, "title_abs_embedding_index": 1639}, {"title": "Improving Fairness and Mitigating MADness in Generative Models", "link_suffix": "/forum?id=tL8dpJmECp", "link": "https://openreview.net/forum?id=tL8dpJmECp", "pdf_link": "https://openreview.net/pdf?id=tL8dpJmECp", "keywords": "Hypernetworks, Generative Models, Fairness, MADness, Maximum Likelihood Estimation, Bias", "abstract": "Generative models unfairly penalize data belonging to minority classes, suffer from model autophagy disorder (MADness), and learn biased estimates of the underlying distribution parameters.  Our theoretical and empirical results show that training generative models with intentionally designed hypernetworks leads to models that 1) are more fair when generating datapoints belonging to minority classes 2) are more stable in a self-consumed (i.e., MAD) setting, and 3) learn parameters that are less statistically biased.  To further mitigate unfairness, MADness, and bias, we introduce a regularization term that penalizes discrepancies between a generative model\u2019s estimated weights when trained on real data versus its own synthetic data.  To facilitate training existing deep generative models within our framework, we offer a scalable implementation of hypernetworks that automatically generates a hypernetwork architecture for any given generative model.", "title_embedding_index": 1615, "title_abs_embedding_index": 1640}, {"title": "Watchmaker Functions and Meta Specification of Open-Ended Learning Systems", "link_suffix": "/forum?id=RrIjnSMhMZ", "link": "https://openreview.net/forum?id=RrIjnSMhMZ", "pdf_link": "https://openreview.net/pdf?id=RrIjnSMhMZ", "keywords": "Open-ended learning systems", "abstract": "Open-ended learning systems aim to foster the continuous evolution of increasingly capable agents through the dynamic generation of novel challenges. The efficacy of these systems is fundamentally influenced by two critical factors: the design of the underlying system, which delineates the space of possibilities, and the open-ended algorithms that drive ongoing progress within this space. Current approaches to system design rely on explicit specification, where state spaces and evolution functions are fully defined at design time, often leading to prohibitive design complexity as systems scale. To address this challenge, we propose an alternative design principle termedmeta specification. This approach defines systems implicitly through constraints, utilizingwatchmaker functions\u2014generalized stochastic evolution functions\u2014coupled with verification routines to perform system evolution. Meta specification principles have the potential to significantly expand the space of possibilities while reducing design complexity, thereby enhancing the potential for open-ended learning. We demonstrate the viability of this principle through an illustrative implementation that co-evolves robot morphologies and robotic tasks, showcasing its capacity for emergent novelty and highlighting the shift in focus towards verification in system design.", "title_embedding_index": 1616, "title_abs_embedding_index": 1641}, {"title": "GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models", "link_suffix": "/forum?id=AjXkRZIvjB", "link": "https://openreview.net/forum?id=AjXkRZIvjB", "pdf_link": "https://openreview.net/pdf?id=AjXkRZIvjB", "keywords": "Reasoning, Large Language Models, Mathematical Reasoning, Datasets", "abstract": "Recent advancements in Large Language Models (LLMs) have sparked interest in their formal reasoning capabilities, particularly in mathematics. The GSM8K benchmark is widely used to assess the mathematical reasoning of models on grade-school-level questions. While the performance of LLMs on GSM8K has significantly improved in recent years, it remains unclear whether their mathematical reasoning capabilities have genuinely advanced, raising questions about the reliability of the reported metrics. To address these concerns, we conduct a large-scale study on several state-of-the-art open and closed models. To overcome the limitations of existing evaluations, we introduce GSM-Symbolic, an improved benchmark created from symbolic templates that allow for the generation of a diverse set of questions. GSM-Symbolic enables more controllable evaluations, providing key insights and more reliable metrics for measuring the reasoning capabilities of models. Our findings reveal that LLMs exhibit noticeable variance when responding to different instantiations of the same question. Specifically, the performance of all models declines when only the numerical values in the question are altered in the GSM-Symbolic benchmark. Furthermore, we investigate the fragility of mathematical reasoning in these models and demonstrate that their performance significantly deteriorates as the number of clauses in a question increases. We hypothesize that this decline is due to the fact that current LLMs are not capable of genuine logical reasoning; instead, they attempt to replicate the reasoning steps observed in their training data. When we add a single clause that appears relevant to the question, we observe significant performance drops (up to 65%) across all state-of-the-art models, even though the added clause does not contribute to the reasoning chain needed to reach the final answer. Overall, our work provides a more nuanced understanding of LLMs' capabilities and limitations in mathematical reasoning.", "title_embedding_index": 1617, "title_abs_embedding_index": 1642}, {"title": "Generating All-Atom Protein Structure from Sequence-Only Training Data", "link_suffix": "/forum?id=6PEbll1C0M", "link": "https://openreview.net/forum?id=6PEbll1C0M", "pdf_link": "https://openreview.net/pdf?id=6PEbll1C0M", "keywords": "proteins, ml for protein engineering, generative models, latent diffusion", "abstract": "Despite growing interest in using generative models to design proteins with useful properties,\nall-atom structure generation remains challenging, because it requires simultaneously generating the 3D protein structure and 1D sequence to specify which side chain atoms to place.\nTo address this multimodal generation problem, we propose PLAID (Protein LAtent Induced Diffusion), a paradigm for multimodal protein generation by learning and sampling from the latent space of protein folding models.\nCrucially, since only sequence inputs are required to obtain the latent representation during training, we can augment the usable training dataset by $10^2\\times$ to $10^4\\times$ compared to experimental structure databases.\nFurthermore, sequence-only training makes more annotations available, allowing access to more specialized labels that are of interest in bioengineering.\nWe demonstrate this by controllably generating proteins with respect to two conditioning variables: 2219 function keywords from the Gene Ontology database, and 3617 organisms across the tree of life.", "title_embedding_index": 1618, "title_abs_embedding_index": 1643}, {"title": "Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse", "link_suffix": "/forum?id=rpbzBXdo4x", "link": "https://openreview.net/forum?id=rpbzBXdo4x", "pdf_link": "https://openreview.net/pdf?id=rpbzBXdo4x", "keywords": "chain of thought, psychology, overthinking", "abstract": "Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open question in what settings CoT systematically reduces model performance. In this paper, we seek to identify the characteristics of tasks where CoT reduces performance by drawing inspiration from cognitive psychology, looking at cases where (i) verbal thinking or deliberation hurts performance in humans, and (ii) the constraints governing human performance generalize to language models. Three such cases are implicit statistical learning, visual recognition, and classifying with patterns containing exceptions. In extensive experiments across all three settings, we find that a diverse collection of state-of-the-art models exhibit significant drop-offs in performance (e.g., up to 36.3% absolute accuracy for GPT-o1 compared to GPT-4o) when using CoT compared to zero-shot counterparts. We also identify three tasks that satisfy condition (i) but not (ii), and find that while verbal thinking reduces human performance in these tasks, CoT retains or increases model performance. Overall, our results show that even though there is not an exact parallel between the cognitive processes of models and those of humans, considering cases where thinking has negative consequences for human performance can help us identify settings where it has negative consequences for models. By connecting the literature on human deliberation with evaluation of CoT, we offer a new tool that can be used in understanding the impact of prompt choices and inference-time reasoning.", "title_embedding_index": 1619, "title_abs_embedding_index": 1644}, {"title": "TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models", "link_suffix": "/forum?id=VWBYDo5NaM", "link": "https://openreview.net/forum?id=VWBYDo5NaM", "pdf_link": "https://openreview.net/pdf?id=VWBYDo5NaM", "keywords": "Natural language explanations, graph neural networks, text-attributed graphs", "abstract": "Representation learning of Text-Attributed Graphs (TAGs) has garnered significant attention due to its applications in various domains, including recommendation systems and social networks. Despite advancements in TAG learning methodologies, challenges remain in explainability due to the black-box nature of existing TAG representation learning models. This paper presents TAGExplainer, the first method designed to generate natural language explanations for TAG learning. TAGExplainer employs a generative language model that maps input-output pairs to explanations reflecting the model's decision-making process. To address the lack of annotated ground truth explanations in real-world scenarios, we propose first generating pseudo-labels that capture the model's decisions from saliency-based explanations, then the pseudo-label generator is iteratively trained based on three training objectives focusing on faithfulness and brevity via Expert Iteration, to improve the quality of generated pseudo-labels. The high-quality pseudo-labels are finally utilized to train an end-to-end explanation generator model. Extensive experiments are conducted to demonstrate the effectiveness of TAGExplainer in producing faithful and concise natural language explanations.", "title_embedding_index": 1620, "title_abs_embedding_index": 1645}, {"title": "The Effect of Personalization in FedProx: A Fine-grained Analysis on Statistical Accuracy and Communication Efficiency", "link_suffix": "/forum?id=aQSbfKYXvo", "link": "https://openreview.net/forum?id=aQSbfKYXvo", "pdf_link": "https://openreview.net/pdf?id=aQSbfKYXvo", "keywords": "Personalized Federated Learning, Statistical Complexity, Communication Complexity, Minimax Optimality", "abstract": "FedProx is a simple yet effective federated learning method that enables model personalization via regularization. Despite remarkable success in practice, a rigorous analysis of how such a regularization provably improves the statistical accuracy of each client's local model hasn't been fully established. Setting the regularization strength heuristically presents a risk, as an inappropriate choice may even degrade accuracy. This work fills in the gap by analyzing the effect of regularization on statistical accuracy, thereby providing a theoretical guideline for setting the regularization strength for achieving personalization. We prove that by adaptively choosing the regularization strength under different statistical heterogeneity, FedProx can consistently outperform pure local training and achieve a nearly minimax-optimal statistical rate. In addition, to shed light on resource allocation, we design an algorithm, provably showing that stronger personalization reduces communication complexity without increasing the computation cost overhead. Finally, our theory is validated on both synthetic and real-world datasets and its generalizability is verified in a non-convex setting.", "title_embedding_index": 1621, "title_abs_embedding_index": 1646}, {"title": "Advancing Algorithmic Trading with Large Language Models: A Reinforcement Learning Approach for Stock Market Optimization", "link_suffix": "/forum?id=w7BGq6ozOL", "link": "https://openreview.net/forum?id=w7BGq6ozOL", "pdf_link": "https://openreview.net/pdf?id=w7BGq6ozOL", "keywords": "Algorithmic trading, Stock market, Large language models, Deep reinforcement learning", "abstract": "In the fast-evolving landscape of financial markets, effective decision-making tools are essential for managing complexities driven by economic indicators and market dynamics. Algorithmic trading strategies have gained prominence for their ability to execute trades autonomously, with Deep Reinforcement Learning (DRL) emerging as a key approach for optimizing trading actions through continuous market interaction. However, RL-based systems face significant challenges, particularly in adapting to evolving time series data and incorporating unstructured textual information. In response to these limitations, recent advancements in Large Language Models (LLMs) offer new opportunities. LLMs possess the capacity to analyze vast volumes of data, providing enhanced insights that can complement traditional market analysis. This study proposes a novel approach that integrates six distinct LLMs into algorithmic trading frameworks, developing Stock-Evol-Instruct, an innovative instruction generation algorithm. This algorithm enables RL agents to fine-tune their trading strategies by leveraging LLM-driven insights for daily stock trading decisions. Empirical evaluation using real-world stock data from Silver and JPMorgan demonstrates the significant potential of this approach to outperform conventional trading models. By bridging the gap between LLMs and RL in algorithmic trading, this study contributes to a new frontier in financial technology, setting the stage for future advancements in autonomous trading systems.", "title_embedding_index": 1622, "title_abs_embedding_index": 1647}, {"title": "Roadmap towards Superhuman Speech Understanding using Large Language Models", "link_suffix": "/forum?id=Pnr8XNWcY0", "link": "https://openreview.net/forum?id=Pnr8XNWcY0", "pdf_link": "https://openreview.net/pdf?id=Pnr8XNWcY0", "keywords": "Large langauge models; speech language models;", "abstract": "The success of large language models (LLMs) has prompted efforts to integrate speech and audio data, aiming to create general foundation models capable of processing both textual and non-textual inputs. Recent advances, such as GPT-4o, highlight the potential for end-to-end speech LLMs, which preserves non-semantic information and  world knowledge for deeper speech understanding.\nTo guide the development of speech LLMs, we propose a five-level roadmap, ranging from basic automatic speech recognition (ASR) to advanced superhuman models capable of integrating non-semantic information with abstract acoustic knowledge for complex tasks. \nMoreover, we design a  benchmark, \\textbf{SAGI Bechmark}, that standardizes critical aspects across various tasks in these five levels, uncovering challenges in using abstract acoustic knowledge and completeness of capability. Our findings reveal gaps in handling paralinguistic cues and abstract acoustic knowledge, and we offer future directions. This paper outlines a roadmap for advancing speech LLMs, introduces a benchmark for evaluation, and provides key insights into their current limitations and potential.", "title_embedding_index": 1623, "title_abs_embedding_index": 1648}, {"title": "SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation", "link_suffix": "/forum?id=rJ5g8ueQaI", "link": "https://openreview.net/forum?id=rJ5g8ueQaI", "pdf_link": "https://openreview.net/pdf?id=rJ5g8ueQaI", "keywords": "state entropy maximization, unsupervised reinforcement learning", "abstract": "In the unsupervised pre-training for reinforcement learning, the agent aims to learn a prior policy for downstream tasks without relying on task-specific reward functions. We focus on state entropy maximization (SEM), where the goal is to learn a policy that maximizes the entropy of the state's stationary distribution. In this paper, we introduce SEMDICE, a principled off-policy algorithm that computes an SEM policy from an arbitrary off-policy dataset, which optimizes the policy directly within the space of stationary distributions. SEMDICE computes a single, stationary Markov state-entropy-maximizing policy from an arbitrary off-policy dataset. Experimental results demonstrate that SEMDICE outperforms baseline algorithms in maximizing state entropy while achieving the best adaptation efficiency for downstream tasks among SEM-based unsupervised RL pre-training methods.", "title_embedding_index": 1624, "title_abs_embedding_index": 1649}]
[
    {
        "title": "LongVU: Spatiotemporal Adaptive Compression for Long Video-Language Understanding",
        "link_suffix": "/forum?id=G9xhvGPtte",
        "link": "https://openreview.net/forum?id=G9xhvGPtte",
        "pdf_link": "https://openreview.net/pdf?id=G9xhvGPtte",
        "keywords": "Long Video Understanding;Video-Language;Spatiotemporal",
        "abstract": "Multimodal Large Language Models (MLLMs) have shown promising progress in understanding and analyzing video content. However, processing long videos remains a significant challenge constrained by the limited context length. To address this limitation, we propose LongVU, a spatiotemporal adaptive compression mechanism to reduce the number of video tokens while preserving visual details of long videos. Our idea is based on leveraging cross-modal query and inter-frame dependencies to adaptively reduce temporal and spatial redundancy in videos. Specifically, we leverage DINOv2 features to remove redundant frames that exhibit high similarity. Then we utilize text-guided cross-modal query for selective frame feature reduction. Further, we perform spatial token reduction across frames based on their temporal dependencies. Our adaptive compression strategy effectively processes a large number of frames with little visual information loss within limited context length. Our LongVU consistently surpass existing methods across a variety of video understanding benchmarks, especially on hour-long video understanding tasks such as VideoMME and MLVU. Given a light-weight LLM, our LongVU also scales effectively into a smaller size with state-of-the-art video understanding performance. Our code will be made publicly available."
    },
    {
        "title": "Learning anti-classes with one-cold cross entropy loss",
        "link_suffix": "/forum?id=k7UQ96cHzc",
        "link": "https://openreview.net/forum?id=k7UQ96cHzc",
        "pdf_link": "https://openreview.net/pdf?id=k7UQ96cHzc",
        "keywords": "deep learning, representation learning, cross entropy, neural collapse, supervised learning, open set recognition, out of distribution detection",
        "abstract": "While softmax cross entropy loss is the standard objective for supervised classification, it primarily focuses on the ground truth classes, ignoring the relationships between the non-target, complementary classes. This leaves valuable information unexploited during optimization. In this work, we propose a novel loss function, one-cold cross entropy (OCCE) loss, that addresses this limitation by structuring the activations of these complementary classes. Specifically, for each class, we define an anti-class, which consists of everything that is not part of the target class\u2014this includes all complementary classes as well as out-of-distribution samples, noise, or in general any instance that does not belong to the true class. By setting a uniform one-cold encoded distribution over the complementary classes as a target for each anti-class, we encourage the model to equally distribute activations across all non- target classes. This approach promotes a symmetric geometric structure of classes in the final feature space, increases the degree of neural collapse during training, addresses the independence deficit problem of neural networks and improves generalization. Our extensive evaluation shows that incorporating OCCE loss in the optimization objective consistently enhances performance across multiple settings, including classification, open-set recognition, and out-of-distribution detection."
    },
    {
        "title": "Efficient Structure-Aware 3D Gaussians via Lightweight Information Shaping",
        "link_suffix": "/forum?id=Pj2qEVzufH",
        "link": "https://openreview.net/forum?id=Pj2qEVzufH",
        "pdf_link": "https://openreview.net/pdf?id=Pj2qEVzufH",
        "keywords": "Mutual Information Maximization; 3D Reconstruction; 3D Editing",
        "abstract": "3D Gaussians, \nas an explicit scene representation, \ntypically involve \nthousands to millions of elements per scene. \nThis makes it \nchallenging to control \nthe scene in ways \nthat reflect the underlying semantics, \nwhere the number of independent entities \nis typically much smaller. \nEspecially, \nif one wants to animate or edit objects in the scene, \nas this requires coordination among the many Gaussians\ninvolved in representing each object. \nTo address this issue, \nwe develop a mutual information shaping technique \nthat enforces resonance and coordination\nbetween correlated Gaussians \nvia a Gaussian attribute decoding network. \nSuch correlations can be learned \nfrom putative 2D object masks in different views. \nBy approximating the \nmutual information with \nthe gradients concerning the network parameters, \nour method ensures consistency \nbetween scene elements \nand enables efficient scene editing \nby operating on network parameters rather than massive Gaussians.\nIn particular, \nwe develop an effective contrastive learning pipeline\nwith lightweight optimization to shape the attribute decoding network,\nwhile ensuring that the shaping (consistency) is maintained during continuous edits, \navoiding re-shaping after parameter changes. \nNotably, \nour training only touches \na small fraction of all Gaussians in the scene \nyet attains the desired correlated behavior \naccording to the underlying scene structure. \nThe proposed technique \nis evaluated on challenging scenes and demonstrates significant performance improvements \nin 3D object segmentation and promoting scene interactions, \nwhile inducing \nlow computation and memory requirements. \nOur code and trained models \nwill be made available."
    },
    {
        "title": "MindLoc: A Secure Brain-Based System for Object Localization",
        "link_suffix": "/forum?id=A5utJ4xf27",
        "link": "https://openreview.net/forum?id=A5utJ4xf27",
        "pdf_link": "https://openreview.net/pdf?id=A5utJ4xf27",
        "keywords": "Multimodal, Privacy Protection, fMRI, Object Localization",
        "abstract": "Object localization tasks aim to accurately locate and identify specified target objects within images, representing a core challenge in the field of computer vision. Traditional object localization systems primarily rely on intermediary modalities such as text descriptions, speech, or visual cues to interpret human intent. However, these modalities only provide indirect expressions of human intent, limiting the efficiency of information transmission. This is particularly evident when detailed descriptions of texture and spatial information are required, resulting in higher interaction costs. While existing brain-based object localization systems offer the potential for directly interpreting human intent, their localization accuracy still lags behind traditional text-based systems. Additionally, the high cost of data collection, limited diversity of participants, and significant individual cognitive differences make it challenging to train subject-independent models, thereby constraining the development of brain-based object localization systems. To address the challenges, we propose MindLoc, a lightweight, cross-subject brain-based object localization model. MindLoc can rapidly and accurately locate target objects in complex images by directly analyzing fMRI signals, combining the precision of traditional localization systems with the convenience of brain-based systems. Additionally, we are the first to introduce encryption technology for the privacy protection of brain data, significantly reducing the psychological burden on participants, which provides a foundation for increasing participant diversity in future studies. Experimental results demonstrate that MindLoc has achieved new state-of-the-art performance in brain-based object localization tasks, showcasing significant advantages in both accuracy and convenience. Our code is\navailable athttps://mindloc-sys.github.io/."
    },
    {
        "title": "Learning Interpretable and Influential Directions with Signal Vectors and Uncertainty Region Alignment",
        "link_suffix": "/forum?id=yeEWZ8qvlS",
        "link": "https://openreview.net/forum?id=yeEWZ8qvlS",
        "pdf_link": "https://openreview.net/pdf?id=yeEWZ8qvlS",
        "keywords": "latent space, interpretability, concepts, directions, signals, patterns, distractors",
        "abstract": "Latent space directions have played a key role in understanding, debugging, and fixing deep learning models. Concepts are often encoded in distinct feature space directions, and evaluating impact of these directions on the model's predictions, highlights their importance in the decision-making process. Additionally, recent studies have shown that penalizing directions associated with spurious artifacts during training can force models to unlearn features irrelevant to their prediction task. Identifying these directions, therefore, provides numerous benefits, including a deeper understanding of the model's strategy, fostering trust, and enabling model correction and improvement. We introduce a novel unsupervised approach utilizing signal vectors and uncertainty region alignment to discover latent space directions that meet two key debugging criteria: significant influence on model predictions and high level of interpretability. To our knowledge, this method is the first of its kind to uncover such directions, leveraging the inherent structure of the feature space and the knowledge encoded in the deep network. We validate our approach using both synthetic and real-world benchmarks, demonstrating that the discovered directions effectively fulfill the critical debugging criteria."
    },
    {
        "title": "Bayesian Image Regression with Soft-thresholded Conditional Autoregressive Prior",
        "link_suffix": "/forum?id=rnL3OafDdw",
        "link": "https://openreview.net/forum?id=rnL3OafDdw",
        "pdf_link": "https://openreview.net/pdf?id=rnL3OafDdw",
        "keywords": "Brain fMRI Image, Variational Inference, Scalar-on-Image Regression, Image-on-Scalar Regression",
        "abstract": "In the analysis of brain functional MRI (fMRI) data using regression models, Bayesian methods are highly valued for their flexibility and ability to quantify uncertainty. However, these methods face computational challenges in high-dimensional settings typical of brain imaging, and the often pre-specified correlation structures may not accurately capture the true spatial relationships within the brain. To address these issues, we develop a general prior specifically designed for regression models with large-scale imaging data. We introduce the Soft-Thresholded Conditional AutoRegressive (ST-CAR) prior, which reduces instability to pre-fixed correlation structures and provides inclusion probabilities to account for the uncertainty in choosing active voxels in the brain. We apply the ST-CAR prior to scalar-on-image (SonI) and image-on-scalar (IonS) regression models\u2014both critical in brain imaging studies\u2014and develop efficient computational algorithms using variational inference (VI) and stochastic subsampling techniques. Simulation studies demonstrate that the ST-CAR prior outperforms existing methods in identifying active brain regions with complex correlation patterns, while our VI algorithms offer superior computational performance. We further validate our approach by applying the ST-CAR to working memory fMRI data from the Adolescent Brain Cognitive Development (ABCD) study, highlighting its effectiveness in practical brain imaging applications."
    },
    {
        "title": "Ensembles provably learn equivariance through data augmentation",
        "link_suffix": "/forum?id=02Od16GFRW",
        "link": "https://openreview.net/forum?id=02Od16GFRW",
        "pdf_link": "https://openreview.net/pdf?id=02Od16GFRW",
        "keywords": "equivariance, invariance, ensemble models, data augmentation, SGD",
        "abstract": "Recently, it was proved that group equivariance emerges in ensembles of neural networks as the result of full augmentation in the limit of infinitely wide neural networks (neural tangent kernel limit). In this paper, we extend this result significantly. We provide a proof that this emergence does not depend on the neural tangent kernel limit at all. We also consider stochastic settings, and furthermore general architectures. For the latter, we provide a simple sufficient condition on the relation between the architecture and the action of the group for our results to hold. We validate our findings through simple numeric experiments."
    },
    {
        "title": "High-Dimension Human Value Representation in Large Language Models",
        "link_suffix": "/forum?id=qhGuHVhJaE",
        "link": "https://openreview.net/forum?id=qhGuHVhJaE",
        "pdf_link": "https://openreview.net/pdf?id=qhGuHVhJaE",
        "keywords": "Value Embedding, Human Value in LLM, LLM Value Alignment, Cultural Understanding in LLM",
        "abstract": "The widespread application of Large Language Models (LLMs) across various tasks and fields has necessitated the alignment of these models with human values and preferences. Given various approaches of human value alignment, there is an urgent need to understand the scope and nature of human values injected into these LLMs before their deployment and adoption. We propose UniVaR, a high-dimensional neural representation of symbolic human value distributions in LLMs, orthogonal to model architecture and training data. This is a continuous and scalable representation, self-supervised from the value-relevant output of 8 LLMs and evaluated on 15 open-source and commercial LLMs. Through UniVaR, we visualize and explore how LLMs prioritize different values in 25 languages and cultures, shedding light on the complex interplay between human values and language modeling."
    },
    {
        "title": "TimeKAN: KAN-based Frequency Decomposition Learning Architecture for Long-term Time Series Forecasting",
        "link_suffix": "/forum?id=wTLc79YNbh",
        "link": "https://openreview.net/forum?id=wTLc79YNbh",
        "pdf_link": "https://openreview.net/pdf?id=wTLc79YNbh",
        "keywords": "Kolmogorov-Arnold Network; Time Series Forecasting",
        "abstract": "Real-world time series often have multiple frequency components that are intertwined with each other, making accurate time series forecasting challenging. Decomposing the mixed frequency components into multiple single frequency components is a natural choice. However, the information density of patterns varies across different frequencies, and employing a uniform modeling approach for different frequency components can lead to inaccurate characterization. To address this challenges, inspired by the flexibility of the recent Kolmogorov-Arnold Network (KAN), we propose a KAN-based Frequency Decomposition Learning architecture (TimeKAN) to address the complex forecasting challenges caused by multiple frequency mixtures. Specifically, TimeKAN mainly consists of three components: Cascaded Frequency Decomposition (CFD) blocks, Multi-order KAN Representation Learning (M-KAN) blocks and Frequency Mixing blocks. CFD blocks adopt a bottom-up cascading approach to obtain series representations for each frequency band. Benefiting from the high flexibility of KAN, we design a novel M-KAN block to learn and represent specific temporal patterns within each frequency band. Finally, Frequency Mixing blocks is used to recombine the frequency bands into the original format. Extensive experimental results across multiple real-world time series datasets demonstrate that TimeKAN achieves state-of-the-art performance as an extremely lightweight architecture."
    },
    {
        "title": "Generative Models: What Do They Know? Do They Know Things? Let's Find Out!",
        "link_suffix": "/forum?id=xkR3bcswuC",
        "link": "https://openreview.net/forum?id=xkR3bcswuC",
        "pdf_link": "https://openreview.net/pdf?id=xkR3bcswuC",
        "keywords": "Visual knowledge, Generative models, Intrinsic Images",
        "abstract": "Generative models excel at mimicking real scenes, suggesting they might inherently encode important intrinsic scene properties. In this paper, we aim to explore the following key questions: (1) What intrinsic knowledge do generative models like Autoregressive models, GANs and Diffusion models encode? (2) Can we establish a general framework to recover intrinsic representations from these models, regardless of their architecture or model type? (3) How minimal can the required learnable parameters and labeled data be to successfully recover this knowledge? (4) Is there a direct link between the quality of a generative model and the accuracy of the recovered scene intrinsics?Our findings indicate that a small Low-Rank Adaptation (LoRA) can recover intrinsic images---depth, normals, albedo, and shading---across different generators (GAN, Autoregressive, and Diffusion) while using the same decoder head that generates the image. As LoRA is lightweight, we introduce very few learnable parameters (as few as 0.04% of Stable Diffusion model weights for a rank of 2), and we find that as few as 250 labeled images are enough to generate intrinsic images with these LoRA modules. Finally, we also show a positive correlation between the generative model's quality and the accuracy of the recovered intrinsics through control experiments."
    },
    {
        "title": "Preference Elicitation for Offline Reinforcement Learning",
        "link_suffix": "/forum?id=2pJpFtdVNe",
        "link": "https://openreview.net/forum?id=2pJpFtdVNe",
        "pdf_link": "https://openreview.net/pdf?id=2pJpFtdVNe",
        "keywords": "Reinforcement Learning, Offline Reinforcement Learning, Preference-based Reinforcement Learning",
        "abstract": "Applying reinforcement learning (RL) to real-world problems is often made challenging by the inability to interact with the environment and the difficulty of designing reward functions. Offline RL addresses the first challenge by considering access to an offline dataset of environment interactions labeled by the reward function. In contrast, Preference-based RL does not assume access to the reward function and learns it from preferences, but typically requires an online interaction with the environment. We bridge the gap between these frameworks by exploring efficient methods for acquiring preference feedback in a fully offline setup. We propose Sim-OPRL, an offline preference-based reinforcement learning algorithm, which leverages a learned environment model to elicit preference feedback on simulated rollouts. Drawing on insights from both the offline RL and the preference-based RL literature, our algorithm employs a pessimistic approach for out-of-distribution data, and an optimistic approach for acquiring informative preferences about the optimal policy. We provide theoretical guarantees regarding the sample complexity of our approach, dependent on how well the offline data covers the optimal policy. Finally, we demonstrate the empirical performance of Sim-OPRL in various environments."
    },
    {
        "title": "Gaussian-Det: Learning Closed-Surface Gaussians for 3D Object Detection",
        "link_suffix": "/forum?id=DtFCIfvAFc",
        "link": "https://openreview.net/forum?id=DtFCIfvAFc",
        "pdf_link": "https://openreview.net/pdf?id=DtFCIfvAFc",
        "keywords": "3D Gaussian Splatting, 3D Object Detection, Surface Closure",
        "abstract": "Skins wrapping around our bodies, leathers covering over the sofa, sheet metal coating the car \u2013 it suggests that objects are enclosed by a series of continuous surfaces, which provides us with informative geometry prior for objectness deduction. In this paper, we propose Gaussian-Det which leverages Gaussian Splatting as surface representation for multi-view based 3D object detection. Unlike existing monocular or NeRF-based methods which depict the objects via discrete positional data, Gaussian-Det models the objects in a continuous manner by formulating the input Gaussians as feature descriptors on a mass of partial surfaces. Furthermore, to address the numerous outliers inherently introduced by Gaussian splatting, we accordingly devise a Closure Inferring Module (CIM) for the comprehensive surface-based objectness deduction. CIM firstly estimates the probabilistic feature residuals for partial surfaces given the underdetermined nature of Gaussian Splatting, which are then coalesced into a holistic representation on the overall surface closure of the object proposal. In this way, the surface information Gaussian-Det exploits serves as the prior on the quality and reliability of objectness and the information basis of proposal refinement. Experiments on both synthetic and real-world datasets demonstrate that Gaussian-Det outperforms various existing approaches, in terms of both average precision and recall."
    },
    {
        "title": "RFMamba: Frequency-Aware State Space Model for RF-Based Human-Centric Perception",
        "link_suffix": "/forum?id=lG9fjBLb6d",
        "link": "https://openreview.net/forum?id=lG9fjBLb6d",
        "pdf_link": "https://openreview.net/pdf?id=lG9fjBLb6d",
        "keywords": "Human-centric perception, State space model, Radio frequency",
        "abstract": "Human-centric perception with radio frequency (RF) signals has recently entered a new era of end-to-end processing with Transformers. Considering the long-sequence nature of RF signals, the State Space Model (SSM) has emerged as a superior alternative due to its effective long-sequence modeling and linear complexity. However, integrating SSM into RF-based sensing presents unique challenges including the fundamentally different signal representation, distinct frequency responses in different scenarios, and incomplete capture caused by specular reflection. To address this, we carefully devise a dual-branch SSM block that is characterized by adaptively grasping the most informative frequency cues and the assistant spatial information to fully explore the human representations from radar echoes. Based on these two branchs, we further introduce an SSM-based network for handling various downstream human perception tasks, named RFMamba. Extensive experimental results demonstrate the superior performance of our proposed RFMamba across all three downstream tasks. To the best of our knowledge, RFMamba is the first attempt to introduce SSM into RF-based human-centric perception."
    },
    {
        "title": "Lina-Speech: Gated Linear Attention is a Fast and Parameter-Efficient Learner for text-to-speech synthesis",
        "link_suffix": "/forum?id=WqVOjZXwAp",
        "link": "https://openreview.net/forum?id=WqVOjZXwAp",
        "pdf_link": "https://openreview.net/pdf?id=WqVOjZXwAp",
        "keywords": "text-to-speech, deep generative model, audio modeling",
        "abstract": "Neural codec language models have demonstrated state-of-the-art performance in text-to-speech (TTS) synthesis. Leveraging scalable architectures like autoregressive transformers, they capitalize on the availability of large speech datasets. When framing voice cloning as a prompt continuation task, these models excel at cloning voices from short audio samples. However this approach can't be extended to multiple speech excerpts and is limited since the concatenation of source and target speech must fall within the maximum context length which is determined during training. In this work, we propose a model that replaces transformers with emergent recurrent architecture such as Gated Linear Attention (GLA). Our model, Lina-Speech, outperforms or matches the baseline models that are up to 4x it's size. We showcase intial-state tuning as a parameter-efficient fine-tuning technique that optimizes the initial state of the recurrent layers, resulting in compact and expressive speaker embedding with fine-grained control over the speech style. Compared to prompt continuation, it allows voice cloning from multiple speech excerpts and full usage of the context window for synthesis. This approach is fast, deployable and does not rely on auxiliary modules. It also demonstrates extensive adaptation to out-of-domain data. We will release publicly our code and checkpoints. Audio samples are available at \\url{https://anonymsubm.github.io}."
    },
    {
        "title": "Feature Averaging: An Implicit Bias of Gradient Descent Leading to Non-Robustness in Neural Networks",
        "link_suffix": "/forum?id=zPHra4V5Mc",
        "link": "https://openreview.net/forum?id=zPHra4V5Mc",
        "pdf_link": "https://openreview.net/pdf?id=zPHra4V5Mc",
        "keywords": "deep learning theory, feature learning, adversarial robustness, implicit bias",
        "abstract": "In this work, we investigate a particular implicit bias in the gradient descent training process, which we term \u201cFeature Averaging\u201d, and argue that it is one of the principal factors contributing to non-robustness of deep neural networks. Despite the existence of multiple discriminative features capable of classifying data, neural networks trained by gradient descent exhibit a tendency to learn the average (or certain combination) of these features, rather than distinguishing and leveraging each feature individually. In particular, we provide a detailed theoretical analysis of the training dynamics of gradient descent in a two-layer ReLU network for a binary classification task, where the data distribution consists of multiple clusters with orthogonal cluster center vectors. We rigorously prove that gradient descent converges to the regime of feature averaging, wherein the weights associated with each hidden-layer neuron represent an average of the cluster centers (each center corresponding to a distinct feature). It leads the network classifier to be non-robust due to an attack that aligns with the negative direction of the averaged features. Furthermore, we prove that, with the provision of more granular supervised information, a two-layer multi-class neural network is capable of learning individual features, which is able to induce a binary classifier with the optimal robustness under our setting. Besides, we also conduct extensive experiments using synthetic datasets, MNIST and CIFAR-10 to substantiate the phenomenon of feature averaging and its role in adversarial robustness of neural networks. We hope the theoretical and empirical insights can provide a deeper understanding of the impact of the gradient descent training on feature learning process, which in turn influences the robustness of the network, and how more detailed supervision may enhance model robustness."
    },
    {
        "title": "Learning Object-centric Latent Dynamics for Reinforcement Learning from Pixels",
        "link_suffix": "/forum?id=iqdqRmqUsD",
        "link": "https://openreview.net/forum?id=iqdqRmqUsD",
        "pdf_link": "https://openreview.net/pdf?id=iqdqRmqUsD",
        "keywords": "Reinforcement Learning, World Models, Object-centric Representations",
        "abstract": "Learning a latent dynamics model provides a task-agnostic representation of an agent\u2019s understanding of its environment. Leveraging this knowledge for model-based reinforcement learning holds the potential to improve sample efficiency over model-free methods by learning inside imagined rollouts. Furthermore, because the latent space serves as input to behavior models, the informative representations learned by the world model facilitate efficient learning of desired skills. However, most existing methods rely on holistic representations of the environment\u2019s state. In contrast, humans reason about objects and their interactions, forecasting how actions will affect specific parts of their surroundings. Inspired by this, we propose Slot-Attention for Object-centric Latent Dynamics (SOLD), a novel algorithm that learns object-centric dynamics models in an unsupervised manner from pixel inputs. We demonstrate that the structured latent space not only improves model interpretability but also provides a valuable input space for behavior models to reason over. Our results show that SOLD outperforms DreamerV3, a state-of-the-art model-based RL algorithm, across a range of benchmark robotic environments that evaluate for both relational reasoning and low-level manipulation capabilities."
    },
    {
        "title": "Teaching Transformers Modular Arithmetic at Scale",
        "link_suffix": "/forum?id=38hLpTVpe7",
        "link": "https://openreview.net/forum?id=38hLpTVpe7",
        "pdf_link": "https://openreview.net/pdf?id=38hLpTVpe7",
        "keywords": "transformers, modular arithmetic, math",
        "abstract": "Modular addition is, on its face, a simple operation: given $N$ elements in $\\mathbb{Z}_q$, compute their sum modulo $q$. Yet, scalable machine learning solutions to this problem remain elusive: prior work trains ML models that sum $N \\le 6$ elements mod $q \\le 1000$. Promising applications of ML models for cryptanalysis$\\textemdash$which often involve modular arithmetic with large $N$ and $q$$\\textemdash$motivate reconsideration of this problem. This work proposes three changes to the modular addition model training pipeline: more diverse training data, an angular embedding, and a custom loss function. With these changes, we demonstrate success with our approach for $N = 256, q = 3329$, a case which is interesting for cryptographic applications, and a significant increase in $N$ and $q$ over  prior work. These techniques also generalize to other modular arithmetic problems, motivating future work."
    },
    {
        "title": "Surface-based Peptide Design with Multi-modal Flow Matching",
        "link_suffix": "/forum?id=MeCPwqrm19",
        "link": "https://openreview.net/forum?id=MeCPwqrm19",
        "pdf_link": "https://openreview.net/pdf?id=MeCPwqrm19",
        "keywords": "Molecular Surfaces, Peptide Design, Flow Matching",
        "abstract": "Therapeutic peptides show promise in targeting previously undruggable binding sites, with recent advancements in deep generative models enabling full-atom peptide co-design for specific protein receptors. However, the critical role of molecular surfaces in protein-protein interactions (PPIs) has been underexplored. To bridge this gap, we propose an \\emph{omni-design} peptides generation paradigm, called SurfFlow, a novel surface-based generative algorithm that enables comprehensive co-design of sequence, structure, and surface for peptides. SurfFlow employs a multi-modality conditional flow matching (CFM) architecture to learn distributions of surface geometries and biochemical properties, enhancing peptide binding accuracy. Evaluated on the comprehensive PepMerge benchmark, SurfFlow consistently outperforms full-atom baselines across all metrics. These results highlight the advantages of considering molecular surfaces in \\emph{de novo} peptide discovery and demonstrate the potential of integrating multiple protein modalities for more effective therapeutic peptide discovery. Anonymous codes are available at~\\url{https://anonymous.4open.science/r/SurfFlow-880B/}."
    },
    {
        "title": "GOAL: A Generalist Combinatorial Optimization Agent Learning",
        "link_suffix": "/forum?id=z2z9suDRjw",
        "link": "https://openreview.net/forum?id=z2z9suDRjw",
        "pdf_link": "https://openreview.net/pdf?id=z2z9suDRjw",
        "keywords": "neural combinatorial optimization, generalist models, transfer learning, fine tuning",
        "abstract": "Machine Learning-based heuristics have recently shown impressive performance in solving a variety of hard combinatorial optimization problems (COPs). However they generally rely on a separate neural model, specialized and trained for each single problem. Any variation of a problem requires adjustment of its model and re-training from scratch. In this paper, we propose GOAL (for Generalist combinatorial Optimization Agent Learning), a generalist model capable of efficiently solving multiple COPs and which can be fine-tuned to solve new COPs. GOAL consists of a single backbone plus light-weight problem-specific adapters for input and output processing. The backbone is based on a new form of mixed-attention blocks which allows to handle problems defined on graphs with arbitrary combinations of node, edge and instance-level features. Additionally, problems which involve heterogeneous types of nodes or edges are handled through a novel multi-type transformer architecture, where the attention blocks are duplicated to attend the meaningful combinations of types while relying on the same shared parameters. We train GOAL on a set of routing, scheduling and classic graph problems and show that it is only slightly inferior to the specialized baselines while being the first multi-task model that solves a wide range of COPs. Finally we showcase the strong transfer learning capacity of GOAL by fine-tuning it on several new problems. Our code is available athttps://anonymous.4open.science/r/GOAL-10/."
    },
    {
        "title": "Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects",
        "link_suffix": "/forum?id=7BLXhmWvwF",
        "link": "https://openreview.net/forum?id=7BLXhmWvwF",
        "pdf_link": "https://openreview.net/pdf?id=7BLXhmWvwF",
        "keywords": "Robotic Manipulation, Equivariance, Graph Neural Networks, Reinforcement Learning, Deformable Objects",
        "abstract": "Manipulating objects with varying geometries and deformable objects is a major challenge in robotics. Tasks such as insertion with different objects or cloth hanging require precise control and effective modelling of complex dynamics. In this work, we frame this problem through the lens of a heterogeneous graph that comprises smaller sub-graphs, such as actuators and objects, accompanied by different edge types describing their interactions. This graph representation serves as a unified structure for both rigid and deformable objects tasks, and can be extended further to tasks comprising multiple actuators. To evaluate this setup, we present a novel and challenging reinforcement learning benchmark, including rigid insertion of diverse objects, as well as rope and cloth manipulation with multiple end-effectors. These tasks present a large search space, as both the initial and target configurations are uniformly sampled in 3D space. To address this issue, we propose a novel graph-based policy model, dubbed Heterogeneous Equivariant Policy (HEPi), utilizing $SE(3)$ equivariant message passing networks as the main backbone to exploit the geometric symmetry. In addition, by modeling explicit heterogeneity, HEPi can outperform Transformer-based and non-heterogeneous equivariant policies in terms of average returns, sample efficiency, and generalization to unseen objects."
    },
    {
        "title": "Leveraging metapaths for learning from knowledge graphs in the context of vision-based classification of object states",
        "link_suffix": "/forum?id=jMSsgTaVKN",
        "link": "https://openreview.net/forum?id=jMSsgTaVKN",
        "pdf_link": "https://openreview.net/pdf?id=jMSsgTaVKN",
        "keywords": "Object State Classification, Meta-paths learning, Zero Shot Learning, Embeddings Learning",
        "abstract": "Zero-Shot Object State Classification (ZS-OSC) aims to recognize unseen object states without any visual training examples. Existing methods typically rely on Knowledge Graphs (KGs) to provide semantic information about states, but they often treat KGs as homogeneous, overlooking the rich relational knowledge encoded in their structure. We propose a novel approach to ZS-OSC that leverages meta-paths to capture complex relationships between object states in a KG. Our method learns to project semantic information from the KG into the visual space via meta-path learning, generating discriminative visual embeddings for unseen state classes. To the best of our knowledge, this is the first work to utilize meta-paths for ZS-OSC. We conduct extensive experiments on four benchmark datasets, demonstrating the superior performance of our approach compared to SoTA zero-shot learning methods and a graph-based baseline. Our ablation study further provides insights into the impact of key design choices on the effectiveness of our method."
    },
    {
        "title": "Optimizing importance weighting in the presence of sub-population shifts",
        "link_suffix": "/forum?id=j4gzziSUr0",
        "link": "https://openreview.net/forum?id=j4gzziSUr0",
        "pdf_link": "https://openreview.net/pdf?id=j4gzziSUr0",
        "keywords": "Importance weighting, Distribution shift, Group Robustness, Bi-level optimization",
        "abstract": "A distribution shift between the training and test data can severely harm performance of machine learning models. Importance weighting addresses this issue by assigning different weights to data points during training. We argue that existing heuristics for determining the weights are suboptimal, as they neglect the increase of the variance of the estimated model due to the limited sample size of the training data. We interpret the optimal weights in terms of a bias-variance trade-off,  and  propose a bi-level optimization procedure in which the weights and model parameters are optimized simultaneously. We apply this framework to existing importance weighting techniques for last-layer retraining of deep neural networks in the presence of sub-population shifts and show empirically that optimizing weights significantly improves generalization performance."
    },
    {
        "title": "Transformers Can Navigate Mazes With Multi-Step Prediction",
        "link_suffix": "/forum?id=PVGS8UZ6GX",
        "link": "https://openreview.net/forum?id=PVGS8UZ6GX",
        "pdf_link": "https://openreview.net/pdf?id=PVGS8UZ6GX",
        "keywords": "transformers, planning, learning objectives",
        "abstract": "Despite their remarkable success in language modeling, transformers trained to predict the next token in a sequence struggle with long-term planning. This limitation is particularly evident in tasks requiring foresight to plan multiple steps ahead such as maze navigation. The standard next single token prediction objective, however, offers no explicit mechanism to predict multiple steps ahead---or revisit the path taken so far. Consequently, in this work we study whether explicitly predicting multiple steps ahead (and backwards) can improve transformers' maze navigation. We train under identical settings, parameter-matched transformers from scratch to navigate mazes of varying types and sizes with standard next token prediction and MLM-U: an objective explicitly predicting multiple steps ahead and backwards. We find MLM-U considerably improves transformers\u2019 ability to navigate mazes compared to standard next token prediction across maze types and complexities. We also find MLM-U training is 4x more sample efficient and converges 2x faster in terms of GPU training hours relative to next token training. Finally, for more complex mazes we find MLM-U benefits from scaling to larger transformers. Remarkably, we find transformers trained with MLM-U outperform larger transformers trained with next token prediction using additional supervision from A* search traces. We hope these findings underscore the promise of learning objectives to advance transformers' capacity for long-term planning."
    },
    {
        "title": "HyperChr: Quantization of Heterogeneously Distributed Matrices through Distribution-Aware Subspace Partitioning",
        "link_suffix": "/forum?id=D2Vz4drFA6",
        "link": "https://openreview.net/forum?id=D2Vz4drFA6",
        "pdf_link": "https://openreview.net/pdf?id=D2Vz4drFA6",
        "keywords": "matrix quantization; LLMs; heterogeneous distribution; Product quantization",
        "abstract": "Matrix quantization is crucial for reducing the memory footprint of matrices across various applications, including large-scale machine learning models and data compression. We have observed that matrices in different application domains exhibit heterogeneity in the distribution across columns. Leveraging this characteristic, we introduce \\textit{HyperChr}, a novel matrix quantization algorithm tailored for heterogeneous data distributions prevalent across different matrix columns. Unlike traditional quantization methods, \\textit{HyperChr} capitalizes on the heterogeneous distribution characteristics of each column to optimally partition high-dimensional subspaces and perform compression within each subspace. This technique enhances the compression effectiveness by grouping vectors with similar distribution ranges, enabling more precise quantization. Moreover, \\textit{HyperChr} dynamically adjusts the number of centroids in each subspace based on the specific data distribution traits, optimizing both storage efficiency and data fidelity.We evaluate \\textit{HyperChr}'s performance on diverse datasets, demonstrating its superiority in reducing quantization errors compared to existing methods. Our results show that \\textit{HyperChr} exhibits significant improvements at lower compression ratios ($\\theta = 2-8$), reducing MAE by an average of 55.3% and MSE by 75.3% compared to PQ. However, at higher compression ratios ($\\theta = 10-16$), the improvements are more moderate, with an average reduction of 14.9% in MAE and 25.9% in MSE compared to PQ. In addition, our algorithm reduces the average dequantization time by 62.9%, which is crucial for large language model inference."
    },
    {
        "title": "MADAR: Efficient Continual Learning for Malware Analysis with Diversity-Aware Replay",
        "link_suffix": "/forum?id=9DvXEO9xdn",
        "link": "https://openreview.net/forum?id=9DvXEO9xdn",
        "pdf_link": "https://openreview.net/pdf?id=9DvXEO9xdn",
        "keywords": "Malware Analysis, Windows Malware, Android Malware, Catastrophic Forgetting, Continual Learning",
        "abstract": "Millions of new pieces of malicious software (i.e., malware) are introduced each year. This poses significant challenges for antivirus vendors, who use machine learning to detect and analyze malware, and must keep up with changes in the distribution while retaining knowledge of older variants. Continual learning (CL) holds the potential to address this challenge by reducing the storage and computational costs of regularly retraining over all the collected data. Prior work, however, shows that CL techniques designed primarily for computer vision tasks fare poorly when applied to malware classification. To address these issues, we begin with an exploratory analysis of a typical malware dataset, which reveals that malware families are diverse and difficult to characterize, requiring a wide variety of samples to learn a robust representation. Based on these findings, we propose $\\underline{M}$alware $\\underline{A}$nalysis with $\\underline{D}$iversity-$\\underline{A}$ware $\\underline{R}$eplay (MADAR), a CL framework that accounts for the unique properties and challenges of the malware data distribution. We extensively evaluate these techniques using both Windows and Android malware, showing that MADAR significantly outperforms prior work. This highlights the importance of understanding domain characteristics when designing CL techniques and demonstrates a path forward for the malware classification domain."
    }
]
[
    {
        "title": "Practical and Rigorous Extremal Bounds for Gaussian Process Regression via Chaining",
        "link_suffix": "/forum?id=kYkgctT6bU",
        "link": "https://openreview.net/forum?id=kYkgctT6bU",
        "pdf_link": "https://openreview.net/pdf?id=kYkgctT6bU",
        "keywords": "Upper and lower bounds, Gaussian Process Regression, Chaining",
        "abstract": "Gaussian Process Regression (GPR) is a popular nonparametric regression method based on Bayesian principles that, unlike most machine learning techniques, provides uncertainty estimates for its predictions. Recent research has focused on robustness to model misspecification but has neglected improvements to the underlying methods for computing bounds. Inspired by the chaining method, we applied it to the prediction intervals of GPR. This work addresses the limitations of current GPR methods, which rely heavily on scaling posterior standard deviations and assume well-specified models, limiting their adaptability and accuracy. We propose a novel chain-based approach that decomposes the problem into smaller, refined stages, enabling better error control and enhanced robustness, particularly in challenging scenarios. Additionally, we innovate by providing tighter,  practical and theoretically sound bounds for commonly used kernels, including RBF and Mat\u00e9rn, improving both their theoretical understanding and practical utility. Numerical experiments validate our theoretical findings, demonstrating that our method outperforms existing approaches on synthetic and real-world datasets."
    },
    {
        "title": "Adaptive Drag: Semantic-Driven Dragging on Diffusion-Based Image Editing",
        "link_suffix": "/forum?id=tkG7jkrkxy",
        "link": "https://openreview.net/forum?id=tkG7jkrkxy",
        "pdf_link": "https://openreview.net/pdf?id=tkG7jkrkxy",
        "keywords": "image edit, point-based drag, diffusion, semantic-driven",
        "abstract": "Recently, several point-based image editing methods ($\\textit{e.g.}$, DragDiffusion, FreeDrag, DragNoise) have emerged, yielding precise and high-quality results based on user instructions. However, these methods often make insufficient use of semantic information, leading to less desirable results. In this paper, we proposed a novel mask-free point-based image editing method, $\\textbf{AdaptiveDrag}$, which provides a more flexible editing approach and generates images that better align with user intent. Specifically, we design an auto mask generation module using super-pixel division for user-friendliness. Next, we leverage a pre-trained diffusion model to optimize the latent, enabling the dragging of features from handle points to target points. To ensure a comprehensive connection between the input image and the drag process, we have developed a semantic-driven optimization. We design adaptive steps that are supervised by the positions of the points and the semantic regions derived from super-pixel segmentation. This refined optimization process also leads to more realistic and accurate drag results. Furthermore, to address the limitations in the generative consistency of the diffusion model, we introduce an innovative corresponding loss during the sampling process. Building on these effective designs, our method delivers superior generation results using only the single input image and the handle-target point pairs. Extensive experiments have been conducted and demonstrate that the proposed method outperforms others in handling various drag instructions ($\\textit{e.g.}$, resize, movement, extension) across different domains ($\\textit{e.g.}$, animals, human face, land space, clothing)."
    },
    {
        "title": "Towards Multi-Domain Chinese Document VQA: a New Dataset and Baseline Method",
        "link_suffix": "/forum?id=Z0qvzed8TK",
        "link": "https://openreview.net/forum?id=Z0qvzed8TK",
        "pdf_link": "https://openreview.net/pdf?id=Z0qvzed8TK",
        "keywords": "Benchmark, Dataset, Chinese DocVQA, In-Context Learning",
        "abstract": "Document Visual Question Answering (DocVQA) remains a significant challenge in the field of document understanding and is a critical evaluation metric for current general-purpose large model techniques. However, prevailing public datasets are predominantly designed for single scenarios or specific sources. Furthermore, most available datasets are in English, limiting the verification of model performance in other languages. This paper presents a novel multi-domain Chinese document VQA dataset, which includes 39 document types from 7 different domains. The designed question set encompasses both common extractive questions and complex abstractive questions. Based on this dataset, we conducted a comprehensive review and analysis of various technical paradigms, including both traditional and large model-based approaches. Using the popular in-context learning framework, we propose a robust baseline that achieves commendable few-shot adaptation. Comparative evaluations demonstrate the superior performance of the proposed method across different solution paradigms. The dataset and code will be published."
    },
    {
        "title": "Precedence-Constrained Winter Value for Effective Graph Data Valuation",
        "link_suffix": "/forum?id=tVRVE0OAyb",
        "link": "https://openreview.net/forum?id=tVRVE0OAyb",
        "pdf_link": "https://openreview.net/pdf?id=tVRVE0OAyb",
        "keywords": "Data Valuation, Graph Learning, Graph neural network",
        "abstract": "Data valuation is essential for quantifying data\u2019s worth, aiding in assessing data quality and determining fair compensation. While existing data valuation methods have proven effective in evaluating the value of Euclidean data, they face limitations when applied to the increasingly popular graph-structured data. Particularly, graph data valuation introduces unique challenges, primarily stemming from the intricate dependencies among nodes and the exponential growth in value estimation costs. To address the challenging problem of graph data valuation, we put forth an innovative solution, Precedence-Constrained Winter (PC-Winter) Value, to account for the complex graph structure. Furthermore, we develop a variety of strategies to address the computational challenges and enable efficient approximation of PC-Winter. Extensive experiments demonstrate the effectiveness of PC-Winter across diverse datasets and tasks."
    },
    {
        "title": "How well does GPT-4o understand vision? Solving standard computer vision tasks with multimodal foundation models",
        "link_suffix": "/forum?id=h3unlS2VWz",
        "link": "https://openreview.net/forum?id=h3unlS2VWz",
        "pdf_link": "https://openreview.net/pdf?id=h3unlS2VWz",
        "keywords": "multimodal foundation models, computer vision",
        "abstract": "Multimodal foundation models, such as GPT-4o, have made remarkable progress recently. However, it is not clear exactly where these models stand in terms of understanding vision. {In this paper, we \\textbf{quantify the performance of popular multimodal foundation models} (GPT-4o, Gemini Pro, Claude 3.5 Sonnet, Qwen2-VL) \\textbf{at standard computer vision tasks} (semantic segmentation, object detection, image classification, depth and surface normal prediction) and \\textbf{using established datasets} (e.g., COCO, ImageNet and its variants, etc).}The main challenges to performing this are: \\textbf{1)} the models are trained to output text and cannot natively express versatile domains, such as segments or 3D geometry, and \\textbf{2)} many of the leading models are proprietary and accessible only at an API level, i.e., there is no weight access to adapt them. We address these challenges by translating standard vision tasks into equivalent text-promptable and API-compatible tasks via {prompt chaining}.We observe that \\textbf{1)} the models are not close to the state-of-the-art at any tasks, and \\textbf{2)} they perform semantic tasks notably better than geometric ones. However, \\textbf{3)} they are respectable generalists; this is remarkable as they are presumably trained on only image-text-based tasks primarily. \\textbf{4)} While the prompting techniques affect the performance, better models exhibit less sensitivity to prompt variations. \\textbf{5)} GPT-4o performs the best, getting the top position in 5 out of 6 tasks."
    },
    {
        "title": "Sounding the Alarm: Backdooring Acoustic Foundation Models for Physically Realizable Triggers",
        "link_suffix": "/forum?id=mFzpBaTLGK",
        "link": "https://openreview.net/forum?id=mFzpBaTLGK",
        "pdf_link": "https://openreview.net/pdf?id=mFzpBaTLGK",
        "keywords": "security, speech model, backdoor attack",
        "abstract": "Although foundation models help increase performance on many downstream tasks while reducing the amount of labeled data needed, \ntheir proliferation has raised a natural question: To what extent can a model downloaded from the Internet be trusted?  We tackle this question for acoustic foundation models (AFMs) and propose the $\\textbf F$oundation $\\textbf A$coustic model $\\textbf B$ackdoor (FAB) attack against AFMs, showing that state-of-the-art models are susceptible to a new attack vector. Despite preserving model performance on benign data, AFM induces backdoors that survive fine-tuning, and, when activated, lead to a significant performance drop on various downstream tasks.  Notably, backdoors created by FAB can be activated in a ${physically\\ realizable}$ manner by ${inconspicuous}$, ${input}$-${agnostic}$ triggers that ${do\\ not\\ require\\ syncing}$ with the acoustic input (e.g., by playing a siren sound in the background). Crucially, FAB also assumes a weaker threat model than past work, where the adversary has no knowledge of the pre-training data and certain architectural details.  We tested FAB with two leading AFMs, on nine tasks, with four triggers, against two defenses, as well as in the digital and physical domains, and found the attack highly successful in all scenarios.  Overall, our work highlights the risks facing AFMs and calls for advanced defences to mitigate them."
    },
    {
        "title": "A Comprehensive Framework for Analyzing the Convergence of Adam: Bridging the Gap with Stochastic Gradient Descent",
        "link_suffix": "/forum?id=mKZsokwMRb",
        "link": "https://openreview.net/forum?id=mKZsokwMRb",
        "pdf_link": "https://openreview.net/pdf?id=mKZsokwMRb",
        "keywords": "Adam, almost sure convergence, l1 convergence, sample complexity, analysis framework",
        "abstract": "Adaptive Moment Estimation (Adam) is a cornerstone optimization algorithm in deep learning, widely recognized for its flexibility with adaptive learning rates and efficiency in handling large-scale data. However, despite its practical success, the theoretical understanding of Adam's convergence has been constrained by stringent assumptions, such as almost surely bounded stochastic gradients or uniformly bounded gradients, which are more restrictive than those typically required for analyzing stochastic gradient descent (SGD).In this paper, we introduce a novel and comprehensive framework for analyzing the convergence properties of Adam. This framework offers a versatile approach to establishing Adam's convergence. Specifically, we prove that Adam achieves asymptotic (last iterate sense) convergence in both the almost sure sense and the (L_1) sense under the relaxed assumptions typically used for SGD, namely (L)-smoothness and the ABC inequality. Meanwhile, under the same assumptions, we show that Adam attains non-asymptotic sample complexity bounds similar to those of SGD."
    },
    {
        "title": "Extended Flow Matching  : a Method of Conditional Generation with Generalized Continuity Equation",
        "link_suffix": "/forum?id=0QJPszYxpo",
        "link": "https://openreview.net/forum?id=0QJPszYxpo",
        "pdf_link": "https://openreview.net/pdf?id=0QJPszYxpo",
        "keywords": "Flow Matching, Generative Model",
        "abstract": "Conditional generative modeling (CGM), which approximates the conditional probability distribution of data given a condition, holds significant promise for generating new data across diverse representations.\nWhile CGM is crucial for generating images, video, and text, its application to scientific computing, such as molecular generation and physical simulations, is also highly anticipated.\nA key challenge in applying CGM to scientific fields is the sparseness of available data conditions, which requires extrapolation beyond observed conditions.\nThis paper proposes the Extended Flow Matching (EFM) framework to address this challenge.\nEFM achieves smooth transitions in distributions when departing from observed conditions, avoiding the unfavorable changes seen in existing flow matching (FM) methods.\nBy introducing a flow with respect to the conditional axis, EFM ensures that the conditional distribution changes gradually with the condition.\nSpecifically, we apply an extended Monge--Kantorovich theory to conditional generative models, creating a framework for learning matrix fields in a generalized continuity equation instead of vector fields.\nFurthermore, by combining the concept of Dirichlet energy on Wasserstein spaces with Multi-Marginal Optimal Transport (MMOT), we derive an algorithm called MMOT-EFM.\nThis algorithm controls the rate of change of the generated conditional distribution.\nOur proposed method outperforms existing methods in molecular generation tasks where conditions are sparsely observed."
    },
    {
        "title": "ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents",
        "link_suffix": "/forum?id=IIzehISTBe",
        "link": "https://openreview.net/forum?id=IIzehISTBe",
        "pdf_link": "https://openreview.net/pdf?id=IIzehISTBe",
        "keywords": "LLM Agent, Web Agent, Trust, Benchmark",
        "abstract": "Recent advancements in LLM-based web agents have introduced novel architectures and benchmarks showcasing progress in autonomous web navigation and interaction. However, most existing benchmarks prioritize effectiveness and accuracy, overlooking crucial factors like safety and trustworthiness\u2014both essential for deploying web agents in enterprise settings. The risks of unsafe web agent behavior, such as accidentally deleting user accounts or performing unintended actions in critical business operations, pose significant barriers to widespread adoption.\nIn this paper, we present ST-WebAgentBench, a new online benchmark specifically designed to evaluate the safety and trustworthiness of web agents in enterprise contexts. This benchmark is grounded in a detailed framework that defines safe and trustworthy (ST) agent behavior, outlines how ST policies should be structured and introduces the Completion under Policies metric to assess agent performance. \nOur evaluation reveals that current SOTA agents struggle with policy adherence and cannot yet be relied upon for critical business applications. Additionally, we propose architectural principles aimed at improving policy awareness and compliance in web agents. We open-source this benchmark and invite the community to contribute, with the goal of fostering a new generation of safer, more trustworthy AI agents. All code, data, environment reproduction resources, and video demonstrations are available at [blinded URL]"
    },
    {
        "title": "Cognitive Insights and Stable Coalition Matching for Fostering Multi-Agent Cooperation",
        "link_suffix": "/forum?id=0GC81gpjOo",
        "link": "https://openreview.net/forum?id=0GC81gpjOo",
        "pdf_link": "https://openreview.net/pdf?id=0GC81gpjOo",
        "keywords": "Multi-Agent Cooperation, LLM, Theory of Mind",
        "abstract": "Cognitive abilities, such as Theory of Mind (ToM), play a vital role in facilitating cooperation in human social interactions. However, Large Language Model (LLM) agents with higher ToM abilities do not necessarily exhibit better cooperative behavior compared to those with lower ToM abilities, highlighting the complexity of translating human cognitive processes to artificial intelligent agents. To address this challenge, we propose a novel matching coalition mechanism that leverages the strengths of agents with different ToM levels by explicitly considering belief alignment and specialized abilities when forming coalitions. Our proposed matching algorithm seeks to find stable coalitions that maximize the potential for cooperative behavior and ensure long-term viability. By incorporating cognitive insights into the design of multi-agent systems, our work demonstrates the potential of leveraging ToM to create more sophisticated and human-like coordination strategies that foster cooperation and improve overall system performance."
    },
    {
        "title": "Federated Few-Shot Class-Incremental Learning",
        "link_suffix": "/forum?id=ZiPoAlKf9Y",
        "link": "https://openreview.net/forum?id=ZiPoAlKf9Y",
        "pdf_link": "https://openreview.net/pdf?id=ZiPoAlKf9Y",
        "keywords": "Federated, Few-Shot, Class-Incremental Learning, Prototype-bias, Rectification",
        "abstract": "This study proposes a challenging yet practical Federated Few-Shot Class-Incremental Learning (FFSCIL) problem, where clients only hold very few samples for new classes.  We develop a novel Unified Optimized Prototype Prompt (UOPP) model to simultaneously handle catastrophic forgetting, over-fitting, and prototype bias in FFSCIL. UOPP utilizes task-wise prompt learning to mitigate task interference and over-fitting, unified static-dynamic prototypes to achieve a stability-plasticity balance, and adaptive dual heads for enhanced inferences. Dynamic prototypes represent new classes in the current few-shot task and are rectified to deal with prototype bias. Our comprehensive experimental results show that UOPP significantly outperforms state-of-the-art (SOTA) methods on three datasets with improvements up to $76%$ on average accuracy and $67%$ on balance mean accuracy respectively. Our extensive analysis shows UOPP robustness in various numbers of local clients and global rounds, low communication costs, and moderate running time. The source code of UOPP is publicly available at \\url{https://anonymous.4open.science/r/op71m15}."
    },
    {
        "title": "Interpretable Analysis and Reasoning Enhancement for LLMs via Cross-Generation Reasoning Trees",
        "link_suffix": "/forum?id=ON3QLXrwVb",
        "link": "https://openreview.net/forum?id=ON3QLXrwVb",
        "pdf_link": "https://openreview.net/pdf?id=ON3QLXrwVb",
        "keywords": "Large Language Models, LLM Reasoning",
        "abstract": "Generating diverse reasoning paths by varying the context (such as demonstrations, prompts, instructions, etc) or sampling methods (such as top-k, top-p, beam-search, etc) and then selecting appropriate paths via majority voting or verifier-based strategies to enhance the reasoning capabilities of large language models (LLMs) is a commonly recognized approach. Although both different contexts and sampling techniques can generate diverse contents, using sampling methods alone does not significantly enhance the diversity of generations. Context variation, however, while fostering greater diversity in reasoning, can also introduce negative effects, which causes that switching contexts can not necessarily lead to proportional improvements in performance. Therefore, there is a need to investigate how context influences LLM generation and mitigate any adverse impacts. The primary challenge lies in the inability to conduct comparative studies once divergences occur in reasoning paths generated under different contexts. Specifically, once the predicted tokens at a given step differ, it becomes unclear whether subsequent tokens in the inference path are influenced by the context or the content already generated. In this paper, we propose a Cross-Generation Reasoning Tree (CGRT) algorithm for studying the impact of different contexts on LLM generation and enhancing LLMs' reasoning performance. Experimental findings reveal that, beyond enhancing interpretability, CGRT integrates the positive effects of both context and sampling strategies more effectively than previous approaches, leading to more rational inference paths. Experiments conducted on Llama2, Llama3, and Qwen demonstrate that, when generating an equivalent number of diverse inference paths, those produced via the \"reasoning tree\" method exhibit higher accuracy."
    },
    {
        "title": "BiMix: Bivariate Data Mixing Law for Language Model Pretraining",
        "link_suffix": "/forum?id=JsM46OZix7",
        "link": "https://openreview.net/forum?id=JsM46OZix7",
        "pdf_link": "https://openreview.net/pdf?id=JsM46OZix7",
        "keywords": "Data Mixture, Large Language Models, Scaling Law",
        "abstract": "Large language models have demonstrated remarkable capabilities across various tasks, primarily attributed to the utilization of diversely sourced data. However, the impact of pretraining data composition on model performance remains poorly understood. This paper introduces BiMix, a novel bivariate data mixing law that models the joint scaling behavior of domain proportions and data volume in LLM pretraining. BiMix provides a systematic framework for understanding and optimizing data mixtures across diverse domains. Through extensive experiments on two large-scale datasets, we demonstrate BiMix's high accuracy in loss extrapolation (mean relative error $< 0.2%$) and its generalization to unseen mixtures (R$^{2} > 0.97$). Optimization of domain proportions yields superior model performance compared to existing methods. Furthermore, we establish entropy-based measures as efficient proxies for data mixing, offering a computationally lightweight strategy. Our work contributes both theoretical insights into data mixing dynamics and practical tools for enhancing LLM training efficiency, paving the way for more effective scaling strategies in language model development."
    },
    {
        "title": "Can VLMs Play Action Role-Playing Games? Take Black Myth Wukong as a Study Case",
        "link_suffix": "/forum?id=8Q0beBHq41",
        "link": "https://openreview.net/forum?id=8Q0beBHq41",
        "pdf_link": "https://openreview.net/pdf?id=8Q0beBHq41",
        "keywords": "VLMs, Agent, ARPGs, Benchmark, Dataset",
        "abstract": "Recently, large language model (LLM)-based agents have made significant advances across various fields. One of the most popular research areas involves applying these agents to video games. Traditionally, these methods have relied on game APIs to access in-game environmental and action data. However, this approach is limited by the availability of APIs and does not reflect how humans play games. With the advent of vision language models (VLMs), agents now have enhanced visual understanding capabilities, enabling them to interact with games using only visual inputs. Despite these advances, current approaches still face challenges in action-oriented tasks, particularly in action role-playing games (ARPGs), where reinforcement learning methods are prevalent but suffer from poor generalization and require extensive training. To address these limitations, we select an ARPG, ``Black Myth: Wukong'', as a research platform to explore the capability boundaries of existing VLMs in scenarios requiring visual-only input and complex action output. We define 13 tasks within the game, with 76.9% focusing on combat, and incorporate several state-of-the-art VLMs into this benchmark. Additionally, we will release a human operation dataset containing recorded gameplay videos and operation logs, including mouse and keyboard actions. Moreover, we propose a novel VARP (Vision Action Role-Playing) agent framework, consisting of an action planning system and a human-guided trajectory system. Our framework demonstrates the ability to perform basic tasks and succeed in 90% of easy and medium-level combat scenarios. This research aims to provide new insights and directions for applying multimodal agents in complex action game environments. The code and datasets will be made available athttps://varp-agent.github.io/."
    },
    {
        "title": "Memorisable Prompting: Preventing LLMs Forgetting False Positive Alarm",
        "link_suffix": "/forum?id=3viQDuclu0",
        "link": "https://openreview.net/forum?id=3viQDuclu0",
        "pdf_link": "https://openreview.net/pdf?id=3viQDuclu0",
        "keywords": "Prompt-based task, Large language model, Memorisable Prompting for Data Annotation",
        "abstract": "Large Language Models (LLMs) are widely recognized for their superior performance across various domains. However, their tendency to generate inaccurate or misleading responses presents significant challenges, particularly in the natural language domain. This issue underscores the need to enhance both the explainability and reliability of LLMs. While recent advancements in prompting have focused on leveraging in-context learning\u2014such as providing step-by-step explanations\u2014these approaches often overlook the critical importance of understanding the response dependency of LLMs on specific datasets. This understanding is crucial for interpreting their outputs and improving their consistency. Moreover, if we can capture and encode these response dependencies, we can integrate them into LLMs as memorized knowledge to mitigate false positive predictions over time. In this paper, we tackle this challenge by introducing the Memorizable Prompting (MP) paradigm, which enables LLMs to retain and utilize information from past responses. Specifically, our approach leverages hint samples\u2014a small set of annotated examples\u2014to learn the response dependencies, defined as the relationship between LLM outputs and the ground-truth annotations for a given dataset. This equips LLMs with the ability to recall past false positives and use that knowledge for self-correction in future predictions. We have evaluated our method on a diverse set of domain-specific datasets, demonstrating its effectiveness across large-scale benchmarks."
    },
    {
        "title": "GlycanML: A Multi-Task and Multi-Structure Benchmark for Glycan Machine Learning",
        "link_suffix": "/forum?id=owEQ0FTfVj",
        "link": "https://openreview.net/forum?id=owEQ0FTfVj",
        "pdf_link": "https://openreview.net/pdf?id=owEQ0FTfVj",
        "keywords": "Glycan Machine Learning, Representation Learning, Multi-Task Learning",
        "abstract": "Glycans are basic biomolecules and perform essential functions within living organisms. The rapid increase of functional glycan data provides a good opportunity for machine learning solutions to glycan understanding. However, there still lacks a standard machine learning benchmark for glycan property and function prediction. In this work, we fill this blank by building a comprehensive benchmark for Glycan Machine Learning (GlycanML). The GlycanML benchmark consists of diverse types of tasks including glycan taxonomy prediction, glycan immunogenicity prediction, glycosylation type prediction, and protein-glycan interaction prediction. Glycans can be represented by both sequences and graphs in GlycanML, which enables us to extensively evaluate sequence-based models and graph neural networks (GNNs) on benchmark tasks. Furthermore, by concurrently performing eight glycan taxonomy prediction tasks, we introduce the GlycanML-MTL testbed for multi-task learning (MTL) algorithms. Also, we evaluate how taxonomy prediction can boost other three function prediction tasks by MTL. Experimental results show the superiority of modeling glycans with multi-relational GNNs, and suitable MTL methods can further boost model performance."
    },
    {
        "title": "XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More",
        "link_suffix": "/forum?id=8X3OWi2weV",
        "link": "https://openreview.net/forum?id=8X3OWi2weV",
        "pdf_link": "https://openreview.net/pdf?id=8X3OWi2weV",
        "keywords": "Traffic Causal Analysis, Spatio-Temporal Forecasting, Incident Analysis",
        "abstract": "Long-separated research has been conducted on two highly correlated tracks: traffic and incidents. Traffic track witnesses complicating deep learning models, e.g., to push the prediction a few percent more accurate, and the incident track only studies the incidents alone, e.g., to infer the incident risk. We, for the first time, spatiotemporally aligned the two tracks in a large-scale region (16,972 traffic nodes) over the whole year of 2023: our XTraffic dataset includes traffic, i.e., time-series indexes on traffic flow, lane occupancy, and average vehicle speed, and incidents, whose records are spatiotemporally-aligned with traffic data, with seven different incident classes. Additionally, each node includes detailed physical and policy-level meta-attributes of lanes. Our data can revolutionalize traditional traffic-related tasks towards higher interpretability and practice: instead of traditional prediction or classification tasks, we conduct: (1) post-incident traffic forecasting to quantify the impact of different incidents on traffic indexes; (2) incident classification using traffic indexes to determine the incidents types for precautions measures; (3) global causal analysis among the traffic indexes, meta-attributes, and incidents to give high-level guidance of the interrelations of various factors; (4) local causal analysis within road nodes to examine how different incidents affect the road segments' relations. The dataset is available athttps://anonymous.4open.science/r/XTraffic-E069."
    },
    {
        "title": "Optimistic Games for Combinatorial Bayesian Optimization with Application to Protein Design",
        "link_suffix": "/forum?id=xiyzCfXTS6",
        "link": "https://openreview.net/forum?id=xiyzCfXTS6",
        "pdf_link": "https://openreview.net/pdf?id=xiyzCfXTS6",
        "keywords": "Combinatorial Bayesian Optimization, Game Theory, Gaussian Processes, Protein Design",
        "abstract": "Bayesian optimization (BO) is a powerful framework to optimize black-box expensive-to-evaluate functions via sequential interactions. In several important problems (e.g. drug discovery, circuit design, neural architecture search, etc.), though, such functions are defined over large $\\textit{combinatorial and unstructured}$ spaces. This makes existing BO algorithms not feasible due to the intractable maximization of the acquisition function over these domains. To address this issue, we propose $\\textbf{GameOpt}$, a novel game-theoretical approach to combinatorial BO. $\\textbf{GameOpt}$ establishes a cooperative game between the different optimization variables, and selects points that are game $\\textit{equilibria}$ of an upper confidence bound acquisition function. These are stable configurations from which no variable has an incentive to deviate$-$ analog to local optima in continuous domains. Crucially, this allows us to efficiently break down the complexity of the combinatorial domain into individual decision sets, making $\\textbf{GameOpt}$ scalable to large combinatorial spaces. We demonstrate the application of $\\textbf{GameOpt}$ to the challenging $\\textit{protein design}$ problem and validate its performance on four real-world protein datasets. Each protein can take up to $20^{X}$ possible configurations, where $X$ is the length of a protein, making standard BO methods infeasible. Instead, our approach iteratively selects informative protein configurations and very quickly discovers highly active protein variants compared to other baselines."
    },
    {
        "title": "MatPool: Matrix-pattern-oriented Pooling for Graph Property Prediction",
        "link_suffix": "/forum?id=Bjerq2n9h3",
        "link": "https://openreview.net/forum?id=Bjerq2n9h3",
        "pdf_link": "https://openreview.net/pdf?id=Bjerq2n9h3",
        "keywords": "Graph Pooling, Matrix-Pattern-Oriented, Matrix Neural Network, Graph Neural Network",
        "abstract": "Graph property prediction usually involves using a model to predict the label for the entire graph, which often has complex structures. Because input graphs have different sizes, current methods generally use graph pooling to coarsen them into a graph-level representation with a unified vector pattern. However, this coarsening process can lead to a significant loss of graph information. In this work, we explore the graph representation by using a matrix pattern and introduce an algorithm called Matrix-pattern-oriented Pooling (MatPool) that provides a unified graph-level representation for different graphs. MatPool multiplies the transposed feature matrix by the feature matrix itself and then conducts an isomorphic mapping to create a Matrix Representation (MR) that preserves the graph information and satisfies permutation invariance. Since the multiplication operation calculates the relationships between each feature, MR exhibits row-column correlations under the matrix pattern. To match this correlation, MatPool uses a novel and efficient Matrix Neural Network (MNN) with two-sided weight matrices to match the row-column correlation under the matrix pattern. We provide theoretical analyses to reveal the properties of MatPool and explain why it can preserve graph information and satisfy the permutation invariance. Extensive experiments on various graph property prediction benchmarks show the efficiency and effectiveness of MatPool."
    },
    {
        "title": "Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?",
        "link_suffix": "/forum?id=xrgXaOV6dK",
        "link": "https://openreview.net/forum?id=xrgXaOV6dK",
        "pdf_link": "https://openreview.net/pdf?id=xrgXaOV6dK",
        "keywords": "LLM-as-a-Judge, AI annotators, evaluation, tool-use",
        "abstract": "Pairwise preferences over model responses are widely collected to evaluate and provide feedback to large language models (LLMs). Given two alternative model responses to the same input, a human or AI annotator selects the \u201cbetter\u201d response. This approach can provide feedback for domains where other hard-coded metrics are difficult to obtain (e.g., quality of a chat interactions), thereby helping measure model progress or model fine-tuning (e.g., via reinforcement learning from human feedback, RLHF). However, for some domains it can be tricky to obtain such pairwise comparisons in high quality - from AI and humans. For example, for responses with many factual statements or complex code, annotators may overly focus on simpler features such as writing quality rather the underlying facts or technical details. In this work, we explore augmenting standard AI annotator systems with additional tools to improve performance on three challenging response domains: long-form factual, math and code tasks. We propose a tool-using agentic system to provide higher quality feedback on these domains. Our system uses web-search and code execution to ground itself based on external validation, independent of the LLM\u2019s internal knowledge and biases. We provide extensive experimental results evaluating our method across the three targeted response domains as well as general annotation tasks, using RewardBench data (incl. AlpacaEval and LLMBar), as well as three new datasets for areas where pre-existing datasets are saturated. Our results indicate that external tools can indeed improve AI annotator performance in many, but not all, cases. More generally, our experiments highlight the high variability of AI annotator performance with respect to simple parameters (e.g., prompt) and the need for improved (non-saturated) annotator benchmarks. We share our data and code publicly."
    },
    {
        "title": "Refined Generalization Analysis of the Deep Ritz Method and Physics-Informed Neural Networks",
        "link_suffix": "/forum?id=vsLohTBH4h",
        "link": "https://openreview.net/forum?id=vsLohTBH4h",
        "pdf_link": "https://openreview.net/pdf?id=vsLohTBH4h",
        "keywords": "Deep Ritz Method, Physics-Informed Neural Networks, Generalization analysis, Fast Rate",
        "abstract": "In this paper, we derive refined generalization bounds for the Deep Ritz Method (DRM) and Physics-Informed Neural Networks (PINNs). For the DRM, we focus on two prototype elliptic partial differential equations (PDEs): Poisson equation and static Schr\u00f6dinger equation on the $d$-dimensional unit hypercube with the Neumann boundary condition. Furthermore, sharper generalization bounds are derived based on the localization techniques under the assumptions that the exact solutions of the PDEs lie in the Barron spaces or the general Sobolev spaces. For the PINNs, we investigate the general linear second order elliptic PDEs with Dirichlet boundary condition using the local Rademacher complexity in the multi-task learning setting. Finally, we discuss the generalization error in the setting of over-parameterization when solutions of PDEs belong to Barron space."
    },
    {
        "title": "Neuron-Level Sequential Editing for Large Language Models",
        "link_suffix": "/forum?id=k1mMxqalb0",
        "link": "https://openreview.net/forum?id=k1mMxqalb0",
        "pdf_link": "https://openreview.net/pdf?id=k1mMxqalb0",
        "keywords": "Model Editing, Large Language Model",
        "abstract": "This work explores sequential model editing in large language models (LLMs), a critical task that involves modifying internal knowledge within LLMs continuously through multi-round editing, each incorporating updates or corrections to adjust the model\u2019s outputs without the need for costly retraining. Existing model editing methods, especially those that alter model parameters, typically focus on single-round editing and often face significant challenges in sequential model editing-most notably issues of model forgetting and failure. To address these challenges, we introduce a new model editing method, namely \\textbf{N}euron-level \\textbf{S}equential \\textbf{E}diting (NSE), tailored for supporting sequential model editing. Specifically, we optimize the target layer's hidden states using the model's original weights to prevent model failure. Furthermore, we iteratively select neurons in multiple layers for editing based on their activation values to mitigate model forgetting. Our empirical experiments demonstrate that NSE significantly outperforms current modifying parameters model editing methods, marking a substantial advancement in the field of sequential model editing. Our code is released on \\url{https://anonymous.4open.science/r/NSE-0A8D/}."
    },
    {
        "title": "Maximum Total Correlation Reinforcement Learning",
        "link_suffix": "/forum?id=JeiaHDawhb",
        "link": "https://openreview.net/forum?id=JeiaHDawhb",
        "pdf_link": "https://openreview.net/pdf?id=JeiaHDawhb",
        "keywords": "Reinforcement Learning, Total Correlation",
        "abstract": "Simplicity is a powerful inductive bias. In reinforcement learning, regularization is used for simpler policies, data augmentation for simpler representations, and sparse reward functions for simpler objectives, all that, with the underlying motivation to increase generalizability and robustness by focusing on the essentials. Supplementary to these techniques, we investigate how to promote simple behavior throughout the duration of the episode. To that end, we introduce a modification of the reinforcement learning problem, that additionally maximizes the total correlation within the induced trajectories. We propose a practical algorithm that optimizes all models, including policy and state representation, based on a lower bound approximation. In simulated robot locomotion environments, our method naturally generates policies that induce periodic and compressible trajectories, and that exhibit superior robustness to noise and changes in dynamics compared to baseline methods, while also improving performance in the original tasks."
    },
    {
        "title": "Linearly Interpretable Concept Embedding Model for Text Classification",
        "link_suffix": "/forum?id=zp88xOXAfS",
        "link": "https://openreview.net/forum?id=zp88xOXAfS",
        "pdf_link": "https://openreview.net/pdf?id=zp88xOXAfS",
        "keywords": "CBM, XAI, Interpretable AI",
        "abstract": "Despite their success, Large-Language Models (LLMs) still face criticism due to their lack of interpretability.\nTraditional post-hoc interpretation methods, based on attention and gradient-based analysis, offer limited insight as they only approximate the model's decision-making processes and have been proved to be unreliable.\nFor this reason, Concept-Bottleneck Models (CBMs) have been lately proposed in the textual field to provide interpretable predictions based on human-understandable concepts. \nHowever, CBMs still face several criticisms for their architectural constraints limiting their expressivity, for the absence of task-interpretability when employing non-linear task predictors and for requiring extensive annotations that are impractical for real-world text data. In this paper we address these challenges by proposing a novel Linearly Interpretable Concept Embedding Model (LICEM) going beyond the current accuracy-interpretability trade-off. LICEM classification accuracy is better than existing interpretable models and matches black-box models. The provided explanations are more plausible and useful with respect to existing solutions, as attested in a user study. Finally, we show our model can be trained without requiring any concept supervision, as concepts can be automatically predicted by the same LLM backbone."
    },
    {
        "title": "Differentially Private Network Training under Hidden State Assumption",
        "link_suffix": "/forum?id=APy5Vdn8Yl",
        "link": "https://openreview.net/forum?id=APy5Vdn8Yl",
        "pdf_link": "https://openreview.net/pdf?id=APy5Vdn8Yl",
        "keywords": "Differential Privacy, Coordinate Descent",
        "abstract": "We present a novel approach called differentially private stochastic block coordinate descent (DP-SBCD) for training neural networks with provable guarantees of differential privacy under the hidden state assumption. Our methodology regards neural networks as optimization problems and decomposes the training process of the neural network into sub-problems, each corresponding to the training of a specific layer. By doing so, we extend the analysis of differential privacy under the hidden state assumption to encompass non-convex problems and algorithms employing proximal gradient descent. Furthermore, in contrast to existing methods, we adopt a novel approach by utilizing calibrated noise sampled from adaptive distributions, yielding improved empirical trade-offs between utility and privacy."
    }
]
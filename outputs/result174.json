[
    {
        "title": "Stochastic Semi-Gradient Descent for Learning Mean Field Games with Population-Aware Function Approximation",
        "link_suffix": "/forum?id=tfO07iz0b9",
        "link": "https://openreview.net/forum?id=tfO07iz0b9",
        "pdf_link": "https://openreview.net/pdf?id=tfO07iz0b9",
        "keywords": "mean field game, linear function approximation, stochastic semi-gradient descent",
        "abstract": "Mean field games (MFGs) model interactions in large-population multi-agent systems through population distributions. Traditional learning methods for MFGs are based on fixed-point iteration (FPI), where policy updates and induced population distributions are computed separately and sequentially. However, FPI-type methods may suffer from inefficiency and instability due to potential oscillations caused by this forward-backward procedure. In this work, we propose a novel perspective that treats the policy and population as a unified parameter controlling the game dynamics. By applying stochastic parameter approximation to this unified parameter, we develop SemiSGD, a simple stochastic gradient descent (SGD)-type method, where an agent updates its policy and population estimates simultaneously and fully asynchronously. Building on this perspective, we further apply linear function approximation (LFA) to the unified parameter, resulting in the first population-aware LFA (PA-LFA) for learning MFGs on continuous state-action spaces. A comprehensive finite-time convergence analysis is provided for SemiSGD with PA-LFA, including its convergence to the equilibrium for linear MFGs\u2014a class of MFGs with a linear structure concerning the population\u2014under the standard contractivity condition, and to a neighborhood of the equilibrium under a more practical condition. We also characterize the approximation error for non-linear MFGs. We validate our theoretical findings with six experiments on three MFGs."
    },
    {
        "title": "Visually Consistent Hierarchical Image Classification",
        "link_suffix": "/forum?id=7HEMpBTb3R",
        "link": "https://openreview.net/forum?id=7HEMpBTb3R",
        "pdf_link": "https://openreview.net/pdf?id=7HEMpBTb3R",
        "keywords": "Hierarchical Classification, Visual grounding",
        "abstract": "Hierarchical classification  requires predicting an entire taxonomy tree rather than a single flat level, which demands both  accurate predictions at each level and consistency across levels.  However, solving hierarchical classification often compromises fine-grained accuracy compared to flat classification because each level requires distinct features, making it a multi-task problem.\nFor example, the fine-grained classification of \"Green Hermit\" and \"Ruby-throated Hummingbird\" demands more specific details, while distinguishing between \"bird\" and \"plant\" at the coarse level requires  broader features.\nPrior methods address  this  by using  separate blocks for each level to learn distinct  features. \nHowever, this approach struggles  to resolve inconsistencies, as classifiers tend to focus on different, unrelated regions.Our key insight is that classifiers across  levels should be grounded in consistent visual cues. For example, the fine-grained classifier may  focus on details such as the beak and wings to identify a  \"Green Hermit\", and then the coarse classifier identifies \"bird\" by grouping these details into the overall \"bird\" shape.\nTherefore, we propose a novel hierarchical model that grounds fine-to-coarse  semantic parsing on consistent hierarchical visual segmentation.  We also introduce a tree-path KL divergence loss to enforce semantic consistency across levels. Our approach significantly outperforms zero-shot CLIP and other state-of-the-art methods on common hierarchical classification benchmarks. Codes will be made publicly available."
    },
    {
        "title": "Efficient Sequential Policy Optimization via Off-Policy Correction in Multi-Agent Reinforcement Learning",
        "link_suffix": "/forum?id=n6Gg0D2jWT",
        "link": "https://openreview.net/forum?id=n6Gg0D2jWT",
        "pdf_link": "https://openreview.net/pdf?id=n6Gg0D2jWT",
        "keywords": "trust region policy optimization, multi-agent learning",
        "abstract": "Although trust region policy optimization methods have achieved a lot of success in cooperative multi-agent tasks, most of them face a non-stationarity problem during the learning process. Recently, sequential trust region methods that update policies agent-by-agent have shed light on alleviating the non-stationarity problem. However, these methods are still less sample-efficient when compared to their counterparts (i.e., PPO) in a single-agent setting. To narrow this efficiency gap, we propose the Off-Policyness-aware Sequential Policy Optimization (OPSPO) method, which explicitly manages the off-policyness that arises from the sequential policy update process among multiple agents. We prove that our OPSPO has the tightness of the monotonic improvement bound compared with other trust region multi-agent learning methods. Finally, we demonstrate that our OPSPO consistently outperforms strong baselines under challenging multi-agent benchmarks, including StarCraftII micromanagement tasks, Multi-agent MuJoCo, and Google Research Football full game scenarios."
    },
    {
        "title": "CineMorph: Learning Time-Continuous Motion Field for Motion Tracking on Cine Magnetic Resonance Images",
        "link_suffix": "/forum?id=PN4f0hnI0U",
        "link": "https://openreview.net/forum?id=PN4f0hnI0U",
        "pdf_link": "https://openreview.net/pdf?id=PN4f0hnI0U",
        "keywords": "Motion tracking, cine MRI, unsupervised learning, diffeomorphic",
        "abstract": "Tracking cardiac motion using cine magnetic resonance imaging (cine MRI) is essential for evaluating cardiac function and diagnosing cardiovascular diseases. Current methods for cardiac motion tracking depend on scaling and squaring (SS) integration to learn discrete Lagrangian motion fields. However, this reliance hinders the effective exploitation of temporal continuity, leading to inadequate tracking accuracy. In this paper, we introduce a novel unsupervised learning method, CineMorph, to achieve temporally continuous cardiac motion tracking in cine MRI image sequences. Our approach integrates a frame-aware UNet with a series of time-continuous Transformer blocks to learn temporally continuous intra-frame motion fields, which are then assembled into time-continuous Lagrangian motion fields. To ensure the diffeomorphism property, we implement semigroup regularization to constrain our model, thus eliminating the reliance on SS integration. We evaluate our method on the public Automatic Cardiac Diagnostic Challenge (ACDC) dataset. The experimental results show that our method outperforms the existing state-of-the-art methods and achieves state-of-the-art performance with a mean DICE score of $83.6%$ and a mean Hausdorff distance of $3.4$ mm."
    },
    {
        "title": "Second-Order Fine-Tuning without Pain for LLMs: A Hessian Informed Zeroth-Order Optimizer",
        "link_suffix": "/forum?id=bEqI61iBue",
        "link": "https://openreview.net/forum?id=bEqI61iBue",
        "pdf_link": "https://openreview.net/pdf?id=bEqI61iBue",
        "keywords": "LLM; deep learning; zeroth order optimizer",
        "abstract": "Fine-tuning large language models (LLMs) is necessary for specific downstream tasks, but classic first-order optimizer entails prohibitive GPU memory because of the back propagation. Recent works such as MeZO have turned to zeroth-order optimizers for fine-tuning, which reduce substantial memory by using two forward passes. However, heterogeneous curvatures across different parameter dimensions in LLMs often cause model convergence instability or even failure. In this work, we propose HiZOO, a diagonal Hessian informed Zeroth-Order Optimizer , which is the first work to leverage the diagonal Hessian to enhance ZOO for fine-tuning LLMs. We provide theoretical proof for HiZOO and visualize the optimization trajectories on test functions to illustrate how it improves convergence in handling heterogeneous curvatures. Extensive experiments on various models (RoBERTa, OPT, Phi-2 and LLama3, with 350M$\\sim$66B parameters) indicate that HiZOO significantly reduces training steps and enhances model accuracy, while keeping the memory advantage of ZOO. For example, on SST2 task HiZOO achieves $8\\times$ speedup and better accuracy over MeZO across different models. We also propose HiZOO-L, which reduces the Hessian memory cost to 10% of the MeZO, while maintaining almost same performance. Compared with ZO-Adam, HiZOO-L achieves a 4.3% improvement, just using 50% of the GPU memory. Code is available athttps://anonymous.4open.science/r/HiZOO-27F8."
    },
    {
        "title": "A Comprehensive Graph Pooling Benchmark: Effectiveness, Robustness and Generalizability",
        "link_suffix": "/forum?id=Onw93uJCWO",
        "link": "https://openreview.net/forum?id=Onw93uJCWO",
        "pdf_link": "https://openreview.net/pdf?id=Onw93uJCWO",
        "keywords": "Graph Pooling; Benchmark; Graph Neural Networks; Graph Machine Learning",
        "abstract": "Graph pooling has gained attention for its ability to obtain effective node and graph representations for various downstream tasks. Despite the recent surge in graph pooling approaches, there is a lack of standardized experimental settings and fair benchmarks to evaluate their performance. To address this issue, we have constructed a comprehensive benchmark that includes 17 graph pooling methods and 28 different graph datasets. This benchmark systematically assesses the performance of graph pooling methods in three dimensions, i.e., effectiveness, robustness, and generalizability. We first evaluate the performance of these graph pooling approaches across different tasks including graph classification, graph regression and node classification. Then, we investigate their performance under potential noise attacks and out-of-distribution shifts in real-world scenarios. We also involve detailed efficiency analysis, backbone analysis, parameter analysis and visualization to provide more evidence. Extensive experiments validate the strong capability and applicability of graph pooling approaches in various scenarios, which can provide valuable insights and guidance for deep geometric learning research. The source code of our benchmark is available at \\url{https://anonymous.4open.science/r/Graph_Pooling_Benchmark-8EDD}."
    },
    {
        "title": "Janus: Dual-server Multi-Round Secure Aggregation with Verifiability for Federated Learning",
        "link_suffix": "/forum?id=7WAMJsDNDE",
        "link": "https://openreview.net/forum?id=7WAMJsDNDE",
        "pdf_link": "https://openreview.net/pdf?id=7WAMJsDNDE",
        "keywords": "federated learning, secure aggregation, privacy enhancement",
        "abstract": "Secure Aggregation (SA) in federated learning is essential for preserving user privacy by ensuring that model updates are masked or encrypted and remain inaccessible to servers. Although the advanced protocol Flamingo (S&P'23) has made significant strides with its multi-round aggregation and optimized communication, it still faces several critical challenges: (i) $\\textit{Dynamic User Participation}$, where Flamingo struggles with scalability due to the complex setups required when users join or leave the training process; (ii) $\\textit{Model Inconsistency Attacks}$ (MIA), where a malicious server could infer sensitive data, which poses severe privacy risks; and (iii) $\\textit{Verifiability}$, as most schemes lack an efficient mechanism for clients to verify the correctness of server-side aggregation, potentially allowing inaccuracies or malicious actions. We introduce Janus, a generic privacy-enhanced multi-round SA scheme through a dual-server architecture. A new user can participate in training by simply obtaining the servers' public keys for aggregation, eliminating the need for complex communication graphs. Our dual-server model separates aggregation tasks, which ensures that neither server has access to the final aggregated results, thus effectively preventing MIA. Additionally, we propose a new cryptographic primitive, $\\textit{Separable Homomorphic Commitment}$, integrated with our dual-server approach to ensure the verifiability of aggregation results. Extensive experiments across various models and datasets show that Janus significantly boosts security while enhancing efficiency. It reduces per-client communication and computation overhead from  logarithmic to constant scale compared to state-of-the-art methods, with almost no compromise in model accuracy."
    },
    {
        "title": "BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models",
        "link_suffix": "/forum?id=G2p8TLuJgy",
        "link": "https://openreview.net/forum?id=G2p8TLuJgy",
        "pdf_link": "https://openreview.net/pdf?id=G2p8TLuJgy",
        "keywords": "Large Language Model, Backdoor Attack, GPT-4, Retrieval-Augmented Generation",
        "abstract": "Large Language Models (LLMs) are constrained by outdated information and a tendency to generate incorrect data, commonly referred to as \"hallucinations.'' Retrieval-Augmented Generation (RAG) addresses these limitations by combining the strengths of retrieval-based methods and generative models. This approach involves retrieving relevant information from a large, up-to-date database and using it to enhance the generation process, leading to more accurate and contextually appropriate responses. Despite its benefits, RAG introduces a new attack surface for LLMs, particularly because RAG databases are often sourced from public data, such as the web. In this paper, we propose BadRAG to identify the vulnerabilities and attacks on retrieval parts (RAG databases) and their indirect attacks on generative parts (LLMs). Specifically, we identify that poisoning several customized content passages could achieve a retrieval backdoor, where the retrieval works well for clean queries but always returns customized adversarial passages for triggered queries. Triggers and adversarial passages can be highly customized to implement various attacks. For example, a trigger could be a semantic group likeThe Republican Party,Donald Trump, etc. Adversarial passages can be tailored to different contents, not only linked to the triggers but also used to indirectly attack generative LLMs without modifying them. These attacks can include denial-of-service attacks on RAG and semantic steering attacks on LLM generations conditioned by the triggers. Our experiments demonstrate that by just poisoning 10 adversarial passages $\\textemdash$ merely 0.04% of the total corpus $\\textemdash$ can induce 98.2% success rate to retrieve the adversarial passages. Then, these passages can increase the reject ratio of RAG-based GPT-4 from 0.01% to 74.6% or increase the rate of negative responses from 0.22% to 72% for targeted queries. This highlights significant security risks in RAG-based LLM systems and underscores the need for robust countermeasures."
    },
    {
        "title": "CAMMARL: Conformal Action Modeling in Multi Agent Reinforcement Learning",
        "link_suffix": "/forum?id=6Imw3BwOMo",
        "link": "https://openreview.net/forum?id=6Imw3BwOMo",
        "pdf_link": "https://openreview.net/pdf?id=6Imw3BwOMo",
        "keywords": "multi agent learning, agent modeling",
        "abstract": "Before taking actions in an environment with more than one intelligent agent, an autonomous agent may benefit from reasoning about the other agents and utilizing a notion of a guarantee or confidence about the behavior of the system. In this article, we propose a novel multi-agent reinforcement learning (MARL) algorithm CAMMARL, which involves modeling the actions of other agents in different situations in the form of confident sets, i.e., sets containing their true actions with a high probability. We then use these estimates to inform an agent\u2019s decision-making. For estimating such sets, we use the concept of conformal predictions, by means of which, we not only obtain an estimate of the most probable outcome but get to quantify the operable uncertainty as well. For instance, we can predict a set that provably covers the true predictions with high probabilities (e.g., 95%). Through several experiments in two fully cooperative multi-agent tasks, we show that CAMMARL elevates the capabilities of an autonomous agent in MARL by modeling conformal prediction sets over the behavior of other agents in the environment and utilizing such estimates to enhance its policy learning"
    },
    {
        "title": "TurboRAG: Accelerating Retrieval-Augmented Generation with Precomputed KV Caches for Chunked Text",
        "link_suffix": "/forum?id=x7NbaU8RSU",
        "link": "https://openreview.net/forum?id=x7NbaU8RSU",
        "pdf_link": "https://openreview.net/pdf?id=x7NbaU8RSU",
        "keywords": "Retrieval-Augmented Generation; Large Language Models; Precomputed KV Cache",
        "abstract": "Current Retrieval-Augmented Generation (RAG) systems concatenate and process numerous retrieved document chunks for prefill which requires a large volume of computation, therefore leading to significant latency in time-to-first-token (TTFT). To reduce the computation overhead as well as TTFT, we introduce TurboRAG, a novel RAG system that redesigns the inference paradigm of the current RAG system by first pre-computing and storing the key-value (KV) caches of documents offline, and then directly retrieving the saved KV cache for prefill. Hence, online computation of KV caches is eliminated during inference. In addition, we provide a number of insights into the mask matrix and positional embedding mechanisms, plus fine-tune a pretrained language model to maintain model accuracy of TurboRAG. Our approach is applicable to most existing large language models and their applications without any requirement in modification of models and inference systems. Experimental results across a suite of RAG benchmarks demonstrate that TurboRAG reduces TTFT by up to 9.4x compared to the conventional RAG systems (on an average of 8.6x), but reserving comparable performance to the standard RAG systems."
    },
    {
        "title": "Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning",
        "link_suffix": "/forum?id=6Ai8SuDsh3",
        "link": "https://openreview.net/forum?id=6Ai8SuDsh3",
        "pdf_link": "https://openreview.net/pdf?id=6Ai8SuDsh3",
        "keywords": "Imitation Learning, Policy Diversity, Offline Learning",
        "abstract": "Recovering a spectrum of diverse policies from a set of expert trajectories is an important research topic in imitation learning. After determining a latent style for a trajectory, previous diverse polices recovering methods usually employ a vanilla behavioral cloning learning objective conditioned on the latent style, treating each state-action pair in the trajectory with equal importance. Based on an observation that in many scenarios, behavioral styles are often highly relevant with only a subset of state-action pairs, this paper presents a new principled method in diverse polices recovering. In particular, after inferring or assigning a latent style for a trajectory, we enhance the vanilla behavioral cloning by incorporating a weighting mechanism based on pointwise mutual information.\nThis additional weighting reflects the significance of each state-action pair's contribution to learning the style, thus allowing our method to focus on state-action pairs most representative of that style.\nWe provide theoretical justifications for our new objective, and extensive empirical evaluations confirm the effectiveness of our method in recovering diverse polices from expert data."
    },
    {
        "title": "BiLO: Bilevel Local Operator Learning for PDE inverse problems",
        "link_suffix": "/forum?id=uIg9Vcw2CY",
        "link": "https://openreview.net/forum?id=uIg9Vcw2CY",
        "pdf_link": "https://openreview.net/pdf?id=uIg9Vcw2CY",
        "keywords": "Partial Differential Equations, physics-informed, PINN, inverse problem, Bilevel optimization, Neural Operator",
        "abstract": "We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. We demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to soft PDE constraints."
    },
    {
        "title": "An Effective Manifold-based Optimization Method for Distributionally Robust Classification",
        "link_suffix": "/forum?id=nzjSvVZBIp",
        "link": "https://openreview.net/forum?id=nzjSvVZBIp",
        "pdf_link": "https://openreview.net/pdf?id=nzjSvVZBIp",
        "keywords": "robustness, optimization, representation learning",
        "abstract": "How to promote the robustness of existing deep learning models is a  challenging problem for many practical classification tasks. Recently, Distributionally Robust Optimization (DRO) methods have shown promising potential to tackle this problem. These methods aim to construct reliable models by minimizing the worst-case risk within a local region (called ''uncertainty set'') around the empirical data distribution. However, conventional DRO methods tend to be overly pessimistic, leading to certain discrepancy between the real data distribution and the uncertainty set, which can degrade the classification performance. To address this issue, we propose a manifold-based DRO method that takes the geometric structure of training data  into account for constructing the uncertainty set. Specifically, our method employs a carefully designed ''game'' that integrates contrastive learning with Jacobian regularization to capture the manifold structure, enabling us to solve DRO problems constrained by the data manifold. By utilizing a novel idea for approximating geodesic distance on manifolds, we also provide the theoretical guarantees for its robustness. Moreover, our proposed method is easy to implement in practice. We conduct a set of experiments on several popular benchmark datasets, where the results demonstrate our advantages in terms of accuracy and robustness."
    },
    {
        "title": "Towards Graph Foundation Models: Learning Generalities Across Graphs via Task-trees",
        "link_suffix": "/forum?id=kSBIEkHzon",
        "link": "https://openreview.net/forum?id=kSBIEkHzon",
        "pdf_link": "https://openreview.net/pdf?id=kSBIEkHzon",
        "keywords": "Graph Neural Network, Graph Foundation Model, Transferable Pattern, Tree Structure",
        "abstract": "Foundation models aim to create general, cross-task, and cross-domain machine learning models by pretraining on large-scale datasets to capture shared patterns or concepts (generalities), such as contours, colors, textures, and edges in images, or tokens, words, and sentences in text. However, discovering generalities across graphs remains challenging, which has hindered the development of graph foundation models. To tackle this challenge, in this paper, we propose a novel approach to learn generalities across graphs via task-trees. Specifically, we first define the basic learning instances in graphs as task-trees and assume that the generalities shared across graphs are, at least partially, preserved in the task-trees of the given graphs. To validate the assumption, we first perform a theoretical analysis of task-trees in terms of stability, transferability, and generalization. We find that if a graph neural network (GNN) model is pretrained on diverse task-trees through a reconstruction task, it can learn sufficient transferable knowledge for downstream tasks using an appropriate set of fine-tuning samples. To empirically validate the assumption, we further instantiate the theorems by developing a cross-task, cross-domain graph foundation model named Graph generality Identifier on task-Trees (GIT). The extensive experiments over 30 graphs from five domains demonstrate the effectiveness of GIT in fine-tuning, in-context learning, and zero-shot learning scenarios. Particularly, the general GIT model pretrained on large-scale datasets can be quickly adapted to specific domains, matching or even surpassing expert models designed for those domains."
    },
    {
        "title": "Planning in a recurrent neural network that plays Sokoban",
        "link_suffix": "/forum?id=ORxjH9kTp8",
        "link": "https://openreview.net/forum?id=ORxjH9kTp8",
        "pdf_link": "https://openreview.net/pdf?id=ORxjH9kTp8",
        "keywords": "Interpretability, Mechanistic Interpretability, Planning, LSTM, Reinforcement Learning",
        "abstract": "How a neural network (NN) generalizes to novel situations depends on whether it has learned to select actions heuristically or via a planning process. Guez et al., (2019, \"An investigation of model-free planning\") found that recurrent NN (RNN) trained to play Sokoban appears to plan, with extra computation steps improving the RNN's success rate. We replicate and expand on their behavioral analysis, finding the RNN learns to give itself extra computation steps in complex situations by \"pacing\" in cycles. Moreover, we train linear probes that predict the future actions taken by the network and find that intervening on the hidden state using these probes controls the agent\u2019s subsequent actions. Leveraging these insights, we perform model surgery, enabling the convolutional NN to generalize beyond its $10 \\times 10$ architectural limit to arbitrarily sized levels. The resulting model solves challenging, highly off-distribution levels. We open-source our model and code, and believe its small size (1.29M parameters) makes it an excellent model organism to deepen our understanding of learned planning."
    },
    {
        "title": "Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment",
        "link_suffix": "/forum?id=h1XoHOd19I",
        "link": "https://openreview.net/forum?id=h1XoHOd19I",
        "pdf_link": "https://openreview.net/pdf?id=h1XoHOd19I",
        "keywords": "LLM, Continual Pre-training, knowledge distillation",
        "abstract": "Adapting large language models (LLMs) to specialized domains typically requires domain-specific corpora for continual pre-training to facilitate knowledge memorization and related instructions for fine-tuning to apply this knowledge.\nHowever, this method may lead to inefficient knowledge memorization due to a lack of awareness of knowledge utilization during the continual pre-training and demands LLMs to simultaneously learn knowledge utilization and format alignment with divergent training objectives during the fine-tuning.\nTo enhance the domain adaptation of LLMs, we revise this process and propose a new domain adaptation framework including domain knowledge learning and general format alignment, called \\emph{Mix-CPT}. Specifically, we first conduct a knowledge mixture continual pre-training that concurrently focuses on knowledge memorization and utilization. To avoid catastrophic forgetting, we further propose a logit swap self-distillation constraint. By leveraging the knowledge and capabilities acquired during continual pre-training, we then efficiently perform instruction tuning and alignment with a few general training samples to achieve format alignment.\nExtensive experiments show that our proposed \\emph{Mix-CPT} framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains."
    },
    {
        "title": "Benchmarking and Rethinking Multiplex Graphs",
        "link_suffix": "/forum?id=RvyJ5iy9LS",
        "link": "https://openreview.net/forum?id=RvyJ5iy9LS",
        "pdf_link": "https://openreview.net/pdf?id=RvyJ5iy9LS",
        "keywords": "graph neural networks, multiplex graphs, graph benchmark, datasets",
        "abstract": "Multiplex graphs, which represent complex real-world relationships, have recently garnered significant research interest. However, contemporary methods exhibit variations in implementations and settings, lacking a unified benchmark for fair comparison. Additionally, existing multiplex graph datasets suffer from small-scale issues and a lack of representative features. Furthermore, current evaluation metrics are restricted to node classification and clustering tasks, lacking evaluations on edge-level tasks. These obstacles impede the further development of the multiplex graph learning community. To address these issues, we first conducted a fair comparison based on existing settings, finding that current methods are approaching performance saturation on existing datasets with minimal differences; and simple end-to-end models sometimes achieve better results. Subsequently, we proposed a unified multiplex graph benchmark called MGB. MGB includes ten baseline models with unified implementations, formalizes seven existing datasets, introduces four new datasets with text attributes, and proposes two novel edge-level evaluation tasks. Experiments on MGB revealed that the performance of existing methods significantly diminishes on new challenging datasets and tasks. Additional results suggest that models with global attention and stronger expressive power in end-to-end solutions hold promise for future work. The data, code, and documentations are publicly available athttps://anonymous.4open.science/r/multiplex-F150."
    },
    {
        "title": "Revisiting and Benchmarking Graph Autoencoders: A Contrastive Learning Perspective",
        "link_suffix": "/forum?id=lYXhiCYkPn",
        "link": "https://openreview.net/forum?id=lYXhiCYkPn",
        "pdf_link": "https://openreview.net/pdf?id=lYXhiCYkPn",
        "keywords": "graph autoencoders; masked graph autoencoders; graph contrastive learning",
        "abstract": "Graph autoencoders (GAEs) are self-supervised learning models that can learn meaningful representations of graph-structured data by reconstructing the input graph from a low-dimensional latent space. Over the past few years, GAEs have gained significant attention in academia and industry. In particular, the recent advent of GAEs with masked autoencoding schemes marks a significant advancement in graph self-supervised learning research. While numerous GAEs have been proposed, the underlying mechanisms of GAEs are not well understood, and a comprehensive benchmark for GAEs is still lacking. In this work, we bridge the gap between GAEs and contrastive learning by establishing conceptual and methodological connections. We revisit the GAEs studied in previous works and demonstrate how contrastive learning principles can be applied to GAEs. Motivated by these insights, we introduce lrGAE (left-right GAE), a general and powerful GAE framework that leverages contrastive learning principles to learn meaningful representations. Our proposed lrGAE not only facilitates a deeper understanding of GAEs but also sets a new benchmark for GAEs across diverse graph-based learning tasks. The source code for lrGAE, including the baselines and all the code for reproducing the results, is publicly available athttps://anonymous.4open.science/r/lrGAE/."
    },
    {
        "title": "Pointwise Information Measures as Confidence Estimators in Deep Neural Networks: A Comparative Study",
        "link_suffix": "/forum?id=0QvLISYIKM",
        "link": "https://openreview.net/forum?id=0QvLISYIKM",
        "pdf_link": "https://openreview.net/pdf?id=0QvLISYIKM",
        "keywords": "information theory, confidence estimation, deep neural networks",
        "abstract": "Estimating the confidence of deep neural network predictions is crucial for ensuring safe deployment in high-stakes applications. The softmax probabilities obtained from the neural networks are commonly interpreted as confidence scores but they are often poorly calibrated. Many existing methods addressing this issue involve modifying the network architecture or training procedure, which may not always be feasible in practice. In this paper, we use tools from information theory to estimate the confidence of deep neural network\u2019s predictions in a post-hoc manner. In particular, we compare three pointwise information (PI) measures: pointwise mutual information (PMI), pointwise $\\mathcal{V}$-information (PVI), and the recently proposed pointwise sliced mutual information (PSI). We show in this paper that these PI measures naturally relate to confidence estimation. We first study the invariance properties of these PI measures with respect to a broad range of transformations. We then study the sensitivity of the PI measures to geometric attributes such as margin and intrinsic dimensionality, as well as their convergence rates. We finally conduct extensive experiments on benchmark computer vision models and datasets and show the effectiveness of these measures as tools for confidence estimation. A notable finding is that PVI is better than PMI and PSI for failure prediction and confidence calibration, outperforming all existing baselines for post-hoc confidence estimation. This is consistent with our theoretical findings which suggest that PVI is the most well-rounded among the PI measures."
    },
    {
        "title": "The Geometry of Phase Transitions in Diffusion Models: Tubular Neighbourhoods and Singularities",
        "link_suffix": "/forum?id=YYMd6zsP2e",
        "link": "https://openreview.net/forum?id=YYMd6zsP2e",
        "pdf_link": "https://openreview.net/pdf?id=YYMd6zsP2e",
        "keywords": "diffusion models, geometry, tubular neighbourhoods",
        "abstract": "Diffusion models undergo phase transitions during the generative process where data features suddenly emerge in the final stages. The current study aims to elucidate this critical phenomenon from the geometrical perspective. We employ the concept of ``injectivity radius'', a quantity that characterises the structure of the data manifold. Through theoretical and empirical evidence, we demonstrate that phase transitions in the generative process of diffusion models are closely related to the injectivity radius. Our findings offer a novel perspective on phase transitions in diffusion models, with potential implications for improving performance and sampling efficiency."
    },
    {
        "title": "Feedback Favors the Generalization of Neural ODEs",
        "link_suffix": "/forum?id=cmfyMV45XO",
        "link": "https://openreview.net/forum?id=cmfyMV45XO",
        "pdf_link": "https://openreview.net/pdf?id=cmfyMV45XO",
        "keywords": "Neural ODEs, feedback, generalization, learning dynamical systems, model predictive control",
        "abstract": "The well-known generalization problem hinders the application of artificial neural networks in continuous-time prediction tasks with varying latent dynamics. In sharp contrast, biological systems can neatly adapt to evolving environments benefiting from real-time feedback mechanisms. Inspired by the feedback philosophy, we present feedback neural networks, showing that a feedback loop can flexibly correct the learned latent dynamics of neural ordinary differential equations (neural ODEs), leading to a prominent generalization improvement. The feedback neural network is a novel two-DOF neural network, which possesses robust performance in unseen scenarios with no loss of accuracy performance on previous tasks. A linear feedback form is presented to correct the learned latent dynamics firstly, with a convergence guarantee. Then, domain randomization is utilized to learn a nonlinear neural feedback form. Finally, extensive tests including trajectory prediction of a real irregular object and model predictive control of a quadrotor with various uncertainties, are implemented, indicating significant improvements over state-of-the-art model-based and learning-based methods."
    },
    {
        "title": "ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer",
        "link_suffix": "/forum?id=Bpn8q40n1n",
        "link": "https://openreview.net/forum?id=Bpn8q40n1n",
        "pdf_link": "https://openreview.net/pdf?id=Bpn8q40n1n",
        "keywords": "Image Generation and Editing, Diffusion Transformer, Instruction Following, Unified Framework",
        "abstract": "Diffusion models have emerged as a powerful generative technology and have been found to be applicable in various scenarios. Most existing foundational diffusion models are primarily designed for text-guided visual generation and do not support multi-modal conditions, which are essential for many visual editing tasks. This limitation prevents these foundational diffusion models from serving as a unified model in the field of visual generation, like GPT-4 in the natural language processing field. In this work, we propose ACE, an All-round Creator and Editor, which achieves comparable performance compared to those expert models in a wide range of visual generation tasks. To achieve this goal, we first introduce a unified condition format termed Long-context Condition Unit (LCU), and propose a novel Transformer-based diffusion model that uses LCU as input, aiming for joint training across various generation and editing tasks. Furthermore, we propose an efficient data collection approach to address the issue of the absence of available training data. It involves acquiring pairwise images with synthesis-based or clustering-based pipelines and supplying these pairs with accurate textual instructions by leveraging a fine-tuned multi-modal large language model. To comprehensively evaluate the performance of our model, we establish a benchmark of manually annotated pairs data across a variety of visual generation tasks. The extensive experimental results demonstrate the superiority of our model in visual generation fields. Thanks to the all-in-one capabilities of our model, we can easily build a multi-modal chat system that responds to any interactive request for image creation using a single model to serve as the backend, avoiding the cumbersome pipeline typically employed in visual agents."
    },
    {
        "title": "The Perfect Blend: Redefining RLHF with Mixture of Judges",
        "link_suffix": "/forum?id=uZmmgHY1mD",
        "link": "https://openreview.net/forum?id=uZmmgHY1mD",
        "pdf_link": "https://openreview.net/pdf?id=uZmmgHY1mD",
        "keywords": "Large Language Model, Reinforcement Learning from Human Feedback, Mixture of Judges, Constrained Policy Optimization",
        "abstract": "Reinforcement learning from human feedback (RLHF) has become the leading approach for fine-tuning large language models (LLM). However, RLHF has limitations in multi-task learning (MTL) due to challenges of reward hacking and extreme multi-objective optimization (i.e., trade-off of multiple and/or sometimes conflicting objectives). Applying RLHF for MTL currently requires careful tuning of the weights for reward model and data combinations. This is often done via human intuition and does not generalize. In this work, we introduce a novel post-training paradigm which we called Constrained Generative Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with cost-efficient constrained policy optimization with stratification, which can identify the perfect blend in RLHF in a principled manner. It shows strong empirical results with theoretical guarantees, does not require extensive hyper-parameter tuning, and is plug-and-play in common post-training pipelines. Together, this can detect and mitigate reward hacking behaviors while reaching a pareto-optimal point across an extremely large number of objectives.Our results show that CGPO consistently outperforms other commonly used SoTA RLHF algorithms (such as PPO and DPO) on a wide range of tasks -- general chat, STEM questions, instruction following, math, coding and knowledge. In particular, CGPO improves over PPO by 7.4% in AlpacaEval-2 (general chat), 12.5% in Arena-Hard (STEM\\reasoning), 2% in IFEval (Instrcution Following), 2% in both MATH and GSM8K (Math\\reasoning), 5% in HumanEval (Coding), and 2% in the ARC challenge (Knowledge). We also observe that PPO is susceptible to severe reward hacking behaviors (it exhibits severe regression in popular coding benchmarks) which can be addressed by CGPO. CGPO represents a breakthrough in RLHF, simultaneously addressing reward-hacking and extreme multi-objective optimization, and thereby advancing the state-of-the-art in aligning general-purpose LLMs."
    },
    {
        "title": "EVINCE: Optimizing Adversarial LLM Dialogues via Conditional Statistics and Information Theory",
        "link_suffix": "/forum?id=ytvWZEiywp",
        "link": "https://openreview.net/forum?id=ytvWZEiywp",
        "pdf_link": "https://openreview.net/pdf?id=ytvWZEiywp",
        "keywords": "LLM, GAI, AGI",
        "abstract": "This paper introduces EVINCE (Entropy and Variation IN Conditional Exchanges), a dialogue framework advancing Artificial General Intelligence (AGI) by enhancing versatility, adaptivity, and reasoning in large language models (LLMs). Leveraging adversarial debate and a novel dual entropy theory, EVINCE improves prediction accuracy, robustness, and stability in LLMs by integrating statistical modeling, information theory, and machine learning to balance diverse perspective exploration with strong prior exploitation. The framework's effectiveness is demonstrated through consistent convergence of information-theoretic metrics, particularly improved mutual information, fostering productive LLM collaboration. We apply EVINCE to healthcare, showing improved disease diagnosis, and discuss its broader implications for decision-making across domains. This work provides theoretical foundations and empirical validation for EVINCE, paving the way for advancements in LLM collaboration and AGI development."
    },
    {
        "title": "On the Entropy Calibration of Language Models",
        "link_suffix": "/forum?id=ZpQ2SqQNXf",
        "link": "https://openreview.net/forum?id=ZpQ2SqQNXf",
        "pdf_link": "https://openreview.net/pdf?id=ZpQ2SqQNXf",
        "keywords": "language models, calibration, entropy, sampling, language model inference",
        "abstract": "Language models are trained with teacher forcing but are used autoregressively, so errors accumulate as more tokens are generated. This issue is well-studied but remains a fundamental problem that harms generation quality. Building on past work, we take the perspective that error accumulation is reflected in the model's entropy, so we can better understand and address it through the lens of entropy calibration. A language model is entropy calibrated if its entropy over generations, i.e. its confidence, matches the log loss it incurs on actual text. First, we find that models are indeed miscalibrated in practice: for base models across a range of sizes, entropy per step increases as more tokens are generated, leading to generations becoming incoherent over time. On the other hand, after instruction tuning, the largest models now have too little entropy (i.e. are overconfident), leading to a lack of diversity in model outputs. From a theoretical perspective, entropy calibration is difficult to attain because it is a global property of the entire generation process, which has an exponentially large output space. Per-step adjustments are tractable but fail to preserve the model's log loss, while global adjustments preserve log loss but are intractable. Our main theoretical contribution is to propose future entropy scaling, an adjustment to the next token probabilities that uses information about the future entropy of each token, i.e. the average entropy of continuations from that token. With additional assumptions, we prove that this adjustment calibrates the model while preserving log loss. While future entropy estimation is expensive, this result suggests that calibration and stabilization of the entropy should be possible without trading off model quality."
    }
]
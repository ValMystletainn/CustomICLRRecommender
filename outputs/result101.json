[
    {
        "title": "NanoMoE: Scaling Mixture of Experts to Individual Layers for Parameter-Efficient Deep Learning",
        "link_suffix": "/forum?id=04RLVxDvig",
        "link": "https://openreview.net/forum?id=04RLVxDvig",
        "pdf_link": "https://openreview.net/pdf?id=04RLVxDvig",
        "keywords": "Mixture of Experts, Parameter Efficiency, Expressivity, Low-Rank Factorization",
        "abstract": "Large language models (LLMs) have achieved remarkable success, but their growing size leads to significant challenges in efficiency and cost. This work explores parameter-efficient deep learning, aiming to achieve comparable performance with fewer parameters and floating-point operations (FLOPs). We introduce NanoMoE, a novel family of parameter-efficient building blocks inspired by the Mixture of Experts (MoE) framework. NanoMoE offers a modular and efficient replacement for fully connected layers within traditional neural networks. We instantiate NanoMoE with three variants of increasing complexity and theoretically demonstrate its superior expressivity compared to low-rank factorization with minimal parameter increase. Empirical results validate that NanoMoE achieves superior model quality compared to low-rank factorization under the same parameter or FLOP budget, confirming its enhanced efficiency."
    },
    {
        "title": "Latent Boost: Leveraging Latent Space Distance Metrics to Augment Classification Performance",
        "link_suffix": "/forum?id=WHtNc5kX1v",
        "link": "https://openreview.net/forum?id=WHtNc5kX1v",
        "pdf_link": "https://openreview.net/pdf?id=WHtNc5kX1v",
        "keywords": "Latent Space, Distance Metrics, Magnet Loss",
        "abstract": "The pursuit of boosting classification performance in Machine Learning has primarily focused on refining model architectures and hyperparameters through probabilistic loss optimization. However, such an approach often neglects the profound, untapped potential embedded in internal structural information, which can significantly elevate the training process. In this work, we introduce Latent Boost, a novel approach that incorporates the very definition of classification via latent representation distance metrics to enhance the conventional dataset-oriented classification training. Thus during training, the model is not only optimized for classification metrics of the discrete data points but also adheres to the rule that the collective representation zones of each class should be sharply clustered. By leveraging the rich structural insights of high-dimensional latent representations, Latent Boost not only improves classification metrics like F1-Scores but also brings additional benefits of improved interpretability with higher silhouette scores and steady-fast convergence with fewer training epochs. Latent Boost brings these performance and latent structural benefits with minimum additional cost and no data-specific requirements."
    },
    {
        "title": "Flow-based imputation of small data",
        "link_suffix": "/forum?id=rcmhydaEJp",
        "link": "https://openreview.net/forum?id=rcmhydaEJp",
        "pdf_link": "https://openreview.net/pdf?id=rcmhydaEJp",
        "keywords": "Normalizing flows, imputation, diffeomorphism, out of distribution detection",
        "abstract": "Many challenges in the physical sciences can be framed as small data problems, where theoretical progress is hindered by the sparsity, low-dimensionality, and/or limited sample size of available empirical data compared to a physical system’s numerous dynamical degrees of freedom. Developing trustworthy imputation methods for these datasets holds immense scientific importance. Normalizing flows are a promising model choice for imputation due to their ability to explicitly estimate sample likelihoods. However, research has shown that normalizing flows are often unreliable for out-of-distribution (OOD) detection in high-dimensional settings, which undermines their trustworthiness for imputation tasks. In contrast, low-dimensional settings provide opportunities to tractably evaluate and mitigate likelihood estimation errors, revealing strategies to reduce or eliminate specific error modes. We focus on the most stringent assumption in normalizing flows: diffeomorphism between the target and base distributions. This assumption introduces two distinct error modes, which we identify and address through a simple and effective strategy. Our approach significantly enhances the trustworthiness of normalizing flows for imputation in small data problems."
    },
    {
        "title": "Towards Simple and Provable Parameter-Free Adaptive Gradient Methods",
        "link_suffix": "/forum?id=CuupjjjT3U",
        "link": "https://openreview.net/forum?id=CuupjjjT3U",
        "pdf_link": "https://openreview.net/pdf?id=CuupjjjT3U",
        "keywords": "parameter-free optimization, adaptive gradient methods",
        "abstract": "Optimization algorithms such as AdaGrad and Adam have significantly advanced the training of deep models by dynamically adjusting the learning rate during the optimization process. However, adhoc tuning of learning rates poses a challenge, leading to inefficiencies in practice. To address this issue, recent research has focused on developing \"learning-rate-free\" or \"parameter-free\" algorithms that operate effectively without the need for learning rate tuning. This paper presents AdaGrad++ and Adam++, novel parameter-free variants of AdaGrad and Adam with convergence guarantees. We prove that AdaGrad++ achieves comparable convergence rates to AdaGrad in convex optimization without predefined learning rate assumptions. Similarly, Adam++ matches the convergence rate of Adam without relying on any conditions on the learning rates. Experimental results across various deep learning tasks validate the competitive performance of AdaGrad++ and Adam++"
    },
    {
        "title": "Scaling up Masked Diffusion Models on Text",
        "link_suffix": "/forum?id=WNvvwK0tut",
        "link": "https://openreview.net/forum?id=WNvvwK0tut",
        "pdf_link": "https://openreview.net/pdf?id=WNvvwK0tut",
        "keywords": "Masked Diffusion Models, Scaling Laws, Conditional Generation, Language Understanding, Reverse Curse, Temporal Quality Degradation",
        "abstract": "Masked diffusion models (MDMs) have shown promise in language modeling, yet their scalability and effectiveness in core language tasks, such as conditional generation and language understanding, remain underexplored. This paper establishes the first scaling law for MDMs, demonstrating a scaling rate comparable to autoregressive models (ARMs) and a relatively small compute gap. Motivated by their scalability, we train a family of MDMs with up to 1.1 billion (B) parameters to systematically evaluate their performance against ARMs of comparable or larger sizes. Fully leveraging the probabilistic formulation of MDMs, we propose a simple yet effectiveunsupervised classifier-free guidancethat effectively exploits large-scale unpaired data, boosting performance for conditional inference. In language understanding, a 1.1B MDM shows competitive results, outperforming the larger 1.5B GPT-2 model on four out of eight zero-shot benchmarks. In conditional generation, MDMs provide a flexible trade-off compared to ARMs utilizing KV-cache: MDMs match the performance of ARMs while being 1.5 times faster, or achieve higher quality than ARMs at a slightly higher computational cost. Moreover, MDMs address challenging tasks for ARMs by effectively handling bidirectional reasoning and adapting to temporal shifts in data. Notably, a 1.1B MDM breaks thereverse curseencountered by much larger ARMs with significantly more data and computation, such as Llama (13B) and GPT-3 (175B)."
    },
    {
        "title": "LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations",
        "link_suffix": "/forum?id=KRnsX5Em3W",
        "link": "https://openreview.net/forum?id=KRnsX5Em3W",
        "pdf_link": "https://openreview.net/pdf?id=KRnsX5Em3W",
        "keywords": "hallucinations, truthfulness, interpretability, probing, LLM",
        "abstract": "Large language models (LLMs) often produce errors, including factual inaccuracies, biases, and reasoning failures, collectively referred to as \"hallucinations\". Recent studies have demonstrated that LLMs' internal states encode information regarding the truthfulness of their outputs, and that this information can be utilized to detect errors. In this work, we show that the internal representations of LLMs encode much more information about truthfulness than previously recognized. We first discover that the truthfulness information is concentrated in specific tokens, and leveraging this property significantly enhances error detection performance. Yet, we show that such error detectors fail to generalize across datasets, implying that---contrary to prior claims---truthfulness encoding is not universal but rather multifaceted. Next, we show that internal representations can also be used for predicting the types of errors the model is likely to make, facilitating the development of tailored mitigation strategies. Lastly, we reveal a discrepancy between LLMs' internal encoding and external behavior: they may encode the correct answer, yet consistently generate an incorrect one. Taken together, these insights deepen our understanding of LLM errors from the model's internal perspective, which can guide future research on enhancing error analysis and mitigation."
    },
    {
        "title": "Selective Unlearning via Representation Erasure Using Adversarial Training",
        "link_suffix": "/forum?id=KzSGJy1PIf",
        "link": "https://openreview.net/forum?id=KzSGJy1PIf",
        "pdf_link": "https://openreview.net/pdf?id=KzSGJy1PIf",
        "keywords": "approximate unlearning, adversarial training",
        "abstract": "When deploying machine learning models in the real world,  we often face the challenge of “unlearning” specific data points or subsets after training.  Inspired by Domain-Adversarial Training of Neural Networks (DANN), we propose a novel algorithm,SURE, for targeted unlearning.SURE treats the process as a domain adaptation problem, where the “forget set” (data to be removed) and a validation set from the same distribution form two distinct domains. We train a domain clas-sifier to discriminate between representations from the forget and validation sets.Using a gradient reversal strategy similar to DANN, we perform gradient updates to the representations to “fool” the domain classifier and thus obfuscate representations belonging to the forget set. Simultaneously, gradient descent is applied to the retain set (original training data minus the forget set) to preserve its classification performance.  Unlike other unlearning approaches whose training objectives are built based on model outputs,SURE directly manipulates there presentations.This is key to ensure robustness against a set of more powerful attacks than currently considered in the literature,  that aim to detect which examples were unlearned through access to learned embeddings.  Our thorough experiments reveal that SURE has a better unlearning quality to utility trade-off compared to other standard unlearning techniques for deep neural networks."
    },
    {
        "title": "Local Steps Speed Up Local GD for Heterogeneous Distributed Logistic Regression",
        "link_suffix": "/forum?id=lydPkW4lfz",
        "link": "https://openreview.net/forum?id=lydPkW4lfz",
        "pdf_link": "https://openreview.net/pdf?id=lydPkW4lfz",
        "keywords": "optimization, convex optimization, distributed optimization, federated learning, logistic regression",
        "abstract": "We analyze two variants of Local Gradient Descent applied to distributed logistic regression with heterogeneous, separable data and show convergence at the rate $O(1/KR)$ for $K$ local steps and sufficiently large $R$ communication rounds. In contrast, all existing convergence guarantees for Local GD applied to any problem are at least $\\Omega(1/R)$, meaning they fail to show the benefit of local updates. The key to our improved guarantee is showing progress on the logistic regression objective when using a large stepsize $\\eta \\gg 1/K$, whereas prior analysis depends on $\\eta \\leq 1/K$."
    },
    {
        "title": "MamKO: Mamba-based Koopman operator for modeling and predictive control",
        "link_suffix": "/forum?id=hNjCVVm0EQ",
        "link": "https://openreview.net/forum?id=hNjCVVm0EQ",
        "pdf_link": "https://openreview.net/pdf?id=hNjCVVm0EQ",
        "keywords": "Mamba; Koopman operator; model predictive control; nonlinear systems",
        "abstract": "The Koopman theory, which enables the transformation of nonlinear systems into linear representations, is a powerful and efficient tool to model and control nonlinear systems. However, the ability of the Koopman operator to model complex systems, particularly time-varying systems, is limited by the fixed linear state-space representation. To address this limitation, the large language model, Mamba, is considered a promising strategy for enhancing modeling capabilities while preserving the linear state-space structure. In this paper, we propose a new framework, the Mamba-based Koopman operator (MamKO), which provides enhanced model predictability and adaptability, as compared to Koopman models with constant Koopman operators. Inspired by the Mamba structure, MamKO generates Koopman operators from online data; this enables the model to effectively capture the dynamic behaviors of the nonlinear system over time. A model predictive control system is then developed based on the proposed MamKO model. The modeling and control performance of the proposed method is evaluated through experiments on benchmark time-invariant and time-varying systems. The experimental results demonstrate the superiority of the proposed approach. Additionally, we perform ablation experiments to test the effectiveness of individual components of MamKO. This approach unlocks new possibilities for integrating large language models with control frameworks, and it achieves a good balance between advanced modeling capabilities and real-time control implementation efficiency."
    },
    {
        "title": "Learning Latent Graph Structures and their Uncertainty",
        "link_suffix": "/forum?id=uwzyMFwyOO",
        "link": "https://openreview.net/forum?id=uwzyMFwyOO",
        "pdf_link": "https://openreview.net/pdf?id=uwzyMFwyOO",
        "keywords": "Graph Structure Learning, Graph Neural Networks, Latent Distribution Calibration, Discrete Random Variables",
        "abstract": "Graph neural networks use relational information as an inductive bias to enhance prediction performance. Not rarely, task-relevant relations are unknown and graph structure learning approaches have been proposed to learn them from data. Given their latent nature, no graph observations are available to provide a direct training signal to the learnable relations. Therefore, graph topologies are typically learned on the prediction task alongside the other graph neural network parameters.\nIn this paper, we demonstrate that minimizing point-prediction losses does not guarantee proper learning of the latent relational information and its associated uncertainty. Conversely, we prove that suitable loss functions on the stochastic model outputs simultaneously grant solving two tasks: (i) learning the unknown distribution of the latent graph and (ii) achieving optimal predictions of the model output. \nFinally, we propose a sampling-based method that solves this joint learning task. Empirical results validate our theoretical claims and demonstrate the effectiveness of the proposed approach."
    },
    {
        "title": "Make the Pertinent Salient: Task-Relevant Reconstruction for Visual Control with Distractions",
        "link_suffix": "/forum?id=JOHhktXd4a",
        "link": "https://openreview.net/forum?id=JOHhktXd4a",
        "pdf_link": "https://openreview.net/pdf?id=JOHhktXd4a",
        "keywords": "Visual Control, Robust Representation Learning, Model-Based Reinforcement Learning",
        "abstract": "Recent advancements in Model-Based Reinforcement Learning (MBRL) have made it a powerful tool for visual control tasks. Despite improved data efficiency, it remains challenging to train MBRL agents with generalizable perception. Training in the presence of visual distractions is particularly difficult due to the high variation they introduce to representation learning. Building on DREAMER, a popular MBRL method, we propose a simple yet effective auxiliary task to facilitate representation learning in distracting environments. Under the assumption that task-relevant components of image observations are straightforward to identify with prior knowledge in a given task, we use a segmentation mask on image observations to only reconstruct task-relevant components. In doing so, we greatly reduce the complexity of representation learning by removing the need to encode task-irrelevant objects in the latent representation. Our method, Segmentation Dreamer (SD), can be used either with ground-truth masks easily accessible in simulation or by leveraging potentially imperfect segmentation foundation models. The latter is further improved by selectively applying the reconstruction loss to avoid providing misleading learning signals due to mask prediction errors. In modified DeepMind Control suite (DMC) and Meta-World tasks with added visual distractions, SD achieves significantly better sample efficiency and greater final performance than prior work. We find that SD is especially helpful in sparse reward tasks otherwise unsolvable by prior work, enabling the training of visually robust agents without the need for extensive reward engineering."
    },
    {
        "title": "Learning Linear Dynamical Systems with Sparse System Matrices",
        "link_suffix": "/forum?id=saFH7zTtQs",
        "link": "https://openreview.net/forum?id=saFH7zTtQs",
        "pdf_link": "https://openreview.net/pdf?id=saFH7zTtQs",
        "keywords": "linear dynamical systems, state estimation, system identification, expectation–maximization algorithm",
        "abstract": "Due to the tractable analysis and control,  linear dynamical systems (LDSs) provide  a fundamental  mathematical tool for  time-series data modeling in various disciplines. Particularly, many LDSs have sparse system matrices  because interactions among variables are limited or only a few significant relationships exist.   However, available learning algorithms for LDSs  lack the ability to  learn system matrices with the sparsity constraint.  To address this issue, we impose sparsity-promoting priors on system matrices and explore the expectation–maximization (EM) algorithm to  give a maximum a posteriori (MAP) estimate of both hidden states and system matrices from noisy observations. In addition, we find that many learning algorithms based on the gradient descent method use an inappropriate derivative rule, because they neglect the inherent symmetry of  noise covariance  matrices. Here, we consider the derivative rule of structured matrices during the optimization process to guarantee their symmetry. Experimental results on simulation and real-world problems illustrate that  the proposed algorithm significantly improves learning accuracy over classical ones."
    },
    {
        "title": "Sentinel: Multi-Patch Transformer with Temporal and Channel Attention for Time Series Forecasting",
        "link_suffix": "/forum?id=zV2cgXk2aY",
        "link": "https://openreview.net/forum?id=zV2cgXk2aY",
        "pdf_link": "https://openreview.net/pdf?id=zV2cgXk2aY",
        "keywords": "Transformer, Time Series Forecasting, Attention mechanism",
        "abstract": "Transformer-based time series forecasting has recently gained strong interest  due to the ability of transformers to model sequential data. Most of the state-of-the-art architectures exploit either temporal or inter-channel dependencies, limiting their effectiveness in multivariate time-series forecasting where both types of dependencies are crucial. We propose Sentinel, a full transformer-based architecture composed of an encoder able to extract contextual information from the channel dimension, and a decoder designed to capture causal relations and dependencies across the temporal dimension. Additionally, we introduce a multi-patch attention mechanism, which leverages the patching process to structure the input sequence in a way that can be naturally integrated into the transformer architecture, replacing the multi-head splitting process. Extensive experiments on standard benchmarks demonstrate that Sentinel, because of its ability to ``monitor\" both the temporal and the inter-channel dimension, achieves better or comparable performance with respect to state-of-the-art approaches."
    },
    {
        "title": "Robustness Auditing for Linear Regression: To Singularity and Beyond",
        "link_suffix": "/forum?id=V5ns6uvRZ9",
        "link": "https://openreview.net/forum?id=V5ns6uvRZ9",
        "pdf_link": "https://openreview.net/pdf?id=V5ns6uvRZ9",
        "keywords": "Robust machine learning, linear regression, robustness auditing, data attribution, ordinary least squares, robust statistics, econometrics",
        "abstract": "It has recently been discovered that the conclusions of many highly influential econometrics studies can be overturned by removing a very small fraction of their samples (often less than $0.5%$). These conclusions are typically based on the results of one or more Ordinary Least Squares (OLS) regressions, raising the question: given a dataset, can we certify the robustness of an OLS fit on this dataset to the removal of a given number of samples?Brute-force techniques quickly break down even on small datasets. Existing approaches which go beyond brute force either can only find candidate small subsets to remove (but cannot certify their non-existence) [BGM20, KZC21], are computationally intractable beyond low dimensional settings [MR22], or require very strong assumptions on the data distribution and too many samples to give reasonable bounds in practice [BP21, FH23].We present an efficient algorithm for certifying the robustness of linear regressions to removals of samples. We implement our algorithm and run it on several landmark econometrics datasets with hundreds of dimensions and tens of thousands of samples, giving the first non-trivial certificates of robustness to sample removal for datasets of dimension $4$ or greater. We prove that under distributional assumptions on a dataset, the bounds produced by our algorithm are tight up to a $1 + o(1)$ multiplicative factor."
    },
    {
        "title": "Learning Multiple Initial Solutions to Optimization Problems",
        "link_suffix": "/forum?id=wsb9GNh1Oi",
        "link": "https://openreview.net/forum?id=wsb9GNh1Oi",
        "pdf_link": "https://openreview.net/pdf?id=wsb9GNh1Oi",
        "keywords": "optimization, initialization, optimal control, robotics, autonomous driving",
        "abstract": "Sequentially solving similar optimization problems under strict runtime constraints is essential for many applications, such as robot control, autonomous driving, and portfolio management. The performance of local optimization methods in these settings is sensitive to the initial solution: poor initialization can lead to slow convergence or suboptimal solutions. To address this challenge, we propose learning to predict multiple diverse initial solutions given parameters that define the problem instance. We introduce two strategies for utilizing multiple initial solutions: (i) a single-optimizer approach, where the most promising initial solution is chosen using a selection function, and (ii) a multiple-optimizers approach, where several optimizers, potentially run in parallel, are each initialized with a different solution, with the best solution chosen afterward. We validate our method on three optimal control benchmark tasks: cart-pole, reacher, and autonomous driving, using different optimizers: DDP, MPPI, and iLQR. We find significant and consistent improvement with our method across all evaluation settings and demonstrate that it efficiently scales with the number of initial solutions required."
    },
    {
        "title": "BRAIN: Behavioral Responses and Artificial Intelligence Neural-Modeling for Consumer Decision-Making",
        "link_suffix": "/forum?id=B6xUlbgP7j",
        "link": "https://openreview.net/forum?id=B6xUlbgP7j",
        "pdf_link": "https://openreview.net/pdf?id=B6xUlbgP7j",
        "keywords": "Decision-Making; PCA; DCNN; Neuromarketing",
        "abstract": "This research investigates consumer neuroscience and neuromarketing through a multivariate methodology, employing Principal Component Analysis (PCA) and deep learning neural networks to interpret consumer responses to functional products. EEG signals were collected, recorded, and analyzed from 16 individuals aged 20 to 29 to identify significant neuronal markers related to consumer choices. The pivotal factors influencing decision-making were identified as the low beta and low gamma frequency bands, as well as participants' attention and meditation levels. The findings validate the effectiveness of our approach, demonstrating its applicability across various fields requiring accurate and reliable classification. Additionally, it is recommended to explore the potential applications of this study in the food industry by creating personalized nutrition strategies based on individuals' brain activity patterns."
    },
    {
        "title": "Playing For You: Text Prompt-guided Joint Audio-visual Generation for Narrating Faces using Multi-entangled Latent Space",
        "link_suffix": "/forum?id=kMz43DyCKA",
        "link": "https://openreview.net/forum?id=kMz43DyCKA",
        "pdf_link": "https://openreview.net/pdf?id=kMz43DyCKA",
        "keywords": "Generating Multimoda",
        "abstract": "We present a novel approach for generating realistic speaking and taking faces by synthesizing a person’s voice and facial movements from a static image, a voice profile, and a target text. The model encodes the prompt/driving text, a driving image and the voice profile of an individual and then combines them to pass it to the multi-entangled latent space to foster key-vale and query for audio and video modality generation pipeline. The multi-entangled latent space is responsible for establishing the spatiotemporal person-specific features between the modalities. Further, entangled features are passed to the respective decoder of each modality for output audio and video generation. Our experiments and analysis through standard metrics showcase the effectiveness of our model. All model checkpoints, code and the proposed dataset can be found at:https://github.com/Playing-for-you."
    },
    {
        "title": "EGLNN:ENHANCED GRAPHLESS NEURAL NETWORK FOR IOT DATA STORAGE TRANSACTION SECURITY",
        "link_suffix": "/forum?id=k9KKFhwNwg",
        "link": "https://openreview.net/forum?id=k9KKFhwNwg",
        "pdf_link": "https://openreview.net/pdf?id=k9KKFhwNwg",
        "keywords": "IoT, Ethereum, Graph Neural Network, Knowledge Distillation, Abnormal Detection",
        "abstract": "With the rise of 5G and the IOT, the amount of data generated by IoT devices has exploded. Ethereum has become a secure tool for storing and trading IoT data due to its openness and tamper-proof nature. However, as Ethereum becomes more and more popular, the Ethereum platform has also become a hotbed for various types of cybercrimes, so ensuring the security of the Ethereum network is crucial. Recently, algorithms based on GNN have been seen as an effective way to detect abnormal nodes in the network. However, through analysis, this work finds that its original network structure is not optimal, directly applied to the existing GNN model with poor results. Meanwhile, it is understood that most of the current GNNs rely on the message-passing principle, which leads to slow model training and inference, and large model size. It is quite challenging to directly apply traditional GNN algorithms in industrial scenarios with limited space and high feedback time requirements. This study proposes a knowledge distillation-based algorithm called Enhanced Graph-Less Neural Network .EGLNN estimates more realistic graph structures through Bayesian graph structure estimator and solves the problem of large-scale GNN models being difficult to be widely applied in industry through the faculty-student distillation method."
    },
    {
        "title": "Towards Secure Tuning: Mitigating Security Risks Arising from Benign Instruction Fine-Tuning",
        "link_suffix": "/forum?id=Egd7Vi1EuA",
        "link": "https://openreview.net/forum?id=Egd7Vi1EuA",
        "pdf_link": "https://openreview.net/pdf?id=Egd7Vi1EuA",
        "keywords": "Large Language Models, Security, Instruction Fine-Tuning",
        "abstract": "Instruction Fine-Tuning (IFT) has become an essential method for adapting base Large Language Models (LLMs) into variants for professional and private use. However, researchers have raised concerns over a significant decrease in LLMs' security following IFT, even when the IFT process involves entirely benign instructions (termed Benign IFT). Our study represents a pioneering effort to mitigate the security risks arising from Benign IFT. Specifically, we conduct a Module Robustness Analysis, aiming to investigate how LLMs' internal modules contribute to their security. Based on our analysis, we propose a novel IFT strategy, called the Modular Layer-wise Learning Rate (ML-LR) strategy. In our analysis, we implement a simple security feature classifier that serves as a proxy to measure the robustness of modules (e.g. $Q$/$K$/$V$, etc.). Our findings reveal that the module robustness shows clear patterns, varying regularly with the module type and the layer depth. Leveraging these insights, we develop a proxy-guided search algorithm to identify a robust subset of modules, termed $Mods_{Robust}$. During IFT, the ML-LR strategy employs differentiated learning rates for $Mods_{Robust}$ and the rest modules. Our experimental results show that in security assessments, the application of our ML-LR strategy significantly mitigates the rise in harmfulness of LLMs following Benign IFT. Notably, our ML-LR strategy has little impact on the usability or expertise of LLMs following Benign IFT. Furthermore, we have conducted comprehensive analyses to verify the soundness and flexibility of our ML-LR strategy."
    },
    {
        "title": "LLMs Are In-Context Reinforcement Learners",
        "link_suffix": "/forum?id=YW79lAHBUF",
        "link": "https://openreview.net/forum?id=YW79lAHBUF",
        "pdf_link": "https://openreview.net/pdf?id=YW79lAHBUF",
        "keywords": "in-context learning, in-context reinforcement learning, large language models",
        "abstract": "Large Language Models (LLMs) can learn new tasks through in-context supervised learning (i.e., ICL). This work studies if this ability extends to in-context reinforcement learning (ICRL), where models are not given gold labels in context, but only their past predictions and rewards. We show that a naive application of ICRL fails miserably, and identify the root cause as a fundamental deficiency at exploration, which leads to quick model degeneration. We propose an algorithm to address this deficiency by increasing test-time compute, as well as a compute-bound approximation. We use several challenging classification tasks to empirically show that our ICRL algorithms lead to effective learning from rewards alone, and analyze the characteristics of this ability and our methods. Overall, our results reveal remarkable ICRL abilities in LLMs."
    },
    {
        "title": "Learning to Ground VLMs without Forgetting",
        "link_suffix": "/forum?id=HjoYVtSkT8",
        "link": "https://openreview.net/forum?id=HjoYVtSkT8",
        "pdf_link": "https://openreview.net/pdf?id=HjoYVtSkT8",
        "keywords": "vision language models, visual grounding, mixture of experts, synthetic datasets",
        "abstract": "Spatial awareness is key to enable embodied multimodal AI systems. Yet, without vast amounts of spatial supervision, current Visual Language Models (VLMs) struggle at this task. In this paper, we introduce LynX, a framework that equips pretrained VLMs with visual grounding ability without forgetting their existing image and language understanding skills.\nTo this end, we propose a Dual Mixture of Experts module that modifies only the decoder layer of the language model, using one frozen Mixture of Experts (MoE) pre-trained on image and language understanding and another learnable MoE for new grounding capabilities. This allows the VLM to retain previously learned knowledge and skills, while acquiring what is missing.\nTo train the model effectively, we generate a high-quality synthetic dataset we call SCouT, which mimics human reasoning in visual grounding. This dataset provides rich supervision signals, describing a step-by-step multimodal reasoning process, thereby simplifying the task of visual grounding. We evaluate LynX on several object detection and visual grounding datasets, demonstrating strong performance in object detection, zero-shot localization and grounded reasoning while maintaining its original image and language understanding capabilities on seven standard benchmark datasets."
    },
    {
        "title": "Self-Supervised Pseudodata Filtering for Improved Replay with Sub-Optimal Generators",
        "link_suffix": "/forum?id=i3DyRNgCey",
        "link": "https://openreview.net/forum?id=i3DyRNgCey",
        "pdf_link": "https://openreview.net/pdf?id=i3DyRNgCey",
        "keywords": "continual learning, catastrophic forgetting, generative replay, feature replay, deep learning",
        "abstract": "Continual learning of a sequence of tasks without forgetting previously acquired knowledge is one of the main challenges faced by modern deep neural networks. In the class-incremental scenario (aka open-set learning), one of the most difficult continual learning problems, new classes are presented to a classifier over time. The model needs to be able to learn and recognize these new classes while also retaining its knowledge of previously witnessed ones. A common approach is to make it revisit the old classes or their features in some form, either by analysing stored exemplars or by using artificially generated samples. The latter approach, Generative Replay, usually relies on a separate generator trained alongside the main classifier. Since the generator also needs to learn continually, it is usually retrained on every task, using its own generated samples as training data representing older classes. This can lead to error propagation and accumulating features unimportant or confusing for the classifier, reducing the overall performance for larger numbers of tasks. We propose a simple filtering mechanism for mitigating this issue – whenever pseudodata is generated for a new task, the classifier can reject samples it is not able to classify with sufficient confidence, thus preventing both models from retraining on poor-quality data. We tested the filter on several datasets, including real-life images, using various combinations of models, as the method can be applied regardless of the network architectures. We show that filtering improves the classifier's accuracy and provide statistical analysis of the results."
    },
    {
        "title": "Learning Robust Representations for Medical Images via Unifying (Self-)Supervisions",
        "link_suffix": "/forum?id=zi3MEZRCqd",
        "link": "https://openreview.net/forum?id=zi3MEZRCqd",
        "pdf_link": "https://openreview.net/pdf?id=zi3MEZRCqd",
        "keywords": "medical image pre-training, medical image representation learning",
        "abstract": "Pre-training medical image encoder to provide robust, task-agnostic representations is highly valuable, as it enhances the understanding of medical images and is important for performing many data-scarce analysis tasks. Current pre-training works are unable to integrate various types of supervisions, including self-supervision and external supervision such as segmentation annotations, while they are highly valuable for medical image understanding. Therefore, in this paper, we take the first step toward exploring unifying all common types of supervisions into a pre-training framework through a same scalable way. This require the pre-training framework being both unified, for accommodating diverse data and extensible, and effective, for making heterogeneous data synergistically assist unknown downstream tasks. To this end, we propose UmiF, whose principle is that once converted into token embeddings in a unified space, all diverse supervisions can be effectively utilized via contrastive learning and mask modeling with a same way. With UmiF, we pre-train on 1.66M samples from 14 public datasets, significantly surpassing previous efforts in terms of the dataset scale. We obtain and release the UmiF model, which achieved state-of-the-art performance across various downstream tasks, including classification, segmentation, and detection, retrieval and VQA."
    },
    {
        "title": "Edge-preserving noise for diffusion models",
        "link_suffix": "/forum?id=Z33PEFMuU3",
        "link": "https://openreview.net/forum?id=Z33PEFMuU3",
        "pdf_link": "https://openreview.net/pdf?id=Z33PEFMuU3",
        "keywords": "diffusion, generative modelling, denoising",
        "abstract": "Classical generative diffusion models learn an isotropic Gaussian denoising process,\ntreating all spatial regions uniformly, thus neglecting potentially valuable structural\ninformation in the data. Inspired by the long-established work on anisotropic\ndiffusion in image processing, we present a novel edge-preserving diffusion model\nthat is a generalization of denoising diffusion probablistic models (DDPM). In\nparticular, we introduce an edge-aware noise scheduler that varies between edgepreserving\nand isotropic Gaussian noise. We show that our model’s generative\nprocess converges faster to results that more closely match the target distribution.\nWe demonstrate its capability to better learn the low-to-mid frequencies within the\ndataset, which plays a crucial role in representing shapes and structural information.\nOur edge-preserving diffusion process consistently outperforms state-of-the-art\nbaselines in unconditional image generation. It is also more robust for generative\ntasks guided by a shape-based prior, such as stroke-to-image generation. We\npresent qualitative and quantitative results showing consistent improvements (FID\nscore) of up to 30% for both tasks."
    },
    {
        "title": "Convolution goes higher-order: a biologically inspired mechanism empowers image classification.",
        "link_suffix": "/forum?id=dPbJb9XdI1",
        "link": "https://openreview.net/forum?id=dPbJb9XdI1",
        "pdf_link": "https://openreview.net/pdf?id=dPbJb9XdI1",
        "keywords": "Higher-order convolution, Biologically inspired neural networks, Image classification, Convolutional Neural Networks, Biological visual processing, Neural representations",
        "abstract": "We propose a novel approach to image classification inspired by complex nonlinear biological visual processing, whereby classical convolutional neural networks (CNNs) are equipped with learnable higher-order convolutions. Our model incorporates a Volterra-like expansion of the convolution operator, capturing multiplicative interactions akin to those observed in advanced stages of biological visual processing. We evaluated this approach on synthetic datasets by measuring sensitivity to testing higher-order correlations and performance in standard benchmarks (MNIST, FashionMNIST, CIFAR10, CIFAR100). Our architecture outperforms traditional CNN baselines, and achieves optimal performance with expansions up to 3rd/4th order, aligning remarkably well with the distribution of pixel intensities in natural images. This alignment between model performance and natural image statistics suggests that our approach effectively captures the structure of visual information in the natural world. Furthermore, Representational Similarity Analysis reveals distinct geometries across network layers, indicating qualitatively different modes of visual information processing. Our work bridges neuroscience and deep learning, offering a path towards more effective, biologically plausible computer vision models. It provides insights into visual information processing and lays the groundwork for neural networks that better capture complex visual patterns, particularly in resource-constrained scenarios."
    }
]
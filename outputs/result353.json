[{"title": "Modeling the Human Visual System: Comparative Insights from Response-Optimized and Task-Optimized Vision Models, Language Models, and different Readout Mechanisms", "link_suffix": "/forum?id=12B3jBTL0V", "link": "https://openreview.net/forum?id=12B3jBTL0V", "pdf_link": "https://openreview.net/pdf?id=12B3jBTL0V", "keywords": "Neuro AI, vision, deep neural networks, representations, fMRI encoding", "abstract": "Over the past decade, predictive modeling of neural responses in the primate visual system has advanced significantly, largely driven by various deep neural network approaches. These include models optimized directly for visual recognition, cross-modal alignment through contrastive objectives, neural response prediction from scratch, and large language model embeddings. Likewise, different readout mechanisms\u2014ranging from fully linear to spatial-feature factorized methods\u2014have been explored for mapping network activations to neural responses. Despite the diversity of these approaches, it remains unclear which method performs best across different visual regions. In this study, we systematically compare these approaches for modeling the human visual system and investigate alternative strategies to improve response predictions. Our findings reveal that for early to mid-level visual areas, response-optimized models with visual inputs offer superior prediction accuracy, while for higher visual regions, embeddings from Large Language Models (LLMs) based on detailed contextual descriptions of images and task optimized models pretrained on large vision datasets provide the best fit. Through comparative analysis of these modeling approaches, we identified three distinct regions in the visual cortex: one sensitive primarily to perceptual features of the input that are not captured by linguistic descriptions, another attuned to fine-grained visual details representing semantic information, and a third responsive to abstract, global meanings aligned with linguistic content. We also highlight the critical role of readout mechanisms, proposing a novel scheme that modulates receptive fields and feature maps based on semantic content, resulting in an accuracy boost of 3-23% over existing SOTAs for all models and brain regions. Together, these findings offer key insights into building more precise models of the visual system.", "title_embedding_index": 17600, "title_abs_embedding_index": 17625}, {"title": "The Discretization Complexity Analysis of Consistency Models under Variance Exploding Forward Process", "link_suffix": "/forum?id=mH2tKj7KR6", "link": "https://openreview.net/forum?id=mH2tKj7KR6", "pdf_link": "https://openreview.net/pdf?id=mH2tKj7KR6", "keywords": "Discretization Complexity, Consistency Model", "abstract": "Consistency models, a new class of one-step generative models, have shown state-of-the-art performance in one-step generation and achieve competitive performance compared to multi-step diffusion models. The most challenging part of consistency models is the training process, which discretizes the diffusion process and trains a consistency function to map any point at any discretized timepoint of the diffusion process to the data distribution. Despite the empirical success, only a few works focus on the discretization complexity of consistency models. However, the setting of those works is far away from the empirical consistency models with good performance, suffers from large discretization complexity, and fails to explain the empirical success of consistency models. To bridge the gap between theory and application, we analyze consistency models with two key properties: (1) variance exploding forward process and (2) gradually decay discretization stepsize, which are both widely used in empirical consistency models. Under the above realistic setting, we make the first step to explain the empirical success of consistency models and achieve the state-of-the-art discretization complexity for consistency models, which is competitive with the results of diffusion models. After obtaining the results of the one-step sampling method of consistency models, we further analyze a multi-step consistency sampling algorithm proposed by \\citet{song2023consistency} and show that this algorithm improves the discretization complexity compared with one-step generation, which matches the empirical observation.", "title_embedding_index": 17601, "title_abs_embedding_index": 17626}, {"title": "Learning Task Relations for Test-Time Training", "link_suffix": "/forum?id=WhvTLognS0", "link": "https://openreview.net/forum?id=WhvTLognS0", "pdf_link": "https://openreview.net/pdf?id=WhvTLognS0", "keywords": "Test-time Training, Task Relation Learning, Multi-task Learning", "abstract": "Generalizing deep neural networks to unseen target domains presents a major challenge in real-world deployments. Test-time training (TTT) addresses this is- sue by using an auxiliary self-supervised task to reduce the gap between source and target domains caused by distribution shifts during deployment. Previous re- search relies on the assumption that the adopted auxiliary task would be beneficial to the target task we want to adapt. However, this situation is not guaranteed as each task has a different objective, thus adaptation relies on the relation be- tween the tasks. This limitation has motivated us to introduce a more generalized framework: Task Relation Learning for Test-time Training (TR-TTT), which can be applied to multiple tasks concurrently. Our key assumption is that task re- lations are crucial information for successful test-time training, and we capture these relations using a Task Relation Learner (TRL). We model task relations as conditional probabilities by predicting the label of a target task based on the latent spaces of other task-specific features. By leveraging these relations, the network can more effectively handle distribution shifts and improve post-adaptation perfor- mance across various tasks\u2014both classification and regression\u2014unlike previous methods focused mainly on simple classification. To validate our approach, we ap- ply TR-TTT to conventional multi-task benchmarks, integrating it with the tradi- tional TTT experimental protocol. Our empirical results demonstrate that TR-TTT significantly outperforms state-of-the-art methods across a range of benchmarks.", "title_embedding_index": 17602, "title_abs_embedding_index": 17627}, {"title": "Improved Methods for Model Pruning", "link_suffix": "/forum?id=V8wrTu8p6x", "link": "https://openreview.net/forum?id=V8wrTu8p6x", "pdf_link": "https://openreview.net/pdf?id=V8wrTu8p6x", "keywords": "model pruning, optimization, alignment, attention", "abstract": "Model pruning is a performance optimization technique for large language and vision models. However, existing pruning methods often lead to significant performance degradation or require extensive retraining and fine-tuning. This technique aims to identify and remove neurons, connections unlikely leading to the contribution during the machine generation phase. Our goal is to obtain a much smaller and faster foundational model that can quickly generate content almost as good as those of the unpruned models. We propose MAMA (short for Movement and Magnitude Analysis), an improved pruning method that effectively reduces model size and network computational complexity while maintaining performance comparable to the original unpruned model even at extreme pruned levels. The improved method is based on weights, bias, activations and proposed novel pruning indicators. Empirical results show that our method outperforms and be comparable to state-of-the-art methods across various pruning levels. All our code, models, dataset, and demo are publicly available.", "title_embedding_index": 17603, "title_abs_embedding_index": 17628}, {"title": "Can LLMs Generate Diverse Molecules? Towards Alignment with Structural Diversity", "link_suffix": "/forum?id=B9177IHxCL", "link": "https://openreview.net/forum?id=B9177IHxCL", "pdf_link": "https://openreview.net/pdf?id=B9177IHxCL", "keywords": "Large language model, molecular generative model, drug discovery", "abstract": "Recent advancements in large language models (LLMs) have demonstrated impressive performance in generating molecular structures as drug candidates, which offers significant potential to accelerate drug discovery. However, the current LLMs overlook a critical requirement for drug discovery: proposing a diverse set of molecules. This diversity is essential for improving the chances of finding a viable drug, as it provides alternative molecules that may succeed where others fail in wet-lab or clinical validations. Despite such a need for diversity, the LLMs often output structurally similar molecules from a given prompt. While decoding schemes like beam search may enhance textual diversity, this often does not align with molecular structural diversity. In response, we propose a new method for fine-tuning molecular generative LLMs to autoregressively generate a set of structurally diverse molecules, where each molecule is generated by conditioning on the previously generated molecules. Our approach consists of two stages: (1) supervised fine-tuning to adapt LLMs to autoregressively generate molecules in a sequence and (2) reinforcement learning to maximize structural diversity within the generated molecules. Our experiments show that (1) our fine-tuning approach enables the LLMs to better discover diverse molecules compared to existing decoding schemes and (2) our fine-tuned model outperforms other representative LLMs in generating diverse molecules, including the ones fine-tuned on chemical domains.", "title_embedding_index": 17604, "title_abs_embedding_index": 17629}, {"title": "FinRipple: Aligning Large Language Models with Financial Market for Event Ripple Effect Awareness", "link_suffix": "/forum?id=o4TyewNBIB", "link": "https://openreview.net/forum?id=o4TyewNBIB", "pdf_link": "https://openreview.net/pdf?id=o4TyewNBIB", "keywords": "Large Language Models, Time-Varying Knowledge Graph, Event Studies, Asset Pricing", "abstract": "Event studies have been fundamental in finance, focusing on analyzing the ripple effects of sudden market events. Accurately predicting these effects is crucial for informed decision-making and effective risk management. However, the dynamic complexity of financial markets and the lack of unified modeling tools make this task challenging. Previous models, constrained by simplistic assumptions and limited scopes, have struggled to address this complexity effectively. In contrast, large language models (LLMs), with their emergent reasoning abilities, offer a promising solution. In this paper, we introduce $\\textbf{FinRipple}$, a novel training framework that enables LLMs to align with market behavior and develop the capability to analyze the ripple effects of sudden events. We first construct a time-varying financial knowledge graph (KG) that is both financially meaningful and noise-reduced to accurately represent the market state. These KGs are then integrated into the LLM using adapters as memory modules. Additionally, we align the LLM with market dynamics by integrating FinRipple with classic asset pricing theories through a reinforcement learning framework. This market-alignment process collects feedback that enhances the LLM's foundational ability to analyze financial events and explain market anomalies that traditional models fail to address. Our key contributions are as follows: (1) We are the first to define the underexplored task of ``event impact prediction''. Our framework not only establishes this task but also provides an open-source benchmark, creating a unified evaluation standard for both academia and industry; (2) FinRipple complements classic asset pricing models by combining strong theoretical foundations with AI-driven capabilities, offering an enhanced analysis of residuals unexplained by traditional models. We also demonstrate its potential for practical applications such as portfolio management; (3) We conduct a comprehensive analysis to ensure that the results generated by LLMs in our framework are more logically consistent and credible, thus improving the reliability of insights for financial decision-making.", "title_embedding_index": 17605, "title_abs_embedding_index": 17630}, {"title": "AhmedML: High-Fidelity Computational Fluid Dynamics Dataset for Incompressible, Low-Speed Bluff Body Aerodynamics", "link_suffix": "/forum?id=KrSaWQH1OA", "link": "https://openreview.net/forum?id=KrSaWQH1OA", "pdf_link": "https://openreview.net/pdf?id=KrSaWQH1OA", "keywords": "CFD, aerodynamics, dataset, automotive, ML", "abstract": "The development of Machine Learning (ML) methods for Computational Fluid Dynamics (CFD) is currently limited by the lack of openly available training data. This paper presents a new open-source dataset comprising of high fidelity, scale-resolving CFD simulations of 500 geometric variations of the Ahmed Car Body - a simplified car-like shape that exhibits many of the flow topologies that are present on bluff bodies such as road vehicles. The dataset contains simulation results that exhibit a broad set of fundamental flow physics such as geometry and pressure-induced flow separation as well as 3D vortical structures. Each variation of the Ahmed car body were run using a high-fidelity, time-accurate, hybrid Reynolds-Averaged Navier-Stokes (RANS) - Large-Eddy Simulation (LES) turbulence modelling approach using the open-source CFD code OpenFOAM. The dataset contains boundary, volume, geometry, and time-averaged forces/moments in widely used open-source formats. In addition, the OpenFOAM case setup is provided so that others can reproduce or extend the dataset. This represents to the authors knowledge, the first open-source large-scale dataset using high-fidelity CFD methods for the widely used Ahmed car body that is available to freely download with a permissive license (CC-BY-SA).", "title_embedding_index": 17606, "title_abs_embedding_index": 17631}, {"title": "Reversible Decoupling Network for Single Image Reflection Removal", "link_suffix": "/forum?id=JIGuWpQcqO", "link": "https://openreview.net/forum?id=JIGuWpQcqO", "pdf_link": "https://openreview.net/pdf?id=JIGuWpQcqO", "keywords": "Invertible network, Reflection separation", "abstract": "Recent deep-learning-based approaches to single-image reflection removal have shown promising advances, primarily for two reasons: 1) the utilization of recognition-pretrained features as inputs, and 2) the design of dual-stream interaction networks. However, according to the Information Bottleneck principle, high-level semantic clues tend to be compressed or discarded during layer-by-layer propagation. Additionally, interactions in dual-stream networks follow a fixed pattern across different layers, limiting overall performance. To address these limitations, we propose a novel architecture called Reversible Decoupling Network (RDNet), which employs a reversible encoder to secure valuable information while flexibly decoupling transmission- and reflection-relevant features during the forward pass. Furthermore, we customize a transmission-rate-aware prompt generator to dynamically calibrate features, further boosting performance. Extensive experiments demonstrate the superiority of RDNet over existing SOTA methods on five widely-adopted benchmark datasets. Our code will be made publicly available.", "title_embedding_index": 17607, "title_abs_embedding_index": 17632}, {"title": "Do as I do (Safely): Mitigating Task-Specific Fine-tuning Risks in Large Language Models", "link_suffix": "/forum?id=lXE5lB6ppV", "link": "https://openreview.net/forum?id=lXE5lB6ppV", "pdf_link": "https://openreview.net/pdf?id=lXE5lB6ppV", "keywords": "large language models, safety, fine-tuning", "abstract": "Recent research shows that fine-tuning on benign instruction-following data can inadvertently undo the safety alignment process and increase a model's propensity to comply with harmful queries. While instruction-following fine-tuning is important, task-specific fine-tuning - where models are trained on datasets with clear ground truth answers (e.g., multiple choice questions) - can enhance model performance on specialized downstream tasks. Understanding and mitigating safety risks in the task-specific setting remains distinct from the instruction-following context due to structural differences in the data. Our work demonstrates how malicious actors can subtly manipulate the structure of almost any task-specific dataset to foster significantly more dangerous model behaviors, while maintaining an appearance of innocuity and reasonable downstream task performance. To address this issue, we propose a novel mitigation strategy that mixes in safety data which mimics the task format and prompting style of the user data, showing this is significantly more effective and efficient than existing baselines at re-establishing safety alignment while maintaining similar task performance.", "title_embedding_index": 17608, "title_abs_embedding_index": 17633}, {"title": "Gamma: Toward Generic Image Assessment with Mixture of Assessment Experts", "link_suffix": "/forum?id=2wkjYEYoss", "link": "https://openreview.net/forum?id=2wkjYEYoss", "pdf_link": "https://openreview.net/pdf?id=2wkjYEYoss", "keywords": "Image assessment, Mixture of Experts (MoE), Mixed training", "abstract": "Image assessment aims to evaluate the quality and aesthetics of images and has been applied across various scenarios, such as natural and AIGC scenes. Existing methods mostly address these sub-tasks or scenes individually. While some works attempt to develop unified image assessment models, they have struggled to achieve satisfactory performance or cover a broad spectrum of assessment scenarios. In this paper, we present \\textbf{Gamma}, a \\textbf{G}eneric im\\textbf{A}ge assess\\textbf{M}ent model using \\textbf{M}ixture of \\textbf{A}ssessment Experts, which can effectively assess images from diverse scenes through mixed-dataset training. Achieving unified training in image assessment presents significant challenges due to annotation biases across different datasets. To address this issue, we first propose a Mixture of Assessment Experts (MoAE) module, which employs shared and adaptive experts to dynamically learn common and specific knowledge for different datasets, respectively. In addition, we introduce a Scene-based Differential Prompt (SDP) strategy, which uses scene-specific prompts to provide prior knowledge and guidance during the learning process, further boosting adaptation for various scenes. Our Gamma model is trained and evaluated on 12 datasets spanning 6 image assessment scenarios. Extensive experiments show that our unified Gamma outperforms other state-of-the-art mixed-training methods by significant margins while covering more scenes.", "title_embedding_index": 17609, "title_abs_embedding_index": 17634}, {"title": "Labels Are Not All You Need: Evaluating Node Embedding Quality without Relying on Labels", "link_suffix": "/forum?id=UYqssWc7TC", "link": "https://openreview.net/forum?id=UYqssWc7TC", "pdf_link": "https://openreview.net/pdf?id=UYqssWc7TC", "keywords": "Graph Representation Learning, Unsupervised Learning, Graph Neural Networks, Model Selection", "abstract": "Graph Neural Network (GNN) based node embedding methods are a promising approach to learning node representations for downstream tasks such as link prediction, node classification, and node clustering. GNN-based methods usually work in an unsupervised or semi-supervised manner, learning node representations without or with limited label information. We empirically show, however, that the performance of learned node embeddings on downstream tasks may be heavily impacted by the GNN-method's hyperparameter configuration. Unfortunately, existing hyperparameter optimisation methods typically rely on labeled data for evaluation, making them unsuitable for unsupervised scenarios. This raises the question:how can we tune the hyperparamters of GNNs without using label information to obtain high quality node embeddings?To answer this, we propose a framework for evaluating node embedding quality without relying on labels. Specifically, our framework consists of two steps:building prior beliefsthat characterize high-quality node embeddings, andquantifying the extentto which those prior beliefs are satisfied. More importantly, we instantiate our framework from two different but complementary perspectives: spatial and spectral information. First, we introduce the Consensus-based Space Occupancy Rate (CSOR) method that evaluates node embedding quality from a spatial view. It conducts pairwise comparisons of the spatial distances between node embeddings obtained from various hyperparameter configurations. Next, we present the Spectral Space Occupancy Rate (SSOR) method, which takes a spectral perspective and evaluates the embedding quality by examining the singular values of the node embedding matrices. Extensive experiments on seven GNN models with four benchmark datasets demonstrate the effectiveness of both CSOR and SSOR. Specifically, both methods consistently prioritize hyperparameter configurations that yield high-quality node embeddings for downstream tasks.", "title_embedding_index": 17610, "title_abs_embedding_index": 17635}, {"title": "Noise Prompt Learning: Learning the Winning Tickets for Diffusion Sampling", "link_suffix": "/forum?id=qIJenSdGbW", "link": "https://openreview.net/forum?id=qIJenSdGbW", "pdf_link": "https://openreview.net/pdf?id=qIJenSdGbW", "keywords": "Noise Prompt, Noise Prompt Learning, Image Synthesis, Diffusion Models", "abstract": "Text-to-image diffusion model is a popular paradigm that synthesizes personalized images by providing a text prompt and a random Gaussian noise. While people observe that some noises are winning tickets that can achieve better text-image alignment and higher human preference than others, we still lack a machine learning framework to obtain those winning noises. To learn winning noises for diffusion sampling, we mainly make three contributions in this paper. First, we identify a new concept termed the $\\textit{noise prompt}$, which aims at turning a random Gaussian noise into a winning noise ticket by adding a small desirable perturbation derived from the text prompt. Following the concept, we first formulate the $\\textit{noise prompt learning}$ framework that systematically learns \"prompted'' winning noise tickets associated with a text prompt for diffusion models. Second, we design a noise prompt data collection pipeline and collect a large-scale $\\textit{noise prompt dataset}$ (NPD) that contains 100k pairs of random noises and winning noises with the associated text prompts. With the prepared NPD as the training dataset, we trained a small $\\textit{noise prompt network}$ (NPNet) that can directly learn to transform a random noise ticket into a winning noise ticket. The learned winning noise perturbation can be considered as a kind of prompt for noise, as it is rich in semantic information and tailored to the given text prompt. Third, our extensive experiments demonstrate the impressive effectiveness and generalization of NPNet on improving the quality of synthesized images across various diffusion models, including SDXL, DreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and efficient controller that acts as a plug-and-play module with very limited additional inference and computational costs, as it just provides a winning noise instead of a random noise without accessing the original pipeline.", "title_embedding_index": 17611, "title_abs_embedding_index": 17636}, {"title": "Parameter-Efficient Fine-Tuning with Circulant and Diagonal Vectors", "link_suffix": "/forum?id=nb9DiBUt7c", "link": "https://openreview.net/forum?id=nb9DiBUt7c", "pdf_link": "https://openreview.net/pdf?id=nb9DiBUt7c", "keywords": "fine-tuning; circulant matrices; diagonal matrices", "abstract": "Foundation models have achieved tremendous success in different domains.\nHowever, their huge computation and storage complexity make these models difficult to fine-tune and also less applicable in practice. \nRecent study shows training in fourier domain can be an effective fine-tuning method in terms of both model performance and number of training parameters. \nIn this work, we propose to further reduce the complexity by using the product of interleaved circulant and diagonal matrices. \nOur method avoids the construction of weight change matrix and applies 1D fast fourier transform (FFT) instead of 2D FFT. \nExperimental results show that our method achieves similar or better  performance across various tasks with much less floating-point operations (FLOPs).", "title_embedding_index": 17612, "title_abs_embedding_index": 17637}, {"title": "Improving AI via Novel Computational Models and Programming Challenges", "link_suffix": "/forum?id=NlY3XppPt3", "link": "https://openreview.net/forum?id=NlY3XppPt3", "pdf_link": "https://openreview.net/pdf?id=NlY3XppPt3", "keywords": "AI, LLM, code generation", "abstract": "AI, like humans, should be able to adapt and apply learned knowledge across diverse domains, such as computational models, mathematical/formal systems, and programming languages to solve problems. Current AI training often relies on existing systems, which limits its ability to generate original solutions or generalize across unfamiliar contexts. To address this, we propose a new computational model along with a revised programming language tailored to this model. By challenging AI to write, analyze, or verify programs within these new frameworks, and by utilizing a virtual machine for evaluation, we aim to test and enhance the AI's adaptability and problem-solving capabilities in a verifiable manner.", "title_embedding_index": 17613, "title_abs_embedding_index": 17638}, {"title": "HyperPg - Prototypical Gaussians on the Hypersphere for Interpretable Deep Learning", "link_suffix": "/forum?id=m1bbeUqg3V", "link": "https://openreview.net/forum?id=m1bbeUqg3V", "pdf_link": "https://openreview.net/pdf?id=m1bbeUqg3V", "keywords": "XAI, Inherently Interpretable Model, Prototype Learning, This looks like That Framework, Image Classification, Deep Learning", "abstract": "Prototype Learning methods provide an interpretable alternative to black-box deep learning models. Approaches such as ProtoPNet learn, which part of a test image \"look like\"' known prototypical parts from training images, combining predictive power with the inherent interpretability of case-based reasoning. However, existing approaches have two main drawbacks: A) They rely solely on deterministic similarity scores without statistical confidence. B) The prototypes are learned in a black-box manner without human input.This work introduces HyperPg, a new prototype representation leveraging Gaussian distributions on a hypersphere in latent space, with learnable mean and variance. HyperPg prototypes adapt to the spread of clusters in the latent space and output likelihood scores.The new architecture, HyperPgNet, leverages HyperPg to learn prototypes aligned with human concepts from pixel-level annotations. Consequently, each prototype represents a specific concept such as color, image texture, or part of the image subject. A concept extraction pipeline built on foundation models provides pixel-level annotations, significantly reducing human labeling effort.Experiments on CUB-200-2011 and Stanford Cars datasets demonstrate that HyperPgNet outperforms other prototype learning architectures while using fewer parameters and training steps. Additionally, the concept-aligned HyperPg prototypes are learned transparently, enhancing model interpretability.", "title_embedding_index": 17614, "title_abs_embedding_index": 17639}, {"title": "Epistemic Monte Carlo Tree Search", "link_suffix": "/forum?id=Tb8RiXOc3N", "link": "https://openreview.net/forum?id=Tb8RiXOc3N", "pdf_link": "https://openreview.net/pdf?id=Tb8RiXOc3N", "keywords": "model based, epistemic uncertainty, exploration, planning, alphazero, muzero", "abstract": "The AlphaZero/MuZero (A/MZ) family of algorithms has achieved remarkable success across various challenging domains by integrating Monte Carlo Tree Search (MCTS) with learned models. Learned models introduce epistemic uncertainty, which is caused by learning from limited data and is useful for exploration in sparse reward environments. MCTS does not account for the propagation of this uncertainty however. To address this, we introduce Epistemic MCTS (EMCTS): a theoretically motivated approach to account for the epistemic uncertainty in search and harness the search for deep exploration. In the challenging sparse-reward task of writing code in the Assembly language SUBLEQ, AZ paired with our method achieves significantly higher sample efficiency over baseline AZ. Search with EMCTS \nsolves variations of the commonly used hard-exploration benchmark Deep Sea - which baseline A/MZ are practically unable to solve - much faster than an otherwise equivalent method that does not use search for uncertainty estimation, demonstrating significant benefits from search for epistemic uncertainty estimation.", "title_embedding_index": 17615, "title_abs_embedding_index": 17640}, {"title": "Plan B: Training LLMs to fail less severely", "link_suffix": "/forum?id=XdRv6I80L1", "link": "https://openreview.net/forum?id=XdRv6I80L1", "pdf_link": "https://openreview.net/pdf?id=XdRv6I80L1", "keywords": "AI safety, data poisoning, alignment, robustness, sleeper agents, model organisms, jailbreaks", "abstract": "Safety-trained LLMs can produce harmful responses across various input types, as shown by research on jailbreaks, data poisoning, and misalignment. Despite ongoing efforts, fully preventing such failures remains difficult. In this work, we propose a second line of defense: instead of solely focusing on eliminating harmful responses, we also aim to reduce their severity when they occur.  As a case study, we experiment with an LLM trained to respond to a backdoor-trigger by complying with harmful requests. We fine-tune the model, without using the trigger in the training data, on the following pairwise preferences: (1) refusal is preferred over any harmful response, (2) less harmful responses are preferred over more harmful ones. We find that training on this preference ordering significantly reduces the harmfulness of backdoor-triggered responses. Finally, we demonstrate that our approach generalizes to several state-of-the-art jailbreak techniques.", "title_embedding_index": 17616, "title_abs_embedding_index": 17641}, {"title": "Influence Functions for Scalable Data Attribution in Diffusion Models", "link_suffix": "/forum?id=esYrEndGsr", "link": "https://openreview.net/forum?id=esYrEndGsr", "pdf_link": "https://openreview.net/pdf?id=esYrEndGsr", "keywords": "diffusion, influence functions, K-FAC, Generalised Gauss Newton, data attribution, Hessian approximation, GGN, interpretability", "abstract": "Diffusion models have led to significant advancements in generative modelling. Yet their widespread adoption poses challenges regarding data attribution and interpretability. In this paper, we aim to help address such challenges in diffusion models by extending influence functions. Influence function-based data attribution methods approximate how a model's output would have changed if some training data were removed. In supervised learning, this is usually used for predicting how the loss on a particular example would change. For diffusion models, we focus on predicting the change in the probability of generating a particular example via several proxy measurements. We show how to formulate influence functions for such quantities and how previously proposed methods can be interpreted as particular design choices in our framework. To ensure scalability of the Hessian computations in influence functions, we use a K-FAC approximation based on generalised Gauss-Newton matrices specifically tailored to diffusion models. We show that our recommended method outperforms previously proposed data attribution methods on common data attribution evaluations, such as the Linear Data-modelling Score (LDS) or retraining without top influences, without the need for method-specific hyperparameter tuning.", "title_embedding_index": 17617, "title_abs_embedding_index": 17642}, {"title": "Second-Order Min-Max Optimization with Lazy Hessians", "link_suffix": "/forum?id=ijbA5swmoK", "link": "https://openreview.net/forum?id=ijbA5swmoK", "pdf_link": "https://openreview.net/pdf?id=ijbA5swmoK", "keywords": "min-max optimization; second-order methods; computational complexity", "abstract": "This paper studies second-order methods for convex-concave minimax optimization.Monteiro & Svaiter (2012)  proposed a method to solve the problem with an optimal iteration complexity of \n$\\mathcal{O}(\\epsilon^{-3/2})$ to find an $\\epsilon$-saddle point.  However, it is unclear whether the\ncomputational complexity, $\\mathcal{O}((N+ d^2) d \\epsilon^{-2/3})$, can be improved. In the above, we follow  Doikov et al. (2023) and assume the complexity of obtaining a first-order oracle as $N$ and the complexity of obtaining a second-order oracle as $dN$. \nIn this paper, we show that the computation cost can be reduced by reusing Hessian across iterations. Our methods take the overall computational complexity of $\\tilde{\\mathcal{O}}( (N+d^2)(d+ d^{2/3}\\epsilon^{-2/3}))$, which improves those of previous methods by a factor of $d^{1/3}$. \nFurthermore, we generalize our method to strongly-convex-strongly-concave minimax problems and establish the complexity of $\\tilde{\\mathcal{O}}((N+d^2) (d + d^{2/3} \\kappa^{2/3}) )$ when the condition number of the problem is $\\kappa$, enjoying a similar speedup upon the state-of-the-art method. \nNumerical experiments on both real and synthetic datasets also verify the efficiency of our method.", "title_embedding_index": 17618, "title_abs_embedding_index": 17643}, {"title": "AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant", "link_suffix": "/forum?id=0sr8bS4S2H", "link": "https://openreview.net/forum?id=0sr8bS4S2H", "pdf_link": "https://openreview.net/pdf?id=0sr8bS4S2H", "keywords": "human-computer interactions, multi-agent, multimodal learning", "abstract": "Digital agents capable of automating complex computer tasks have attracted considerable attention due to their immense potential to enhance human-computer interaction. However, existing agent methods reveal deficiencies in their generalization and specialization capabilities, especially in handling open-ended computer tasks in real-world environments. Inspired by the rich functionality of the App store, we present AgentStore, a scalable platform designed to dynamically integrate heterogeneous agents for automating computer tasks. AgentStore empowers users to integrate third-party agents, allowing the system to continuously enrich its capabilities and adapt to rapidly evolving operating systems. Additionally, we propose a novel core MetaAgent with the AgentToken strategy to efficiently manage diverse agents and utilize their specialized and generalist abilities for both domain-specific and system-wide tasks. Extensive experiments on challenging benchmarks demonstrate that AgentStore surpasses the limitations of previous systems with narrow capabilities, particularly achieving a significant improvement from 11.21% to 23.85% on the OSWorld benchmark, more than doubling the previous results. Comprehensive quantitative and qualitative results further demonstrate AgentStore's ability to enhance agent systems in both generalization and specialization, underscoring its potential for developing the specialized generalist computer assistant. All our codes will be made publicly available.", "title_embedding_index": 17619, "title_abs_embedding_index": 17644}, {"title": "LinBridge: A Learnable Framework for Interpreting Nonlinear Neural Encoding Models", "link_suffix": "/forum?id=C0Boqhem9u", "link": "https://openreview.net/forum?id=C0Boqhem9u", "pdf_link": "https://openreview.net/pdf?id=C0Boqhem9u", "keywords": "Nonlinear encoding models, Jacobian matrix, Linear inherent component, Mapping bias", "abstract": "Neural encoding of artificial neural networks (ANNs) aligns the computational representations of ANNs with brain responses, providing profound insights into the neural basis underpinning information processing in the human brain. Current neural encoding studies primarily employ linear encoding models for interpretability, despite the prevalence of nonlinear neural responses. This leads to a growing interest in developing nonlinear encoding models that retain interpretability. To address this problem, we propose LinBridge, a learnable and flexible framework based on Jacobian analysis for interpreting nonlinear encoding models. LinBridge posits that the nonlinear mapping between ANN representations and neural responses can be factorized into a linear inherent component that approximates the complex nonlinear relationship, and a mapping bias that captures sample-selective nonlinearity. The Jacobian matrix, which reflects output change rates relative to input, enables the analysis of sample-selective mapping in nonlinear models. LinBridge employs a self-supervised learning strategy to extract both the linear inherent component and nonlinear mapping biases from the Jacobian matrices of the test set, allowing it to adapt effectively to various nonlinear encoding models. We validate the LinBridge framework in the scenario of neural visual encoding, using computational visual representations from CLIP-ViT to predict brain activity recorded via functional magnetic resonance imaging (fMRI). Our experimental results demonstrate that: 1) the linear inherent component extracted by LinBridge accurately reflects the complex mappings of nonlinear neural encoding models; 2) the sample-selective mapping bias elucidates the variability of nonlinearity across different levels of the visual processing hierarchy. This study not only introduces a novel tool for interpreting nonlinear neural encoding models but also provides novel evidence regarding the distribution of hierarchical nonlinearity within the visual cortex.", "title_embedding_index": 17620, "title_abs_embedding_index": 17645}, {"title": "ParaSolver: A Hierarchical Parallel Integral Solver for Diffusion Models", "link_suffix": "/forum?id=2JihLwirxO", "link": "https://openreview.net/forum?id=2JihLwirxO", "pdf_link": "https://openreview.net/pdf?id=2JihLwirxO", "keywords": "Diffusion Models;", "abstract": "This paper explores the challenge of accelerating the sequential inference process of Diffusion Probabilistic Models (DPMs). We tackle this critical issue from a dynamic systems perspective, in which the inherent sequential nature is transformed into a parallel sampling process. Specifically, we propose a unified framework that generalizes the sequential sampling process of DPMs as solving a system of banded nonlinear equations. Under this generic framework, we reveal that the Jacobian of the banded nonlinear equations system possesses a unit-diagonal structure, enabling further approximation for acceleration. Moreover, we theoretically propose an effective initialization approach for parallel sampling methods. Finally, we construct ParaSolver, a hierarchical parallel sampling technique that enhances sampling speed without compromising quality. Extensive experiments show that ParaSolver achieves up to 12.1\u00d7 speedup in terms of wall-clock time. The source code will be publicly available.", "title_embedding_index": 17621, "title_abs_embedding_index": 17646}, {"title": "RAGDP: Retrieve-Augmented Generative Diffusion Policy", "link_suffix": "/forum?id=op1uHGKeux", "link": "https://openreview.net/forum?id=op1uHGKeux", "pdf_link": "https://openreview.net/pdf?id=op1uHGKeux", "keywords": "Imitation Learning, Diffusion Models, Behavior Cloning", "abstract": "Diffusion Policy has attracted attention for its ability to achieve significant accuracy gains in a variety of imitation learning tasks. However, since Diffusion Policy relies on the Diffusion Model, it requires multiple denoising steps to generate a single action leading to long generation times. To address this issue, methods like DDIM and Consistency Models have been introduced to speed up the process. While these methods reduce computation time, this often comes at the cost of accuracy. In this paper, we propose RAGDP, a technique designed to improve the efficiency of learned Diffusion Policies without sacrificing accuracy. RAGDP builds upon the Retrieval-Augmented Generation (RAG) technique, which is commonly used in large language models to store and retrieve data from a vector database based on encoded embeddings. In RAGDP, pairs of expert observation and actions data are stored in a vector database. The system then searches the database using encoded observation data to retrieve expert action data with high similarity. This retrieved expert data is subsequently used by the RAGDP algorithm to generate actions tailored to the current environment. We introduce two action generation algorithms, RAGDP-VP and RAGDP-VE, which correspond to different types of Diffusion Models. Our results demonstrate that RAGDP can significantly improve the speed of Diffusion Policy without compromising accuracy. Furthermore, RAGDP can be integrated with existing speed-up methods to enhance their performance.", "title_embedding_index": 17622, "title_abs_embedding_index": 17647}, {"title": "Enhance Multi-View Classification Through Multi-Scale Alignment and Expanded Boundary", "link_suffix": "/forum?id=t1J2CnDFwj", "link": "https://openreview.net/forum?id=t1J2CnDFwj", "pdf_link": "https://openreview.net/pdf?id=t1J2CnDFwj", "keywords": "Multi-View Classification, Multi-Scale Alignment, Fuzzy Logic, Decision Boundary", "abstract": "Multi-view classification aims at unifying the data from multiple views to complementarily enhance the classification performance. Unfortunately, two major problems in multi-view data are damaging model performance. The first is feature heterogeneity, which makes it hard to fuse features from different views. Considering this, we introduce a multi-scale alignment module, including an instance-scale alignment module and a prototype-scale alignment module to mine the commonality from an inter-view perspective and an inter-class perspective respectively, jointly alleviating feature heterogeneity. The second is information redundancy which easily incurs ambiguous data to blur class boundaries and impair model generalization. Therefore, we propose a novel expanded boundary by extending the original class boundary with fuzzy set theory, which adaptively adjusts the boundary to fit ambiguous data. By integrating the expanded boundary into the prototype-scale alignment module, our model further tightens the produced representations and reduces boundary ambiguity. Additionally, compared with the original class boundary, the expanded boundary preserves more margins for classifying unseen data, which guarantees the model generalization. Extensive experiment results across various real-world datasets demonstrate the superiority of the proposed model against existing state-of-the-art methods.", "title_embedding_index": 17623, "title_abs_embedding_index": 17648}, {"title": "How Do We Select Right LLM for Each Query?", "link_suffix": "/forum?id=AfA3qNY0Fq", "link": "https://openreview.net/forum?id=AfA3qNY0Fq", "pdf_link": "https://openreview.net/pdf?id=AfA3qNY0Fq", "keywords": "Multi-armed bandits, LLM recommendation", "abstract": "As Large Language Models (LLMs) continue to expand in both variety and cost, selecting the most appropriate model for each query is becoming increasingly crucial. Many existing works treat this as an offline problem, necessitating a data-gathering phase to compile a set of query-answer-reward triplets beforehand. They often struggle to determine the adequate number of triplets needed and are prone to overfitting if the data volume is insufficient. To address these limitations, we propose a new solution, the Multi-Armed Router (MAR), which applies multi-armed bandit theory\u2014a perspective previously unexplored in this domain. Unlike previous works that base decision-making solely on regression techniques using static datasets (i.e., constructed triplets), our method treats this as an online multi-LLM recommendation problem, which better mirrors real-world applications. Moreover, rather than the vanilla multi-armed bandit, our framework employs contextual bandit algorithms to navigate the trade-offs between exploring new models and exploiting proven models, while considering the dependency between the input query and the answer's reward. Due to the lack of an off-the-shelf dataset in this area, we construct WildArena, a dataset of 4,029 real-world user queries. For each query, there are seven open-ended responses derived from seven leading LLMs, respectively, with an evaluation score for each answer by using the LLM-as-a-Judge framework. We hope that the introduction of the new perspective and the dataset will facilitate the research in per-query LLM routing.", "title_embedding_index": 17624, "title_abs_embedding_index": 17649}]
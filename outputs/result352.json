[{"title": "Leveraging Prior Experience: An Expandable Auxiliary Knowledge Base for Text-to-SQL", "link_suffix": "/forum?id=p97nsl3Fvq", "link": "https://openreview.net/forum?id=p97nsl3Fvq", "pdf_link": "https://openreview.net/pdf?id=p97nsl3Fvq", "keywords": "Large language models; Text to SQL;  In-context learning; Continuous learning;", "abstract": "Large Language Models (LLMs) exhibit impressive problem-solving skills across many tasks, but they still underperform compared to humans in various downstream applications, such as text-to-SQL. On the BIRD benchmark leaderboard, human performance achieves an accuracy of 92.96%, whereas the top-performing method reaches only 72.39%. Notably, these state-of-the-art (SoTA) methods predominantly rely on in-context learning to simulate human-like reasoning. However, they overlook a critical human skill: continual learning. Inspired by the educational practice of maintaining mistake notebooks during our formative years, we propose LPE-SQL ($\\underline{\\textbf{L}}$everaging $\\underline{\\textbf{P}}$rior $\\underline{\\textbf{E}}$xperience: An Expandable Auxiliary Knowledge Base for Text-to-$\\underline{\\textbf{SQL}}$), a novel framework designed to augment LLMs by enabling continual learning without requiring parameter fine-tuning. LPE-SQL consists of four modules that $\\textbf{i)}$ retrieve relevant entries, $\\textbf{ii)}$ efficient sql generation, $\\textbf{iii)}$ generate the final result through a cross-consistency mechanism and $\\textbf{iv)}$ log successful and failed tasks along with their reasoning processes or reflection-generated tips. Importantly, the core module of LPE-SQL is the fourth one, while the other modules employ foundational methods, allowing LPE-SQL to be easily integrated with SoTA technologies to further enhance performance. Our experimental results demonstrate that this continual learning approach yields substantial performance gains, with the smaller Llama-3.1-70B model with surpassing the performance of the larger Llama-3.1-405B model using SoTA methods.", "title_embedding_index": 17550, "title_abs_embedding_index": 17575}, {"title": "Integrating Relation Dependences and Textual Semantics for Coherent Logical Reasoning over Temporal Knowledge Graph", "link_suffix": "/forum?id=CNGkrfDhdG", "link": "https://openreview.net/forum?id=CNGkrfDhdG", "pdf_link": "https://openreview.net/pdf?id=CNGkrfDhdG", "keywords": "Temporal knowledge graph, Knowledge graph, Multi-hop logical rules, Link forecasting, Inductive reasoning", "abstract": "Temporal knowledge graphs (TKGs) reflect the evolution patterns of facts, which can be summarized as logical rules and applied to forecast future facts. However, existing logical reasoning methods on TKGs face two limitations: 1) A lack of efficient strategies for extracting logical paths. 2) Insufficient utilization of structural and textual information. To bridge these gaps, we propose CoLR, a two-stage framework that mines relation dependencies and textual semantics for Coherent Logical Reasoning over TKGs. In the first stage, we construct a temporal relation structure graph (TRSG) composed of relations and cohesion weights between them. Besides, we define a novel time-fusion search graph (TFSG) along with TRSG to facilitate efficient and reliable temporal path searching. In the second stage,\nthe textual content and timestamp sequences from these paths undergo encoding via a pre-trained language model and a time sequence encoder to accurately capture potential logical rules. Additionally, for quadruplets missing paths, historical edges sampled based on relation cohesion are used as supplements. Given the limitations of existing benchmark datasets in evaluating accuracy, generalization, and robustness, we construct three new datasets tailored to transductive, inductive, and few-shot scenarios, respectively. These datasets, combined with four real-world datasets, are employed to evaluate our model comprehensively. Experimental results demonstrate that our approach significantly outperforms existing methods across all three scenarios. Our code is available athttps://anonymous.4open.science/r/CoLR-0839", "title_embedding_index": 17551, "title_abs_embedding_index": 17576}, {"title": "Multi Task Inverse Reinforcement Learning for Common Sense Reward", "link_suffix": "/forum?id=xvUVk9T3kZ", "link": "https://openreview.net/forum?id=xvUVk9T3kZ", "pdf_link": "https://openreview.net/pdf?id=xvUVk9T3kZ", "keywords": "multi task learning, reinforcement learning", "abstract": "One of the challenges in applying reinforcement learning in a complex real-world environment lies in providing the agent with a sufficiently detailed reward function. Any misalignment between the reward and the desired behavior can result in unwanted outcomes. This may lead to issues like \"reward hacking\" where the agent maximizes rewards by unintended behavior. In this work, we propose to disentangle the reward into two distinct parts. A simple task-specific reward, outlining the particulars of the task at hand, and an unknown common-sense reward, indicating the expected behavior of the agent within the environment. We then explore how this common-sense reward can be learned from expert demonstrations. We first show that inverse reinforcement learning, even when it succeeds in training an agent, does not learn a useful reward function. That is, training a new agent with the learned reward does not impair the desired behaviors. We then demonstrate that this problem can be solved by training simultaneously on multiple tasks. That is, multi-task inverse reinforcement learning can  learn a useful reward function.", "title_embedding_index": 17552, "title_abs_embedding_index": 17577}, {"title": "HiLoRA: High-frequency-augmented Low-Rank Adaptation", "link_suffix": "/forum?id=DOHsYZrrny", "link": "https://openreview.net/forum?id=DOHsYZrrny", "pdf_link": "https://openreview.net/pdf?id=DOHsYZrrny", "keywords": "Large Language Models, LoRA, Frequency, Catastrophic Forgetting", "abstract": "As large language models (LLMs) have demonstrated remarkable performance, parameter-efficient fine-tuning (PEFT) has emerged as an important paradigm. As a solution, low-rank adaptation (LoRA) freezes the pre-trained weights and introduces small learnable adapters instead of fine-tuning the full set of parameters. However, LoRA suffers from $\\textit{catastrophic forgetting}$, where pre-trained knowledge is overwhlemed and forgotten as new information is learned. One cause of this issue is $\\textit{implicit regularization}$, where deep learning models tend to favor more generalized solutions. This tendency leads to a significant increase in the largest singular values of the weights, which correspond to low-frequency components. To address this problem, we propose an advanced LoRA that balances the retention of pre-trained knowledge with the learning of new information. Since fine-tuning involves learning fine-grained details, which correspond to high-frequency information, we designed HiLoRA, a method that injects learnable high-frequency components into the pre-trained model. By leveraging the parameterized SVD and constraining singular values to appropriate levels, HiLoRA adapts to new tasks by focusing on the high-frequency domain with minimal change from the pre-trained weights. To evaluate the effectiveness of HiLoRA, we conduct extensive experiments on natural language understanding and question answering tasks. The results show that HiLoRA not only improves performance but also effectively retains pre-trained knowledge compared to baseline models.", "title_embedding_index": 17553, "title_abs_embedding_index": 17578}, {"title": "Composing Novel Classes: A Concept-Driven Approach to Generalized Category Discovery", "link_suffix": "/forum?id=qrTOtUdz4Z", "link": "https://openreview.net/forum?id=qrTOtUdz4Z", "pdf_link": "https://openreview.net/pdf?id=qrTOtUdz4Z", "keywords": "generalized category discovery; self-supervised learning; knowledge transfer; knowledge distillation; unsupervised learning;", "abstract": "We tackle the generalized category discovery (GCD) problem, which aims to discover novel classes in unlabeled datasets by leveraging the knowledge of known classes. Previous works utilize the known class knowledge through shared representation spaces. Despite their progress, our analysis experiments show that novel classes can achieve impressive clustering results on the feature space of a known class pre-trained model, suggesting that existing methods may not fully utilize known class knowledge. To address it, we introduce a novel concept learning framework for GCD, named ConceptGCD, that categorizes concepts into two types: derivable and underivable from known class concepts, and adopts a stage-wise learning strategy to learn them separately. Specifically, our framework first extracts known class concepts by a known class pre-trained model and then produces derivable concepts from them by a generator layer with a covariance-augmented loss. Subsequently, we expand the generator layer to learn underivable concepts in a balanced manner ensured by a concept score normalization strategy and integrate a contrastive loss to preserve previously learned concepts. Extensive experiments on various benchmark datasets demonstrate the superiority of our approach over the previous state-of-the-art methods.", "title_embedding_index": 17554, "title_abs_embedding_index": 17579}, {"title": "Simulating Human-like Daily Activities with Desire-driven Autonomy", "link_suffix": "/forum?id=3ms8EQY7f8", "link": "https://openreview.net/forum?id=3ms8EQY7f8", "pdf_link": "https://openreview.net/pdf?id=3ms8EQY7f8", "keywords": "desire;autonomy;daily activities;", "abstract": "Existing task-oriented AI agents often depend on explicit instructions or external rewards, limiting their ability to be driven by intrinsic motivations like humans. In this paper, we present a desire-driven autonomy framework to guide a Large Language Model based (LLM-based) agent to simulate human-like daily activities. In contrast to previous agents, our Desire-driven Autonomous Agent (D2A) operates on the principle of intrinsic desire, allowing it to propose and select tasks that fulfill its motivational framework autonomously. Inspired by the Theory of Needs from Maslow. A.H., the motivational framework incorporates an understanding of human-like desires, such as the need for social interaction, personal fulfillment, and self-care. Utilizing a desire-driven task generation mechanism, the agent evaluates its current state and takes a sequence of activities aligned with its intrinsic motivations. Through simulations, we demonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent, contextually relevant daily activities while exhibiting variability and adaptability similar to human behavior. A comparative analysis with other LLM-based frameworks demonstrates that our approach significantly enhances the rationality of the simulated activities.", "title_embedding_index": 17555, "title_abs_embedding_index": 17580}, {"title": "Reshaping Reservoirs: Hebbian Plasticity for Improved Data Separability", "link_suffix": "/forum?id=aOBYawUuWL", "link": "https://openreview.net/forum?id=aOBYawUuWL", "pdf_link": "https://openreview.net/pdf?id=aOBYawUuWL", "keywords": "bio-inspired, hebian plasticity, echo states network, unsupervised learning, time series", "abstract": "This paper introduces Hebbian Architecture Generation (HAG), a method grounded in Hebbian plasticity principles, designed to optimize the structure of Reservoir Computing networks. HAG adapts the synaptic weights in Recurrent Neural Networks by dynamically forming connections between neurons that exhibit high Pearson correlation. Unlike conventional reservoir computing models that rely on static, randomly initialized connectivity matrices, HAG tailors the reservoir architecture to specific tasks by autonomously optimizing network properties such as signal decorrelation and eigenvalue spread. This task-specific adaptability enhances the linear separability of input data, as supported by Cover\u2019s theorem, which posits that increasing the dimensionality of the feature space improves pattern recognition. Experimental results show that HAG outperforms traditional Echo State Networks across various predictive modeling and pattern recognition benchmarks. By aligning with biological principles of structural plasticity, HAG addresses limitations of static reservoir architectures, offering a biologically plausible and highly adaptable alternative for improved performance in dynamic learning environments.", "title_embedding_index": 17556, "title_abs_embedding_index": 17581}, {"title": "Closed-Loop Long-Horizon Robotic Planning via Equilibrium Sequence Modeling", "link_suffix": "/forum?id=VoZ0nSy0Ry", "link": "https://openreview.net/forum?id=VoZ0nSy0Ry", "pdf_link": "https://openreview.net/pdf?id=VoZ0nSy0Ry", "keywords": "Deep Equilibrium Models, Large Language Models, Robot Task Planning", "abstract": "In the endeavor to make autonomous robots take actions, task planning is a major challenge that requires translating high-level task descriptions into long-horizon action sequences. Despite recent advances in language model agents, they remain prone to planning errors and limited in their ability to plan ahead. To address these limitations in robotic planning, we advocate a self-refining scheme that iteratively refines a draft plan until an equilibrium is reached. Remarkably, this process can be optimized end-to-end from an analytical perspective without the need to curate additional verifiers or reward models, allowing us to train self-refining planners in a simple supervised learning fashion. Meanwhile, a nested equilibrium sequence modeling procedure is devised for efficient closed-loop planning that incorporates useful feedback from the environment (or an internal world model). Our method is evaluated on the VirtualHome-Env benchmark, showing advanced performance with better scaling for inference computation. Code is available athttps://github.com/anonymous-iclr-2025/equilibrium-planner.", "title_embedding_index": 17557, "title_abs_embedding_index": 17582}, {"title": "Ctrl-U: Robust Conditional Image Generation via Uncertainty-aware Reward Modeling", "link_suffix": "/forum?id=eC2ICbECNM", "link": "https://openreview.net/forum?id=eC2ICbECNM", "pdf_link": "https://openreview.net/pdf?id=eC2ICbECNM", "keywords": "Conditional generation, semantic alignment, uncertainty learning", "abstract": "In this paper, we focus on the task of conditional image generation, where an image is synthesized according to user instructions. The critical challenge underpinning this task is ensuring both the fidelity of the generated images and their semantic alignment with the provided conditions. To tackle this issue, previous studies have employed supervised perceptual losses derived from pre-trained models, i.e., reward models, to enforce alignment between the condition and the generated result. However, we observe one inherent shortcoming: considering the diversity of synthesized images, the reward model usually provides inaccurate feedback when encountering newly generated data, which can undermine the training process. To address this limitation, we propose an uncertainty-aware reward modeling, called Ctrl-U, including uncertainty estimation and uncertainty-aware regularization, designed to reduce the adverse effects of imprecise feedback from the reward model. Given the inherent cognitive uncertainty within reward models, even images generated under identical conditions often result in a relatively large discrepancy in reward loss. Inspired by the observation, we explicitly leverage such prediction variance as an uncertainty indicator. Based on the uncertainty estimation, we regularize the model training by adaptively rectifying the reward. In particular, rewards with lower uncertainty receive higher loss weights, while those with higher uncertainty are given reduced weights to allow for larger variability. The proposed uncertainty regularization facilitates reward fine-tuning through consistency construction. Extensive experiments validate the effectiveness of our methodology in improving the controllability and generation quality, as well as its scalability across diverse conditional scenarios, including segmentation mask, edge, and depth conditions.", "title_embedding_index": 17558, "title_abs_embedding_index": 17583}, {"title": "Gradient correlation is needed to accelerate SGD with momentum", "link_suffix": "/forum?id=2Q8gTck8Uq", "link": "https://openreview.net/forum?id=2Q8gTck8Uq", "pdf_link": "https://openreview.net/pdf?id=2Q8gTck8Uq", "keywords": "optimization, convex, nesterov momentum, sgd, neural network", "abstract": "Empirically, it has been observed that adding momentum to Stochastic Gradient Descent (SGD) accelerates the convergence of the algorithm.\nHowever, the literature has been rather pessimistic, even in the case of convex functions, about the possibility of theoretically proving this observation.\nWe investigate the possibility of obtaining accelerated convergence of the Stochastic Nesterov Accelerated Gradient (SNAG), a momentum-based version of SGD, when minimizing a sum of functions in a convex setting. \nWe demonstrate that the average correlation between gradients allows to verify the strong growth condition, which is the key ingredient to obtain acceleration with SNAG.\nNumerical experiments, both in linear regression and deep neural network optimization, confirm in practice our theoretical results.", "title_embedding_index": 17559, "title_abs_embedding_index": 17584}, {"title": "Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing", "link_suffix": "/forum?id=INFfvQArFY", "link": "https://openreview.net/forum?id=INFfvQArFY", "pdf_link": "https://openreview.net/pdf?id=INFfvQArFY", "keywords": "Knowledge Editing", "abstract": "The locate-then-edit paradigm has shown significant promise for knowledge editing (KE) in Large Language Models (LLMs). While previous methods perform well on single-hop fact recall tasks, they consistently struggle with multi-hop factual recall tasks involving newly edited knowledge. In this paper, leveraging tools in mechanistic interpretability, we first identify that in multi-hop tasks, LLMs tend to retrieve implicit subject knowledge from deeper MLP layers, unlike single-hop tasks, which rely on earlier layers. This distinction explains the poor performance of current methods in multi-hop queries, as they primarily focus on editing shallow layers, leaving deeper layers unchanged. To address this, we propose IFMET, a novel locate-then-edit KE approach designed to edit both shallow and deep MLP layers. IFMET employs multi-hop editing prompts and supplementary sets to locate and modify knowledge across different reasoning stages. Experimental results demonstrate that IFMET significantly improves performance on multi-hop factual recall tasks, effectively overcoming the limitations of previous locate-then-edit methods.", "title_embedding_index": 17560, "title_abs_embedding_index": 17585}, {"title": "Multiplicative Logit Adjustment Approximates Neural-Collapse-Aware Decision Boundary Adjustment", "link_suffix": "/forum?id=II81zQUS1x", "link": "https://openreview.net/forum?id=II81zQUS1x", "pdf_link": "https://openreview.net/pdf?id=II81zQUS1x", "keywords": "long-tailed recognition, imbalanced learning, neural collapse, logit adjustment, multiplicative logit adjustment, machine learning, learning theory", "abstract": "Real-world data distributions are often highly skewed. This has spurred a growing body of research on long-tailed recognition, aimed at addressing the imbalance in training classification models. Among the methods studied, multiplicative logit adjustment (MLA) stands out as a simple and effective method. What theoretical foundation explains the effectiveness of this heuristic method?\nWe provide a justification for the effectiveness of MLA with the following two-step process. First, we develop a theory that adjusts optimal decision boundaries by estimating feature spread on the basis of neural collapse. Second, we demonstrate that MLA approximates this optimal method. Additionally, through experiments on long-tailed datasets, we illustrate the practical usefulness of MLA under more realistic conditions. We also offer experimental insights to guide the tuning of MLA hyperparameters.", "title_embedding_index": 17561, "title_abs_embedding_index": 17586}, {"title": "Pyramidal Flow Matching for Efficient Video Generative Modeling", "link_suffix": "/forum?id=66NzcRQuOq", "link": "https://openreview.net/forum?id=66NzcRQuOq", "pdf_link": "https://openreview.net/pdf?id=66NzcRQuOq", "keywords": "Generative Model, Flow Matching, Video Generation", "abstract": "Video generation requires modeling a vast spatiotemporal space, which demands significant computational resources and data usage. To reduce the complexity, the prevailing approaches employ a cascaded architecture to avoid direct training with full resolution. Despite reducing computational demands, the separate optimization of each sub-stage hinders knowledge sharing and sacrifices flexibility. This work introduces a unified pyramidal flow matching algorithm. It reinterprets the original denoising trajectory as a series of pyramid stages, where only the final stage operates at the full resolution, thereby enabling more efficient video generative modeling. Through our sophisticated design, the flows of different pyramid stages can be interlinked to maintain continuity. Moreover, we craft autoregressive video generation with a temporal pyramid to compress the full-resolution history. The entire framework can be optimized in an end-to-end manner and with a single unified Diffusion Transformer (DiT). Extensive experiments demonstrate that our method supports generating high-quality 5-second (up to 10-second) videos at 768p resolution and 24 FPS within 20.7k A100 GPU training hours. All the training and inference code and model weights will be open-sourced. Project page:https://anonymous-pyramid-flow.github.io.", "title_embedding_index": 17562, "title_abs_embedding_index": 17587}, {"title": "CtrLoRA: An Extensible and Efficient Framework for Controllable Image Generation", "link_suffix": "/forum?id=3Gga05Jdmj", "link": "https://openreview.net/forum?id=3Gga05Jdmj", "pdf_link": "https://openreview.net/pdf?id=3Gga05Jdmj", "keywords": "Controllable Image Generation, Image-to-Image Generation, ControlNet, LoRA, Resource-Efficient Adaptation", "abstract": "Recently, large-scale diffusion models have made impressive progress in text-to-image (T2I) generation. To further equip these T2I models with fine-grained spatial control, approaches like ControlNet introduce an extra network that learns to follow a condition image. However, for every single condition type, ControlNet requires independent training on millions of data pairs with hundreds of GPU hours, which is quite expensive and makes it challenging for ordinary users to explore and develop new types of conditions. To address this problem, we propose the CtrLoRA framework, which trains a Base ControlNet to learn the common knowledge of image-to-image generation from multiple base conditions, along with condition-specific LoRAs to capture distinct characteristics of each condition. Utilizing our pretrained Base ControlNet, users can easily adapt it to new conditions, requiring as few as 1,000 data pairs and less than one hour of single-GPU training to obtain satisfactory results in most scenarios. Moreover, our CtrLoRA reduces the learnable parameters by 90% compared to ControlNet, significantly lowering the threshold to distribute and deploy the model weights. Extensive experiments on various types of conditions demonstrate the efficiency and effectiveness of our method. All codes and model weights will be publicly available.", "title_embedding_index": 17563, "title_abs_embedding_index": 17588}, {"title": "Efficient Gradient-Based Algorithm for Training Deep Learning Models With Many Nonlinear Activations", "link_suffix": "/forum?id=gQPwP1JFwC", "link": "https://openreview.net/forum?id=gQPwP1JFwC", "pdf_link": "https://openreview.net/pdf?id=gQPwP1JFwC", "keywords": "deep learning, optimization, deep learning theory, deep neural network", "abstract": "This research paper presents a novel algorithm for training deep neural networks with many nonlinear layers (e.g., 30). The method is based on backpropagation of an approximated gradient, averaged over the range of a weight update. Unlike the gradient, the average gradient of a loss function is proven within this research to provide more accurate information on the change in loss caused by the associated parameter update of a model. Therefore, it may be utilized to improve learning. In our implementation, the efficiently approximated average gradient is paired with RMSProp and compared to the typical gradient-based approach. For the tested deep model with many nonlinear layers on MNIST and Fashion MNIST, the presented algorithm: $\\quad$(a) generalizes better, at least in a reasonable epoch count,   $\\quad$(b) in the case of optimal implementation, learning would require less computation time than the gradient-based RMSProp, with the memory requirement of the Adam optimizer,  $\\quad$ (c) performs well on a broader range of learning rates, therefore it may bring time and energy savings from reduced hyperparameter searches,   $\\quad$(d) improves sample efficiency about three times according to median training losses. However, in the case of the tested shallow model, the method performs approximately the same as the gradient-based RMSProp in terms of both training and test loss. The source code is provided at [...].", "title_embedding_index": 17564, "title_abs_embedding_index": 17589}, {"title": "Efficiently Learning Probabilistic Logical Models by Cheaply Ranking Mined Rules", "link_suffix": "/forum?id=Ns6fnLFsCZ", "link": "https://openreview.net/forum?id=Ns6fnLFsCZ", "pdf_link": "https://openreview.net/pdf?id=Ns6fnLFsCZ", "keywords": "Structure Learning, Probabilistic Logical Models, MLN, PSL, Knowledge Graph Reasoning, Neurosymbolic", "abstract": "Probabilistic logical models are a core component of neurosymbolic AI and are important models in their own right for tasks that require high explainability. Unlike neural networks, logical models are often handcrafted using domain expertise, making their development costly and prone to errors. While there are algorithms that learn logical models from data, they are generally prohibitively expensive, limiting their applicability in real-world settings. In this work, we introduce precision and recall for logical rules and define their composition as rule utility -- a cost-effective measure to evaluate the predictive power of logical models. Further, we introduce SPECTRUM, a scalable framework for learning logical models from relational data. Its scalability derives from a linear-time algorithm that mines recurrent structures in the data along with a second algorithm that, using the cheap utility measure, efficiently ranks rules built from these structures. Moreover, we derive theoretical guarantees on the utility of the learnt logical model. As a result, we demonstrate across various tasks that SPECTRUM scales to larger datasets, often learning more accurate logical models orders of magnitude faster than previous methods without requiring specialised GPU hardware.", "title_embedding_index": 17565, "title_abs_embedding_index": 17590}, {"title": "Dominant Shuffle: An Incredibly Simple but Exceptionally Effective Data Augmentation Method for Time-Series Prediction", "link_suffix": "/forum?id=QWMCaEfoR7", "link": "https://openreview.net/forum?id=QWMCaEfoR7", "pdf_link": "https://openreview.net/pdf?id=QWMCaEfoR7", "keywords": "time series prediction, data augmentation, deep learning", "abstract": "Frequency-domain data augmentation (DA) has shown strong performance in time-series prediction due to its ability to preserve data-label consistency. However, we observed that existing frequency-domain augmentations introduce excessive variability, leading to out-of-distribution samples that may be harmful to model performance. To address this, we introduced two simple modifications to frequency-domain DA. First, we limit perturbations to dominant frequencies with larger magnitudes, which capture the main periodicities and trends of the signal. Second, instead of using complicated random perturbations, we simply shuffle the dominant frequency components, which preserves the original structure while avoiding external noise. With the two simple modifications, we proposed dominant shuffle\u2014a simple yet highly effective data augmentation technique for time-series prediction. Our method is remarkably simple, requiring only a few lines of code, yet exceptionally effective, consistently and significantly improving model performance. Extensive experiments on short-term, long term, few-shot and cold-start prediction tasks with eight state-of-the-art models, nine existing augmentation methods and twelve datasets demonstrate that dominant shuffle consistently boosts model performance with substantial gains, outperforming existing augmentation techniques.", "title_embedding_index": 17566, "title_abs_embedding_index": 17591}, {"title": "Data-driven plasma equilibrium forecasting in magnetic fusion tokamak", "link_suffix": "/forum?id=GpcqrBh6G8", "link": "https://openreview.net/forum?id=GpcqrBh6G8", "pdf_link": "https://openreview.net/pdf?id=GpcqrBh6G8", "keywords": "nuclear fusion, plasma equilibrium, tokamak, video prediction", "abstract": "The most promising approach to achieving nuclear fusion is through tokamaks, which confine plasma using magnetic fields.\nUnderstanding the current plasma equilibrium state in tokamaks is critical for effective plasma control.\nUnlike previous studies, which reconstruct equilibrium from magnetic field information, our work forecasts future equilibrium based on past equilibrium states.\nSpecifically, we formulate the plasma equilibrium prediction task as a video prediction task, a well-explored problem in the machine learning community.\nThis formulation allows us to capture the spatio-temporal dynamics of plasma states and provides a foundation for multimodal modeling of data streams from tokamak operations.\nOur methodology, incorporating a physics-inspired learning technique for physically reliable predictions, achieved plausible results in forecasting future plasma equilibrium up to 200 ms ahead compared to baselines.\nThis approach holds promise for predicting plasma instabilities and preventing disruptions, marking a significant step towards developing stable fusion reactors.", "title_embedding_index": 17567, "title_abs_embedding_index": 17592}, {"title": "Fast Summation of Radial Kernels via QMC Slicing", "link_suffix": "/forum?id=iNmVX9lx9l", "link": "https://openreview.net/forum?id=iNmVX9lx9l", "pdf_link": "https://openreview.net/pdf?id=iNmVX9lx9l", "keywords": "fast kernel summation, slicing, quasi-Monte Carlo, non-equispaced fast Fourier transforms, random Fourier features", "abstract": "The fast computation of large kernel sums is a challenging task, which arises as a subproblem in any kernel method. We approach the problem by slicing,  which relies on random projections to one-dimensional subspaces and fast Fourier summation. We prove bounds for the slicing error and propose a quasi-Monte Carlo (QMC) approach for selecting the projections based on spherical quadrature rules. Numerical examples demonstrate that our QMC-slicing approach significantly outperforms existing methods like (QMC-)random Fourier features, orthogonal Fourier features or non-QMC slicing  on standard test datasets.", "title_embedding_index": 17568, "title_abs_embedding_index": 17593}, {"title": "Stealix: Model Stealing via Prompt Evolution", "link_suffix": "/forum?id=kvN8MJTOCM", "link": "https://openreview.net/forum?id=kvN8MJTOCM", "pdf_link": "https://openreview.net/pdf?id=kvN8MJTOCM", "keywords": "model stealing, security, genetic algorithm, prompt optimization", "abstract": "Model stealing poses a significant security risk in machine learning by enabling attackers to replicate a black-box model without access to its training data, thus jeopardizing intellectual property and exposing sensitive information.\nRecent methods that use pre-trained diffusion models for data synthesis improve efficiency and performance but rely heavily on manually crafted prompts, limiting automation and scalability, especially for attackers with little expertise.\nTo assess the risks posed by open-source pre-trained models, we propose a more realistic threat model that eliminates the need for prompt design skills or knowledge of class names.\nIn this context, we introduce Stealix, the first approach to perform model stealing without predefined prompts. Stealix uses two open-source pre-trained models to infer the victim model\u2019s data distribution, and iteratively refines prompts through a genetic algorithm based on a proxy metric, progressively improving the precision and diversity of synthetic images.\nOur experimental results demonstrate that Stealix significantly outperforms other methods, even those with access to class names or fine-grained prompts, while operating under the same query budget. These findings highlight the scalability of our approach and suggest that the risks posed by pre-trained generative models in model stealing may be greater than previously recognized.", "title_embedding_index": 17569, "title_abs_embedding_index": 17594}, {"title": "Chain-of-thoughts for molecular understanding", "link_suffix": "/forum?id=Yufi9fWhj9", "link": "https://openreview.net/forum?id=Yufi9fWhj9", "pdf_link": "https://openreview.net/pdf?id=Yufi9fWhj9", "keywords": "Large language model, chain-of-thought", "abstract": "The adaptation of large language models (LLMs) to chemistry have shown promising performance in molecular understanding tasks, such as generating a text description from a molecule. However, proper reasoning based on molecular structural information remains a significant challenge, e.g., even advanced LLMs such as GPT-4o struggle to identify functional groups which are crucial for inferring the molecular property of interest. To address this limitation, we propose StructCoT, a structure-aware chain-of-thought (CoT) that enhances LLMs\u2019 understanding of molecular structures by explicitly injecting the key structural features of molecules. Moreover, we introduce two fine-tuning frameworks for adapting the existing LLMs to use our StructCoT. Our experiments demonstrate that incorporating \\Algname with our fine-tuning frameworks leads to consistent improvements in both molecular understanding tasks.", "title_embedding_index": 17570, "title_abs_embedding_index": 17595}, {"title": "Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning", "link_suffix": "/forum?id=3wEGdrV5Cb", "link": "https://openreview.net/forum?id=3wEGdrV5Cb", "pdf_link": "https://openreview.net/pdf?id=3wEGdrV5Cb", "keywords": "Federated Learning; Federated Domain Adaptation; Federated Fine-Tuning", "abstract": "Federated Domain Adaptation (FDA) is a Federated Learning (FL) scenario where models are trained across multiple clients with unique data domains but a shared category space, without transmitting private data. The primary challenge in FDA is data heterogeneity, which causes significant divergences in gradient updates when using conventional averaging-based aggregation methods, reducing the efficacy of the global model. This further undermines both in-domain and out-of-domain performance (within the same federated system but outside the local client), which is critical in certain business applications. To address this, we propose a novel framework called \\textbf{M}ulti-domain \\textbf{P}rototype-based \\textbf{F}ederated Fine-\\textbf{T}uning (MPFT). MPFT fine-tunes a pre-trained model using multi-domain prototypes, i.e., several pretrained representations enriched with domain-specific information from category-specific local data. This enables supervised learning on the server to create a globally optimized adapter that is subsequently distributed to local clients, without the intrusion of data privacy. Empirical results show that MPFT significantly improves both in-domain and out-of-domain accuracy over conventional methods, enhancing knowledge preservation and adaptation in FDA. Notably, MPFT achieves convergence within a single communication round, greatly reducing computation and communication costs. To ensure privacy, MPFT applies differential privacy to protect the prototypes. Additionally, we develop a prototype-based feature space hijacking attack to evaluate robustness, confirming that raw data samples remain unrecoverable even after extensive training epochs. The complete implementation of MPFL is available at \\url{https://anonymous.4open.science/r/DomainFL/}.", "title_embedding_index": 17571, "title_abs_embedding_index": 17596}, {"title": "Generalization Guarantees for Representation Learning via Data-Dependent Gaussian Mixture Priors", "link_suffix": "/forum?id=fGdF8Bq1FV", "link": "https://openreview.net/forum?id=fGdF8Bq1FV", "pdf_link": "https://openreview.net/pdf?id=fGdF8Bq1FV", "keywords": "Representation learning algorithm, Gaussian-Mixture, regularizer, rate-disotortion", "abstract": "We establish in-expectation and tail bounds on the generalization error of representation learning type algorithms. The bounds are in terms of the relative entropy between the distribution of the representations extracted from the training and \"test'' datasets and a data-dependent symmetric prior, i.e., the Minimum Description Length (MDL) of the latent variables for the training and test datasets. Our bounds are shown to reflect the \"structure'' and \"simplicity'' of the encoder and significantly improve upon the few existing ones for the studied model. We then use our in-expectation bound to devise a suitable data-dependent regularizer; and we investigate thoroughly the important question of the selection of the prior. We propose a systematic approach to simultaneously learning a date-dependent Gaussian mixture prior and using it as a regularizer. Interestingly, we show that a weighted attention mechanism emerges naturally in this procedure. Our experiments show that our approach outperforms the now popular Variational Information Bottleneck (VIB) method as well as the recent Category-Dependent VIB (CDVIB).", "title_embedding_index": 17572, "title_abs_embedding_index": 17597}, {"title": "DiffPath: Generating Road Network based Path with Latent Diffusion Model", "link_suffix": "/forum?id=1o3fKLQPRA", "link": "https://openreview.net/forum?id=1o3fKLQPRA", "pdf_link": "https://openreview.net/pdf?id=1o3fKLQPRA", "keywords": "Path Generation, Latent Diffusion Model, Path Distribution, Long-range Dependencies", "abstract": "With the increasing use of GPS technology, path has become essential for applications such as navigation, urban planning, and traffic optimization. However, obtaining real-world path presents challenges due to privacy concerns and the difficulty of collecting large datasets. Existing methods, including count-based and deep learning approaches, struggle with two main challenges: handling complex distributions of path segments and ensuring global coherence in generated paths. To address these, we introduce DiffPath, a path generation model based on Latent Diffusion Models (LDMs). By embedding path into a continuous latent space and leveraging a transformer architecture, DiffPath captures both local transitions and global dependencies, ensuring the generation of realistic paths. Experimental results demonstrate that our model outperforms existing approaches in generating paths that adhere to real-world road network structures while maintaining privacy.", "title_embedding_index": 17573, "title_abs_embedding_index": 17598}, {"title": "NEAR: A Training-Free Pre-Estimator of Machine Learning Model Performance", "link_suffix": "/forum?id=Z8RZrvngm5", "link": "https://openreview.net/forum?id=Z8RZrvngm5", "pdf_link": "https://openreview.net/pdf?id=Z8RZrvngm5", "keywords": "Network Expressivity by Activation Rank (NEAR), Effective Rank, Neural Architecture Search", "abstract": "Artificial neural networks have been shown to be state-of-the-art machine learning models in a wide variety of applications, including natural language processing and image recognition. However, building a performant neural network is a laborious task and requires substantial computing power. Neural Architecture Search (NAS) addresses this issue by an automatic selection of the optimal network from a set of potential candidates. While many NAS methods still require training of (some) neural networks, zero-cost proxies promise to identify the optimal network without training. In this work, we propose the zero-cost proxy Network Expressivity by Activation Rank (NEAR). It is based on the effective rank of the pre- and post-activation matrix, i.e., the values of a neural network layer before and after applying its activation function. We demonstrate the cutting-edge correlation between this network score and the model accuracy on NAS-Bench-101 and NATS-Bench-SSS/TSS. In addition, we present a simple approach to estimate the optimal layer sizes in multi-layer perceptrons. Furthermore, we show that this score can be utilized to select hyperparameters such as the activation function and the neural network weight initialization scheme.", "title_embedding_index": 17574, "title_abs_embedding_index": 17599}]
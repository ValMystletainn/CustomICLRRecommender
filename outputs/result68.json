[
    {
        "title": "Instruct-SkillMix: A Powerful Pipeline for LLM Instruction Tuning",
        "link_suffix": "/forum?id=44z7HL4mfX",
        "link": "https://openreview.net/forum?id=44z7HL4mfX",
        "pdf_link": "https://openreview.net/pdf?id=44z7HL4mfX",
        "keywords": "instruction tuning, high quality synthetic data, diverse synthetic data",
        "abstract": "We introduce INSTRUCT-SKILLMIX, an automated approach for creating diverse, high quality SFT data for instruction-following. The pipeline involves two stages, each leveraging an existing powerful LLM: (1) Skill extraction: uses the LLM to extract core “skills” for instruction-following by directly prompting the model. This is inspired by “LLM metacognition” of (Didolkar et al., 2024); (2) Data generation: uses the powerful LLM to generate (instruction, response) data that\nexhibit a randomly chosen pair of these skills. Here, the use of random skill combinations promotes diversity and difficulty. The estimated cost of creating the dataset is under $600.Vanilla SFT (i.e., no PPO, DPO, or RL methods) on data generated from INSTRUCT-SKILLMIX leads to strong gains on instruction following benchmarks such as AlpacaEval 2.0, MT-Bench, and WildBench. With just 4K examples, LLaMA-3-8B-Base achieves 42.76% length-controlled win rate on AlpacaEval 2.0, a level similar to frontier models like Claude 3 Opus and LLaMA-3.1-405B-Instruct. Ablation studies also suggest plausible reasons for why creating open instruction-tuning datasets via naive crowd-sourcing has proved difficult. In our dataset,adding 20% low quality answers (“shirkers”) causes a noticeable degradation in performance.The INSTRUCT-SKILLMIX pipeline seems flexible and adaptable to other settings."
    },
    {
        "title": "On the Limitation and Redundancy of Transformers: A Rank Perspective",
        "link_suffix": "/forum?id=0sary0UZn5",
        "link": "https://openreview.net/forum?id=0sary0UZn5",
        "pdf_link": "https://openreview.net/pdf?id=0sary0UZn5",
        "keywords": "Transformers, self-attention, low-rank, redundancy, model reduction",
        "abstract": "Transformers have showcased superior performances across a variety of real-world applications, particularly leading to unparalleled successes of large “foundation” models. \nHowever, since these models are usually trained on web-scale datasets, the overall computation and memory loads are considerably increasing, calling for moreefficientmethods in machine learning. \nIn this work, we step towards this direction by exploring the architectural limitation and redundancy of Transformers via investigating the ranks of attention score matrices. \nOn one hand, extensive experiments are conducted on various model configurations (model dimensions, heads, layers, etc) and data distributions (both synthetic and real-world datasets with varied sequence lengths), uncovering two key properties: \nalthough the attention rank increases with the head dimension $d_h$, as expected, the rank is eventually upper bounded (limitation) and gets saturated (redundancy). We call them thelow-rank barrierandmodel-reduction effect, respectively. \nOn the other hand, we provide rigorous demonstrations for these observations through a fine-grained mathematical analysis, highlighting (i) a consistent theoretical upper bound ($\\approx 0.63n$, $n$: the sequence length) of the attention rank regardless of the head dimension $d_h$, and (ii) a critical position of the rank saturation ($d_h=\\Omega(\\log n)$).\nThese results shed light on the inductive biases and internal dynamics of Transformers, contributing to the theoretical understanding and assessment of the model capacity and efficiency in practical applications."
    },
    {
        "title": "PEDVLM: PEDESTRIAN VISION LANGUAGE MODEL FOR INTENTIONS PREDICTION",
        "link_suffix": "/forum?id=RAX45dcfA2",
        "link": "https://openreview.net/forum?id=RAX45dcfA2",
        "pdf_link": "https://openreview.net/pdf?id=RAX45dcfA2",
        "keywords": "Pedestrian Intention Prediction, Vision Language Model, Autonomous Vehicle",
        "abstract": "Effective modeling of human behavior is crucial for the safe and reliable coexistence of humans and autonomous vehicles. Traditional deep learning methods have limitations in capturing the complexities of pedestrian behavior, often relying on simplistic representations or indirect inference from visual cues, which hinders their explainability. To address this gap, we introduce $\\textbf{PedVLM}$, a vision-language model that leverages multiple modalities (RGB images, optical flow, and text) to predict pedestrian intentions and also provide explainability for pedestrian behavior. PedVLM comprises a CLIP-based vision encoder and a text-to-text transfer transformer (T5) language model, which together extract and combine visual and text embeddings to predict pedestrian actions and enhance explainability. Furthermore, to complement our PedVLM model and further facilitate research, we also publicly release the corresponding dataset, PedPrompt, which includes the prompts in the Question-Answer (QA) template for pedestrian intention prediction.  PedVLM is evaluated on PedPrompt, JAAD, and PIE datasets demonstrates its efficacy compared to state-of-the-art methods. The dataset and code will be made available at {https://github.com/abc/ped_VLM}."
    },
    {
        "title": "Improving Inverse Folding for Peptide Design with Diversity-Regularized Direct Preference Optimization",
        "link_suffix": "/forum?id=VY96NfQRIo",
        "link": "https://openreview.net/forum?id=VY96NfQRIo",
        "pdf_link": "https://openreview.net/pdf?id=VY96NfQRIo",
        "keywords": "Inverse Folding, Structure-based design, Peptide Design, Direct Preference Optimization",
        "abstract": "Inverse folding models play an important role in structure-based design by predicting amino acid sequences that fold into desired reference structures. Models like ProteinMPNN, a message-passing encoder-decoder model, are trained to reliably produce new sequences from a reference structure. However, when applied to peptides, these models are prone to generating repetitive sequences that do not fold into the reference structure.  To address this, we finetune ProteinMPNN to produce diverse and structurally consistent peptide sequences via Direct Preference Optimization (DPO). We derive two enhancements to DPO: online diversity regularization and domain-specific priors.Additionally, we develop a new understanding on improving diversity in decoder models. When conditioned on OpenFold generated structures, our finetuned models achieve state-of-the-art structural similarity scores, improving base ProteinMPNN by at least 8%. Compared to standard DPO, our regularized method achieves up to 20% higher sequence diversity with no loss in structural similarity score."
    },
    {
        "title": "Multimodal Structure Preservation Learning",
        "link_suffix": "/forum?id=AAZ3vwyQ4X",
        "link": "https://openreview.net/forum?id=AAZ3vwyQ4X",
        "pdf_link": "https://openreview.net/pdf?id=AAZ3vwyQ4X",
        "keywords": "multimodal machine learning, structure preservation learning, modality gap",
        "abstract": "When selecting data to build machine learning models in practical applications, factors such as availability, acquisition cost, and discriminatory power are crucial considerations. Different data modalities often capture unique aspects of the underlying phenomenon, making their utilities complementary. On the other hand, some sources of data host structural information that is key to their value. Hence, the utility of one data type can sometimes be enhanced by matching the structure of another. We propose Multimodal Structure Preservation Learning (MSPL) as a novel method of learning data representations that leverages the clustering structure provided by one data modality to enhance the utility of data from another modality. We demonstrate the effectiveness of MSPL in uncovering latent structures in synthetic time series data and recovering clusters from whole genome sequencing and antimicrobial resistance data using mass spectrometry data in support of epidemiology applications. The results show that MSPL can imbue the learned features with external structures and help reap the beneficial synergies occurring across disparate data modalities."
    },
    {
        "title": "Building Generalist Robot Policy from Pre-trained Visual Representations",
        "link_suffix": "/forum?id=9GKMCecZ7c",
        "link": "https://openreview.net/forum?id=9GKMCecZ7c",
        "pdf_link": "https://openreview.net/pdf?id=9GKMCecZ7c",
        "keywords": "robot learning, pre-trained vision models, generalizability",
        "abstract": "In this paper, we investigate the use of vision pre-trained models (PTMs) for developing generalist robot manipulation policies. We study whether embodied policies trained with representations from vision and language PTMs are capable of multi-tasking and overcoming domain gaps. Evaluating a set of off-the-shelf vision PTMs, our first finding is that the commonly used global features are generally inadequate for building multi-task robot manipulation policies, while keeping local features significantly improves in-domain performance and out-of-domain generalizibility. Experiment results show that DINOv2, a model trained on conventional vision datasets, outperforms models explicitly designed for robot learning. To bridge the domain gaps, we further experiment on the effect of augmentation methods on embodied robot policies and few-shot adaptation. On the later case, we propose a novel objective by introducing self-distillation to the objectives of few-shot adaptation. Experiment results show that our approach is compatible with multiple PTMs, improving performance on novel domains when the number of demonstration available is limited."
    },
    {
        "title": "On Learning Representations for Tabular Dataset Distillation",
        "link_suffix": "/forum?id=Thnk4ez3wN",
        "link": "https://openreview.net/forum?id=Thnk4ez3wN",
        "pdf_link": "https://openreview.net/pdf?id=Thnk4ez3wN",
        "keywords": "Dataset Distillation, Tabular Data, Representation Learning, Autoencoders",
        "abstract": "Dataset distillation generates a small set of information-rich instances from a large dataset, resulting in reduced storage requirements, privacy or copyright risks, and computational costs for downstream modeling, though much of the research has focused on the image data modality. We study tabular data distillation, which brings in novel challenges such as the inherent feature heterogeneity and the common use of non-differentiable learning models (such as decision tree ensembles and nearest-neighbor predictors). To mitigate these challenges, we present TDColER, a tabular data distillation framework via column embeddings-based representation learning. To evaluate this framework, we also present a tabular data distillation benchmark, TDBench. Based on an elaborate evaluation on TDBench, resulting in 226,200 distilled datasets and 541,980 models trained on them, we demonstrate that TDColER is able to boost the distilled data quality of off-the-shelf distillation schemes by 0.5-143% across 7 different tabular learning models."
    },
    {
        "title": "P-SPIKESSM: HARNESSING PROBABILISTIC SPIKING STATE SPACE MODELS FOR LONG-RANGE DEPENDENCY TASKS",
        "link_suffix": "/forum?id=Sf4ep9Udjf",
        "link": "https://openreview.net/forum?id=Sf4ep9Udjf",
        "pdf_link": "https://openreview.net/pdf?id=Sf4ep9Udjf",
        "keywords": "Spiking Neural Networks, Sequence Learning",
        "abstract": "Spiking neural networks (SNNs) are posited as a computationally efficient and biologically plausible alternative to conventional neural architectures, with their core computational framework primarily using the leaky integrate-and-fire (LIF) neuron model. However, the limited hidden state representation of LIF neurons, characterized by a scalar membrane potential, and sequential spike generation process, poses challenges for effectively developing scalable spiking models to address long-range dependencies in sequence learning tasks. In this study, we  develop a scalable probabilistic spiking learning framework for long-range dependency tasks leveraging the fundamentals of state space models. Unlike LIF neurons that rely on the determinitic Heaviside function for a sequential process of spike generation, we introduce a SpikeSampler layer that samples spikes stochastically based on an SSM-based neuronal model while allowing parallel computations. To address non-differentiability of the spiking operation and enable effective training, we also propose a surrogate function tailored for the stochastic nature of the SpikeSampler layer. To enhance inter-neuron communication, we introduce the SpikeMixer block, which integrates spikes from neuron populations in each layer. This is followed by a ClampFuse layer, incorporating a residual connection to capture complex dependencies, enabling scalability of the model. Our models attain state-of-the-art performance among SNN models across diverse long-range dependency tasks, encompassing the Long Range Arena benchmark, permuted sequential MNIST, and the Speech Command dataset and demonstrate sparse spiking pattern highlighting its computational efficiency."
    },
    {
        "title": "Speeding Up Image Classifiers with Little Companions",
        "link_suffix": "/forum?id=0mJZplhexS",
        "link": "https://openreview.net/forum?id=0mJZplhexS",
        "pdf_link": "https://openreview.net/pdf?id=0mJZplhexS",
        "keywords": "model compression, computer vision, efficiency",
        "abstract": "Scaling up neural networks has been a key recipe to the success of large language and vision models. However, in practice, up-scaled models can be disproportionately costly in terms of computations, providing only marginal improvements in performance; for example, EfficientViT-L3-384 achieves <2% improvement on ImageNet-1K accuracy over the base L1-224 model, while requiring 14× more multiply–accumulate operations (MACs). In this paper, we investigate scaling properties of popular families of neural networks for image classification, and find that scaled-up models mostly help with “difficult” samples. Decomposing the samples by difficulty, we develop an embarrassingly simple model-agnostic two-pass Little-Big algorithm that first uses a light-weight “little” model to make predictions of all samples, and only passes the difficult ones for the “big” model to solve. Good little companions achieve drastic MACs reduction for a wide variety of model families and scales. Without loss of accuracy or modification of existing models, our Little-Big models achieve MACs reductions of 76% for EfficientViT-L3-384, 81% for EfficientNet-B7-600, 71% for DeiT3-L-384 on ImageNet-1K. Little-Big also speeds up the InternImage-G-512 model by 62% while achieving 90% ImageNet1K top-1 accuracy, serving both as a strong baseline and as a simple practical method for large model compression."
    },
    {
        "title": "A Kernel Perspective on Training-Free Few-Shot Adaptation of Large Vision-Language Models",
        "link_suffix": "/forum?id=C7ffKahGty",
        "link": "https://openreview.net/forum?id=C7ffKahGty",
        "pdf_link": "https://openreview.net/pdf?id=C7ffKahGty",
        "keywords": "Few-shot Learning, Vision-Language, CLIP, Efficient adaptation",
        "abstract": "The growing popularity of Contrastive Language-Image Pretraining (CLIP) has led to its widespread application in various visual downstream tasks. To enhance CLIP's effectiveness, efficient few-shot adaptation techniques have been widely adopted. Among these approaches, training-free methods, particularly caching methods exemplified by Tip-Adapter, have gained attention for their lightweight adaptation without the need for additional fine-tuning. In this paper, we revisit Tip-Adapter from a kernel perspective, showing that caching methods function as local adapters and are connected to a well-established kernel literature. Leveraging this insight, we offer a theoretical understanding of how these methods operate and suggest multiple avenues for enhancing over the Tip-Adapter baseline. Notably, our analysis shows the importance of incorporating global information in local adapters. Therefore, we subsequently propose a global method that learns a proximal regularizer in a reproducing kernel Hilbert space (RKHS) using CLIP as a base learner. Our method, that we call ProKeR (Proximal Kernel ridge Regression), has a closed form solution and achieves state-of-the-art performance across 11 datasets in the standard few-shot adaptation benchmark."
    },
    {
        "title": "Better autoregressive regression with LLMs",
        "link_suffix": "/forum?id=xGs7Ch3Vyo",
        "link": "https://openreview.net/forum?id=xGs7Ch3Vyo",
        "pdf_link": "https://openreview.net/pdf?id=xGs7Ch3Vyo",
        "keywords": "regression, LLMs",
        "abstract": "Large language models (LLMs) have proven successful on many machine learning  tasks,\nincluding those that do not involve language generation. \nIn specific, LLMs have been shown to be effective in solving regression, where the targets are real-numbers.\nOne common approach is to fine tune the LLM based on the log-perplexity loss and use  autoregressive sampling at the inference time. \nAnother approach relies on adding a predictive head and finetuning it with a suitable loss. \nDespite the success, there has not been a study on the principled ways of using decoder LLMs for regression. \nIn this work we compare different prior works under a unified view, and introduce RAFT, regression-aware fine-tuning, a novel approach based on the Bayes-optimal decision rule. \nWe demonstrate how RAFT improves over established baselines on several benchmarks and model families."
    },
    {
        "title": "Aligning Multimodal Models for Clinical Reasoning using Rule-based Rewards",
        "link_suffix": "/forum?id=x4W8P7ybTE",
        "link": "https://openreview.net/forum?id=x4W8P7ybTE",
        "pdf_link": "https://openreview.net/pdf?id=x4W8P7ybTE",
        "keywords": "Medical Vision-Language Models",
        "abstract": "Vision-Language Models (VLM) can support clinicians by analyzing medical images and engaging in natural language interactions to assist in diagnostic and treatment tasks. However, VLMs often exhibit \"hallucinatory\" behavior, generating textual outputs not grounded in contextual multimodal information. This challenge is particularly pronounced in the medical domain, where we do not only require VLM outputs to be accurate in single interactions but also to be consistent with clinical reasoning and diagnostic pathways throughout multi-turn conversations. For this purpose, we propose a new alignment algorithm that uses rule-based representations of clinical reasoning to ground VLMs in medical knowledge. These representations are utilized to (i) generate visual instruction tuning data at scale, simulating clinician-VLM conversations with demonstrations of clinical reasoning, and (ii) to derive a rule-based reward function that automatically evaluates the clinical validity of VLM responses throughout clinician-VLM interactions. Our algorithm eliminates the need for human involvement in training data generation or reward model construction, reducing costs compared to standard reinforcement learning with human feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a conversational VLM finetuned for analyzing bone marrow pathology slides, demonstrating strong performance in single and multi-turn medical conversations."
    },
    {
        "title": "100 instances is all you need: predicting LLM success by testing on a few instances",
        "link_suffix": "/forum?id=UoWslU6hsX",
        "link": "https://openreview.net/forum?id=UoWslU6hsX",
        "pdf_link": "https://openreview.net/pdf?id=UoWslU6hsX",
        "keywords": "AI evaluation, Large Language Models, Benchmarking",
        "abstract": "Predicting if LLMs will succeed on individual task instances is essential to ensure their reliability in high-stakes applications. To do so, we can evaluate a LLM on a set of instances and train an \"assessor\" to predict its performance. However, this requires evaluating each new LLM on sufficiently many instances. In this work, we build a \"generic assessor\" predicting the performance of any LLM on an instance by using the LLM's performance on a small set of reference instances and the features of the considered instance. In practice, we make use of existing evaluation results to extract the representative instances and train the assessor. Thus, the performance of a new LLM can be predicted by only testing it on the reference instances, leveraging the information contained in other LLMs' evaluations. We conduct empirical studies on HELM-Lite and KindsOfReasoning, a new collection of existing reasoning datasets that we introduce, where we evaluate all instruction-fine-tuned OpenAI models until $\\texttt{gpt4-0125-preview}$. We find that a few instances (around 100) are enough to achieve predictive power comparable to the LLM-specific assessors trained on the complete set of several thousand instances. Interestingly, randomly selecting the reference instances performs comparably to the advanced selection methods we tested. Finally, we identify a sharp drop in the predictive power of the generic and specific assessors in out-of-distribution scenarios, suggesting that the inherent predictability of LLMs is low."
    },
    {
        "title": "Trained Transformer Classifiers Generalize and Exhibit Benign Overfitting In-Context",
        "link_suffix": "/forum?id=jwsPS8yRe4",
        "link": "https://openreview.net/forum?id=jwsPS8yRe4",
        "pdf_link": "https://openreview.net/pdf?id=jwsPS8yRe4",
        "keywords": "in-context learning, generalization, benign overfitting, implicit regularization",
        "abstract": "Transformers have the capacity to act as supervised learning algorithms: by properly encoding a set of labeled training (''in-context'') examples and an unlabeled test example into an input sequence of vectors of the same dimension, the forward pass of the transformer can produce predictions for that unlabeled test example.  A line of recent work has shown that when linear transformers are pre-trained on random instances for linear regression tasks, these trained transformers make predictions using an algorithm similar to that of ordinary least squares.  In this work, we investigate the behavior of linear transformers trained on random linear classification tasks.  Via an analysis of the implicit regularization of gradient descent, we characterize how many pre-training tasks and in-context examples are needed for the trained transformer to generalize well at test-time.  We further show that in some settings, these trained transformers can exhibit ''benign overfitting in-context'': when in-context examples are corrupted by label flipping noise, the transformer memorizes all of its in-context examples (including those with noisy labels) yet still generalizes near-optimally for clean test examples."
    },
    {
        "title": "ReferPix2Pix: Guiding  Multi-Modal LLMs for Image Editing with Referential Pixel Grounding",
        "link_suffix": "/forum?id=NbgODSFW3q",
        "link": "https://openreview.net/forum?id=NbgODSFW3q",
        "pdf_link": "https://openreview.net/pdf?id=NbgODSFW3q",
        "keywords": "Image Editing; Multimodal Large Language Models; Referring Expression Comprehension; Multimodal Coreference Resolution",
        "abstract": "Instruction-based image editing methods allow user-friendly instruction to enhance controllability via natural command. However, without a user-provided mask, existing methods could not identify and edit specific objects if multiple similar instances exist, such as \\textit{``add the man on the right a hat''}. Furthermore, the iterative nature of the editing process may inherently involve ambiguous references from users, such as \\textit{`change it to blue'}, posing challenges in identifying the target without a contextual understanding. Multimodal large language models (MLLMs) offer impressive cross-modal comprehension and co-reference resolution capabilities. In this work, we present \\emph{ReferPix2Pix}, which leverages MLLMs to interpret editing instructions and provide regions of interest (RoI) for precise editing. Such pixel-grounded guidance from MLLMs enhances comprehension of referring expressions and resolves ambiguous references that facilitate localized editing of editing models. Additionally, we developed CoReferEdit benchmark to evaluate editing capabilities across iterative editing phases with multimodal co-references. Our comprehensive experiments show that our approach significantly enhances editing capability in referring and co-referential editing tasks. Our code and data will be made publicly available\\footnote{Please refer to the \\href{https://anonymous.4open.science/r/ReferPix2Pix}{anonymouswebpage} for code and qualitative results.}."
    },
    {
        "title": "Bayesian Learning of Adaptive Koopman Operator with Application to Robust Motion Planning for Autonomous Trucks",
        "link_suffix": "/forum?id=yIdCQFvbYe",
        "link": "https://openreview.net/forum?id=yIdCQFvbYe",
        "pdf_link": "https://openreview.net/pdf?id=yIdCQFvbYe",
        "keywords": "Koopman Theory, Motion Planning, Autonomous Systems",
        "abstract": "Koopman theory has recently been shown to enable an efficient data-driven approach for modeling physical systems, offering a linear framework despite underlying nonlinear dynamics. It is, however, not clear how to account for uncertainty or temporal distributional shifts within this framework, both commonly encountered in real-world autonomous driving with changing weather conditions and time-varying vehicle dynamics. In this work, we introduce Bayesian learning of adaptive Koopman operator to address these limitations. Specifically, we propose a Bayesian Koopman operator that incorporates uncertainty quantification, enabling more robust predictions. To tackle distributional shifts, we propose an online adaptation mechanism, ensuring the operator remains responsive to changes in system dynamics. Additionally, we apply the architecture to motion planning and show that it gives fast and precise predictions. By leveraging uncertainty awareness and real-time updates, our planner generates dynamically accurate trajectories and makes more informed decisions. We evaluate our method on real-world truck dynamics data under varying weather conditions—such as wet roads, snow, and ice—where uncertainty and dynamic shifts are prominent, as well as in other simulated environments. The results demonstrate our method’s ability to deliver accurate, uncertainty-aware open-loop predictions for dynamic systems."
    },
    {
        "title": "PolyPythias: Stability and Outliers across Fifty Language Model Pre-Training Runs",
        "link_suffix": "/forum?id=bmrYu2Ekdz",
        "link": "https://openreview.net/forum?id=bmrYu2Ekdz",
        "pdf_link": "https://openreview.net/pdf?id=bmrYu2Ekdz",
        "keywords": "language models, training dynamics, interpretability, memorization, robustness, training stability",
        "abstract": "Understanding the stability of language model pre-training and its effects on downstream performance is still understudied. \nPrior work shows that the training process can yield significantly different results in response to slight variations in initial conditions, e.g., the random seed.\nCrucially, resources to study pre-training stability in language models are still lacking, especially for decoder-only models.\nWe introduce the PolyPythias, a set of 45 new training runs for the Pythia model suite: 9 new seeds across 5 model sizes, from 14M to 410M parameters, resulting in about 7k new checkpoints that we release.\nUsing these new 45 training runs, in addition to the 5 already available, we study the effects of different initial conditions determined by the seed---i.e., parameters' initialisation and data order---on (i) downstream performance, (ii) learned linguistic representations, and (iii) emergence of training phases.\nIn addition to common scaling behaviours, our analyses generally reveal highly consistent training dynamics across both model sizes and initial conditions.\nAdditionally, the new seeds for each model allow us to identify outlier training runs and delineate their characteristics.\nOur findings show the potential of using these methods to predict training stability."
    },
    {
        "title": "FoundationForensics: Traceback Backdoor Attacks for Vision Foundation Models",
        "link_suffix": "/forum?id=5AoOHSickG",
        "link": "https://openreview.net/forum?id=5AoOHSickG",
        "pdf_link": "https://openreview.net/pdf?id=5AoOHSickG",
        "keywords": "Backdoor Attacks, Foundation Models",
        "abstract": "Foundation models are typically pre-trained on uncurated unlabeled data collected from various domains on the Internet. As a result, they are fundamentally vulnerable to backdoor attacks, where an attacker injects carefully crafted poisoned inputs into the pre-training data via hosting them on the Internet. A backdoored foundation model outputs an attacker-desired embedding vector for any input with an attacker-chosen trigger. In this work, we propose FoundationForensics, the first forensics method to trace back poisoned pre-training inputs for foundation models after a backdoor attack has happened and a trigger-embedded input has been detected. Our FoundationForensics first calculates a maliciousness score for each pre-training input by quantifying its contribution to the foundation model's backdoor behavior for the detected trigger-embedded input and then detects the pre-training inputs with outlier maliciousness scores as poisoned. We theoretically analyze the security of FoundationForensics and empirically evaluate it on single-modal and multi-modal foundation models, three datasets, four existing backdoor attacks, and seven adaptive ones. Our results show that FoundationForensics can accurately traceback the poisoned pre-training inputs for foundation models."
    },
    {
        "title": "Analyzing Neural Scaling Laws in Two-Layer Networks with Power-Law Data Spectra",
        "link_suffix": "/forum?id=wFD16gwpze",
        "link": "https://openreview.net/forum?id=wFD16gwpze",
        "pdf_link": "https://openreview.net/pdf?id=wFD16gwpze",
        "keywords": "Statistical mechanics, neural scaling laws",
        "abstract": "Neural scaling laws describe how the performance of deep neural networks scales with key factors such as training data size, model complexity, and training time, often following power-law behaviors over multiple orders of magnitude. Despite their empirical observation, the theoretical understanding of these scaling laws remains limited. In this work, we employ techniques from statistical mechanics to analyze one-pass stochastic gradient descent within a student-teacher framework, where both the student and teacher are two-layer neural networks. Our study primarily focuses on the generalization error and its behavior in response to data covariance matrices that exhibit power-law spectra.\nFor linear activation functions, we derive analytical expressions for the generalization error, exploring different learning regimes and identifying conditions under which power-law scaling emerges. Additionally, we extend our analysis to non-linear activation functions in the feature learning regime, investigating how power-law spectra in the data covariance matrix impact learning dynamics. Importantly, we find that the length of the symmetric plateau depends on the number of distinct eigenvalues of the data covariance matrix and the number of hidden units, demonstrating how these plateaus behave under various configurations. In addition, our results reveal a transition from exponential to power-law convergence in the specialized phase when the data covariance matrix possesses a power-law spectrum. This work contributes to the theoretical understanding of neural scaling laws and provides insights into optimizing learning performance in practical scenarios involving complex data structures."
    },
    {
        "title": "Adapters for Altering LLM Vocabularies: What Languages Benefit the Most?",
        "link_suffix": "/forum?id=KxQRHOre9D",
        "link": "https://openreview.net/forum?id=KxQRHOre9D",
        "pdf_link": "https://openreview.net/pdf?id=KxQRHOre9D",
        "keywords": "Vocabulary Adaptation, Vocabulary Transfer, Tokenizer Transfer, Initializing Embedding, Adapter, Multilingual, Machine Translation",
        "abstract": "Vocabulary adaptation, which integrates new vocabulary into pre-trained language models (LMs), enables expansion to new languages and mitigates token over-fragmentation. However, existing approaches are limited by their reliance on heuristic or external embeddings. We propose VocADT, a novel method for vocabulary adaptation using adapter modules that are trained to learn the optimal linear combination of existing embeddings while keeping the model's weights fixed. VocADT offers a flexible and scalable solution without requiring external resources or language constraints. Across 11 languages—with various scripts, resource availability, and fragmentation—we demonstrate that VocADT outperforms the original Mistral model and other baselines across various multilingual tasks. We find that Latin-script languages and highly fragmented languages benefit the most from vocabulary adaptation. We further fine-tune the adapted model on the generative task of machine translation and find that vocabulary adaptation is still beneficial after fine-tuning and that VocADT is the most effective method."
    },
    {
        "title": "Model Collapse in the Chain of Diffusion Finetuning: A Novel Perspective from Quantitative Trait Modeling",
        "link_suffix": "/forum?id=P5UETqZXqT",
        "link": "https://openreview.net/forum?id=P5UETqZXqT",
        "pdf_link": "https://openreview.net/pdf?id=P5UETqZXqT",
        "keywords": "generative, diffusion, model collapse",
        "abstract": "The success of generative models has reached a unique threshold where their outputs are indistinguishable from real data, leading to the inevitable contamination of future data collection pipelines with synthetic data. While their potential to generate infinite samples initially offers promise for reducing data collection costs and addressing challenges in data-scarce fields, the severe degradation in performance has been observed when iterative loops of training and generation occur---known as ''model collapse.'' This paper explores a practical scenario in which a pretrained text-to-image diffusion model is finetuned using synthetic images generated from a previous iteration, a process we refer to as the ''Chain of Diffusion.'' We first demonstrate the significant degradation in image qualities caused by this iterative process and identify the key factor driving this decline through rigorous empirical investigations. Drawing on an analogy between the Chain of Diffusion and biological evolution, we then introduce a novel theoretical analysis based on quantitative trait modeling. Our theoretical analysis aligns with empirical observations of the generated images in the Chain of Diffusion. Finally, we propose Reusable Diffusion Finetuning (ReDiFine), a simple yet effective strategy inspired by genetic mutations. ReDiFine mitigates model collapse without requiring any hyperparameter tuning, making it a plug-and-play solution for reusable image generation."
    },
    {
        "title": "SSPictR: Spatial Semantic Pointer Picture Representation",
        "link_suffix": "/forum?id=dmh53n4onc",
        "link": "https://openreview.net/forum?id=dmh53n4onc",
        "pdf_link": "https://openreview.net/pdf?id=dmh53n4onc",
        "keywords": "scene representation, scene recognition, cognitive maps, spatial semantic pointers, vector symbolic algebras",
        "abstract": "The development of image representations that capture semantic and spatial information efficiently, which are also interpretable and generalisable, remains unsolved. Drawing from a cognitive modelling framework, we propose SSPictR – a biologically plausible image representation based on spatial semantic pointers (SSPs). SSPictR encodes semantic labels and their spatial locations extracted from segmentation maps and only requires a single vector to capture a fully decodable neuro-symbolic representation of a natural scene. It is inherently interpretable, offers a high compression factor and significantly faster inference speed on downstream tasks, such as scene recognition. We evaluate the efficiency and generalisability of SSPictR on the popular Places365, and ADE20K datasets for scene recognition, on COCOStuff for segmentation reconstruction, and on VISC and Savoias for prediction of visual complexity. We show that the scene representations provided by SSPictR are more generalisable within and across these tasks while only requiring a fraction of model parameters and, therefore, offer 25 times higher inference speed, with comparable accuracy. As such, SSPictR opens up a new direction for future research on cognitively-inspired image representations that are not only significantly smaller but also more interpretable and generalisable."
    },
    {
        "title": "Revisiting the Superficial Alignment Hypothesis",
        "link_suffix": "/forum?id=SIzjhS9kEF",
        "link": "https://openreview.net/forum?id=SIzjhS9kEF",
        "pdf_link": "https://openreview.net/pdf?id=SIzjhS9kEF",
        "keywords": "Large Language Models, Alignment, Artificial Intelligence, Supervised Finetuning, Post-training, Pre-training, Scaling Laws, Evaluation, Reasoning",
        "abstract": "The Superficial Alignment Hypothesis posits that almost all of a language model's abilities and knowledge are learned during pre-training, while post-training is about giving a model the right style and format. We re-examine these claims by empirically studying the scaling behavior of post-training with increasing finetuning examples and evaluating them using objective task-specific standardized benchmarks. Through experiments with the Llama-3, Mistral, and Llama-2 model families of multiple sizes, we observe that, similar to the pre-training scaling laws, post-training task performance scales as a power law against the number of finetuning examples. This power law relationship holds across a broad array of capabilities, including mathematical reasoning, coding, instruction following, and multihop-reasoning. In addition, for tasks like math and multihop reasoning, we observe that a handful of examples merely align the model stylistically but do not saturate performance on the benchmarks. Model performance is instead correlated with its reasoning ability and it improves significantly with more examples, illustrating the need for holistic evaluation programs leveraging objective benchmarks in addition to measurement of alignment to human preferences. We also observe that language models are not necessarily limited to using knowledge learned during pre-training. With appropriate post-training, a model's ability to integrate new knowledge greatly improves on downstream tasks like multihop question-answering. Taken together, these results shed new light on the Superficial Alignment Hypothesis, suggesting that it is, at best, an over-simplification."
    },
    {
        "title": "COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement",
        "link_suffix": "/forum?id=0JjsZC0w8x",
        "link": "https://openreview.net/forum?id=0JjsZC0w8x",
        "pdf_link": "https://openreview.net/pdf?id=0JjsZC0w8x",
        "keywords": "autoregressive large language modeling, decoding, iterative refinement",
        "abstract": "Iterative refinement has emerged as an effective paradigm for enhancing the capabilities of large language models (LLMs) on complex tasks. However, existing approaches typically implement iterative refinement at the application or prompting level, relying on autoregressive (AR) modeling. The sequential token generation in AR models can lead to high inference latency. \nTo overcome these challenges, we proposeContext-WiseOrder-AgnosticLanguage Modeling (COrAL), which incorporates iterative refinement directly into the LLM architecture while maintaining computational efficiency. Our approach models multiple token dependencies within manageable context windows, enabling the model to perform iterative refinement internally during the generation process. Leveraging the order-agnostic nature of COrAL, we introduce sliding blockwise order-agnostic decoding, which performs multi-token forward prediction and backward reconstruction within context windows. This allows the model to iteratively refine its outputs in parallel in the sliding block, effectively capturing diverse dependencies without the high inference cost of sequential generation.\nEmpirical evaluations on reasoning tasks demonstrate that COrAL improves performance and inference speed, respectively, achieving absolute accuracy gains of $4.6$% on GSM8K and $4.0$% on LogiQA, along with inference speedups of up to $3.9\\times$ over next-token baselines. Preliminary results on code generation indicate a drop in pass rates due to inconsistencies in order-agnostic outputs, highlighting the inherent quality--speed trade-off."
    },
    {
        "title": "Hierarchical Clustering for Conditional Diffusion in Image Generation",
        "link_suffix": "/forum?id=k29iamlbpv",
        "link": "https://openreview.net/forum?id=k29iamlbpv",
        "pdf_link": "https://openreview.net/pdf?id=k29iamlbpv",
        "keywords": "Clustering, Generative Modeling, Hierarchical Clustering, Variational Autoencoders, Diffusion Models",
        "abstract": "Finding clusters of data points with similar characteristics and generating new cluster-specific samples can significantly enhance our understanding of complex data distributions. While clustering has been widely explored using Variational Autoencoders, these models often lack generation quality in real-world datasets. This paper addresses this gap by introducing TreeDiffusion, a deep generative model that conditions Diffusion Models on hierarchical clusters to obtain high-quality, cluster-specific generations. The proposed pipeline consists of two steps: a VAE-based clustering model that learns the hierarchical structure of the data, and a conditional diffusion model that generates realistic images for each cluster. We propose this two-stage process to ensure that the generated samples remain representative of their respective clusters and enhance image fidelity to the level of diffusion models. A key strength of our method is its ability to create images for each cluster, providing better visualization of the learned representations by the clustering model, as demonstrated through qualitative results. This method effectively addresses the generative limitations of VAE-based approaches while preserving their clustering performance. Empirically, we demonstrate that conditioning diffusion models on hierarchical clusters significantly enhances generative performance, thereby advancing the state of generative clustering models."
    }
]
[{"title": "A Prototype-oriented Fast Refinement Model for Few-shot Industrial Anomaly Detection", "link_suffix": "/forum?id=gTsLBDMZrL", "link": "https://openreview.net/forum?id=gTsLBDMZrL", "pdf_link": "https://openreview.net/pdf?id=gTsLBDMZrL", "keywords": "Industrial Anomaly Detection, Few-shot Learning, Optimal Transport", "abstract": "Industrial Anomaly Detection (IAD) in low data regime is crucial for automating industrial inspections in practice. Previous methods have primarily focused on obtaining robust prototypes using only a few normal images per product. However, these methods seldom account for transferring the characteristics of online query images to enhance the representativeness of the original prototypes in a systematic way. To address the pivot issue, we propose a fast prototype-oriented refinement model for few-shot IAD. Given online query images, we formulate prototype refinement as a nested optimization problem between transport probability for anomaly suppression and transform matrix for characteristic transfer. Then we present an Expectation Maximization (EM)-based algorithm to iteratively compute the transport probability and transform matrix. In the E-step, we use entropy-based optimal transport, known as the Sinkhorn algorithm, to learn the transport probability. In the M-step, the transform matrix is updated via gradient descent. Finally, we integrate our model with two popular and recently proposed few-shot IAD methods, PatchCore and WinCLIP. Comprehensive experiments on three widely used datasets including MVTec, ViSA, and MPDD verify the effectiveness and efficiency of our proposed model in few-shot IAD applications.", "title_embedding_index": 13850, "title_abs_embedding_index": 13875}, {"title": "D3PM: Diffusion Model Responds to the Duty Call from Causal Discovery", "link_suffix": "/forum?id=TRHyAnInUC", "link": "https://openreview.net/forum?id=TRHyAnInUC", "pdf_link": "https://openreview.net/pdf?id=TRHyAnInUC", "keywords": "causal discovery, deep learning, diffusion models", "abstract": "Causal discovery (CD) involves inferring cause-and-effect relationships as directed acyclic graphs (DAGs). In this work, we assume that the data is generated by an additive noise model (ANM). Recent work has formulated the problem as a continuous optimization problem, which consists of solving an inverse problem and satisfying an acyclicity constraint. However, solving the inverse problem in CD is often unstable, i.e. high sensitivity of the effects to perturbations in the causes. To address this instability, we formulate the inverse problem as a regularized optimization scheme and propose a novel variation-negotiation regularizer. Compared to traditional regularization techniques for the continuous optimization problem, e.g. $\\ell_1$ penalty on graphs, the proposed regularizer exploits the variation variable in ANMs to stabilize the solutions (i.e. DAGs). This regularizer is advantageous as it does not rely on any hypotheses, such as graph sparsity, about true DAGs. The variation-negotiation regularizer regulates the DAG purely based on observed data.Building on the proposed regularizer, a series of improvements to the regularized optimization scheme reveal the connections between solving the regularized optimization problem and learning a diffusion model, as they share comparable objective functions. This insight leads us to develop an equivalent diffusion model called DAG-invariant Denoising Diffusion Probabilistic Model. Extensive empirical experiments on synthetic and real datasets demonstrate that the proposed diffusion model achieves outstanding performance on all datasets.", "title_embedding_index": 13851, "title_abs_embedding_index": 13876}, {"title": "Distill Visual Chart Reasoning Ability from LLMs to MLLMs", "link_suffix": "/forum?id=cjlPAgNifc", "link": "https://openreview.net/forum?id=cjlPAgNifc", "pdf_link": "https://openreview.net/pdf?id=cjlPAgNifc", "keywords": "multimodal large language models, synthetic data, chart question answering", "abstract": "Solving complex chart Q&A tasks requires advanced visual reasoning abilities in multimodal large language models (MLLMs). Recent studies highlight that these abilities consist of two main parts: recognizing key information from visual inputs and conducting reasoning over it. Thus, a promising approach to enhance MLLMs is to construct relevant training data focusing on the two aspects. However, collecting and annotating complex charts and questions is costly and time-consuming, and ensuring the quality of annotated answers remains a challenge. In this paper, we propose Code-as-Intermediary Translation (CIT), a cost-effective, efficient and easily scalable data synthesis method for distilling visual reasoning abilities from LLMs to MLLMs. The code serves as an intermediary that translates visual chart representations into textual representations, enabling LLMs to understand cross-modal information. Specifically, we employ text-based synthesizing techniques to construct chart-plotting code and produce ReachQA, a dataset containing 3k reasoning-intensive charts and 20k Q&A pairs to enhance both recognition and reasoning abilities. Experiments show that when fine-tuned with our data, models not only perform well on chart-related benchmarks, but also demonstrate improved multimodal reasoning abilities on general mathematical benchmarks such as MathVista.", "title_embedding_index": 13852, "title_abs_embedding_index": 13877}, {"title": "Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map", "link_suffix": "/forum?id=ZPCBcR7Drg", "link": "https://openreview.net/forum?id=ZPCBcR7Drg", "pdf_link": "https://openreview.net/pdf?id=ZPCBcR7Drg", "keywords": "Driving rules, autonomous driving", "abstract": "Ensuring adherence to traffic sign regulations is essential for both human and autonomous vehicle navigation. While current benchmark datasets concentrate on lane perception or basic traffic sign recognition, they often overlook the intricate task of integrating these regulations into lane operations. Addressing this gap, we introduce MapDR, a novel dataset designed for the extraction of Driving Rules from traffic signs and their association with vectorized, locally perceived HD Maps.\nMapDR features over 10,000 annotated video clips that capture the intricate correlation between traffic sign regulations and lanes. We define two pivotal sub-tasks: 1) Rule Extraction from Traffic Sign, which accurately deciphers regulatory instructions, and 2) Rule-Lane Correspondence Reasoning, which aligns these rules with their respective lanes.\nBuilt upon this benchmark, we provide a multimodal solution that offers a strong baseline for advancing autonomous driving technologies. It fills a critical gap in the integration of traffic sign rules, contributing to the development of reliable autonomous navigation systems.", "title_embedding_index": 13853, "title_abs_embedding_index": 13878}, {"title": "Learning Splitting Heuristics in Divide-and-Conquer SAT Solvers with Reinforcement Learning", "link_suffix": "/forum?id=uUsL07BsMA", "link": "https://openreview.net/forum?id=uUsL07BsMA", "pdf_link": "https://openreview.net/pdf?id=uUsL07BsMA", "keywords": "SAT Problem, Divide And Conquer, Graph Neural Network, Reinforcememt Learning", "abstract": "We propose RDC-SAT, a novel approach to optimize splitting heuristics in Divide-and-Conquer SAT solvers using deep reinforcement learning.  Our method dynamically extracts features from the current solving state whenever a split is required.  These features, such as learned clauses, variable activity scores, and clause LBD (Literal Block Distance) values, are represented as a graph.  A GNN integrated with an Actor-Critic model processes this graph to determine the optimal split variable.  Unlike traditional linear state transitions characterized by Markov processes, divide-and-conquer challenges involve tree-like state transitions.  To address this, we developed a reinforcement learning environment based on the Painless framework that efficiently handles these transitions.  Additionally, we designed different discounted reward functions for satisfiable and unsatisfiable SAT problems, capable of handling tree-like state transitions.  We trained our model using the Decentralized Proximal Policy Optimization (DPPO) algorithm on phase transition random 3-SAT problems and implemented the RDC-SAT solver, which operates in both GPU-accelerated and non-GPU modes.  Evaluations show that RDC-SAT significantly improves the performance of D&C solvers on phase transition random 3-SAT datasets and generalizes well to the SAT Competition 2023 dataset, substantially outperforming traditional splitting heuristics.", "title_embedding_index": 13854, "title_abs_embedding_index": 13879}, {"title": "Provably Robust Explainable Graph Neural Networks against Graph Perturbation Attacks", "link_suffix": "/forum?id=iFK0xoceR0", "link": "https://openreview.net/forum?id=iFK0xoceR0", "pdf_link": "https://openreview.net/pdf?id=iFK0xoceR0", "keywords": "Certiffed Defenses, Explainable Graph Neural Network, Explainable Artificial Intelligence", "abstract": "Explaining Graph Neural Network (XGNN) has gained growing attention to facilitate the trust of using GNNs, which is the mainstream method to learn graph data. Despite their growing attention, Existing XGNNs focus on improving the explanation performance, and its robustness under attacks is largely unexplored. We noticed that an adversary can slightly perturb the graph structure such that the explanation result of XGNNs is largely changed. Such vulnerability of XGNNs could cause serious issues particularly in safety/security-critical applications. In this paper, we take the first step to study the robustness of XGNN against graph perturbation attacks, and propose XGNNCert, the first provably robust XGNN. Particularly, our XGNNCert can provably ensure the explanation result for a graph under the worst-case graph perturbation attack is close to that without the attack, while not affecting the GNN prediction, when the number of perturbed edges is bounded. Evaluation results on multiple graph datasets and GNN explainers show the effectiveness of XGNNCert.", "title_embedding_index": 13855, "title_abs_embedding_index": 13880}, {"title": "Towards Ultra-High-Definition Image Deraining: A Benchmark and An Efficient Method", "link_suffix": "/forum?id=HZz81oCNlp", "link": "https://openreview.net/forum?id=HZz81oCNlp", "pdf_link": "https://openreview.net/pdf?id=HZz81oCNlp", "keywords": "Image deraining, Rain removal, Ultra-high-definition, 4K image, Benchmark dataset, Vision MLP", "abstract": "Despite significant progress has been made in image deraining, existing approaches are mostly carried out on low-resolution images. The effectiveness of these methods on high-resolution images is still unknown, especially for ultra-high-definition (UHD) images, given the continuous advancement of imaging devices. In this paper, we focus on the task of UHD image deraining, and contribute the first large-scale UHD image deraining dataset, 4K-Rain13k, that contains 13,000 image pairs at 4K resolution. Based on this dataset, we conduct a benchmark study on existing methods for processing UHD images. Furthermore, we develop an effective and efficient architecture (called UDR-Mixer) to better solve this task. Specifically, our method contains two building components: a spatial feature rearrangement layer that captures long-range information of UHD images, and a frequency feature modulation layer that facilitates high-quality UHD image reconstruction. Extensive experimental results demonstrate that our method performs favorably against the state-of-the-art approaches while maintaining a lower model complexity. The code and dataset will be available to the public.", "title_embedding_index": 13856, "title_abs_embedding_index": 13881}, {"title": "StringLLM: Understanding the String Processing Capability of Large Language Models", "link_suffix": "/forum?id=kTXChtaaNO", "link": "https://openreview.net/forum?id=kTXChtaaNO", "pdf_link": "https://openreview.net/pdf?id=kTXChtaaNO", "keywords": "Large Language Models, String Processing, Benchmarks, Datasets", "abstract": "String processing, which mainly involves the analysis and manipulation of strings, is a fundamental component of modern computing. Despite the significant advancements of large language models (LLMs) in various natural language processing (NLP) tasks, their capability in string processing remains underexplored and underdeveloped. To bridge this gap, we present a comprehensive study of LLMs' string processing capability. In particular, we first propose StringLLM, a method to construct datasets for benchmarking string processing capability of LLMs. We use StringLLM to build a series of datasets, referred to as StringBench. It encompasses a wide range of string processing tasks, allowing us to systematically evaluate LLMs' performance in this area. Our evaluations indicate that LLMs struggle with accurately processing strings compared to humans. To uncover the underlying reasons for this limitation, we conduct an in-depth analysis and subsequently propose an effective approach that significantly enhances LLMs' string processing capability via fine-tuning. This work provides a foundation for future research to understand LLMs' string processing capability. We will publish our code and data upon paper acceptance.", "title_embedding_index": 13857, "title_abs_embedding_index": 13882}, {"title": "ROSE: Reduced Overhead Stereo Event-Intensity Depth Estimation", "link_suffix": "/forum?id=IjLumaGZ4h", "link": "https://openreview.net/forum?id=IjLumaGZ4h", "pdf_link": "https://openreview.net/pdf?id=IjLumaGZ4h", "keywords": "Event-based Vision, Stereo Depth Estimation", "abstract": "Stereo depth estimation using event cameras is a promising approach for real-time vision tasks, offering low-latency, high-speed data capture. However, existing methods often suffer from high computational overhead, limiting their real-time applicability. To address these challenges, we introduce ROSE (Reduced Overhead Stereo Event and Intensity) a Real-Time framework for efficient depth estimation from events and intensity images. Current approaches rely on dense networks that fail to scale with increasing data complexity, constraining both accuracy and speed. In contrast, ROSE incorporates lightweight event representation networks and optimizes the stereo matching process to reduce model size and computational load without compromising accuracy.\nWe replace conventional network components with efficient spatio-temporal representations and streamline adaptive aggregation modules, reducing computational complexity by 1000\u00d7 compared to previous methods. Furthermore, we adapt event grouping strategies to better align with intensity images, improving the quality of depth estimation under various lighting and motion conditions. Extensive experiments on the DSEC and MVSEC benchmarks demonstrate that ROSE achieves real-time performance, boosting frame rates to 32.2 FPS on DSEC and 66.9 FPS on MVSEC while maintaining competitive depth accuracy. This marks a significant improvement over prior work in terms of speed and scalability, making ROSE a viable solution for real-time stereo depth estimation in resource-constrained environments. Our code and models will be released to support further advancements in the field.", "title_embedding_index": 13858, "title_abs_embedding_index": 13883}, {"title": "Parrot: Multilingual Visual Instruction Tuning", "link_suffix": "/forum?id=78NPsEq8cF", "link": "https://openreview.net/forum?id=78NPsEq8cF", "pdf_link": "https://openreview.net/pdf?id=78NPsEq8cF", "keywords": "Multimodal Large Language Models; Multilingual MLLM; Mixture-of-Experts", "abstract": "The rapid development of Multimodal Large Language Models (MLLMs) like GPT-4V has marked a significant step towards artificial general intelligence. Existing methods mainly focus on aligning vision encoders with LLMs through supervised fine-tuning (SFT) to endow LLMs with multimodal abilities, making MLLMs' inherent ability to react to multiple languages progressively deteriorate as the training process evolves. We empirically find that the imbalanced SFT datasets, primarily composed of English-centric image-text pairs, lead to significantly reduced performance in non-English languages. This is due to the failure of aligning the vision encoder and LLM with multilingual tokens during the SFT process. In this paper, we introduce Parrot, a novel method that utilizes textual guidance to drive visual token alignment at the language level. Parrot makes the visual tokens condition on diverse language inputs and uses Mixture-of-Experts (MoE) to promote the alignment of multilingual tokens. Specifically, to enhance non-English visual tokens alignment, we compute the cross-attention using the initial visual features and textual embeddings, the result of which is then fed into the MoE router to select the most relevant experts. The selected experts subsequently convert the initial visual tokens into language-specific visual tokens. Moreover, considering the current lack of benchmarks for evaluating multilingual capabilities within the field, we collect and make available a Massive Multilingual Multimodal Benchmark which includes 6 languages, 15 categories, and 12,000 questions, named as MMMB. Our method not only demonstrates state-of-the-art performance on multilingual MMBench and MMMB, but also excels across a broad range of multimodal tasks.", "title_embedding_index": 13859, "title_abs_embedding_index": 13884}, {"title": "Toward Learning Generalized Cross-Problem Solving Strategies for Combinatorial Optimization", "link_suffix": "/forum?id=VnaJNW80pN", "link": "https://openreview.net/forum?id=VnaJNW80pN", "pdf_link": "https://openreview.net/pdf?id=VnaJNW80pN", "keywords": "Neural Combinatorial Optimization, Multi-task Learning", "abstract": "Combinatorial optimization (CO) problems are fundamental across various domains, with many sharing similarities in optimization objectives, decision variables, and constraints. Many traditional algorithms perform well on related problems using similar solution strategies, highlighting the commonality in solving different problems. However, most machine learning approaches treat each CO problem in isolation, failing to capitalize on the underlying relationships between problems. In this paper, we investigate the potential to learn generalized solving strategies that capture the shared structure among different CO problems, enabling easier adaptation to related tasks. To this end, we propose to first divide the model architecture into three components: a header, an encoder, and a decoder; where The header and decoder address problem-specific inputs and outputs, while the encoder is designed to learn shared strategies that generalize across different problems.  To ensure this, we enforce alignment in the optimization directions of the encoder across problems, maintaining consistency in both gradient directions and magnitudes to harmonize optimization processes. This is achieved by introducing the additional problem-specific rotation matrices and loss weights to steer the gradients, which are updated via a gradient consistency loss. Extensive experiments on six CO problems demonstrate that our method enhances the model's ability to capture shared solving strategies across problems. We show that the learned encoder on several problems can directly perform comparably on new problems to models trained from scratch, highlighting its potential to support developing the foundational model for combinatorial optimization. Source code will be made publicly available.", "title_embedding_index": 13860, "title_abs_embedding_index": 13885}, {"title": "Counterfactual Generative Modeling with Variational Causal Inference", "link_suffix": "/forum?id=oeDcgVC7Xh", "link": "https://openreview.net/forum?id=oeDcgVC7Xh", "pdf_link": "https://openreview.net/pdf?id=oeDcgVC7Xh", "keywords": "deep probabilistic modeling, bayesian networks, variational inference, causal inference, counterfactual generative modeling, causal machine learning, deep unsupervised learning, graphical models", "abstract": "Estimating an individual's potential outcomes under counterfactual treatments is a challenging task for traditional causal inference and supervised learning approaches when the outcome is high-dimensional (e.g. gene expressions, facial images) and covariates are relatively limited. In this case, to predict one's outcomes under counterfactual treatments, it is crucial to leverage individual information contained in its high-dimensional observed outcome in addition to the covariates. Prior works using variational inference in counterfactual generative modeling have been focusing on neural adaptations and model variants within the conditional variational autoencoder formulation, which we argue is fundamentally ill-suited to the notion of counterfactual in causal inference. In this work, we present a novel variational Bayesian causal inference framework and its theoretical backings to fittingly handle counterfactual generative modeling tasks, through which we are able to conduct counterfactual supervision end-to-end during training without any counterfactual samples, and encourage latent disentanglement that aids the correct identification of causal effect in counterfactual generations. In experiments, we demonstrate the advantage of our framework compared to state-of-the-art models in counterfactual generative modeling on multiple benchmarks.", "title_embedding_index": 13861, "title_abs_embedding_index": 13886}, {"title": "Multi-Grained Knowledge for Retrieval-Augmented Question Answering on Hyper-long Contexts", "link_suffix": "/forum?id=xE3Ra2GTpX", "link": "https://openreview.net/forum?id=xE3Ra2GTpX", "pdf_link": "https://openreview.net/pdf?id=xE3Ra2GTpX", "keywords": "Knowledge-based Question Answering, Retrieval-Augmented, Large Language Model Generation, Information Extraction, Hyper-long Contexts", "abstract": "In the task of hyper-long context question answering (QA), a key challenge is extracting accurate answers from vast and dispersed information, much like finding a needle in a haystack. Existing approaches face major limitations, particularly the input-length constraints of Large Language Models (LLMs), which hinder their ability to understand hyper-long contexts. Furthermore, Retrieval-Augmented Generation (RAG) methods, which heavily rely on semantic representations, often experience semantic loss and retrieval errors when answers are spread across different parts of the text.\nTherefore, there is a pressing need to develop more effective strategies to optimize information extraction and reasoning. \nIn this paper, we propose a multi-grained entity graph-based QA method that constructs an entity graph and dynamically combines both local and global contexts. Our approach captures information across three granularity levels (i.e., micro-level, feature-level, and macro-level), and incorporates iterative retrieval and reasoning mechanisms to generate accurate answers for hyper-long contexts.\nSpecifically, we first utilize EntiGraph to extract entities, attributes, relationships, and events from hyper-long contexts, and aggregate them to generate multi-granularity QA pairs. Then, we retrieve the most relevant QA pairs according to the query. Additionally, we introduce LoopAgent, an iterative retrieval mechanism that dynamically refines queries across multiple retrieval rounds, combining reasoning mechanisms to enhance the accuracy and effectiveness of answering complex questions.\nWe evaluated our method on various datasets from LongBench and InfiniteBench, and the experimental results demonstrate the effectiveness of our approach, significantly outperforming existing methods in both the accuracy and granularity of the extracted answers. Furthermore, it has been successfully deployed in online novel-based applications, showing significant improvements in handling long-tail queries and answering detail-oriented questions.", "title_embedding_index": 13862, "title_abs_embedding_index": 13887}, {"title": "Efficient Evolutionary Search Over Chemical Space with Large Language Models", "link_suffix": "/forum?id=awWiNvQwf3", "link": "https://openreview.net/forum?id=awWiNvQwf3", "pdf_link": "https://openreview.net/pdf?id=awWiNvQwf3", "keywords": "Large Language Models, Evolutionary Search, Molecule Optimization, AI for Science, Molecular generation", "abstract": "Molecular discovery, when formulated as an optimization problem, presents significant computational challenges because optimization objectives can be non-differentiable. Evolutionary Algorithms (EAs), often used to optimize black-box objectives in molecular discovery, traverse chemical space by performing random mutations and crossovers, leading to a large number of expensive objective evaluations. In this work, we ameliorate this shortcoming by incorporating chemistry-aware Large Language Models (LLMs) into EAs. Namely, we redesign crossover and mutation operations in EAs using LLMs trained on large corpora of chemical information. We perform extensive empirical studies on both commercial and open-source models on multiple tasks involving property optimization, molecular rediscovery, and structure-based drug design, demonstrating that the joint usage of LLMs with EAs yields superior performance over all baseline models across single- and multi-objective settings. We demonstrate that our algorithm improves both the quality of the final solution and convergence speed, thereby reducing the number of required objective evaluations.", "title_embedding_index": 13863, "title_abs_embedding_index": 13888}, {"title": "Dual Consolidation for Pre-Trained Model-Based Domain-Incremental Learning", "link_suffix": "/forum?id=55oi1LCdDL", "link": "https://openreview.net/forum?id=55oi1LCdDL", "pdf_link": "https://openreview.net/pdf?id=55oi1LCdDL", "keywords": "Domain-Incremental Learning, Pre-Trained Model, Continual Learning", "abstract": "Domain-Incremental Learning (DIL) involves the progressive adaptation of a model to new concepts across different domains. While recent advances in pre-trained models provide a solid foundation for DIL, learning new concepts often results in the catastrophic forgetting of pre-trained knowledge. Specifically, sequential model updates can overwrite both the representation and the classifier with knowledge from the latest domain. Thus, it is crucial to develop a representation and corresponding classifier that accommodate all seen domains throughout the learning process. To this end, we propose DUal ConsolidaTion (Duct) to unify and consolidate historical knowledge at both the representation and classifier levels. By merging the backbone of different stages, we create a representation space suitable for multiple domains incrementally. The merged representation serves as a balanced intermediary that captures task-specific features from all seen domains. Additionally, to address the mismatch between consolidated embeddings and the classifier, we introduce an extra classifier consolidation process. Leveraging class-wise semantic information, we estimate the classifier weights of old domains within the latest embedding space. By merging historical and estimated classifiers, we align them with the consolidated embedding space, facilitating incremental classification. Extensive experimental results on four benchmark datasets demonstrate Duct's state-of-the-art performance.", "title_embedding_index": 13864, "title_abs_embedding_index": 13889}, {"title": "Entropic Distribution Matching for Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity", "link_suffix": "/forum?id=NQEe7B7bSw", "link": "https://openreview.net/forum?id=NQEe7B7bSw", "pdf_link": "https://openreview.net/pdf?id=NQEe7B7bSw", "keywords": "Large language models, supervised fine-tuning, distribution matching", "abstract": "Large language models rely on Supervised Fine-Tuning (SFT) to specialize in downstream tasks. Cross Entropy (CE) loss is the de facto choice in SFT. However, CE often results in overfitting and limited output diversity due to its aggressive distribution matching strategy, which forces the model\u2019s generative distribution to closely mimic the empirical data distribution. This paper aims to address these issues by introducing the maximum entropy principle, encouraging models to resist overfitting while preserving output diversity. Specifically, we develop a new distribution matching method called GEM, which solves reverse Kullback-Leibler divergence minimization with an entropy regularizer.For the SFT of Llama-3-8B models, GEM outperforms CE in several aspects. First, when applied to acquire general instruction-following abilities, GEM exhibits reduced overfitting, as evidenced by lower perplexity and better performance on the IFEval benchmark. Second, this advantage is also observed in domain-specific fine-tuning, where GEM continues to outperform CE in specialized math reasoning and code generation tasks. Last, we show that GEM-tuned models offer better output diversity, which helps scale up test-time compute: with the same sampling budget, they achieve performance gains of up to 10 points in math reasoning and code generation tasks, compared with CE-tuned models.", "title_embedding_index": 13865, "title_abs_embedding_index": 13890}, {"title": "UniAdapt: A Universal Adapter for Knowledge Calibration", "link_suffix": "/forum?id=hLZEbvDYhz", "link": "https://openreview.net/forum?id=hLZEbvDYhz", "pdf_link": "https://openreview.net/pdf?id=hLZEbvDYhz", "keywords": "Lifelong model editing, Mixture of experts, Retrieval-Augmented Generation", "abstract": "Large Language Models (LLMs) require frequent updates to correct errors and keep pace with continuously evolving knowledge in a timely and effective manner. Recent research init model editinghas highlighted the challenges in balancing generalization and locality, especially in the context oflifelong model editing. We discover that inserting knowledge directly into the model often causes conflicts and potentially disrupts other unrelated pre-trained knowledge. To address this problem, we introduce UniAdapt, a universal adapter for knowledge calibration. Inspired by the Mixture of Experts architecture and Retrieval-Augmented Generation, UniAdapt is designed with a vector-assisted router that is responsible for routing inputs to appropriate experts. The router maintains a vector store, including multiple shards, to construct routing vectors based on semantic similarity search results. UniAdapt is fully model-agnostic and designed for seamless plug-and-play integration. Experimental results show that UniAdapt outperforms existing lifelong model editors and achieves exceptional results in most metrics.", "title_embedding_index": 13866, "title_abs_embedding_index": 13891}, {"title": "Unraveling Cross-Modality Knowledge Conflicts in Large Vision-Language Models", "link_suffix": "/forum?id=ZZrSOMLoau", "link": "https://openreview.net/forum?id=ZZrSOMLoau", "pdf_link": "https://openreview.net/pdf?id=ZZrSOMLoau", "keywords": "Knowledge Conflict, Vision and Language", "abstract": "Large Vision-Language Models (LVLMs) have demonstrated impressive capabilities for capturing and reasoning over multimodal inputs.\nHowever, these models are prone to parametric knowledge conflicts, which arise from inconsistencies of represented knowledge between their vision and language components.\nIn this paper, we formally define the problem ofcross-modality parametric knowledge conflictand present a systematic approach to detect, interpret, and mitigate them.\nWe introduce a pipeline that identifies conflicts between visual and textual answers, showing a persistently high conflict rate across modalities in recent LVLMs regardless of the model size.\nWe further investigate how these conflicts interfere with the inference process and propose a contrastive metric to discern the conflicting samples from the others.\nBuilding on these insights, we develop a novel dynamic contrastive decoding method that removes undesirable logits inferred from the less confident modality components based on answer confidence. \nFor models that do not provide logits, we also introduce two prompt-based strategies to mitigate the conflicts.\nOur methods achieve promising improvements in accuracy on both the ViQuAE and InfoSeek datasets.\nSpecifically, using LLaVA-34B, our proposed dynamic contrastive decoding improves an average accuracy of 2.24%.", "title_embedding_index": 13867, "title_abs_embedding_index": 13892}, {"title": "GSBAK:top-KGeometric Score-based Black-box Attack", "link_suffix": "/forum?id=htX7AoHyln", "link": "https://openreview.net/forum?id=htX7AoHyln", "pdf_link": "https://openreview.net/pdf?id=htX7AoHyln", "keywords": "Adversarial Attack, Black-box Attack, Score-based Attack, Top-K Attack", "abstract": "Existing score-based adversarial attacks mainly focus on crafting $top$-1 adversarial examples against classifiers with single-label classification. Their attack success rate and query efficiency are often less than satisfactory, particularly under small perturbation requirements; moreover, the vulnerability of classifiers with multi-label learning is yet to be studied. In this paper, we propose a comprehensive surrogate free score-based attack, named \\b geometric \\b score-based \\b black-box \\b attack (GSBA$^K$), to craft adversarial examples in an aggressive $top$-$K$ setting for both untargeted and targeted attacks, where the goal is to change the $top$-$K$ predictions of the target classifier. We introduce novel gradient-based methods to find a good initial boundary point to attack. Our iterative method employs novel gradient estimation techniques, particularly effective in $top$-$K$ setting, on the decision boundary to effectively exploit the geometry of the decision boundary. Additionally, GSBA$^K$ can be used to attack against classifiers with $top$-$K$ multi-label learning. Extensive experiential results on ImageNet and PASCAL VOC datasets validate the effectiveness of GSBA$^K$ in crafting $top$-$K$ adversarial examples.", "title_embedding_index": 13868, "title_abs_embedding_index": 13893}, {"title": "Beyond In-Context Learning: Enhancing Long-form Generation of Large Language Models via Task-Inherent Attribute Guidelines", "link_suffix": "/forum?id=Dj9wssUmLn", "link": "https://openreview.net/forum?id=Dj9wssUmLn", "pdf_link": "https://openreview.net/pdf?id=Dj9wssUmLn", "keywords": "In-context Learning, Prompt Optimization, Long-form Generation", "abstract": "In-context learning (ICL) is an important yet not fully understood ability of pre-trained large language models (LLMs). It can greatly enhance task performance using a few examples, termed demonstrations, without fine-tuning. Although effective in question answering, ICL often underperforms in long-form generation tasks such as summarization. Under appropriately realistic assumptions, we empirically and theoretically show that ICL demonstrations alone are insufficient to teach LLMs the task\u2019s language and format distributions for generation.\nWe argue for explicit exposure to the task distributions and hypothesize that defining them by prompting enhances model performance. To this end, we present LongGuide, which efficiently generates two parallel streams of guidelines capturing task language and format properties: (i) Metric Guidelines (MGs) that instruct models to optimize self-evaluated metrics; and (ii) Output Constraint Guidelines (OCGs) that constrain generation at both token and sentence levels. LongGuide automatically selects the best combination of guidelines, improving both strong open- and closed-source LLMs by over 5% in both zero- and few-shot settings. We show that LongGuide is generalizable, learnable by weak models to enhance strong ones, and integrates synergistically with automatic prompt optimizers.", "title_embedding_index": 13869, "title_abs_embedding_index": 13894}, {"title": "Translation and Fusion Improves Zero-shot Cross-lingual Information Extraction", "link_suffix": "/forum?id=qrTrnrEi9d", "link": "https://openreview.net/forum?id=qrTrnrEi9d", "pdf_link": "https://openreview.net/pdf?id=qrTrnrEi9d", "keywords": "large language model, multilingual, information extraction, low-resource language", "abstract": "Large language models (LLMs) combined with instruction tuning have shown significant progress in information extraction (IE) tasks, exhibiting strong generalization capabilities to unseen datasets by following annotation guidelines. However, their applicability to low-resource languages remains limited due to lack of both labeled data for fine-tuning, and unlabeled text for pre-training. In this paper, we propose TransFusion, a framework in which models are fine-tuned to use English translations of low-resource language data, enabling more precise predictions through annotation fusion. Based on TransFusion, we introduce GoLLIE-TF, a cross-lingual instruction-tuned LLM for IE tasks, designed to close the performance gap between high and low-resource languages. Our experiments across twelve multilingual IE datasets spanning 50 languages demonstrate that GoLLIE-TF achieves better cross-lingual transfer over the base model. In addition, we show that TransFusion significantly improves low-resource language named entity recognition when applied to proprietary models such as GPT-4 (+5 F1) with a prompting approach, or fine-tuning different language models including decoder-only (+14 F1) and encoder-only (+13 F1) architectures.", "title_embedding_index": 13870, "title_abs_embedding_index": 13895}, {"title": "It's Not a Modality Gap: Characterizing and Addressing the Contrastive Gap", "link_suffix": "/forum?id=wE8wJXgI9T", "link": "https://openreview.net/forum?id=wE8wJXgI9T", "pdf_link": "https://openreview.net/pdf?id=wE8wJXgI9T", "keywords": "Multi Modal Representation Learning, Contrastive Representation Learning, Modality Gap, CLIP", "abstract": "Learning jointly from images and texts using contrastive pre-training has emerged as an effective method to train large-scale models with a strong grasp of semantic image concepts. For instance, CLIP, pre-trained on a large corpus of web data, excels in tasks like zero-shot image classification, object detection, geolocalization, and more. These contrastive models embed input images and texts into a shared representational space. Recently, it was claimed that models like CLIP show amodality gap, where image and text embeddings occupy disjoint areas in the representational space. Previous studies attribute this gap to factors like data artifacts (mismatched pairs), model architecture artifacts (the cone effect), and the nature of the loss landscape (getting stuck in local minima). We demonstrate that, even after accounting for these factors, and even when using thesame modality, the contrastive loss actuallycreatesa gap during training. As a result, we propose renaming this phenomenon thecontrastive gap. We show that the contrastive gap is exacerbated by training with small batch sizes in high-dimensional spaces, causing embeddings of each modality to occupy small disjoint portions of the latent space. Our experiments show that minimizing the contrastive gap via the addition of uniformity and alignment terms optimizes the representational space and conveys better performance on downstream tasks such as zero-shot image classification and multi-modal arithmetic.", "title_embedding_index": 13871, "title_abs_embedding_index": 13896}, {"title": "LGDiffGait: Local and Global Difference Learning for Gait Recognition with Silhouettes", "link_suffix": "/forum?id=4ZhUKd05QM", "link": "https://openreview.net/forum?id=4ZhUKd05QM", "pdf_link": "https://openreview.net/pdf?id=4ZhUKd05QM", "keywords": "Gait Recognition; Movement Difference Modeling; Temporal Modeling", "abstract": "The subtle differences between consecutive frames of a gait video sequence are crucial for accurate gait identification, as they reflect the distinctive movement of various body parts during an individual\u2019s walk. However, most existing methods often focus on capturing spatial-temporal features of entire gait sequences only, which results in the neglect of these nuances. To address the limitation, in this paper, we propose a new approach, named Local and Global Difference Learning for Gait Recognition with Silhouettes (LGDiffGait). Specifically, the differences within gait sequences are explicitly modeled at two levels: local window-level and global sequence-level. For the local window-level, we apply sliding windows along the temporal dimension to aggregate the window-level information, and the local movement is defined as the difference between pooled features of adjacent frames within each window. For the global sequence-level, global pooling across the entire sequence is employed, which is followed by subtraction to capture overall movement differences. Moreover, after difference feature learning, we develop a temporal alignment module to align these extracted local and global differences with the overall sequence dynamics, ensuring temporal consistency. By explicitly modeling these differences, LGDiffGait can capture the subtle movements of different body parts, enabling the extraction of more discriminative features. Our experimental results demonstrate that LGDiffGait achieves state-of-the-art performance on four publicly available datasets.", "title_embedding_index": 13872, "title_abs_embedding_index": 13897}, {"title": "TOSN-Trans\uff1aTransparent Object Segmentation Network with Transformer", "link_suffix": "/forum?id=Rhclu9eWxU", "link": "https://openreview.net/forum?id=Rhclu9eWxU", "pdf_link": "https://openreview.net/pdf?id=Rhclu9eWxU", "keywords": "RGB-D, glass segmentation, feature fusion, dual-network, efficient transformer, boundary optimization", "abstract": "Due to the optical properties of glass materials, most glass appears transparent in RGB images. However, in depth images, different acquisition methods make glass visible. Therefore, Therefore, using RGB-D dual-channel feature input makes it easier to recognize and segment glass objects. Building on this concept, we propose a multi-layer symmetrical dual-channel network architecture, which can effectively realize trans-modal feature fusion of RGB-D images based on attention mechanism, and integrate Convolutional and Transformer architectures to extract local features and non-local dependencies, respectively. To further enhance segmentation accuracy and efficiency, this paper also designs a boundary optimization module. This module constructs a distance map based on edge prediction guidance, enabling high-precision glass edge recognition. To support this work, we collect a new dataset comprising 5551 sets of calibrated RGB-D images. The effectiveness and accuracy of the proposed glass segmentation method are rigorously evaluated quantitatively and qualitatively. The code for this paper has been published at:https://github.com/Jaccury/RGB-D-Transparent-object-segmentation.", "title_embedding_index": 13873, "title_abs_embedding_index": 13898}, {"title": "Discovering Latent Structural Causal Models from Spatio-Temporal Data", "link_suffix": "/forum?id=ZKRHiu5kE4", "link": "https://openreview.net/forum?id=ZKRHiu5kE4", "pdf_link": "https://openreview.net/pdf?id=ZKRHiu5kE4", "keywords": "Causal Inference, Causal Represetation Learning, Spatio-Temporal Dynamic Modeling, Variational Inference, Probablistic Graphical Model", "abstract": "Many important phenomenon in scientific fields such as climate, neuroscience and epidemiology are naturally represented as spatiotemporal gridded data with complex interactions. Inferring causal relationships from these data is a difficult problem compounded by the high dimensionality of such data and the correlations between spatially proximate points. We present SPACY (SPAtiotemporal Causal discoverY), a novel framework based on variational inference, designed to explicitly model latent time-series and their causal relationships from spatially confined modes in the data. Our method uses an end-to-end training process that maximizes an evidence-lower bound (ELBO) for the data likelihood. Theoretically, we show that, under some conditions, the latent variables are identifiable up to transformation by an invertible matrix. Empirically, we show that SPACY outperforms state-of-the-art baselines on synthetic data, remains scalable for large grids, and identifies key known phenomena from real-world climate data.", "title_embedding_index": 13874, "title_abs_embedding_index": 13899}]
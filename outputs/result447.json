[
    {
        "title": "DFRot: Achieving Outlier-Free and Massive Activation-Free for Rotated LLMs with Refined Rotation",
        "link_suffix": "/forum?id=XtXa6hoNrU",
        "link": "https://openreview.net/forum?id=XtXa6hoNrU",
        "pdf_link": "https://openreview.net/pdf?id=XtXa6hoNrU",
        "keywords": "large language models, rotational, quantization, orthogonal Procrustes transforms, Outlier-Free and Massive Activation-Free",
        "abstract": "Using rotational invariance to eliminate outliers in large language models (LLMs) has recently gained considerable attention, especially in the context of quantization. Prior studies have shown that in low-precision quantization scenarios, such as 4-bit weights and 4-bit activations~(W4A4), randomized Hadamard transforms can achieve significantly higher accuracy than randomized orthogonal transforms. Notably, the reason behind this phenomena remains unknown. In this paper, we find that these transformations show substantial improvement in eliminating outliers for common tokens and achieve similar quantization error. The primary reason for the accuracy difference lies in the fact that randomized Hadamard transforms can slightly reduce the quantization error for tokens with massive activations while randomized orthogonal transforms increase the quantization error. Due to the extreme rarity of these tokens and their critical impact on model accuracy, we consider this a long-tail optimization problem, and therefore construct a simple yet effective method: a weighted loss function. Additionally, we propose an optimization strategy for the rotational matrix that involves alternating optimization of quantization parameters while employing orthogonal Procrustes transforms to refine the orthogonal matrix. This makes the distribution of the rotated activation values more conducive to quantization, especially for tokens with massive activations. Our method enhances the Rotated LLMs by achieving dual free, \\textit{Outlier-Free} and \\textit{Massive Activation-Free}, dubbed as DFRot. Extensive experiments demonstrate the effectiveness and efficiency of DFRot. By tuning the rotational matrix using just a single sample, DFRot achieves a perplexity improvement of 0.25 and 0.21 on W4A4KV4 and W4A4KV16, respectively, for LLaMA3-8B, a model known for its quantization challenges. Code is anonymously available at \\url{https://anonymous.4open.science/r/DFRot-8FE3}."
    },
    {
        "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
        "link_suffix": "/forum?id=8m7p4k6Zeb",
        "link": "https://openreview.net/forum?id=8m7p4k6Zeb",
        "pdf_link": "https://openreview.net/pdf?id=8m7p4k6Zeb",
        "keywords": "Synthetic Data, LLM finetuning, Long Context, Retrieval",
        "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to accurately retrieve information and maintain reasoning capabilities when processing long-context inputs. To address these limitations, we propose a finetuning approach utilizing a carefully designed synthetic dataset comprising numerical key-value retrieval tasks. Our experiments on models like GPT-3.5 Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset significantly improves LLMs' information retrieval and reasoning capabilities in longer-context settings. We present an analysis of the finetuned models, illustrating the transfer of skills from synthetic to real task evaluations (e.g., $10.5%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5 Turbo). We also find that finetuned LLMs' performance on general benchmarks remains almost constant while LLMs finetuned on other baseline long-context augmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B finetuned on our synthetic data cause no performance drop while other baseline data can cause a drop that ranges from $2.33%$ to $6.19%$). Our study highlights the potential of finetuning on synthetic data for improving the performance of LLMs on longer-context tasks."
    },
    {
        "title": "Learning Relational Invariance for Out-of-Distribution Molecular Relational Learning",
        "link_suffix": "/forum?id=etrY4TegYb",
        "link": "https://openreview.net/forum?id=etrY4TegYb",
        "pdf_link": "https://openreview.net/pdf?id=etrY4TegYb",
        "keywords": "molecular relational learning, out of distribution, invariant learning",
        "abstract": "Molecular Relational Learning (MRL) expands the scope of molecular representation learning by incorporating additional molecules, aiming to understand  the interactions between pairs of molecules. While MRL has shown promising results, the existing methods have not been able to generalise to real world scenarios. Invariant learning is pivotal in addressing Out-of-Distribution (OOD) generalization challenges. However, two major obstacles impede the progress of invariant learning in MRL: (1) Unlike single-molecular cases, interactions between molecules introduce added complexity, with a heavy reliance on molecular substructure recognition, often leading to the misspecification of invariant patterns. (2) Accurate modeling of interactions can effectively improve generalizations. However, previous methods focus on node interaction, which is limited by the expressiveness of GNN, and long-range interactions cannot be captured. To address these, we propose a novel Relational Invariant Learning (RIL) framework that  uses a multi-granularity interaction approach to improve OOD generalization for MRL, and the framework is denoted as RILOOD. Specifically,  we model the environment diversity distribution of molecules by mixup-based Conditional Modeling. Then, we employ a multi-granularity refinement strategy to learn the Context-Aware Representation, which is essential for capturing multi-level interaction. We further design an invariant learning module to capture the invariant patterns that robustly generalize across unseen environments. Extensive experiments on molecular datasets show that our method achieves stronger generalization against state-of-the-art methods in the presence of various distribution shifts. Our code will be released after our paper is accepted."
    },
    {
        "title": "GaussianFocus: Constrained Attention Focus for 3D Gaussian Splatting",
        "link_suffix": "/forum?id=LieTse3fQB",
        "link": "https://openreview.net/forum?id=LieTse3fQB",
        "pdf_link": "https://openreview.net/pdf?id=LieTse3fQB",
        "keywords": "3D Gaussian Splatting, 3D Reconstruction, Novel View Synthesis, Neural Rendering, Large Scene Reconstruction",
        "abstract": "Recent developments in 3D reconstruction and neural rendering have significantly propelled the capabilities of photo-realistic 3D scene rendering across various academic and industrial fields. The 3D Gaussian Splatting technique, alongside its derivatives, integrates the advantages of primitive-based and volumetric representations to deliver top-tier rendering quality and efficiency. Despite these advancements, the method tends to generate excessive redundant noisy Gaussians overfitted to every training view, which degrades the rendering quality. Additionally, while 3D Gaussian Splatting excels in small-scale and object-centric scenes, its application to larger scenes is hindered by constraints such as limited video memory, excessive optimization duration, and variable appearance across views. To address these challenges, we introduce GaussianFocus, an innovative approach that incorporates a patch attention algorithm to refine rendering quality and implements a Gaussian constraints strategy to minimize redundancy. Moreover, we propose a subdivision reconstruction strategy for large-scale scenes, dividing them into smaller mergeable blocks for individual training. Our results indicate that GaussianFocus significantly reduces unnecessary Gaussians and enhances rendering quality, surpassing existing State-of-The-Art (SoTA) methods. Furthermore, we demonstrate the capability of our approach to effectively manage and render large scenes, such as urban environments, maintaining high fidelity in the visual output."
    },
    {
        "title": "Enhancing Document Understanding with Group Position Embedding: A Novel Approach to Incorporate Layout Information",
        "link_suffix": "/forum?id=Dj9a4zQsSl",
        "link": "https://openreview.net/forum?id=Dj9a4zQsSl",
        "pdf_link": "https://openreview.net/pdf?id=Dj9a4zQsSl",
        "keywords": "DocAI, LLM, Position Embedding",
        "abstract": "Recent advancements in document understanding have been dominated by leveraging large language models (LLMs) and multimodal large models. However, enabling LLMs to comprehend complex document layouts and structural information often necessitates intricate network modifications or costly pre-training, limiting their practical applicability. In this paper, we introduce Group Position Embedding (GPE), a novel and efficient technique to enhance the layout understanding capabilities of LLMs without architectural changes or additional pre-training. GPE achieves this by strategically grouping the attention heads and feeding each group with distinct positional embeddings, effectively encoding layout information relevant to document comprehension. This simple yet powerful method allows for effective integration of layout information within the existing LLM framework.  We evaluate GPE against several competitive baselines across five mainstream document tasks. We also introduce a challenging benchmark called BLADE, specifically designed to assess layout comprehension. \n Extensive experiments on both established and BLADE benchmarks confirm the efficacy of GPE in significantly advancing the state-of-the-art in document understanding."
    },
    {
        "title": "Towards Realistic UAV Vision-Language Navigation: Platform, Benchmark, and Methodology",
        "link_suffix": "/forum?id=rUvCIvI4eB",
        "link": "https://openreview.net/forum?id=rUvCIvI4eB",
        "pdf_link": "https://openreview.net/pdf?id=rUvCIvI4eB",
        "keywords": "Unmanned Aerial Vehicle, Drone, Vision-Language Navigation",
        "abstract": "Developing agents capable of navigating to a target location based on language instructions and visual information, known as vision-language navigation (VLN), has attracted widespread interest. Most research has focused on ground-based agents, while UAV-based VLN remains relatively underexplored. Recent efforts in UAV vision-language navigation predominantly adopt ground-based VLN settings, relying on predefined discrete action spaces and neglecting the inherent disparities in agent movement dynamics and the complexity of navigation tasks between ground and aerial environments. To address these disparities and challenges, we propose solutions from three perspectives: platform, benchmark, and methodology. To enable realistic UAV trajectory simulation in VLN tasks, we propose the OpenUAV platform,  which features diverse environments, realistic flight control, and extensive algorithmic support. We further construct a target-oriented VLN dataset consisting of approximately 12k trajectories on this platform, serving as the first dataset specifically designed for realistic UAV VLN tasks. To tackle the challenges posed by complex aerial environments, we propose an assistant-guided UAV object search benchmark called UAV-Need-Help, which provides varying levels of guidance information to help UAVs better accomplish realistic VLN tasks. We also propose a UAV navigation LLM that, given multi-view images, task descriptions, and assistant instructions, leverages the multimodal understanding capabilities of the MLLM to jointly process visual and textual information, and performs hierarchical trajectory generation. The evaluation results of our method significantly outperform the baseline models, while there remains a considerable gap between our results and those achieved by human operators, underscoring the challenge presented by the UAV-Need-Help task."
    },
    {
        "title": "SlowFast-LLaVA: A strong training-free baseline for video large language models",
        "link_suffix": "/forum?id=WkpqUVcSTy",
        "link": "https://openreview.net/forum?id=WkpqUVcSTy",
        "pdf_link": "https://openreview.net/pdf?id=WkpqUVcSTy",
        "keywords": "Multimodal Large Language Model, Video Understanding, Video Question-Answering",
        "abstract": "We propose SlowFast-LLaVA (or SF-LLaVA for short), a training-free video large language model (LLM) that can jointly capture the detailed spatial semantics and long-range temporal context without exceeding the token budget of commonly used LLMs. This is realized by using a two-stream SlowFast design of inputs for Video LLMs to aggregate features from sampled video frames in an effective way. Specifically, the Slow pathway extracts features at a low frame rate while keeping as many spatial details as possible (e.g., with 24x24 tokens), and the Fast pathway operates on a high frame rate but uses a larger spatial pooling stride (e.g., downsampling 6x) to focus on the motion cues. As a result, this design allows us to adequately capture both spatial and temporal features that are beneficial for understanding details in the video. Experimental results show that SF-LLaVA outperforms existing training-free methods on a wide range of video tasks. On some benchmarks, it achieves comparable or even better performance compared to state-of-the-art Video LLMs that are fine-tuned on video datasets."
    },
    {
        "title": "Orator: LLM-Guided Multi-Shot Speech Video Generation",
        "link_suffix": "/forum?id=Bz6eAiOjrI",
        "link": "https://openreview.net/forum?id=Bz6eAiOjrI",
        "pdf_link": "https://openreview.net/pdf?id=Bz6eAiOjrI",
        "keywords": "Speech video generation, Multimodal video generation, Human video dataset, LLM-directed human video synthesis",
        "abstract": "In this work, we propose a novel system for automatically generating multi-shot speech videos with natural camera transitions, using input text lines and reference images from various camera angles. Existing human video generation datasets and methods are largely centered on faces or half-body single-shot videos, thus lack the capacity to produce multi-shot full-body dynamic movements from different camera angles.  Recognizing the lack of suitable datasets, we first introduce TalkCuts, a large-scale dataset containing over 500 hours of human speech videos with diverse camera shots, rich 3D SMPL-X motion annotations, and camera trajectories, covering a wide range of identities. Based on this dataset, we further propose an LLM-guided multi-modal generation framework, named Orator, where the LLM serves as a multi-role director, generating detailed instructions for camera transitions, speaker gestures, and vocal delivery. This enables the system to generate coherent long-form videos through a multi-modal video generation module. Extensive experiments show that our framework successfully generates coherent and engaging multi-shot speech videos. Both the dataset and the model will be made publicly available."
    },
    {
        "title": "TFCounter: Polishing Gems for Training-Free Object Counting",
        "link_suffix": "/forum?id=ow51wrwVtI",
        "link": "https://openreview.net/forum?id=ow51wrwVtI",
        "pdf_link": "https://openreview.net/pdf?id=ow51wrwVtI",
        "keywords": "Object Counting, Training-Free Method",
        "abstract": "Object counting is a challenging task with broad application prospects in security surveillance, traffic management, and disease diagnosis. Existing object counting methods face a tri-fold challenge: achieving superior performance, maintaining high generalizability, and minimizing annotation costs. We develop a novel training-free class-agnostic object counter, TFCounter, which is prompt-context-aware via the cascade of the essential elements in large-scale foundation models. This approach employs an iterative counting framework with a dual prompt system to recognize a broader spectrum of objects varying in shape, appearance, and size. Besides, it introduces an innovative context-aware similarity module incorporating background context to enhance accuracy within messy scenes. To demonstrate cross-domain generalizability,  we collect a novel counting dataset named BIKE-1000, including exclusive 1000 images of shared bicycles from Meituan. Extensive experiments on FSC-147, CARPK, and BIKE-1000 datasets demonstrate that TFCounter outperforms existing leading training-free methods and exhibits competitive results compared to trained counterparts."
    },
    {
        "title": "Fine-Grained Verifiers: Preference Modeling as Next-token  in Vision-Language Alignment",
        "link_suffix": "/forum?id=cJQ1K2fjpD",
        "link": "https://openreview.net/forum?id=cJQ1K2fjpD",
        "pdf_link": "https://openreview.net/pdf?id=cJQ1K2fjpD",
        "keywords": "Large Models; Alignment; Hallucination",
        "abstract": "The recent advancements in large language models (LLMs) and pre-trained vision models have accelerated the development of vision-language large models (VLLMs), enhancing the interaction between visual and linguistic modalities. Despite their notable success across various domains, VLLMs face challenges in modality alignment, which can lead to issues like hallucinations and unsafe content generation. Current alignment techniques often rely on coarse feedback and external datasets, limiting scalability and performance. In this paper, we propose FiSAO (Fine-Grained Self-Alignment Optimization), a novel self-alignment method that utilizes the model\u2019s own visual encoder as a fine-grained verifier to improve vision-language alignment without the need for additional data. By leveraging token-level feedback from the vision encoder, FiSAO significantly improves vision-language alignment, even surpassing traditional preference tuning methods that require additional data. Through both theoretical analysis and experimental validation, we demonstrate that FiSAO effectively addresses the misalignment problem in VLLMs, marking the first instance of token-level rewards being applied to such models.  Our code is avaliable at \\url{https://anonymous.4open.science/r/FISAO-57F0/}."
    },
    {
        "title": "Unlearning-based Neural Interpretations",
        "link_suffix": "/forum?id=PBjCTeDL6o",
        "link": "https://openreview.net/forum?id=PBjCTeDL6o",
        "pdf_link": "https://openreview.net/pdf?id=PBjCTeDL6o",
        "keywords": "Explainability, Attribution, Debiasing, Bias",
        "abstract": "Gradient-based interpretations often require an anchor point of comparison to avoid saturation in computing feature importance. We show that current baselines defined using static functions \u2014 constant mapping, averaging or blurring \u2014 inject harmful colour, texture or frequency assumptions that deviate from model behaviour. This leads to accumulation of irregular gradients, resulting in attribution maps that are biased, fragile and manipulable. Departing from the static approach, we propose $\\texttt{UNI}$ to compute an (un)learnable, debiased and adaptive baseline by perturbing the input towards an $\\textit{unlearning direction}$ of steepest ascent. Our method discovers reliable baselines and succeeds in erasing salient features, which in turn locally smooths the high-curvature decision boundaries. Our analyses point to unlearning as a promising avenue for generating faithful, efficient and robust interpretations."
    },
    {
        "title": "On the Convergence of Symbolic Pattern Forests and Silhouette Coefficients for Robust Time Series Clustering",
        "link_suffix": "/forum?id=w5h443GIGo",
        "link": "https://openreview.net/forum?id=w5h443GIGo",
        "pdf_link": "https://openreview.net/pdf?id=w5h443GIGo",
        "keywords": "Data Mining, Time Series, Clustering",
        "abstract": "Clustering algorithms are fundamental to data mining, serving dual roles as exploratory tools and preprocessing steps for advanced analytics. A persistent challenge in this domain is determining the optimal number of clusters, particularly for time series data where prevalent algorithms like k-means and k-shape require a priori knowledge of cluster quantity. This paper presents the first approach to time series clustering that does not require prior specification of cluster numbers. We introduce a novel extension of the Symbolic Pattern Forest (SPF) algorithm that automatically optimizes the number of clusters for time series datasets. Our method integrates SPF for cluster generation with the Silhouette Coefficient, computed on a two-stage vector representation: first transforming time series into Symbolic Aggregate approXimation (SAX) representations, then deriving both bag-of-words and TF-IDF vectors. Rigorous evaluation on diverse datasets from the UCR archive demonstrates that our approach significantly outperforms traditional baseline methods. This work contributes to the field of time series analysis by providing a truly unsupervised, data-driven approach to clustering, with potential impacts across various temporal data mining applications where the underlying number of clusters is unknown or variable."
    },
    {
        "title": "Minimal Impact ControlNet: Advancing Multi-ControlNet Integration",
        "link_suffix": "/forum?id=rzbSNDXgGD",
        "link": "https://openreview.net/forum?id=rzbSNDXgGD",
        "pdf_link": "https://openreview.net/pdf?id=rzbSNDXgGD",
        "keywords": "generative models, ControlNet",
        "abstract": "With the advancement of diffusion models, there is a growing demand for high-quality, controllable image generation, particularly through methods that utilize one or multiple control signals based on ControlNet. However, in current ControlNet training, each control is designed to influence all areas of an image, which can lead to conflicts when different control signals are expected to manage different parts of the image in practical applications. This issue is especially pronounced with edge-type control conditions, where regions lacking boundary information often represent low-frequency signals, referred to as silent control signals. When combining multiple ControlNets, these silent control signals can suppress the generation of textures in related areas, resulting in suboptimal outcomes. To address this problem, we propose Minimal Impact ControlNet. Our approach mitigates conflicts through three key strategies: constructing a balanced dataset, combining and injecting feature signals in a balanced manner, and addressing the asymmetry in the score function\u2019s Jacobian matrix induced by ControlNet. These improvements enhance the compatibility of control signals, allowing for freer and more harmonious generation in areas with silent control signals."
    },
    {
        "title": "Distillation-Free One-Step Diffusion for Real-World Image Super-Resolution",
        "link_suffix": "/forum?id=2ogxyVlHmi",
        "link": "https://openreview.net/forum?id=2ogxyVlHmi",
        "pdf_link": "https://openreview.net/pdf?id=2ogxyVlHmi",
        "keywords": "One-Step Diffusion, Image Super-Resolution, Distillation-Free, Diffusion Models",
        "abstract": "Diffusion models have been achieving excellent performance for real-world image super-resolution (Real-ISR) with considerable computational costs. Current approaches are trying to derive one-step diffusion models from multi-step counterparts through knowledge distillation. However, these methods incur substantial training costs and may constrain the performance of the student model by the teacher's limitations. To tackle these issues, we propose DFOSD, a Distillation-Free One-Step Diffusion model. Specifically, we propose a noise-aware discriminator (NAD) to participate in adversarial training, further enhancing the authenticity of the generated content. Additionally, we improve the perceptual loss with edge-aware DISTS (EA-DISTS) to enhance the model's ability to generate fine details. Our experiments demonstrate that, compared with previous diffusion-based methods requiring dozens or even hundreds of steps, our DFOSD achieves comparable or even superior results in both objective metrics and subjective evaluations. Our DFOSD also abtains higher performance and efficiency compared with other one-step diffusion methods. We will release code and models."
    },
    {
        "title": "TASAR: Transfer-based Attack on Skeletal Action Recognition",
        "link_suffix": "/forum?id=I393kV3bz4",
        "link": "https://openreview.net/forum?id=I393kV3bz4",
        "pdf_link": "https://openreview.net/pdf?id=I393kV3bz4",
        "keywords": "Human Activity Recognition, Transfer-based adversarial attack",
        "abstract": "Skeletal sequences, as well-structured representations of human behaviors, play a vital role in Human Activity Recognition (HAR). The transferability of adversarial skeletal sequences enables attacks in real-world HAR scenarios, such as autonomous driving, intelligent surveillance, and human-computer interactions. However, most existing skeleton-based HAR (S-HAR) attacks are primarily designed for white-box scenarios and exhibit weak adversarial transferability. Therefore, they cannot be considered true transfer-based S-HAR attacks. More importantly, the reason for this failure remains unclear. In this paper, we study this phenomenon through the lens of loss surface, and find that its sharpness contributes to the weak transferability in S-HAR. Inspired by this observation, we assume and empirically validate that smoothening the rugged loss landscape could potentially improve adversarial transferability in S-HAR. To this end, we propose the first Transfer-based Attack on Skeletal Action Recognition, TASAR. TASAR explores the smoothed model posterior without requiring surrogate re-training, which is achieved by a new post-train Dual Bayesian optimization strategy. Furthermore, unlike previous transfer-based attacks that treat each frame independently and overlook temporal coherence within sequences, TASAR incorporates motion dynamics into the Bayesian attack gradient, effectively disrupting the spatial-temporal coherence of S-HARs. To exhaustively evaluate the effectiveness of existing methods and our method, we build the first large-scale robust S-HAR benchmark, comprising 7 S-HAR models, 10 attack methods, 3 S-HAR datasets and 2 defense methods. Extensive results demonstrate the superiority of TASAR. Our benchmark enables easy comparisons for future studies, with the code available in the anonymous linkhttps://anonymous.4open.science/r/RobustBenchHAR-5492/README.mdand supplementary material."
    },
    {
        "title": "Toward Practical Learning-based Frequency Estimation without Ground Truth",
        "link_suffix": "/forum?id=dSuC2qFXqB",
        "link": "https://openreview.net/forum?id=dSuC2qFXqB",
        "pdf_link": "https://openreview.net/pdf?id=dSuC2qFXqB",
        "keywords": "sketching algorithms, ML for streaming data, frequency estimation",
        "abstract": "Estimating the frequency of items on the high-volume, fast data stream has been extensively studied in many areas, such as database and network measurement. Traditional sketch algorithms only allow to give very rough estimates with limited memory cost, whereas some learning-augmented algorithms have been proposed recently, their offline framework requires actual frequencies that are challenging to access in general for training, and speed is too slow for real-time processing, despite the still coarse-grained accuracy. To this end, we propose a more practical learning-based estimation framework namely UCL-sketch, by following the line of equation-based sketch to estimate per-key frequencies. In a nutshell, there are two key techniques: online training via equivalent learning without ground truth, and highly scalable architecture with logical estimation buckets. We implemented experiments on both real-world and synthetic datasets. The results demonstrate that our method greatly outperforms existing state-of-the-art sketches regarding per-key accuracy and distribution, while preserving resource efficiency. Our code is attached in the supplementary material, and will be made publicly available."
    },
    {
        "title": "Autoverse: an Evolvable Game Language for Learning Robust Embodied Agents",
        "link_suffix": "/forum?id=ysQiaWhnCN",
        "link": "https://openreview.net/forum?id=ysQiaWhnCN",
        "pdf_link": "https://openreview.net/pdf?id=ysQiaWhnCN",
        "keywords": "open-ended learning, reinforcement learning, imitation learning, evolution, search",
        "abstract": "We introduce Autoverse, an evolvable, domain-specific language for single-player 2D grid-based games, and demonstrate its use as a scalable training ground for Open-Ended Learning (OEL) algorithms. Autoverse uses cellular-automaton-like rewrite rules to describe game mechanics, allowing it to express various game environments (e.g. mazes, dungeons, sokoban puzzles) that are popular testbeds for Reinforcement Learning (RL) agents. Each rewrite rule can be expressed as a series of simple convolutions, allowing for environments to be parallelized on the GPU, thereby drastically accelerating RL training. Using Autoverse, we propose jump-starting open-ended learning by imitation learning from search. In such an approach, we first evolve Autoverse environments (their rules and initial map topology) to maximize the number of iterations required by greedy tree search to discover a new best solution, producing a curriculum of increasingly complex environments and playtraces. We then distill these expert playtraces into a neural-network-based policy using imitation learning. Finally, we use the learned policy as a starting point for open-ended RL, where new training environments are continually evolved to maximize the RL player agent's value function error (a proxy for its regret, or the learnability of generated environments), finding that this approach improves the performance and generality of resultant player agents."
    },
    {
        "title": "Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions: Benchmarking Large Language Models",
        "link_suffix": "/forum?id=uV3Gdoq2ez",
        "link": "https://openreview.net/forum?id=uV3Gdoq2ez",
        "pdf_link": "https://openreview.net/pdf?id=uV3Gdoq2ez",
        "keywords": "peer review, large language models",
        "abstract": "Large Language Models (LLMs) have demonstrated wide-ranging applications across various fields and have shown significant potential in the academic peer-review process. However, existing applications are primarily limited to static review generation based on submitted papers, which fail to capture the dynamic and iterative nature of real-world peer reviews. In this paper, we reformulate the peer-review process as a multi-turn, long-context dialogue, incorporating distinct roles for authors, reviewers, and decision makers. We construct a comprehensive dataset containing over 30,854 papers with 110,642 reviews collected from the top-tier conferences. This dataset is meticulously designed to facilitate the applications of LLMs for multi-turn dialogues, effectively simulating the complete peer-review process. Furthermore, we propose a series of metrics to evaluate the performance of LLMs for each role under this reformulated peer-review setting, ensuring fair and comprehensive evaluations. We believe this work provides a promising perspective on enhancing the LLM-driven peer-review process by incorporating dynamic, role-based interactions. It aligns closely with the iterative and interactive nature of real-world academic peer review, offering a robust foundation for future research and development in this area."
    },
    {
        "title": "HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts",
        "link_suffix": "/forum?id=2eFq6S35iB",
        "link": "https://openreview.net/forum?id=2eFq6S35iB",
        "pdf_link": "https://openreview.net/pdf?id=2eFq6S35iB",
        "keywords": "Generalized Category Discovery",
        "abstract": "Generalized Category Discovery (GCD) is a challenging task in which, given a partially labelled dataset, models must categorize all unlabelled instances, regardless of whether they come from labelled categories or from new ones. In this paper, we challenge a remaining assumption in this task: that all images share the same \\underline{domain}. Specifically, we introduce a new task and method to handle GCD when the unlabelled data also contains images from different domains to the labelled set. Our proposed `HiLo' networks extract High-level semantic and Low-level domain features, before minimizing the mutual information between the representations. Our intuition is that the clusterings based on domain information and semantic information should be independent. We further extend our method with a specialized domain augmentation tailored for the GCD task, as well as a curriculum learning approach. Finally, we construct a benchmark from corrupted fine-grained datasets as well as a large-scale evaluation on DomainNet with real-world domain shifts, reimplementing a number of GCD baselines in this setting. We demonstrate that HiLo outperforms SoTA category discovery models by a large margin on all evaluations."
    },
    {
        "title": "Exact Recovery Guarantees for Parameterized Nonlinear System Identification Problem under Adversarial Attacks",
        "link_suffix": "/forum?id=TKRIRI9tQv",
        "link": "https://openreview.net/forum?id=TKRIRI9tQv",
        "pdf_link": "https://openreview.net/pdf?id=TKRIRI9tQv",
        "keywords": "System identification, robust control, exact recovery",
        "abstract": "In this work, we study the system identification problem for parameterized nonlinear systems using basis functions under adversarial attacks. Motivated by the LASSO-type estimators, we analyze the exact recovery property of a nonsmooth estimator, which is generated by solving an embedded $\\ell_1$-loss minimization problem. First, we derive necessary and sufficient conditions for the well-specifiedness of the estimator and the uniqueness of global solutions to the underlying optimization problem. Next, we provide exact recovery guarantees for the estimator under two different scenarios of boundedness and Lipschitz continuity of the basis functions. The non-asymptotic exact recovery is guaranteed with high probability, even when there are more severely corrupted data than clean data. Finally, we numerically illustrate the validity of our theory. This is the first study on the sample complexity analysis of a nonsmooth estimator for the nonlinear system identification problem."
    },
    {
        "title": "Differentially Private Bilevel Optimization",
        "link_suffix": "/forum?id=vgV4y086FY",
        "link": "https://openreview.net/forum?id=vgV4y086FY",
        "pdf_link": "https://openreview.net/pdf?id=vgV4y086FY",
        "keywords": "Bilevel optimization, differential privacy, nonconvex optimization, first-order methods",
        "abstract": "We present differentially private (DP) algorithms for bilevel optimization, a problem class that received significant attention lately in various machine learning applications.\nThese are the first DP algorithms for this task that are able to provide any desired privacy, while also avoiding Hessian computations which are prohibitive in large-scale settings.\nUnder the well-studied setting in which the upper-level is not necessarily convex and the lower-level problem is strongly-convex, our proposed gradient-based $(\\epsilon,\\delta)$-DP algorithm returns a point with hypergradient norm at most $\\widetilde{\\mathcal{O}}\\left((\\sqrt{d_\\mathrm{up}}/\\epsilon n)^{1/2}+(\\sqrt{d_\\mathrm{low}}/\\epsilon n)^{1/3}\\right)$ where $n$ is the dataset size, and $d_\\mathrm{up}/d_\\mathrm{low}$ are the upper/lower level dimensions.\nOur analysis covers constrained and unconstrained problems alike, accounts for mini-batch gradients, and applies to both empirical and population losses."
    },
    {
        "title": "Event Camera Object Detection at Arbitrary Frequencies",
        "link_suffix": "/forum?id=suyX1TOJJK",
        "link": "https://openreview.net/forum?id=suyX1TOJJK",
        "pdf_link": "https://openreview.net/pdf?id=suyX1TOJJK",
        "keywords": "Event Camera Object Detection, Low-Latency Vision, Label-Efficient Learning",
        "abstract": "Event cameras offer unparalleled advantages for real-time perception in dynamic environments, thanks to their microsecond-level temporal resolution and asynchronous operation. However, existing event-based object detection methods are limited by fixed-frequency paradigms, which fail to fully exploit the high-temporal resolution and adaptability of event cameras. To address these limitations, we propose FlexEvent, a novel event camera object detection framework that enables detection at arbitrary frequencies. FlexEvent consists of two key components: FlexFuser, an adaptive event-frame fusion module that integrates high-frequency event data with rich semantic information from RGB frames, and FAL, a frequency-adaptive learning mechanism that generates frequency-adjusted labels to enhance model generalization across varying operational frequencies. This combination allows FlexEvent to detect objects with high accuracy in both fast-moving and static scenarios, while adapting to dynamic environments. Extensive experiments on large-scale event camera datasets demonstrate that our approach surpasses state-of-the-art methods, achieving significant improvements in both standard and high-frequency settings. Notably, FlexEvent maintains robust performance when scaling from 20 Hz to 90 Hz and delivers accurate detection up to 180 Hz, proving its effectiveness in extreme conditions. Our framework sets a new benchmark for event-based object detection and paves the way for more adaptable, real-time vision systems. The code will be made publicly available to facilitate future research."
    },
    {
        "title": "Can LVLMs Describe Videos like Humans? A Five-in-One Video Annotations Benchmark for Better Human-Machine Comparison",
        "link_suffix": "/forum?id=Zggz6seq6F",
        "link": "https://openreview.net/forum?id=Zggz6seq6F",
        "pdf_link": "https://openreview.net/pdf?id=Zggz6seq6F",
        "keywords": "Video Caption, Video Understanding, LVLM Evaluation, Human-machine Comparison",
        "abstract": "Large vision-language models (LVLMs) have made significant strides in addressing complex video tasks, sparking researchers' interest in their human-like multimodal understanding capabilities. Video description serves as a fundamental task for evaluating video comprehension, necessitating a deep understanding of spatial and temporal dynamics, which presents challenges for both humans and machines. Thus, investigating whether LVLMs can describe videos as comprehensively as humans\u2014through reasonable human-machine comparisons using video captioning as a proxy task\u2014will enhance our understanding and application of these models. However, current benchmarks for video comprehension have notable limitations, including short video durations, brief annotations, and reliance on a single annotator's perspective. These factors hinder a comprehensive assessment of LVLMs' ability to understand complex, lengthy videos and prevent the establishment of a robust human baseline that accurately reflects human video comprehension capabilities. To address these issues, we propose a novel benchmark, FIOVA (Five In One Video Annotations), designed to evaluate the differences between LVLMs and human understanding more comprehensively. FIOVA includes 3,002 long video sequences (averaging 33.6 seconds) that cover diverse scenarios with complex spatiotemporal relationships. Each video is annotated by five distinct annotators, capturing a wide range of perspectives and resulting in captions that are 4 to 15 times longer than existing benchmarks, thereby establishing a robust baseline that represents human understanding comprehensively for the first time in video description tasks. Using the FIOVA benchmark, we conducted an in-depth evaluation of six state-of-the-art LVLMs (VideoLLaMA2, LLaVA-NEXT-Video, Video-LLaVA, VideoChat2, Tarsier, and ShareGPT4Video), comparing their performance with humans. Results show that while current LVLMs demonstrate some perception and reasoning capabilities, they still struggle with information omission and descriptive depth. Moreover, we found significant discrepancies between LVLMs and humans in complex videos, particularly where human annotators exhibited substantial disagreement, whereas LVLMs tended to rely on uniform strategies for challenging content. These findings underscore the limitations of using a single human annotator as the groundtruth for evaluation and highlight the need for new evaluation perspectives. We believe this work offers valuable insights into the differences between LVLMs and humans, ultimately guiding future advancements toward human-level video comprehension."
    },
    {
        "title": "Compute Or Load KV Cache? Why Not Both?",
        "link_suffix": "/forum?id=cK0kUzocJW",
        "link": "https://openreview.net/forum?id=cK0kUzocJW",
        "pdf_link": "https://openreview.net/pdf?id=cK0kUzocJW",
        "keywords": "Efficient LLM Serving, LLM Serving System, LLM Prefix Caching",
        "abstract": "Recent advancements in Large Language Models (LLMs) have significantly in-\ncreased context window sizes, enabling sophisticated applications but also in-\ntroducing substantial computational overheads, particularly computing key-value\n(KV) cache in the prefill stage. Prefix caching has emerged to save GPU power\nin this scenario, which saves KV cache at disks and reuse them across multiple\nqueries. However, traditional prefix caching mechanisms often suffer from sub-\nstantial latency because the speed of loading KV cache from disks to GPU mem-\nory is bottlenecked by the throughput of I/O devices. To optimize the latency of\nlong-context prefill, we propose Cake, a novel KV cache loader, which employs\na bidirectional parallelized KV cache generation strategy. Upon receiving a pre-\nfill task, Cake simultaneously and dynamically loads saved KV cache from prefix\ncache locations and computes KV cache on local GPUs, maximizing the utiliza-\ntion of available computation and I/O bandwidth resources. Additionally, Cake\nautomatically adapts to diverse system statuses without manual parameter. tuning.\nIn experiments on various prompt datasets, GPUs, and I/O devices, Cake offers\nup to 68.1% Time To First Token (TTFT) reduction compare with compute-only\nmethod and 94.6% TTFT reduction compare with I/O-only method."
    },
    {
        "title": "ICL-TSVD: Bridging Theory and Practice in Continual Learning with Pre-trained Models",
        "link_suffix": "/forum?id=bqv7M0wc4x",
        "link": "https://openreview.net/forum?id=bqv7M0wc4x",
        "pdf_link": "https://openreview.net/pdf?id=bqv7M0wc4x",
        "keywords": "Continual Learning; Pretrained Models; Overparameterization; Generalization; Random Feature Models",
        "abstract": "The goal of continual learning (CL) is to train a model that can solve multiple tasks presented sequentially. Recent CL approaches have achieved strong performance by leveraging large pre-trained models that generalize well to downstream tasks. However, such methods lack theoretical guarantees, making them prone to unexpected failures. Conversely, principled CL approaches often fail to achieve competitive performance. In this work, we bridge this gap between theory and practice by integrating an empirically strong approach (RanPAC) into a principled framework, Ideal Continual Learner (ICL), designed to prevent forgetting. Specifically, we lift pre-trained features into a higher dimensional space and formulate an over-parametrized minimum-norm least-squares problem. We find that the lifted features are highly ill-conditioned, potentially leading to large training errors (numerical instability) and increased generalization errors (double descent). We address these challenges by continually truncating the singular value decomposition (SVD) of the lifted features. Our approach, termed ICL-TSVD, is stable with respect to the choice of hyperparameters, can handle hundreds of tasks, and outperforms state-of-the-art CL methods on multiple datasets. Importantly, our method satisfies a recurrence relation throughout its continual learning process, which allows us to prove it maintains small training and generalization errors by appropriately truncating a fraction of SVD factors. This results in a stable continual learning method with strong empirical performance and theoretical guarantees."
    }
]
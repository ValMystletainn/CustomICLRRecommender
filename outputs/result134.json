[{"title": "Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts", "link_suffix": "/forum?id=BGppv7fa3K", "link": "https://openreview.net/forum?id=BGppv7fa3K", "pdf_link": "https://openreview.net/pdf?id=BGppv7fa3K", "keywords": "reinforcement learning, multi-agent systems, contract design, principal-agent MDP, sequential social dilemmas, neural networks", "abstract": "The increasing deployment of AI is shaping the future landscape of the internet, which is set to become an integrated ecosystem of AI agents. Orchestrating the interaction among AI agents necessitates decentralized, self-sustaining mechanisms that harmonize the tension between individual interests and social welfare. In this paper we tackle this challenge by synergizing reinforcement learning with principal-agent theory from economics. Taken separately, the former allows unrealistic freedom of intervention, while the latter struggles to scale in sequential settings. Combining them achieves the best of both worlds. We propose a framework where a principal guides an agent in a Markov Decision Process (MDP) using a series of contracts, which specify payments by the principal based on observable outcomes of the agent's actions. We present and analyze a meta-algorithm that iteratively optimizes the policies of the principal and agent, showing its equivalence to a contraction operator on the principal\u2019s Q-function, and its convergence to subgame-perfect equilibrium. We then scale our algorithm with deep Q-learning and analyze its convergence in the presence of approximation error, both theoretically and through experiments with randomly generated binary game-trees. Extending our framework to multiple agents, we apply our methodology to the combinatorial Coin Game. Addressing this multi-agent sequential social dilemma is a promising first step toward scaling our approach to more complex, real-world instances.", "title_embedding_index": 6650, "title_abs_embedding_index": 6675}, {"title": "Lambda-Skip Connections: the architectural component that prevents Rank Collapse", "link_suffix": "/forum?id=1yJP5TVWih", "link": "https://openreview.net/forum?id=1yJP5TVWih", "pdf_link": "https://openreview.net/pdf?id=1yJP5TVWih", "keywords": "Rank Collapse, Skip Connections, Sequence Modeling Architectures", "abstract": "Rank collapse, a phenomenon where embedding vectors in sequence models\nrapidly converge to a uniform token or equilibrium state, has recently gained at-\ntention in the deep learning literature. This phenomenon leads to reduced expres-\nsivity and potential training instabilities due to vanishing gradients. Empirical ev-\nidence suggests that architectural components like skip connections, LayerNorm,\nand MultiLayer Perceptrons (MLPs) play critical roles in mitigating rank collapse.\nWhile this issue is well-documented for transformers, alternative sequence mod-\nels, such as State Space Models (SSMs), which have recently gained prominence,\nhave not been thoroughly examined for similar vulnerabilities. This paper extends\nthe theory of rank collapse from transformers to SSMs using a unifying frame-\nwork that captures both architectures. We introduce a modification in the skip\nconnection component, termed lambda-skip connections, that provides guaran-\ntees for rank collapse prevention. We present, via analytical results, a sufficient\ncondition to achieve the guarantee for all of the aforementioned architectures. We\nalso study the necessity of this condition via ablation studies and analytical exam-\nples. To our knowledge, this is the first study that provides a general guarantee to\nprevent rank collapse, and that investigates rank collapse in the context of SSMs,\noffering valuable understanding for both theoreticians and practitioners. Finally,\nwe validate our findings with experiments demonstrating the crucial role of archi-\ntectural components in preventing rank collapse.", "title_embedding_index": 6651, "title_abs_embedding_index": 6676}, {"title": "Activation Decay by Loss Smoothing to Enhance Generalization", "link_suffix": "/forum?id=InRaT76E2S", "link": "https://openreview.net/forum?id=InRaT76E2S", "pdf_link": "https://openreview.net/pdf?id=InRaT76E2S", "keywords": "loss smoothing, sharpness aware minimization, flat minima, deep learning, activation decay", "abstract": "Generalization in deep learning is strongly influenced by the sharpness of the minima encountered during training. We introduce a novel, deterministic, and computationally efficient method called \\emph{activation decay}, designed to flatten sharp minima and improve generalization across a wide range of tasks. Derived from Gaussian smoothing, activation decay operates by regularizing the activations of critical network layers, effectively reducing sharpness and improving robustness. Unlike stochastic techniques such as dropout or the more computationally expensive Sharpness-Aware Minimization (SAM), our approach requires no additional computational overhead, making it particularly suited for large-scale models.\nWe further demonstrate that activation decay can be seamlessly combined with other regularization techniques, offering enhanced regularization without increasing training complexity. Extensive experiments on CIFAR-10, ImageNet, and natural language processing (NLP) tasks validate our approach, showing consistent improvements in generalization and robustness to label noise.", "title_embedding_index": 6652, "title_abs_embedding_index": 6677}, {"title": "Hyperparameter Optimization via Interacting with Probabilistic Circuits", "link_suffix": "/forum?id=uC003NHlEi", "link": "https://openreview.net/forum?id=uC003NHlEi", "pdf_link": "https://openreview.net/pdf?id=uC003NHlEi", "keywords": "Hyperparameter Optimization, Probabilistic Circuits, Tractable Probabilistic Models", "abstract": "Despite the growing interest in designing truly interactive hyperparameter optimization (HPO) methods, to date, only a few allow to include human feedback. However, these methods add friction to the interactive process, rigidly requiring to fully specify the user input as prior distribution ex ante and often imposing additional constraints on the optimization framework. This hinders the flexible incorporation of expertise and valuable knowledge of domain experts, which might provide partial feedback at any time during optimization. To overcome these limitations, we introduce a novel Bayesian optimization approach leveraging tractable probabilistic models named probabilistic circuits (PCs) as surrogate model. PCs encode a tractable joint distribution over the hybrid hyperparameter space and evaluation scores, and enable exact conditional inference and sampling, allowing users to provide valuable insights interactively and generate configurations adhering to their feedback. We demonstrate the benefits of the resulting interactive HPO through an extensive empirical evaluation of diverse benchmarks, including the challenging setting of neural architecture search.", "title_embedding_index": 6653, "title_abs_embedding_index": 6678}, {"title": "Are LLMs Better than Reported? Detecting Label Errors and Mitigating Their Effect on Model\u00a0Performance", "link_suffix": "/forum?id=mhyl7HhNM5", "link": "https://openreview.net/forum?id=mhyl7HhNM5", "pdf_link": "https://openreview.net/pdf?id=mhyl7HhNM5", "keywords": "LLMs, label errors detection, label errors handling, data annotation", "abstract": "NLP benchmarks rely on standardized datasets for training and evaluating models and are crucial for advancing the field. Traditionally, expert annotations ensure high-quality labels; however, the cost of expert annotation does not scale well with the growing demand for larger datasets required by modern models.\nWhile crowd-sourcing provides a more scalable solution, it often comes at the expense of annotation precision and consistency. Recent advancements in large language models (LLMs) offer new opportunities to enhance the annotation process, particularly for detecting label errors in existing datasets. In this work, we consider the recent approach of LLM-as-a-judge, leveraging an ensemble of LLMs to flag potentially mislabeled examples.\nThrough a case study of four datasets from the TRUE benchmark, covering different tasks and domains, we empirically analyze the labeling quality of existing datasets, and compare expert, crowd-sourced, and our LLM-based annotations in terms of agreement, label quality, and efficiency, demonstrating the strengths and limitations of each annotation method. Our findings reveal a substantial number of label errors, which, when corrected, induce a significant upward shift in reported model performance. This suggests that many of the LLMs so-called mistakes are due to label errors rather than genuine model failures. Additionally, we discuss the implications of mislabeled data and propose methods to mitigate them in training to improve model performance.", "title_embedding_index": 6654, "title_abs_embedding_index": 6679}, {"title": "Foundation Models Secretly Understand Neural Network Weights: Enhancing Hypernetwork Architectures with Foundation Models", "link_suffix": "/forum?id=cADpvQgnqg", "link": "https://openreview.net/forum?id=cADpvQgnqg", "pdf_link": "https://openreview.net/pdf?id=cADpvQgnqg", "keywords": "neural fields, neural implicit representations, foundation models, hypernetworks, generalizable INR", "abstract": "Large pre-trained models, or foundation models, have shown impressive performance when adapted to a variety of downstream tasks, often out-performing specialized models. Hypernetworks, neural networks that generate some or all of the parameters of another neural network, have become an increasingly important technique for conditioning and generalizing implicit neural representations (INRs), which represent signals or objects such as audio or 3D shapes using a neural network. However, despite the potential benefits of incorporating foundation models in hypernetwork methods, this research direction has not been investigated, likely due to the dissimilarity of the weight generation task with other visual tasks. To address this gap, we (1) show how foundation models can improve hypernetworks with Transformer-based architectures, (2) provide an empirical analysis of the benefits of foundation models for hypernetworks through the lens of the generalizable INR task, showing that leveraging foundation models improves performance, generalizability, and data efficiency across a variety of algorithms and modalities, and provide further analysis in examining the design space of foundation model-based hypernetworks, including examining the choice of foundation models, algorithms, and the effect of scaling foundation models.", "title_embedding_index": 6655, "title_abs_embedding_index": 6680}, {"title": "Enhancement of In-Context Reasoning in LLMs through Inductive Rule Learning", "link_suffix": "/forum?id=3x4vpeAclU", "link": "https://openreview.net/forum?id=3x4vpeAclU", "pdf_link": "https://openreview.net/pdf?id=3x4vpeAclU", "keywords": "In-Context Learning, Inductive Reasoning", "abstract": "Currently, Large language models (LLMs) have achieved remarkable performance across various language tasks, largely due to their training on extensive datasets and their considerable model size. These models exhibit in-context learning abilities, which is to learn through few-shot learning. However, the underlying reasoning process remains ambiguous, it is unclear whether the model simply retrieves relevant information and instructions from its training data to generate similar responses, or whether it generalizes examples to form overarching rules, which are then applied to produce accurate answers. Another method for improving few-shot learning is Chain-of-Thought prompting that complement steps by steps instruction for LLMs, so they can follow this instruction to solve many reasoning tasks. Several approaches for evaluating the reasoning abilities of LLMs typically involve task-solving through code generation, which enables models to formalize problems and leverage a code compiler to solve them precisely. However, these methods are constrained to specific task types and are insufficient for a comprehensive assessment of the model's broader reasoning capabilities. Therefore, this paper proposes a method to enhance in-context learning capabilities through two main stages: generating general rules from the provided examples and utilizing LLMs to verify these general rules, thereby aiming to improve reliability and accuracy. At the same time, this approach seeks to investigate the inductive and deductive reasoning abilities, and can improve our understanding of the model\u2019s reasoning by generating and applying general rules to provide transparent, clearly explained responses. The proposed method demonstrates competitive performance on the 1D-ARC benchmark and several traditional language tasks, suggesting its potential for more robust evaluation of LLM reasoning abilities.", "title_embedding_index": 6656, "title_abs_embedding_index": 6681}, {"title": "R-CoT: Reverse Chain-of-Thought Problem Generation for Geometric Reasoning in Large Multimodal Models", "link_suffix": "/forum?id=iwVkB9zaVb", "link": "https://openreview.net/forum?id=iwVkB9zaVb", "pdf_link": "https://openreview.net/pdf?id=iwVkB9zaVb", "keywords": "Large Multimodal Models, Mathematical Reasoning, Geometric Reasoning", "abstract": "Existing Large Multimodal Models (LMMs) struggle with mathematical geometric reasoning due to a lack of high-quality image-text paired data. Current geometric data generation approaches, which apply preset templates to generate geometric data or use Large Language Models (LLMs) to rephrase questions and answers (Q&A), unavoidably limit data accuracy and diversity. To synthesize higher-quality data, we propose a two-stage Reverse Chain-of-Thought (R-CoT) geometry problem generation pipeline. First, we introduce GeoChain to produce high-fidelity geometric images and corresponding descriptions highlighting relations among geometric elements. We then design a Reverse A&Q method that reasons step-by-step based on the descriptions and generates questions in reverse from the reasoning results. Experiments demonstrate that the proposed method brings significant and consistent improvements on multiple LMM baselines, achieving new performance records in the 2B, 7B, and 8B settings. Notably, R-CoT-8B significantly outperforms previous state-of-the-art open-source mathematical models by 16.6% on MathVista and 9.2% on GeoQA, while also surpassing the closed-source model GPT-4o by an average of 13% across both datasets.", "title_embedding_index": 6657, "title_abs_embedding_index": 6682}, {"title": "Node-Level Topological Representation Learning on Point Clouds", "link_suffix": "/forum?id=NiCSyYOfex", "link": "https://openreview.net/forum?id=NiCSyYOfex", "pdf_link": "https://openreview.net/pdf?id=NiCSyYOfex", "keywords": "Topological Data Analysis, Hodge Laplacian, Hodge Theory, Geometry Processing, Differential Geometry, Algebraic Topology, Point Clouds, Representation Learning on Point Clouds", "abstract": "Topological Data Analysis (TDA) allows us to extract powerful topological, and higher-order information on the global shape of a data set or point cloud. Tools like Persistent Homology or the Euler Transform give a single complex description of the global structure of the point cloud. However, common machine learning applications like classification require point-level information and features to be available. In this paper, we bridge this gap and propose a novel method to extract node-level topological features from complex point clouds using discrete variants of concepts from algebraic topology and differential geometry. We verify the effectiveness of these topological point features (TOPF) on both synthetic and real-world data and study their robustness under noise.", "title_embedding_index": 6658, "title_abs_embedding_index": 6683}, {"title": "Mini-Monkey: Alleviating the Semantic Sawtooth Effect for Lightweight MLLMs via Complementary Image Pyramid", "link_suffix": "/forum?id=71XtUhazG0", "link": "https://openreview.net/forum?id=71XtUhazG0", "pdf_link": "https://openreview.net/pdf?id=71XtUhazG0", "keywords": "Multimodal Large Language Model, Document Understanding", "abstract": "Recently, scaling images to high resolution has received much attention in multimodal large language models (MLLMs). Most existing practices adopt a sliding-window-style cropping strategy to adapt to resolution increase. Such a cropping strategy, however, can easily cut off objects and connected regions, which introduces semantic discontinuity and therefore impedes MLLMs from recognizing small or irregularly shaped objects or text, leading to a phenomenon we call the semantic sawtooth effect. This effect is particularly evident in lightweight MLLMs. To address this issue, we introduce a Complementary Image Pyramid (CIP), a simple, effective, and plug-and-play solution designed to mitigate semantic discontinuity during high-resolution image processing. In particular, CIP dynamically constructs an image pyramid to provide complementary semantic information for the cropping-based MLLMs, enabling it rich acquire semantics at all levels. Furthermore, we introduce a Scale Compression Mechanism (SCM) to reduce the additional computational overhead by compressing the redundant visual tokens. Our experiments demonstrate that CIP can consistently enhance the performance across diverse architectures (e.g., MiniCPM-V-2, InternVL2, and LLaVA-OneVision), various model capacity (1B$\\rightarrow$8B), and different usage configurations (training-free and fine-tuning). Leveraging the proposed CIP and SCM, we introduce a lightweight MLLM, Mini-Monkey, which achieves remarkable performance in both general multimodal understanding and document understanding. On the OCRBench, the 2B-version Mini-Monkey even surpasses the 8B model InternVL2-8B by 12 score. Additionally, training Mini-Monkey is cheap, requiring only eight RTX 3090 GPUs. Code and models will be available.", "title_embedding_index": 6659, "title_abs_embedding_index": 6684}, {"title": "Multi-objective antibody design with constrained preference optimization", "link_suffix": "/forum?id=4ktJJBvvUd", "link": "https://openreview.net/forum?id=4ktJJBvvUd", "pdf_link": "https://openreview.net/pdf?id=4ktJJBvvUd", "keywords": "antibody design, diffusion generative model, preference optimization", "abstract": "Antibody design is crucial for developing therapies against diseases such as cancer and viral infections. Recent deep generative models have significantly advanced computational antibody design, particularly in enhancing binding affinity to target antigens. However, beyond binding affinity, antibodies should exhibit other favorable biophysical properties such as non-antigen binding specificity and low self-association, which are important for antibody developability and clinical safety. To address this challenge, we propose AbNovo, a framework that leverages constrained preference optimization for multi-objective antibody design. First, we pre-train an antigen-conditioned generative model for antibody structure and sequence co-design. Then, we fine-tune the model using binding affinity as a reward while enforcing explicit constraints on other biophysical properties. Specifically, we model the physical binding energy with continuous rewards rather than pairwise preferences and explore a primal-and-dual approach for constrained optimization. Additionally, we incorporate a structure-aware protein language model to mitigate the issue of limited training data. Evaluated on independent test sets, AbNovo outperforms existing methods in metrics of binding affinity such as Rosetta binding energy and evolutionary plausibility, as well as in metrics for other biophysical properties like stability and specificity.", "title_embedding_index": 6660, "title_abs_embedding_index": 6685}, {"title": "Towards General Certified Robustness of Combinatorial Optimization Solvers", "link_suffix": "/forum?id=Y3haavNdBX", "link": "https://openreview.net/forum?id=Y3haavNdBX", "pdf_link": "https://openreview.net/pdf?id=Y3haavNdBX", "keywords": "Certified Robustness; Combinatorial Optimization", "abstract": "Combinatorial optimization (CO), driven by algorithmic advancements, now spans applications like network design and bioinformatics, crucial for optimizing complex systems and tackling NP-hard problems efficiently across various industries.\nNonetheless, the study for robustness, especially certified robustness in the CO domain which ensures optimization consistency among different data distributions, persists as an unexplored domain.\nIn this study, we explore the certified robustness and robustness enhancement strategy for CO solvers.\nFirstly, this study extends the randomized smoothing technique, a widely used certified robustness method in recognition and classification, and introduces a general definition of certified robustness for CO solvers.\nSpecifically, this study provides a theoretical guarantee that the output variations of CO solvers, as measured by the 1-Wasserstein distance, remain certifiably bounded when input instances vary within a specified range.\nSecondly, inspired by the concept of smoothing\u2014replacing the output of a single sample with the statistical output of multiple similar samples\u2014we discover that \u201ceasy instances\u201d often exist near current instances. These easy instances satisfy the constraints of the current instances but result in lower solver costs. \nBased on this finding, we propose a robustness enhancement method to search for and solve easy instances instead of current instances, thereby minimizing solver vulnerabilities.\nExperiments across datasets and solvers illustrate that our proposed certification definition can achieve a solid robustness guarantee and the enhancement method significantly amplifies the model\u2019s immunity to perturbations in practice.", "title_embedding_index": 6661, "title_abs_embedding_index": 6686}, {"title": "The Two-Hop Curse: LLMs trained on A\u2192B, B\u2192C fail to learn A\u2192C", "link_suffix": "/forum?id=HVblmL5Rws", "link": "https://openreview.net/forum?id=HVblmL5Rws", "pdf_link": "https://openreview.net/pdf?id=HVblmL5Rws", "keywords": "latent reasoning, two-hop reasoning, chain of thought, LLMs, question answering, llama, fine-tuning, fact representation, knowledge representation, world models", "abstract": "While LLMs excel at answering multi-hop questions like \u201cWho is the spouse of the performer of Imagine?\u201d by thinking out loud (chain-of-thought), they perform surprisingly poorly when required to reason in their latent space and answer without chain-of-thought. This observation was previously referred to as the compositionality gap, implying that although language models are less reliable at two-hop latent reasoning, they still perform it sometimes. In this paper, we introduce a controlled setting for investigating the compositionality gap. We run a series of experiments finetuning a large language model (Llama-3-8B-Instruct) on synthetic facts expressed in English. We attempt to elicit two-hop reasoning in three ways: (i) fine-tune on a data mixture designed to incentivize two-hop reasoning, (ii) force facts to be stored in layers in the correct order, and (iii) use an auxiliary loss to provide activation-level supervision for two-hop reasoning. We show that LLaMA 3 8B successfully learns to answer two-hop questions about synthetic facts using CoT, but completely fails without CoT, achieving chance-level accuracy and chance-level test loss. Failures of LLMs in our controlled setting cast doubt on the purported ability of present LLMs to perform multihop latent reasoning and lead us to conjecture that, rather than a reasoning gap, current language models might exhibit a two-hop reasoning curse \u2014 a complete lack of ability rather than a relative weakness. This is the Two-Hop Curse.", "title_embedding_index": 6662, "title_abs_embedding_index": 6687}, {"title": "\u0394-DiT: Accelerating Diffusion Transformers without training via Denoising Property Alignment", "link_suffix": "/forum?id=pDI03iK5Bf", "link": "https://openreview.net/forum?id=pDI03iK5Bf", "pdf_link": "https://openreview.net/pdf?id=pDI03iK5Bf", "keywords": "Diffusion Model, Training-Free, Acceleration, Diffusion Transformer", "abstract": "Diffusion models are now commonly used for producing high-quality and diverse images, but the iterative denoising process is time-intensive, limiting their usage in real-time applications. As a result, various acceleration techniques have been developed, though these primarily target UNet-based architectures and are not directly applicable to Transformer-based diffusion models (DiT). To address the specific challenges of the DiT architecture, we first analyze the relationship between the depth of DiT blocks and the quality of image generation. While skipping blocks can lead to large degradations in generation quality, we propose the $\\Delta$-Cache method, which captures and stores the incremental changes of different blocks, thereby mitigating the performance gap and maintaining closer alignment with the original results. Our analysis indicates that the shallow DiT blocks primarily define the global structure of images such as compositions, and outlines, while the deep blocks refine details. Based on this, we introduce a denoising property alignment method that selectively bypasses computations of different blocks at various timesteps while preserving performance. Comprehensive experiments on PIXART-$\\alpha$ and DiT-XL demonstrate that $\\Delta$-DiT achieves a $1.6\\times$ speedup in 20-step generation and enhances performance in most cases. In the 4-step consistent model generation scenario, and with a more demanding $1.12\\times$ acceleration, our approach significantly outperforms existing methods.", "title_embedding_index": 6663, "title_abs_embedding_index": 6688}, {"title": "Dynamics Based Neural Encoding with Inter-Intra Region Connectivity", "link_suffix": "/forum?id=mV6cO4mGjH", "link": "https://openreview.net/forum?id=mV6cO4mGjH", "pdf_link": "https://openreview.net/pdf?id=mV6cO4mGjH", "keywords": "Neuroscience, Neural Encoding, Video Understanding", "abstract": "Extensive literature has drawn comparisons between recordings of biological neurons in the brain and deep neural networks. This comparative analysis aims to advance and interpret deep neural networks and enhance our understanding of biological neural systems. However, previous works did not consider the time aspect and how the encoding of video and dynamics in deep networks relate to the biological neural systems within a large-scale comparison. Towards this end, we propose the first large-scale study focused on comparing video understanding models with respect to the visual cortex recordings using video stimuli. The study encompasses more than two million regression fits, examining image vs. video understanding, convolutional vs. transformer-based and fully vs. self-supervised models. Our study resulted in both, insights to help better understand deep video understanding models and a novel neural encoding scheme to better encode biological neural systems. We provide key insights on how video understanding models predict visual cortex responses; showing video understanding better than image understanding models, convolutional models are better in the early-mid visual cortical regions than transformer based ones except for multiscale transformers and that two-stream models are better than single stream. Furthermore, we propose a novel neural encoding scheme that is built on top of the best performing video understanding models, while incorporating inter-intra region connectivity across the visual cortex. Our neural encoding leverages the encoded dynamics from video stimuli, through utilizing two-stream networks and multiscale transformers, while taking connectivity priors into consideration. Our results show that merging both intra and inter-region connectivity priors increases the encoding performance over each one of them standalone or no connectivity priors. It also shows the necessity for encoding dynamics to fully benefit from such connectivity priors.", "title_embedding_index": 6664, "title_abs_embedding_index": 6689}, {"title": "DIAR: Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation", "link_suffix": "/forum?id=7hM5597bCv", "link": "https://openreview.net/forum?id=7hM5597bCv", "pdf_link": "https://openreview.net/pdf?id=7hM5597bCv", "keywords": "Diffusion model, offline RL, Q-learning", "abstract": "We propose a novel offline reinforcement learning (offline RL) approach, introducing the Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation (DIAR) framework. We address two key challenges in offline RL: out-of-distribution samples and long-horizon problems. We leverage diffusion models to learn state-action sequence distributions and incorporate value functions for more balanced and adaptive decision-making. DIAR introduces an Adaptive Revaluation mechanism that dynamically adjusts decision lengths by comparing current and future state values, enabling flexible long-term decision-making. Furthermore, we address Q-value overestimation by combining Q-network learning with a value function guided by a diffusion model. The diffusion model generates diverse latent trajectories, enhancing policy robustness and generalization. As demonstrated in tasks like Maze2D, AntMaze, and Kitchen, DIAR consistently outperforms state-of-the-art algorithms in long-horizon, sparse-reward environments.", "title_embedding_index": 6665, "title_abs_embedding_index": 6690}, {"title": "NL-Eye: Abductive NLI For Images", "link_suffix": "/forum?id=2zmO1GVT0Y", "link": "https://openreview.net/forum?id=2zmO1GVT0Y", "pdf_link": "https://openreview.net/pdf?id=2zmO1GVT0Y", "keywords": "Benchmark, Multimodality, Abductive Reasoning, NLI, VLM", "abstract": "Will a Visual Language Model (VLM)-based bot warn us about slipping if it detects a wet floor? Recent VLMs have demonstrated impressive capabilities, yet their ability to infer outcomes and causes remains underexplored. To address this, we introduce NL-Eye, a benchmark designed to assess VLMs' visual abductive reasoning skills. NL-Eye adapts the abductive Natural Language Inference (NLI) task to the visual domain, requiring models to evaluate the plausibility of hypothesis images based on a premise image and explain their decisions. NL-Eye consists of 350 carefully curated triplet examples (1,050 images) spanning diverse reasoning categories: physical, functional, logical, emotional, cultural, and social. The data curation process involved two steps\u2014writing textual descriptions and generating images using text-to-image models, both requiring substantial human involvement to ensure high-quality and challenging scenes. Our experiments show that VLMs struggle significantly on NL-Eye, often performing at random baseline levels, while humans excel in both plausibility prediction and explanation quality. This demonstrates a deficiency in the abductive reasoning capabilities of modern VLMs. NL-Eye represents a crucial step toward developing VLMs capable of robust multimodal reasoning for real-world applications, including accident-prevention bots and generated video verification.", "title_embedding_index": 6666, "title_abs_embedding_index": 6691}, {"title": "COFlowNet: Conservative Constraints on Flows Enable High-Quality Candidate Generation", "link_suffix": "/forum?id=tXUkT709OJ", "link": "https://openreview.net/forum?id=tXUkT709OJ", "pdf_link": "https://openreview.net/pdf?id=tXUkT709OJ", "keywords": "generative flow network, offline RL, molecule design", "abstract": "Generative flow networks (GFlowNet) have been considered as powerful tools for generating candidates with desired property. Given that evaluating the property of candidates can be complex and time-consuming, existing GFlowNets train proxy models for efficient online evaluation. However, the performance of proxy models is heavily dependent on the amount of data and is of considerable uncertainty. Therefore, it is of great interest that how to develop an offline GFlowNet which does not rely on online evaluating. \nUnder offline setting, the limited data results in insufficient exploration of state space. \nThe insufficient exploration means that offline GFlowNets can hardly generate satisfying candidates out of the distribution of training data. Therefore, it is critical to restrict the offline model to act in distribution of training data. The distinctive training goal of GFlownets poses unique challenge for making such restriction.\nTackling the challenge, we proposes Conservative Offline GFlowNet (COFlowNet) in this paper. We define unsupported flow, edges containing unseen states in training data. Models can learn extremely few knowledge about unsupported flow from training data. By constraining the model from exploring unsupported flows, we restrict COFlowNet to explore as optimal trajectories on the training set as possible, thus generating better candidates. In order to improve the diversity of candidates, we further introduce quantile version of unsupported flow restriction. Experimental result on several widely-used datasets validates the effectiveness of COFlowNet on generating high-scored and diverse candidates. All implementations are available at \\href{https://anonymous.4open.science/r/COflownet-2872}{https://anonymous.4open.science/r/COflownet-2872}", "title_embedding_index": 6667, "title_abs_embedding_index": 6692}, {"title": "VN-EGNN: E(3)- and SE(3)-Equivariant Graph Neural Networks with Virtual Nodes Enhance Protein Binding Site Identification", "link_suffix": "/forum?id=AExygKPmnJ", "link": "https://openreview.net/forum?id=AExygKPmnJ", "pdf_link": "https://openreview.net/pdf?id=AExygKPmnJ", "keywords": "Binding site, protein, equivariance, graph neural network, message passing", "abstract": "Being able to identify regions within or around proteins, to which ligands can potentially bind,  is an essential step in developing new drugs. Binding site identification methods can now profit from  the availability of large amounts of 3D structures in protein structure databases or from AlphaFold predictions. Current binding site identification methods heavily rely on graph neural networks (GNNs), usually designed to output E($3$)-equivariant predictions. Such methods turned out to be very beneficial for physics-related tasks like binding energy or motion trajectory prediction. However, the performance of GNNs at binding site identification is still limited potentially due to the lack of dedicated nodes that model hidden geometric entities, such as binding pockets. In this work, we extend E($n$)-equivariant graph neural networks (EGNNs) by adding virtual nodes and applying an extended message passing scheme. The virtual nodes in these graphs are dedicated entities to learn representations of binding sites, which leads to improved predictive performance. In our experiments, we show that our proposed method, VN-EGNN, sets a new state-of-the-art at locating binding site centers on COACH420, HOLO4K and PDBbind2020.", "title_embedding_index": 6668, "title_abs_embedding_index": 6693}, {"title": "Channel Independence Improves Out-of-Distribution Generalisation in Multivariate Time Series Classification", "link_suffix": "/forum?id=CLImhawlGn", "link": "https://openreview.net/forum?id=CLImhawlGn", "pdf_link": "https://openreview.net/pdf?id=CLImhawlGn", "keywords": "time series classification, OOD generalization, domain generalization", "abstract": "Robustness to distribution shift is a necessary property of machine learning models for their safe and effective deployment. However, deep learning models are susceptible to learning spurious features of the in-distribution (ID) training data that fail to generalise to out-of-distribution (OOD) data. Domain generalisation algorithms aim to tackle this problem, but recent studies have demonstrated that their improvement over standard empirical risk minimisation is marginal. We address this problem for multivariate time series classification (TSC), where it is standard practise to use feature extractor architectures that learn with channel dependence (CD), enabling cross-channel patterns to be learned. Inspired by recent success in time series forecasting, we investigate how channel independence (CI) impacts OOD generalisation in TSC. Our experiments on six time series datasets reveal that ID and OOD features exhibit significantly greater distributional divergence when learned with CD compared to CI. As a consequence, models that learn with CI are more robust to distribution shift, evidenced by smaller generalisation gaps (the difference between ID and OOD performance) across datasets. On datasets that have a stronger shift, OOD accuracy is substantially higher for CI than CD.", "title_embedding_index": 6669, "title_abs_embedding_index": 6694}, {"title": "Manipulating Infrared Emissivity with Galvanized Iron Sheets for Physical Adversarial Attack", "link_suffix": "/forum?id=FGLnLjtemf", "link": "https://openreview.net/forum?id=FGLnLjtemf", "pdf_link": "https://openreview.net/pdf?id=FGLnLjtemf", "keywords": "Adversarial Patch, Deep neural network, Physical sample generation", "abstract": "For adversarial attacks on infrared detectors, previous works have focused on designing the physical patches through temperature variations, overlooking the impact of infrared emissivity on infrared imaging. In fact, infrared emissivity significantly affects infrared radiant intensity at the same temperature. In this paper, a QR-like adversarial attack patch is designed by manipulating the surface emissivity of objects to alter the infrared radiation intensity emitted from the object's surface, called Emissivity QR-like Patch (E-QR patch). In this paper, the surface emissivity of the object is manipulated through the adjustment of surface roughness. Various levels of surface roughness are realized by a commonly used metal material, galvanized iron sheets, to produce physically adversarial patches with diverse infrared radiation intensity. Considering the possible transformation distributions between the digital and physical domains, a physical E-QR patch, which is robust to noise, angle, and position, is generated by an expectation over the transformation framework. Smoothing loss is incorporated to minimize the loss in physical reconstruction, thereby effectively mitigating shooting errors in the physical domain induced by abrupt pixel changes in the digital domain. Experimental results show that the E-QR patch achieves more than 80% attack success rate for infrared pedestrian detectors in a physical environment.", "title_embedding_index": 6670, "title_abs_embedding_index": 6695}, {"title": "Autoencoder-Based General-Purpose Representation Learning for Entity Embedding", "link_suffix": "/forum?id=0C5iHPPwsG", "link": "https://openreview.net/forum?id=0C5iHPPwsG", "pdf_link": "https://openreview.net/pdf?id=0C5iHPPwsG", "keywords": "customer, embeddings, embedding, tabular, general, purpose, autoencoder, representation learning, general purpose, reconstruction loss, entity, entity embedding, entity representation, contractive autoencoder, dimensionality, reduction, latent, space, representation, feature, regularization, variational autoencoder", "abstract": "Recent advances in representation learning have successfully leveraged the underlying domain-specific structure of data across various fields. However, representing diverse and complex entities stored in tabular format within a latent space remains challenging.\nIn this paper, we introduce DeepCAE, a novel method for calculating the regularization term for multi-layer contractive autoencoders (CAEs). Additionally, we formalize a general-purpose entity embedding framework and use it to empirically show that DeepCAE outperforms all other tested autoencoder variants in both reconstruction performance and downstream prediction performance. Notably, when compared to a stacked CAE across 13 datasets, DeepCAE achieves a 34% improvement in reconstruction error.", "title_embedding_index": 6671, "title_abs_embedding_index": 6696}, {"title": "Curriculum-aware Training for Discriminating Molecular Property Prediction Models", "link_suffix": "/forum?id=6DHIkLv5i3", "link": "https://openreview.net/forum?id=6DHIkLv5i3", "pdf_link": "https://openreview.net/pdf?id=6DHIkLv5i3", "keywords": "molecular property prediction, curriculum learning", "abstract": "Despite their wide application across various fields, current molecular property prediction models struggle with the challenge of activity cliff, which refers to the situation where molecules with similar chemical structures display remarkable different properties. This phenomenon hinders existing models' ability to learn distinctive representations for molecules with similar chemical structures, and results in inaccurate predictions on molecules with activity cliff. To address this limitation, we first present empirical evidence demonstrating the ineffectiveness of standard training pipelines on molecules with activity cliff. We propose a novel approach that reformulates molecular property prediction as a node classification problem, introducing two innovative tasks at both the node and edge levels to improve learning outcomes for these challenging molecules with activity cliff. Our method is versatile, allowing seamless integration with a variety of base models, whether pre-trained or randomly initialized. Extensive evaluation across different molecular property prediction datasets validate the effectiveness of our approach.", "title_embedding_index": 6672, "title_abs_embedding_index": 6697}, {"title": "BOOD: Boundary-based Out-Of-Distribution Data Generation", "link_suffix": "/forum?id=0rACj8JLAL", "link": "https://openreview.net/forum?id=0rACj8JLAL", "pdf_link": "https://openreview.net/pdf?id=0rACj8JLAL", "keywords": "OOD detection, Diffusion models, Training data generation", "abstract": "Harnessing the power of diffusion models to synthesize auxiliary training data based on latent space features has proven effective in enhancing out-of-distribution (OOD) detection performance. However, extracting effective features outside the in-distribution (ID) boundary in latent space remains challenging due to the difficulty of identifying decision boundaries between classes. This paper proposes a novel framework called Boundary-based Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD features and generates human-compatible outlier images using diffusion models. BOOD first learns a text-conditioned latent feature space from the ID dataset, selects ID features closest to the decision boundary, and perturbs them to cross the decision boundary to form OOD features. These synthetic OOD features are then decoded into images in pixel space by a diffusion model. Compared to previous works, BOOD provides a more efficient strategy for synthesizing informative OOD features, facilitating clearer distinctions between ID and OOD data. Extensive experimental results on common benchmarks demonstrate that BOOD surpasses the state-of-the-art method significantly, achieving a 27.9% decrease in average FPR95 (40.31% vs. 12.47%) and a 7.2% improvement in average AUROC (90.15% vs. 97.34%) on the Cifar-100 dataset.", "title_embedding_index": 6673, "title_abs_embedding_index": 6698}, {"title": "Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?", "link_suffix": "/forum?id=LO4MEPoqrG", "link": "https://openreview.net/forum?id=LO4MEPoqrG", "pdf_link": "https://openreview.net/pdf?id=LO4MEPoqrG", "keywords": "jailbreaks, LLMs", "abstract": "Large Language Models (LLMs) are known to be susceptible to crafted adversarial attacks or jailbreaks that lead to the generation of objectionable content despite being aligned to human preferences using safety fine-tuning methods. While the large dimensionality of input token space makes it inevitable to find \\emph{adversarial} prompts that can jailbreak these models, we aim to evaluate whether safety fine-tuned LLMs are safe against \\emph{natural} prompts which are semantically related to toxic prompts that elicit safe responses after alignment. We surprisingly find that popular aligned LLMs such as GPT4 can be compromised using naive prompts that are NOT even crafted with an objective of jailbreaking the model. Furthermore, we empirically show that given a seed prompt that elicits a toxic response from an unaligned model, one can systematically generate several semantically related \\emph{natural} prompts that can jailbreak aligned LLMs. Towards this, we propose a method of \\emph{Response Guided Question Augmentation (ReG-QA)} to evaluate the generalization of safety aligned LLMs to natural prompts, by first generating several toxic answers from a seed question using an unaligned LLM (Q to A), and further prompting another LLM to generate questions that are likely to produce these answers (A to Q). We interestingly find that safety fine-tuned LLMs such as GPT-4o are vulnerable to producing natural jailbreak \\textit{questions} from unsafe content (without denial) and can thus be used for the latter (A to Q) step. Using the proposed approach, we obtain attack success rates that are comparable to/ better than leading adversarial attack methods on the JailbreakBench leaderboard.", "title_embedding_index": 6674, "title_abs_embedding_index": 6699}]
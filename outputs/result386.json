[
    {
        "title": "Iterative Training of Language Models with Opponent Modeling for Red Teaming Data Generation",
        "link_suffix": "/forum?id=AGsoQnNrs5",
        "link": "https://openreview.net/forum?id=AGsoQnNrs5",
        "pdf_link": "https://openreview.net/pdf?id=AGsoQnNrs5",
        "keywords": "LLM Safety, Red Teaming of LLMs, Synthetic Data Generation",
        "abstract": "Large language models (LLMs) exhibit impressive capabilities across various tasks but are also prone to generating harmful outputs. To address this risk, we explore an iterative red teaming approach that focuses on adversarial prompt refinement. Although this method improves attack success rates, it faces challenges of slow progress, high computational cost, and limited prompt diversity. To overcome these limitations, we propose a training framework using a smaller model, Llama3.1-8B, integrated with opponent modeling to simulate responses and enhance attack performance. Our method achieves a 74.95% attack success rate on Llama2-7b-Chat and 69.10% on Llama3-8b-Instruct, while also preserving prompt diversity. Our analysis of the trained red teaming LLM reveals that red teaming abilities are densely embedded in model parameters, unlike the sparsity observed in safety alignment features. We release the data and code to facilitate further research on improving LLM safety alignment."
    },
    {
        "title": "HALO: Human-Aligned End-to-end Image Retargeting with Layered Transformations",
        "link_suffix": "/forum?id=pfXVid1p1d",
        "link": "https://openreview.net/forum?id=pfXVid1p1d",
        "pdf_link": "https://openreview.net/pdf?id=pfXVid1p1d",
        "keywords": "Image Retargeting, Image Transformation, Image Editing",
        "abstract": "Image retargeting aims to change the aspect-ratio of an image while maintaining its content and structure with less visual artifacts. \nExisting methods still generate many artifacts or lose a lot of original content or structure.  To address this, we introduce HALO, an end-to-end trainable solution for image retargeting. \nThe core idea of HALO is to warp the input image to target resolution. \nSince humans are more sensitive to distortions in salient areas than non-salient areas of an image, HALO decomposes the input image into salient/non-salient layers and applies different wrapping fields to different layers. To further minimize the structure distortion in the output images, we propose perceptual structure similarity loss which measures the structure similarity between input and output images and aligns with human perception. Both quantitative results and a user study on the RetargetMe dataset show that our algorithm achieves SOTA. \nEspecially, our method increases human preference by 13.21% compared with the second best method."
    },
    {
        "title": "Temperature Optimization for Bayesian Deep Learning",
        "link_suffix": "/forum?id=MnBrLJez3q",
        "link": "https://openreview.net/forum?id=MnBrLJez3q",
        "pdf_link": "https://openreview.net/pdf?id=MnBrLJez3q",
        "keywords": "Bayesian deep learning, cold posterior effect, temperature selection, posterior tempering",
        "abstract": "The Cold Posterior Effect (CPE) is a phenomenon in Bayesian Deep Learning (BDL), where tempering the posterior to a cold temperature often improves the predictive performance of the posterior predictive distribution (PPD). Although the term `CPE' suggests colder temperatures are inherently better, the BDL community increasingly recognizes that this is not always the case. Despite this, there remains no systematic method for finding the optimal temperature beyond grid search. In this work, we propose a data-driven approach to select the temperature that maximizes test log-predictive density, treating the temperature as a model parameter and estimating it directly from the data. We empirically demonstrate that our method performs comparably to grid search, at a fraction of the cost, across both regression and classification tasks. Finally, we highlight the differing perspectives on CPE between the BDL and Generalized Bayes communities: while the former primarily focuses on predictive performance of the PPD, the latter emphasizes calibrated uncertainty and robustness to model misspecification; these distinct objectives lead to different temperature preferences."
    },
    {
        "title": "Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow",
        "link_suffix": "/forum?id=2RcTuBc4mA",
        "link": "https://openreview.net/forum?id=2RcTuBc4mA",
        "pdf_link": "https://openreview.net/pdf?id=2RcTuBc4mA",
        "keywords": "Attention Flow, Feature Attributions, Transformers, Barrier Regularization, Maximum Flow",
        "abstract": "This paper introduces Generalized Attention Flow, a novel feature attribution method for Transformer models that addresses the limitations of existing approaches. By generalizing Attention Flow and substituting attention weights with an arbitrary Information Tensor, the method leverages attention weights, their gradients, maximum flow, and the barrier method to generate more accurate feature attributions. The proposed approach demonstrates superior theoretical properties and resolves issues associated with previous methods that rely solely on simple aggregation of attention weights. Comprehensive benchmarking in NLP sequence classification tasks reveals that a specific variant of Generalized Attention Flow consistently outperforms state-of-the-art feature attribution methods across most evaluation scenarios, offering a more accurate explanation of Transformer model outputs."
    },
    {
        "title": "Your Weak LLM is Secretly a Strong Teacher for Alignment",
        "link_suffix": "/forum?id=sGqd1tF8P8",
        "link": "https://openreview.net/forum?id=sGqd1tF8P8",
        "pdf_link": "https://openreview.net/pdf?id=sGqd1tF8P8",
        "keywords": "large language models; alignment",
        "abstract": "The burgeoning capabilities of large language models (LLMs) have underscored the need for alignment to ensure these models act in accordance with human values and intentions. Existing alignment frameworks present constraints either in the form of expensive human effort or high computational costs. This paper explores a promising middle ground, where we employ a weak LLM that is significantly less resource-intensive than top-tier models, yet offers more automation than purely human feedback. We present a systematic study to evaluate and understand weak LLM's ability to generate feedback for alignment. Our empirical findings demonstrate that weak LLMs can provide feedback that rivals or even exceeds that of fully human-annotated data. Our study indicates a minimized impact of model size on feedback efficacy, shedding light on a scalable and sustainable alignment strategy. To deepen our understanding of alignment under weak LLM feedback, we conduct a series of qualitative and quantitative analyses, offering novel insights into the quality discrepancies between human feedback vs. weak LLM feedback."
    },
    {
        "title": "See Further When Clear: Adaptive Generative Modeling with Curriculum Consistency Model",
        "link_suffix": "/forum?id=xVOMtecrAS",
        "link": "https://openreview.net/forum?id=xVOMtecrAS",
        "pdf_link": "https://openreview.net/pdf?id=xVOMtecrAS",
        "keywords": "adaptive curriculum learning, noise schedule, flow matching, consistency models",
        "abstract": "Significant advances have been made in the sampling efficiency of diffusion models, driven by Consistency Distillation (CD), which trains a student model to mimic the output of a teacher model at an earlier timestep. However, we found that the learning complexity of the student model varies significantly across different timesteps, leading to suboptimal performance in consistency models.\nTo address this issue, we propose the Curriculum Consistency Model (CCM), which stabilizes and balances the learning complexity across timesteps. We define the distillation process as a curriculum and introduce Peak Signal-to-Noise Ratio (PSNR) as a metric to quantify the difficulty of each step in this curriculum.\nBy incorporating adversarial losses, our method achieves competitive single-step sampling Fr\u00e9chet Inception Distance (FID) scores of 1.64 on CIFAR-10 and 2.18 on ImageNet 64x64.\nMoreover, our approach generalizes well to both Flow Matching models and diffusion models. We have extended our method to large-scale text-to-image models, including Stable Diffusion XL and Stable Diffusion 3."
    },
    {
        "title": "GaussianClin: Multimodal Featured Gaussian Splatting for Dynamic Clinical Videos",
        "link_suffix": "/forum?id=pmznhtCHNb",
        "link": "https://openreview.net/forum?id=pmznhtCHNb",
        "pdf_link": "https://openreview.net/pdf?id=pmznhtCHNb",
        "keywords": "3D Scene Reconstruction, Robot-assisted Clinical Application",
        "abstract": "Reconstructing dynamic 3D models from clinical videos is crucial for medical applications such as surgical visualization, robot-assisted surgery, and medical training. However, the clinical environment presents unique challenges, including limited surface textures, inconsistent lighting, and the need for expert-level medical knowledge, making it difficult for non-experts to directly apply existing techniques. To address these challenges, we presentGaussianClin, a novel approach that enhances 3D modeling capabilities in dynamic clinical videos by leveraging multimodal feature-based Gaussian splatting (GS). By embedding trained multimodal feature fields into the radiance field,GaussianClinintegrates general medical knowledge and improves the performance of GS in tasks like 3D tissue visualization, real-time object enhancement, clinical instrument and organ segmentation, and medical visual question answering. To effectively capture temporal dynamics and tissue deformations, we further introduce a spatiotemporal graph distillation, which significantly improves handling deformable tissues compared to standard GS methods. Experimental results demonstrate thatGaussianClinenables clinical 3D expert models to leverage massive pre-trained 2D multimodal foundation models, thereby paving the way for advancements in robot-assisted surgery and medical data processing."
    },
    {
        "title": "Beyond Canonicalization: How Tensorial Messages Improve Equivariant Message Passing",
        "link_suffix": "/forum?id=vDp6StrKIq",
        "link": "https://openreview.net/forum?id=vDp6StrKIq",
        "pdf_link": "https://openreview.net/pdf?id=vDp6StrKIq",
        "keywords": "equivariance, message passing, tensor representation, local frames, geometric deep learning",
        "abstract": "In numerous applications of geometric deep learning, the studied systems exhibit spatial symmetries and it is desirable to enforce these. For the symmetry of global rotations and reflections, this means that the model should be equivariant with respect to the transformations that form the group of $\\mathrm O(d)$.\nWhile many approaches for equivariant message passing require specialized architectures, including non-standard normalization layers or non-linearities, we here present a framework based on local reference frames (\"local canonicalization\") which can be integrated with any architecture without restrictions.\nWe enhance equivariant message passing based on local canonicalization by introducing tensorial messages to communicate geometric information consistently between different local coordinate frames.\nOur framework applies to message passing on geometric data in Euclidean spaces of arbitrary dimension.\nWe explicitly show how our approach can be adapted to make a popular existing point cloud architecture equivariant. We demonstrate the superiority of tensorial messages and achieve state-of-the-art results on normal vector regression and competitive results on other standard 3D point cloud tasks."
    },
    {
        "title": "Accelerating Diffusion Transformers with Token-wise Feature Caching",
        "link_suffix": "/forum?id=yYZbZGo4ei",
        "link": "https://openreview.net/forum?id=yYZbZGo4ei",
        "pdf_link": "https://openreview.net/pdf?id=yYZbZGo4ei",
        "keywords": "Diffusion Models, Image generation, Video generation, Model Acceleration, Feature Cache",
        "abstract": "Diffusion transformers have shown significant effectiveness in both image and video synthesis at the expense of huge computation costs. To address this problem, feature caching methods have been introduced to accelerate diffusion transformers by caching the features in previous timesteps and reusing them in the following timesteps. However, previous caching methods ignore that different tokens exhibit different sensitivities to feature caching, and feature caching on some tokens may lead to 10X more destruction to the overall generation quality compared with other tokens. In this paper, we introduce token-wise feature caching, allowing us to adaptively select the most suitable tokens for caching, and further enable us to apply different caching ratios to neural layers in different types and depths. Extensive experiments on PixArt-alpha, OpenSora, and DiT demonstrate our effectiveness in both image and video generation with no requirements for training. For instance, 2.36X and 1.93X acceleration are achieved on OpenSora and PixArt-alpha with almost no drop in generation quality. Codes have been released in the supplementary material and will be released in Github."
    },
    {
        "title": "Towards Unified Human Motion-Language Understanding via Sparse Interpretable Characterization",
        "link_suffix": "/forum?id=Oh8MuCacJW",
        "link": "https://openreview.net/forum?id=Oh8MuCacJW",
        "pdf_link": "https://openreview.net/pdf?id=Oh8MuCacJW",
        "keywords": "Interpretable Human Motion Understanding, visualization and interpretation of motion representations, Human Motion representation learning",
        "abstract": "Recently, the comprehensive understanding of human motion has been a prominent area of research due to its critical importance in many fields. However, existing methods often prioritize specific downstream tasks and roughly align text and motion features within a CLIP-like framework. This results in a lack of rich semantic information which restricts a more profound comprehension of human motions, ultimately leading to unsatisfactory performance.\nTherefore, we propose a novel motion-language representation paradigm to enhance the interpretability of motion representations by constructing a universal motion-language space, where both motion and text features are concretely lexicalized, ensuring that each element of features carries specific semantic meaning.\nSpecifically, we introduce a multi-phase strategy mainly comprising Lexical Bottlenecked Masked Language Modeling to enhance the language model's focus on high-entropy words crucial for motion semantics, Contrastive Masked Motion Modeling to strengthen motion feature extraction by capturing spatiotemporal dynamics directly from skeletal motion, Lexical Bottlenecked Masked Motion Modeling to enable the motion model to capture the underlying semantic features of motion for improved cross-modal understanding, and Lexical Contrastive Motion-Language Pretraining to align motion and text lexicon representations, thereby ensuring enhanced cross-modal coherence.\nComprehensive analyses and extensive experiments across multiple public datasets demonstrate that our model achieves state-of-the-art performance across various tasks and scenarios."
    },
    {
        "title": "WorkflowLLM: Enhancing Workflow Orchestration Capability of Large Language Models",
        "link_suffix": "/forum?id=3Hy00Wvabi",
        "link": "https://openreview.net/forum?id=3Hy00Wvabi",
        "pdf_link": "https://openreview.net/pdf?id=3Hy00Wvabi",
        "keywords": "Large Language Models, Process Automation, Workflow, Tool Learning",
        "abstract": "Recent advancements in large language models (LLMs) have driven a revolutionary paradigm shift in process automation from Robotic Process Automation to Agentic Process Automation by automating the workflow orchestration procedure based on LLMs. However, existing LLMs (even the advanced OpenAI GPT-4o) are confined to achieving satisfactory capability in workflow orchestration. To address this limitation, we present WorkflowLLM, a data-centric framework elaborately designed to enhance the capability of LLMs in workflow orchestration. It first constructs a large-scale fine-tuning dataset WorkflowBench with 106,763 samples, covering 1,503 APIs from 83 applications across 28 categories. Specifically, the construction process can be divided into three phases: (1) Data Collection: we collect real-world workflow data from Apple Shortcuts and RoutineHub, transcribing them into Python-style code. We further equip them with generated hierarchical thought via ChatGPT. (2) Query Expansion: we prompt ChatGPT to generate more task queries to enrich the diversity and complexity of workflows. (3) Workflow Generation: we leverage an annotator model trained on collected data to generate workflows for synthesized queries. Finally, we merge the synthetic samples that pass quality confirmation with the collected samples to obtain the WorkflowBench. Based on WorkflowBench, we fine-tune Llama-3.1-8B to obtain WorkflowLlama. Our experiments show that WorkflowLlama demonstrates a strong capacity to orchestrate complex workflows, while also achieving notable generalization performance on previously unseen APIs. Additionally, WorkflowBench exhibits robust zero-shot generalization capabilities on an out-of-distribution task planning dataset, T-Eval."
    },
    {
        "title": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers",
        "link_suffix": "/forum?id=f3xXPDCh8Q",
        "link": "https://openreview.net/forum?id=f3xXPDCh8Q",
        "pdf_link": "https://openreview.net/pdf?id=f3xXPDCh8Q",
        "keywords": "Neural PDE Solver, Deep Learning",
        "abstract": "Deep models have recently emerged as a promising tool to solve partial differential equations (PDEs), known as neural PDE solvers. While neural solvers trained from either simulation data or physics-informed loss can solve PDEs reasonably well, they are mainly restricted to a few instances of PDEs, e.g. a certain equation with a limited set of coefficients. This limits the generalization of neural solvers to diverse PDEs, impeding them from being practical surrogate models for numerical solvers. In this paper, we present the Universal PDE Solver (Unisolver) capable of solving a wide scope of PDEs by training a novel Transformer model on diverse data and conditioned on diverse PDEs. Instead of purely scaling up data and parameters, Unisolver stems from the theoretical analysis of the PDE-solving process. Our key finding is that a PDE solution is fundamentally under the control of a series of PDE components, e.g. equation symbols, coefficients, and boundary conditions. Inspired by the mathematical structure of PDEs, we define a complete set of PDE components and flexibly embed them as domain-wise (e.g. equation symbols) and point-wise (e.g. boundaries) conditions for Transformer PDE solvers. Integrating physical insights with recent Transformer advances, Unisolver achieves consistent state-of-the-art results on three challenging large-scale benchmarks, showing impressive performance gains and favorable PDE generalizability."
    },
    {
        "title": "Intervening Anchor Token: Decoding Strategy in Alleviating Hallucinations for MLLMs",
        "link_suffix": "/forum?id=zGb4WgCW5i",
        "link": "https://openreview.net/forum?id=zGb4WgCW5i",
        "pdf_link": "https://openreview.net/pdf?id=zGb4WgCW5i",
        "keywords": "Multimodal large language models; Hallucination",
        "abstract": "Multimodal large language models (MLLMs) offer a powerful mechanism for interpreting visual information. However, they often suffer from hallucinations, which impede the real-world usage of these models. Existing methods attempt to alleviate this issue by designing special decoding strategies that penalize the summary tokens. However, these methods lack analysis of the relationship between hallucination and summarization mechanism of LLMs. Interestingly, we find that penalizing summary tokens is not necessary: merely intervening the query-key parameters variance, without costing extra inference time, still alleviates hallucinations. Specifically, we explore the causes of hallucinations by analyzing localized self-attention patterns called ``anchor\" tokens and define the attention localization degree of the model as token propagation probabilities. Our analysis reveals that over-propagation of anchor tokens occurs when the distribution of eigenvalues of the query and key matrices has a non-zero mean and a polarized variance, leading to excessive dependence on anchor tokens while neglecting vision information and describes the image content with hallucination. Based on the observation, we propose a versatile plug-and-play decoding strategy, Dynamic Token Propagation Mechanism (TAME), to alleviate excessive propagation by dynamically intervening the eigenspectrum variance of the attention weight, thereby alleviating hallucinations without relying on complex decoding strategies. Extensive experiments reveal a correlation between the eigenspectrum and hallucinations across various MLLMs, and show that TAME reduces the percentage of hallucinated objects."
    },
    {
        "title": "A Large-scale Interpretable Multi-modality Benchmark for Image Forgery Localization",
        "link_suffix": "/forum?id=7AvYFqcNfn",
        "link": "https://openreview.net/forum?id=7AvYFqcNfn",
        "pdf_link": "https://openreview.net/pdf?id=7AvYFqcNfn",
        "keywords": "Image Forgery Localization, Forgery Detection, Semantic Segmentation, Deepfake Detection, Multimodal Learning, Explainable AI, Salient Region Detection, Image-Text Pair Dataset, Interpretable Machine Learning, Large Language Models (LLMs)",
        "abstract": "Image forgery localization, which centers on identifying tampered pixels within an image, has seen significant advancements. Traditional approaches often model this challenge as a variant of image segmentation, treating the segmentation of forged areas as the end product. However, while semantic segmentation provides distinct regions with clear semantics that are readily interpretable by humans, the interpretation regarding the detected forgery regions is less straightforward and is an under explored problem. We argue that the simplistic binary forgery mask, which merely delineates tampered pixels, fails to provide adequate information for explaining the model's predictions. First, the mask does not elucidate the rationale behind the model's localization. Second, the forgery mask treats all forgery pixels uniformly, which prevents it from emphasizing the most conspicuous unreal regions and ultimately hinders human discernment of the most anomalous areas. In this study, we mitigate the aforementioned limitations by generating salient region-focused interpretation for the forgery images, articulating the rationale behind the predicted forgery mask and underscoring the pivotal forgery regions with a interpretation description. To support this, we craft aMulti-ModalTramperTracing (MMTT) dataset, comprising images manipulated using deepfake techniques and paired with manual, interpretable textual annotations. To harvest high-quality annotation, annotators are instructed to meticulously observe the manipulated images and articulate the typical characteristics of the forgery regions. Subsequently, we collect a dataset of 128,303 image-text pairs. Leveraging the MMTT dataset, we develop ForgeryTalker, an architecture designed for concurrent forgery localization and interpretation. ForgeryTalker first trains a forgery prompter network to identify the pivotal clues within the explanatory text. Subsequently, the region prompter is incorporated into multimodal large language model for finetuning to achieve the dual goals of localization and interpretation. Extensive experiments conducted on the MMTT dataset verify the superior performance of our proposed model."
    },
    {
        "title": "Estimation of single-cell and tissue perturbation effect in spatial transcriptomics via Spatial Causal Disentanglement",
        "link_suffix": "/forum?id=Tqdsruwyac",
        "link": "https://openreview.net/forum?id=Tqdsruwyac",
        "pdf_link": "https://openreview.net/pdf?id=Tqdsruwyac",
        "keywords": "spatial causal inference, spatially disentangled representations, spatial transcriptomics, mechanistic interpretability",
        "abstract": "Models of virtual cells and virtual tissues at single-cell resolution would allow us to test perturbations in silico and accelerate progress in tissue and cell engineering. However, most such models are not rooted in causal inference and as a result, could mistake correlation for causation.\nWe introduce Celcomen, a novel generative graph neural network grounded in mathematical causality to disentangle intra- and inter-cellular gene regulation in spatial transcriptomics and single-cell data. Celcomen can also be prompted by perturbations to generate spatial counterfactuals, thus offering insights into experimentally inaccessible states, with potential applications in human health. We validate the model's disentanglement and identifiability through simulations, and demonstrate its counterfactual predictions in clinically relevant settings, including human glioblastoma and fetal spleen, recovering inflammation-related gene programs post immune system perturbation. Moreover, it supports mechanistic interpretability, as its parameters can be reverse-engineered from observed behavior, making it an accessible model for understanding both neural networks and complex biological systems."
    },
    {
        "title": "Towards Mitigating Factual Hallucination in LLMs through Self-Alignment with Memory",
        "link_suffix": "/forum?id=Hfv4LoCQPo",
        "link": "https://openreview.net/forum?id=Hfv4LoCQPo",
        "pdf_link": "https://openreview.net/pdf?id=Hfv4LoCQPo",
        "keywords": "Hallucination, Large Language Model, Dataset",
        "abstract": "Despite the impressive performance of Large Language Models (LLMs) across numerous tasks and widespread application in real-world scenarios, LLMs still struggle to guarantee their responses to be accurate and aligned with objective facts. This leads to factual hallucination of LLMs, which can be difficult to detect and mislead users lacking relevant knowledge. Post-training techniques have been employed to mitigate this issue, yet they are usually followed by a trade-off between honesty and helpfulness, along with a lack of generalized improvements. In this paper, we propose to address it by augmenting LLM's fundamental capacity of leveraging its internal memory, that is, the knowledge derived from pre-training data. We introduce FactualBench, a comprehensive and precise factual QA dataset consisting of nearly 200k Chinese generative QA data spanning 21 domains for both evaluation and training purposes. Furthermore, we propose self-alignment with memory, i.e., fine-tuning the model via preference learning on self-generated pairwise data from FactualBench. Extensive experiments show that our method significantly enhances LLM's performance on FactualBench, with consistent improvements across various benchmarks concerning factuality, helpfulness and multiple skills. Additionally, different post-training techniques and tuning data sources are discussed to further understand their effectiveness."
    },
    {
        "title": "ComPC: Completing a 3D Point Cloud with 2D Diffusion Priors",
        "link_suffix": "/forum?id=SoUwcVplq4",
        "link": "https://openreview.net/forum?id=SoUwcVplq4",
        "pdf_link": "https://openreview.net/pdf?id=SoUwcVplq4",
        "keywords": "Gaussian Splatting, Diffusion Model, Point Cloud Completion",
        "abstract": "3D point clouds directly collected from objects through sensors are often incomplete due to self-occlusion. Conventional methods for completing these partial point clouds rely on manually organized training sets and are usually limited to object categories seen during training. In this work, we propose a test-time framework for completing partial point clouds across unseen categories without any requirement for training. Leveraging point rendering via Gaussian Splatting, we develop techniques of Partial Gaussian Initialization, Zero-shot Fractal Completion, and Point Cloud Extraction that utilize priors from pre-trained 2D diffusion models to infer missing regions and extract uniform completed point clouds. Experimental results on both synthetic and real-world scanned point clouds demonstrate that our approach outperforms existing methods in completing a variety of objects."
    },
    {
        "title": "Privacy-Preserving Logistic Regression Training with A Faster Gradient Variant",
        "link_suffix": "/forum?id=HJWdrvVyOi",
        "link": "https://openreview.net/forum?id=HJWdrvVyOi",
        "pdf_link": "https://openreview.net/pdf?id=HJWdrvVyOi",
        "keywords": "Homomorphic Encryption, Logistic Regression, Quadratic Gradient, Simplified Fixed Hessian, Nesterov\u2019s Accelerated Gradient, Gradient Ascent Algorithm",
        "abstract": "Training logistic regression over encrypted data has been a compelling approach in addressing security concerns for several years. In this paper, we introduce an efficient gradient variant, called $quadratic$ $gradient$, for privacy-preserving logistic regression training. We enhance Nesterov's Accelerated Gradient (NAG), Adaptive Gradient Algorithm (Adagrad) and Adam algorithms by incorporating their quadratic gradients and evaluate these improved algorithms on various datasets. Experimental results demonstrate that the enhanced algorithms achieve significantly improved convergence speed compared to traditional first-order gradient methods. Moreover, we applied the enhanced NAG method to implement homomorphic logistic regression training, achieving comparable results within just 4 iterations.\nThere is a good chance that the quadratic gradient approach could integrate first-order gradient descent/ascent algorithms with the second-order Newton-Raphson methods, and that it could be applied to a wide range of numerical optimization problems."
    },
    {
        "title": "SINGER: Stochastic Network Graph Evolving Operator for High Dimensional PDEs",
        "link_suffix": "/forum?id=wVADj7yKee",
        "link": "https://openreview.net/forum?id=wVADj7yKee",
        "pdf_link": "https://openreview.net/pdf?id=wVADj7yKee",
        "keywords": "PDE, High Dimension, Neural ODE",
        "abstract": "We present a novel framework, StochastIc Network Graph Evolving operatoR (SINGER), for learning the evolution operator of high-dimensional partial differential equations (PDEs). The framework uses a sub-network to approximate the solution at the initial time step and stochastically evolves the sub-network parameters over time by a graph neural network to approximate the solution at later time steps. The framework is designed to inherit the desirable properties of the parametric solution operator, including graph topology, semigroup, and stability, with a theoretical guarantee. Numerical experiments on 8 evolution PDEs of 5,10,15,20-dimensions show that our method outperforms existing baselines in almost all cases (31 out of 32), and that our method generalizes well to unseen initial conditions, equation dimensions, sub-network width, and time steps."
    },
    {
        "title": "PhysPDE: Rethinking PDE Discovery and a Physical HYpothesis Selection Benchmark",
        "link_suffix": "/forum?id=G3CpBCQwNh",
        "link": "https://openreview.net/forum?id=G3CpBCQwNh",
        "pdf_link": "https://openreview.net/pdf?id=G3CpBCQwNh",
        "keywords": "AI4Science, Physics, PDEs, PDE Discovery",
        "abstract": "Despite extensive research, recovering PDE expressions from experimental observations often involves symbolic regression. This method generally lacks the incorporation of meaningful physical insights, resulting in outcomes lacking clear physical interpretations. Recognizing that the primary interest of Machine Learning for Science (ML4Sci) often lies in understanding the underlying physical mechanisms or even discovering new physical laws rather than simply obtaining mathematical expressions, this paper introduces a novel ML4Sci task paradigm. This paradigm focuses on interpreting experimental data within the framework of prior physical hypotheses and theories, thereby guiding and constraining the discovery of PDE expressions. We have formulated this approach as a nonlinear mixed-integer programming (MIP) problem, addressed through an efficient search scheme developed for this purpose. Our experiments on newly designed Fluid Mechanics and Laser Fusion datasets demonstrate the interpretability and feasibility of this method."
    },
    {
        "title": "High-Dynamic Radar Sequence Prediction for Weather Nowcasting Using Spatiotemporal Coherent Gaussian Representation",
        "link_suffix": "/forum?id=Cjz9Xhm7sI",
        "link": "https://openreview.net/forum?id=Cjz9Xhm7sI",
        "pdf_link": "https://openreview.net/pdf?id=Cjz9Xhm7sI",
        "keywords": "3D Gaussian, Dynamic Reconstruction, Radar Prediction, Weather Nowcasting",
        "abstract": "Weather nowcasting is an essential task that involves predicting future radar echo sequences based on current observations, offering significant benefits for disaster management, transportation, and urban planning. Current prediction methods are limited by training and storage efficiency, mainly focusing on 2D spatial predictions at specific altitudes. Meanwhile, 3D volumetric predictions at each timestamp remain largely unexplored. To address such a challenge, we introduce a comprehensive framework for 3D radar sequence prediction in weather nowcasting, using the newly proposed SpatioTemporal Coherent Gaussian Splatting (STC-GS) for dynamic radar representation and GauMamba for efficient and accurate forecasting. Specifically, rather than relying on a 4D Gaussian for dynamic scene reconstruction, STC-GS optimizes 3D scenes at each frame by employing a group of Gaussians while effectively capturing their movements across consecutive frames. It ensures consistent tracking of each Gaussian over time, making it particularly effective for prediction tasks. With the temporally correlated Gaussian groups established, we utilize them to train GauMamba, which integrates a memory mechanism into the Mamba framework. This allows the model to learn the temporal evolution of Gaussian groups while efficiently handling a large volume of Gaussian tokens. As a result, it achieves both efficiency and accuracy in forecasting a wide range of dynamic meteorological radar signals. The experimental results demonstrate that our STC-GS can efficiently represent 3D radar sequences with over $16\\times$ higher spatial resolution compared with the existing 3D representation methods, while GauMamba outperforms state-of-the-art methods in forecasting a broad spectrum of high-dynamic weather conditions."
    },
    {
        "title": "Track-On: Transformer-based Online Point Tracking with Memory",
        "link_suffix": "/forum?id=oRlANEuqG5",
        "link": "https://openreview.net/forum?id=oRlANEuqG5",
        "pdf_link": "https://openreview.net/pdf?id=oRlANEuqG5",
        "keywords": "Point Tracking, Online Point Tracking, Tracking Any Point",
        "abstract": "In this paper, we consider the problem of long-term point tracking, which requires consistent identification of points across multiple frames in a video, despite changes in appearance, lighting, perspective, and occlusions. Unlike existing point tracking approaches, we target online tracking on a frame-by-frame basis, making it suitable for real-world, streaming scenarios. We introduce Track-On, a simple transformer-based model designed for online long-term point tracking. Our model processes video frames sequentially without access to future frames, leveraging two memory modules \u2014spatial memory and context memory\u2014 to capture temporal information and maintain reliable point tracking over long time horizons. Unlike prior methods that depend on iterative updates and full temporal modeling, our approach employs patch classification and refinement to identify correspondences and track points with high accuracy. Through extensive experiments, we demonstrate that Track-On sets a new state-of-the-art for online models and delivers superior or competitive results compared to offline approaches on TAP-Vid benchmark. Our method offers a robust and scalable solution for real-time tracking in diverse applications."
    },
    {
        "title": "Large Language Models Meet Symbolic Provers for Logical Reasoning Evaluation",
        "link_suffix": "/forum?id=C25SgeXWjE",
        "link": "https://openreview.net/forum?id=C25SgeXWjE",
        "pdf_link": "https://openreview.net/pdf?id=C25SgeXWjE",
        "keywords": "logical reasoning, symbolic provers, LLMs evaluation",
        "abstract": "First-order logic (FOL) reasoning, which involves sequential deduction, is pivotal for intelligent systems and serves as a valuable task for evaluating reasoning capabilities, particularly in chain-of-thought (CoT) contexts. Existing benchmarks often rely on extensive human annotation or handcrafted templates, making it difficult to achieve the necessary complexity, scalability, and diversity for robust evaluation. To address these limitations, we propose a novel framework that synergizes the generative strengths of Large Language Models (LLMs) with the rigor and precision of symbolic provers, enabling the creation of a scalable, diverse, and high-quality FOL reasoning dataset, ProverGen. Our evaluation shows that state-of-the-art LLMs struggle to solve ProverGen problems, even with CoT prompting, highlighting the dataset\u2019s challenging nature. We also finetune Llama3.1-8B-Instruct on a separate training set generated by our framework. The finetuned model demonstrates consistent improvements on both in-distribution and out-of-distribution test sets, suggesting the value of our proposed data generation framework\\footnote{We will release our code as well as the dataset.}."
    },
    {
        "title": "Capturing substructure interactions by invariant Information Bottle Theory for Generalizable Property Prediction",
        "link_suffix": "/forum?id=IiMKfn4dxk",
        "link": "https://openreview.net/forum?id=IiMKfn4dxk",
        "pdf_link": "https://openreview.net/pdf?id=IiMKfn4dxk",
        "keywords": "Molecular Merged Graph.+ Drug-drug interaction.+ Out-of-Distribution",
        "abstract": "Molecular interactions are a common phenomenon in physical chemistry, often resulting in unexpected biochemical properties harmful to humans, such as drug-drug interactions. Machine learning has shown great potential for predicting these interactions rapidly and accurately. However, the complexity of molecular structures and the diversity of interactions often reduce prediction accuracy and hinder generalizability. Identifying core invariant substructures (i.e., rationales) has become essential to improving the model's interpretability and generalization. Despite significant progress, existing models frequently overlook the pairwise molecular interaction, leading to insufficient capture of interaction dynamics. To address these limitations, we propose I2Mole (Interaction-aware Invariant Molecular learning), a novel framework for generalizable property prediction. I2Mole meticulously models atomic interactions, such as hydrogen bonds and Van der Waals forces, by first establishing indiscriminate connections between intermolecular atoms, which are then refined using an improved graph information bottleneck theory tailored for merged graphs. To further enhance model generalization, we construct an environment codebook by environment subgraph of the merged graph. This approach not only could provide noise source for optimizing mutual information but also preserve the integrity of chemical semantic information. By comprehensively leveraging the information inherent in the merged graph, our model accurately captures core substructures and significantly enhances generalization capabilities. Extensive experimental validation demonstrates I2Mole's efficacy and generalizability. The implementation code is available athttps://anonymous.4open/r/I2Mol-C616."
    },
    {
        "title": "Spatiotemporal Backward Inconsistency Learning Gives STGNNs Icing on the Cake",
        "link_suffix": "/forum?id=7rOdRAGuBA",
        "link": "https://openreview.net/forum?id=7rOdRAGuBA",
        "pdf_link": "https://openreview.net/pdf?id=7rOdRAGuBA",
        "keywords": "spatiotemporal learning; time series learning; graph neraul network",
        "abstract": "Spatiotemporal prediction models facilitate various smart-city applications across various domains,such as traffic and climate. While current advancements in these models emphasize leveraging cutting-edge technologies to enhance spatiotemporal learning, they often operate under the implicit assumption of spatiotemporal feature consistency between inputs and labels, overlooking the critical issue of input-label inconsistency. In this study, we introduce a universal spatiotemporal backward inconsistency learning module capable of seamless integration into a variety of models, offering a notable performance boost by explicitly modeling label features to address input-label inconsistency. Our approach includes the development of a spatiotemporal residual theory, advocating for a holistic spatiotemporal learning that encompasses both forward spatiotemporal learning to capture input data\u2019s spatiotemporal features for generating base predictions, akin to existing STNNs, and a backward process to learn residuals that rectify input-label inconsistency, thereby refining the base predictions. Based on this theory, we design the Spatio-Temporal Backward Inconsistency Learning Module (STBIM) for this backward correction process, comprising a residual learning module for decoupling inconsistency information from input representations and label representations, and a residual propagation module for smoothing residual terms to facilitate stable learning. The generated prediction correction term is used to enhance the prediction accuracy. Experimental results on 11 datasets from the traffic and atmospheric domains, combined with 15 spatiotemporal prediction models, demonstrate the broad positive impact of the proposed STBIM. The code is available athttps://anonymous.4open.science/r/ICLR2025-2598."
    }
]
[
    {
        "title": "A Multimodal Class-Incremental Learning benchmark for classification tasks",
        "link_suffix": "/forum?id=gNoqEdT2wO",
        "link": "https://openreview.net/forum?id=gNoqEdT2wO",
        "pdf_link": "https://openreview.net/pdf?id=gNoqEdT2wO",
        "keywords": "multimodal, continual learning, incremental learning, benchmark, vision, language, vision-language, multimodal continual learning",
        "abstract": "Continual learning has made significant progress in addressing catastrophic forgetting in vision and language domains, yet the majority of research has treated these modalities separately. The exploration of multimodal continual learning remains sparse, with a few existing works focused on specific applications like VQA, text-to-vision retrieval, and incremental multi-tasking. These efforts lack a general benchmark to standardize the evaluation of models in multimodal continual learning settings. In this paper, we introduce a novel benchmark for Multimodal Class-Incremental Learning (MCIL), designed specifically for multimodal classification tasks. Our benchmark comprises a curated selection of multimodal datasets tailored to classification challenges. We further adapt a widely used Vision-Language model to multiple existing continual learning strategies, providing crucial insights into the behavior of vision-language models in incremental classification tasks. This work represents the first comprehensive framework for MCIL, establishing a foundation for future research in multimodal continual learning."
    },
    {
        "title": "The Fair Language Model Paradox",
        "link_suffix": "/forum?id=Kb1bIuGuax",
        "link": "https://openreview.net/forum?id=Kb1bIuGuax",
        "pdf_link": "https://openreview.net/pdf?id=Kb1bIuGuax",
        "keywords": "LLM, Fairness, WeightDecay, Unbalanced",
        "abstract": "Large Language Models (LLMs) are widely deployed in real-world applications, yet little is known about their training dynamics at the token level. Evaluation typically relies on aggregated training loss, measured at the batch level, which overlooks subtle per-token biases arising from (i) varying token-level dynamics and (ii) structural biases introduced by hyperparameters. While weight decay is commonly used to stabilize training, we reveal that it silently introduces performance biases detectable only at the token level. In fact, we empirically show across different dataset sizes, model architectures and sizes ranging from 270M to 3B parameters that as weight decay increases, low-frequency tokens are disproportionately depreciated. This is particularly concerning, as these neglected low-frequency tokens represent the vast majority of the token distribution in most languages, calling for novel regularization techniques that ensure fairness across all available tokens."
    },
    {
        "title": "Causal Representation Learning from Multimodal Biological Observations",
        "link_suffix": "/forum?id=hjROBHstZ3",
        "link": "https://openreview.net/forum?id=hjROBHstZ3",
        "pdf_link": "https://openreview.net/pdf?id=hjROBHstZ3",
        "keywords": "multimodal observations, identifiability, causal representation learning",
        "abstract": "Prevalent in biological applications (e.g., human phenotype measurements), multimodal datasets can provide valuable insights into the underlying biological mechanisms. However, current machine learning models designed to analyze such datasets still lack interpretability and theoretical guarantees, which are essential to biological applications. Recent advances in causal representation learning have shown promise in uncovering the interpretable latent causal variables with formal theoretical certificates. Unfortunately, existing works for multimodal distributions either rely on restrictive parametric assumptions or provide rather coarse identification results, limiting their applicability to biological research which favors a detailed understanding of the mechanisms.In this work, we aim to develop flexible identification conditions for multimodal data and principled methods to facilitate the understanding of biological datasets. Theoretically, we consider a flexible nonparametric latent distribution (c.f., parametric assumptions in prior work) permitting causal relationships across potentially different modalities. We establish identifiability guarantees for each latent component, extending the subspace identification results from prior work. Our key theoretical ingredient is the structural sparsity of the causal connections among distinct modalities, which, as we will discuss, is natural for a large collection of biological systems. Empirically, we propose a practical framework to instantiate our theoretical insights. We demonstrate the effectiveness of our approach through extensive experiments on both numerical and synthetic datasets. Results on a real-world human phenotype dataset are consistent with established medical research, validating our theoretical and methodological framework."
    },
    {
        "title": "Implicit Dynamical Flow Fusion (IDFF) for Generative Modeling",
        "link_suffix": "/forum?id=iBS5SmeofT",
        "link": "https://openreview.net/forum?id=iBS5SmeofT",
        "pdf_link": "https://openreview.net/pdf?id=iBS5SmeofT",
        "keywords": "Generative modeling, Conditional Flow Matching (CFM), Image generation, Time-series generation, Flow-based models",
        "abstract": "Conditional Flow Matching (CFM) models can generate high-quality samples from a non-informative prior, but they can be slow, often needing hundreds of network evaluations (NFE). To address this, we propose Implicit Dynamical Flow Fusion (IDFF); IDFF learns a new vector field with an additional momentum term that enables taking longer steps during sample generation while maintaining the fidelity of the generated distribution. Consequently, IDFFs reduce the NFEs by a factor of ten (relative to CFMs) without sacrificing sample quality, enabling rapid sampling and efficient handling of image and time-series data generation tasks. We evaluate IDFF on standard benchmarks such as CIFAR-10 and CelebA for image generation, where we achieve likelihood and quality performance comparable to CFMs and diffusion-based models with fewer NFEs. IDFF also shows superior performance on time-series datasets modeling, including molecular simulation and sea surface temperature (SST) datasets, highlighting its versatility and effectiveness across different domains."
    },
    {
        "title": "Neural Electrostatics: A 3D Physics-Informed Boundary Element Poisson Equation Solver",
        "link_suffix": "/forum?id=HyqTTe85MZ",
        "link": "https://openreview.net/forum?id=HyqTTe85MZ",
        "pdf_link": "https://openreview.net/pdf?id=HyqTTe85MZ",
        "keywords": "PINN, physics informed, scientific machine learning, electrostatics, scientific computing",
        "abstract": "Electrostatics solvers relate an imposed voltage to a\ncorresponding charge density. Current classical methods require fine\ndiscretization and scale poorly due to the construction of a large linear system\nof equations. We recast the problem using neural networks and introduce\nneural electrostatics, a hybrid 3D boundary element method (BEM). By using the\nboundary element form, we are able to overcome many shortcomings of previous\nneural solvers, such as learning trivial solutions and balancing loss terms\nbetween the domain and boundary, at the cost of introducing a large integral\ncontaining a singular kernel. We handle this singularity by locally\ntransforming the integral into polar coordinates and applying a numerical\nquadrature. We also show that previous neural solver sampling methods are unable\nto minimize the PDE residual, and propose a variational adaptive sampling\nmethod. This technique is able to reduce mean absolute error by 5 times, while\nkeeping training time constant. Extensive scaling and ablation studies are\nperformed to justify our method. Results show that our method learns a charge\ndistribution within 1.2 $pC/m^2$ of mean absolute error from a classical BEM\nsolver, while using 25 times fewer rectangular elements."
    },
    {
        "title": "Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized Control",
        "link_suffix": "/forum?id=pfS4D6RWC8",
        "link": "https://openreview.net/forum?id=pfS4D6RWC8",
        "pdf_link": "https://openreview.net/pdf?id=pfS4D6RWC8",
        "keywords": "diffusion models, reinforcement learning",
        "abstract": "Diffusion models excel at capturing complex data distributions, such as those of natural images and proteins. While diffusion models are trained to represent the distribution in the training dataset, we often are more concerned with other properties, such as the aesthetic quality of the generated images or the functional properties of generated proteins. Diffusion models can be finetuned in a goal-directed way by maximizing the value of some reward function (e.g., the aesthetic quality of an image). However, these approaches may lead to reduced sample diversity, significant deviations from the training data distribution, and even poor sample quality due to the exploitation of an imperfect reward function. The last issue often occurs when the reward function is a learned model meant to approximate a ground-truth \"genuine\" reward, as is the case in many practical applications. These challenges, collectively termed \"reward collapse,\" pose a substantial obstacle. To address this reward collapse, we frame the finetuning problem as entropy-regularized control against the pretrained diffusion model, i.e., directly optimizing entropy-enhanced rewards with neural SDEs. We present theoretical and empirical evidence that demonstrates our framework is capable of efficiently generating diverse samples with high genuine rewards, mitigating the overoptimization of imperfect reward models."
    },
    {
        "title": "Asynchronous Factorization for Multi-Agent Reinforcement Learning",
        "link_suffix": "/forum?id=5pd46nlxc6",
        "link": "https://openreview.net/forum?id=5pd46nlxc6",
        "pdf_link": "https://openreview.net/pdf?id=5pd46nlxc6",
        "keywords": "Macro-actions, Multi-Agent Reinforcement Learning, Asynchronous Factorization.",
        "abstract": "Value factorization is widely used to design high-quality, scalable multi-agent reinforcement learning algorithms. However, current methods typically assume agents execute synchronous, 1-stepprimitive actions, failing to capture the typical nature of multi-agent systems. In reality, agents are asynchronous and executemacro-actions---extended actions of variable and unknown duration---making decisions at different times. This paper proposes value factorization for asynchronous agents. First, we formalize the requirements for consistency between centralized and decentralized macro-action selection, proving they generalize the primitive case. We then propose update schemes to enable factorization architectures to support macro-actions. We evaluate these asynchronous factorization algorithms on standard macro-action benchmarks, showing they scale and perform well on complex coordination tasks where their synchronous counterparts fail."
    },
    {
        "title": "Backpropagation-free training of neural PDE solvers for time-dependent problems",
        "link_suffix": "/forum?id=4KKqHIb4iG",
        "link": "https://openreview.net/forum?id=4KKqHIb4iG",
        "pdf_link": "https://openreview.net/pdf?id=4KKqHIb4iG",
        "keywords": "neural PDE solvers, time-dependent partial differential equations, random feature networks, backpropagation-free training",
        "abstract": "Approximating solutions to time-dependent Partial Differential Equations (PDEs) is one of the most important problems in computational science. Neural PDE solvers have shown promise recently because they are mesh-free and easy to implement. However, backpropagation-based training often leads to poor approximation accuracy and long training time. In particular, capturing high-frequency temporal dynamics and solving over long time spans pose significant challenges. To address these, we present an approach to training neural PDE solvers without back-propagation by integrating two key ideas: separation of space and time variables and random sampling of weights and biases of the hidden layers. We reformulate the PDE as an ordinary differential equation using a neural network ansatz, construct neural basis functions only in the spatial domain, and solve the ODE leveraging classical ODE solvers from scientific computing. We demonstrate that our backpropagation-free algorithm outperforms the iterative, gradient-based optimization of physics-informed neural networks with respect to training time and accuracy, often by several orders of magnitude using different complicated PDEs characterized by high-frequency temporal dynamics, long time span, complex spatial domain, non-linearities, and shocks."
    },
    {
        "title": "AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs",
        "link_suffix": "/forum?id=bhK7U37VW8",
        "link": "https://openreview.net/forum?id=bhK7U37VW8",
        "pdf_link": "https://openreview.net/pdf?id=bhK7U37VW8",
        "keywords": "Large Language Model, Jailbreak Attack, LLM Agent",
        "abstract": "Jailbreak attacks serve as essential red-teaming tools, proactively assessing whether LLMs can behave responsibly and safely in adversarial environments. Despite diverse strategies (e.g., cipher, low-resource language, persuasions, and so on) that have been proposed and shown success, these strategies are still manually designed, limiting their scope and effectiveness as a red-teaming tool. In this paper, we propose AutoDAN-Turbo, a black-box jailbreak method that can automatically discover as many jailbreak strategies as possible from scratch, without any human intervention or predefined scopes (e.g., specified candidate strategies), and use them for red-teaming. As a result, AutoDAN-Turbo can significantly outperform baseline methods, achieving a 74.3% higher average attack success rate on public benchmarks. Notably, AutoDAN-Turbo achieves an 88.5 attack success rate on GPT-4-1106-turbo. In addition, AutoDAN-Turbo is a unified framework that can incorporate existing human-designed jailbreak strategies in a plug-and-play manner. By integrating human-designed strategies, AutoDAN-Turbo can even achieve a higher attack success rate of 93.4 on GPT-4-1106-turbo."
    },
    {
        "title": "Towards Automated Knowledge Integration From Human-Interpretable Representations",
        "link_suffix": "/forum?id=NTHMw8S1Ow",
        "link": "https://openreview.net/forum?id=NTHMw8S1Ow",
        "pdf_link": "https://openreview.net/pdf?id=NTHMw8S1Ow",
        "keywords": "informed machine learning, knowledge integration, data efficiency, prior knowledge",
        "abstract": "In noisy and low-data environments, a significant challenge in machine learning lies in effectively incorporating inductive biases that enhance data efficiency and robustness. Despite many success of informed machine learning methods, designing algorithms with explicit inductive biases based on prior expert knowledge remains largely a manual process. In this work, we explore how prior knowledge represented in its native formats, e.g. in natural language, can be integrated into machine learning models in an automated manner. Inspired by the learning to learn principles of meta-learning, we consider an approach of learning to integrate knowledge via conditional meta-learning, a paradigm we refer to as informed meta-learning. We introduce and motivate theoretically the principles of informed meta-learning enabling automated and controllable inductive bias selection. To illustrate our claims, we implement an instantiation of informed meta-learning--the Informed Neural Process, and empirically demonstrate the potential benefits and limitations of informed meta-learning in improving data efficiency and generalizing to novel knowledge representations."
    },
    {
        "title": "On the Learn-to-Optimize Capabilities of Transformers in In-Context Sparse Recovery",
        "link_suffix": "/forum?id=NHhjczmJjo",
        "link": "https://openreview.net/forum?id=NHhjczmJjo",
        "pdf_link": "https://openreview.net/pdf?id=NHhjczmJjo",
        "keywords": "Transformer, In-context learning, Learning-to-optimize",
        "abstract": "An intriguing property of the Transformer is its ability to perform in-context learning (ICL), where the Transformer can solve different inference tasks without parameter updating based on the contextual information provided by the corresponding input-output demonstration pairs. It has been theoretically proved that ICL is enabled by the capability of Transformers to perform gradient-descent algorithms (Von Oswald et al., 2023a; Bai et al., 2024). This work takes a step further and shows that Transformers can perform learning-to-optimize (L2O) algorithms. Specifically, for the ICL sparse recovery (formulated as LASSO) tasks, we show that a K-layer Transformer can perform an L2O algorithm with a provable convergence rate linear in K. This provides a new perspective explaining the superior ICL capability of Transformers, even with only a few layers, which cannot be achieved by the standard gradient-descent algorithms. Moreover, unlike the conventional L2O algorithms that require the measurement matrix involved in training to match that in testing, the trained Transformer is able to solve sparse recovery problems generated with different measurement matrices.  Besides, Transformers as an L2O algorithm can leverage structural information embedded in the training tasks to accelerate its convergence during ICL, and generalize across different lengths of demonstration pairs, where conventional L2O algorithms typically struggle or fail. Such theoretical findings are supported by our experimental results."
    },
    {
        "title": "RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems",
        "link_suffix": "/forum?id=KDXj60FpJr",
        "link": "https://openreview.net/forum?id=KDXj60FpJr",
        "pdf_link": "https://openreview.net/pdf?id=KDXj60FpJr",
        "keywords": "Retrieval Augmented Generation, Language Modeling, Question Answering",
        "abstract": "Retrieval-augmented generation (RAG) systems have shown promise in improving\ntask performance by leveraging external context, but realizing their full potential\ndepends on careful configuration. In this paper, we investigate how the choice of\nretriever and reader models, context length, and context quality impact RAG per-\nformance across different task types. Our findings reveal that while some readers\nconsistently benefit from additional context, others degrade when exposed to irrele-\nvant information, highlighting the need for tuning based on reader sensitivity to\nnoise. Moreover, retriever improvements do not always translate into proportional\ngains in reader results, particularly in open-domain questions. However, in spe-\ncialized tasks, even small improvements in retrieval can significantly boost reader\nresults. These insights underscore the importance of optimizing RAG systems by\naligning configurations with task complexity and domain-specific needs."
    },
    {
        "title": "SVIP: Towards Verifiable Inference of Open-source Large Language Models",
        "link_suffix": "/forum?id=cpZMsDwRie",
        "link": "https://openreview.net/forum?id=cpZMsDwRie",
        "pdf_link": "https://openreview.net/pdf?id=cpZMsDwRie",
        "keywords": "Large Language Models; Verifiable Inference; Trustworthy AI; Adversarial Attack",
        "abstract": "Open-source Large Language Models (LLMs) have recently demonstrated remarkable capabilities in natural language understanding and generation, leading to widespread adoption across various domains. However, their increasing model sizes render local deployment impractical for individual users, pushing many to rely on computing service providers for inference through a blackbox API. This reliance introduces a new risk: a computing provider may stealthily substitute the requested LLM with a smaller, less capable model without consent from users, thereby delivering inferior outputs while benefiting from cost savings. In this paper, we formalize the problem of verifiable inference for LLMs. Existing verifiable computing solutions based on cryptographic or game-theoretic techniques are either computationally uneconomical or rest on strong assumptions. We introduce $\\texttt{SVIP}$, a secret-based verifiable LLM inference protocol that leverages intermediate outputs from LLM as unique model identifiers. By training a proxy task on these outputs and requiring the computing provider to return both the generated text and the processed intermediate outputs, users can reliably verify whether the computing provider is acting honestly. In addition, the integration of a secret mechanism further enhances the security of our protocol. We thoroughly analyze our protocol under multiple strong and adaptive adversarial scenarios. Our extensive experiments demonstrate that $\\texttt{SVIP}$ is accurate, generalizable, computationally efficient, and resistant to various attacks. Notably, $\\texttt{SVIP}$ achieves false negative rates below  $5\\%$ and false positive rates below  $3\\%$, while requiring less than $0.01$ seconds per query for verification."
    },
    {
        "title": "Towards Understanding Why Group Robustness Methods Work",
        "link_suffix": "/forum?id=hmXUWc1ugd",
        "link": "https://openreview.net/forum?id=hmXUWc1ugd",
        "pdf_link": "https://openreview.net/pdf?id=hmXUWc1ugd",
        "keywords": "robustness fairness deep learning",
        "abstract": "Deep Learning has made remarkable strides, yet models trained under conventional Empirical Risk Minimization (ERM) approaches encounter challenges regarding their generalization capabilities. In particular, a lack of robustness to spurious correlations. In response, Group Robustness Methods (GRMs) have been developed to combat them. These methods partition training datasets into distinct groups based on spurious features and class labels and adjust their weighting in the loss function. These methods show remarkable performance in dealing with spurious correlations. The underlying mechanisms for their success, however, are not so well understood. Our work contributes by shedding light on the learning dynamics of GRMs, through an empirical and theoretical analysis of them that reveals the differences in feature learning and the type of classifiers they learn versus ERM. Surprisingly, both GRMs and ERM models retain spurious information in their representations, even when it is irrelevant to the task at hand. We find evidence that suggests that the key to GRMs' success is two-fold: distributing prediction across multiple features in representation space to avoid relying on few but spurious attributes and incentivizing the classifier to become orthogonal to spurious features. We verify our findings by proposing an upgrade to the Subsampling baseline method called Group Distributionally Robust Feature Reweighting (GDRFR) that is easy to compute and only requires a fraction of group labels during a finetuning phase and retrieve most of GRMs performance gains over ERM."
    },
    {
        "title": "Provably Mitigating Corruption, Overoptimization, and Verbosity Simultaneously in Offline and Online RLHF/DPO Alignment",
        "link_suffix": "/forum?id=K2OWrXUVby",
        "link": "https://openreview.net/forum?id=K2OWrXUVby",
        "pdf_link": "https://openreview.net/pdf?id=K2OWrXUVby",
        "keywords": "RLHF, DPO, large language model, alignment",
        "abstract": "Reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO) are emerging and important techniques to align large language models (LLM) with human preference. However, the quality of RLHF and DPO training is seriously compromised byCorruptedpreference, rewardOveroptimization, and bias towardsVerbosity. To our knowledge, most existing works tackle only one of these important issues, and the few other works require much computation to estimate multiple reward models and lack theoretical guarantee of generalization ability. In this work, we propose RLHF-COVand DPO-COValgorithms that can simultaneously mitigate these three issues, in both offline and online settings. This ability is theoretically demonstrated by obtaining length-regularized generalization error rates for our DPO-COV algorithms trained on corrupted data, which match the best-known rates for simpler cases with clean data and without length regularization. Moreover, our DPO-COV algorithm is simple to implement without reward estimation, and is proved to be equivalent to our RLHF-COV algorithm, which directly implies the equivalence between the vanilla RLHF and DPO algorithms."
    },
    {
        "title": "Resolving Lexical Bias in Edit Scoping with Projector Editor Networks",
        "link_suffix": "/forum?id=QyhxT8xska",
        "link": "https://openreview.net/forum?id=QyhxT8xska",
        "pdf_link": "https://openreview.net/pdf?id=QyhxT8xska",
        "keywords": "Representation Learning, Model Editing and LLM's",
        "abstract": "Weight-preserving large language model editing techniques rely heavily on the scoping mechanism that decides when to apply an edit to the base model. These scoping mechanisms utilize distance functions in the representation space. In this work, we show that distance-based scoping functions grapple with strong lexical biases leading to issues such as deciding that irrelevant prompts that share overlapping words should result in applying an edit. We address these problems by introducing Projector Editor Networks for Model Editing (PENME), a principled model editing approach designed to learn the optimal representation space for scoping via contrastive learning. We show that PENME achieves state of the art model editing results while being compute-efficient at inference time than previous methods and flexible enough to adapt across architectures"
    },
    {
        "title": "No more hard-prompts: SoftSRV prompting for synthetic data generation",
        "link_suffix": "/forum?id=BeT8QvxCk2",
        "link": "https://openreview.net/forum?id=BeT8QvxCk2",
        "pdf_link": "https://openreview.net/pdf?id=BeT8QvxCk2",
        "keywords": "Synthetic Data Generation, Language Models, LLMs, Fine-tuning",
        "abstract": "We present a novel soft-prompt based framework, SoftSRV, that leverages a frozen pre-trained large language model (LLM) to generate targeted synthetic text sequences. Given a sample from the target distribution, our proposed framework uses data-driven loss minimization to train a parameterized ``variable'' soft-prompt. This soft-prompt is then used to steer the frozen LLM to generate synthetic sequences that are similar to the target distribution. We argue that SoftSRV provides a practical improvement over common hard-prompting approaches that rely on human-curated prompt-templates, which can be idiosyncratic, labor intensive to craft, and may need to be specialized per domain. We empirically evaluate SoftSRV and other baselines, using a frozen large decoder-only model to generate synthetic fine-tuning data for a small Gemma model. To test generality, we evaluate across three different domains (coding, math, reasoning) without any particular specialization to each domain. In this challenging setting, SoftSRV significantly improves upon hard-prompt baselines, generating data with superior fine-tuning performance and that better matches the target distribution according to the {\\sc mauve} similarity metric."
    },
    {
        "title": "OvercookedV2: Rethinking Overcooked for Zero-Shot Coordination",
        "link_suffix": "/forum?id=hlvLM3GX8R",
        "link": "https://openreview.net/forum?id=hlvLM3GX8R",
        "pdf_link": "https://openreview.net/pdf?id=hlvLM3GX8R",
        "keywords": "multi-agent reinforcement learning, reinforcement learning, multi-agent systems, zero-shot coordination, overcooked, human-AI coordination",
        "abstract": "AI agents hold the potential to transform everyday life by helping humans achieve their goals.\nTo do this successfully, agents need to be able to coordinate with novel partners without prior interaction, a setting known as zero-shot coordination (ZSC).\nOvercooked has become one of the most popular benchmarks for evaluating coordination capabilities of AI agents and learning algorithms.\nIn this work, we investigate the origins of ZSC challenges in Overcooked.\nWe introduce a state augmentation mechanism which mixes states that might be encountered when paired with unknown partners into the training distribution, reducing the out-of-distribution challenge associated with ZSC.\nWe show that independently trained agents under this algorithm coordinate successfully in Overcooked.\nOur results suggest that ZSC failure can largely be attributed to poor state coverage under self-play rather than more sophisticated coordination challenges. The Overcooked environment is therefore not suitable as a ZSC benchmark.\nTo address these shortcomings, we introduce OvercookedV2, a new version of the benchmark, which includes asymmetric information and stochasticity, facilitating the creation of interesting ZSC scenarios.\nTo validate OvercookedV2, we conduct experiments demonstrating that mere exhaustive state coverage is insufficient to coordinate well. Finally, we use OvercookedV2 to build a new range of coordination challenges, including ones that require test time protocol formation, and we demonstrate the need for new coordination algorithms that can adapt online.\nWe hope that OvercookedV2 will help benchmark the next generation of ZSC algorithms and advance collaboration between AI agents and humans."
    },
    {
        "title": "Sketching for Convex and Nonconvex Regularized Least Squares with Sharp Guarantees",
        "link_suffix": "/forum?id=7liN6uHAQZ",
        "link": "https://openreview.net/forum?id=7liN6uHAQZ",
        "pdf_link": "https://openreview.net/pdf?id=7liN6uHAQZ",
        "keywords": "Sketching, Random Projection, Minimax Rates",
        "abstract": "Randomized algorithms are important for solving large-scale optimization problems efficiently. In this paper, we propose a fast sketching algorithm for least square problems regularized by convex or nonconvex regularization functions, Sketching for Regularized Optimization, or SRO. SRO first generates a sketch of the original data matrix, then solves the sketched problem. We prove minimax rates for sparse signal estimation by solving the sketched sparse convex or nonconvex learning problems. A new Iterative SRO algorithm is proposed to geometrically reduce the approximation error for solving the sketched convex regularized problems. To the best of our knowledge, our results are among the first to demonstrate minimax rates for convex or nonconvex sparse learning problem by sketching under a unified theoretical framework. Experimental results demonstrate the effectiveness of the proposed SRO and Iterative SRO algorithms."
    },
    {
        "title": "TULIP: Token-length Upgraded CLIP",
        "link_suffix": "/forum?id=r9oqHOdoHf",
        "link": "https://openreview.net/forum?id=r9oqHOdoHf",
        "pdf_link": "https://openreview.net/pdf?id=r9oqHOdoHf",
        "keywords": "Vision-Language Models, CLIP, Position Encodings, Long captioning",
        "abstract": "We address the challenge of representing long captions in vision-language models, such as CLIP. By design these models are limited by fixed, absolute positional encodings, restricting inputs to a maximum of 77 tokens and hindering performance on tasks requiring longer descriptions. Although recent work has attempted to overcome this limit, their proposed approaches struggle to model token relationships over longer distances and simply extend to a fixed new token length. Instead, we propose a generalizable method, named TULIP, able to upgrade the token length to any length for CLIP-like models. We do so by improving the architecture with relative position encodings, followed by a training procedure that (i) distills the original CLIP text encoder into an encoder with relative position encodings and (ii) enhances the model for aligning longer captions with images. By effectively encoding captions longer than the default 77 tokens, our model outperforms baselines on cross-modal tasks such as retrieval and text-to-image"
    },
    {
        "title": "DIRECT: Deep Active Learning under Imbalance and Label Noise",
        "link_suffix": "/forum?id=yiQCeXdPvs",
        "link": "https://openreview.net/forum?id=yiQCeXdPvs",
        "pdf_link": "https://openreview.net/pdf?id=yiQCeXdPvs",
        "keywords": "Deep Learning, Active Learning",
        "abstract": "Class imbalance is a prevalent issue in real world machine learning applications, often leading to poor performance in rare and minority classes. With an abundance of wild unlabeled data, active learning is perhaps the most effective technique in solving the problem at its root -- collecting a more balanced and informative set of labeled examples during annotation. Label noise is another common issue in data annotation jobs, which is especially challenging for active learning methods. In this work, we conduct the first study of active learning under both class imbalance and label noise. We propose a novel algorithm that robustly identifies the class separation threshold and annotates the most uncertain examples that are closest from it. Through a novel reduction to one-dimensional active learning, our algorithm DIRECT is able to leverage classic active learning theory and methods to address issues such as batch labeling and tolerance towards label noise. We present extensive experiments on imbalanced datasets with and without label noise. Our results demonstrate that DIRECT can save more than 60% of the annotation budget compared to state-of-art active learning algorithms and more than 80% of annotation budget compared to random sampling."
    },
    {
        "title": "Beyond 2:4: Exploring V:N:M Sparsity for Efficient Transformer Inference on GPUs",
        "link_suffix": "/forum?id=gWHQQagPbN",
        "link": "https://openreview.net/forum?id=gWHQQagPbN",
        "pdf_link": "https://openreview.net/pdf?id=gWHQQagPbN",
        "keywords": "V:N:M sparisity, Transformer inference acceleration, accuracy-speedup tradeoffs, channel permutation",
        "abstract": "To date, 2:4 sparsity has stood as the only sparse pattern that can be accelerated\nusing sparse tensor cores on GPUs. In practice, 2:4 sparsity often possesses low\nactual speedups (≤ 1.3) and requires fixed sparse ratios, meaning that other ratios,\nsuch as 4:8, 8:16, or those exceeding 50% sparsity, do not incur any speedups on\nGPUs. Recent studies suggest that V:N:M sparsity is promising in addressing\nthese limitations of 2:4 sparsity. This sparsity divides a weight matrix into mul-\ntiple V×M blocks, pruning (M-4) columns within each block and applying 2:4\nsparsity to the remaining columns. V:N:M sparsity inherently encompasses 2:4\nsparsity but allows for higher and more flexible pruning ratios, typically resulting\nin greater practical speedups. However, regarding accuracy, the effects of V:N:M\nsparsity on broader Transformer models, such as vision Transformers and large\nlanguage models (LLMs), are largely unexamined. Moreover, Some specific is-\nsues related to V:N:M sparsity, such as how to select appropriate V and M values,\nremain unresolved. In this study, we thoroughly investigate the application of\nV:N:M sparsity in vision models and LLMs across multiple tasks, from pretaining\nto downstream tasks. We propose three key approaches to enhance the applica-\nbility and accuracy of V:N:M-sparse Transformers, including heuristic V and M\nselection, V:N:M-specific channel permutation and three-staged LoRA training\ntechniques. Experimental results show that, with our methods, the DeiT-small\nachieves lossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains ac-\ncuracy even at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5\nsparsity performs comparably or better than training-free 2:4 sparse alternatives on\ndownstream tasks. More importantly, V:N:M-sparse Transformers offer a wider\nrange of speedup-accuracy trade-offs compared to 2:4 sparsity. Overall, our explo-\nration largely facilitates the V:N:M sparsity to act as a truly effective acceleration\nsolution for Transformers in cost-sensitive inference scenarios."
    },
    {
        "title": "Sparse Repellency for Shielded Generation in Text-to-Image Diffusion Models",
        "link_suffix": "/forum?id=EWQaqDgXgr",
        "link": "https://openreview.net/forum?id=EWQaqDgXgr",
        "pdf_link": "https://openreview.net/pdf?id=EWQaqDgXgr",
        "keywords": "Diffusion Model, Guidance, Repellency, Diversity",
        "abstract": "The increased adoption of diffusion models in text-to-image generation has triggered concerns on their reliability. Such models are now closely scrutinized under the lens of various metrics, notably calibration, fairness, or compute efficiency. We focus in this work on two issues that arise when deploying these models: a lack of diversity when prompting images, and a tendency to recreate images from the training set. To solve both problems, we propose a method that coaxes the sampled trajectories of pretrained diffusion models to land on images that fall outside of a reference set. We achieve this by adding a simple repellency term to the diffusion SDE throughout the generation trajectory, that is triggered whenever it is expected to land too closely to an image in the shielded reference set. Our method is sparse in the sense that these repellency terms are mostly zero and inactive, even more so towards the end of the generation trajectory. Our method, named SPELL\nfor sparse repellency, can be used either with a static reference set that contains protected images, or dynamically, by updating the reference set at each timestep with the expected images concurrently generated within a batch. We show that adding SPELL to popular diffusion models improves their diversity while impacting their FID only marginally, and performs comparatively better than other recent training-free diversity methods. Moreover, we demonstrate how SPELL can ensure a shielded generation away from a very large set of protected images by considering all 1.2M images from ImageNet as the protected set."
    },
    {
        "title": "DELIFT: Data Efficient Language model Instruction Fine-Tuning",
        "link_suffix": "/forum?id=Fty0wTcemV",
        "link": "https://openreview.net/forum?id=Fty0wTcemV",
        "pdf_link": "https://openreview.net/pdf?id=Fty0wTcemV",
        "keywords": "Instruction Fine-Tuning; Data Selection; Efficient Fine-Tuning; Submodular Functions",
        "abstract": "Fine-tuning large language models (LLMs) is essential for enhancing their performance on specific tasks but is often resource-intensive due to redundant or uninformative data. To address this inefficiency, we introduce DELIFT (Data Efficient Language model Instruction Fine-Tuning), a novel algorithm that systematically optimizes data selection across the three key stages of fine-tuning: (1) instruction tuning, (2) task-specific fine-tuning (e.g., reasoning, question-answering), and (3) continual learning (e.g., incorporating new data versions). Unlike existing methods that focus on single-stage optimization or rely on computationally intensive gradient calculations, DELIFT operates efficiently across all stages. Central to our approach is a pairwise utility metric that quantifies how beneficial a data sample is for improving the model's responses to other samples, effectively measuring the informational value relative to the model's current capabilities. By leveraging different submodular functions applied to this metric, DELIFT selects diverse and optimal subsets that are useful across all stages of fine-tuning. Experiments across various tasks and model scales demonstrate that DELIFT can reduce the fine-tuning data size by up to 70% without compromising performance, offering significant computational savings and outperforming existing methods in both efficiency and efficacy."
    },
    {
        "title": "U-shaped and Inverted-U Scaling behind\\Emergent Abilities of Large Language Models",
        "link_suffix": "/forum?id=jjfve2gIXe",
        "link": "https://openreview.net/forum?id=jjfve2gIXe",
        "pdf_link": "https://openreview.net/pdf?id=jjfve2gIXe",
        "keywords": "large language models, emergent abilities, scaling laws",
        "abstract": "Large language models (LLMs) have been shown to exhibit emergent abilities in some downstream tasks, where performance seems to stagnate at first and then improve sharply and unpredictably with scale beyond a threshold. By dividing questions in the datasets according to difficulty level by average performance, we observe U-shaped scaling for hard questions, and inverted-U scaling followed by steady improvement for easy questions. Moreover, the emergence threshold roughly coincides with the point at which performance on easy questions reverts from inverse scaling to standard scaling. Capitalizing on the observable though opposing scaling trend on easy and hard questions, we propose a simple yet effective pipeline, called Slice-and-Sandwich, to predict both the emergence threshold and model performance beyond the threshold."
    }
]
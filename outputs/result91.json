[
    {
        "title": "The Sampling-Gaussian for stereo matching",
        "link_suffix": "/forum?id=lGDmwb12Qq",
        "link": "https://openreview.net/forum?id=lGDmwb12Qq",
        "pdf_link": "https://openreview.net/pdf?id=lGDmwb12Qq",
        "keywords": "stereo matching.+disparity estimation.+Gaussian Distribution.+interpretable deep learning",
        "abstract": "The soft-argmax operation is widely adopted in neural network-based stereo matching methods to enable differentiable regression of disparity. However, network trained with soft-argmax is prone to being multimodal due to absence of explicit constraint to the shape of the probability distribution. Previous methods leverages Laplacian distribution and cross-entropy for training but failed to effectively improve the accuracy and even compromises the efficiency of the network. In this paper, we conduct a detailed analysis of the previous distribution-based methods and propose a novel supervision method for stereo matching, Sampling-Gaussian. We sample from the Gaussian distribution for supervision. Moreover, we interpret the training as minimizing the distance in vector space and propose a combined loss of L1 loss and cosine similarity loss. Additionally, we leveraged bilinear interpolation to upsample the cost volume. Our method can be directly applied to any soft-argmax-based stereo matching method without a reduction in efficiency. We have conducted comprehensive experiments to demonstrate the superior performance of our  Sampling-Gaussian. The experimental results prove that we have achieved better accuracy on five baseline methods and two datasets. Our method is easy to implement, and the code is available online."
    },
    {
        "title": "EMMA: Efficient Visual Alignment in Multi-Modal LLMs",
        "link_suffix": "/forum?id=QPDbIFumQ8",
        "link": "https://openreview.net/forum?id=QPDbIFumQ8",
        "pdf_link": "https://openreview.net/pdf?id=QPDbIFumQ8",
        "keywords": "Multi-Modal LLMs, Modality Adaptation, Visual Alignment",
        "abstract": "Multi-modal Large Language Models (MLLMs) have recently exhibited impressive general-purpose capabilities by leveraging vision foundation models to encode the core concepts of images into representations. These are then combined with instructions and processed by the language model to generate high-quality responses. Despite significant progress\nin enhancing the language component, challenges persist in optimally fusing visual encodings within the language model for task-specific adaptability. Recent research has focused on improving this fusion through modality adaptation modules but at the cost of significantly increased model complexity and training data needs. \nIn this paper, we propose EMMA (Efficient Multi-Modal Adaptation), a lightweight cross-modality module designed to efficiently fuse visual and textual encodings, generating instruction-aware visual representations for the language model. Our key contributions include: (1) an efficient early fusion mechanism that integrates vision and language representations with minimal added parameters (less than 0.2% increase in model size), (2) an in-depth interpretability analysis that sheds light on the internal mechanisms of the proposed method; (3) comprehensive experiments that demonstrate notable improvements on both specialized and general benchmarks for MLLMs. Empirical results show that EMMA boosts performance across multiple tasks by up to 9.3% while significantly improving robustness against hallucinations."
    },
    {
        "title": "Fugatto 1: Foundational Generative Audio Transformer Opus 1",
        "link_suffix": "/forum?id=B2Fqu7Y2cd",
        "link": "https://openreview.net/forum?id=B2Fqu7Y2cd",
        "pdf_link": "https://openreview.net/pdf?id=B2Fqu7Y2cd",
        "keywords": "Generative Models, Audio, Foundation Models",
        "abstract": "Fugatto is a versatile audio synthesis and transformation model capable of following free-form text instructions with optional audio inputs. While large language models (LLMs) trained with text on a simple next-token prediction objective can learn to infer instructions directly from the data, models trained solely on audio data lack this capacity. This is because audio data does not inherently contain the instructions that were used to generate it. To overcome this challenge, we introduce a specialized dataset generation approach optimized for producing a wide range of audio generation and transformation tasks, ensuring the data reveals meaningful relationships between audio and language. Another challenge lies in achieving compositional abilities -- such as combining, interpolating between, or negating instructions -- using data alone. To address it, we propose ComposableART, an inference-time technique that extends classifier-free guidance to compositional guidance. It enables the seamless and flexible composition of instructions, leading to highly customizable audio outputs outside the training distribution. Our evaluations across a diverse set of tasks demonstrate that Fugatto performs competitively with specialized models, while ComposableART enhances its sonic palette and control over synthesis. Most notably, we highlight our framework's ability to synthesize emergent sounds -- sonic phenomena that transcend conventional audio generation -- unlocking new creative possibilities. \\href{https://fugatto.github.io/}{DemoWebsite.}"
    },
    {
        "title": "Increment Vector Transformation for Class Incremental Learning",
        "link_suffix": "/forum?id=DSGDdj0HEM",
        "link": "https://openreview.net/forum?id=DSGDdj0HEM",
        "pdf_link": "https://openreview.net/pdf?id=DSGDdj0HEM",
        "keywords": "Class incremental learning",
        "abstract": "Class Incremental Learning (CIL) presents a major challenge due to the phenomenon of catastrophic forgetting.\nRecent studies on Linear Mode Connectivity (LMC) reveal that Naive-SGD oracle, trained with all historical data, connects to previous task minima through low-loss linear paths---a property generally absent in current CIL methods.\nIn this paper, we explore whether LMC holds for the CIL oracle. Our empirical results confirm the presence of LMC in the CIL oracle, showing that models can retain performance on earlier tasks by following the discovered low-loss linear paths. Motivated by this finding, we propose Increment Vector Transformation (IVT), which leverages the diagonal of the Fisher Information Matrix to approximate Hessian-based transformation, uncovering low-loss linear paths for incremental updates. \nOur method is orthogonal to existing CIL approaches, serving as a plug-in with minor extra computational costs.\nExtensive experiments on CIFAR-100, ImageNet-Subset, and ImageNet-Full demonstrate significant performance improvements when integrating IVT with representative CIL methods."
    },
    {
        "title": "A long range foundation model for zero-shot predictions in single-cell and spatial transcriptomics data",
        "link_suffix": "/forum?id=VdX9tL3VXH",
        "link": "https://openreview.net/forum?id=VdX9tL3VXH",
        "pdf_link": "https://openreview.net/pdf?id=VdX9tL3VXH",
        "keywords": "Foundation models, single-cell RNA-seq, spatial transcriptomics, masked language modelling, computational biology, zero shot inference",
        "abstract": "Large transformers pre-trained with language model objectives have demonstrated success in multiple fields, and have tremendous potential for modeling single-cell RNA-seq and spatial transcriptomics data. However, these approaches are yet to overcome various challenges, including inductive biases that hinder generalization, artifacts and quality of the underlying data, as well as downstream evaluation pipelines that do not reflect the biological challenges in the field. In this work, we propose a new framework, sCellTransformer (sCT), that relies on a first principles formulation of the problem as well as a validation pipeline designed to evaluate models generalization through zero-shot predictions. sCT leverages a long-range convolutional-transformer architecture that is trained from unprocessed single-cell and spatial transcriptomics data. In contrast to previous works, sCT represents cells with up to 20,000 protein-coding genes, processes sets of multiple cells, and predicts about a million discretized gene expression tokens. We show that representing gene expression as discrete levels allows us to mitigate the high sparsity present in single-cell data both during training and evaluation. We present state-of-the-art empirical results on several zero-shot gene expression imputation, cell-typing, and clustering tasks in both single-cell as well as spatial domains, outperforming current foundation models."
    },
    {
        "title": "Distributed Quasi-Newton Method for Fair and Fast Federated Learning",
        "link_suffix": "/forum?id=n6PE0xbgdA",
        "link": "https://openreview.net/forum?id=n6PE0xbgdA",
        "pdf_link": "https://openreview.net/pdf?id=n6PE0xbgdA",
        "keywords": "Federated Learning, Fairness",
        "abstract": "Federated Learning (FL) is a promising technology that enables edge devices/clients to collaboratively and iteratively train a machine learning model under the coordination of a central server. The most common approach to FL is first-order methods, where clients send their local gradients to the server in each iteration. However, these methods often suffer from slow convergence rates. As a remedy, second-order methods, such as quasi-Newton, can be employed to accelerate convergence. Unfortunately, similarly to the first-order FL methods, the application of second-order methods in FL can lead to unfair models, achieving high average accuracy while performing poorly on certain clients' local datasets. To tackle this issue, in this paper we introduce  a novel second-order FL framework, dubbed distributed quasi-Newton federated learning (DQN-Fed). This approach seeks to ensure fairness while leveraging the fast convergence properties of quasi-Newton methods in the FL context. Specifically, DQN-Fed helps the server update the global model in such a way that (i) all local loss functions decrease to promote fairness, and (ii) the rate of change in local loss functions aligns with that of the quasi-Newton method. We prove the convergence of DQN-Fed and demonstrate its linear-quadratic convergence rate. Moreover, we validate the efficacy of DQN-Fed across a range of federated datasets, showing that it surpasses state-of-the-art fair FL methods in both fairness and convergence speed. The Code for paper is publicly available athttps://github.com/ICMLDQNFed/ICMLDQN."
    },
    {
        "title": "Finding the Number of Clusters in a Graph: a Nearly-Linear Time Algorithm",
        "link_suffix": "/forum?id=5dpuLgwQ0d",
        "link": "https://openreview.net/forum?id=5dpuLgwQ0d",
        "pdf_link": "https://openreview.net/pdf?id=5dpuLgwQ0d",
        "keywords": "spectral clustering, eigen-gap heuristic, number of clusters",
        "abstract": "Given an undirected graph  $G$ with the normalised adjacency matrix $N_G$, the well-known eigen-gap heuristic for clustering asserts that $G$ has $k$ clusters if there is a large gap between the $k$th and $(k+1)$th largest eigenvalues of $N_G$. Although this heuristic is well-supported in spectral graph theory and widely applied in practice, determining $k$ often relies on computing  the eigenvalues of $N_G$ with high time complexity. This paper addresses this key problem in graph clustering,  and shows that  the number of clusters \n$k$  implied by the eigen-gap heuristic  can be computed in nearly-linear time."
    },
    {
        "title": "Enhancing single-cell Multi-Modal Multi-Task Learning via Sparse Mixture-of-Experts",
        "link_suffix": "/forum?id=JfRPsrP6qX",
        "link": "https://openreview.net/forum?id=JfRPsrP6qX",
        "pdf_link": "https://openreview.net/pdf?id=JfRPsrP6qX",
        "keywords": "Single-cell Multi-modal data, Multi-Task Learning, Sparse MoE",
        "abstract": "Recent advances in measuring high-dimensional modalities, including protein levels and DNA accessibility, at the single-cell level have prompted the need for frameworks capable of handling multi-omics data while simultaneously addressing multiple tasks. Despite these advancements, much of the work in the single-cell domain remains limited, often focusing on either a single-modal or single-task perspective. A few recent studies have ventured into multi-omics and multi-task learning, but we identified a ① Optimization Conflict issue, leading to suboptimal results when integrating additional modalities, which is undesirable. Furthermore, there is a ② Costly Interpretability challenge, as current approaches predominantly rely on costly post-hoc methods like SHAP. Motivated by these challenges, we introduce scMoE, a novel framework that, for the first time, applies Sparse Mixture-of-Experts (SMoE) within the single-cell domain. This is achieved by incorporating an SMoE layer into a transformer block with a cross-attention module. Thanks to its design, scMoE inherently possesses mechanistic interpretability, a critical aspect for understanding underlying mechanisms when handling biological data. Furthermore, from a post-hoc perspective, we enhance interpretability by extending the concept of activation vectors (CAVs). Extensive experiments on simulated dataset, Dyngen, and real-world multi-omics single-cell datasets, including DBiT-seq, Patch-seq, ATAC-seq, demonstrate the effectiveness of scMoE."
    },
    {
        "title": "Identifiability Guarantees For Time Series Representation via Contrastive Sparsity-inducing",
        "link_suffix": "/forum?id=9unhkXMOk0",
        "link": "https://openreview.net/forum?id=9unhkXMOk0",
        "pdf_link": "https://openreview.net/pdf?id=9unhkXMOk0",
        "keywords": "Time Series Representations Learning, Generalization, Disentangled Representations Learning, Source Separation",
        "abstract": "Time series representations learned from high-dimensional data are generally expected to be more robust and better at generalizing to new and potentially out-of-distribution scenarios. However, this is not always the case, as variations in unseen data or prior assumptions may insufficiently constrain the posterior probability distribution, resulting in ill-defined representations and consequently weaker predictions. While disentangled representations for time series are often said to be beneficial for generalizing downstream tasks, the current empirical and theoretical understanding remains limited. In this work, we provide new results on identifiability that guarantee disentangled representations via Contrastive Sparsity-inducing Learning, which improves generalization and interpretability. Motivated by this result, we propose the TimeCSL framework to learn a disentangled representation that generalizes and maintains compositionality. We conduct a large-scale study on time series source separation, investigating whether sufficiently disentangled representations enhance the ability to generalize to source combinations in downstream tasks for both training data and unseen combinations in the testing distribution. Our results show that sufficient identifiability in time series representations leads to improved performance under shifted distributions."
    },
    {
        "title": "Balancing Bias in Two-sided Markets for Fair Stable Matchings",
        "link_suffix": "/forum?id=qykpnEWf2J",
        "link": "https://openreview.net/forum?id=qykpnEWf2J",
        "pdf_link": "https://openreview.net/pdf?id=qykpnEWf2J",
        "keywords": "stable marriage; fairness",
        "abstract": "The Balanced Stable Marriage (BSM) problem aims to find a stable matching in a two-sided market that minimizes the maximum dissatisfaction among two sides. The classical Deferred Acceptance algorithm merely produces an unfair stable marriage, providing optimal partners for one side while partially assigning pessimal partners to the other. Solving BSM is NP-hard, thwarting attempts to resolve the problem exactly. As the instance size increases in practice, recent studies have explored heuristics for finding a fair stable marriage but have not found an exact optimal solution for BSM efficiently. Nevertheless, in this paper we propose an efficient algorithm, Isorropia, that returns the exact optimal solution to practical BSM problem instances. Isorropia constructs two sets of candidate rotations from which it builds three sets of promising antichains, and performs local search on those three sets of promising antichains. Our extensive experimental study shows that Isorropia surpasses the time-efficiency of baselines that return the exact solution by up to three orders of magnitude."
    },
    {
        "title": "Federated Dynamical Low-Rank Training with Global Loss Convergence Guarantees",
        "link_suffix": "/forum?id=RAC3ng3TSN",
        "link": "https://openreview.net/forum?id=RAC3ng3TSN",
        "pdf_link": "https://openreview.net/pdf?id=RAC3ng3TSN",
        "keywords": "Federated Learning, Low-Rank, Model Compression, Efficient Federated Learning",
        "abstract": "In this work, we propose a federated dynamical low-rank training (FeDLRT)\nscheme to reduce client compute and communication costs - two significant per-\nformance bottlenecks in horizontal federated learning. Our method builds upon\ndynamical low-rank splitting schemes for manifold-constrained optimization to\ncreate a global low-rank basis of network weights, which enables client training on\na small coefficient matrix. A consistent global low-rank basis allows us to incorpo-\nrate a variance correction scheme and prove global loss descent and convergence\nto a stationary point. Dynamic augmentation and truncation of the low-rank bases\nautomatically optimizes computing and communication resource utilization. We\ndemonstrate the efficiency of FeDLRT in an array of computer vision benchmarks\nand show a reduction of client compute and communication costs by up to an order\nof magnitude with minimal impacts on global accuracy."
    },
    {
        "title": "Herb-GANNet: Synthetic Data Generation through Conditional GANs for Improving Accuracy in Medicinal Leaf Classification",
        "link_suffix": "/forum?id=DXz1PDA0Wg",
        "link": "https://openreview.net/forum?id=DXz1PDA0Wg",
        "pdf_link": "https://openreview.net/pdf?id=DXz1PDA0Wg",
        "keywords": "medicinal leaf classification, data augmentation, generative adversarial networks (GAN), deep learning, image generation, classification, drug discovery",
        "abstract": "Accurate classification of medicinal leaves is essential across various fields, including agriculture, Ayurveda, drug discovery, and biodiversity conservation. However, this task can be complex and time consuming for experts due to the complexity of plant morphology, limited public datasets, and inherent class imbalances among species. These issues not only hinder effective identification and utilization of medicinal plants but also impede research and development in related domains. This study explores the application of Conditional Generative Adversarial Networks (CGANs) to generate synthetic data aimed at improving medicinal leaf classification models. CGANs offer effective solution for augmenting datasets and addressing class imbalance issues. We employed a conditional Deep Convolution Generative Adversarial Network (cDCGAN) to produce 500 synthetic images for each of thirty different plant species. To evaluate the effectiveness of the generated data, we trained and evaluated three popular convolutional neural networks: ResNet-34, VGG-16, and EfficientNet-B1, on both the original and augmented datasets. Our results show that CGAN-generated data significantly improved the performance across all tested models. EfficientNet-B1 achieved the lowest test loss of 1.74% on the augmented dataset, while ResNet-34 exhibited the highest test accuracy of 98.26%. These findings indicate that cDCGANs can generate synthetic data that effectively mimics real images, leading to (1) larger training datasets, (2) reduced data collection cost, and (3) increased data diversity and model generalization by providing a broader range of training examples."
    },
    {
        "title": "HÖLDER PRUNING: LOCALIZED PRUNING FOR BACKDOOR REMOVAL IN DEEP NEURAL NETWORKS",
        "link_suffix": "/forum?id=yJduhi9mDQ",
        "link": "https://openreview.net/forum?id=yJduhi9mDQ",
        "pdf_link": "https://openreview.net/pdf?id=yJduhi9mDQ",
        "keywords": "Holder Pruning, Holder iteration defense, backdoor attacks, Deep Neural Networks, backdoor defense",
        "abstract": "Deep Neural Networks (DNNs) have become the cornerstone of modern machine\nlearning applications, achieving impressive results in domains ranging from com-\nputer vision to autonomous systems. However, their dependence on extensive data\nand computational resources exposes them to vulnerabilities such as backdoor\nattacks, where poisoned samples can lead to erroneous model outputs. To counter\nthese threats, we introduce a defense strategy called Hölder Pruning to detect\nand eliminate neurons affected by triggers embedded in poisoned samples. Our\nmethod partitions the neural network into two stages: feature extraction and feature\nprocessing, aiming to detect and remove backdoored neurons—the highly sensitive\nneurons affected by the embedded triggers—while maintaining model performance\nThis improves model sensitivity to perturbations and enhances pruning precision\nby exploiting the unique clustering properties of poisoned samples. We use the\nHölder constant to quantify sensitivity of neurons to input perturbations and prove\nthat using the Fast Gradient Sign Method (FGSM) can effectively identify highly\nsensitive backdoored neurons. Our extensive experiments demonstrate efficacy of\nHölder Pruning across six clean feature extractors (SimCLR, Pretrained ResNet-18,\nViT, ALIGN, CLIP, and BLIP-2) and confirm robustness against nine backdoor\nattacks (BadNets, LC, SIG, LF, WaNet, Input-Aware, SSBA, Trojan, BppAttack)\nusing three datasets (CIFAR-10, CIFAR-100, GTSRB). We compare Hölder Pruning to eight SOTA backdoor defenses (FP, ANP, CLP, FMP, ABL, DBD, D-ST)\nand show that Hölder Pruning outperforms all eight SOTA methods. Moreover,\nHölder Pruning achieves a runtime up to 1000x faster than SOTA defenses when\na clean feature extractor is available. Even when clean feature extractors are not\navailable, our method is up to 10x faster."
    },
    {
        "title": "Mitigating the Influence of Distractor Tasks in LMs with Prior-Aware Decoding",
        "link_suffix": "/forum?id=dlUjNdybnq",
        "link": "https://openreview.net/forum?id=dlUjNdybnq",
        "pdf_link": "https://openreview.net/pdf?id=dlUjNdybnq",
        "keywords": "Inverse Scaling, Contrastive Decoding",
        "abstract": "The broad capabilities of Language Models (LMs) can be limited by their sensitivity to distractor tasks: LMs can infer secondary tasks from the prompt in addition to the intended one, leading to unwanted outputs. For example, prompt injection attacks can cause models to deviate from explicit directives. In some ‘inverse scaling’ cases, this unwanted behaviour actually worsens as models scale up to at least 540B parameters. We present a theoretical framework that interprets LMs as a product of experts that combine multiple data generation processes. Based on this framework, we introduce prior-aware decoding (PAD) -- a simple contrastive inference method to reduce the influence of distractor tasks. We apply PAD to eleven models, across four datasets, and find improvements in 41 out of 44 task-model combinations, with a median increase in task completion proportion of 40%. The results suggest a promising direction for further development towards more reliable language models."
    },
    {
        "title": "Multi-Step Preference Optimization via Two-Player Markov Games",
        "link_suffix": "/forum?id=NTNdRElwbp",
        "link": "https://openreview.net/forum?id=NTNdRElwbp",
        "pdf_link": "https://openreview.net/pdf?id=NTNdRElwbp",
        "keywords": "Multi-step Preference Optimization, Two-player Markov game, RLHF, Optimistic Online Gradient Descent",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been highly successful in aligning large language models with human preferences. While prevalent methods like DPO have demonstrated strong performance, they frame interactions with the language model as a bandit problem, which limits their applicability in real-world scenarios where multi-turn conversations are common. Additionally, DPO relies on the Bradley-Terry model assumption, which does not adequately capture the non-transitive nature of human preferences. In this paper, we address these challenges by modeling the alignment problem as a two-player constant-sum Markov game, where each player seeks to maximize their winning rate against the other across all steps of the conversation. Our approach Multi-step Preference Optimization (MPO) is built upon the natural actor-critic framework. We further develop OMPO based on the optimistic online gradient descent algorithm. Theoretically, we provide a rigorous analysis for both algorithms on convergence and show that OMPO requires $\\mathcal{O}(\\epsilon^{-1})$ policy updates to converge to an $\\epsilon$-approximate Nash equilibrium. We also validate the effectiveness of our method through experiments on the multi-turn conversations dataset in MT-bench-101."
    },
    {
        "title": "Video Q-Former: Multimodal Large Language Model with Spatio-Temporal Querying Transformer Towards Video Understanding",
        "link_suffix": "/forum?id=R6sIi9Kbxv",
        "link": "https://openreview.net/forum?id=R6sIi9Kbxv",
        "pdf_link": "https://openreview.net/pdf?id=R6sIi9Kbxv",
        "keywords": "Multimodal Large Language Model, Vision-Language Pretraining, Video Understanding",
        "abstract": "Large language models (LLMs) have made remarkable strides in natural language processing tasks. However, effectively processing and understanding visual information remains a challenge for these models. To address this, multimodal large language models have been proposed, which integrate pre-trained visual encoders with LLMs. Although existing image-based approaches have shown success in aligning visual and textual modalities, extending these advancements to videos is challenging due to the richer visual and temporal information they contain. Current methods, including Video-ChatGPT and Video-LLaMA, have limitations in capturing inter-frame relationships and providing sufficient semantic context. To overcome these challenges, we propose Video Q-Former, a model that adaptively extracts spatiotemporal features from videos with a spatio-temporal querying transformer, enhancing the LLM’s comprehension of visual-language alignment. Extensive experiments demonstrate that our model achieves state-of-the-art performance across various datasets in zero-shot video question answering tasks."
    },
    {
        "title": "Nesterov acceleration in benignly non-convex landscapes",
        "link_suffix": "/forum?id=YwJkv2YqBq",
        "link": "https://openreview.net/forum?id=YwJkv2YqBq",
        "pdf_link": "https://openreview.net/pdf?id=YwJkv2YqBq",
        "keywords": "Nonconvex optimization, stochastic optimization, stochastic acceleration, smooth convex optimization, deep learning, accelerated gradient descent",
        "abstract": "While momentum-based optimization algorithms are commonly used in the notoriously non-convex optimization problems of deep learning, their analysis has historically been restricted to the convex and strongly convex setting. In this article, we partially close this gap between theory and practice and demonstrate that virtually identical guarantees can be obtained in optimization problems with a `benign' non-convexity. We show that these weaker geometric assumptions are well justified in overparametrized deep learning, at least locally. Variations of this result are obtained for a continuous time model of Nesterov's accelerated gradient descent algorithm (NAG), the classical discrete time version of NAG, and versions of NAG with stochastic gradient estimates with purely additive noise and with noise that exhibits both additive and multiplicative scaling."
    },
    {
        "title": "Standard Gaussian Process Can Be Excellent for High-Dimensional Bayesian Optimization",
        "link_suffix": "/forum?id=kX8h23UG6v",
        "link": "https://openreview.net/forum?id=kX8h23UG6v",
        "pdf_link": "https://openreview.net/pdf?id=kX8h23UG6v",
        "keywords": "Gaussian Process, Bayesian Optimization, High Dimensional Bayesian Optimization",
        "abstract": "A long-standing belief holds that Bayesian Optimization (BO) with standard Gaussian processes (GP) --- referred to as standard BO --- underperforms in high-dimensional optimization problems. While this belief seems plausible, it lacks both robust empirical evidence and theoretical justification. To address this gap, we present a systematic investigation. First, through a comprehensive evaluation across eleven widely used benchmarks, we found that while the popular Square Exponential (SE) kernel often leads to poor performance, using Mat'ern kernels enables standard BO to consistently achieve top-tier results, frequently surpassing methods specifically designed for high-dimensional optimization. Second, our theoretical analysis reveals that the SE kernel’s failure primarily stems from improper initialization of the length-scale parameters, which are commonly used in practice but can cause gradient vanishing in training. We provide a probabilistic bound to characterize this issue, showing that Mat'ern kernels are less susceptible and can robustly handle much higher dimensions. Third, we propose a simple robust initialization strategy that dramatically improves the performance of the SE kernel, bringing it close to state-of-the-art methods, without requiring any additional priors or regularization. We prove another probabilistic bound that demonstrates how the gradient vanishing issue can be effectively mitigated with our method. Our findings advocate for a re-evaluation of standard BO’s potential in high-dimensional settings."
    },
    {
        "title": "Large Language Models Are Natural Video Popularity Predictors",
        "link_suffix": "/forum?id=iKsTtpzBtc",
        "link": "https://openreview.net/forum?id=iKsTtpzBtc",
        "pdf_link": "https://openreview.net/pdf?id=iKsTtpzBtc",
        "keywords": "Large Language Models (LLMs), Vision-Language Models (VLMs), Multimodal Textual Representations, Video Popularity Prediction",
        "abstract": "Predicting video popularity is typically formalized as a supervised learning problem, where models classify videos as popular or unpopular. Traditional approaches rely heavily on meta-information and aggregated user engagement data, but video popularity is highly context-dependent, influenced by cultural, social, and temporal factors that these approaches fail to capture. We argue that Large Language Models (LLMs), with their deep contextual awareness, are well-suited to address these challenges. A key difficulty, however, lies in bridging the modality gap between pixel-based video data and token-based LLMs. To overcome this, we transform frame-level visual data into sequential text representations using Vision-Language Models (VLMs), enabling LLMs to process multimodal video content—titles, frame-based descriptions, and captions—and capture rich contextual information for more accurate predictions. Evaluating on a newly introduced dataset of 17,000 videos, we show that while a supervised neural network using content embeddings achieved 80% accuracy, our LLM-based method reached 82% without fine-tuning. A combined approach, integrating the neural network's predictions into the LLM, further improved accuracy to 85.5%. Additionally, the LLM generates interpretable hypotheses explaining its predictions based on theoretically sound attributes. Survey-based manual validations confirm the quality of these hypotheses and address concerns about hallucinations in the video-to-text conversion process. Our findings highlight that LLMs, equipped with textually transformed multimodal representations, offer a powerful, interpretable, and data-efficient solution to the context-dependent challenge of video popularity prediction."
    },
    {
        "title": "NativQA: Multilingual Culturally-Aligned Natural Queries for LLMs",
        "link_suffix": "/forum?id=o1SGGW53GF",
        "link": "https://openreview.net/forum?id=o1SGGW53GF",
        "pdf_link": "https://openreview.net/pdf?id=o1SGGW53GF",
        "keywords": "resources for less-resourced languages, multilingual benchmarks, multilingual corpora, NLP datasets, datasets for low resource languages",
        "abstract": "Natural Question Answering (QA) datasets play a crucial role in evaluating the capabilities of large language models (LLMs), ensuring their effectiveness in real-world applications. Despite the numerous QA datasets that have been developed, there is a notable lack of region-specific datasets generated by native users in their own languages. This gap hinders the effective benchmarking of LLMs for regional and cultural specificities. Furthermore, it also limits the development of fine-tuned models. In this study, we propose a scalable, language-independent framework, NativQA, to seamlessly construct culturally and regionally aligned QA datasets in native languages, for LLM evaluation and tuning. We demonstrate the efficacy of the proposed framework by designing a multilingual natural QA dataset, \\mnqa, consisting of ~64k manually annotated QA pairs in seven languages, ranging from high to extremely low resource, based on queries from native speakers from 9 regions covering 18 topics. We benchmark open- and closed-source LLMs with the MultiNativQA dataset. We also showcase the framework efficacy in constructing fine-tuning data especially for low-resource and dialectally-rich languages. We made both the framework NativQA and MultiNativQA dataset publicly available for the community (https://anonymous.com/)."
    },
    {
        "title": "Topic and Description Reasoning Generation based on User-Contributed Comments",
        "link_suffix": "/forum?id=tKFZ53nerQ",
        "link": "https://openreview.net/forum?id=tKFZ53nerQ",
        "pdf_link": "https://openreview.net/pdf?id=tKFZ53nerQ",
        "keywords": "topic modeling, topic reasoning, large language models",
        "abstract": "We propose Topic and Description Reasoning Generation (TDRG), a text inference and generation method based on user-contributed comments with large language models (LLMs). Unlike summarization methods, TDRG can infer the topic according to comments contributed by different users, and generate a readable description that addresses the issue of the lack of interpretability in traditional topic modeling for text mining. In this paper, we adopted zero-shot and fine-tuning methods to generate topics and descriptions for comments. We use a human-annotated YouTube comment dataset to evaluate performance. Our results demonstrate that the potential of large language models of reasoning the topic and description. Generated topic titles and descriptions are similar to human references in textual semantics, but the words used are different from those of humans."
    },
    {
        "title": "Modification-Considering Value Learning for Reward Hacking Mitigation in RL",
        "link_suffix": "/forum?id=UHYRNAfnNA",
        "link": "https://openreview.net/forum?id=UHYRNAfnNA",
        "pdf_link": "https://openreview.net/pdf?id=UHYRNAfnNA",
        "keywords": "Reward Hacking, AI Safety, Alignment, Reinforcement Learning, Deep Reinforcement Learning, Reward Tampering, Sensor Tampering, Reinforcement Learning with General Utilities",
        "abstract": "Reinforcement learning (RL) agents can exploit unintended strategies to achieve high rewards without fulfilling the desired objectives, a phenomenon known as reward hacking. In this work, we examine reward hacking through the lens of General Utility RL, which generalizes RL by considering utility functions over entire trajectories rather than state-based rewards. From this perspective, many instances of reward hacking can be seen as inconsistencies between current and updated utility functions, where the behavior optimized for an updated utility function is poorly evaluated by the original one. Our main contribution is Modification-Considering Value Learning (MC-VL), a novel algorithm designed to address this inconsistency during learning. Starting with a coarse yet value-aligned initial utility function, the MC-VL agent iteratively refines this function based on past observations while considering the potential consequences of updates. This approach enables the agent to anticipate and reject modifications that may lead to undesired behavior. To empirically validate our approach, we implement an MC-VL agent based on the Double Deep Q-Network (DDQN) and demonstrate its effectiveness in preventing reward hacking across various grid-world tasks, including benchmarks from the AI Safety Gridworlds suite."
    },
    {
        "title": "Modeling Real-Time Interactive Conversations as Timed Diarized Transcripts",
        "link_suffix": "/forum?id=6BjEqGn1OO",
        "link": "https://openreview.net/forum?id=6BjEqGn1OO",
        "pdf_link": "https://openreview.net/pdf?id=6BjEqGn1OO",
        "keywords": "LLMs, real-time, interactivity",
        "abstract": "Chatbots built upon language models have exploded in popularity, but they have largely been limited to synchronous, turn-by-turn dialogues. In this paper we present a simple yet general method to simulate real-time interactive conversations using pretrained text-only language models, by modeling timed diarized transcripts and decoding them with causal rejection sampling. We demonstrate the promise of this method with two case studies: instant messenger dialogues and spoken conversations, which require generation at about 30 tok/s and 20 tok/s respectively to maintain real-time interactivity. These capabilities can be added into language models using relatively little data and run on commodity hardware."
    },
    {
        "title": "Addax: Utilizing Zeroth-Order Gradients to Improve Memory Efficiency and Performance of SGD for Fine-Tuning Language Models",
        "link_suffix": "/forum?id=QhxjQOMdDF",
        "link": "https://openreview.net/forum?id=QhxjQOMdDF",
        "pdf_link": "https://openreview.net/pdf?id=QhxjQOMdDF",
        "keywords": "Large Language Models, memory efficient Fine-tuning, Zeroth order optimization",
        "abstract": "Fine-tuning language models (LMs) with the standard Adam optimizer often demands excessive memory, limiting accessibility. The ``in-place'' version of Stochastic Gradient Descent (IP-SGD) and Memory-Efficient Zeroth-order Optimizer (MeZO) have been proposed as solutions to improve memory efficiency. However, IP-SGD still requires a decent amount of memory, and MeZO suffers from slow convergence and degraded final performance due to its zeroth-order nature. This paper introduces Addax, a novel method that improves both memory efficiency and algorithm performance of IP-SGD by integrating it with MeZO. Specifically, Addax computes the zeroth-order or first-order gradient of the data points in the minibatch based on their memory consumption and combines zeroth- and first-order gradient estimates to obtain the updated direction in each step.\nBy computing the zeroth-order order gradient of data points that require more memory and the first-order gradient of the ones that require less memory, Addax overcomes the slow convergence of MeZO and excessive memory requirement of IP-SGD. Additionally, the zeroth-order gradient acts as a regularizer for the first-order gradient, further enhancing the model's final performance.\nTheoretically, we establish the convergence of Addax under mild assumptions, demonstrating faster convergence and less restrictive hyper-parameter choices than MeZO. Our extensive experiments with diverse LMs and tasks show that Addax consistently outperforms MeZO in terms of accuracy and convergence speed, while having a comparable memory footprint. \nIn particular, our experiments using one A100 GPU on OPT-13B model reveal that, on average, Addax outperforms MeZO in terms of accuracy/F1 score by 14%, and runs $15\\times$ faster, while having a comparable memory footprint to MeZO. In our experiments on the larger OPT-30B model, on average, Addax outperforms MeZO in terms of accuracy/F1 score by >16% and runs $30\\times$ faster on a single H100 GPU. Moreover, Addax surpasses the performance of standard fine-tuning approaches, such as IP-SGD and Adam, in most tasks in terms of Accuracy/F1 score with significantly less memory requirement."
    },
    {
        "title": "Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models",
        "link_suffix": "/forum?id=uZgK0tcPqd",
        "link": "https://openreview.net/forum?id=uZgK0tcPqd",
        "pdf_link": "https://openreview.net/pdf?id=uZgK0tcPqd",
        "keywords": "reward model, RLHF, visual attention, LLMs, eye tracking, implicit feedback",
        "abstract": "Advancements in Natural Language Processing (NLP), have led to the emergence of Large Language Models (LLMs) such as GPT, Llama, Claude, and Gemini, which excel across a range of tasks but require extensive fine-tuning to align their outputs with human expectations. A widely used method for achieving this alignment is Reinforcement Learning from Human Feedback (RLHF), which, despite its success, faces challenges in accurately modelling human preferences. In this paper, we introduce GazeReward, a novel framework that integrates implicit feedback -- and specifically eye-tracking (ET) data -- into the Reward Model (RM). In addition, we explore how ET-based features can provide insights into user preferences. Through ablation studies we test our framework with different integration methods, LLMs, and ET generator models, demonstrating that our approach significantly improves the accuracy of the RM on established human preference datasets. This work advances the ongoing discussion on optimizing AI alignment with human values, exploring the potential of cognitive data for shaping future NLP research."
    }
]
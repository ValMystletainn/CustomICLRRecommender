[{"title": "Distributional Reinforcement Learning Based On Historical Information For Option Hedging", "link_suffix": "/forum?id=rcCNk4AI2J", "link": "https://openreview.net/forum?id=rcCNk4AI2J", "pdf_link": "https://openreview.net/pdf?id=rcCNk4AI2J", "keywords": "Reinforcement Learning; Option Hedging; Finance", "abstract": "Options are widely used financial derivatives for risk management and corporate operations. Option hedging aims to mitigate investment risks from asset price fluctuations by buying and selling other financial products. Traditional hedging strategies based on the Black-Scholes model face practical limitations due to the assumptions of constant volatility and the neglect of transaction costs. Recently, reinforcement learning(RL) has gained attention in the study of option hedging strategies, but several challenges remain: current methods rely on real-time market data (e.g., underlying asset prices, holdings, remaining option term) to determine optimal positions, underutilizing the potential value of historical data; existing approaches focus on the expected hedging cost, overlooking the comprehensive distribution of costs;  In the aspect of training data generation, commonly used single simulation methods perform well under specific conditions but struggle to ensure the robustness of the model across diverse datasets. To address these issues, we propose a novel distributional RL option hedging method that incorporates historical information. Historical states are included in the state variables, with a gated recurrent unit (GRU) network layer extracting historical information. This is then combined with current information from fully connected layers to inform subsequent network layers, ensuring the agent considers both current and historical market information when learning hedging strategies. The output of the value network is set as a series of quantiles, with the Quantile Huber Loss function fitting their distribution to evaluate strategies based on distribution rather than expected value. To diversify data sources, we use a combination of the Black-Scholes model, the Binomial model, and the Heston model to simulate a large volume of option data. Experimental results show that our method significantly reduces hedging costs and demonstrates strong adaptability and practicality under various market conditions.", "title_embedding_index": 5650, "title_abs_embedding_index": 5675}, {"title": "Learning to Rank for AutoML: enhancing pipeline selection with ranking information", "link_suffix": "/forum?id=XjSdhzBTMq", "link": "https://openreview.net/forum?id=XjSdhzBTMq", "pdf_link": "https://openreview.net/pdf?id=XjSdhzBTMq", "keywords": "AutoML, Learning-to-Rank, Pipeline selection, Meta-learning, Ranking, Bayesian optimization, Monte Carlo tree search, OpenML datasets, Metric-agnostic, Machine Learning", "abstract": "This paper introduces a learning-to-rank (LTR) framework to address the problem of pipeline selection in automated machine learning systems. The traditional approach to AutoML involves learning to predict the performance of various pipelines on a given task based on data acquired from previous tasks (i.e., meta-learning), which can be complex due to the need for different models for each task-specific metric. The proposed framework aims to select the best pipeline based on ranking rather than estimating a target metric, aligning more closely with the ultimate goal of the task (i.e., selecting pipeline candidates in order, from more to least promising). This approach enables more robust, metric-agnostic solutions that are easier to compare using ranking metrics like NDCG and MRR. The paper evaluates LTR strategies on public OpenML datasets, demonstrating a clear advantage for ranking-based methods. Additionally, the integration of LTR with Bayesian optimization and Monte Carlo tree search is explored, leading to improvements in the ranking metrics. Finally, the study found a strong correlation between ranking metrics (e.g., NDCG and MRR) and AutoML metrics, such as the task objective metric and the time to find the best solution, providing insights into how ranking-based methods could enhance AutoML systems.", "title_embedding_index": 5651, "title_abs_embedding_index": 5676}, {"title": "UFGTime: Reforming the Pure Graph Paradigm for Multivariate Time Series Forecasting in the Frequency Domain", "link_suffix": "/forum?id=xaafWdM5jI", "link": "https://openreview.net/forum?id=xaafWdM5jI", "pdf_link": "https://openreview.net/pdf?id=xaafWdM5jI", "keywords": "Multivariate Time Series Forecasting, GNN, Pure Graph Paradigm", "abstract": "Recent advances in multivariate time series forecasting have seen a shift toward a pure graph paradigm, which transforms time series into hypervariate graphs and employs graph neural networks (GNNs) to holistically capture intertwined spatiotemporal dependencies. While promising, this approach faces notable challenges. First, converting time series into hypervariate graphs often neglects essential temporal sequences, which are vital for accurately capturing temporal dependencies. Second, treating the graph as a complete structure can obscure the varying importance of intra- and inter-series connections, potentially overlooking key local patterns. To address these challenges, we introduce a novel hyperspectral graph data structure that embeds sequential order into frequency signals and employs a sparse yet meaningful topological structure. In addition, we propose the \\textsc{Ufgtime} framework, featuring a frequency-based global graph framelet message-passing operator tailored to hyperspectral graphs, effectively mitigating the smoothing issue and capturing global insights through sparse connections. Extensive experiments demonstrate that our framework significantly surpasses state-of-the-art methods, excelling in both short- and long-range time series forecasting while achieving superior efficiency. Our code is available at:~\\url{https://anonymous.4open.science/r/UFGTIME-E352}.", "title_embedding_index": 5652, "title_abs_embedding_index": 5677}, {"title": "Towards Adaptive Time Series Foundation Models Against Distribution Shift", "link_suffix": "/forum?id=YhIpTdrUDY", "link": "https://openreview.net/forum?id=YhIpTdrUDY", "pdf_link": "https://openreview.net/pdf?id=YhIpTdrUDY", "keywords": "Time series, Pretraining, Distribution Shifts, Foundation Model", "abstract": "Foundation models have demonstrated remarkable success across diverse machine-learning domains through large-scale pretraining. However, their application to time series data poses challenges due to substantial mismatches in the distributions of pretraining datasets. In this paper, we tackle this issue by proposing a domain-aware adaptive normalization strategy within the Transformer architecture. Specifically, we replace the traditional LayerNorm with a prototype-guided dynamic normalization mechanism, where learned prototypes represent distinct data distributions, and sample-to-prototype similarity determines the appropriate normalization layer. This approach effectively captures the diverse characteristics of time series data, ensuring better alignment between pretrained representations and downstream tasks. Our method significantly improves fine-tuning performance, outperforming vanilla pretraining techniques and reducing the negative impact of distribution shifts. Extensive experiments on various real-world time series datasets demonstrate the efficacy of our approach, paving the way for more robust and generalizable time series foundation models.", "title_embedding_index": 5653, "title_abs_embedding_index": 5678}, {"title": "Unlocking Structured Thinking in Language Models with Cognitive Prompting", "link_suffix": "/forum?id=VOBhmsqQlQ", "link": "https://openreview.net/forum?id=VOBhmsqQlQ", "pdf_link": "https://openreview.net/pdf?id=VOBhmsqQlQ", "keywords": "Cognitive Prompting, Large Language Models, Arithmetic Reasoning, Commonsense Reasoning", "abstract": "We propose cognitive prompting as a novel approach to guide problem-solving in large language models (LLMs) through structured, human-like cognitive operations such as goal clarification, decomposition, filtering, abstraction, and pattern recognition. By employing systematic, step-by-step reasoning, cognitive prompting enables LLMs to efficiently tackle complex, multi-step tasks. We evaluate the effectiveness of cognitive prompting on Meta's LLaMA models, comparing performance on arithmetic reasoning tasks using the GSM8K dataset and on commonsense reasoning benchmarks. Our analysis includes comparisons between models without cognitive prompting, models with a static sequence of cognitive operations, and models using reflective cognitive prompting, where the LLM dynamically self-selects the sequence of cognitive operations. The results show that cognitive prompting, particularly when dynamically adapted, significantly improves the performance of larger models, such as LLaMA3.1 70B, and enhances their ability to handle multi-step reasoning tasks. This approach also improves interpretability and flexibility, highlighting cognitive prompting as a promising strategy for general-purpose AI reasoning.", "title_embedding_index": 5654, "title_abs_embedding_index": 5679}, {"title": "FE-GNN: Feature Enhanced Graph Neural Networks for Account Classification in Ethereum", "link_suffix": "/forum?id=yM7rw8Bo1f", "link": "https://openreview.net/forum?id=yM7rw8Bo1f", "pdf_link": "https://openreview.net/pdf?id=yM7rw8Bo1f", "keywords": "Blockchain, Identity identification, GNN", "abstract": "Since the birth of the blockchain cryptocurrency trading platform represented by Bitcoin, cryptocurrencies based on blockchain technology have gained widespread attention and accumulated a large amount of transaction data. The analysis of cryptocurrency transactions has become an important research direction with social and economic value, and an important area of blockchain scientific research. Identifying the identity of different cryptocurrency addresses and understanding their behavior is the core challenge to achieve cryptocurrency transaction analysis, otherwise it is difficult to understand blockchain datasets and analyze them with meaningful results. To this end, this paper proposes a blockchain address identity identification method called \\textbf{F}eature \\textbf{E}nhanced \\textbf{G}raph \\textbf{N}eural \\textbf{N}etworks (FE-GNN). Specifically, a transaction graph is constructed based on the collected transaction data, and graph learning techniques based on graph convolutional networks and graph attention networks are used to infer the blockchain address identity. Experimental results show that the FE-GNN algorithm outperforms previous algorithms.", "title_embedding_index": 5655, "title_abs_embedding_index": 5680}, {"title": "As Simple as Fine-tuning: LLM Alignment via Bidirectional Negative Feedback Loss", "link_suffix": "/forum?id=fsX9nFwMNj", "link": "https://openreview.net/forum?id=fsX9nFwMNj", "pdf_link": "https://openreview.net/pdf?id=fsX9nFwMNj", "keywords": "LLM Alignemnt, Preference Learning, Text Generation", "abstract": "Direct Preference Optimization (DPO) has emerged as a more computationally efficient alternative to Reinforcement Learning from Human Feedback (RLHF) with Proximal Policy Optimization (PPO), eliminating the need for reward models and online sampling. Despite these benefits, DPO and its variants remain sensitive to hyper-parameters and prone to instability, particularly on mathematical datasets. We argue that these issues arise from the unidirectional likelihood-derivative negative feedback inherent in the log-likelihood loss function.\nTo address this, we propose a novel LLM alignment loss that establishes a stable Bidirectional Negative Feedback (BNF) during optimization. \nOur proposed BNF loss eliminates the need for pairwise contrastive losses and does not require any extra tunable hyper-parameters or pairwise preference data, streamlining the alignment pipeline to be as simple as supervised fine-tuning.\nWe conduct extensive experiments across two challenging QA benchmarks and four reasoning benchmarks. \nThe experimental results show that BNF achieves comparable performance to the best methods on QA benchmarks, while its performance decrease on the four reasoning benchmarks is significantly lower compared to the best methods, thus striking a better balance between value alignment and reasoning ability. \nIn addition, we further validate the performance of BNF on non-pairwise datasets, and conduct in-depth analysis of log-likelihood and logit shifts across different preference optimization methods.\nWe will release all the source code, checkpoints, and datasets on GitHub.", "title_embedding_index": 5656, "title_abs_embedding_index": 5681}, {"title": "Exploring the Limitations of Layer Synchronization in Spiking Neural Networks", "link_suffix": "/forum?id=6iM7mmVhXh", "link": "https://openreview.net/forum?id=6iM7mmVhXh", "pdf_link": "https://openreview.net/pdf?id=6iM7mmVhXh", "keywords": "spiking neural network, asynchronous processing, neuromorphic computing, energy-efficiency, low latency", "abstract": "Neural-network processing in machine learning applications relies on layer synchronization. This is practiced even in artificial Spiking Neural Networks (SNNs), which are touted as consistent with neurobiology, in spite of processing in the brain being in fact asynchronous. A truly asynchronous system however would allow all neurons to evaluate concurrently their threshold and emit spikes upon receiving any presynaptic current. Omitting layer synchronization is potentially beneficial, for latency and energy efficiency, but asynchronous execution of models previously trained with layer synchronization may entail a mismatch in network dynamics and performance. We present and quantify this problem, and show that models trained with layer synchronization either perform poorly in absence of the synchronization, or fail to benefit from any energy and latency reduction, when such a mechanism is in place. We then explore a potential solution direction, based on a generalization of backpropagation-based training that integrates knowledge about an asynchronous execution scheduling strategy, for learning models suitable for asynchronous processing. We experiment with 2 asynchronous neuron execution scheduling strategies in datasets that encode spatial and temporal information, and we show the potential of asynchronous processing to use less spikes (up to 50%), complete inference faster (up to 2x), and achieve competitive or even better accuracy (up to $\\sim$10% higher). Our exploration affirms that asynchronous event-based AI processing can be indeed more efficient, but we need to rethink how we train our SNN models to benefit from it.", "title_embedding_index": 5657, "title_abs_embedding_index": 5682}, {"title": "Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues", "link_suffix": "/forum?id=UvTo3tVBk2", "link": "https://openreview.net/forum?id=UvTo3tVBk2", "pdf_link": "https://openreview.net/pdf?id=UvTo3tVBk2", "keywords": "State Tracking, state space, mamba, Linear RNN, Linear Attention, GLA, DeltaNet, Formal Languages", "abstract": "Linear Recurrent Neural Networks (LRNNs), such as Mamba, RWKV, GLA, mLSTM, and DeltaNet have emerged as efficient alternatives to transformers in large language modeling, offering linear scaling with sequence length and improved training efficiency. However, LRNNs struggle with state-tracking which is important for, e.g., code comprehension or tracking chess pieces across a board. Even parity, the simplest state-tracking task, which non-linear RNNs like LSTMs handle effectively, cannot be solved by current LRNNs. Recently, Sarrof et al. (2024) demonstrated that the failure of LRNNs like Mamba to solve parity stems from restricting the eigenvalue range of their diagonal state-transition matrices to $[0, 1]$, and that incorporating negative eigenvalues can resolve this issue. We generalize this result to full matrix LRNNs, which have recently shown promise in models such as DeltaNet. We prove that no finite-precision LRNN with state-transition matrices having only positive eigenvalues can solve parity, while complex eigenvalues are needed to count modulo $3$. Notably, we also prove that LRNNs can learn any regular language when their state-transition matrices are products of identity plus vector outer product matrices with eigenvalues in the range $[-1, 1]$. Our empirical results confirm that extending the eigenvalue range of models like Mamba and DeltaNet to include negative values not only enables them to solve parity but consistently improves their performance on state-tracking tasks. Furthermore, pre-training LRNNs with an extended eigenvalue range for language modeling achieves comparable performance and stability while showing promise for coding tasks. Our work enhances the expressivity of modern LRNNs, broadening their applicability without changing the cost of training or inference.", "title_embedding_index": 5658, "title_abs_embedding_index": 5683}, {"title": "xLSTM-Mixer: Multivariate Time Series Forecasting by Mixing via Scalar Memories", "link_suffix": "/forum?id=ZPZ4eCQU9k", "link": "https://openreview.net/forum?id=ZPZ4eCQU9k", "pdf_link": "https://openreview.net/pdf?id=ZPZ4eCQU9k", "keywords": "time series, xLSTM, forecasting, mixing, recurrent", "abstract": "Time series data is prevalent across numerous fields, necessitating the development of robust and accurate forecasting models. Capturing patterns both within and between temporal and multivariate components is crucial for reliable predictions.\nWe introduce xLSTM-Mixer, a model designed to effectively integrate temporal sequences, joint time-variate information, and multiple perspectives for robust forecasting. Our approach begins with a linear forecast shared across variates, which is then refined by xLSTM blocks. They serve as key elements for modeling the complex dynamics of challenging time series data. xLSTM-Mixer ultimately\nreconciles two distinct views to produce the final forecast. Our extensive evaluations demonstrate its superior long-term forecasting performance compared to recent state-of-the-art methods. A thorough model analysis provides further insights into its key components and confirms its robustness and effectiveness. This work contributes to the resurgence of recurrent models in time series forecasting.", "title_embedding_index": 5659, "title_abs_embedding_index": 5684}, {"title": "A Gradient Descent Optimizer with auto-controlled large Learning Rates, dynamic Batch Sizes and without Momentum", "link_suffix": "/forum?id=1eMbYu0841", "link": "https://openreview.net/forum?id=1eMbYu0841", "pdf_link": "https://openreview.net/pdf?id=1eMbYu0841", "keywords": "Machine Learning, ICRL, Optimization", "abstract": "We present a novel, fast gradient based momentum-free optimizer algorithm with dynamic learning rate and dynamic batch size. The main ideas are to exponentially adapt the learning rate $ \\alpha $ by situational awareness, mainly striving for orthogonal neighboring gradients, and to increase the batch size when the gradients become too noisy, leading to random walks rather than gradient descent. The method has a high success and fast convergence rate and relies only on few hyper-parameters, providing greater universality. It scales only linearly (of order $O(n)$) with dimension and is rotation invariant, thereby overcoming known limitations. The optimization method is termed ELRA (Exponential Learning Rate Adaption). The impressive performance of ELRA is demonstrated by experiments on several benchmark data-sets (ranging from MNIST to ImageNet) against common optimizers such as Adam, Lion and SGD.", "title_embedding_index": 5660, "title_abs_embedding_index": 5685}, {"title": "Unimodal-driven Distillation in Multimodal Emotion Recognition with Dynamic Fusion", "link_suffix": "/forum?id=9DDJuab67K", "link": "https://openreview.net/forum?id=9DDJuab67K", "pdf_link": "https://openreview.net/pdf?id=9DDJuab67K", "keywords": "Emotion Recognition in Conversations, Multimodal Representation, Mixture of Experts, Knowledge Distillation", "abstract": "Multimodal Emotion Recognition in Conversations (MERC) seeks to identify emotional states across multiple modalities, including text, audio, and video. This field of study is pivotal for advancing machine intelligence, with significant implications for applications such as intelligent dialogue systems and public opinion analysis. Most existing approaches primarily employ full-sequence interaction and distillation techniques, aiming to construct a comprehensive global contextual understanding while simultaneously enhancing the interaction among heterogeneous modalities. However, the presence of repetitive and redundant information, coupled with gradient conflicts arising from modal heterogeneity, can significantly impede the effectiveness of multimodal learning and long-range relationship modeling. In this work, we propose an innovative heterogeneous multimodal integration method called SUMMER, grounded in attention mechanism and knowledge distillation techniques, which facilitates dynamic interactive fusion of multimodal representations. Specifically, the Sparse Dynamic Mixture of Experts strategy is proposed to dynamically adjust the relevance of the temporal information to construct local to global token-wise interactions. Then a Global Mixture of Experts is employed to enhance the model's overall contextual understanding across modalities. Notably, we introduce retrograde distillation that utilizes a pre-trained unimodal teacher model to guide the learning of multimodal student model, intervening and supervising multimodal fusion within both the latent and logit spaces. Experiments on the IEMOCAP and MELD datasets demonstrate that our SUMMER framework consistently outperforms existing state-of-the-art methods, with particularly significant improvements in recognizing minority and semantically similar emotions in MERC tasks.", "title_embedding_index": 5661, "title_abs_embedding_index": 5686}, {"title": "Quantum Algorithm for Sparse Online Learning with Truncated Gradient Descent", "link_suffix": "/forum?id=XABvLUXQ45", "link": "https://openreview.net/forum?id=XABvLUXQ45", "pdf_link": "https://openreview.net/pdf?id=XABvLUXQ45", "keywords": "Quantum algorithms, online learning, truncated gradient descent, logistic regression, support vector machine, least squares", "abstract": "Logistic regression, the Support Vector Machine (SVM) and least squares are well-studied methods in the statistical and computer science community, with various practical applications. High-dimensional data arriving on a real-time basis makes the design of online learning algorithms that produce sparse solutions essential. The seminal work of Langford \\emph{et al.} developed a method to obtain sparsity via truncated gradient descent, showing a near-optimal online regret bound. Based on this method, we develop a quantum sparse online learning algorithm for logistic regression, the SVM and least squares. Given efficient quantum access to the inputs, we show that a quadratic speedup in the time complexity with respect to the dimension of the problem is achievable, while maintaining a regret of $O(1/\\sqrt{T})$, where $T$ is the number of time steps.", "title_embedding_index": 5662, "title_abs_embedding_index": 5687}, {"title": "Deep Clustering with Uniform Quasi-low-rank Hypersphere Embedding", "link_suffix": "/forum?id=6bpvbNLXH9", "link": "https://openreview.net/forum?id=6bpvbNLXH9", "pdf_link": "https://openreview.net/pdf?id=6bpvbNLXH9", "keywords": "unsupervised learning, representation learning, deep clustering", "abstract": "With the powerful representation ability of neural networks, deep clustering (DC) has been widely studied in machine learning communities. However, current research on DC has rarely laid emphasis on the inter-cluster representation structures, i.e. ignoring the performance degradation caused by the low uncorrelation between different clusters. To tackle this problem, a Uniform quasi-Low-rank Hypersphere Embedding based DC (ULHE-DC) method is proposed herein, which promotes learning an inter-cluster uniform and intra-cluster compact representation in a novel geometric manner. Specifically, clusters are uniformly distributed on a unit hypersphere via minimizing the hyperspherical energy of the centroids, and the embeddings belonging to the same cluster are simultaneously collapsed to a quasi-low-rank subspace through intra-cluster correlation maximization. Additionally, a pre-training based optimization scheme is proposed, in which an auto-encoder (AE) is pre-trained and the parameters of the encoder of AE are inherited to initialize the feature extractor for clustering, aiming at engaging the model learning cluster-oriented representation more efficiently. Experimental results validate the strong competitiveness of the proposed method, compared with several state-of-the-art (SOTA) benchmarks.", "title_embedding_index": 5663, "title_abs_embedding_index": 5688}, {"title": "E(3)-equivariant models cannot learn chirality: Field-based molecular generation", "link_suffix": "/forum?id=mXHTifc1Fn", "link": "https://openreview.net/forum?id=mXHTifc1Fn", "pdf_link": "https://openreview.net/pdf?id=mXHTifc1Fn", "keywords": "deep generative models, molecule generation", "abstract": "Obtaining the desired effect of drugs is highly dependent on their molecular geometries. Thus, the current prevailing paradigm focuses on 3D point-cloud atom representations, utilizing graph neural network (GNN) parametrizations, with rotational symmetries baked in via E(3) invariant layers. We prove that such models must necessarily disregard chirality, a geometric property of the molecules that cannot be superimposed on their mirror image by rotation and translation. Chirality plays a key role in determining drug safety and potency. To address this glaring issue, we introduce a novel field-based representation, proposing reference rotations that replace rotational symmetry constraints. The proposed model captures all molecular geometries including chirality, while still achieving highly competitive performance with E(3)-based methods across standard benchmarking metrics.", "title_embedding_index": 5664, "title_abs_embedding_index": 5689}, {"title": "On Inherent 3D Reasoning of VLMs in Indoor Scene Layout Design", "link_suffix": "/forum?id=uBhqll8pw1", "link": "https://openreview.net/forum?id=uBhqll8pw1", "pdf_link": "https://openreview.net/pdf?id=uBhqll8pw1", "keywords": "VLMs, Evaluation, 3D", "abstract": "Large vision-language models (VLMs) such as GPT-4o, Llama-3.2 have shown remarkable capabilities in visual understanding and reasoning, prompting us to test their off-the-shelf ability to reason and act as a 3D design assistant. This study investigates VLMs\u2019 3D reasoning capabilities using indoor scene layout synthesis i.e. placement of furniture in a room, as a test-bed. We study 3D reasoning in\nthis context through three key primitives: (1) communication of spatial locations, (2) reasoning about free space and object collision, and (3) reasoning about object alignment, orientation, and functionality, each crucial to creating a VLM agent-based scene layout synthesis pipeline. We evaluate five state-of-the-art VLMs, both proprietary and open, on a new dataset incorporating 3400 questions that assess VLMs\u2019 current 3D reasoning abilities in our context. Our findings reveal several remarkable insights: (1) VLMs consistently prefer normalized coordinates for spatial communication over absolute coordinates or pointing with image markers. (2) Contrary to expectations, VLMs perform best with simplified sketch based scene representation or, most strikingly, with no visual input at all, com-\npared to detailed renderings. (3) Free space reasoning remains challenging, with performance only slightly above random guessing, though frontier models show significant improvement with collision checking tools. Surprisingly, free space reasoning with clear visible collisions in the image can also fail. (4) Reasoning about object alignment, size, orientation and functionality together compounds errors leading to near chance performance on our dataset. These findings serve to highlight current potential and limitations of using VLMs off-the-shelf in 3D reasoning tasks, offering insights for developing advanced visual assistants capable of understanding and manipulating 3D environments.", "title_embedding_index": 5665, "title_abs_embedding_index": 5690}, {"title": "Differentially Private Deep Model-Based Reinforcement Learning", "link_suffix": "/forum?id=1YYp1rPRlm", "link": "https://openreview.net/forum?id=1YYp1rPRlm", "pdf_link": "https://openreview.net/pdf?id=1YYp1rPRlm", "keywords": "machine learning, reinforcement learning, privacy, differential privacy, deep learning, model-based, offline", "abstract": "We address private deep offline reinforcement learning (RL), where the goal is to train a policy on standard control tasks that is differentially private (DP) with respect to individual trajectories in the dataset. To achieve this, we introduce PriMORL, a model-based RL algorithm with formal differential privacy guarantees.\nPriMORL first learns an ensemble of trajectory-level DP models of the environment from offline data.\nIt then optimizes a policy on the penalized private model, without any further interaction with the system or access to the dataset. \nIn addition to offering strong theoretical guarantees, we empirically demonstrate that PriMORL enables the training of private RL agents on offline continuous control tasks with deep function approximations, whereas current methods are limited to simpler tabular and linear Markov Decision Processes (MDPs). We furthermore outline the trade-offs involved in achieving privacy in this setting.", "title_embedding_index": 5666, "title_abs_embedding_index": 5691}, {"title": "On Limitation of Transformer for Learning HMMs", "link_suffix": "/forum?id=b5lXUwZiD3", "link": "https://openreview.net/forum?id=b5lXUwZiD3", "pdf_link": "https://openreview.net/pdf?id=b5lXUwZiD3", "keywords": "Transformers, RNN, HMM, representation learning, expressive power", "abstract": "This paper investigate the capability of transformer in learning a fundamental sequential model --- the Hidden Markov Model (HMM). We design various types of HMM examples and variants inspired by theory, and conduct extensive experiments testing and comparing the performance of both transformers and Recurrent Neural Networks (RNNs). Our experiments reveal three important findings: (1) Transformers can effectively learn a large number of HMMs, but this require the depth of transformers to be at least logarithmic in the sequence length; (2) There are challenging HMMs where Transformers struggle to learn, while RNNs succeed. We also consistently observe that Transformers underperform RNNs in both training speed and testing accuracy across all tested HMM models. (3) Long mixing times and the lack of access to intermediate latent states significantly degrade Transformer's performance, but has much less impact on RNNs' performance. To address the limitation of transformers in modeling HMMs, we demonstrate that a variant of the Chain-of-Thought (CoT), called \\emph{block CoT} in the training phase, can help transformers to reduce the evaluation error and to learn longer sequences at a cost of increasing the training time. Finally, we complement our empirical findings by theoretical results proving the expressiveness of transformers in approximating HMMs with logarithmic depth.", "title_embedding_index": 5667, "title_abs_embedding_index": 5692}, {"title": "Chordal Graph Sampling-Based Mini-batch Training Algorithm for Large Graphs", "link_suffix": "/forum?id=1959usnw3Z", "link": "https://openreview.net/forum?id=1959usnw3Z", "pdf_link": "https://openreview.net/pdf?id=1959usnw3Z", "keywords": "Large scale dataset, Graph neural networks", "abstract": "Graph Neural Networks (GNNs) are powerful models for learning representations of attributed graphs. To scale GNNs to large graphs, many methods use various techniques, such as sampling and decoupling, to alleviate the \u201cneighbor explosion\u201d problem during mini-batch training. However, these sampling-based mini-batch training methods often suffer from greater information loss than decoupling-based methods or full-batch GCNs. Besides, most original segmentation methods for large graphs usually lose a large number of edges, resulting in suboptimal performance when performing mini-batch training. Therefore, we propose a Chordal Graph Sampling-based mini-batch Training algorithm for GNNs on large-scale graph datasets, called CGST. CGST includes a balanced chordal graph partition module and a batch random aggregation module to improve performance on node classification tasks while maintaining main information of the original graph structure. Experiments on three large-scale graph datasets prove the effectiveness of CGST.", "title_embedding_index": 5668, "title_abs_embedding_index": 5693}, {"title": "Quantum entanglement for attention models", "link_suffix": "/forum?id=3jRzJVf3OQ", "link": "https://openreview.net/forum?id=3jRzJVf3OQ", "pdf_link": "https://openreview.net/pdf?id=3jRzJVf3OQ", "keywords": "Attention models, Quantum entanglement, Transformers", "abstract": "Attention mechanisms in deep learning establish relationships between different positions within a sequence, enabling models like Transformers to generate effective outputs by focusing on relevant input segments and their relations. The performance of Transformers is highly dependent on the chosen attention mechanism, with various approaches balancing trade-offs between computational cost, memory efficiency, and generalization ability based on the task.Quantum machine learning models possess the potential to outperform their classical counterparts in specialized settings. This makes exploring the benefits of quantum resources within classical machine learning models a promising research direction. The role of entanglement in quantum machine learning, whether in fully quantum or as subroutines in classical-quantum hybrid models, remains poorly understood. In this work, we investigate whether quantum entanglement, when used as a resource, can improve the performance of the attention layer in Transformers.\nWe introduce an entanglement-based attention layer within a classical Transformer architecture and numerically identify scenarios where this hybrid approach proves advantageous. Our experiments on simple standard classification tasks in both vision and NLP domains reveal that the entanglement-based attention layer outperforms classical attention, showing superior generalization on quantum-generated datasets and in settings with limited training data for classical datasets. Additionally, it demonstrates a smaller generalization gap across all tested datasets. Our work contributes towards exploring the power of quantum resources as a subroutine in the classical-quantum hybrid setting to further enhance classical models.", "title_embedding_index": 5669, "title_abs_embedding_index": 5694}, {"title": "Mechanistic Behavior Editing of Language Models", "link_suffix": "/forum?id=iZI1vCiTTA", "link": "https://openreview.net/forum?id=iZI1vCiTTA", "pdf_link": "https://openreview.net/pdf?id=iZI1vCiTTA", "keywords": "Mechanistic Intervention, Bayesian Optimization", "abstract": "Large Language Models trained on web-scale text acquire language generation abilities that can solve a wide range of tasks, particularly when task knowledge is refined into the generative prior using in-context examples. However, spurious features learned from noisy data hinder their generalizability. Supervised finetuning can introduce task specificity, but introduce data inefficiency. Prior studies indicate that (i) noisy neural circuitries coexist with generalizable ones within LLMs, and (ii) finetuning typically enhances (or suppresses) existing abilities without introducing newer ones. Building upon these, we propose TaRot, a novel method for task adaptation. TaRot intervenes in the neural circuitries using learnable rotation matrices that are optimized using Bayesian Optimization, on labelled samples in the order of standard few-shot prompting examples. Experiments on multiple classification and generation tasks using LLMs of varying sizes reveal the efficacy of TaRot, improving upon both zero- as well as few-shot performance, with average improvements (across models and tasks) of 23.81% and 11.15%, respectively", "title_embedding_index": 5670, "title_abs_embedding_index": 5695}, {"title": "Distilling Cross-Domain Knowledge for Person Re-ID by Aligning Any Pretrained Encoder with CLIP Textual Features", "link_suffix": "/forum?id=CXS3cIb5Dc", "link": "https://openreview.net/forum?id=CXS3cIb5Dc", "pdf_link": "https://openreview.net/pdf?id=CXS3cIb5Dc", "keywords": "CLIP; Person ReID; Knowledge Distillation", "abstract": "Based on the alignment of image-text pairs, CLIP has demonstrated superior performance across various tasks, even in a zero-shot setting. In person ReID, CLIP-based models achieve state-of-the-art results without explicit text descriptions for further fine-tuning. However, previous models are primarily initialized with weights from ImageNet or self-supervised methods, lacking cross-domain knowledge in both image and text areas. This paper introduces a novel approach that aligns a pure image-domain pretrained student model with CLIP textual features, distilling cross-domain knowledge from existing CLIP-ReID into the online student model. To leverage CLIP\u2019s textual features for each ID, we address the challenge of mismatched feature dimensions between the teacher and student. A trainable adapter is inserted on the student side to match dimensions and preserve the prior knowledge within the pretrained student. For the student encoder yielding lower or equal-dimensional features compared to the teacher, the adapter is initialized as an identity matrix, while offline PCA is employed on the teacher side for dimensionality reduction. PCA eigenvectors are computed from all training images and applied to existing text features for matching with the student. In cases where the student outputs exceed the teacher's dimensions, the adapter is initialized using eigenvectors computed from the student side to retain knowledge in the pretrained student model. After dimension alignment, text features for each ID are compared with online image features, specifying cross-domain similarities, which are further constrained to mimic the teacher through a KL-divergence loss. Experiments with different pretraining encoder structures demonstrate the effectiveness of this approach, which is also compatible with relation knowledge distillation to enhance performance.", "title_embedding_index": 5671, "title_abs_embedding_index": 5696}, {"title": "Assessing the Knowledge-intensive Reasoning Capability of Large Language Models with Realistic Benchmarks Generated Programmatically at Scale", "link_suffix": "/forum?id=iSTMsye6SD", "link": "https://openreview.net/forum?id=iSTMsye6SD", "pdf_link": "https://openreview.net/pdf?id=iSTMsye6SD", "keywords": "Large Language Models, Evaluation, Reasoning, Hallucination", "abstract": "Although LLMs demonstrates strong reasoning capability in such tasks as mathematical problem solving, less is known about their reasoning capability in settings that require extensive real-world knowledge due to the limited scale and knowledge coverage of existing benchmarks. To shed more light into this, we propose a novel pipeline that is capable of programmatically generating realistic knowledge-intensive question answering benchmarks that require complex reasoning. Leveraging open knowledge graphs, the graph query language SPARQL, and LLMs, our pipeline requires no manual annotation and can therefore scale to unprecedented benchmark size and knowledge coverage. We evaluate several state-of-the-art LLMs with benchmarks generated by our pipeline, and find that the LLMs struggle to recall and leverage world knowledge for reasoning, even for world knowledge present in their pre-training corpuses. Additionally, retrieval-augmented generation and chain-of-thoughts prompting does not fully solve the problems. Our benchmarks further enable us to examine to what extent the confidence of LLMs in the outcomes of their reasoning transparently reflects their confidence in the underlying knowledge, a study that is first-of-its-kind to our best knowledge. We find that the confidence of LLMs in the outcomes of their reasoning reflects poorly their confidence in the underlying knowledge, which suggests a direction of future improvement.", "title_embedding_index": 5672, "title_abs_embedding_index": 5697}, {"title": "One Model Transfer to All: On Robust Jailbreak Prompts Generation against LLMs", "link_suffix": "/forum?id=sULAwlAWc1", "link": "https://openreview.net/forum?id=sULAwlAWc1", "pdf_link": "https://openreview.net/pdf?id=sULAwlAWc1", "keywords": "large language model, jailbreak attack, robustness", "abstract": "Safety alignment in large language models (LLMs) is increasingly compromised by jailbreak attacks, which can manipulate these models to generate harmful or unintended content. Investigating these attacks is crucial for uncovering model vulnerabilities. However, many existing jailbreak strategies fail to keep pace with the rapid development of defense mechanisms, such as defensive suffixes, rendering them ineffective against defended models. To tackle this issue, we introduce a novel attack method called ArrAttack, specifically designed to target defended LLMs. ArrAttack automatically generates robust jailbreak prompts capable of bypassing various defense measures. This capability is supported by a universal robustness judgment model that, once trained, can perform robustness evaluation for any target model with a wide variety of defenses. By leveraging this model, we can rapidly develop a robust jailbreak prompt generator that efficiently converts malicious input prompts into effective attacks. Extensive evaluations reveal that ArrAttack significantly outperforms existing attack strategies, demonstrating strong transferability across both white-box and black-box models, including GPT-4 and Claude-3. Our work bridges the gap between jailbreak attacks and defenses, providing a fresh perspective on generating robust jailbreak prompts.", "title_embedding_index": 5673, "title_abs_embedding_index": 5698}, {"title": "LLM Embeddings Improve Test-Time Adaptation to TabularY|X-Shifts", "link_suffix": "/forum?id=OyjMJjfhiw", "link": "https://openreview.net/forum?id=OyjMJjfhiw", "pdf_link": "https://openreview.net/pdf?id=OyjMJjfhiw", "keywords": "LLM embeddings, distribution shifts, tabular data", "abstract": "For tabular datasets, the change in the relationship between the label and covariates ($Y|X$-shifts) is common due to missing variables. Since it is impossible to generalize to a completely new and unknown domain, we study models that are easy to adapt to the target domain even with few labeled examples. We focus on building more informative representations of tabular data that can mitigate $Y|X$-shifts, and propose to leverage the prior world knowledge in LLMs by serializing the tabular data to encode it. We find LLM embeddings alone provide inconsistent improvements in robustness, but models trained on them can be well adapted to the target domain even using 32 labeled observations. Our finding is based on a systematic study consisting of 7650 source-target pairs and benchmark against261,000model configurations trained by 20 algorithms. Our observation holds when ablating the size of accessible target data and different adaptation strategies.", "title_embedding_index": 5674, "title_abs_embedding_index": 5699}]
[
    {
        "title": "Targeted Manipulation and Deception Emerge in LLMs Trained on User* Feedback",
        "link_suffix": "/forum?id=Wf2ndb8nhf",
        "link": "https://openreview.net/forum?id=Wf2ndb8nhf",
        "pdf_link": "https://openreview.net/pdf?id=Wf2ndb8nhf",
        "keywords": "manipulation, deception, alignment, reward hacking, user feedback",
        "abstract": "When AI systems are trained to maximize positive feedback from humans, this creates a perverse incentive structure for the AI to resort to any available means—including harmful behaviors like sycophancy, deception, and manipulation—to ensure it receives positive human feedback, regardless of whether its actions truly merit such approval. So far, with LLM training, this drive has only been documented in the emergence of relatively mild forms of sycophancy, in which the system overly agrees with or praises the user.\nOur work shows that in domains of practical LLM usage, optimizinguserfeedback (as opposed toannotatorfeedback) may reliably lead to the emergence of manipulation, deception, and extreme forms of sycophancy which target the users that are most vulnerable to them. To mitigate this issue, it seems promising to leverage continued safety training or external annotator feedback to \"veto\" that of users. We find that while such approach can reduce or remove the emergence of harmful behaviors in some settings, it can even exacerbate them in others, making them more sophisticated and harder to detect. Our findings caution against optimizing user feedback without stringent safeguards, and constitute a cautionary tale of the fundamental risks and limitations that come along with optimizing any form of feedback, whether from humans or AI systems. Warning: this paper contains examples that may be offensive or upsetting."
    },
    {
        "title": "Interpreting Emergent Planning in Model-Free Reinforcement Learning",
        "link_suffix": "/forum?id=DzGe40glxs",
        "link": "https://openreview.net/forum?id=DzGe40glxs",
        "pdf_link": "https://openreview.net/pdf?id=DzGe40glxs",
        "keywords": "reinforcement learning, interpretability, planning, probes, model-free, mechanistic interpretability, sokoban",
        "abstract": "We present the first mechanistic evidence that model-free reinforcement learning agents can learn to plan. This is achieved by applying a methodology based on concept-based interpretability to a model-free agent in Sokoban -- a commonly used benchmark for studying planning. Specifically, we demonstrate that DRC, a generic model-free agent introduced byGuez et al. (2019), uses learned concept representations to internally formulate plans that both predict the long-term effects of actions on the environment and influence action selection. Our methodology involves: (1) probing for planning-relevant concepts, (2) investigating plan formation within the agent's representations, and (3) verifying that discovered plans (in agent's representations) have causal effect on agent's behavior through interventions. We also show that the emergence of these plans coincides with the emergence of a planning-like property: the ability to benefit from additional test-time compute. Finally, we perform a qualitative analysis of the planning algorithm learned by the agent and discover a strong resemblance to parallelized bidirectional search. Our findings advance understanding of the internal mechanisms underlying planning behavior in agents, enabling improved diagnosis, interpretation, and control of agent planning processes."
    },
    {
        "title": "Gaussian Differentially Private Human Faces Under a Face Radial Curve Representation",
        "link_suffix": "/forum?id=K2Tqn8R9pu",
        "link": "https://openreview.net/forum?id=K2Tqn8R9pu",
        "pdf_link": "https://openreview.net/pdf?id=K2Tqn8R9pu",
        "keywords": "differential privacy, shape analysis, functional data analysis",
        "abstract": "In this paper we consider the problem of releasing a Gaussian Differentially Private (GDP) 3D human face. The human face is a complex structure with many features and inherently tied to one's identity.  Protecting this data, in a formally private way, is important yet challenging given the dimensionality of the problem. We extend approximate DP techniques for functional data to the GDP framework. We further propose a novel representation, face radial curves, of a 3D face as a set of functions and then utilize our proposed GDP functional data mechanism. To preserve the shape of the face while injecting noise we rely on tools from shape analysis for our novel representation of the face. We show that our method preserves the shape of the average face and injects less noise than traditional methods for the same privacy budget. Our mechanism consists of two primary components, the first is generally applicable to function value summaries (as are commonly found in nonparametric statistics or functional data analysis) while the second is general to disk-like surfaces and hence more applicable than just to human faces."
    },
    {
        "title": "PackNets: A Variational Autoencoder-Like Approach for Packing Circles in Any Shape",
        "link_suffix": "/forum?id=6gUrqzDNsQ",
        "link": "https://openreview.net/forum?id=6gUrqzDNsQ",
        "pdf_link": "https://openreview.net/pdf?id=6gUrqzDNsQ",
        "keywords": "Encoder-decoder, Packing, Neural networks, Arbitrary shapes",
        "abstract": "The problem of packing smaller objects within a larger one has long been of interest. In this work, we employ an encoder-decoder architecture, parameterized by neural networks, for circle packing. Our solution consists of an encoder that takes the index of a circle as input and outputs a point, which is then transformed by a constraint block into a valid center within the outer shape. A perturbation block perturbs this center while ensuring it remains within the corresponding radius, and the decoder estimates the circle's index based on the perturbed center. The functionality of the perturbation block is akin to adding noise to the latent space variables in variational autoencoders (VAEs); however, it differs significantly in both the method and purpose of perturbation injection, as we inject perturbation to push the centers of the circles sufficiently apart.  Additionally, unlike typical VAEs, our architecture incorporates a constraint block to ensure that the circles do not breach the boundary of the outer shape. We design the constraint block to pack both congruent and non-congruent circles within arbitrary shapes, implementing a scheduled injection of perturbation from a beta distribution in the perturbation block to gradually push the centers apart. We compare our approach to established methods, including disciplined convex-concave programming (DCCP) and other packing techniques, demonstrating competitive performance in terms of packing density—the fraction of the outer object's area covered by the circles. Our method outperforms the DCCP-based solution in the non-congruent case and approaches the best-known packing densities. To our knowledge, this is the first work to present solutions for packing circles within arbitrary shapes."
    },
    {
        "title": "Diffusion Transformers for Tabular Data Time Series Generation",
        "link_suffix": "/forum?id=bhOysNJvWm",
        "link": "https://openreview.net/forum?id=bhOysNJvWm",
        "pdf_link": "https://openreview.net/pdf?id=bhOysNJvWm",
        "keywords": "tabular data generation, time series, diffusion models",
        "abstract": "Tabular data generation has recently attracted a growing interest due to its different application scenarios. However, \ngenerating time series of tabular data, where each element of the series depends on the others,\nremains a largely unexplored domain. \nThis gap is probably due to the difficulty of jointly solving different problems, the main of which are the heterogeneity of tabular data (a problem common to non-time-dependent approaches) and the variable length of a time series.\nIn this paper, we propose a Diffusion Transformers (DiTs) based approach for tabular data series generation. Inspired by the recent success of DiTs in image and video generation, we extend this framework to deal with heterogeneous data and variable-length sequences. \nUsing extensive experiments on six datasets, we show that the proposed approach  outperforms previous work by a large margin. \nOur code will be made public after this article is accepted."
    },
    {
        "title": "Less is More: Exploiting Feature Density for Enhanced Membership Inference Attacks",
        "link_suffix": "/forum?id=Jq8NPYVxLW",
        "link": "https://openreview.net/forum?id=Jq8NPYVxLW",
        "pdf_link": "https://openreview.net/pdf?id=Jq8NPYVxLW",
        "keywords": "membership inference attack, machine learning privacy",
        "abstract": "Membership inference attacks have become the de facto standard for assessing privacy breaches across various machine learning (ML) models. However, existing approaches often require substantial resources, including large numbers of shadow models and auxiliary datasets, to achieve high true positive rates (TPR) in the low false positive rate (FPR) region. This makes these attacks prohibitively expensive and less practical. In this work, we propose a novel membership inference attack that exploits feature density gaps by progressively removing features from both members and non-members and evaluating the corresponding model outputs as a new membership signal. Our method requires only a few dozen queries and does not rely on large auxiliary datasets or the training of numerous shadow models. Extensive evaluations on both classification and diffusion models demonstrate that our method significantly improves the TPR at low FPR across multiple scenarios."
    },
    {
        "title": "AgentGym: Evaluating and Evolving Large Language Model-based Agents across Diverse Envronments",
        "link_suffix": "/forum?id=b8eEutZlPb",
        "link": "https://openreview.net/forum?id=b8eEutZlPb",
        "pdf_link": "https://openreview.net/pdf?id=b8eEutZlPb",
        "keywords": "large language model, LLM-based agent, self-improvement, evaluation",
        "abstract": "Large language models (LLMs), with their generalized capabilities, are considered as a promising foundation to build generally-capable agents that can handle multi-turn decision-making tasks across various interactive environments. Previous attempts typically gather expert-provided trajectories and have LLM-based agents imitate these trajectories step-by-step. However, this supervised fine-tuning approach depends heavily on human supervision, limiting scalability and restricting the agent's exploration and learning in the environments. In this paper, we take the first step towards developing generally-capable LLM-based agents that can explore and evolve themselves across diverse environments. To achieve this, we identify a trinity of ingredients: 1) diverse interactive environments for agent exploration, 2) a trajectory set to equip agents with basic capabilities and prior knowledge, and 3) an effective and scalable approach for agent improvement across environments. We propose AgentGym, a new interactive framework featuring various real-world scenarios and environments for broad, unified, real-time, and concurrent agent exploration. AgentGym also includes a database with expanded instructions, high-quality trajectories, and a benchmark suite. Next, we investigate the potential of agent self-evolution across various environments with a derived exploration-learning method named AgentEvol. Experimental results show that the evolved agents can achieve results comparable to SOTA models. We will release the code, dataset, benchmark, and checkpoints."
    },
    {
        "title": "Unlocking SVD-Space for Feedback Aligned Local Training",
        "link_suffix": "/forum?id=8Agcic0csh",
        "link": "https://openreview.net/forum?id=8Agcic0csh",
        "pdf_link": "https://openreview.net/pdf?id=8Agcic0csh",
        "keywords": "Direct Feedback Alignment, Local learning, Singular Value Decomposition",
        "abstract": "Deep Neural Networks (DNNs) are typically trained using backpropagation, which, despite its effectiveness, requires substantial memory and computing resources. To address these limitations, we propose a novel local training framework that enables efficient and scalable neural network training without relying on global backpropagation. Our framework harnesses the alignment of Singular Value Decomposed (SVD) weight space with feedback matrices, guided by custom layerwise loss functions, to enable efficient and scalable neural network training. We decompose weight matrices into their SVD components before training, and perform local updates on the SVD components themselves, driven by a tailored objective that integrates feedback error, alignment regularization, orthogonality constraints, and sparsity. Our approach leverages Direct Feedback Alignment (DFA) to eliminate the need for global backpropagation and further optimizes model complexity by dynamically reducing the rank of the SVD components during training. The result is a compute- and memory-efficient model with classification accuracy on par with traditional backpropagation while achieving a 50-75% reduction in memory usage and computational cost during training. With strong theoretical convergence guarantees, we demonstrate that training in the SVD space with DFA not only accelerates computation but also offers a powerful, energy-efficient solution for scalable deep learning in resource-constrained environments. Code is available."
    },
    {
        "title": "Non-Equilibrium Dynamics of Hybrid Continuous-Discrete Ground-State Sampling",
        "link_suffix": "/forum?id=BlSIKSPhfz",
        "link": "https://openreview.net/forum?id=BlSIKSPhfz",
        "pdf_link": "https://openreview.net/pdf?id=BlSIKSPhfz",
        "keywords": "Combinatorial optimization, Degenerate ground-state sampling, Metropolis-Hastings algorithm, Chaotic dynamics, Wishart planted ensemble",
        "abstract": "We propose a general framework for a hybrid continuous-discrete algorithm that integrates continuous-time deterministic dynamics with Metropolis-Hastings steps to combine search dynamics with and without detailed balance. Our purpose is to study the non-equilibrium dynamics that leads to the ground state of rugged energy landscapes in this general setting. Our results show that MH-driven dynamics reach ``easy'' ground states faster, indicating a stronger bias in the non-equilibrium dynamics of the algorithm with reversible transition probabilities. To validate this, we construct a set of Ising problem instances with a controllable bias in the energy landscape that makes one degenerate solution more accessible than another. The constructed hybrid algorithm demonstrates significant improvements in convergence and ground-state sampling accuracy, achieving a 100x speedup on GPUs compared to simulated annealing, making it well-suited for large-scale applications."
    },
    {
        "title": "Complexity of Injectivity and Verification of ReLU Neural Networks",
        "link_suffix": "/forum?id=Vz5HgVwcdu",
        "link": "https://openreview.net/forum?id=Vz5HgVwcdu",
        "pdf_link": "https://openreview.net/pdf?id=Vz5HgVwcdu",
        "keywords": "ReLU neural networks, computational complexity, parameterized complexity, verification, computational geometry",
        "abstract": "Neural networks with ReLU activation play a key role in modern machine learning. Understanding the functions represented by ReLU networks is a major topic in current research as this enables a better interpretability of learning processes.Injectivity plays a crucial role whenever invertibility of a neural network is necessary, such as, e.g., for inverse problems or generative models. The exact computational complexity of deciding injectivity was recently posed as an open problem (Puthawala et al. [JMLR 2022]).\nWe answer this question by proving coNP-completeness. On the positive side, we show that the problem for a single ReLU layer is still tractable for small input dimension; more precisely, we present a parameterized algorithm which yields fixed-parameter tractability with\nrespect to theinput dimension.In addition, we study the network verification problem which is of great importance since neural networks are increasingly used in safety-critical systems. We prove that network verification is coNP-hard for a general class of input domains. Our result thus highlights that the hardness of network verification is intrinsic to the ReLU networks themselves, rather than specific input domains. In this context, we also characterize surjectivity for ReLU networks with one-dimensional output which turns out to be the complement of a basic network verification task. We reveal interesting connections to computational convexity byformulating the surjectivity problem as a zonotope containment problem."
    },
    {
        "title": "Learning to Achieve Goals with Belief State Transformers",
        "link_suffix": "/forum?id=ThRMTCgpvo",
        "link": "https://openreview.net/forum?id=ThRMTCgpvo",
        "pdf_link": "https://openreview.net/pdf?id=ThRMTCgpvo",
        "keywords": "representation learning, transformers, next-token prediction, reasoning, planning",
        "abstract": "We introduce the \"Belief State Transformer\", a next-token predictor that takes both a prefix and suffix as inputs, with a novel objective of predicting both the next token for the prefix and the previous token for the suffix. The Belief State Transformer effectively learns to solve challenging problems that conventional forward-only transformers struggle with, in a domain-independent fashion.  Key to this success is learning a compact belief state that captures all relevant information necessary for accurate predictions.\nEmpirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short. \nFor the task of story writing with known prefixes and suffixes, our approach outperforms the Fill-in-the-Middle method for reaching known goals and demonstrates improved performance even when the goals are unknown.Altogether, the Belief State Transformer enables more efficient goal-conditioned decoding, better test-time inference, and high-quality text representations on small scale problems."
    },
    {
        "title": "Rapid Grassmannian Averaging with Chebyshev Polynomials",
        "link_suffix": "/forum?id=ntxoThl1Zp",
        "link": "https://openreview.net/forum?id=ntxoThl1Zp",
        "pdf_link": "https://openreview.net/pdf?id=ntxoThl1Zp",
        "keywords": "Grassmannian, Grassmann, Manifold, Subspace, Average, Averaging, Mean, Fast, Rapid, Chebyshev, Polynomial, Power, Method, Iteration, Consensus, Decentralized, Distributed",
        "abstract": "We propose new algorithms to efficiently average a collection of points on a Grassmannian manifold in both the centralized and decentralized settings. Grassmannian points are used ubiquitously in machine learning, computer vision, and signal processing to represent data through (often low-dimensional) subspaces. While averaging these points is crucial to many tasks (especially in the decentralized setting), existing methods unfortunately remain computationally expensive due to the non-Euclidean geometry of the manifold. Our proposed algorithms, Rapid Grassmannian Averaging (RGrAv) and Decentralized Rapid Grassmannian Averaging (DRGrAv), overcome this challenge by leveraging the spectral structure of the problem to rapidly compute an average using only small matrix multiplications and QR factorizations. We provide a theoretical guarantee of optimality and present numerical experiments which demonstrate that our algorithms outperform state-of-the-art methods in providing high accuracy solutions in minimal time. Additional experiments showcase the versatility of our algorithms to tasks such as $K$-means clustering on video motion data, establishing RGrAv and DRGrAv as powerful tools for generic Grassmannian averaging."
    },
    {
        "title": "More Space Is All You Need: Revisiting  Molecular Representation Learning",
        "link_suffix": "/forum?id=LBsr2llHz0",
        "link": "https://openreview.net/forum?id=LBsr2llHz0",
        "pdf_link": "https://openreview.net/pdf?id=LBsr2llHz0",
        "keywords": "Molecular Representation Learning, Molecular Property",
        "abstract": "Molecular representation learning (MRL) has become pivotal in leveraging limited supervised data for applications such as drug discovery and material design. While early MRL methods relied on 1D sequences and 2D graphs, recent advancements have incorporated 3D conformational information, focusing predominantly on atomic interactions within 3D space. However, we argue that the space beyond atoms is also crucial for MRL, which is overlooked by prior models. To address this, we propose a novel transformer-based framework, dubbed SpaceFormer, which incorporates additional 3D space beyond atoms to enhance molecular representation ability. \nSpaceFormer introduces three key components: (1) Precision-Preserved Gridding, which discretizes continuous 3D space into grid cells while preserving precision; (2) Grid Sampling, which employs an importance sampling strategy to improve efficiency; and (3) Linear-Complexity 3D Positional Encoding, which extends Rotary Positional Encoding to 3D space to capture pairwise angular directions and utilizes random Fourier features to efficiently encode radial distances. Extensive experiments show that SpaceFormer significantly outperforms previous 3D MRL models across various tasks, validating the benefit of leveraging the additional 3D space beyond atoms in MRL models."
    },
    {
        "title": "A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment",
        "link_suffix": "/forum?id=eUkbTUsDgs",
        "link": "https://openreview.net/forum?id=eUkbTUsDgs",
        "pdf_link": "https://openreview.net/pdf?id=eUkbTUsDgs",
        "keywords": "LLM Agents, Animal Cognition, Cognitive Science, Evaluation",
        "abstract": "As general-purpose tools, Large Language Models (LLMs) must often reason about everyday physical environments. In a question-and-answer capacity, understanding the interactions of physical objects may be necessary to give an appropriate response. Additionally, LLMs are increasingly used as the reasoning engines in agentic systems, designing and controlling their action sequences. The vast majority of research has approached this question using static benchmarks, comprised of text or image-based questions about the physical world. However, these benchmarks do not capture the complexity and nuance of physical processes as they are experienced in real life. Here we advocate for a second, relatively unexplored, approach:~that of `embodying' the LLMs by granting them control of an agent within a 3D environment. We present the first embodied evaluation of physical common-sense reasoning in LLMs using cognitively meaningful evaluation. Our framework allows direct comparison of LLMs with other embodied agents, such as those based on Deep Reinforcement Learning, and human and non-human animals. We employ the Animal-AI (AAI) environment, a simulated 3D \\textit{virtual laboratory}, to study physical common-sense reasoning in LLMs. For this, we use the AAI Testbed, a suite of experiments that replicate laboratory studies with non-human animals, to study physical reasoning capabilities ranging from distance estimation, navigation around obstacles, tracking out-of-sight objects, and tool use. We demonstrate that state-of-the-art multi-modal models with no finetuning can complete this style of task, allowing meaningful comparison to the entrants of the 2019 Animal-AI Olympics competition and to human children. Our results show that LLMs cannot yet perform competitively with human children on these tasks. We argue that this approach allows the study of physical reasoning using ecologically valid experiments drawn directly from cognitive science, improving the predictability and reliability of LLMs."
    },
    {
        "title": "Is Pontryagin's Maximum Principle All You Need? Solving optimal control problems with PMP-inspired neural networks",
        "link_suffix": "/forum?id=wMSZEP7BDh",
        "link": "https://openreview.net/forum?id=wMSZEP7BDh",
        "pdf_link": "https://openreview.net/pdf?id=wMSZEP7BDh",
        "keywords": "prior knowledge, Pontryagin's Maximum Principle, optimal control",
        "abstract": "Calculus of variations is the mathematics of functional optimization, i.e., when the solution are functions over a time interval. This is particularly important when the time interval is unknown like in minimum-time control problems, so that forward in time solutions are not possible. Calculus of Variations offers a robust framework for learning optimal control and inference. How can this framework be leveraged to design neural networks to solve challenges in control and inference? We propose the Pontryagin's Maximum Principle Neural Network (PMP-net) that is tailored to estimate control and inference solutions, in accordance with the necessary conditions outlined by Pontryagin’s Maximum Principle. We assess PMP-net on two classic optimal control and inference problems: optimal linear filtering and minimum-time control. Our findings indicate that PMP-net can be effectively trained in an unsupervised manner to solve these problems without the need for ground-truth data, successfully deriving the classical \"Kalman filter\" and \"bang-bang\" control solution. This establishes a new approach for addressing general, possibly yet unsolved, optimal control problems."
    },
    {
        "title": "MeanSparse: Post-Training Robustness Enhancement Through Mean-Centered Feature Sparsification",
        "link_suffix": "/forum?id=CSZKElOtG5",
        "link": "https://openreview.net/forum?id=CSZKElOtG5",
        "pdf_link": "https://openreview.net/pdf?id=CSZKElOtG5",
        "keywords": "Adversarial Training, Sparsification, Robustness, Activation Functions, Proximal Operator",
        "abstract": "We present a simple yet effective method to improve the robustness of both Convolutional and attention-based Neural Networks against adversarial examples by post-processing an adversarially trained model. \nOur technique, MeanSparse,  cascades the activation functions of a trained model with novel operators that sparsify mean-centered feature vectors. \nThis is equivalent to reducing feature variations around the mean, and we show that such reduced variations merely affect the model's utility, yet they strongly attenuate the adversarial perturbations and decrease the attacker's success rate.\nOur experiments show that, when applied to the top models in the RobustBench leaderboard, MeanSparse achieves a new robustness record of $75.28$% (from $73.71$%), $44.78$% (from $42.67$%) and $62.12$% (from $59.56$%) on CIFAR-10, CIFAR-100 and ImageNet, respectively, in terms of AutoAttack accuracy. \nCode:https://anonymous.4open.science/r/MeanSparse-84B0/"
    },
    {
        "title": "Directed graph transformers meet metabolic networks",
        "link_suffix": "/forum?id=X7EMiddusV",
        "link": "https://openreview.net/forum?id=X7EMiddusV",
        "pdf_link": "https://openreview.net/pdf?id=X7EMiddusV",
        "keywords": "Graph Transformers, Genome-Scale Metabolic Models, Metabolic Networks, Essential Reactions, Petri Nets, Biological Networks, Systems Biology",
        "abstract": "Technical advances in sequencing have allowed the reconstruction of genome-scale metabolic models (GEMs) for a wide range of microorganisms. These models have been particularly useful for the prediction of essential genes and reactions, which are potential targets for antimicrobial therapies. However, current methods for essentiality prediction are computationally limited and are not able to accommodate the increasingly available data. Motivated by the success of data-driven approaches in other domains, this work introduces the metabolic transformer, a model designed for holistic identification of essential reactions in  genome-scale models, entirely trained on synthetic knock-out data.  It is demonstrated that the problem of essential reaction prediction can be theoretically formulated as the identification of redundant nodes in directed bipartite graphs. This reveals the limitations of message-passing schemes and motivates the development of a novel graph transformer architecture specifically tailored for metabolic networks. The proposed architecture is capable of addressing the essential reaction identification problem by capturing both the directionality and global structure of metabolic networks. To demonstrate the effectiveness of our approach, we composed a large-scale dataset of genome-scale models reconstructed from real microorganisms."
    },
    {
        "title": "SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models",
        "link_suffix": "/forum?id=pJhgMNKEV3",
        "link": "https://openreview.net/forum?id=pJhgMNKEV3",
        "pdf_link": "https://openreview.net/pdf?id=pJhgMNKEV3",
        "keywords": "Large Language Models, Mathematical Reasoning, Code Generation",
        "abstract": "There is a growing trend of teaching large language models (LLMs) to solve mathematical problems through coding. Existing studies primarily focus on prompting powerful, closed-source models to generate seed training data followed by in-domain data augmentation, equipping LLMs with considerable capabilities for code-assisted mathematical reasoning. However, continually training these models on augmented data derived from a few datasets such as GSM8K may impair their generalization abilities and restrict their effectiveness to limited question types. Conversely, the potential of improving such LLMs by leveraging large-scale, expert-written, diverse math question-answer pairs remains unexplored. To utilize these resources and tackle unique challenges such as code response assessment, we propose a novel paradigm that uses a code-based critic model to guide steps including question-code data construction, quality control, and complementary evaluation. We also explore different alignment algorithms with self-generated instruction/preference data to foster continuous self-improvement. Experiments across both in-distribution (up to $+5.7%$) and out-of-distribution ($+4.4%$) benchmarks in English and Chinese show the effectiveness of the proposed paradigm."
    },
    {
        "title": "Understanding Factual Recall in Transformers via Associative Memories",
        "link_suffix": "/forum?id=hwSmPOAmhk",
        "link": "https://openreview.net/forum?id=hwSmPOAmhk",
        "pdf_link": "https://openreview.net/pdf?id=hwSmPOAmhk",
        "keywords": "transformers, associative memories, factual recall, storage capacity, training dynamics",
        "abstract": "Large language models have demonstrated an impressive ability to perform factual recall. Prior work has found that transformers trained on factual recall tasks can store information at a rate proportional to their parameter count. In our work, we show that shallow transformers can use a combination of associative memories to obtain such near optimal storage capacity. We begin by proving that the storage capacities of both linear and MLP associative memories scale linearly with parameter count. We next introduce a synthetic factual recall task, and prove that a transformer with a single layer of self-attention followed by an MLP can obtain 100% accuracy on the task whenever either the total number of self-attention parameters or MLP parameters scales (up to log factors) linearly with the number of facts. In particular, the transformer can trade off between using the value matrices or the MLP as an associative memory to store the dataset of facts. We complement these expressivity results with an analysis of the gradient flow trajectory of a simplified linear attention model trained on our factual recall task, where we show that the model exhibits sequential learning behavior."
    },
    {
        "title": "Bridging the Data Provenance Gap Across Text, Speech, and Video",
        "link_suffix": "/forum?id=G5DziesYxL",
        "link": "https://openreview.net/forum?id=G5DziesYxL",
        "pdf_link": "https://openreview.net/pdf?id=G5DziesYxL",
        "keywords": "training data, audit, speech, video, text",
        "abstract": "Progress in AI is driven largely by the scale and quality of training data. Despite this, there is a deficit of empirical analysis examining the attributes of well-established datasets beyond text. In this work we conduct the largest and first-of-its-kind longitudinal audit across modalities---popular text, speech, and video datasets---from their detailed sourcing trends and use restrictions to their geographical and linguistic representation. Our manual analysis covers nearly 4000 public datasets between 1990-2024, spanning 608 languages, 798 sources, 659 organizations, and 67 countries. We find that multimodal machine learning applications have overwhelmingly turned to web-crawled and social media platforms, such as YouTube, for their training sets, eclipsing all other sources since 2019. Secondly, tracing the chain of dataset derivations we find that while less than 33% of datasets are restrictively licensed, over 99%, 78%, and 99% of the source content in widely-used text, speech, and video datasets, respectively, carry non-commercial restrictions. Finally, counter to increasing absolute multilingual and geographic inclusion in publicly available AI training data, our audit demonstrates measures of relative geographical and multilingual representation have failed to significantly improve their coverage since 2013. We believe the breadth of our audit enables us to empirically examine trends in data sourcing, restrictions, and Western-centricity at an ecosystem-level, and that visibility into these questions are essential to progress in responsible AI. As a contribution to ongoing improvements in dataset transparency and responsible use, we release our entire multimodal audit, allowing practitioners to trace data provenance across text, speech, and video."
    },
    {
        "title": "FedMAP: Unlocking Potential in Personalized Federated Learning through Bi-Level MAP Optimization",
        "link_suffix": "/forum?id=jYP8Cd2bMW",
        "link": "https://openreview.net/forum?id=jYP8Cd2bMW",
        "pdf_link": "https://openreview.net/pdf?id=jYP8Cd2bMW",
        "keywords": "Federated Learning, Personalized Federated Learning, Non-IID Data Distributions, Bi-level Optimization",
        "abstract": "Federated Learning (FL) enables collaborative training of machine learning (ML) models on decentralized data while preserving data privacy. However, data across clients often differs significantly due to class imbalance, feature distribution skew, sample size imbalance, and other phenomena.\nUsing information from these not identically distributed (non-IID) datasets causes challenges in training. Existing FL methods based on a single global model cannot effectively capture client data variations, resulting in suboptimal performance. Personalized FL (PFL) techniques were introduced to adapt to the local data distribution of each client and utilize the data from other clients. \nThey have shown promising results in addressing these challenges. \nWe propose FedMAP, a novel Bayesian PFL framework which applies Maximum A Posteriori (MAP) estimation to effectively mitigate various non-IID data issues, by means of a parametric prior distribution, which is updated during aggregation. We provide a theoretical foundation illustrating FedMAP's convergence properties. In particular, we prove that the prior updates in FedMAP correspond to gradient descent iterations for a linear combination of envelope functions associated with the local losses. This differs from previous FL approaches, that aim at minimizing a weighted average of local loss functions and often face challenges with heterogeneous data distributions, resulting in reduced client performance and slower convergence in non-IID settings. \nFinally, we show, through evaluations of synthetic and real-world datasets, that FedMAP achieves better performance than the existing methods. Moreover, we offer a robust, ready-to-use framework to facilitate practical deployment and further research."
    },
    {
        "title": "Topological Data Analysis on Graphs: Euler characteristics, Persistent Homology, or Spectrum?",
        "link_suffix": "/forum?id=kuchZdMRMa",
        "link": "https://openreview.net/forum?id=kuchZdMRMa",
        "pdf_link": "https://openreview.net/pdf?id=kuchZdMRMa",
        "keywords": "graph representation learning, topological data analysis, Euler characteristics, persistent homology, Laplacian spectrum, graph neural networks",
        "abstract": "Graph neural networks (GNNs) are limited by the Weisfeiler-Leman (WL) hierarchy and cannot compute graph properties such as cycles. Topological descriptors (TDs) such as the Euler characteristics (EC), persistent homology (PH), and Laplacian spectrums have thus been employed to enhance the GNNs. However, despite empirical successes,  the theoretical underpinnings of these TDs remain largely underexplored. We bridge this gap with a rigorous characterization of TDs focusing on three key aspects: expressivity (representational power), stability (robustness to data perturbations), and computation (implementation cost). We evaluate the expressivity of different TDs, and  design a novel scheme that is strictly more expressive. We also propose a new metric to assess the stability of the state-of-the-art RePHINE method. To address computational costs, we introduce and analyze weaker variants for several descriptors. TDs find significant application in molecular contexts, so we also explore new  filtration functions on the molecular graphs. Finally, we formalize the properties of filtration functions derived from graph products. Overall, this work lays the foundation for the principled design and analysis of new TDs that can be tailored to specific applications."
    },
    {
        "title": "Zero-shot Object-level Out-of-distribution Detection with Context-aware Inpainting",
        "link_suffix": "/forum?id=7fjYy3TOPM",
        "link": "https://openreview.net/forum?id=7fjYy3TOPM",
        "pdf_link": "https://openreview.net/pdf?id=7fjYy3TOPM",
        "keywords": "out-of-distribution detection, zero-shot, generative model",
        "abstract": "Detecting when an object detector predicts wrongly, for example, misrecognizing an out-of-distribution (ODD) unseen object as a seen one, is crucial to ensure the model’s trustworthiness. Modern object detectors are known to be overly confident, making it hard to rely solely on their responses to detect error cases. We therefore investigate the use of an auxiliary model for the rescue. Specifically, we leverage an off-the-shelf text-to-image generative model (e.g., Stable Diffusion), whose training objective is different from discriminative models. We surmise such a discrepancy would allow us to use their inconsistency as an error indicator. Concretely, given a detected object box and the predicted class label, we perform class-conditioned inpainting on the box-removed image. When the predicted object label is incorrect, the inpainted image is doomed to deviate from the original one, making the reconstruction error an effective recognition error indicator, especially on misclassified OOD samples. Extensive experiments demonstrate that our approach consistently outperforms prior zero-shot and non-zero-shot OOD detection approaches."
    },
    {
        "title": "Neuro-Symbolic Rule Lists",
        "link_suffix": "/forum?id=yAN2oPHs7y",
        "link": "https://openreview.net/forum?id=yAN2oPHs7y",
        "pdf_link": "https://openreview.net/pdf?id=yAN2oPHs7y",
        "keywords": "Neuro-Symbolic;Rule Induction; Intepretability",
        "abstract": "Machine learning models deployed in sensitive areas such as healthcare must be interpretable to ensure accountability and fairness.\nRule lists (If$\\texttt{Age} < 35 \\wedge  \\texttt{Priors}  > 0$then$\\texttt{Recidivism} = $True,else if\"Next Condition\" ...)\noffer full transparency, making them well-suited for high-stakes decisions.\nHowever, learning such rule lists presents significant challenges. Existing methods based on combinatorial optimization require feature pre-discretization and impose restrictions on rule size.  Neuro-symbolic methods use more scalable continuous optimization yet place similar pre-discretization constraints and suffer from unstable optimization. To address the existing limitations, we introduce NyRules, an end-to-end trainable model that unifies discretization, rule learning, and rule order into a single differentiable framework. \nWe formulate a continuous relaxation of the rule list learning problem that converges to a strict rule list through temperature annealing.\nNyRules learns both the discretizations of individual features, as well as their combination into conjunctive rules without any pre-processing or restrictions.\nExtensive experiments demonstrate that NyRules consistently outperforms both combinatorial and neuro-symbolic methods,\neffectively learning simple and complex rules, as well as their order, across a wide range of datasets."
    },
    {
        "title": "What can we learn from Harry Potter? An Exploratory Study of Visual Representation Learning from Atypical Videos",
        "link_suffix": "/forum?id=3ZdGSTxKuy",
        "link": "https://openreview.net/forum?id=3ZdGSTxKuy",
        "pdf_link": "https://openreview.net/pdf?id=3ZdGSTxKuy",
        "keywords": "Open-world learning, Out-of-distribution detection, Video classification",
        "abstract": "Humans usually show exceptional generalisation and discovery ability in the open world, when being shown uncommonly new concepts. Whereas most existing studies in the literature focus on common typical data from closed sets, and open world novel discovery is under-explored in videos.\nIn this paper, we are interested in asking: \\textit{what if atypical unusual videos are exposed in the learning process?}\nTo this end, we collect a new video dataset consisting of various types of unusual atypical data (e.g. sci-fi, animation, etc.). To study how such atypical data may benefit representation learning in open-world discovery, we feed them into the model training process for representation learning. Taking out-of-distribution (OOD) detection as a task to evaluate the model's novel discovery capability, we found that such a simple learning approach consistently improves performance across a few different settings. Furthermore, we found that increasing the categorical diversity of the atypical samples further boosts OOD detection performance.  These observations in our extensive experimental evaluations reveal the benefits of atypical videos for visual representation learning in the open world, together with the newly proposed dataset, encouraging further studies in this direction."
    }
]
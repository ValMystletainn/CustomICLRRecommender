[{"title": "Align-VL: Can Being Modest Help in the Alignment of Vision-Language Models?", "link_suffix": "/forum?id=HhP9bgCugr", "link": "https://openreview.net/forum?id=HhP9bgCugr", "pdf_link": "https://openreview.net/pdf?id=HhP9bgCugr", "keywords": "Vision-Language Models, Multimodal Alignment, Embedding Smoothing", "abstract": "Multimodal alignment aims to learn a shared latent space between different modal inputs to establish connections across modalities.\nA prime example is Visual Language Models (VLMs), such as CLIP, which benefit from extensive image-text pre-training and excel in image recognition tasks. \nThese models are emblematic of successful multimodal alignment.\nSubsequent work has successfully aligned multimodal data on limited datasets using feature mixing enhancement methods.\nHowever, these models encounter significant challenges:\n{The presence of {ambiguous samples (either partially matched or completely unmatched)} in datasets with weakly associated, low-quality image-text pairs causes models to become overconfident (in training) and confused (in inference), ultimately reducing performance}. Current contrastive learning methods, which rely on single positive pairs, exacerbate this issue by encouraging overconfidence when the model encounters such ambiguous samples.\nTo overcome these challenges, we developed Align-VL, a multimodal alignment enhancement method that operates on the latent spaces of pre-trained unimodal encoders. This approach adjusts the matching degree of the data and moderates model overconfidence, promoting more appropriate and effective alignments.\nAlign-VL incorporates {Random Perturbation} and {Embedding Smoothing} strategies to enhance input feature robustness and reduce model overconfidence, improving the model's ability to manage uncertainty and generalize to new data. \nIn our experiments, Align-VL outperformed existing state-of-the-art (SoTA) methods in image-text retrieval tasks, demonstrating its superior effectiveness.\nAlign-VL also offers significant reductions in training time and data requirements compared to methods like CLIP, using substantially fewer GPU days and image-text pairs. \nCode will be publicly available.", "title_embedding_index": 5200, "title_abs_embedding_index": 5225}, {"title": "G2T-LLM: Graph-to-Tree Text Encoding for Molecule Generation with Fine-Tuned Large Language Models", "link_suffix": "/forum?id=hrMNbdxcqL", "link": "https://openreview.net/forum?id=hrMNbdxcqL", "pdf_link": "https://openreview.net/pdf?id=hrMNbdxcqL", "keywords": "Molecule Generation, Large Language Model, Graph Generation, Tree", "abstract": "We introduce G2T-LLM, a novel approach for molecule generation that uses graph-to-tree text encoding to transform graph-based molecular structures into a hierarchical text format optimized for large language models (LLMs). This encoding converts complex molecular graphs into tree-structured formats, such as JSON and XML, which LLMs are particularly adept at processing due to their extensive pre-training on these types of data. By leveraging the flexibility of LLMs, our approach allows for intuitive interaction using natural language prompts, providing a more accessible interface for molecular design. Through supervised fine-tuning, G2T-LLM generates valid and coherent chemical structures, addressing common challenges like invalid outputs seen in traditional graph-based methods. While LLMs are computationally intensive, they offer superior generalization and adaptability, enabling the generation of diverse molecular structures with minimal task-specific customization. The proposed approach achieved comparable performances with state-of-the-art methods on various benchmark molecular generation datasets, demonstrating its potential as a flexible and innovative tool for AI-driven molecular design.", "title_embedding_index": 5201, "title_abs_embedding_index": 5226}, {"title": "Benchmarks and Custom Package for Energy Forecasting", "link_suffix": "/forum?id=hKeHfOUCXL", "link": "https://openreview.net/forum?id=hKeHfOUCXL", "pdf_link": "https://openreview.net/pdf?id=hKeHfOUCXL", "keywords": "Energy Forecasting.+Benchmark.+Dataset", "abstract": "Energy (load, wind, photovoltaic) forecasting is significant in the power industry as it can provide a reference for subsequent tasks such as power grid dispatch, thus bringing huge economic benefits. However, there are many differences between energy forecasting and traditional time series forecasting. On the one hand, traditional time series mainly focus on capturing characteristics like trends and cycles. In contrast, the energy series is largely influenced by many external factors, such as meteorological and calendar variables. On the other hand, energy forecasting aims to minimize the cost of subsequent tasks such as power grid dispatch, rather than simply pursuing prediction accuracy. In addition, the scale of energy data can also significantly impact the predicted results. In this paper, we collected large-scale load datasets and released a new renewable energy dataset that contains both station-level and region-level renewable generation data with meteorological data. For load data, we also included load domain-specific feature engineering and provided a method to customize the loss function and link the forecasting error to requirements related to subsequent tasks (such as power grid dispatching costs), integrating it into our forecasting framework. Based on such a situation, we conducted extensive experiments with 21 forecasting methods in these energy datasets at different levels under 11 evaluation metrics, providing a comprehensive reference for researchers to compare different energy forecasting models.", "title_embedding_index": 5202, "title_abs_embedding_index": 5227}, {"title": "Fantastic Experts and How to Find Them: A  Multi-Dimensional Study for Experts-Level Sparsification in Mixture-of-Experts", "link_suffix": "/forum?id=UUZuwDv8iw", "link": "https://openreview.net/forum?id=UUZuwDv8iw", "pdf_link": "https://openreview.net/pdf?id=UUZuwDv8iw", "keywords": "Mixture of Experts; Compression; Expert Pruning; Efficiency", "abstract": "Sparsely activated Mixture-of-Experts (SMoE) has shown promise in scaling up the learning capacity of neural networks. However, vanilla SMoEs have issues such as expert redundancy and heavy memory requirements, making them inefficient and non-scalable, especially for resource-constrained scenarios. Expert-level sparsification of SMoEs involves pruning the least important experts to address these limitations. In this work, we aim to address three questions: (1) What is the best recipe across multiple plausible recipes to identify the least knowledgeable subset of experts that can be dropped to achieve a desired sparsity level? (2) How should we perform expert dropping (one-shot or iterative), and what correction measures can we undertake to minimize its drastic impact on SMoE subnetwork capabilities? (3) What capabilities of full-SMoEs are severely impacted by the removal of the least dominant experts, and how can we recover them? Firstly, we propose MoE Experts Compression Suite (MC-Suite), which is a collection of some previously explored and multiple novel recipes to provide a comprehensive benchmark for estimating expert importance from diverse perspectives, as well as unveil numerous valuable insights for SMoE experts. Secondly, unlike prior works with a one-shot expert pruning approach, we explore the benefits of iterative pruning with the re-estimation of the MC-Suite criterion. Moreover, we introduce the benefits of task-agnostic fine-tuning as a correction mechanism during progressive expert dropping, which we term MoE Lottery Subnetworks. Lastly, we present an experimentally validated conjecture that, during expert dropping, SMoEs' instruction-following capabilities are predominantly hurt, which can be restored to a robust level subject to external augmentation of instruction-following capabilities using k-shot examples and supervised fine-tuning.", "title_embedding_index": 5203, "title_abs_embedding_index": 5228}, {"title": "Self-rationalization improves LLM as a fine-grained judge", "link_suffix": "/forum?id=RZZPnAaw6Z", "link": "https://openreview.net/forum?id=RZZPnAaw6Z", "pdf_link": "https://openreview.net/pdf?id=RZZPnAaw6Z", "keywords": "Large Language Model, LLM-as-Judge, Self-Rationalizing, Preference Optimization, Meta-Judge, Fine-grained evaluation", "abstract": "LLM-as-a-judge models have been used for evaluating both human and AI generated content, specifically by providing scores and rationales. Rationales, in addition to increasing transparency, help models learn to calibrate its judgments. Enhancing a model's rationale can therefore improve its calibration abilities and ultimately the ability to score content. We introduce Self-Rationalization, an iterative process of improving the rationales for the judge models, which consequently improves the score for fine-grained customizable scoring criteria (i.e., likert-scale scoring with arbitrary evaluation criteria). Self-rationalization works by having the model generate multiple judgments with rationales for the same input, curating a preference pair dataset from its own judgements, and iteratively fine-tuning the judge via DPO. Intuitively, this approach allows the judge model to self-improve by learning from its own rationales, leading to better alignment and evaluation accuracy. After just two iterations -- while only relying on examples in the training set -- human evaluation shows that our judge model learns to produce higher quality rationales, with a win rate of $62\\%$ on average compared to models just trained via SFT on rationale . This judge model also achieves high scoring accuracy on BigGen Bench and Reward Bench, outperforming even bigger sized models trained using SFT with rationale, self-consistency or best-of-$N$ sampling by $3\\%$ to $9\\%$.", "title_embedding_index": 5204, "title_abs_embedding_index": 5229}, {"title": "AFTD: a foreground target detection dataset for airport scenario", "link_suffix": "/forum?id=UpPXWd9SBk", "link": "https://openreview.net/forum?id=UpPXWd9SBk", "pdf_link": "https://openreview.net/pdf?id=UpPXWd9SBk", "keywords": "airport surface.+video surveillance.+object detection.+movable target", "abstract": "The detection of foreground targets on airport surface is the foundation of airport\u00a0 surveillance applications. However, effective algorithms and specialized benchmarks are still lacking in this area. Based\u00a0on this fact, we propose an Airport Foreground Target Detection dataset (AFTD),\u00a0 which contains the three most important foreground targets moving on the airport surface: aircraft, vehicle, and person.  Through self collection and collection of web images, we have obtained a total of\u00a0 over 200000 images and filtered out 10050 images based on diversity principles to\u00a0 form the AFTD dataset, which includes a total of 26968 aircraft instances, 24759 vehicle instances, and 5064 person instances. AFTD includes a variety of changes of these\u00a0targets, such as super multi-scale, multi-level occlusion and viewangle changes, etc.\u00a0In addition, we further illustrate the challenges posed by AFTD to existing algorithms through statistical analysis and detailed experiments, and discuss how to solve these challenges in the airport surveillance scenario.The AFTD dataset can be downloaded fromhttp://www.agvs-caac.com/aftd/aftd.html.", "title_embedding_index": 5205, "title_abs_embedding_index": 5230}, {"title": "Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model Fine-tuning", "link_suffix": "/forum?id=uO0itv7XFa", "link": "https://openreview.net/forum?id=uO0itv7XFa", "pdf_link": "https://openreview.net/pdf?id=uO0itv7XFa", "keywords": "Large language models, Tool Use, Agent, Reasoning", "abstract": "When using agent-task datasets to enhance agent capabilities for Large Language Models (LLMs), current methodologies often treat all tokens within a sample equally. \nHowever, we argue that tokens serving different roles\u2014specifically, reasoning tokens versus boilerplate tokens (e.g., those governing output format)\u2014differ significantly in importance and learning complexity, necessitating their disentanglement and distinct treatment. \nTo address this, we propose a novel Shuffle-Aware Discriminator (SHAD) for adaptive token discrimination.\nSHAD classifies tokens by exploiting predictability differences observed after shuffling input-output combinations across samples: boilerplate tokens, due to their repetitive nature among samples, maintain predictability, whereas reasoning tokens do not.\nUsing SHAD, we propose the Reasoning-highlighted Fine-Tuning (RFT) method, which adaptively emphasizes reasoning tokens during fine-tuning, yielding notable performance gains over common Supervised Fine-Tuning (SFT).", "title_embedding_index": 5206, "title_abs_embedding_index": 5231}, {"title": "How to Train Long-Context Language Models (Effectively)", "link_suffix": "/forum?id=nwZHFKrYTB", "link": "https://openreview.net/forum?id=nwZHFKrYTB", "pdf_link": "https://openreview.net/pdf?id=nwZHFKrYTB", "keywords": "language models, long-context language models, continual pre-training, long-context SFT", "abstract": "We study the problem of adapting a language model (LM) to make effective use of long-context information. We first establish a reliable evaluation protocol to guide model development---instead of perplexity, we use a broad set of long-context tasks, and we evaluate models after supervised fine-tuning (SFT) with instruction data as this better reveals long-context abilities. Supported by our robust evaluations, we run thorough experiments to decide the data mix for continued pre-training, the instruction tuning dataset, and other design choices such as position extrapolation. We find that (1) code repositories and books are excellent sources of long data, but it is crucial to combine them with high-quality short data; (2) training with a sequence length beyond the evaluation length boosts long-context performance; (3) for SFT, using only short instruction datasets yields strong performance on long-context tasks. Our final model, ProLong-8B, which is initialized from Llama-3 and trained on 40B tokens, demonstrates state-of-the-art long-context performance among similarly sized models at a length of 128K, outperforming Llama-3.1-8B on the majority of long-context tasks despite having seen 5% as many tokens during long-context training. Additionally, ProLong can effectively process up to 512K tokens, one of the longest context windows of publicly available LMs.", "title_embedding_index": 5207, "title_abs_embedding_index": 5232}, {"title": "BILBO: BILevel Bayesian Optimization", "link_suffix": "/forum?id=ye1mxb79lw", "link": "https://openreview.net/forum?id=ye1mxb79lw", "pdf_link": "https://openreview.net/pdf?id=ye1mxb79lw", "keywords": "bilevel, Bayesian optimization", "abstract": "Bilevel optimization, characterized by a two-level hierarchical optimization structure, is prevalent in real-world problems but poses significant challenges, especially in noisy, constrained, and derivative-free settings. To tackle these challenges, we present a novel algorithm for BILevel Bayesian Optimization (BILBO) that optimizes both upper- and lower-level problems jointly in a sample-efficient manner by using confidence bounds to construct trusted sets of feasible and lower-level optimal solutions. We show that sampling from our trusted sets guarantees points with instantaneous regret bounds. Moreover, BILBO selects only one function query per iteration, facilitating its use in decoupled settings where upper- and lower-level function evaluations may come from different simulators or experiments. We also show that this function query selection strategy leads to an instantaneous regret bound for the query point. The performance of BILBO is theoretically guaranteed with a sublinear regret bound and is empirically evaluated on several synthetic and real-world problems.", "title_embedding_index": 5208, "title_abs_embedding_index": 5233}, {"title": "Risk Informed Policy Learning for Safer Exploration", "link_suffix": "/forum?id=gJG4IPwg6l", "link": "https://openreview.net/forum?id=gJG4IPwg6l", "pdf_link": "https://openreview.net/pdf?id=gJG4IPwg6l", "keywords": "Reinforcement Learning, Safe Exploration, Representation Learning, Inductive Bias", "abstract": "Reinforcement learning algorithms typically necessitate extensive exploration of the state space to find optimal policies. However, in safety-critical applications, the risks associated with such exploration can lead to catastrophic consequences. Existing safe exploration methods mitigate this by imposing constraints, but these often result in overly conservative behaviours and inefficient learning. Overfitting on negative experiences hampers the agent's ability to learn accurate risk representations, limiting its exploration of risky yet potentially high-reward regions of the state space. To address this, we introduce a method that explicitly learns state-conditioned risk representations by incorporating an inductive bias. By augmenting state features with these risk representations, our approach naturally encourages safer exploration without being excessively cautious, resulting in more efficient and safer policy learning. Empirical evaluations across diverse environments show that our method significantly improves task performance while reducing constraint violations during training, underscoring its effectiveness in balancing exploration with safety.", "title_embedding_index": 5209, "title_abs_embedding_index": 5234}, {"title": "Combining Induction and Transduction for Abstract Reasoning", "link_suffix": "/forum?id=UmdotAAVDe", "link": "https://openreview.net/forum?id=UmdotAAVDe", "pdf_link": "https://openreview.net/pdf?id=UmdotAAVDe", "keywords": "Abstract Reasoning, Visual Reasoning, Program Synthesis, Induction, Transduction", "abstract": "When learning an input-output mapping from very few examples, is it better to first infer a latent function that explains the examples, or is it better to directly predict new test outputs?\nWe study this question on ARC, a highly diverse dataset of abstract reasoning tasks.\nWe train neural models for induction (inferring latent functions) and transduction (directly predicting the test output for a given test input).\nOur models are trained on synthetic data generated by prompting LLMs to produce  Python code specifying a function to be inferred, plus a stochastic subroutine for generating inputs to that function.\nWe find inductive and transductive models solve very different problems, despite training on the same data, and having the same architecture.", "title_embedding_index": 5210, "title_abs_embedding_index": 5235}, {"title": "Prompt Infection: LLM-to-LLM Prompt Injection within Multi-Agent Systems", "link_suffix": "/forum?id=NAbqM2cMjD", "link": "https://openreview.net/forum?id=NAbqM2cMjD", "pdf_link": "https://openreview.net/pdf?id=NAbqM2cMjD", "keywords": "Large Language Models, Prompt Injection, Multi-Agent Systems, LLM Security, LLM Safety", "abstract": "As Large Language Models (LLMs) grow increasingly powerful, multi-agent systems\u2014where multiple LLMs collaborate to tackle complex tasks\u2014are becoming more prevalent in modern AI applications. Most safety research, however, has focused on vulnerabilities in single-agent LLMs. These include prompt injection attacks, where malicious prompts embedded in external content trick the LLM into executing unintended or harmful actions, compromising the victim\u2019s application. In this paper, we reveal a more dangerous vector: LLM-to-LLM prompt injection within multi-agent systems. We introduce Prompt Infection, a novel attack where malicious prompts self-replicate across interconnected agents, behaving much like a computer virus. This attack poses severe threats, including data theft, scams, misinformation, and system-wide disruption, all while propagating silently through the system. Our extensive experiments demonstrate that multi-agent systems are highly susceptible, even when agents do not directly share communications. To address this, we propose LLM Tagging, a defense mechanism that, when combined with existing safeguards, significantly mitigates infection spread. This work underscores the urgent need for advanced security measures as multi-agent LLM systems become more widely adopted.", "title_embedding_index": 5211, "title_abs_embedding_index": 5236}, {"title": "Open-Vocabulary Object Detection for Incomparable Spaces", "link_suffix": "/forum?id=1Nwsqw0sTm", "link": "https://openreview.net/forum?id=1Nwsqw0sTm", "pdf_link": "https://openreview.net/pdf?id=1Nwsqw0sTm", "keywords": "Multimodal learning, object detection", "abstract": "In open-vocabulary object detection (OVDet), specifying the object of interest at inference time opens up powerful possibilities, allowing users to define new categories without retraining the model. These objects can be identified through text descriptions, image examples, or a combination of both. However, visual and textual data, while complementary, encode different data types, making direct comparison or alignment challenging. Naive fusion approaches often lead to misaligned predictions, particularly when one modality is ambiguous or incomplete. In this work, we propose an approach for OVDet that aligns relational structures across these incomparable spaces, ensuring optimal correspondence between visual and textual inputs. This shift from feature fusion to relational alignment bridges the gap between these spaces, enabling robust detection even when input from one modality is weak.  Our evaluation on the challenging datasets demonstrates that our model sets a new benchmark in detecting rare objects, outperforming existing OVDet models. Additionally, we show that our multi-modal classifiers outperform single-modality models and even surpass fully-supervised detectors.", "title_embedding_index": 5212, "title_abs_embedding_index": 5237}, {"title": "Collective variables of neural networks: empirical time evolution and scaling laws", "link_suffix": "/forum?id=S04xvGXjEs", "link": "https://openreview.net/forum?id=S04xvGXjEs", "pdf_link": "https://openreview.net/pdf?id=S04xvGXjEs", "keywords": "neural network theory, neural scaling laws, neural tangent kernel, statistical physics of neural networks", "abstract": "This work presents a novel means for understanding learning dynamics and scaling relations in neural networks.\nWe show that certain measures on the spectrum of the empirical neural tangent kernel, specifically entropy and trace, yield insight into the representations learned by a neural network and how these can be improved through architecture scaling.\nThese results are demonstrated first on test cases before being shown on more complex networks, including transformers, auto-encoders, graph neural networks, and reinforcement learning studies.\nIn testing on a wide range of architectures, we highlight the universal nature of training dynamics and further discuss how it can be used to understand the mechanisms behind learning in neural networks.\nWe identify two such dominant mechanisms present throughout machine learning training.\nThe first, information compression, is seen through a reduction in the entropy of the NTK spectrum during training, and occurs predominantly in small neural networks.\nThe second, coined structure formation, is seen through an increasing entropy and thus, the creation of structure in the neural network representations beyond the prior established by the network at initialization.\nDue to the ubiquity of the latter in deep neural network architectures and its flexibility in the creation of feature-rich representations, we argue that this form of evolution of the network's entropy be considered the onset of a deep learning regime.", "title_embedding_index": 5213, "title_abs_embedding_index": 5238}, {"title": "TabKANet: Tabular Data Modeling with Kolmogorov-Arnold Network and Transformer", "link_suffix": "/forum?id=3qDhqj6qfu", "link": "https://openreview.net/forum?id=3qDhqj6qfu", "pdf_link": "https://openreview.net/pdf?id=3qDhqj6qfu", "keywords": "Tabular Data Modeling; Kolmogorov-Arnold Network; Numerical Feature Embedding", "abstract": "Tabular data is the most common type of data in real-life scenarios. In this study, we propose the TabKANet model for tabular data modeling, which targets the bottlenecks in learning from numerical content. We constructed a Kolmogorov-Arnold Network (KAN) based Numerical Embedding Module and unified numerical and categorical features encoding within a Transformer architecture. TabKANet has demonstrated stable and significantly superior performance compared to Neural Networks (NNs) across multiple public datasets in binary classification, multi-class classification, and regression tasks. Its performance is comparable to or surpasses that of  Gradient Boosted Decision Tree models (GBDTs). Our code is publicly available on GitHub:https://github.com/AI-thpremed/TabKANet.", "title_embedding_index": 5214, "title_abs_embedding_index": 5239}, {"title": "Intelligent Control in Embodied Robotics: Enhancing Human-Robot Interaction through Adaptive Control Techniques", "link_suffix": "/forum?id=70kYH6InYU", "link": "https://openreview.net/forum?id=70kYH6InYU", "pdf_link": "https://openreview.net/pdf?id=70kYH6InYU", "keywords": "Embodied Intelligence, Large Language Models (LLMs), Human-Robot Interaction, Adaptive Control, Data Amplification", "abstract": "Current embodied intelligence models often lack the ability to adjust control methods dynamically in response to human intentions, limiting their effectiveness in real-world interactions. This paper proposes a novel framework that enables robots to dynamically adapt their control parameters by integrating large language models (LLMs) with intelligent controllers. \nOur approach simulates human-robot interactions and generates synthetic training data, allowing robots to better understand and respond to diverse human needs. We validate the framework using two commonly used control techniques and demonstrate that it can effectively adjust control methods, such as Proportional-Integral-Derivative (PID) and Nonlinear Model Predictive Control (NMPC), based on real-time human feedback. Experimental results show that our model enhances adaptability and responsiveness in human-robot interaction.\n This work advances embodied intelligence by introducing an adaptive control framework and providing a scalable method for data generation, which together enable more intuitive and effective robot behaviors.", "title_embedding_index": 5215, "title_abs_embedding_index": 5240}, {"title": "Unveiling Neural Combinatorial Optimization Model Representations Through Probing", "link_suffix": "/forum?id=agEy9hliY1", "link": "https://openreview.net/forum?id=agEy9hliY1", "pdf_link": "https://openreview.net/pdf?id=agEy9hliY1", "keywords": "neural combinatorial optimization, vehicle routing problem, probing, representation learning", "abstract": "Neural combinatorial optimization (NCO) models have achieved remarkable performance, yet their learned underlying representations remain largely unclear. This hinders real-world application, as industrial stakeholders may want a deeper understanding of NCO models before committing resources. In this paper, we make the first step towards interpreting NCO models by investigating embeddings learned by various architectures through three probing tasks. Specifically, we analyze representative and state-of-the-art attention-based models, including AM, POMO, and LEHD, on the representative Traveling Salesman Problem and Capacitated Vehicle Routing Problem. Our findings reveal that NCO models encode linear representations of Euclidean distances between nodes, while also capturing additional knowledge that help avoid making myopic decisions. Furthermore, we show that architectural choices affect the ability of deep models to accurately represent Euclidean distances and to incorporate non-myopic decision-making strategies. We also verify to what extent NCO models understand the feasibility of constraints. Our work represents an initial effort to interpret NCO models, enhance understanding of why certain architectures outperform others, and demonstrate probing as a valuable tool for analyzing their internal mechanisms.", "title_embedding_index": 5216, "title_abs_embedding_index": 5241}, {"title": "Table Learning Representation from Scanned PDF Documents Containing Some Red Stamps", "link_suffix": "/forum?id=hiZPVlbGsI", "link": "https://openreview.net/forum?id=hiZPVlbGsI", "pdf_link": "https://openreview.net/pdf?id=hiZPVlbGsI", "keywords": "Table Learning Representation, Table detection, Table recognition, Scanned PDF Documents, Red Stamps", "abstract": "Generally, it can be challenging to recognize the table contents from scanned PDF documents containing some red stamps and reconcile the recognized table contents. \nIn this paper, we address the reconciliation challenge involving matching the handwritten invoice amounts overlapped with a red stamp against the invoice amounts found in multi-page tables extracted from scanned PDF documents and we propose a context-splitting Transformer-based table recognition method for recognizing the handwritten invoice amounts overlapped with a red stamp against the invoice amounts.Firstly, we recognize the layout structure of the table which is detected from the scanned PDF document containing some red stamps on the handwritten invoice amounts of the table. \nSecondly, we represent the table cells as context-splitting embedding vectors which involve spatial context embedding, position context embedding, lexical context embedding, and colored context embedding.Finally, we apply a stack of Transformer-based self-attention encoders to recognize the cross-modality table cells where we multiply the length of query vector and the length of key vector with the scaling factor of the original Transformer in order to make the training process more stable. \nWe improve the recognition accuracy of table cells with a red stamp on handwritten invoice amounts.", "title_embedding_index": 5217, "title_abs_embedding_index": 5242}, {"title": "CPDD: Generalized Compressed Representation for Multivariate Long-term Time Series Generation", "link_suffix": "/forum?id=4f4HDfbwY5", "link": "https://openreview.net/forum?id=4f4HDfbwY5", "pdf_link": "https://openreview.net/pdf?id=4f4HDfbwY5", "keywords": "Generative Model, Deep Learning, Mode Function, Diffusion Model, Long-term Time Series", "abstract": "The generation of time series has increasingly wide applications in many fields, such as electricity and energy. Generating realistic multivariate long time series is a crucial step towards making time series generative models practical, with the challenge being the balance between long-term dependencies and short-term feature learning. Towards this end, we propose a novel time series generative model named Compressed Patch Denoising Diffusion-model (CPDD). Concretely, CPDD first employs the Time-series Patch Compressed (TPC) module based on the patch mode decomposition method to obtain the latent encoding of multi-scale feature fusion. Subsequently, it utilizes a diffusion-based model to learn the latent distribution and decode the resulting samples, thereby achieving high-quality multivariate long-time series generation. Through extensive experiments, results show that CPDD achieves state-of-the-art performance in the generation task of multivariate long-time series. Furthermore, TPC also exhibits remarkable efficiency in terms of robustness and generalization in time series reconstruction.", "title_embedding_index": 5218, "title_abs_embedding_index": 5243}, {"title": "CViT: Continuous Vision Transformer for Operator Learning", "link_suffix": "/forum?id=cRnCcuLvyr", "link": "https://openreview.net/forum?id=cRnCcuLvyr", "pdf_link": "https://openreview.net/pdf?id=cRnCcuLvyr", "keywords": "Scientific Machine Learning, Operator Learning, Neural Operators, Neural Fields, Vision Transformer, Partial Differential Equations", "abstract": "Operator learning, which aims to approximate maps between infinite-dimensional function spaces, is an important area in scientific machine learning with applications across various physical domains. Here we introduce the Continuous Vision Transformer (CViT), a novel neural operator architecture that leverages advances in computer vision to address challenges in learning complex physical systems.  CViT combines a vision transformer encoder, a novel grid-based coordinate embedding, and a query-wise cross-attention mechanism to effectively capture multi-scale dependencies. This design allows for flexible output representations and consistent evaluation at arbitrary resolutions. We demonstrate CViT's effectiveness across a diverse range of partial differential equation (PDE) systems, including fluid dynamics, climate modeling, and reaction-diffusion processes. Our comprehensive experiments show that CViT achieves state-of-the-art performance on multiple benchmarks, often surpassing larger foundation models, even without extensive pretraining and roll-out fine-tuning. Taken together, CViT exhibits robust handling of discontinuous solutions, multi-scale features, and intricate spatio-temporal dynamics. Our contributions can be viewed as a significant step towards adapting advanced computer vision architectures for building more flexible and accurate machine learning models in the physical sciences.", "title_embedding_index": 5219, "title_abs_embedding_index": 5244}, {"title": "TIDMAD: Time Series Dataset for Discovering Dark Matter with AI Denoising", "link_suffix": "/forum?id=p2QAOORDoG", "link": "https://openreview.net/forum?id=p2QAOORDoG", "pdf_link": "https://openreview.net/pdf?id=p2QAOORDoG", "keywords": "benchmark, dataset, denoising, public dataset, dark matter, physics, time series, ultra-long time series", "abstract": "Dark matter makes up approximately 85% of total matter in our universe, yet it has never been directly observed in any laboratory on Earth. The origin of dark matter is one of the most important questions in contemporary physics, and a convincing detection of dark matter would be a Nobel-Prize-level breakthrough in fundamental science. The ABRACADABRA experiment was specifically designed to search for dark matter. Although it has not yet made a discovery, ABRACADABRA has produced several dark matter search results widely endorsed by the physics community. The experiment generates ultra-long time-series data at a rate of 10 million samples per second, where the dark matter signal would manifest itself as a sinusoidal oscillation mode within the ultra-long time series. In this paper, we present the TIDMAD --- a comprehensive data release from the ABRACADABRA experiment including three key components: an ultra-long time series dataset divided into training, validation, and science subsets; a carefully-designed denoising score for direct model benchmarking; and a complete analysis framework which produces a community-standard dark matter search result suitable for publication as a physics paper. This data release enables core AI algorithms to extract the signal and produce real physics results thereby advancing fundamental science. The data downloading and associated analysis scripts are available athttps://anonymous.4open.science/r/TIDMAD.", "title_embedding_index": 5220, "title_abs_embedding_index": 5245}, {"title": "How Jailbreak Defenses Work and Ensemble? A Mechanistic Investigation", "link_suffix": "/forum?id=RdGvvqjkC1", "link": "https://openreview.net/forum?id=RdGvvqjkC1", "pdf_link": "https://openreview.net/pdf?id=RdGvvqjkC1", "keywords": "Jailbreak, defense, analysis, LVLM", "abstract": "Jailbreak attacks, where malicious prompts bypass generative models\u2019 built-in safety, have raised significant concerns about model vulnerability. While diverse defense methods have been proposed, the underlying mechanisms governing the trade-offs between model safety and helpfulness, and their application to Large Vision-Language Models (LVLMs) remain insufficiently explored. This paper systematically investigates jailbreak defense mechanisms by reformulating the standard generation task as a binary classification problem to probe model refusal tendencies across both harmful and benign queries. Our analysis identifies two key defense mechanisms: safety shift, which generally increases refusal probabilities for all queries, and harmfulness discrimination, which enhances the model\u2019s ability to distinguish between benign and harmful queries. Leveraging these mechanisms, we design two ensemble defense strategies\u2014inter-mechanism and intra-mechanism ensembles\u2014to explore the safety-helpfulness balance. Empirical evaluations on the MM-SafetyBench and MOSSBench datasets on top of LLaVA-1.5 models demonstrate the effectiveness of these ensemble approaches in either enhancing model safety or achieving an improved safety-utility balance. These findings offer valuable insights into jailbreak defense strategies and contribute to the development of more resilient LVLM safety systems.", "title_embedding_index": 5221, "title_abs_embedding_index": 5246}, {"title": "SURE-VQA: Systematic Understanding of Robustness Evaluation in Medical VQA Tasks", "link_suffix": "/forum?id=nHdWdcoyAg", "link": "https://openreview.net/forum?id=nHdWdcoyAg", "pdf_link": "https://openreview.net/pdf?id=nHdWdcoyAg", "keywords": "robustness, VQA, validation", "abstract": "Vision-Language Models (VLMs) have great potential in medical tasks, like Visual Question Answering (VQA), where they could act as interactive assistants for both patients and clinicians. Yet their robustness to distribution shifts on unseen data remains a critical concern for safe deployment. Evaluating such robustness requires a controlled experimental setup that allows for systematic insights into the model's behavior. However, we demonstrate that current setups fail to offer sufficiently thorough evaluations, limiting their ability to accurately assess model robustness.\nTo address this gap, our work introduces a novel framework, called SURE-VQA, centered around three key requirements to overcome the current pitfalls and systematically analyze the robustness of VLMs: 1) Since robustness on synthetic shifts does not necessarily translate to real-world shifts, robustness should be measured on real-world shifts that are inherent to the VQA data; 2) Traditional token-matching metrics often fail to capture underlying semantics, necessitating the use of large language models (LLMs) for more accurate semantic evaluation; 3) Model performance often lacks interpretability due to missing sanity baselines, thus meaningful baselines should be reported that allow assessing the multimodal impact on the VLM.\nTo demonstrate the relevance of this framework, we conduct a study on the robustness of various Parameter-Efficient Fine-Tuning (PEFT) methods across three medical datasets with four different types of distribution shifts. \nOur study reveals several important findings: 1) Sanity baselines that do not utilize image data can perform surprisingly well; 2) We confirm LoRA as the best-performing PEFT method; 3) No PEFT method consistently outperforms others in terms of robustness to shifts. Code is provided athttps://github.com/KOFRJO/sure-vqa.", "title_embedding_index": 5222, "title_abs_embedding_index": 5247}, {"title": "MultiRC: Joint Learning for Time Series Anomaly Prediction and Detection with Multi-scale Reconstructive Contrast", "link_suffix": "/forum?id=fAvG3P3Cxx", "link": "https://openreview.net/forum?id=fAvG3P3Cxx", "pdf_link": "https://openreview.net/pdf?id=fAvG3P3Cxx", "keywords": "Time Series Anomaly Prediction, Time Series Anomaly Detection, Self-Supervised Learning", "abstract": "Many methods have been proposed for unsupervised time series anomaly detection. Despite some progress, research on predicting future anomalies is still relatively scarce. Predicting anomalies is particularly challenging due to the diverse reaction time and the lack of labeled data. To address these challenges, we propose MultiRC to integrate reconstructive and contrastive learning for joint learning of anomaly prediction and detection, with multi-scale structure and adaptive dominant period mask to deal with the diverse reaction time. MultiRC also generates negative samples to provide essential training momentum for the anomaly prediction tasks and prevent model degradation. We evaluate seven benchmark datasets from different fields. For both anomaly prediction and detection tasks, MultiRC outperforms existing state-of-the-art methods. The code is available athttps://anonymous.4open.science/status/MultiRC-CCE6.", "title_embedding_index": 5223, "title_abs_embedding_index": 5248}, {"title": "MuVi: Video-to-Music Generation with Semantic Alignment and Rhythmic Synchronization", "link_suffix": "/forum?id=E040QmNETN", "link": "https://openreview.net/forum?id=E040QmNETN", "pdf_link": "https://openreview.net/pdf?id=E040QmNETN", "keywords": "Video-to-music generation, music generation", "abstract": "Generating music that aligns with the visual content of a video has been a challenging task, as it requires a deep understanding of visual semantics and involves generating music whose melody, rhythm, and dynamics harmonize with the visual narratives. This paper presents MuVi, a novel framework that effectively addresses these challenges to enhance the cohesion and immersive experience of audio-visual content. MuVi analyzes video content through a specially designed visual adaptor to extract contextually and temporally relevant features. These features are used to generate music that not only matches the video\u2019s mood and theme but also its rhythm and pacing. We also introduce a contrastive music-visual pre-training scheme to ensure synchronization, based on the periodicity nature of music phrases. In addition, we demonstrate that our flow-matching-based music generator has in-context learning ability, allowing us to control the style and genre of the generated music. Experimental results show that MuVi demonstrates superior performance in both audio quality and temporal synchronization. The generated music video samples are available at muvi-v2m.github.io.", "title_embedding_index": 5224, "title_abs_embedding_index": 5249}]
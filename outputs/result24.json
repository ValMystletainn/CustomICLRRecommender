[
    {
        "title": "Hyperbolic Genome Embeddings",
        "link_suffix": "/forum?id=NkGDNM8LB0",
        "link": "https://openreview.net/forum?id=NkGDNM8LB0",
        "pdf_link": "https://openreview.net/pdf?id=NkGDNM8LB0",
        "keywords": "genomics, representation learning, hyperbolic geometry",
        "abstract": "Current approaches to genomic sequence modeling often struggle to align the inductive biases of machine learning models with the evolutionarily-informed structure of biological systems. To this end, we formulate a novel application of hyperbolic CNNs that exploits this structure, enabling more expressive DNA sequence representations. Our strategy circumvents the need for explicit phylogenetic mapping while discerning key properties of sequences pertaining to core functional and regulatory behavior. Across 37 out of 43 genome interpretation benchmark datasets, our hyperbolic models outperform their Euclidean equivalents. Notably, our approach even surpasses state-of-the-art performance on six GUE benchmark datasets, consistently outperforming many DNA language models while using 13-379$\\times$ fewer parameters and avoiding pretraining. Our results include a novel benchmark dataset - the Transposable Elements Benchmark - which explores a significant but understudied component of the genome with deep evolutionary significance. We further motivate our work by constructing an empirical method for interpreting the hyperbolicity of dataset embeddings. Throughout these assessments, we find persistent evidence highlighting the potential of our hyperbolic framework as a robust paradigm for genome representation learning."
    },
    {
        "title": "One Stone Three Birds:Three-Dimensional Implicit Neural Network for Compression and Continuous Representation of Multi-Altitude Climate Data",
        "link_suffix": "/forum?id=q6CM6UdP3K",
        "link": "https://openreview.net/forum?id=q6CM6UdP3K",
        "pdf_link": "https://openreview.net/pdf?id=q6CM6UdP3K",
        "keywords": "Multi-modal representation learning, continuous super-resolution, dimensionality reduction, cross-modal prediction, scientific data compression",
        "abstract": "Wind energy stands out as a promising clean and renewable energy alternative, not only for its potential to combat global warming but also for its capacity to meet the ever-growing demand for energy. However, analysis of wind data to fully harness the benefits of wind energy demands tackling several related challenges: \n(1) Current data resolution is inadequate for capturing the detailed information needed across diverse climatic conditions;\n(2) Efficient management and storage of real-time measurements are currently lacking;\n(3) Extrapolating wind data across spatial specifications enables analysis at costly-to-measure, unobserved points is necessary.\nIn response to these challenges, we introduce a modality-agnostic learning framework utilizing implicit neural networks. Our model effectively compresses a large volume of climate data into a manageable latent codec. It also learns underlying continuous climate patterns, enabling reconstruction at any scale and supporting modality transfer and fusion. Extensive experimental results show consistent performance improvements over existing baselines."
    },
    {
        "title": "Enhance Reasoning for Large Language Models with Reinforcement Learning in the Game Werewolf",
        "link_suffix": "/forum?id=mBrAuyd26J",
        "link": "https://openreview.net/forum?id=mBrAuyd26J",
        "pdf_link": "https://openreview.net/pdf?id=mBrAuyd26J",
        "keywords": "large language models, reinforcement learning, social deduction game",
        "abstract": "Despite their success across a broad spectrum of general tasks, Large Language Models (LLMs) often underperform in domain-specific tasks not well-represented in their pre-training corpora. We introduce an innovative framework integrating general-purpose LLMs with an external \\emph{Thinker} module to enhance the reasoning capabilities of LLM-based agents. Unlike augmenting LLMs with prompt engineering, our Thinker module directly accesses knowledge from domain databases and employs supervised or reinforcement learning (RL). We establish a reasoning hierarchy where LLMs handle intuitive System-1 tasks that are domain-agnostic, while the Thinker focuses on System-2 tasks that require complex logical analysis and domain-specific knowledge. Our framework is demonstrated through a 9-player Werewolf game that necessitates dual-system reasoning. We design a communication protocol between LLMs and the Thinker, then optimize the Thinker through online RL and refine it by imitation learning. Drawing from 18800 human games, this work also contributes to the largest dataset for social deduction games to date. Experiments show that GPT-3.5 and GPT-4, augmented with the Thinker, significantly improve in deductive reasoning, speech generation, and online gameplay evaluated by human players. Further, integrating a fine-tuned 6B Werewolf-specific LLM with the Thinker achieves performance on par with GPT-4."
    },
    {
        "title": "Double Check My Desired Return: Transformer with Value Validation for Offline RL",
        "link_suffix": "/forum?id=BxLK1M1f8T",
        "link": "https://openreview.net/forum?id=BxLK1M1f8T",
        "pdf_link": "https://openreview.net/pdf?id=BxLK1M1f8T",
        "keywords": "Offline Reinforcement Learning, Transformer",
        "abstract": "Recently, there has been increasing interest in applying Transformers to offline reinforcement learning (RL). Existing methods typically frame offline RL as a sequence modeling problem and learn actions via Supervised learning (RvS). However, RvS-trained Transformers struggle to align actual returns with desired target returns, especially when dealing with underrepresented returns in the dataset (interpolation) or missed higher returns that could be achieved by stitching sub-optimal trajectories (extrapolation). In this work, we propose a novel method that Double Checks the Transformer with value validation for Offline RL (Doctor). Doctor integrates the strengths of supervised learning (SL) and temporal difference (TD) learning by jointly optimizing the action prediction and value function. SL stabilizes the prediction of actions conditioned on target returns, while TD learning adds stitching capability to the Transformer. During inference, we introduce a double-check mechanism. We sample actions around desired target returns and validate them with value functions. This mechanism ensures better alignment between the predicted action and the desired target return and is beneficial for further online exploration and fine-tuning. We evaluate Doctor on the D4RL benchmark in both offline and offline-to-online settings, demonstrating that Doctor does much better in return alignment, either within the dataset or beyond the dataset. Furthermore, Doctor performs on par with or outperforms existing RvS-based and TD-based offline RL methods on the final performance."
    },
    {
        "title": "CASD: Enhancing Generation Accuracy via Context-Aware Speculative Decoding",
        "link_suffix": "/forum?id=g3D27bfmrf",
        "link": "https://openreview.net/forum?id=g3D27bfmrf",
        "pdf_link": "https://openreview.net/pdf?id=g3D27bfmrf",
        "keywords": "Language model, Natural language processing, Long context generation, Speculative decoding",
        "abstract": "With recent advancements in long-context model variants, Large language models (LLMs) can conveniently process different types of task-related information by simply converting them into an input sequence, even consisting of over 100K tokens. Though with a simple and unified form, there is still considerable room in leveraging input context effectively and efficiently. In this paper, we propose a simple yet effective CASD (Context-Aware Speculative Decoding) method to boost context usage. CASD is a decoding algorithm that requires no extra training or draft models. It improves not only generation performance but also inference efficiency. Experiments on 8 datasets (including question answering, summarization and code completion tasks in LongBench) show that CASD increases the average generation score by 3.3 points. CASD achieves a mean acceptance length of 3.10 and a speed-up ratio of 1.99. Moreover, CASD integrates effectively with context compression technology, addressing the issue of excessive memory overhead caused by long contexts. Since CASD directly retrieves token-level content from the input context to boost the generation accuracy, it can effectively mitigate the possible side-effects of context compression methods when crucial context information is dropped. Our anonymous code is available at \\href{https://anonymous.4open.science/r/CASD}{https://anonymous.4open.science/r/CASD}."
    },
    {
        "title": "Explainable Rewards in RLHF Using LLM-as-a-Judge",
        "link_suffix": "/forum?id=FaOeBrlPst",
        "link": "https://openreview.net/forum?id=FaOeBrlPst",
        "pdf_link": "https://openreview.net/pdf?id=FaOeBrlPst",
        "keywords": "Large Language Models; Reinforcement Learning from Human Feedback; Explainability",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been gaining popularity as a method for aligning Large Language Models (LLMs) with human preferences. It involves performing Supervised Fine-Tuning (SFT) followed by fine-tuning using a reward model trained on human preference data. However, two primary issues with this approach are the difficult and expensive curation of human preference data and the opaque, black-box nature of the rewards. To address these issues, this paper introduces a novel framework for aligning LLMs with human preferences. Our framework involves using representative sub-dimensions for specific tasks to generate rewards by leveraging a performant out-of-the-box LLM. We evaluate our approach by fine-tuning two models, one using our approach and one using traditional black-box rewards. Evaluation using an advanced LLM-based method demonstrates that our approach maintains the performance of the black-box baseline while offering superior explainability and flexibility. This framework not only enhances transparency in RLHF but also eliminates reliance on expensive human-curated preference data."
    },
    {
        "title": "Using Multimodal Deep Neural Networks to Disentangle Language from Visual Aesthetic Experience",
        "link_suffix": "/forum?id=p5RsCkE9sz",
        "link": "https://openreview.net/forum?id=p5RsCkE9sz",
        "pdf_link": "https://openreview.net/pdf?id=p5RsCkE9sz",
        "keywords": "multimodal deep neural networks, vision and language, affect and aesthetics",
        "abstract": "When we experience a visual stimulus as beautiful, how much of that experience derives from perceptual computations we cannot describe versus conceptual knowledge we can readily translate into natural language? Disentangling perception from language in affective experiences through behavioral paradigms or neuroimaging is often empirically intractable. Here, we circumnavigate this challenge by using linear decoding over the learned representations of unimodal vision, unimodal language, and multimodal (language-aligned) deep neural network (DNN) models to predict human beauty ratings of naturalistic images. We find that unimodal vision models (e.g. SimCLR) account for the vast majority of explainable variance in these ratings. Language-aligned vision models (e.g. SLIP) yield small gains relative to unimodal vision. Unimodal language models (e.g. GPT2) conditioned on visual embeddings to generate captions (via CLIPCap) yield no further gains. Pure-language model embeddings of machine-generated captions alone yield lower predictions. Taken together, these results suggest that whatever words we may eventually find to describe our experiences of beauty, the ineffable computations of feedforward perception likely remain the dominant basis of our judgment."
    },
    {
        "title": "Discovering Physics Laws of Dynamical Systems via Invariant Function Learning",
        "link_suffix": "/forum?id=TwMLUpPg8G",
        "link": "https://openreview.net/forum?id=TwMLUpPg8G",
        "pdf_link": "https://openreview.net/pdf?id=TwMLUpPg8G",
        "keywords": "dynamical system, ordinary differential equation, invariant learning",
        "abstract": "We consider learning underlying laws of dynamical systems governed by ordinary differential equations (ODE). A key challenge is how to discover intrinsic dynamics across multiple environments while circumventing environment-specific mechanisms. Unlike prior work, we tackle more complex environments where changes extend beyond function coefficients to entirely different function forms. For example, we demonstrate the discovery of ideal pendulum's natural motion $\\alpha \\sin{\\theta_t}$ by observing pendulum dynamics in different environments, such as the damped environment $\\alpha \\sin(\\theta_t) - \\rho \\omega_t$ and powered environment $\\alpha \\sin(\\theta_t) + \\rho \\frac{\\omega_t}{\\left|\\omega_t\\right|}$. Here, we formulate this problem as an $invariant\\ function\\ learning$ task and propose a new method, known as $\\mathbf{D}$isentanglement of $\\mathbf{I}$nvariant $\\mathbf{F}$unctions (DIF), that is grounded in causal analysis. We propose a causal graph and design an encoder-decoder hypernetwork that explicitly disentangles invariant functions from environment-specific dynamics. The discovery of invariant functions is guaranteed by our information-based principle that enforces the independence between extracted invariant functions and environments. Quantitative comparisons with meta-learning and invariant learning baselines on three ODE systems demonstrate the effectiveness and efficiency of our method. Furthermore, symbolic regression explanation results highlight the ability of our framework to uncover intrinsic laws."
    },
    {
        "title": "Identifying neural dynamics using interventional state space models",
        "link_suffix": "/forum?id=FwW3jqchtY",
        "link": "https://openreview.net/forum?id=FwW3jqchtY",
        "pdf_link": "https://openreview.net/pdf?id=FwW3jqchtY",
        "keywords": "Causal dynamical systems, interventions, state space models, photostimulation, micro-stimulation",
        "abstract": "Neural circuits produce signals that are complex and nonlinear. To facilitate the understanding of neural dynamics, a popular approach is to fit state space models (SSM) to data and analyze the dynamics of the low-dimensional latent variables. Despite the power of SSM in explaining neural circuit dynamics, it has been shown that these models merely capture statistical associations in the data and cannot be causally interpreted. Therefore, an important research problem is to build models that can predict neural dynamics under causal manipulations. Here, we propose interventional state space models (iSSM), a class of causal models that can predict neural responses to novel perturbations. We draw on recent advances in causal dynamical systems and present theoretical results for the identifiability of iSSM. In simulations of the motor cortex, we show that iSSM can recover the true latents and the underlying dynamics. In addition, we illustrate two applications of iSSM in biological datasets. First, we apply iSSM to a dataset of calcium recordings from ALM neurons in mice during photostimulation and uncover dynamical mechanisms underlying short-term memory. Second, we apply iSSM to a dataset of electrophysiological recordings from macaque dlPFC recordings during micro-stimulation and show that it successfully predicts responses to unseen perturbations."
    },
    {
        "title": "Discovering Factor Level Preferences to Improve Human-Model Alignment",
        "link_suffix": "/forum?id=CrGfGLC2Ad",
        "link": "https://openreview.net/forum?id=CrGfGLC2Ad",
        "pdf_link": "https://openreview.net/pdf?id=CrGfGLC2Ad",
        "keywords": "human alignment, Large Language Model, explainability, generation, evaluation",
        "abstract": "Despite advancements in Large Language Model (LLM) alignment, understanding the reasons behind LLM preferences remains crucial for bridging the gap between desired and actual behavior. LLMs often exhibit biases or tendencies that diverge from human preferences, such as favoring certain writing styles or producing overly verbose outputs. However, current methods for evaluating preference alignment often lack explainability, relying on coarse-grained comparisons. To address this, we introduce PROFILE (PRObing Factors of InfLuence for Explainability), a novel framework that uncovers and quantifies the influence of specific factors driving preferences. PROFILE's factor level analysis explains the \"why\" behind human-model alignment and misalignment, offering insights into the direction of model improvement. We apply PROFILE to analyze human and LLM preferences across three tasks: summarization, helpful response generation, and document-based question-answering.  Our factor level analysis reveals a substantial discrepancy between human and LLM preferences in generation tasks, whereas LLMs show strong alignment with human preferences in evaluation tasks. We demonstrate how leveraging factor level insights, including addressing misaligned factors or exploiting the generation-evaluation gap, can improve alignment with human preferences. This work underscores the importance of explainable preference analysis and highlights PROFILE's potential to provide valuable training signals, driving further improvements in human-LLM alignment."
    },
    {
        "title": "Deep Distributed Optimization for Large-Scale Quadratic Programming",
        "link_suffix": "/forum?id=hzuumhfYSO",
        "link": "https://openreview.net/forum?id=hzuumhfYSO",
        "pdf_link": "https://openreview.net/pdf?id=hzuumhfYSO",
        "keywords": "Deep Learning Aided Optimization, Distributed Optimization, Large-Scale Quadratic Programming",
        "abstract": "Distributed optimization is a powerful technique for large-scale decision-making, yet it is typically subject to rigorous tuning, computational/communication restrictions, and limited generalizability. On the other hand, black-box deep neural networks often lack interpretability and performance guarantees despite their widespread success in certain tasks. To leverage their complementary strengths, we introduce a deep learning-aided distributed optimization architecture for large-scale quadratic programming (QP). First, we combine the state-of-the-art OSQP method with a consensus approach to yield a distributed QP method, whose convergence guarantees are established. Then, we unfold this optimizer into a deep learning framework, named DeepDistributedQP, which relies on learning policies for the algorithm parameters towards accelerating its convergence to the optimal solution under a prescribed amount of iterations. Our approach is also theoretically grounded through Probably Approximately Correct (PAC)-Bayes theory, providing generalization bounds on the expected distance from optimality for unseen problems. DeepDistributedQP, as well as its non-distributed version, significantly outperform their standard optimization counterparts, on a variety of tasks ranging from randomly generated problems and optimal control to linear regression and transportation networks. The strong generalization capabilities of our approach are also demonstrated by evaluating the provided PAC-Bayes bounds which guarantee improved performance over traditional optimizers."
    },
    {
        "title": "VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers",
        "link_suffix": "/forum?id=0bcRCD7YUx",
        "link": "https://openreview.net/forum?id=0bcRCD7YUx",
        "pdf_link": "https://openreview.net/pdf?id=0bcRCD7YUx",
        "keywords": "Zero-shot Text to Speech Synthesis, Speech Generation, Voice Cloning, Language Modeling, In-Context Learning",
        "abstract": "This paper introduces VALL-E 2, the latest advancement in neural codec language models that marks a milestone in zero-shot text-to-speech synthesis (TTS), achieving human parity for the first time. Based on its predecessor, VALL-E, this work introduces two significant enhancements: Repetition Aware Sampling refines the original nucleus sampling process by accounting for token repetition in the decoding history. It not only stabilizes the decoding but also circumvents the infinite loop issue. Grouped Code Modeling organizes codec codes into groups to effectively shorten the sequence length, which not only boosts inference speed but also addresses the challenges of long sequence modeling. Our experiments on the LibriSpeech and VCTK datasets show that VALL-E 2 surpasses previous systems in speech robustness, naturalness, and speaker similarity. It is the first of its kind to reach human parity on these benchmarks. Moreover, VALL-E 2 consistently synthesizes high-quality speech, even for sentences that are traditionally challenging due to their complexity or repetitive phrases. The advantages of this work could contribute to valuable endeavors, such as generating speech for individuals with aphasia or people with amyotrophic lateral sclerosis.  Seehttps://anonymous/valle2for demos of VALL-E 2."
    },
    {
        "title": "HuWo：Building Physical Interaction World Models for Humanoid Robot Locomotion",
        "link_suffix": "/forum?id=bhUIoQ61pA",
        "link": "https://openreview.net/forum?id=bhUIoQ61pA",
        "pdf_link": "https://openreview.net/pdf?id=bhUIoQ61pA",
        "keywords": "Reinforcement Learning, Humanoid Locomotion, World Mode, Sim-to-Real Transfer",
        "abstract": "Reinforcement Learning control has been proved to be an effective approach for quadruped robot locomotion. However, locomotion tasks for humanoid robots are challenging, especially in complex environments. The main reason is that humanoid robots must maintain balance during movement and constantly engage in complex dynamic interactions with the environment. Understanding robot-environment interaction dynamics is key to achieving stable locomotion for humanoid robots. Since there is privileged information that the robot cannot directly access, to expand the observable space, previous reinforcement learning-based methods either reconstruct environmental information from partial observations or reconstruct robotic dynamics information from partial observations, but they fall short of fully capturing the dynamics of robot-environment interactions. In this work, we propose an end-to-end reinforcement learning control framework based on physical interaction$\\textbf{Wo}$rld Model for $\\textbf{Hu}$manoid Robots (HuWo). Our key innovation is to introduce a physical interaction world model to understand the interaction between the robot and environment, employing the hidden layers of transformer-XL for implicit modeling of this process across temporal sequences. The proposed framework can showcase robust and flexible locomotion ability in complex environments such as slopes, stairs, and discontinuous surfaces. We validated the robustness of this method using the $Zerith1$ robot, both in simulations and real-world deployments, and quantitatively compared our HuWo against the baselines with better traversability and command-tracking."
    },
    {
        "title": "Feature-guided score diffusion for sampling conditional densities",
        "link_suffix": "/forum?id=kwY3eL3QVh",
        "link": "https://openreview.net/forum?id=kwY3eL3QVh",
        "pdf_link": "https://openreview.net/pdf?id=kwY3eL3QVh",
        "keywords": "Conditional sampling, Representation learning, Score diffusion",
        "abstract": "Score diffusion methods can learn probability densities from samples. The score of the noise-corrupted density is estimated using a deep neural network, which is then used to  iteratively transport a Gaussian white noise density to a target density. Variants for conditional densities have been developed, but correct estimation of the corresponding scores is difficult.\nWe avoid these difficulties by introducing an algorithm that operate by projecting the score onto the target class mean in a learned feature space.\nThe features and the projected score are computed using the same network, which is trained by optimizing a single denoising loss. \nLearned feature vectors of same-class images are tightly clustered relative to those of different classes. \nWe show that feature class centroids provide a low-dimensional Euclidean embedding of the class conditional densities. \nWe demonstrate that, when trained on a dataset of mixed image classes,\nthis projected score can generate high quality and diverse samples from the conditioning class.\nConditional generation can be performed using feature vectors interpolated between those of the training set, demonstrating out-of-distribution generalization."
    },
    {
        "title": "Vision-Based Grasping through Goal-Conditioned Masking",
        "link_suffix": "/forum?id=sXF5P4N7e8",
        "link": "https://openreview.net/forum?id=sXF5P4N7e8",
        "pdf_link": "https://openreview.net/pdf?id=sXF5P4N7e8",
        "keywords": "Goal-Conditioned Reinforcement Learning, Robotic Reaching and Grasping, Masking-Based Goal Representation, Visual Goal Recognition, Out-of-Distribution Object Generalization",
        "abstract": "Goal-Conditioned Reinforcement Learning for robotic reaching and grasping has enabled agents to achieve diverse objectives with a unified policy, leveraging goal conditioning such as images, vectors, and text. The existing methods, however, carry inherent limitations; for example, vector-based one-hot encodings allow only a predetermined object set. Meanwhile, goal state images in image-based goal conditioning can be hard to obtain in the real world and may limit generalization to novel objects. This paper introduces a mask-based goal conditioning method that offers object-agnostic visual cues to promote efficient feature sharing and robust generalization. The agent receives text-based goal directives and utilizes a pre-trained object detection model to generate a mask for goal conditioning and facilitate generalization to out-of-distribution objects. In addition, we show that the mask can enhance sample efficiency by augmenting sparse rewards without needing privileged information of the target location, unlike distance-based reward shaping. The effectiveness of the proposed framework is demonstrated in a simulated reach-and-grasp task. The mask-based goal conditioning consistently maintains a $\\sim$90% success rate in grasping both in and out-of-distribution objects. Furthermore, the results show that the mask-augmented reward facilitates a learning speed and grasping success rate on par with distance-based reward."
    },
    {
        "title": "Dynamic Loss-Based Sample Reweighting for Improved Large Language Model Pretraining",
        "link_suffix": "/forum?id=gU4ZgQNsOC",
        "link": "https://openreview.net/forum?id=gU4ZgQNsOC",
        "pdf_link": "https://openreview.net/pdf?id=gU4ZgQNsOC",
        "keywords": "sample reweighing, large language models, pretraining",
        "abstract": "Pretraining large language models (LLMs) on vast and heterogeneous datasets is crucial for achieving state-of-the-art performance across diverse downstream tasks. However, current training paradigms treat all samples equally, overlooking the importance or relevance of individual samples throughout the training process. Existing reweighting strategies, which primarily focus on group-level data importance, fail to leverage fined-grained instance-level information and do not adapt dynamically to individual sample importance as training progresses. In this paper, we introduce novel algorithms for dynamic, instance-level data reweighting aimed at improving both the efficiency and effectiveness of LLM pretraining. Our methods adjust the weight of each training sample based on its loss value in an online fashion, allowing the model to dynamically focus on more informative or important samples at the current training stage. In particular, our framework allows to systematically devise reweighting strategies that deprioritize redundant or uninformative data, which we find tend to work best. \nFurthermore, we develop a new theoretical framework for analyzing the impact of loss-based reweighting on the convergence of gradient-based methods, providing the first formal characterization of how these strategies affect convergence bounds. We empirically validate our approach across a spectrum of tasks, from large-scale LLM pretraining to smaller-scale linear regression problems, demonstrating that loss-based reweighting can lead to faster convergence and improved performance."
    },
    {
        "title": "Curriculum GNN-LLM Alignment for Text-Attributed Graphs",
        "link_suffix": "/forum?id=tmwR707odU",
        "link": "https://openreview.net/forum?id=tmwR707odU",
        "pdf_link": "https://openreview.net/pdf?id=tmwR707odU",
        "keywords": "Graph neural networks, Large language models, Text-attributed graphs, Curriculum learning",
        "abstract": "Aligning Graph Neural Networks (GNNs) and Large Language Models (LLMs) benefits in leveraging both textual and structural knowledge for Text-attributed Graphs (TAGs) learning, which has attracted an increasing amount of attention in the research community. Most existing literature assumes a uniformly identical level of learning difficulties across texts and structures in TAGs, however, we discover the $\\textit{text-structure imbalance}$ problem in real-world TAGs, $\\textit{i.e.}$, nodes exhibit various levels of difficulties when learning different textual and structural information. Existing works ignoring these different difficulties may result in under-optimized GNNs and LLMs with over-reliance on either simplistic text or structure, thus failing to conduct node classifications that involve simultaneously learning complex text and structural information for nodes in TAGs. To address this problem, we propose a novel Curriculum GNN-LLM Alignment ($\\textbf{CurGL}$) method, which strategically balances the learning difficulties of textual and structural information on a node-by-node basis to enhance the alignment between GNNs and LLMs. Specifically, we first propose a text-structure difficulty measurer to estimate the learning difficulty of both text and structure in a node-wise manner. Then, we propose a class-based node selection strategy to balance the training process via gradually scheduling more nodes. Finally, we propose the curriculum co-play alignment by iteratively promoting useful information from GNNs and LLMs, to progressively enhance both components with balanced textual and structural information. Extensive experiments on real-world datasets demonstrate that our proposed $\\textbf{CurGL}$ method is able to outperform state-of-the-art GraphLLM, curriculum learning, as well as GNN baselines. To the best of our knowledge, this is the first study of curriculum alignment on TAGs."
    },
    {
        "title": "MQuAKE-Remastered: Multi-Hop Knowledge Editing Can Only Be Advanced with Reliable Evaluations",
        "link_suffix": "/forum?id=m9wG6ai2Xk",
        "link": "https://openreview.net/forum?id=m9wG6ai2Xk",
        "pdf_link": "https://openreview.net/pdf?id=m9wG6ai2Xk",
        "keywords": "knowledge edit, model edit, multi-hop, question answering, natural language processing, dataset audit",
        "abstract": "Large language models (LLMs) can give out erroneous answers to factually rooted questions either as a result of undesired training outcomes or simply because the world has moved on after a certain knowledge cutoff date. Under such scenarios, knowledge editing often comes to the rescue by delivering efficient patches for such erroneous answers without significantly altering the rests, where many editing methods have seen reasonable success when the editing targets are simple and direct (e.g., \"what club does Lionel Messi currently play for?\").However, knowledge fragments like this are often deeply intertwined in the real world, making effectively propagating the editing effect to non-directly related questions a practical challenge (e.g., \"who is the offspring of the owner of the club that Messi currently plays for?\"). Prior arts have coined this task as multi-hop knowledge editing with the most popular dataset being MQuAKE, serving as the sole evaluation benchmark for many later proposed editing methods due to the expensive nature of making knowledge editing datasets at scale.In this work, we reveal thatup to 33% or 76% of MQuAKE's questions and ground truth labels are, in fact, corrupted in various fashions due to some unintentional clerical or procedural oversights.Our work provides a detailed audit of MQuAKE's error pattern and a comprehensive fix without sacrificing its dataset capacity. Additionally, we benchmarked almost all proposed \\mquake{}-evaluated editing methods on our post-fix dataset, \\mquaker{}. It is our observation that many methods try to overfit the original \\mquake{} by exploiting some data-specific properties of \\mquake{}. We provide a guideline on how to faithfully approach such datasets and show that a simple, minimally invasive approach can bring excellent editing performance without such exploitation. Please refer to the supplemental material for assets."
    },
    {
        "title": "S2-Attention: Hardware-Aware Context Sharding Among Attention Heads",
        "link_suffix": "/forum?id=OqTVwjLlRI",
        "link": "https://openreview.net/forum?id=OqTVwjLlRI",
        "pdf_link": "https://openreview.net/pdf?id=OqTVwjLlRI",
        "keywords": "efficient transformer, kernel, sparse attention, long context, efficiency, infrastructure, pre-training, inference, sparsity, software library",
        "abstract": "Sparse attention, which selectively attends to a subset of tokens in the context, has been an established approach to enhance the efficiency of Transformers. \nHowever, its theoretical reduction in FLOPs has rarely translated into wall-clock speed-up over its dense attention counterparts, mainly due to the lack of hardware-level optimizations like FlashAttention.\nMeanwhile, it remains unclear wheter sparse attention can maintain the model's quality at a scale of today's large language models (LLMs), and how this can be achieved.\n%how to guarantee model quality with sparse attention, given the decoder-only architecture and model scale of modern LLMs.This paper presents Sparsely-Sharded(S2) Attention, a Triton library that provides kernel optimization for sparse attention customizable at both per-head and per-context-range levels.\nS2-Attention enables the exploration of novel and high-performance sparse attention techniques, which we demonstrate through extensive ablations across a wide range of sparse attention deisngs at various model scales. \n% design heuristics across model scale. \nFrom these insights, we present several basic guidelines to design sparse attention that can achieve not only practical efficiency improvements, but also strong performance on downstream tasks.\n% heterogeneous context sharding, union completeness, and inevitable density as principles to improve LLM training and inference efficiency without compromising model quality.\nTo achieve high parallelization and optimized memory IO, sparse attention should \\textbf{shard the context heterogeneously across attention heads}, where each head attends to a different subset of tokens while \\textbf{collectively covering the full context}. Meanwhile, we find hybrid architectures combining sparse and dense attention particularly beneficial in practice.\nThese design choices lead to a novel sparse attention architecture,\nwhich we evaluate with 1.3B, 7B models.\nIt achieves wall-clock speedup of 8.79X, 15.87X, 25.3X compared to the strong FlashAttention-2 baseline with strong downstream performance on-par with full attention and perfect retrieval performance at a 128k context length. \n% on-par downstream performance and perfect 128k needle retrieval.\n% In 1.3B, 7B, 70B Llama architecture models, S2-Attention following the principles delivers a speedup of 7X, 12X, 22X wall-clock speed-up compared to FlashAttention-2, while achieving on-par downstream performance and perfect 128k needle retrieval.\nIn inference, for 7B models, our model, with the help of our S2-Attention kernel, achieves 4.5x speed-up compared to dense counterparts. \nS2-Attention will be released with easy-to-customize APIs for direct usage in Megatron and vLLM. \nWe hope they will help future research develop sparse attention algorithms to improve the efficiency of large language models."
    },
    {
        "title": "Modeling Spatiotemporal Heterogeneity in Earth Science Machine Learning: An End-to-End Approach",
        "link_suffix": "/forum?id=eyJcXtZ9xv",
        "link": "https://openreview.net/forum?id=eyJcXtZ9xv",
        "pdf_link": "https://openreview.net/pdf?id=eyJcXtZ9xv",
        "keywords": "AI4Science, Remote Sensing, Tabular Machine Learning, Spatiotemporal Prediction, Spatiotemporal Heterogeneity",
        "abstract": "In Earth sciences, unobserved factors often lead to spatially nonstationary distributions, causing relationships between features and targets to vary across locations. Traditional tabular machine learning methods struggle to effectively model this spatial heterogeneity. While approaches like Geographically Weighted Regression (GWR) capture local variations, they often miss global patterns, overfit local noise, and lack the ability to model temporal changes in spatial heterogeneity. Our research aims to model spatiotemporal heterogeneity. To achieve this, we propose an end-to-end approach that fits the entire dataset to capture global patterns, while designing the model as a conditional generative framework to learn sparse spatial heterogeneity, mitigating overfitting through localized condition sharing. Our method involves four key steps: constructing a spatiotemporal graph, encoding tabular features, aggregating spatial heterogeneity node embeddings via graph convolutions, and decoding with spatial condition vectors for location-specific predictions. We validate our approach by predicting vegetation gross primary productivity (GPP) using global climate and land cover data (2001–2020). Trained on 50M samples and tested on 2.8M, our model achieves an RMSE of 0.836, outperforming GWR (2.149), LightGBM (1.063) and TabNet (0.944). Visual analysis of the learned node embeddings reveals clear spatial heterogeneity patterns and their temporal dynamics."
    },
    {
        "title": "Frame-Voyager: Learning to Query Frames for Video Large Language Models",
        "link_suffix": "/forum?id=LNL7zKvm7e",
        "link": "https://openreview.net/forum?id=LNL7zKvm7e",
        "pdf_link": "https://openreview.net/pdf?id=LNL7zKvm7e",
        "keywords": "Video-LLM, Adaptive Frame Sampling",
        "abstract": "Video Large Language Models (Video-LLMs) have made remarkable progress in video understanding tasks. However, they are constrained by the maximum length of input tokens, making it impractical to input entire videos. Existing frame selection approaches, such as uniform frame sampling and text-frame retrieval, fail to account for the information density variations in the videos or the complex instructions in the tasks, leading to sub-optimal performance. In this paper, we propose Frame-Voyager that learns to query informative frame combinations, based on the given textual queries in the task. To train Frame-Voyager, we introduce a new data collection and labeling pipeline, by ranking frame combinations using a pre-trained Video-LLM. Given a video of M frames, we traverse its T-frame combinations, feed them into a Video-LLM, and rank them based on Video-LLM's prediction losses. Using this ranking as supervision, we train Frame-Voyager to query the frame combinations with lower losses. In experiments, we evaluate Frame-Voyager on four Video Question Answering benchmarks by plugging it into two different Video-LLMs. The experimental results demonstrate that Frame-Voyager achieves impressive results in all settings, highlighting its potential as a plug-and-play solution for Video-LLMs."
    },
    {
        "title": "PN-GAIL: Leveraging Non-optimal Information from Imperfect Demonstrations",
        "link_suffix": "/forum?id=0e2pcSxQJS",
        "link": "https://openreview.net/forum?id=0e2pcSxQJS",
        "pdf_link": "https://openreview.net/pdf?id=0e2pcSxQJS",
        "keywords": "Generative adversarial imitation learning, imperfect demonstrations, reinforcement learning",
        "abstract": "Imitation learning aims at constructing an optimal policy by emulating expert demonstrations. However, the prevailing approaches in this domain typically presume that the demonstrations are optimal, an assumption that seldom holds true in the complexities of real-world applications. The data collected in practical scenarios often contains imperfections, encompassing both optimal and non-optimal examples. In this study, we propose Positive-Negative Generative Adversarial Imitation Learning (PN-GAIL), a novel approach that falls within the framework of Generative Adversarial Imitation Learning (GAIL). PN-GAIL innovatively leverages non-optimal information from imperfect demonstrations, allowing the discriminator to comprehensively assess the positive and negative risks associated with these demonstrations. Furthermore, it requires only a small subset of labeled confidence scores. Theoretical analysis indicates that PN-GAIL deviates from the non-optimal data while mimicking imperfect demonstrations. Experimental results demonstrate that PN-GAIL surpasses conventional baseline methods in dealing with imperfect demonstrations, thereby significantly augmenting the practical utility of imitation learning in real-world contexts. Our codes are available athttps://anonymous.4open.science/r/PN-GAIL-3828."
    },
    {
        "title": "Attributing Culture-Conditioned Generations to Pretraining Corpora",
        "link_suffix": "/forum?id=XrsOu4KgDE",
        "link": "https://openreview.net/forum?id=XrsOu4KgDE",
        "pdf_link": "https://openreview.net/pdf?id=XrsOu4KgDE",
        "keywords": "culture bias, pretraining data, memorization, generalization",
        "abstract": "In open-ended generative tasks such as narrative writing or dialog interaction, large language models are known to manifest culture biases, showing inadequate knowledge and producing templated generations on less prevalent cultures. Previous works suggest that such biased generations are due to the uneven representation of each culture in pretraining corpora of the language models. In this\nwork, we study how pretraining data lead to biased culture-conditioned generations via the lens of LLM memorization and generalization, in order to provide more insights on improving the pretraining data and the pretraining procedure of LLMs. We introduce the MEMOed framework (MEMOrization from pretraining document) which determines whether a generation for a culture is due to memorization or generalization. On culture-conditioned generations about food and clothing entities for 110 cultures, we find that for a culture with high frequency in pretraining data, the model can recall more memorized knowledge about the culture; for cultures appearing least frequently, none of their generations contain any entities memorized from pretraining. In addition, we discover that the model prefers generating about entities with extraordinarily high frequency regardless of the conditioned-culture, an indication of overmemorization, where the model demonstrates biases towards frequent terms in pretraining data regardless of its correctness. Our findings show that current LLM generations majorly consist of memorization and un-founded overmemorization. We hope that the MEMOed framework and our insights will inspire more works on attributing model performance on pretraining data."
    },
    {
        "title": "Compositional World Models with Interpretable Abstractions",
        "link_suffix": "/forum?id=EHmjRIA4l2",
        "link": "https://openreview.net/forum?id=EHmjRIA4l2",
        "pdf_link": "https://openreview.net/pdf?id=EHmjRIA4l2",
        "keywords": "State-Action Abstractions, Predictive Coding, Hierarchical Planning, Compositional World Models, Contrastive Learning, Hypernetworks, Hierarchical Reinforcement Learning",
        "abstract": "We present a modular and compositional approach to learning human-aligned world models via state-action hierarchies. Our approach is inspired by sensory-motor hierarchies in the mammalian brain. We model complex state transition dynamics as a sequence of simpler dynamics, which in turn can be modeled using even simpler dynamics, and so on, endowing the approach with rich compositionality. We introduce Composer, a practical method for learning complex world models that leverages hypernetworks and abstract states for generating lower-level transition functions on-the-fly. We first show that state abstractions in Composer emerge naturally in simple environments as a consequence of training. Incorporating a variant of contrastive learning allows Composer to scale to more complex environments while ensuring that the learned abstractions are human aligned. Additionally, learning a higher-level transition function between learned abstract states leads to a hierarchy of transition functions for modeling complex dynamics. We apply Composer to compositional navigation problems and show its capability for rapid planning and transfer to novel scenarios. In both traditional grid-world navigation problems as well as in the more complex Habitat vision-based navigation domain, a Composer-based agent learns to model the state-action dynamics within and between different rooms using a hierarchy of transition functions and leverage this hierarchy for efficient downstream planning. Our results suggest that Composer offers a promising framework for learning the complex dynamics of real-world environments using a compositional and interpretable approach."
    },
    {
        "title": "Rethinking Language-Alignment in Human Visual Cortex with Syntax Manipulation and Word Models",
        "link_suffix": "/forum?id=veyPSmKrX4",
        "link": "https://openreview.net/forum?id=veyPSmKrX4",
        "pdf_link": "https://openreview.net/pdf?id=veyPSmKrX4",
        "keywords": "multimodality, language models, vision models, visuosemantics, visual neuroscience",
        "abstract": "Recent success predicting human ventral visual system responses to images from large language model (LLM) representations of image captions has sparked renewed interest in the possibility that high-level visual representations are aligned to language. Here, we further explore this possibility using image-caption pairs from the Natural Scenes fMRI Dataset, examining how well language-only representations of image captions predict image-evoked human visual cortical responses, compared to predictions based on vision model responses to the images themselves. As in recent work, we find that unimodal language models predict brain responses in human visual cortex as well as unimodal vision models. However, we find that the predictive power of large language models rests almost entirely on their ability to capture information about the nouns present in image descriptions, with little to no role for syntactic structure or semantic compositionality in predicting neural responses to static natural scenes. We propose that the convergence between language-model and vision-model representations and those of high-level visual cortex arises not from direct interaction between vision and language, but instead from common reference to real-world entities, and the prediction of brain data whose principal variance is defined by common objects in common, non-compositional contexts."
    }
]
[{"title": "HomieBot: an Adaptive System for Embodied Mobile Manipulation in Open Environments", "link_suffix": "/forum?id=NQTrARs2pz", "link": "https://openreview.net/forum?id=NQTrARs2pz", "pdf_link": "https://openreview.net/pdf?id=NQTrARs2pz", "keywords": "Embodied Agent, Embodied AI Benchmark, Mobile Manipulation", "abstract": "Embodied Mobile Manipulation in Open Environments (EMMOE) is the challenge that agents understanding and executing long-horizon everyday tasks in home environments. This challenge encompasses task planning, decision-making, navigation and manipulation, and is crucial to develop a powerful home assistant capable of automatically completing daily tasks. However, the absence of a holistic benchmark, data incompatibility between large language models (LLMs) and mobile manipulation tasks, the lack of a comprehensive framework, and insufficient dynamic adaptation mechanisms all continue to hinder its development. To address these issues, we propose EMMOE, the first unified benchmark that evaluates high-level planners and low-level policies simultaneously. Additionally, We manually collect EMMOE-100, the first everyday task dataset featuring detailed decision-making processes, Chain-of-Thought (CoT) outputs, feedback from low-level execution and a trainable data format for Large Multimodal Models (LMMs). Furthermore, we design HomieBot, a sophisticated agent system which integrates LMM with Direct Preference Optimization (DPO) as the high-level planner, small navigation and manipulation models as the low-level executor. HomieBot can get a 31.8% success rate in training tasks and 20% in test tasks.", "title_embedding_index": 9500, "title_abs_embedding_index": 9525}, {"title": "Scalable Gaussian Process via Hilbert-Schmidt Singular Value Decomposition", "link_suffix": "/forum?id=xUHL8mtSUL", "link": "https://openreview.net/forum?id=xUHL8mtSUL", "pdf_link": "https://openreview.net/pdf?id=xUHL8mtSUL", "keywords": "Scalability, Gaussian process regression, Hilbert Schmidt singular value decomposition, compact Mat\\'ern", "abstract": "Gaussian process regression is widely used for its flexible mean predictions and inherent uncertainty quantification. However, its scalability is limited by cubic time complexity, $O(n^3)$, and quadratic space complexity, $O(n^2)$, making it infeasible for large-scale datasets. Although recent advances have introduced approximate methods with time complexity $O(nm^2)$, where $m\\ll n$ is a tuning parameter, these methods each have their own bottlenecks, such as requiring a relatively large $m$ or involving expensive preprocessing steps. Moreover, for extremely large datasets with millions of samples, the space complexity $O(n^2)$ becomes another significant bottleneck. In this paper, we present a novel method based on the Hilbert-Schmidt singular value decomposition that obtains a low-rank decomposition ``for free\", reducing both time complexity to $O(nm^2)$ and space complexity to $O(nm)$, with no preprocessing overhead. We used simulated large-scale datasets to demonstrate the performance of our method compared to state-of-the-art approaches.", "title_embedding_index": 9501, "title_abs_embedding_index": 9526}, {"title": "Mobility Networked Time-Series Forecasting Benchmark Datasets", "link_suffix": "/forum?id=HV67MnnXkL", "link": "https://openreview.net/forum?id=HV67MnnXkL", "pdf_link": "https://openreview.net/pdf?id=HV67MnnXkL", "keywords": "mobility, networked time series, time series, origin-destination, forecasting, prediction, transportation, epidemic", "abstract": "Human mobility is crucial for urban planning (e.g., public transportation) and epidemic response strategies. However, existing research often neglects integrating comprehensive perspectives on spatial dynamics, temporal trends, and other contextual views due to the limitations of existing mobility datasets. To bridge this gap, we introduceMOBINS(MOBIlityNetworked timeSeries), a novel dataset collection designed for networked time-series forecasting of dynamic human movements.MOBINSfeatures diverse and explainable datasets that capture various mobility patterns across different transportation modes in four cities and two countries and cover both transportation and epidemic domains at the administrative area level. Our experiments with nine baseline methods reveal the significant impact of different model backbones on the proposed six datasets. We provide a valuable resource for advancing urban mobility research, and our dataset collection is available athttps://anonymous.4open.science/r/MOBINS.", "title_embedding_index": 9502, "title_abs_embedding_index": 9527}, {"title": "MoLEx: Mixture of Layer Experts for Fine-tuning with Sparse Upcycling", "link_suffix": "/forum?id=rWui9vLhOc", "link": "https://openreview.net/forum?id=rWui9vLhOc", "pdf_link": "https://openreview.net/pdf?id=rWui9vLhOc", "keywords": "Parameter efficient fine-tuning, mixture of experts, sparse upcycling", "abstract": "Large-scale pre-training of deep models, followed by fine-tuning them to adapt to downstream tasks, has become the cornerstone of natural language processing (NLP). The prevalence of vast corpses of data coupled with computational resources has led to large models with a considerable number of parameters. While the massive size of these models has led to remarkable success in many NLP tasks, a detriment is the expense required to retrain all the base model's parameters for the adaptation to each task or domain. Parameter Efficient Fine-Tuning (PEFT) provides a highly effective solution for this challenge by minimizing the number of parameters required to be trained in adjusting to the new task while maintaining the quality of the model. While existing methods have achieved impressive results, they mainly focus on adapting a subset of parameters using adapters, weight reparameterization, and prompt engineering. In this paper, we study layers as extractors of different types of linguistic information that are valuable when used in conjunction with each other. We then propose the Mixture of Layer Experts (MoLEx), a novel Sparse Mixture of Experts (SMoE) whose experts are layers in the pre-trained model. In particular, MoLEx is applied at each layer of the pre-trained model. It performs a conditional computation of a mixture of layers during fine-tuning to provide the model with more structural knowledge about the data. By providing an avenue for information exchange between layers, MoLEx enables the model to make a more well-informed prediction for the downstream task, leading to better fine-tuning results with the same number of effective parameters. As experts can be processed in parallel, MoLEx introduces minimal additional computational overhead. We empirically corroborate the advantages of MoLEx when combined with popular PEFT baseline methods on a variety of downstream fine-tuning tasks, including the popular GLUE benchmark for natural language understanding (NLU) as well as the natural language generation (NLG) End-to-End Challenge (E2E).", "title_embedding_index": 9503, "title_abs_embedding_index": 9528}, {"title": "Regression Conformal Prediction under Bias", "link_suffix": "/forum?id=v8RDgaEtE2", "link": "https://openreview.net/forum?id=v8RDgaEtE2", "pdf_link": "https://openreview.net/pdf?id=v8RDgaEtE2", "keywords": "Conformal Prediction, Bias, Uncertainty Quantification", "abstract": "Uncertainty quantification is crucial to account for the imperfect predictions of machine learning algorithms for high-impact applications. Conformal prediction (CP) is a powerful framework for uncertainty quantification that generates calibrated prediction intervals with valid coverage. \nIn this work, we study how CP intervals are affected by \\emph{bias} -- the systematic deviation of a prediction from ground truth values -- a phenomenon prevalent in many real-world applications.\nWe investigate the influence of bias on interval lengths of two different types of adjustments -- symmetric adjustments, the conventional method where both sides of the interval are adjusted equally, and asymmetric adjustments, a more flexible method where the interval can be adjusted unequally in positive or negative directions.\nWe present theoretical and empirical analyses characterizing how symmetric and asymmetric adjustments impact the \"tightness\" of CP intervals for regression tasks. \nSpecifically for absolute residual and quantile-based non-conformity scores, we prove: 1) the upper bound of symmetrically adjusted interval lengths increases by $2|b|$ where $b$ is a globally applied scalar value representing bias, 2) asymmetrically adjusted interval lengths are not affected by bias, and 3) conditions when asymmetrically adjusted interval lengths are guaranteed to be smaller than symmetric ones.\nOur analyses suggest that even if predictions exhibit significant drift from ground truth values, asymmetrically adjusted intervals are still able to maintain the same tightness and validity of intervals as if the drift had never happened, while symmetric ones significantly inflate the lengths. \nWe demonstrate our theoretical results with two real-world prediction tasks: sparse-view computed tomography (CT) reconstruction and time-series weather forecasting. Our work paves the way for more bias-robust machine learning systems.", "title_embedding_index": 9504, "title_abs_embedding_index": 9529}, {"title": "Characteristic Function-Based Regularization for Probability Function Informed Neural Networks", "link_suffix": "/forum?id=BSGQHpGI1Q", "link": "https://openreview.net/forum?id=BSGQHpGI1Q", "pdf_link": "https://openreview.net/pdf?id=BSGQHpGI1Q", "keywords": "Regularisation, Supervised Learning, Neural Network Architecture Paradigms", "abstract": "Regularization is essential in neural network training to prevent overfitting and improve generalization. In this paper, we propose a novel regularization technique that leverages decomposable distribution and central limit theory assumptions by exploiting the properties of characteristic functions. We first define Probability Function Informed Neural Networks as a class of universal function approximators capable of embedding the knowledge of some probabilistic rules constructed over a given dataset into the learning process (a similar concept to Physics-informed neural networks (PINNs), if the reader is familiar with those). We then enforce a regularization framework over this network, aiming to impose structural constraints on the network\u2019s weights to promote greater generalizability in the given probabilistic setting. Rather than replacing traditional regularization methods such as L2 or dropout, our approach is intended to supplement this and other similar classes of neural network architectures by providing instead a contextual delta of generalization. We demonstrate that integrating this method into such architectures helps improve performance on benchmark supervised classification datasets, by preserving essential distributional properties to mitigate the risk of overfitting. This characteristic function-based regularization offers a new perspective for enhancing distribution-aware learning in machine learning models.", "title_embedding_index": 9505, "title_abs_embedding_index": 9530}, {"title": "Faster Diffusion Sampling with Randomized Midpoints: Sequential and Parallel", "link_suffix": "/forum?id=MT3aOfXIbY", "link": "https://openreview.net/forum?id=MT3aOfXIbY", "pdf_link": "https://openreview.net/pdf?id=MT3aOfXIbY", "keywords": "Diffusion Sampling, Generative Model, Statistical Theory", "abstract": "Sampling algorithms play an important role in controlling the quality and runtime of diffusion model inference. In recent years, a number of works (Chen et al., 2023c;b; Benton et al., 2023; Lee et al., 2022) have analyzed algorithms for diffusion sampling with provable guarantees; these works show that for essentially any data distribution, one can approximately sample in polynomial time given a sufficiently accurate estimate of its score functions at different noise levels.In this work, we propose a new scheme inspired by Shen and Lee's randomized midpoint method for log-concave sampling  (Shen & Lee, 2019). We prove that this approach achieves the best known dimension dependence for sampling from arbitrary smooth distributions in total variation distance ($\\widetilde O(d^{5/12})$ compared to $\\widetilde O(\\sqrt{d})$ from prior work). We also show that our algorithm can be parallelized to run in only $\\widetilde O(\\log^2 d)$ parallel rounds, constituting the first provable guarantees for parallel sampling with diffusion models.As a byproduct of our methods, for the well-studied problem of log-concave sampling in total variation distance, we give an algorithm and simple analysis achieving dimension dependence $\\widetilde O(d^{5/12})$ compared to $\\widetilde O(\\sqrt{d})$ from prior work.", "title_embedding_index": 9506, "title_abs_embedding_index": 9531}, {"title": "X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale", "link_suffix": "/forum?id=csbf1p8xUq", "link": "https://openreview.net/forum?id=csbf1p8xUq", "pdf_link": "https://openreview.net/pdf?id=csbf1p8xUq", "keywords": "Large Language Model, Machine Translation, Multilingual", "abstract": "Large language models (LLMs) have achieved remarkable success across various NLP tasks, yet their focus has predominantly been on English due to English-centric pre-training and limited multilingual data. While some multilingual LLMs claim to support for hundreds of languages, models often fail to provide high-quality response for mid- and low-resource languages, leading to imbalanced performance heavily skewed in favor of high-resource languages like English and Chinese. In this paper, we prioritize quality over scaling number of languages, with a focus on multilingual machine translation task, and introduceX-ALMA, a model designed with a commitment to ensuring top-tier performance across 50 diverse languages, regardless of their resource levels. X-ALMA surpasses state-of-the-art open-source multilingual LLMs, such as Aya-101 and Aya-23, in every single translation direction on the FLORES and WMT'23 test datasets according to COMET-22. This is achieved by plug-and-play language-specific module architecture to prevent language conflicts during training and a carefully designed training regimen with novel optimization methods to maximize the translation performance. At the final stage of training regimen, our proposed Adaptive Rejection Preference Optimization (ARPO) surpasses existing preference optimization methods in translation tasks.", "title_embedding_index": 9507, "title_abs_embedding_index": 9532}, {"title": "Beyond Finite Data: Towards Data-free Out-of-distribution Generalization via Extrapolation", "link_suffix": "/forum?id=ZbOSRZ0JXH", "link": "https://openreview.net/forum?id=ZbOSRZ0JXH", "pdf_link": "https://openreview.net/pdf?id=ZbOSRZ0JXH", "keywords": "domain generalization, out-of-distribution generalization, large language model", "abstract": "Out-of-distribution (OOD) generalization is a favorable yet challenging property for deep neural networks. The core challenges lie in the limited availability of source domains that help models learn an invariant representation from the spurious features. Various domain augmentation have been proposed but largely rely on interpolating existing domains and frequently face difficulties in creating truly \"novel\" domains. Humans, on the other hand, can easily extrapolate novel domains, thus, an intriguing question arises: How can neural networks extrapolate like humans and achieve OOD generalization?\nWe introduce a novel approach to domain extrapolation that leverages reasoning ability and the extensive knowledge encapsulated within large language models (LLMs) to synthesize entirely new domains. Starting with the class of interest, we query the LLMs to extract relevant knowledge for these novel domains. We then bridge the gap between the text-centric knowledge derived from LLMs and the pixel input space of the model using text-to-image generation techniques. By augmenting the training set of domain generalization datasets with high-fidelity, photo-realistic images of these new domains, we achieve significant improvements over all existing methods, as demonstrated in both single and multi-domain generalization across various benchmarks.\nWith the ability to extrapolate any domains for any class, our method has the potential to learn a generalized model for any task without any data. To illustrate, we put forth a much more difficult setting termed, data-free domain generalization, that aims to learn a generalized model in the absence of any collected data. Our empirical findings support the above argument and our methods exhibit commendable performance in this setting, even surpassing the supervised setting by approximately 1-2% on datasets such as VLCS.", "title_embedding_index": 9508, "title_abs_embedding_index": 9533}, {"title": "Score-based pullback Riemannian geometry", "link_suffix": "/forum?id=emSgz2bKVq", "link": "https://openreview.net/forum?id=emSgz2bKVq", "pdf_link": "https://openreview.net/pdf?id=emSgz2bKVq", "keywords": "Data-driven Riemannian geometry, interpretable representation learning, pullback Riemannian geometry, generative models, closed-form geodesics, manifold dimension estimation", "abstract": "Data-driven Riemannian geometry has emerged as a powerful tool for interpretable representation learning, offering improved efficiency in downstream tasks. Moving forward, it is crucial to balance cheap manifold mappings with efficient training algorithms. In this work, we integrate concepts from pullback Riemannian geometry and generative models to propose a framework for data-driven Riemannian geometry that is scalable in both geometry and learning: score-based pullback Riemannian geometry. Focusing on unimodal distributions as a first step, we propose a score-based Riemannian structure with closed-form geodesics that pass through the data probability density. With this structure, we construct a Riemannian autoencoder (RAE) with error bounds for discovering the correct data manifold dimension. This framework can naturally be used with anisotropic normalizing flows by adopting isometry regularization during training. Through numerical experiments on various datasets, we demonstrate that our framework not only produces high-quality geodesics through the data support, but also reliably estimates the intrinsic dimension of the data manifold and provides a global chart of the manifold, even in high-dimensional ambient spaces.", "title_embedding_index": 9509, "title_abs_embedding_index": 9534}, {"title": "nGPT: Normalized Transformer with Representation Learning on the Hypersphere", "link_suffix": "/forum?id=se4vjm7h4E", "link": "https://openreview.net/forum?id=se4vjm7h4E", "pdf_link": "https://openreview.net/pdf?id=se4vjm7h4E", "keywords": "transformer, normalization, representation", "abstract": "We propose a novel neural network architecture, the normalized Transformer (nGPT) with representation learning on the hypersphere. In nGPT, all vectors forming the embeddings, MLP, attention matrices and hidden states are unit norm normalized. The input stream of tokens travels on the surface of a hypersphere, with each layer contributing a displacement towards the target output predictions. These displacements are defined by the MLP and attention blocks, whose vector components also reside on the same hypersphere. Experiments show that nGPT learns much faster, reducing the number of training steps required to achieve the same accuracy by a factor of 4 to 20, depending on the sequence length.", "title_embedding_index": 9510, "title_abs_embedding_index": 9535}, {"title": "Seeing is Knowing: Advancing Semantic Understanding with MLLMs in Grounding Tasks", "link_suffix": "/forum?id=akPwQb4fHU", "link": "https://openreview.net/forum?id=akPwQb4fHU", "pdf_link": "https://openreview.net/pdf?id=akPwQb4fHU", "keywords": "Zero-shot segmentation; Multimodal LLM; MLLM Grounding", "abstract": "Large vision models (VLMs) achieve success in most daily scenarios but face challenges in special grounding tasks. This limitation is primarily due to insufficient semantic understanding for both tasks and images in current vision models. In contrast, large multimodal language models (M-LLMs) excel in semantic comprehension and instruction-following but underperform in detailed recognition. To harness the strengths of both, we propose to utilize M-LLMs to assist VLMs in handling difficult segmentation tasks.\nThe key to our approach involves\n(1)leveraging M-LLMs for semantic expertise\nand (2)formatting instruction-based guidance.\nOur proposed framework is generalizable, performing well across various tasks. Experimental results show a significant performance improvement (10%+) in challenging tasks like camouflage object detection, anomaly detection and medical image segmentation compared to zero-shot baselines.", "title_embedding_index": 9511, "title_abs_embedding_index": 9536}, {"title": "Pushing the Limits of All-Atom Geometric Graph Neural Networks: Pre-Training, Scaling, and Zero-Shot Transfer", "link_suffix": "/forum?id=4S2L519nIX", "link": "https://openreview.net/forum?id=4S2L519nIX", "pdf_link": "https://openreview.net/pdf?id=4S2L519nIX", "keywords": "Geometric Graph Neural Networks, Self-supervised Pre-training, Scaling, Zero-shot Transfer, Molecular Representation", "abstract": "Constructing transferable descriptors for conformation representation of molecular and biological systems has been a long-standing challenge in drug discovery, learning-based molecular dynamics, and protein mechanism analysis. Geometric graph neural networks (Geom-GNNs) with all-atom information have transformed atomistic simulations by serving as a general learnable geometric descriptors for downstream tasks such as interatomic potential and molecular property prediction. However, common practices involve supervising Geom-GNNs on specific downstream tasks, which suffer from the lack of high-quality data and inaccurate labels, potentially leading to poor generalization and performance degradation on out-of-distribution (OOD) scenarios, especially with quantum chemical data. In this work, we explored the possibility of using pre-trained Geom-GNNs as transferable and highly effective geometric descriptors for improved generalization. To explore their representation power, we studied the scaling behaviors of Geom-GNNs under self-supervised pre-training, supervised and unsupervised learning setups. We found the expressive power of different architectures can differ on the pre-training task. Interestingly, Geom-GNNs do not follow the power-law scaling on the pre-training task, and universally lack predictable scaling behavior on the supervised tasks with quantum chemical labels. More importantly, we demonstrate how all-atom graph embedding can be organically combined with other neural architectures to enhance the expressive power. Meanwhile, the low-dimensional projection of the latent space shows excellent agreement with conventional geometrical descriptors.", "title_embedding_index": 9512, "title_abs_embedding_index": 9537}, {"title": "MuPT: A Generative Symbolic Music Pretrained Transformer", "link_suffix": "/forum?id=iAK9oHp4Zz", "link": "https://openreview.net/forum?id=iAK9oHp4Zz", "pdf_link": "https://openreview.net/pdf?id=iAK9oHp4Zz", "keywords": "Pretrained Transformer, SMT-ABC Notation, SMS Law", "abstract": "In this paper, we explore the application of Large Language Models (LLMs) to the pre-training of music. While the prevalent use of MIDI in music modeling is well-established, our findings suggest that LLMs are inherently more compatible with ABC Notation, which aligns more closely with their design and strengths, thereby enhancing the model's performance in musical composition.\nTo address the challenges associated with misaligned measures from different tracks during generation, we propose the development of a $\\underline{S}$ynchronized $\\underline{M}$ulti-$\\underline{T}$rack ABC Notation ($\\textbf{SMT-ABC Notation}$), which aims to preserve coherence across multiple musical tracks. \nOur contributions include a series of models capable of handling up to 8192 tokens, covering 90% of the symbolic music data in our training set. Furthermore, we explore the implications of the $\\underline{S}$ymbolic $\\underline{M}$usic $\\underline{S}$caling Law ($\\textbf{SMS Law}$) on model performance. The results indicate a promising research direction in music generation, offering extensive resources for further research through our open-source contributions.", "title_embedding_index": 9513, "title_abs_embedding_index": 9538}, {"title": "Improving Instruction-Following in Language Models through Activation Steering", "link_suffix": "/forum?id=wozhdnRCtw", "link": "https://openreview.net/forum?id=wozhdnRCtw", "pdf_link": "https://openreview.net/pdf?id=wozhdnRCtw", "keywords": "Interpretability, Mechanistic Interpretability, Instruction-following, Activation Steering, LLMs", "abstract": "The ability to follow instructions is crucial for numerous real-world applications of language models. In pursuit of deeper insights and more powerful capabilities, we derive instruction-specific vector representations from language models and use them to steer models accordingly. These vectors are computed as the difference in activations between inputs with and without instructions, enabling a modular approach to activation steering. We demonstrate how this method can enhance model adherence to constraints such as output format, length, and word inclusion, providing inference-time control over instruction following. Our experiments across four models demonstrate how we can use the activation vectors to guide models to follow constraints even without explicit instructions and to enhance performance when instructions are present. Additionally, we explore the compositionality of activation steering, successfully applying multiple instructions simultaneously. Finally, we demonstrate that steering vectors computed on instruction-tuned models can transfer to improve base models. Our findings demonstrate that activation steering offers a practical and scalable approach for fine-grained control in language generatio", "title_embedding_index": 9514, "title_abs_embedding_index": 9539}, {"title": "From Molecules to Mixtures: Learning Representations of Olfactory Mixture Similarity using Inductive Biases", "link_suffix": "/forum?id=6wXYXYSFPK", "link": "https://openreview.net/forum?id=6wXYXYSFPK", "pdf_link": "https://openreview.net/pdf?id=6wXYXYSFPK", "keywords": "representation learning, graph attention, graph neural networks, inductive bias, olfaction perception, molecular mixtures", "abstract": "Olfaction---how molecules are perceived as odors to humans---remains poorly understood. Recently, the primary odor map (POM) was introduced to digitize the olfactory properties of single compounds. However, smells in real life are not pure single molecules, but are complex mixtures of molecules, whose representations remain relatively underexplored. In this work, we introduce \\textsc{POMMix}, extending the POM to represent mixtures. Our representation builds upon the symmetries of the problem space in a hierarchical manner: 1) graph neural networks for building molecular embeddings, 2) attention mechanisms for aggregating molecular representations into mixture representations, and 3) cosine prediction heads to encode olfactory perceptual distance in the mixture embedding space. \\textsc{POMMix} achieves state-of-the-art predictive performance across multiple datasets. We also evaluate the generalizability of the representation on multiple splits when applied to unseen molecules and mixture sizes. Our work advances the effort to digitize olfaction, and highlights the synergy of domain expertise and deep learning in crafting expressive representations in low-data regimes.", "title_embedding_index": 9515, "title_abs_embedding_index": 9540}, {"title": "DiffuSolve: Diffusion-Based Solver for Non-Convex Trajectory Optimization", "link_suffix": "/forum?id=KsVlV2CRya", "link": "https://openreview.net/forum?id=KsVlV2CRya", "pdf_link": "https://openreview.net/pdf?id=KsVlV2CRya", "keywords": "Diffusion Model, Nonconvex Optimization, Trajectory Optimization, Numerical Solver", "abstract": "Optimal trajectory design is computationally expensive for nonlinear and high-dimensional dynamical systems. The challenge arises from the non-convex nature of the optimization problem with multiple local optima, which usually requires a global search. Traditional numerical solvers struggle to find diverse solutions efficiently without appropriate initial guesses. In this paper, we introduce DiffuSolve, a general diffusion model-based solver for non-convex trajectory optimization. An expressive diffusion model is trained on pre-collected locally optimal solutions and efficiently samples initial guesses, which then warm-starts numerical solvers to fine-tune the feasibility and optimality. We also present DiffuSolve+, a novel constrained diffusion model with an additional loss in training that further reduces the problem constraint violations of diffusion samples. Experimental evaluations on three tasks verify the improved robustness, diversity, and a 2$\\times$ to 11$\\times$ increase in computational efficiency with our proposed method, which generalizes well to trajectory optimization problems of varying challenges.", "title_embedding_index": 9516, "title_abs_embedding_index": 9541}, {"title": "Explainable self-supervised learning by spiking functions: a theory", "link_suffix": "/forum?id=QhnPrsZ38V", "link": "https://openreview.net/forum?id=QhnPrsZ38V", "pdf_link": "https://openreview.net/pdf?id=QhnPrsZ38V", "keywords": "Self-supervised learning, spiking neural networks, information theory, XAI", "abstract": "Deep neural networks trained in an end-to-end manner have been proven to be efficient in a wide range of machine learning tasks. However, there is one drawback of end-to-end learning: The learned features and information are implicitly represented in neural network parameters, which are not explainable: The learned features cannot be used as explicit regularities to explain the data probability distribution. To resolve this issue, we propose in this paper a new machine learning theory, which describes in mathematics what are 'non-randomness' and 'regularities' in a data probability distribution. Our theory applies a spiking function to distinguish data samples from random noises. In this process, 'non-randomness', or a large amount of information, is encoded by the spiking function into regularities, a small amount of information. Then, our theory describes the application of multiple spiking functions to the same data distribution. In this process, we claim that the 'best' regularities, or the optimal spiking functions, are those who can capture the largest amount of information from the data distribution, and then encode the captured information into the smallest amount of information. By optimizing the spiking functions, one can achieve an explainable self-supervised learning system.", "title_embedding_index": 9517, "title_abs_embedding_index": 9542}, {"title": "AudioMorphix: Training-free audio editing with diffusion probabilistic models", "link_suffix": "/forum?id=a8dQutiF9E", "link": "https://openreview.net/forum?id=a8dQutiF9E", "pdf_link": "https://openreview.net/pdf?id=a8dQutiF9E", "keywords": "Audio editing, diffusion probabilistic model", "abstract": "Despite recent advancements in diffusion-based audio generation, precisely editing content in a specific area of a recording remains challenging. In this paper, we introduce AudioMorphix, a training-free audio editor that manipulates a target area of a recording using another recording as a reference. Specifically, we conceptualize audio editing as part of a morphing cycle, \nin which different sounds can be combined into a cohesive audio mixture through morphing, whereas the mixture can be disentangled into individual components via demorphing. Leveraging the concept of audio morphing cycle, we optimize the noised latent conditioned on raw input together with reference audio and devise a series of energy functions to refine the guided diffusion process. Additionally, we manipulate the features within self-attention layers to preserve detailed characteristics from the original recordings. To accommodate a broad range of audio editing techniques, we collected a new evaluation dataset, providing editing instructions, reference audio and captions, and the duration of the edited area as guidance. Extensive experiments demonstrate that the AudioMorphix yields promising performance on various audio editing tasks, including addition, removal, and style transferring. Demo and code is available at this url.", "title_embedding_index": 9518, "title_abs_embedding_index": 9543}, {"title": "VEditBench: Holistic Benchmark for Text-Guided Video Editing", "link_suffix": "/forum?id=6325Jzc9eR", "link": "https://openreview.net/forum?id=6325Jzc9eR", "pdf_link": "https://openreview.net/pdf?id=6325Jzc9eR", "keywords": "Benchmark, Generative Models, Video Editing", "abstract": "Video editing usually requires substantial human expertise and effort. However, recent advances in generative models have democratized this process, enabling video edits to be made using simple textual instructions. Despite this progress, the absence of a standardized and comprehensive benchmark has made it difficult to compare different methods within a common framework. To address this gap, we introduce VEditBench, a comprehensive benchmark for text-guided video editing (TGVE). VEditBench offers several key features: (1) 420 real-world videos spanning diverse categories and durations, including 300 short videos (2-4 seconds) and 120 longer videos (10-20 seconds); (2) 6 editing tasks that capture a broad range of practical editing challenges: object insertion, object removal, object swap, scene replacement, motion change, and style translation; (3) 9 evaluation dimensions to assess the semantic fidelity and visual quality of edits. We evaluate ten state-of-the-art video editing models using VEditBench, offering an in-depth analysis of their performance across metrics, tasks, and models. We hope VEditBench will provide valuable insights to the community and serve as the standard benchmark for TGVE models following its open-sourcing.", "title_embedding_index": 9519, "title_abs_embedding_index": 9544}, {"title": "Adversarial Inception for Bounded Backdoor Poisoning in Deep Reinforcement Learning", "link_suffix": "/forum?id=NALkteEo9Q", "link": "https://openreview.net/forum?id=NALkteEo9Q", "pdf_link": "https://openreview.net/pdf?id=NALkteEo9Q", "keywords": "Reinforcement Learning, Poisoning Attacks, Backdoor Attacks, Adversarial Machine Learning", "abstract": "Recent works have demonstrated the vulnerability of Deep Reinforcement Learning (DRL) algorithms against training-time, backdoor poisoning attacks. These attacks induce pre-determined, adversarial behavior in the agent upon observing a fixed trigger during deployment while allowing the agent to solve its intended task during training. Prior attacks rely on arbitrarily large perturbations to the agent's rewards to achieve both of these objectives - leaving them open to detection. Thus, in this work, we propose a new class of backdoor attacks against DRL which achieve state of the art performance while minimally altering the agent's rewards. These ``inception'' attacks train the agent to associate the targeted adversarial behavior with high returns by inducing a disjunction between the agent's chosen action and the true action executed in the environment during training. We formally define these attacks and prove they can achieve both adversarial objectives. We then devise an online inception attack which significantly out-performs prior attacks under bounded reward constraints.", "title_embedding_index": 9520, "title_abs_embedding_index": 9545}, {"title": "Were RNNs All We Needed?", "link_suffix": "/forum?id=GrmFFxGnOR", "link": "https://openreview.net/forum?id=GrmFFxGnOR", "pdf_link": "https://openreview.net/pdf?id=GrmFFxGnOR", "keywords": "Recurrent Neural Networks, RNNs, Sequence Modelling, Efficiency, LSTMs, GRUs, Parallel Scan", "abstract": "The scalability limitations of Transformers regarding sequence length have renewed interest in recurrent sequence models that are parallelizable during training. As a result, many novel recurrent architectures, such as S4, Mamba, and Aaren, have been proposed that achieve comparable performance. In this work, we revisit traditional recurrent neural networks (RNNs) from over a decade ago: LSTMs (1997) and GRUs (2014). While these models were slow due to requiring to backpropagate through time (BPTT), we show that by removing their hidden state dependencies from their input, forget, and update gates, LSTMs and GRUs no longer need to BPTT and can be efficiently trained in parallel. Building on this, we introduce minimal versions (minLSTMs and minGRUs) that (1) use significantly fewer parameters than their traditional counterparts and (2) are fully parallelizable during training ($175 \\times$ faster for a sequence of length $512$). Lastly, we show that these stripped-down versions of decade-old RNNs match the empirical performance of recent sequence models.", "title_embedding_index": 9521, "title_abs_embedding_index": 9546}, {"title": "Functional Homotopy: Smoothing Discrete Optimization via Continuous Parameters for LLM Jailbreak Attacks", "link_suffix": "/forum?id=uhaLuZcCjH", "link": "https://openreview.net/forum?id=uhaLuZcCjH", "pdf_link": "https://openreview.net/pdf?id=uhaLuZcCjH", "keywords": "alignment, optimization", "abstract": "Optimization methods are widely employed in deep learning to address and mitigate undesired model responses. While gradient-based techniques have proven effective for image models, their application to language models is hindered by the discrete nature of the input space. This study introduces a novel optimization approach, termed thefunctional homotopymethod, which leverages the functional duality between model training and input generation. By constructing a series of easy-to-hard optimization problems, we iteratively solve these using principles derived from established homotopy methods. We apply this approach to jailbreak attack synthesis for large language models (LLMs), achieving a 20%-30% improvement in success rate over existing methods in circumventing established safe open-source models such as Llama-2 and Llama-3.", "title_embedding_index": 9522, "title_abs_embedding_index": 9547}, {"title": "Forte : Finding Outliers with Representation Typicality Estimation", "link_suffix": "/forum?id=7XNgVPxCiA", "link": "https://openreview.net/forum?id=7XNgVPxCiA", "pdf_link": "https://openreview.net/pdf?id=7XNgVPxCiA", "keywords": "Generative Models, Out-of-Distribution Detection (OOD)", "abstract": "Generative models can now produce photorealistic synthetic data which is virtually indistinguishable from the real data used to train it. This is a significant evolution over previous models which could produce reasonable facsimiles of the training data, but ones which could be visually distinguished from the training data by human evaluation. Recent work on OOD detection has raised doubts that generative model likelihoods are optimal OOD detectors due to issues involving likelihood misestimation, entropy in the generative process, and typicality. We speculate that generative OOD detectors also failed because their models focused on the pixels rather than the semantic content of the data, leading to failures in near-OOD cases where the pixels may be similar but the information content is significantly different. We hypothesize that estimating typical sets using self-supervised learners leads to better OOD detectors. We introduce a novel approach that leverages representation learning, and informative summary statistics based on manifold estimation, to address all of the aforementioned issues. Our method outperforms other unsupervised approaches and achieves state-of-the art performance on well-established challenging benchmarks, and new synthetic data detection tasks.", "title_embedding_index": 9523, "title_abs_embedding_index": 9548}, {"title": "NarrativeBridge: Enhancing Video Captioning with Causal-Temporal Narrative", "link_suffix": "/forum?id=bBoetBIN2R", "link": "https://openreview.net/forum?id=bBoetBIN2R", "pdf_link": "https://openreview.net/pdf?id=bBoetBIN2R", "keywords": "Video Captioning, Video Narrative, Video Storytelling", "abstract": "Existing video captioning benchmarks and models lack coherent representations of causal-temporal narrative, which is sequences of events linked through cause and effect, unfolding over time and driven by characters or agents. This lack of narrative restricts models\u2019 ability to generate text descriptions that capture the causal and temporal dynamics inherent in video content. To address this gap, we propose NarrativeBridge, an approach comprising of: (1) a novel Causal-Temporal Narrative (CTN) captions benchmark generated using a large language model and few-shot prompting, explicitly encoding cause-effect temporal relationships in video descriptions, evaluated automatically to ensure caption quality and relevance and validated through human evaluation; and (2) a dedicated Cause-Effect Network (CEN) architecture with separate encoders for capturing cause and effect dynamics independently, enabling effective learning and generation of captions with causal- temporal narrative. Extensive experiments demonstrate that CEN significantly outperforms state-of-the-art models, including fine-tuned vision-language models, and is more accurate in articulating the causal and temporal aspects of video content than the second best model (GIT): 17.88 and 17.44 CIDEr on the MSVD and MSR-VTT datasets, respectively. Cross-dataset evaluations further showcase CEN\u2019s strong generalization capabilities. The proposed framework understands and generates nuanced text descriptions with intricate causal-temporal narrative structures present in videos, addressing a critical limitation in video captioning.", "title_embedding_index": 9524, "title_abs_embedding_index": 9549}]
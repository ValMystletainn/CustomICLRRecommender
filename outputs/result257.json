[
    {
        "title": "Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum",
        "link_suffix": "/forum?id=Mr1wsHM9JK",
        "link": "https://openreview.net/forum?id=Mr1wsHM9JK",
        "pdf_link": "https://openreview.net/pdf?id=Mr1wsHM9JK",
        "keywords": "federated learning, momentum, distributed learning, deep learning",
        "abstract": "Federated Learning (FL) has emerged as the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios. However, system and statistical challenges hinder real-world applications, which demand efficient learning from edge devices and robustness to heterogeneity. Despite significant research efforts, existing approaches (i) are not sufficiently robust, (ii) do not perform well in large-scale scenarios, and (iii) are not communication efficient. In this work, we propose a novelGeneralized Heavy-Ball Momentum(GHBM), proving that it enjoys an improved theoretical convergence rate w.r.t. existing FL methods based on classical momentum inpartial participation, without relying on bounded data heterogeneity. Then, we present FedHBM as an adaptive, communication-efficient by-design instance of GHBM. Extensive experimentation on vision and language tasks, in both controlled and realistic large-scale scenarios, confirms our theoretical findings, showing that GHBM substantially improves the state of the art, especially in large scale scenarios with high data heterogeneity and low client participation."
    },
    {
        "title": "Making Transformer Decoders Better Differentiable Indexers",
        "link_suffix": "/forum?id=bePaRx0otZ",
        "link": "https://openreview.net/forum?id=bePaRx0otZ",
        "pdf_link": "https://openreview.net/pdf?id=bePaRx0otZ",
        "keywords": "Generative Retrieval, Generative Index, End-to-end Recommender System, Information Retrieval, Transformer",
        "abstract": "Retrieval aims to find the top-k items most relevant to a query/user from a large dataset. Traditional retrieval models represent queries/users and items as embedding vectors and use Approximate Nearest Neighbor (ANN) search for retrieval. Recently, researchers have proposed a generative-based retrieval method that represents items as token sequences and uses a decoder model for autoregressive training. Compared to traditional methods, this approach uses more complex models and integrates index structure during training, leading to better performance. However, these methods remain two-stage processes, where index construction is separate from the retrieval model, limiting the model's overall capacity. Additionally, existing methods construct indices by clustering pre-trained item representations in Euclidean space. However, real-world scenarios are more complex, making this approach less accurate. To address these issues, we propose a \\underline{U}nified framework for \\underline{R}etrieval and \\underline{I}ndexing, termed \\textbf{URI}. URI ensures strong consistency between index construction and the retrieval model, typically a Transformer decoder. URI simultaneously builds the index and trains the decoder, constructing the index through the decoder itself. It no longer relies on one-sided item representations in Euclidean space but constructs the index within the interactive space between queries and items. Experimental comparisons on three real-world datasets show that URI significantly outperforms existing methods."
    },
    {
        "title": "MergePrint: Robust Fingerprinting against Merging Large Language Models",
        "link_suffix": "/forum?id=JVBR1ud4lL",
        "link": "https://openreview.net/forum?id=JVBR1ud4lL",
        "pdf_link": "https://openreview.net/pdf?id=JVBR1ud4lL",
        "keywords": "model fingerprinting, large language models, model merging",
        "abstract": "As the cost of training large language models (LLMs) rises, protecting their intellectual property has become increasingly critical. Model merging, which integrates multiple expert models into a single model capable of performing multiple tasks, presents a growing risk of unauthorized and malicious usage.\nWhile fingerprinting techniques have been studied for asserting model ownership, existing methods have primarily focused on fine-tuning, leaving model merging underexplored.\nTo address this gap, we propose a novel fingerprinting method MergePrint that embeds robust fingerprints designed to preserve ownership claims even after model merging.\nBy optimizing against a pseudo-merged model, which simulates post-merged model weights, MergePrint generates fingerprints that remain detectable after merging.\nAdditionally, we optimize the fingerprint inputs to minimize performance degradation, enabling verification through specific outputs from targeted inputs. \nThis approach provides a practical fingerprinting strategy for asserting ownership in cases of misappropriation through model merging."
    },
    {
        "title": "MotionRL: Align Text-to-Motion Generation to Human Preferences with Multi-Reward Reinforcement Learning",
        "link_suffix": "/forum?id=v1OQ0kNq0w",
        "link": "https://openreview.net/forum?id=v1OQ0kNq0w",
        "pdf_link": "https://openreview.net/pdf?id=v1OQ0kNq0w",
        "keywords": "Motion Generation; Reinforcement Learning;",
        "abstract": "We introduce \\textbf{MotionRL}, the first approach to utilize Multi-Reward Reinforcement Learning (RL) for optimizing text-to-motion generation tasks and aligning them with human preferences. Previous works focused on improving numerical performance metrics on the given datasets, often neglecting the variability and subjectivity of human feedback. In contrast, our novel approach uses reinforcement learning to fine-tune the motion generator based on human preferences prior knowledge of the human perception model, allowing it to generate motions that better align human preferences. In addition, MotionRL introduces a novel multi-objective optimization strategy to approximate Pareto optimality between text adherence, motion quality, and human preferences. Extensive experiments and user studies demonstrate that MotionRL not only allows control over the generated results across different objectives but also significantly enhances performance across these metrics compared to other algorithms."
    },
    {
        "title": "Sharpness-Aware Black-Box Optimization",
        "link_suffix": "/forum?id=h7EwIfjxgn",
        "link": "https://openreview.net/forum?id=h7EwIfjxgn",
        "pdf_link": "https://openreview.net/pdf?id=h7EwIfjxgn",
        "keywords": "Black-box Optimization, Sharpness-Aware Minimization",
        "abstract": "Black-box optimization algorithms have been widely used in various machine learning problems, including reinforcement learning and prompt fine-tuning. However, directly optimizing the training loss value, as commonly done in existing black-box optimization methods, could lead to suboptimal model quality and generalization performance.\nTo address those problems in black-box optimization, we propose a novel Sharpness-Aware Black-box Optimization (SABO) algorithm, which applies a sharpness-aware minimization strategy to improve the model generalization. Specifically, the proposed SABO method first reparameterizes the objective function by its expectation over a Gaussian distribution. \nThen it iteratively updates the parameterized distribution by approximated stochastic gradients of the maximum objective value within a small neighborhood around the current solution in the Gaussian distribution space. \nTheoretically, we prove the convergence rate and generalization bound of the proposed SABO algorithm. \nEmpirically, extensive experiments on the black-box prompt fine-tuning tasks demonstrate the effectiveness of the proposed SABO method in improving model generalization performance."
    },
    {
        "title": "Improving Multi-modal Representations via Binding Space in Scale",
        "link_suffix": "/forum?id=l2izo0z7gu",
        "link": "https://openreview.net/forum?id=l2izo0z7gu",
        "pdf_link": "https://openreview.net/pdf?id=l2izo0z7gu",
        "keywords": "multimodal representations",
        "abstract": "Recently, human-computer interaction with various modalities has shown promising applications, like GPT-4o and Gemini. Meanwhile, multimodal representation models have emerged as the foundation for these versatile multimodal understanding and generation pipeline. Models like CLIP, CLAP and ImageBind can map their specialized modalities into respective joint spaces. To construct a high-quality omni representation space that can be shared and expert in any modality, we propose to merge these advanced models into a unified space in scale. With this insight, we present \\textbf{OmniBind}, advanced multimodal joint representation models via fusing knowledge of 14 pre-trained spaces, which support 3D, audio, image, video and language inputs. To alleviate the interference between different knowledge sources in integrated space, we dynamically assign weights to different spaces by learning routers with two objectives: cross-modal overall alignment and language representation decoupling. Notably, since binding and routing spaces only require lightweight networks, OmniBind is extremely training-efficient. Extensive experiments demonstrate the versatility and superiority of OmniBind as an omni representation model, highlighting its great potential for diverse applications, such as any-query and composable multimodal understanding."
    },
    {
        "title": "A Unified Theory of Stochastic Proximal Point Methods without Smoothness",
        "link_suffix": "/forum?id=AqHbMV28o7",
        "link": "https://openreview.net/forum?id=AqHbMV28o7",
        "pdf_link": "https://openreview.net/pdf?id=AqHbMV28o7",
        "keywords": "Stochastic optimization, empirical risk minimization, stochastic proximal point algorithm, variance reduction, sampling",
        "abstract": "This paper presents a comprehensive analysis of a broad range of variations of the stochastic proximal point method (SPPM). Proximal point methods have attracted considerable interest owing to their numerical stability and robustness against imperfect tuning, a trait not shared by the dominant stochastic gradient descent (SGD) algorithm. A framework of assumptions that we introduce encompasses methods employing techniques such as variance reduction and arbitrary sampling. A cornerstone of our general theoretical approach is a parametric assumption on the iterates, correction and control vectors. We establish a single theorem that ensures linear convergence under this assumption and $\\mu$-strong convexity of the loss function, and without the need to invoke smoothness. This integral theorem reinstates best known complexity and convergence guarantees for several existing methods, which demonstrates the robustness of our approach. We expand our study by developing three new variants of SPPM, and through numerical experiments elucidate various properties inherent to them."
    },
    {
        "title": "FRACTAL CALIBRATION FOR LONG-TAILED OBJECT DETECTION",
        "link_suffix": "/forum?id=cs8dm8MgOT",
        "link": "https://openreview.net/forum?id=cs8dm8MgOT",
        "pdf_link": "https://openreview.net/pdf?id=cs8dm8MgOT",
        "keywords": "long-tail learning, imbalanced object detection, long-tailed instance segmentation",
        "abstract": "Real-world datasets follow an imbalanced distribution, which poses significant\nchallenges in rare-category object detection. Recent studies tackle this problem\nby developing re-weighting and re-sampling methods, that utilise the class frequencies of the dataset. However, these techniques focus solely on the frequency statistics and ignore the distribution of the classes in image space, missing important information. In contrast to them, we propose Fractal CALibration (FRACAL): a novel post-calibration method for long-tailed object detection. FRACAL\ndevises a logit adjustment method that utilises the fractal dimension to estimate how uniformly classes are distributed in image space. During inference, it uses the fractal dimension to inversely downweight the probabilities of uniformly spaced class predictions achieving balance in two axes: between frequent and rare categories, and between uniformly spaced and sparsely spaced classes. FRACAL is a\npost-processing method and it does not require any training, also it can be combined with many off-the-shelf models such as one-stage sigmoid detectors and two-stage instance segmentation models. FRACAL boosts the rare class performance by up to 8.6% and surpasses all previous methods on LVIS dataset, while showing good generalisation to other datasets such as COCO, V3Det and OpenImages. We provide the code in the Appendix."
    },
    {
        "title": "From Tokens to Words: On the Inner Lexicon of LLMs",
        "link_suffix": "/forum?id=328vch6tRs",
        "link": "https://openreview.net/forum?id=328vch6tRs",
        "pdf_link": "https://openreview.net/pdf?id=328vch6tRs",
        "keywords": "Detokenization, Large Language Models, LLM, Byte-Pair Encoding, BPE, Subword Tokens, Word Reconstruction, Latent Lexicon, Inner Dictionary, Token Aggregation, Feed-Forward Networks, FFNs, Out-of-Vocabulary Words, Efficiency, Tokenization, Language Model Optimization",
        "abstract": "Natural language is composed of words, but modern LLMs processsub-wordsas input. A natural question raised by this discrepancy is whether LLMs encode words internally, and if so how. We present evidence that LLMs engage in an intrinsic detokenization process, where sub-word sequences are combined into coherent word representations. Our experiments show that this process takes place primarily within the early and middle layers of the model. They also show that it is robust to non-morphemic splits, typos and perhaps importantly---to out-of-vocabulary words: when feeding the inner representation of such words to the model as input vectors, it can \"understand\" them despite never seeing them during training. Our findings suggest that LLMs maintain a latent vocabulary beyond the tokenizer's scope. These insights provide a practical, finetuning-free application for expanding the vocabulary of pre-trained models. By enabling the addition of new vocabulary words, we reduce input length and inference iterations, which reduces both space and model latency, with little to no loss in model accuracy."
    },
    {
        "title": "GLoRa: A Benchmark to Evaluate the Ability to Learn Long-Range Dependencies in Graphs",
        "link_suffix": "/forum?id=2jf5x5XoYk",
        "link": "https://openreview.net/forum?id=2jf5x5XoYk",
        "pdf_link": "https://openreview.net/pdf?id=2jf5x5XoYk",
        "keywords": "Graph Learning, Graph Neural Networks, Synthetic Benchmarks, Long-Range Dependencies",
        "abstract": "Learning on graphs is one of the most active research topics in machine learning (ML). Among the key challenges in this field, effectively learning long-range dependencies in graphs has been a particularly difficult problem. It has been observed that, in practice, the performance of many ML approaches, including various types of graph neural networks (GNNs), degrades significantly when the learning task involves long-range dependencies\u2014that is, when the answer is determined by the presence of a certain path of significant length in the graph. This issue has been attributed to several phenomena, including, most prominently, oversmoothing, over-squashing, and vanishing gradient. A number of solutions have been proposed to mitigate these causes. However, evaluation of these solutions is complicated by the fact that existing benchmarks do not really test systems for their ability to learn tasks based on long-range dependencies in a transparent manner. In this paper, we design a synthetic benchmark that provably allows testing systems for this learning ability. We then evaluate state-of-the-art systems against it and conclude that none of them can claim that it can learn long-range dependencies well. We also observe that this weak performance cannot be attributed to any of the three causes, thus indicating that further investigation is necessary."
    },
    {
        "title": "Rethinking The Reliability of Representation Engineering in Large Language Models",
        "link_suffix": "/forum?id=sYJQEgkkaI",
        "link": "https://openreview.net/forum?id=sYJQEgkkaI",
        "pdf_link": "https://openreview.net/pdf?id=sYJQEgkkaI",
        "keywords": "transparency, interpretability, causality, AI safety",
        "abstract": "Inspired by cognitive neuroscience, representation engineering (RepE) seeks to connect the neural activities within large language models (LLMs) to their behaviors, providing a promising pathway towards transparent AI.\nDespite its successful applications under many contexts, the connection established by RepE is not always reliable, as it implicitly assumes that LLMs will consistently follow the roles assigned in the instructions during neural activities collection.\nWhen this assumption is violated, observed correlations between the collected neural activities and model behaviors may not be causal due to potential confounding biases, thereby compromising the reliability of RepE.\nWe identify this key limitation and propose CAusal Representation Engineering (CARE), a principled framework that employs matched-pair trial design to control for confounders.\nBy isolating the impact of confounders on neural activities and model behaviors, CARE grounds the connection in causality, allowing for more reliable interpretations and control of LLMs.\nExtensive empirical evaluations across various aspects of safety demonstrate the effectiveness of CARE compared to the original RepE implementation, particularly in controlling model behaviors, highlighting the importance of causality in developing transparent and trustworthy AI systems."
    },
    {
        "title": "B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners",
        "link_suffix": "/forum?id=P6dwZJpJ4m",
        "link": "https://openreview.net/forum?id=P6dwZJpJ4m",
        "pdf_link": "https://openreview.net/pdf?id=P6dwZJpJ4m",
        "keywords": "large language models, self-improvement, complex reasoning",
        "abstract": "In the absence of extensive human-annotated data for complex reasoning tasks, self-improvement -- where models are trained on their own outputs -- has emerged as a primary method for enhancing performance. Recently, the approach to self-improvement has shifted toward a more dynamic, online fashion through iterative training processes. However, the critical factors underlying the mechanism of these self-improving methods remain poorly understood, such as under what conditions self-improvement is effective, and what are the bottlenecks in the current iterations.\nIn this work, we identify and propose methods to monitor two pivotal factors in this iterative process: (1) the model's ability to explore and generate high-quality responses among multiple candidates (exploration); and (2) the reliability of external rewards in selecting the best responses from the generated outputs (exploitation).\nThese factors are inherently moving targets throughout the self-improvement cycles, yet their dynamics are rarely discussed in prior research -- It remains unclear what impedes continual model enhancement after only a few iterations. \nUsing mathematical reasoning as a case study, we begin with a quantitative analysis to track the dynamics of exploration and exploitation, discovering that a model's exploratory capabilities rapidly deteriorate over iterations, and the effectiveness of exploiting external rewards diminishes as well due to shifts in distribution from the original policy.\nMotivated by these findings, we introduce B-STaR, a Self-Taught Reasoning framework that autonomously adjusts configurations across iterations to Balance exploration and exploitation, thereby optimizing the self-teaching effectiveness based on the current policy model and available rewards.\nOur experiments in mathematical reasoning demonstrate that B-STaR not only enhances the model's exploratory capabilities throughout training but also achieves a more effective balance between exploration and exploitation, leading to superior performance. Crucially, this work deconstructs the opaque nature of self-training algorithms, elucidating the interpretable dynamics throughout the process and highlighting current limitations for future research to address."
    },
    {
        "title": "Simple and Fast CNN for Vision",
        "link_suffix": "/forum?id=2GEiBzs2Do",
        "link": "https://openreview.net/forum?id=2GEiBzs2Do",
        "pdf_link": "https://openreview.net/pdf?id=2GEiBzs2Do",
        "keywords": "Convolutional Neural Network, Vision Backbone, Lightweight, Fast",
        "abstract": "Traditional Convolutional Neural Networks (CNNs) tend to use $3\\times 3$ small kernels, but can only capture limited neighboring spatial information. \nInspired by the success of Vision Transformers (ViTs) in capturing long-range visual dependencies, recent CNNs have reached a consensus on utilizing large kernel convolutions (e.g., astonishingly, 111 kernel). \nNevertheless, these approaches are unfriendly to hardware, imposing a serious computation burden on training or inference. \nThis paper introduces a Simple and Fast Convolutional Neural Network (SFCNN) that employs a sequence of stacked $3\\times 3$ convolutions but surpasses state-of-the-art CNNs with larger kernels. \nIn particular, we build a thin and deep model, which encourages more $3\\times 3$ convolutions to capture more spatial information under the limited computing complexity rather than opting for a heavier and shallower architecture. \nTo further enlarge the receptive field, we redesign the traditional inverted residual bottleneck with two $3\\times 3$ depthwise convolutions. \nIn addition, we propose a novel Global Sigmoid Linear Unit (GSiLU) activation function to capture global coarse-grained spatial information. \nOur SFCNN performs better than state-of-the-art CNNs and ViTs on various tasks, including ImageNet-1K image classification, COCO instance segmentation, and ADE20K semantic segmentation. \nIt also has good scalability and outperforms existing state-of-the-art lightweight models. \nAll materials containing codes and logs have been included in the supplementary materials."
    },
    {
        "title": "Sampling Theory and Overparameterization: Shaping Loss Landscapes in\u21132Regression",
        "link_suffix": "/forum?id=UFRn8203LU",
        "link": "https://openreview.net/forum?id=UFRn8203LU",
        "pdf_link": "https://openreview.net/pdf?id=UFRn8203LU",
        "keywords": "Shannon sampling theory, overparameterization.",
        "abstract": "Overparameterization in neural networks has demonstrated remarkable advantages for both memorization and generalization, particularly in models trained with gradient descent. While much of the existing research focuses on the interplay between overparameterization and gradient-based methods, we explore its influence on the loss landscape of $\\ell^2$ supervised regression problems, independent of any specific optimizer. By leveraging the Nyquist-Shannon-Whittaker sampling theorem, we establish a theoretical link between sampling theory and overparameterized neural networks. Our findings reveal that overparameterization not only exponentially increases the number of global minima but also expands the dimensionality of loss valleys for various $\\ell^2$ regression problems modelled with feedforward neural networks. We empirically validate these theoretical insights across multiple supervised $\\ell^2$ regression tasks, trained with both gradient-based and non-gradient-based optimization algorithms. These results offer fresh perspectives on the advantages of overparameterization in neural network design, independent of the chosen learning algorithm."
    },
    {
        "title": "Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting",
        "link_suffix": "/forum?id=R9lgWYE508",
        "link": "https://openreview.net/forum?id=R9lgWYE508",
        "pdf_link": "https://openreview.net/pdf?id=R9lgWYE508",
        "keywords": "Novel View Synthesis, 3D Gaussian Splatting",
        "abstract": "In this work, we investigate the limitations of the 3D Gaussian Splatting (3DGS) optimization scheme, revealing why it undergoes significant performance drops when initialized with noisy or random point clouds. Through in-depth analysis, we identify a key limitation of the 3DGS optimization: limited Gaussian transportability. Since Gaussians are optimized solely based on image photometric loss, the optimization tends to overfit the parameters of the projected Gaussians to improve reconstruction at their current positions, rather than relocating them to more optimal locations. This leads to producing under-reconstructed regions when starting with noisy or random initialization, failing to transport Gaussians to correct locations. Based on our findings, we propose RAIN-GS (Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting), a set of simple yet effective modifications, including initializing sparse Gaussians with large variances, progressive Gaussian low-pass filtering, and an Adaptive Bound-Expanding split algorithm. These modifications enable Gaussians to effectively redistribute across the scene, capturing both coarse structure and fine details. By addressing the inherent limitations of 3DGS, RAIN-GS allows effective training even with random point clouds, significantly enhancing reconstruction quality."
    },
    {
        "title": "SimLabel: Consistency-Guided OOD Detection with Pretrained Vision-Language Models",
        "link_suffix": "/forum?id=Aw1w5sL6ru",
        "link": "https://openreview.net/forum?id=Aw1w5sL6ru",
        "pdf_link": "https://openreview.net/pdf?id=Aw1w5sL6ru",
        "keywords": "Out-of-distribution detection, Vision-Language Models",
        "abstract": "Detecting out-of-distribution (OOD) data is crucial in real-world machine learning applications to prevent severe errors, particularly in safety-critical domains. Existing methods often leverage language information from vision-language models (VLMs) to enhance OOD detection by improving confidence estimation through rich class-wise text information. However, those methods primarily focus on obtaining OOD scores based on the similarity of the new sample to each in-distribution (ID) class, overlooking the OOD scores to a group of similar classes. We assume that an ID sample should consistently receive high similarity score across similar ID classes. This paper investigates the ability of image-text comprehension among different semantic-related ID labels in VLMs and proposes a novel post-hoc strategy called SimLabel. SimLabel enhances the separability between ID and OOD samples by establishing a more robust image-class similarity metric that considers consistency over a set of similar class labels. Extensive experiments demonstrate the superior performance of SimLabel across various zero-shot OOD detection benchmarks, underscoring its efficacy in achieving robust OOD detection."
    },
    {
        "title": "AdaRankGrad: Adaptive Gradient Rank and Moments for Memory-Efficient LLMs Training and Fine-Tuning",
        "link_suffix": "/forum?id=LvNROciCne",
        "link": "https://openreview.net/forum?id=LvNROciCne",
        "pdf_link": "https://openreview.net/pdf?id=LvNROciCne",
        "keywords": "low rank adaptation; low rank gradient training; memory efficient fine tuning; memory optimization; adaptive rank; foundation large language models;",
        "abstract": "Training and fine-tuning large language models (LLMs) come with challenges related to memory and computational requirements due to the increasing size of the model weights and the optimizer states. To tackle these challenges, various techniques have been developed, such as low-rank adaptation (LoRA), which involves introducing a parallel trainable low-rank matrix to the fixed pre-trained weights at each layer. However, these methods often fall short compared to the full-rank weight training approach, as they restrict the parameter search to a low-rank subspace. This limitation can disrupt training dynamics and may require a full-rank warm start to mitigate the impact. \nIn this paper, we introduce a new method inspired by a phenomenon we formally prove: as training progresses, the rank of the estimated layer gradients gradually decreases and asymptotically approaches rank one. Leveraging this, our approach involves adaptively reducing the rank of the gradients during Adam optimization steps, using an efficient online-updating low-rank projections rule. We further present a randomized-svd scheme for efficiently finding the projection matrix. \nOur technique enables full-parameter fine-tuning with adaptive low-rank gradient updates, significantly reducing overall memory requirements during training compared to state-of-the-art methods while improving model performance in both pretraining and fine-tuning. Finally, we provide a convergence analysis of our method and demonstrate its merits for training and fine-tuning language and biological foundation models."
    },
    {
        "title": "From Bulk to Budget: Best Practices To Compress Multimodal Large Language Models",
        "link_suffix": "/forum?id=774F8gF0UO",
        "link": "https://openreview.net/forum?id=774F8gF0UO",
        "pdf_link": "https://openreview.net/pdf?id=774F8gF0UO",
        "keywords": "Multimodal large language models, model pruning, knowledge distillation, model compression",
        "abstract": "Multimodal large language models (MLLMs) are increasingly developed to meet diverse deployment needs, varying in scale and computational demand. While recent research has focused on building MLLMs from Small Language Models (SLMs), these efforts remain limited in flexibility and are still data- and compute-intensive. In this paper, we present the first comprehensive study on flexibly compressing and recovering existing MLLMs in a data-efficient manner. Hence, we address a critical gap in the literature by empirically analyzing best practices for adapting to specific hardware or resource limitations. Our study investigates pruning and knowledge distillation techniques, examining their impact on downstream performance across various model compression strategies, including pruning paradigms, recovery training schemes, and data requirements. Key findings reveal that widthwise pruning is particularly effective in resource-constrained scenarios. For smaller compression ratios, finetuning the multimodal projector alone can restore most performance, while combining finetuning with hidden state knowledge distillation proves most effective across all compression levels. Notably, we demonstrate efficient model downsizing using as little as 5% of the original dataset for moderate compression. Our analysis suggests best practices for compressing MLLMs for resource-efficient deployment. With our best practices, Bunny-v1.0-3B retains over 95% of its original performance, while LLaVA-v1.5-7B maintains more than 97%, with compression ratios below 30%."
    },
    {
        "title": "Memory-Enhanced Neural Solvers for Efficient Adaptation in Combinatorial Optimization",
        "link_suffix": "/forum?id=VHGZjZmzsO",
        "link": "https://openreview.net/forum?id=VHGZjZmzsO",
        "pdf_link": "https://openreview.net/pdf?id=VHGZjZmzsO",
        "keywords": "Reinforcement Learning, Combinatorial Optimization, TSP, CVRP",
        "abstract": "Combinatorial Optimization is crucial to numerous real-world applications, yet still presents challenges due to its (NP-)hard nature. Amongst existing approaches, heuristics often offer the best trade-off between quality and scalability, making them suitable for industrial use. While Reinforcement Learning (RL) offers a flexible framework for designing heuristics, its adoption over handcrafted heuristics remains incomplete within industrial solvers. Existing learned methods still lack the ability to adapt to specific instances and fully leverage the available computational budget. The current best methods either rely on a collection of pre-trained policies, or on data-inefficient fine-tuning; hence failing to fully utilize newly available information within the constraints of the budget. In response, we present MEMENTO, an approach that leverages memory to improve the adaptation of neural solvers at inference time. MEMENTO enables updating the action distribution dynamically based on the outcome of previous decisions. We validate its effectiveness on benchmark problems, in particular Traveling Salesman and Capacitated Vehicle Routing, demonstrating its superiority over tree-search and policy-gradient fine-tuning; and showing it can be zero-shot combined with diversity-based solvers. We successfully train all RL auto-regressive solvers on large instances, and show that MEMENTO can scale and is data-efficient. Overall, MEMENTO enables to push the state-of-the-art on 11 out of 12 evaluated tasks."
    },
    {
        "title": "Rethinking Softmax: Self-Attention with Polynomial Activations",
        "link_suffix": "/forum?id=PMf2Dg1TAA",
        "link": "https://openreview.net/forum?id=PMf2Dg1TAA",
        "pdf_link": "https://openreview.net/pdf?id=PMf2Dg1TAA",
        "keywords": "polynomial activations, softmax, theory of transformers.",
        "abstract": "This paper challenges the conventional belief that softmax attention in transformers is effective primarily because it generates a probability distribution for attention allocation. Instead, we theoretically show that its success lies in its ability to implicitly regularize the Frobenius norm of the attention matrix during training. We then explore alternative activations that regularize the Froebnius norm of the attention matrix, demonstrating that certain polynomial activations can achieve this effect, making them suitable for attention-based architectures. Empirical results indicate these activations perform comparably or better than softmax across various computer vision and language tasks, suggesting new possibilities for attention mechanisms beyond softmax."
    },
    {
        "title": "Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare",
        "link_suffix": "/forum?id=HYaUHZAoPc",
        "link": "https://openreview.net/forum?id=HYaUHZAoPc",
        "pdf_link": "https://openreview.net/pdf?id=HYaUHZAoPc",
        "keywords": "Reinforcement Learning, Inverse Constrained Reinforcement Learning, Healthcare",
        "abstract": "Reinforcement Learning (RL) applied in healthcare can lead to unsafe medical decisions and treatment, such as excessive dosages or abrupt changes, often due to agents overlooking common-sense constraints. Consequently, Constrained Reinforcement Learning (CRL) is a natural choice for safe decisions. However, specifying the exact cost function is inherently difficult in healthcare. Recent Inverse Constrained Reinforcement Learning (ICRL) is a promising approach that infers constraints from expert demonstrations. ICRL algorithms model Markovian decisions in an interactive environment. These settings do not align with the practical requirement of a decision-making system in healthcare, where decisions rely on historical treatment recorded in an offline dataset. To tackle these issues, we propose the Constraint Transformer (CT). Specifically, 1) we utilize a causal attention mechanism to incorporate historical decisions and observations into the constraint modeling, while employing a Non-Markovian layer for weighted constraints to capture critical states. 2) A generative world model is used to perform exploratory data augmentation, enabling offline RL methods to simulate unsafe decision sequences. In multiple medical scenarios, empirical results demonstrate that CT can capture unsafe states and achieve strategies that approximate lower mortality rates, reducing the occurrence probability of unsafe behaviors."
    },
    {
        "title": "Topology-aware Graph Diffusion Model with Persistent Homology",
        "link_suffix": "/forum?id=ZC0wgCabT2",
        "link": "https://openreview.net/forum?id=ZC0wgCabT2",
        "pdf_link": "https://openreview.net/pdf?id=ZC0wgCabT2",
        "keywords": "Graph Generation, Diffusion, Topology, Brain Network",
        "abstract": "Generating realistic graphs presents challenges in estimating accurate distribution of graphs in an embedding space while preserving structural characteristics such as topology. However, existing graph generation methods primarily focus on approximating the joint distribution of graph nodes and edges, overlooking topology-wise similarity hindering accurate representation of global graph structures such as connected components and loops. To address this issue, we propose a topology-aware diffusion-based graph generation method that aims to closely resemble the structural characteristics of the original graph by leveraging persistent homology from topological data analysis (TDA). Specifically, we suggest a novel loss function, Persistence Diagram Matching (PDM) loss, which ensures the generated graphs to closely match the topology of the original graphs, enhancing their fidelity and preserving essential homological properties. Also, we introduce a novel topology-aware attention to enhance the self-attention module in the denoising network. Through comprehensive experiments, we demonstrate the effectiveness of our approach not only by exhibiting high generation performance across various metrics, but also by demonstrating a closer alignment with the distribution of topological features observed in the original graphs. In addition, application to real brain network data showcases its versatility and potential for complex and real graph application."
    },
    {
        "title": "Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making",
        "link_suffix": "/forum?id=gYNBQygmXG",
        "link": "https://openreview.net/forum?id=gYNBQygmXG",
        "pdf_link": "https://openreview.net/pdf?id=gYNBQygmXG",
        "keywords": "counterfactual reasoning, causal explanation formula, multi-agent Markov decision processes, accountability",
        "abstract": "We address the challenge of explaining counterfactual outcomes in multi-agent Markov decision processes. In particular, we aim to explain the total counterfactual effect of an agent's action on the outcome of a realized scenario through its influence on the environment dynamics and the agents' behavior. To achieve this, we introduce a novelcausal explanation formulathat decomposes the counterfactual effect by attributing to each agent and state variable a score reflecting their respective contributions to the effect. First, we show that the total counterfactual effect of an agent's action can be decomposed into two components: one measuring the effect that propagates through all subsequent agents' actions and another related to the effect that propagates through the state transitions. Building on recent advancements in causal contribution analysis, we further decompose these two effects as follows. For the former, we consideragent-specific effects-- a causal concept that quantifies the counterfactual effect of an agent's action that propagates through a subset of agents. Based on this notion, we use Shapley value to attribute the effect to individual agents. For the latter, we consider the concept ofstructure-preserving interventionsand attribute the effect to state variables based on their \"intrinsic'' contributions. Through extensive experimentation, we demonstrate the interpretability of our decomposition approach in a Gridworld environment with LLM-assisted agents and a sepsis management simulator."
    },
    {
        "title": "Regularized Maximum Mean Discrepancy for Variable Selection",
        "link_suffix": "/forum?id=yqaN7MfkFU",
        "link": "https://openreview.net/forum?id=yqaN7MfkFU",
        "pdf_link": "https://openreview.net/pdf?id=yqaN7MfkFU",
        "keywords": "Variable selection, Maximum mean discrepancy, Two-sample tests, Binary classification",
        "abstract": "In this paper, we propose a variable selection method based on maximum mean discrepancy (MMD) to effectively identify important variables that contribute to distributional differences between two samples. We begin by assigning weights to each variable and then optimizing these weights within a regularized MMD framework. The optimized weights serve as an importance measure for each variable and can be leveraged for variable selection. Additionally, using the optimized weights, we design two algorithms aimed at enhancing test power and improving classification accuracy for two-sample tests and classification problems. Our method is model-free and makes no assumptions about the underlying structure of the data. Moreover, we propose an acceleration method to improve computational efficiency.\nWe also provide theoretical guarantees, including the consistency of the estimated weights and the convergence of our acceleration algorithms. Through numerical simulations and real-world datasets, we validate the effectiveness of the proposed method."
    },
    {
        "title": "ThinkBot: Embodied Instruction Following with Thought Chain Reasoning",
        "link_suffix": "/forum?id=tFDTHA3odg",
        "link": "https://openreview.net/forum?id=tFDTHA3odg",
        "pdf_link": "https://openreview.net/pdf?id=tFDTHA3odg",
        "keywords": "Embodied Instruction Following (EIF), Large Language Model, Chain-of-thought Reasoning",
        "abstract": "Embodied Instruction Following (EIF) requires agents to complete human instruction by interacting objects in complicated surrounding environments. Conventional methods directly consider the sparse human instruction to generate action plans for agents, which usually fail to achieve human goals because of the instruction incoherence in action descriptions. On the contrary, we propose ThinkBot that reasons the thought chain in human instruction to recover the missing action descriptions, so that the agent can successfully complete human goals by following the coherent instruction. Specifically, we first design an instruction completer based on large language models to recover the missing actions with interacted objects between consecutive human instruction, where the perceived surrounding environments and the completed sub-goals are considered for instruction completion. Based on the partially observed scene semantic maps, we present an object localizer to infer the position of interacted objects for agents to achieve complex human goals. Extensive experiments in the simulated environment show that our ThinkBot outperforms the state-of-the-art EIF methods by a sizable margin in both success rate and execution efficiency."
    }
]
[
    {
        "title": "Stabilized Neural Prediction of Potential Outcomes in Continuous Time",
        "link_suffix": "/forum?id=aN57tSd5Us",
        "link": "https://openreview.net/forum?id=aN57tSd5Us",
        "pdf_link": "https://openreview.net/pdf?id=aN57tSd5Us",
        "keywords": "causal inference, potential outcomes, continuous time, treatment effects, inverse propensity weighting, confounding, medicine",
        "abstract": "Patient trajectories from electronic health records are widely used to predict potential outcomes of treatments over time, which then allows for personalizing care. Yet, existing neural methods for this purpose have a key limitation: while some adjust for time-varying confounders, these methods assume that the time series are recorded in discrete time. In other words, they are constrained to settings where measurements and treatments are conducted at fixed time steps, even though this is unrealistic in medical practice. In this work, we aim to predict potential outcomes in continuous time. The latter is of direct practical relevance because it allows for modeling patient trajectories where measurements and treatments take place at arbitrary, irregular timestamps. We thus propose a new method called stabilized continuous time inverse propensity network (SCIP-Net), for which we derive stabilized inverse propensity weights for robust prediction of the potential outcomes. To the best of our knowledge, our SCIP-Net is the first the first neural method that performs proper adjustments for time-varying confounders in continuous time."
    },
    {
        "title": "UIFace: Unleashing Inherent Model Capabilities to Enhance Intra-Class Diversity in Synthetic Face Recognition",
        "link_suffix": "/forum?id=riieAeQBJm",
        "link": "https://openreview.net/forum?id=riieAeQBJm",
        "pdf_link": "https://openreview.net/pdf?id=riieAeQBJm",
        "keywords": "face recognition, face image synthesis, diffusion model",
        "abstract": "Face recognition (FR) stands as one of the most crucial applications in computer vision. The accuracy of FR models has significantly improved in recent years due to the availability of large-scale human face datasets. However, directly using these datasets can inevitably lead to privacy and legal problems. Generating synthetic data to train FR models is a feasible solution to circumvent these issues. While existing synthetic-based face recognition methods have made significant progress in generating identity-preserving images, they are severely plagued by context overfitting, resulting in a lack of intra-class diversity of generated images and poor face recognition performance. In this paper, we propose a framework to $\\textbf{U}$nleash model $\\textbf{I}$nherent capabilities to enhance intra-class diversity for synthetic face recognition, shorted as $\\textbf{UIFace}$. Our framework first train a diffusion model that can perform denoising conditioned on either identity contexts or a learnable empty context. The former generates identity-preserving images but lacks variations, while the latter exploits the model's intrinsic ability to synthesize intra-class-diversified images but with random identities. Then we adopt a novel two-stage denoising strategy to fully leverage the strengths of both type of contexts, resulting in images that are diverse as well as identity-preserving. Moreover, an attention injection module is introduced to further augment the intra-class variations by utilizing attention maps from the empty context to guide the denoising process in ID-conditioned generation. Experiments show that our method significantly surpasses previous approaches with even less training data and half the size of synthetic dataset. More surprisingly, the proposed $\\textbf{UIFace}$ even achieves comparable performance of FR models trained on real datasets when we increase the number of synthetic identities."
    },
    {
        "title": "Geometrically Constrained Gaussian Splatting SLAM",
        "link_suffix": "/forum?id=w1Pwcx5hPp",
        "link": "https://openreview.net/forum?id=w1Pwcx5hPp",
        "pdf_link": "https://openreview.net/pdf?id=w1Pwcx5hPp",
        "keywords": "3DGS, SLAM, Robotics",
        "abstract": "3D Gaussian Splatting (3DGS) has emerged as a promising technique in SLAM due to its rapid and high-quality rendering capabilities. However, its reliance on discrete Gaussian ellipsoid primitives limits its effectiveness in capturing essential geometric features crucial for accurate pose estimation. To overcome this limitation, we propose a novel dense RGB-D SLAM system that integrates an implicit Truncated Signed Distance Function (TSDF) hash grid to constrain the distribution of Gaussian ellipsoids. This innovative approach enables precise estimation of the scene's geometric structure by smoothing the discrete Gaussian ellipsoids and anchoring them to the scene's surface. Acting as a low-pass filter, the implicit TSDF hash grid mitigates the inductive biases inherent in traditional 3DGS methods while preserving rendering quality. Our geometrically constrained map also significantly enhances generalization capabilities for depth estimation in novel views. Extensive experiments on the Replica, ScanNet, and TUM datasets demonstrate that our system achieves state-of-the-art tracking and mapping accuracy at speeds up to 30 times faster than existing 3DGS-based systems."
    },
    {
        "title": "FlashRNN: I/O-Aware Optimization of Traditional RNNs on modern hardware",
        "link_suffix": "/forum?id=l0ZzTvPfTw",
        "link": "https://openreview.net/forum?id=l0ZzTvPfTw",
        "pdf_link": "https://openreview.net/pdf?id=l0ZzTvPfTw",
        "keywords": "RNN, LSTM, Sequence Models, GPU, Hardware Optimization",
        "abstract": "While Transformers and other sequence-parallelizable neural network architectures seem like the current state of the art in sequence modeling, they specifically lack state-tracking capabilities. These are important for time-series tasks and logical reasoning. Traditional RNNs like LSTMs and GRUs, as well as modern variants like sLSTM do have these capabilities at the cost of strictly sequential processing. While this is often seen as a strong limitation, we show how fast these networks can get with our hardware-optimization FlashRNN in Triton and CUDA, optimizing kernels to the register level on modern GPUs. We extend traditional RNNs with a parallelization variant that processes multiple RNNs of smaller hidden state in parallel, similar to the head-wise processing in Transformers. To enable flexibility on different GPU variants, we introduce a new optimization framework for hardware-internal cache sizes, memory and compute handling. It models the hardware in a setting using polyhedral-like constraints, including the notion of divisibility. This speeds up the solution process in our ConstrINT library for general integer constraint satisfaction problems (integer CSPs).\nWe show that our kernels can achieve 50x speed-ups over a vanilla PyTorch implementation and allow 40x larger hidden sizes compared to our Triton implementation. We will open-source our kernels and the optimization library to boost research in the direction of state-tracking enabled RNNs and sequence modeling."
    },
    {
        "title": "Power of Augmented Replicas in Out-Of-Distribution Detection",
        "link_suffix": "/forum?id=cLj51OYBsh",
        "link": "https://openreview.net/forum?id=cLj51OYBsh",
        "pdf_link": "https://openreview.net/pdf?id=cLj51OYBsh",
        "keywords": "Data Augmentation, Out-of-Distribution Detection (OOD), trustworthy ML",
        "abstract": "Data augmentation is widely used in machine learning to enhance training datasets by introducing minor variations to the original data, traditionally aiming to prevent overfitting and improve model performance. This paper explores a novel application of data augmentation during the inference stage to enhance out-of-distribution (OOD) detection. The proposed method involves replicating the inference image multiple times, applying various transformation techniques to each replica, and then evaluating the detectors using these augmented images. The effectiveness of this approach is assessed across different detectors, models, and datasets, demonstrating its potential to improve OOD detection capabilities."
    },
    {
        "title": "MuseTalk: Real-Time High Quality Lip Synchronization with Latent Space Inpainting",
        "link_suffix": "/forum?id=n20n1hojPg",
        "link": "https://openreview.net/forum?id=n20n1hojPg",
        "pdf_link": "https://openreview.net/pdf?id=n20n1hojPg",
        "keywords": "talking face, face visual dubbing, generative models, multimodality, AI-generated content",
        "abstract": "Achieving high-resolution, identity consistency, and accurate lip-speech synchronization in face visual dubbing presents significant challenges, particularly for real-time applications like live video streaming. We propose MuseTalk, which generates lip-sync targets in a latent space encoded by a Variational Autoencoder, enabling high-fidelity talking face video generation with efficient inference. Specifically, we project the occluded lower half of the face image and itself as an reference into a low-dimensional latent space and use a multi-scale U-Net to fuse audio and visual features at various levels. We further propose a novel sampling strategy during training, which selects reference images with head poses closely matching the target, allowing the model to focus on precise lip movement by filtering out redundant information. Additionally, we analyze the mechanism of lip-sync loss and reveal its relationship with input information volume. Extensive experiments show that MuseTalk consistently outperforms recent state-of-the-art methods in visual fidelity and achieves comparable lip-sync accuracy. As MuseTalk supports the online generation of face at 256x256 at more than 30 FPS with negligible starting latency, it paves the way for real-time applications. The codes and models will be made publicly available upon acceptance."
    },
    {
        "title": "Improving Nonlinear Projection Heads using Pretrained Autoencoder Embeddings",
        "link_suffix": "/forum?id=f89YIjbuRC",
        "link": "https://openreview.net/forum?id=f89YIjbuRC",
        "pdf_link": "https://openreview.net/pdf?id=f89YIjbuRC",
        "keywords": "Nonlinear Projection Heads, Multilayer Perceptrons, Autoencoder Embeddings, SimCLR Framework, Contrastive Learning, Representation Learning",
        "abstract": "This empirical study aims at improving the effectiveness of the standard 2-layer MLP projection head $g(\\cdot)$ featured in the SimCLR framework through the use of pretrained autoencoder embeddings. Given a contrastive learning task with a largely unlabeled image classification dataset, we first train a shallow autoencoder architecture and extract its compressed representations contained in the encoder's embedding layer. After freezing the weights within this pretrained layer, we use it as a drop-in replacement for the input layer of SimCLR's default projector. Additionally, we also apply further architectural changes to the projector by decreasing its width and changing its activation function. The different projection heads are then used to contrastively train and evaluate a feature extractor $f(\\cdot)$ following the SimCLR protocol, while also examining the performance impact of $Z$-score normalized datasets. Our experiments indicate that using a pretrained autoencoder embedding in the projector can not only increase classification accuracy by up to 2.9% or 1.7% on average but can also significantly decrease the dimensionality of the projection space. Our results also suggest, that using the sigmoid and $\\tanh$ activation functions within the projector can outperform ReLU in terms of peak and average classification accuracy. When applying our presented projectors, then not applying $Z$-score normalization to datasets often increases peak performance. In contrast, the default projection head can benefit more from normalization. All experiments involving our pretrained projectors are conducted with frozen embeddings, since our test results indicate an advantage compared to using their non-frozen counterparts."
    },
    {
        "title": "Delay-Aware Reinforcement Learning: Insights From Delay Distributional Perspective",
        "link_suffix": "/forum?id=Y9cVrdYn10",
        "link": "https://openreview.net/forum?id=Y9cVrdYn10",
        "pdf_link": "https://openreview.net/pdf?id=Y9cVrdYn10",
        "keywords": "Reinforcement Learning, Random Delays, Value Correction, SAC",
        "abstract": "Although deep reinforcement learning (DRL) has achieved great success across various domains, the presence of random delays in real-world scenarios (e.g., remote control) poses a significant challenge to its practicality. Existing delay-aware DRLs mainly focus on state augmentation with historical memory, ensuring that the actions taken are aligned with the true state. However, these approaches still rely on the conventional expected $Q$ value. In contrast, to model delay uncertainty, we aim to go beyond the expected value and propose a distributional DRL to represent the distribution of this $Q$ value. Based on the delay distribution, we further propose a correction mechanism for the distributional $Q$ value, enabling the agent to learn accurate returns in delayed environments. Finally, we apply these techniques to design the delay-aware distributional actor-critic (DADAC) DRL framework, in which the critic is the corrected distributional value function. Experimental results demonstrate that compared to the state-of-the-art delay-aware DRL methods, the proposed DADAC exhibits substantial performance advantages in handling random delays in the MuJoCo continuous control tasks. The corresponding source code is available athttps://anonymous.4open.science/r/DADAC."
    },
    {
        "title": "Residual Deep Gaussian Processes on Manifolds",
        "link_suffix": "/forum?id=JWtrk7mprJ",
        "link": "https://openreview.net/forum?id=JWtrk7mprJ",
        "pdf_link": "https://openreview.net/pdf?id=JWtrk7mprJ",
        "keywords": "Gaussian processes, manifolds, deep Gaussian processes, probabilistic methods, variational inference, uncertainty quantification, geometric learning",
        "abstract": "We propose practical deep Gaussian process models on Riemannian manifolds, similar in spirit to residual neural networks.\nWith manifold-to-manifold hidden layers and an arbitrary last layer, they can model manifold- and scalar-valued functions, as well as vector fields.\nWe target data inherently supported on manifolds, which is too complex for shallow Gaussian processes thereon.\nFor example, while the latter perform well on high-altitude wind data, they struggle with the more intricate, nonstationary patterns at low altitudes.\nOur models significantly improve performance in these settings, enhancing prediction quality and uncertainty calibration, and remain robust to overfitting, reverting to shallow models when additional complexity is unneeded.\nWe further showcase our models on Bayesian optimisation problems on manifolds, using stylised examples motivated by robotics, and obtain substantial improvements in later stages of the optimisation process.\nFinally, we show our models to have potential for speeding up inference for non-manifold data, when, and if, it can be mapped to a proxy manifold well enough."
    },
    {
        "title": "Robustness through Random Activation: Adversarial Training with  Bernoulli Rectified Linear Units",
        "link_suffix": "/forum?id=eiIM576lpj",
        "link": "https://openreview.net/forum?id=eiIM576lpj",
        "pdf_link": "https://openreview.net/pdf?id=eiIM576lpj",
        "keywords": "Adversarial training, Adversarial attack, Activation function",
        "abstract": "Despite their considerable achievements across a range of domains, deep learning models have been demonstrated to be susceptible to adversarial attacks.\nIn order to mitigate this vulnerability, adversarial training has become a prevalent defense strategy. \nIn this context, we propose Bernoulli Rectified Linear Units (BReLU), an activation function designed to further enhance the effectiveness of adversarial training. In contrast to conventional activation functions, BReLU modulates activation probabilities in accordance with input values, thereby introducing input-dependent randomness into the model.\nThe experimental results demonstrate that the incorporation of BReLU into adversarial training significantly enhances the robustness of the model against adversarial attacks. Specifically, on the CIFAR-10 dataset using the ResNet-18 model, BReLU improved robustness by 15% under FGSM, by 8% under PGD-20, and  by 54% under the CW attack compared to ReLU.\nOur findings indicate that BReLU represents a promising addition to adversarial training techniques for strengthening deep learning models against adversarial threats."
    },
    {
        "title": "Flow Tree: A dynamic model for navigation paths and strategies",
        "link_suffix": "/forum?id=evyIlAvQ6J",
        "link": "https://openreview.net/forum?id=evyIlAvQ6J",
        "pdf_link": "https://openreview.net/pdf?id=evyIlAvQ6J",
        "keywords": "dynamics, navigation, behavior, trees, mazes, cognitive representation, neuroscience",
        "abstract": "Navigation is a dynamic process that involves learning how to represent the environment, along with positions in and trajectories through it. Spatial navigation skills vary significantly among individual humans. But what exactly differentiates a good navigator from a bad one, or an easy-to-navigate path from a hard one, is not well understood. Several studies have analysed exploration and navigation behaviour using static quantitative measures, like counts of positions visited or distance travelled. These static measures, however, are inherently limited in their ability to describe dynamic behaviors, providing a coarse quantification of the navigation process. To fill this gap, we introduce the \\emph{Flow Tree}, a novel data structure, which quantifies the dynamics of a group of trajectories through time. This is a discrete adaptation of the Reeb graph, a mathematical structure from topology, computed from multiple trajectories (from different people or the same person over time). Each divergence in trajectory is captured as a node, encoding the variability of the collection of trajectories. A Flow Tree encodes how difficult it will be to navigate a certain path for a group of humans. We apply the Flow Tree to a behavioural dataset of 100 humans exploring and then navigating a small, closed-form maze in virtual reality. In this paper we (1) describe what a Flow Tree is and how to calculate it, (2) show that Flow Trees can be used to predict path difficulty more effectively than static metrics, and (3) demonstrate that a trajectory through the Flow Tree is predictive of that individual's success. We (4) introduce a hypothesis testing framework over Flow Trees to quantitatively differentiate between the strategies of the best navigators from those of worst. Thus, we show that Flow Trees are a powerful tool to analyse dynamic trajectory data.\\footnote{The code will be made publicly available at [anon-github-link].}"
    },
    {
        "title": "Visual Scratchpads: Enabling Global Reasoning in Vision",
        "link_suffix": "/forum?id=wdmI6A9d2w",
        "link": "https://openreview.net/forum?id=wdmI6A9d2w",
        "pdf_link": "https://openreview.net/pdf?id=wdmI6A9d2w",
        "keywords": "reasoning, scratchpad, vision, visual reasoning",
        "abstract": "Modern vision models have achieved remarkable success in benchmarks where a small subset of local features provides critical information about the target. There is now a growing interest in solving tasks that require more global reasoning, where local features offer no significant information. These tasks are reminiscent of the connectivity problems discussed by Minsky and Papert in 1969, which exposed the limitations of the perceptron model and contributed to the first AI winter. In this paper, we revisit such tasks by introducing four global visual benchmarks involving path findings and mazes. \nWe show the following: (1) Although today's large vision models largely surpass the expressivity limitations of the early models, they still struggle with learning efficiency; we introduce the 'globality degree' to understand this; (2) we then demonstrate that the outcome changes and global reasoning becomes feasible with the introduction of a 'visual scratchpad'; similarly to the text scratchpads and chain-of-thoughts used in language models, visual scratchpads help break down global problems into simpler subproblems; (3) we further show that more specific 'inductive scratchpads', which take steps relying on less information, afford better out-of-distribution generalization and succeed for smaller model sizes."
    },
    {
        "title": "Dream to Manipulate: Compositional World Models Empowering Robot Imitation Learning with Imagination",
        "link_suffix": "/forum?id=3RSLW9YSgk",
        "link": "https://openreview.net/forum?id=3RSLW9YSgk",
        "pdf_link": "https://openreview.net/pdf?id=3RSLW9YSgk",
        "keywords": "World model;  Imagination; Imitation Learning; Gaussian Splatting; Compositional; Physics-informed; Object-centric;",
        "abstract": "A world model provides an agent with a representation of its environment, enabling it to predict the causal consequences of its actions. Current world models typically cannot directly and explicitly imitate the actual environment in front of a robot, often resulting in unrealistic behaviors and hallucinations that make them unsuitable for real-world applications. In this paper, we introduce a new paradigm for constructing world models that are explicit representations of the real world and its dynamics. By integrating cutting-edge advances in real-time photorealism with Gaussian Splatting and physics simulators, we propose the first compositional manipulation world model, which we call DreMa. DreMa replicates the observed world and its dynamics, allowing it to imagine novel configurations of objects and predict the future consequences of robot actions. We leverage this capability to generate new data for imitation learning by applying equivariant\ntransformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in both accuracy and robustness by incrementing actions and object distributions, reducing the data needed to learn a policy and improving the generalization of the agents. As a highlight, we show that a real Franka Emika Panda robot, powered by DreMa \u2019s imagination, can\nsuccessfully learn novel physical tasks from just a single example per task variation (one-shot policy learning). Our project page and source code can be found in:https://dreamtomanipulate.github.io/DreMa/."
    },
    {
        "title": "Inverse Rendering for Shape, Light, and Material Decomposition using Multi-Bounce Path Tracing and Reservoir Sampling",
        "link_suffix": "/forum?id=KEXoZxTwbr",
        "link": "https://openreview.net/forum?id=KEXoZxTwbr",
        "pdf_link": "https://openreview.net/pdf?id=KEXoZxTwbr",
        "keywords": "Inverse Rendering, Material Decomposition, 3D reconstruction, relighting",
        "abstract": "We present a novel two-stage inverse rendering framework that jointly reconstructs and optimizes explicit geometry, materials, and lighting from multi-view images. \nUnlike previous methods that rely on implicit irradiance fields or oversimplified path tracing algorithms, our method first extracts an explicit triangular mesh in the initial stage. \nSubsequently, it employs a more realistic physically-based inverse rendering model in the second stage, utilizing multi-bounce path tracing and Monte Carlo integration. \nBy leveraging multi-bounce path tracing, our method not only effectively estimates indirect illumination (including self-shadowing and internal reflections). but also enhances the intrinsic decomposition of shape,\nmaterial, and lighting. Moreover, we incorporate reservoir sampling into our framework to address the noise in Monte Carlo integration, enhancing convergence and facilitating gradient-based optimization with low sample counts. \nThrough both qualitative and quantitative assessments across various scenarios, especially those with complex shadows, we demonstrate that our method achieves state-of-the-art performance in decomposition results.\nAdditionally, our optimized explicit geometry supports further applications in scene editing, relighting, and material editing, compatible with modern graphics engines and CAD software."
    },
    {
        "title": "DA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation On Diverse Modalities",
        "link_suffix": "/forum?id=FWqTha5Jh9",
        "link": "https://openreview.net/forum?id=FWqTha5Jh9",
        "pdf_link": "https://openreview.net/pdf?id=FWqTha5Jh9",
        "keywords": "Benchmark, Unsupervised Domain Adaptation, Model selection",
        "abstract": "Unsupervised Domain Adaptation (DA) consists of adapting a model trained on a labeled source domain to perform well on an unlabeled target domain with some data distribution shift.\nWhile many methods have been proposed in the literature, fair and realistic evaluation remains an open question, particularly due to methodological difficulties in selecting hyperparameters in the unsupervised setting.\nWith DA-Bench, we propose a framework to evaluate DA methods on diverse modalities, beyond computer vision task that have been largely explored in the literature. We present a complete and fair evaluation of existing shallow algorithms, including reweighting, mapping, and subspace alignment.\nRealistic hyperparameter selection is performed with nested cross-validation and various unsupervised model selection scores, on both simulated datasets with controlled shifts and real-world datasets across diverse modalities, such as images, text, biomedical, and tabular data.\nOur benchmark highlights the importance of realistic validation and provides practical guidance for real-life applications, with key insights into the choice and impact of model selection approaches.\nDA-Bench is open-source, reproducible, and can be easily extended with novel DA methods, datasets, and model selection criteria without requiring re-evaluating competitors."
    },
    {
        "title": "ProteinAdapter: Adapting Pre-trained Large Protein Models for Efficient Protein Representation Learning",
        "link_suffix": "/forum?id=jqx5XI4Yr3",
        "link": "https://openreview.net/forum?id=jqx5XI4Yr3",
        "pdf_link": "https://openreview.net/pdf?id=jqx5XI4Yr3",
        "keywords": "Protein Representation, Structured State Space Models",
        "abstract": "The study of proteins is crucial in various scientific disciplines, but understanding their intricate multi-level relationships remains challenging. Inspired by the sequence and structure understanding of Large Protein Models (LPMs), we introduce a new ProteinAdapter, to efficiently transfer the broad knowledge encapsulated in multiple LPMs, e.g., ESM-1b, to task-specific insights. ProteinAdapter could largely save labor-intensive analysis on the 3D position and the amino acid order. Specifically, (1) with a modest number of additional parameters, ProteinAdapter facilitates multi-level protein representation learning by integrating both sequence and geometric structure embeddings from LPMs; (2) based on the learned embedding, we further scale up the proposed ProteinAdapter to various tasks with a unified Multi-Scale Predictor, which optimally harnesses the learned embeddings through task-specific attention. Albeit simple, the proposed method is scalable to multiple downstream tasks without bells and whistles. Extensive experiments on over 20 tasks show that ProteinAdapter outperforms state-of-the-art methods under both single-task and multi-task scenarios."
    },
    {
        "title": "Spike No More: Stabilizing the Pre-training of Large Language Models",
        "link_suffix": "/forum?id=G84F1h2IiD",
        "link": "https://openreview.net/forum?id=G84F1h2IiD",
        "pdf_link": "https://openreview.net/pdf?id=G84F1h2IiD",
        "keywords": "neural language model, transformer, llm",
        "abstract": "Loss spikes often occur during pre-training of large language models.\nThe spikes degrade the performance of large language models and sometimes ruin the pre-training.\nSince the pre-training needs a vast computational budget, we should avoid such spikes.\nBased on the assumption that the loss spike is caused by the sudden growth of the gradient norm, we explore factors to keep the gradient norm small through an analysis of the spectral norms of the Jacobian matrices for the sub-layers.\nOur findings suggest that stabilizing the pre-training process requires two conditions: small sub-layers and large shortcut.\nWe conduct various experiments to empirically verify our theoretical analyses.\nExperimental results demonstrate that methods satisfying the conditions effectively prevent loss spikes during pre-training."
    },
    {
        "title": "Local Control Networks (LCNs): Optimizing Flexibility in Neural Network Data Pattern Capture",
        "link_suffix": "/forum?id=wYVP4g8Low",
        "link": "https://openreview.net/forum?id=wYVP4g8Low",
        "pdf_link": "https://openreview.net/pdf?id=wYVP4g8Low",
        "keywords": "Optimization, Learning Representation, Neural Network, Activation Function",
        "abstract": "The widespread use of multilayer perceptrons (MLPs) often relies on a fixed activation function (e.g., ReLU, Sigmoid, Tanh) for all nodes within the hidden layers. While effective in many scenarios, this uniformity may limit the network\u2019s ability to capture complex data patterns. We argue that employing the same activation function at every node is suboptimal and propose leveraging different activation functions at each node to increase flexibility and adaptability. To achieve this, we introduce Local Control Networks (LCNs), which leverage B-spline functions to enable distinct activation curves at each node. Our mathematical analysis demonstrates the properties and benefits of LCNs over conventional MLPs. In addition, we demonstrate that more complex architectures, such as Kolmogorov\u2013Arnold Networks (KANs), are unnecessary in certain scenarios, and LCNs can be a more efficient alternative. Empirical experiments on various benchmarks and datasets validate our theoretical findings. In computer vision tasks, LCNs achieve marginal improvements over MLPs and outperform KANs by approximately 5%, while also being more computationally efficient than KANs. In basic machine learning tasks, LCNs show a 1% improvement over MLPs and a 0.6% improvement over KANs. For symbolic formula representation tasks, LCNs perform on par with KANs, with both architectures outperforming MLPs. Our findings suggest that diverse activations at the node level can lead to improved performance and efficiency."
    },
    {
        "title": "The Computational Complexity of Circuit Discovery for Inner Interpretability",
        "link_suffix": "/forum?id=QogcGNXJVw",
        "link": "https://openreview.net/forum?id=QogcGNXJVw",
        "pdf_link": "https://openreview.net/pdf?id=QogcGNXJVw",
        "keywords": "inner interpretability, mechanistic interpretability, circuit discovery, computational complexity, parameterized complexity",
        "abstract": "Many proposed applications of neural networks in machine learning, cognitive/brain science, and society hinge on the feasibility of inner interpretability via circuit discovery. This calls for empirical and theoretical explorations of viable algorithmic options. Despite advances in the design and testing of heuristics, there are concerns about their scalability and faithfulness at a time when we lack understanding of the complexity properties of the problems they are deployed to solve. To address this, we study circuit discovery with classical and parameterized computational complexity theory: (1) we describe a conceptual scaffolding to reason about circuit finding queries in terms of affordances for description, explanation, prediction and control; (2) we formalize a comprehensive set of queries that capture mechanistic explanation, and propose a formal framework for their analysis; (3) we use it to settle the complexity of many query variants and relaxations of practical interest on multi-layer perceptrons (part of, e.g., transformers). Our findings reveal a challenging complexity landscape. Many queries are intractable (NP-hard, $\\Sigma^p_2$-hard), remain fixed-parameter intractable (W[1]-hard) when constraining model/circuit features (e.g., depth), and are inapproximable under additive, multiplicative, and probabilistic approximation schemes. To navigate this landscape, we prove there exist transformations to tackle some of these hard problems (NP- vs. $\\Sigma^p_2$-complete) with better-understood heuristics, and prove the tractability (PTIME) or fixed-parameter tractability (FPT) of more modest queries which retain useful affordances. This framework allows us to understand the scope and limits of interpretability queries, explore viable options, and compare their resource demands among existing and future architectures."
    },
    {
        "title": "GeoILP: A Synthetic Dataset to Guide Large-Scale Rule Induction",
        "link_suffix": "/forum?id=cfGpIcOIa5",
        "link": "https://openreview.net/forum?id=cfGpIcOIa5",
        "pdf_link": "https://openreview.net/pdf?id=cfGpIcOIa5",
        "keywords": "inductive logic programming, rule induction, dataset",
        "abstract": "Inductive logic programming (ILP) is a machine learning approach aiming to learn explanatory rules from data.\n    While existing ILP systems can successfully solve small-scale tasks, large-scale applications with various language biases are rarely explored.\n    Besides, it is crucial for a large majority of current ILP systems to require expert-defined language bias, which hampers the development of ILP towards broader utilizations.\n    In this paper, we introduce GeoILP, a large-scale synthetic dataset of diverse ILP tasks involving numerous aspects of language bias.\n    % including complex rule forms, high deduction complexity, and more realistic assumptions.\n    The ILP tasks are built from geometry problems, at the level from textbook exercise to regional International Mathematical Olympiad (IMO), with the help of a deduction engine.\n    These problems are elaborately selected to cover all challenging language biases, such as recursion, predicate invention, and high arity.\n    Experimental results show that no existing method can solve GeoILP tasks.\n    In addition, along with classic symbolic-form data, we provide image-form data to boost the development of the joint learning of neural perception and symbolic rule induction."
    },
    {
        "title": "Perceptogram: Visual Reconstruction from EEG Using Image Generative Models",
        "link_suffix": "/forum?id=IZOeRDS6zU",
        "link": "https://openreview.net/forum?id=IZOeRDS6zU",
        "pdf_link": "https://openreview.net/pdf?id=IZOeRDS6zU",
        "keywords": "visual-evoked potentials, electroencephalography, EEG, visual reconstruction, visual representations, spatiotemporal semantic map",
        "abstract": "In this work, we reconstruct viewed images from EEG recordings with state-of-the-art quantitative reconstruction performance using a linear decoder that maps the EEG to image latents. We choose latent diffusion guided by CLIP embedding as the primary method of image reconstruction as it is currently the most effective at capturing visual semantics. We also explore reconstruction results from a latent space of  PCA and ICA components, which capture luminance and hue-related information from the EEG. The linear model provides interpretable EEG features relevant for differentiating general semantic categories of the images.  We create spatiotemporal semantic maps that reflect the temporal evolution of class-relevant semantic information over time."
    },
    {
        "title": "Auditing Privacy Protection of Machine Unlearning",
        "link_suffix": "/forum?id=Uv7bWrIucU",
        "link": "https://openreview.net/forum?id=Uv7bWrIucU",
        "pdf_link": "https://openreview.net/pdf?id=Uv7bWrIucU",
        "keywords": "Machine unlearning, Auditing privacy, Privacy estimation, Membership inference attack",
        "abstract": "Machine unlearning aims to remove the effect of specific data from trained models to ensure individuals\u2019 privacy. However, it\u2019s arguable how to evaluate whether the privacy protection goal is achieved by machine unlearning. Furthermore, recent studies show unlearning may also increase the retained samples\u2019 privacy risks. This paper takes a holistic approach to auditing both unlearned and retained samples\u2019 privacy risks before and after unlearning. \nWe derive the privacy criteria for unlearned and retained samples, respectively, based on the perspectives of differential privacy and membership inference attacks. To make the auditing practical, we also develop an efficient membership inference attack, A-LiRA, utilizing data augmentation to reduce the cost of shadow model training. Our experimental findings indicate that existing machine unlearning algorithms do not consistently protect the privacy of unlearned samples and may inadvertently compromise the privacy of retained samples. For reproducibility, we have pubished our code.\\footnote{ \\url{https://anonymous.4open.science/r/Auditing-machine-unlearning-CB10/README.md}}"
    },
    {
        "title": "UNICORNN: Unimodal Calibrated Ordinal Regression Neural Network",
        "link_suffix": "/forum?id=dMj3SDNxn4",
        "link": "https://openreview.net/forum?id=dMj3SDNxn4",
        "pdf_link": "https://openreview.net/pdf?id=dMj3SDNxn4",
        "keywords": "unimodality, ordinal regression, probability calibration, deep learning",
        "abstract": "Ordinal regression is a supervised machine learning technique aimed at predicting the value of a discrete dependent variable with an ordered set of possible outcomes. Many of the algorithms that have been developed to address this issue rely on maximum likelihood for training. However, the standard maximum likelihood approach often fails to adequately capture the inherent order of classes, even though it tends to produce well-calibrated probabilities. Alternatively, some methods use Optimal Transport (OT) divergence as their training objective. Unlike maximum likelihood, OT accounts for the ordering of classes; however, in this manuscript, we show that it doesn't always yield well-calibrated probabilities. To overcome these limitations, we introduce UNICORNN, an approach inspired by the well-known Proportional Odds Model, which offers three key guarantees: (i) it ensures unimodal output probabilities, a valuable feature for many real-world applications;\n(ii) it employs OT loss during training to accurately capture the natural order of classes;\n(iii) it provides well-calibrated probability estimates through a post-training accuracy-preserving calibration step.\nExperimental results on six real-world datasets \ndemonstrate that UNICORNN consistently either outperforms or performs as well as recently proposed deep learning approaches for ordinal regression. It excels in both accuracy and probability calibration, while also guaranteeing output unimodality. The code will be publicly available upon acceptance."
    },
    {
        "title": "Pretraining A Shared Q-Network for Data Efficient Offline Reinforcement Learning",
        "link_suffix": "/forum?id=p5o0sbE5kY",
        "link": "https://openreview.net/forum?id=p5o0sbE5kY",
        "pdf_link": "https://openreview.net/pdf?id=p5o0sbE5kY",
        "keywords": "Offline RL, Data Efficiency, Pretraining Q network",
        "abstract": "Recent breakthroughs in supervised learning domains such as computer vision and natural language processing follow the consistent paradigm: pretrain a neural network with a large dataset and fine-tune it onto downstream tasks with a relatively small dataset. Offline reinforcement learning (RL) can be an alternative approach for learning the best policy with the static dataset in sequential decision-making problems, akin to supervised learning. Following the paradigm, previous works have focused on constructing a large dataset or pretraining networks with the static dataset and fine-tuning them with online interactions. However, it is still vague that offline RL can exhibit data efficiency, e.g. robustness to static dataset size. In this paper, we propose a simple yet effective plug-and-play method that pretrains a Q-network under an offline RL scheme, improving task performance and data efficiency. Our method consists of two core functionalities: Transforming the Q-network structure to a shared network architecture and pretraining weights of the shared network by a supervised regression task that predicts the forward dynamics of a task. We provide an analysis of how our method enables improved performance even in a small dataset in terms of the projected Bellman equation. We also empirically demonstrate that the proposed method improves the performance of existing popular offline RL methods on the D4RL and Robomimic benchmarks with an average improvement of $135.94$% on the D4RL benchmark. Moreover, we demonstrate the proposed method boosts data efficiency in offline RL with varying data collection strategies."
    },
    {
        "title": "GRASP: Generating  Graphs  via Spectral Diffusion",
        "link_suffix": "/forum?id=AAXBfJNHDt",
        "link": "https://openreview.net/forum?id=AAXBfJNHDt",
        "pdf_link": "https://openreview.net/pdf?id=AAXBfJNHDt",
        "keywords": "graph neural networks, laplacian, eigendecomposition, spectrum, diffusion model, generative model",
        "abstract": "In this paper, we present GRASP, a novel graph generative model based on 1) the spectral decomposition of the graph Laplacian matrix and 2) a diffusion process. Specifically, we propose to use a denoising model to sample eigenvectors and eigenvalues from which we can reconstruct the graph Laplacian and adjacency matrix. Using the Laplacian spectrum allows us to naturally capture the structural characteristics of the graph and work directly in the node space while avoiding the quadratic complexity bottleneck that limits the applicability of other diffusion-based methods. This, in turn, is accomplished by truncating the spectrum, which, as we show in our experiments, results in a faster yet accurate generative process and by designing a novel transformer-based architecture linear in the number of nodes. Our permutation invariant model can also handle node features by concatenating them to the eigenvectors of each node. An extensive set of experiments on both synthetic and real-world graphs demonstrates the strengths of our model against state-of-the-art alternatives."
    }
]
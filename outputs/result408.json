[{"title": "MixLinear: Extreme Low Resource Multivariate Time Series Forecasting with0.1kParameters", "link_suffix": "/forum?id=IFGtG1o2qj", "link": "https://openreview.net/forum?id=IFGtG1o2qj", "pdf_link": "https://openreview.net/pdf?id=IFGtG1o2qj", "keywords": "Time series analysis, Time series forecasting, Time domain decomposition, Frequency domain decomposition", "abstract": "In recent years, there has been a growing interest in Long-term Time Series Forecasting (LTSF), which involves predicting long-term future values by analyzing a large amount of historical time-series data to identify patterns and trends. There exist significant challenges in LTSF due to its complex temporal dependencies and high computational demands. Although the Transformer-based models offer high forecasting accuracy, they are often too compute-intensive to be deployed on devices with hardware constraints. On the other hand, the linear models aim to reduce the computational overhead by employing either decomposition methods in the time domain or compact representations in the frequency domain. \nIn this paper, we propose MixLinear, an ultra-lightweight multivariate time series forecasting model specifically designed for resource-constrained environments. MixLinear effectively captures both temporal and frequency domain features by modeling intra-segment and inter-segment variations in the time domain and extracting frequency variations from a low-dimensional latent space in the frequency domain. By reducing the parameter scale of a downsampled $n$-length input/output one-layer linear model from $O(n^2)$ to $O(n)$, MixLinear achieves efficient computation without sacrificing accuracy.\nExtensive evaluations across four benchmark datasets demonstrate that MixLinear attains forecasting performance comparable to, or surpassing, state-of-the-art models with significantly fewer parameters ($0.1K$), which makes it well-suited for deployment on devices with limited computational capacity.", "title_embedding_index": 20350, "title_abs_embedding_index": 20375}, {"title": "SSLA: A Generalized Attribution Method for Interpreting Self-Supervised Learning without Downstream Task Dependency", "link_suffix": "/forum?id=2bEjhK2vYp", "link": "https://openreview.net/forum?id=2bEjhK2vYp", "pdf_link": "https://openreview.net/pdf?id=2bEjhK2vYp", "keywords": "Interpretability, Attribution, Self-Supervised Learning", "abstract": "Self-Supervised Learning (SSL) is a crucial component of unsupervised tasks, enabling the learning of general feature representations without the need for labeled categories. However, our understanding of SSL tasks remains limited, and it is still unclear how SSL models extract key features from raw data. Existing interpretability methods are heavily reliant on downstream tasks, requiring information from these tasks to explain SSL models. This reliance blurs the line between interpreting the SSL model itself and the downstream task model. Moreover, these methods often require additional samples beyond the target of interpretation, introducing extra information that complicates the interpretability process.\nIn this paper, we propose three fundamental prerequisites for the interpretability of SSL tasks and design the Self-Supervised Learning Attribution (SSLA) algorithm that adheres to these prerequisites. SSLA redefines the interpretability objective by introducing a feature similarity measure, reducing the impact of randomness inherent in SSL algorithms, and achieving more stable interpretability results. Additionally, SSLA abstracts the interpretability process, making it independent of specific neural network architectures. To the best of our knowledge, SSLA is the first SSL interpretability method that does not rely on downstream tasks. We also redesign a more reasonable evaluation framework and establish baselines for comparative assessment. The source code for our implementation is publicly available athttps://anonymous.4open.science/r/SSLA-EF85.", "title_embedding_index": 20351, "title_abs_embedding_index": 20376}, {"title": "\u03b1-Divergence Loss Function for Neural Density Ratio Estimation", "link_suffix": "/forum?id=ZkDgQ2PDDm", "link": "https://openreview.net/forum?id=ZkDgQ2PDDm", "pdf_link": "https://openreview.net/pdf?id=ZkDgQ2PDDm", "keywords": "density ratio estimation, variational divergence optimization, $\\alpha$-divergence, Kullback\u2013Leibler divergence, and $f$-divergence.", "abstract": "Density ratio estimation (DRE) is a fundamental machine learning technique for capturing relationships between two probability distributions. State-of-the-art DRE methods estimate the density ratio using neural networks trained with loss functions derived from variational representations of $f$-divergence.\n   However, existing methods face optimization challenges, such as overfitting due to lower-unbounded loss functions, biased mini-batch gradients, vanishing training loss gradients, and high sample requirements for Kullback-Leibler (KL) divergence loss functions.\n   To address these issues, we focus on $\\alpha$-divergence, which provides a suitable variational representation of $f$-divergence.\n   Subsequently, a novel loss function for DRE, the $\\alpha$-divergence loss function ($\\alpha$-Div), is derived.\n      $\\alpha$-Div is concise but offers stable and effective optimization for DRE.\n   The boundedness of $\\alpha$-divergence provides the potential for successful DRE with data exhibiting high KL-divergence.\n      Our numerical experiments demonstrate the effectiveness in optimization using $\\alpha$-Div.\n   However, the experiments also show that the proposed loss function offers no significant advantage over the KL-divergence loss function in terms of RMSE for DRE. This indicates that the accuracy of DRE is\n primarily determined by the amount of KL-divergence in the data and is less dependent on $\\alpha$-divergence.", "title_embedding_index": 20352, "title_abs_embedding_index": 20377}, {"title": "Dynamic Cross-Layer Prefix Alignment for Resolving Label Preference Discrepancies in LLMs Fine-Tuning", "link_suffix": "/forum?id=pwilycD30m", "link": "https://openreview.net/forum?id=pwilycD30m", "pdf_link": "https://openreview.net/pdf?id=pwilycD30m", "keywords": "Label preference discrepancies, Cross-layer prefix sharing, Large language model fine-tuning", "abstract": "Fine-tuning large language models (LLMs) to adapt them for specialized downstream tasks is a common practice, yet existing methods overlook a critical issue: label preference discrepancies among different annotators. Such inconsistencies in labeling can significantly impair the model's robustness and generalization. In this work, we propose Dynamic Cross-Layer Preference Correction (DCPC), a novel self-supervised learning framework designed to mitigate these inconsistencies. DCPC incorporates a preference-sensitive similarity mechanism, cross-layer prefix alignment, and a Preference Correction Module (PCM) to dynamically adjust embeddings across transformer layers. By leveraging self-supervision, DCPC effectively aligns semantic representations and ensures consistency in label predictions, even in the presence of preference shifts. We evaluate DCPC across multiple tasks using prominent base models and introduce modified datasets that simulate real-world preference shifts. Our results show that DCPC consistently outperforms state-of-the-art Parameter-Efficient Fine-Tuning (PEFT) methods in handling label preference discrepancies.", "title_embedding_index": 20353, "title_abs_embedding_index": 20378}, {"title": "MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models", "link_suffix": "/forum?id=tZCqSVncRf", "link": "https://openreview.net/forum?id=tZCqSVncRf", "pdf_link": "https://openreview.net/pdf?id=tZCqSVncRf", "keywords": "inductive reasoning, large language model, model explanation", "abstract": "Inductive reasoning is an essential capability for large language models (LLMs) to achieve higher intelligence, which requires the model to generalize rules from observed facts and then apply them to unseen examples. We present {\\scshape Mirage}, a synthetic dataset that addresses the limitations of previous work, specifically the lack of comprehensive evaluation and flexible test data. In it, we evaluate LLMs' capabilities in both the inductive and deductive stages, allowing for flexible variation in input distribution, task scenario, and task difficulty to analyze the factors influencing LLMs' inductive reasoning. Based on these multi-faceted evaluations, we demonstrate that the LLM is a poor rule-based reasoner. In many cases, when conducting inductive reasoning, they do not rely on a correct rule to answer the unseen case. From the perspectives of different prompting methods, observation numbers, and task forms, models tend to consistently conduct correct deduction without correct inductive rules. Besides, we find that LLMs are good neighbor-based reasoners. In the inductive reasoning process, the model tends to focus on observed facts that are close to the current test example in feature space. By leveraging these similar examples, the model maintains strong inductive capabilities within a localized region, significantly improving its deductive performance.", "title_embedding_index": 20354, "title_abs_embedding_index": 20379}, {"title": "Feature Level Instance Attribution", "link_suffix": "/forum?id=fdvSCcB7i8", "link": "https://openreview.net/forum?id=fdvSCcB7i8", "pdf_link": "https://openreview.net/pdf?id=fdvSCcB7i8", "keywords": "Interpretability, attribution", "abstract": "Instance attribution has emerged as one of the most crucial methodologies for model explainability because it identifies training data that significantly impacts model predictions, thereby optimizing model performance and enhancing transparency and trustworthiness. The applications of instance attribution include data cleaning, where it identifies and rectifies poor-quality data to improve model outcomes, and in specific domains such as detection of harmful speech, social network graph labeling, and medical image annotation, it provides precise insights into how data influences model decisions. Specifically, current instance attribution methods facilitate the identification of causal relationships between training data and model predictions. A higher Instance-level Training Data Influence value (IL value) indicates that the training data used for the computation play a more significant role in the model's prediction process. However, the current methods can only indicate that a training sample is important, but they do not explain why this sample is important. A feasible algorithm is urgently needed to provide an explanation for this behavior. This paper discovers that artificially manipulating the attribution score by modifying samples (e.g., changing a pixel value in image data) can significantly intervene in the importance of training samples and yield explainability results at the feature-level during the intervention process. The proposed Feature Level Instance Attribution (FLIA) algorithm assists in identifying crucial feature locations in training data that significantly impact causality. To avoid the frequent retraining of models for evaluation, we introduce an unlearning algorithm as an assessment method and provide detailed empirical evidence of our algorithm's efficacy. To facilitate future research, we have made the code available at:https://anonymous.4open.science/r/FIIA-D60E/.", "title_embedding_index": 20355, "title_abs_embedding_index": 20380}, {"title": "PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training", "link_suffix": "/forum?id=j4LITBSUjs", "link": "https://openreview.net/forum?id=j4LITBSUjs", "pdf_link": "https://openreview.net/pdf?id=j4LITBSUjs", "keywords": "Multi-Modal Large Language Models, Hallucinations Mitigation, Hallucinations Evaluation, Language Model Priors", "abstract": "This paper aims to address the challenge of hallucinations in Multimodal Large Language Models (MLLMs)  particularly for dense image captioning tasks. To tackle the challenge, we identify the current lack of a metric that finely measures the caption quality in concept level. We hereby introduce HalFscore, a novel metric built upon the language graph and is designed to evaluate both the  accuracy and completeness of dense captions at a\ngranular level. Additionally, we identify the root cause of hallucination as the model's over-reliance on its language prior. To address this, we propose PerturboLLaVA, which reduces the model's reliance on the language prior by incorporating adversarially perturbed text during training. This method enhances the model's focus on visual inputs, effectively reducing hallucinations and producing accurate, image-grounded descriptions without incurring additional computational overhead.  PerturboLLaVA significantly improves the fidelity of generated captions, outperforming existing approaches in handling multimodal hallucinations and achieving improved performance across general multimodal benchmarks.", "title_embedding_index": 20356, "title_abs_embedding_index": 20381}, {"title": "Training Over a Distribution of Hyperparameters for Enhanced Performance and Adaptability on Imbalanced Classification", "link_suffix": "/forum?id=UZQl0rbxj6", "link": "https://openreview.net/forum?id=UZQl0rbxj6", "pdf_link": "https://openreview.net/pdf?id=UZQl0rbxj6", "keywords": "class imbalance, hyperparameter tuning, ROC curves, machine learning", "abstract": "Although binary classification is a well-studied problem, training reliable classifiers under severe class imbalance remains a challenge. Recent techniques mitigate the ill effects of imbalance on training by modifying the loss functions or optimization methods. We observe that different hyperparameter values on these loss functions perform better at different recall values. We propose to exploit this fact by training one model over a distribution of hyperparameter values--instead of a single value--via Loss Conditional Training (LCT). Experiments show that training over a distribution of hyperparameters not only approximates the performance of several models, but actually improves the overall performance of models on both CIFAR and real medical imaging applications such as melanoma and diabetic retinopathy detection. Furthermore, training models with LCT is more efficient because some hyperparameter tuning can be conducted after training to meet individual needs without needing to retrain from scratch. Code will be made available upon acceptance of this paper.", "title_embedding_index": 20357, "title_abs_embedding_index": 20382}, {"title": "One for all and all for one: Efficient computation of partial Wasserstein distances on the line", "link_suffix": "/forum?id=kzEPsHbJDv", "link": "https://openreview.net/forum?id=kzEPsHbJDv", "pdf_link": "https://openreview.net/pdf?id=kzEPsHbJDv", "keywords": "Optimal Transport, Partial Optimal Transport, Sliced Partial Optimal Transport", "abstract": "Partial Wasserstein helps overcoming some of the limitations of Optimal Transport when the distributions at stake differ in mass, contain noise or outliers or exhibit mass mismatches across distribution modes.\nWe introduce PAWL, a novel algorithm designed to efficiently compute exact PArtial Wasserstein distances on the Line. PAWL not only solves the partial transportation problem for a specified amount of mass to be transported, butfor alladmissible mass amounts. This flexibility is valuable for machine learning tasks where the level of noise is uncertain and may need to be determined through cross-validation, for example. \nBy achieving $O(n \\log n)$ time complexity for the partial 1-Wasserstein problem on the line, it enables practical applications with large scale datasets. \nAdditionally, we introduce a novel slicing strategy tailored to Partial Wasserstein, which does not permit transporting mass between outliers or noisy data points. Through empirical evaluations on both synthetic and real-world datasets, we demonstrate the advantages of PAWL in terms of computational efficiency and performance in downstream tasks, outperforming existing (sliced) Partial Optimal Transport techniques.", "title_embedding_index": 20358, "title_abs_embedding_index": 20383}, {"title": "Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning", "link_suffix": "/forum?id=Sc5rcsoyKR", "link": "https://openreview.net/forum?id=Sc5rcsoyKR", "pdf_link": "https://openreview.net/pdf?id=Sc5rcsoyKR", "keywords": "Contrastive Learning, Unsupervised Sentence Representation Learning, Few-shot Learning, NLP", "abstract": "Recently, using large language models (LLMs) for data augmentation has led to considerable improvements in unsupervised sentence embedding models. However, existing methods encounter two primary challenges: limited data diversity and high data noise. Current approaches often neglect fine-grained knowledge, such as entities and quantities, leading to insufficient diversity.  Additionally, unsupervised data frequently lacks discriminative information, and the generated synthetic samples may introduce noise. In this paper, we propose a pipeline-based data augmentation method via LLMs and introduce the Gaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) model to enhance unsupervised sentence embeddings. To tackle the issue of low data diversity, our pipeline utilizes knowledge graphs (KGs) to extract entities and quantities, enabling LLMs to generate more diverse, knowledge-enriched samples. To address high data noise, the GCSE model uses a Gaussian-decayed function to limit the impact of false hard negative samples, enhancing the model's discriminative capability. Experimental results show that our approach achieves state-of-the-art performance in semantic textual similarity (STS) tasks, using fewer data samples and smaller LLMs, demonstrating its efficiency and robustness across various models.", "title_embedding_index": 20359, "title_abs_embedding_index": 20384}, {"title": "Slerp+: Spherical Linear Interpolation for Unified Compositional Retrieval", "link_suffix": "/forum?id=YCOVTlMFIG", "link": "https://openreview.net/forum?id=YCOVTlMFIG", "pdf_link": "https://openreview.net/pdf?id=YCOVTlMFIG", "keywords": "multi-modal representation learning, composed retrieval", "abstract": "Zero-shot composed image/video retrieval is a challenging task that involves using a combination of a reference visual input and a relative caption as a query to search for target visual data. Earlier studies have treated composed image retrieval and composed video retrieval methods separately, potentially neglecting the benefits of integrating image-video-text representation learning.  In this paper, we consolidate these tasks into a single Composed \\emph{Visual} Retrieval (CVR) task, which requires the composition of image and video samples with textual modifications using a unified retrieval model. Our principal insight is that the video modality can be effectively added to existing vision-language pretrained models. When integrated with the Spherical Linear Interpolation (Slerp) method previously proposed for Composed Image Retrieval (CoIR), we found that it results in an effective approach for solving the CVR task, which we called $\\text{Slerp}^{+}$. Extensive experiments demonstrate $\\text{Slerp}^{+}$'s superiority across various composed image and video retrieval benchmarks, including our newly proposed video benchmark. Notably, $\\text{Slerp}^{+}$ mutually enhances image and video retrieval performance over single-modality models, underscoring its potential to transform the field of compositional visual retrieval.", "title_embedding_index": 20360, "title_abs_embedding_index": 20385}, {"title": "Jailbreak Antidote: Runtime Safety-Utility Balance via Sparse Representation Adjustment in Large Language Models", "link_suffix": "/forum?id=s20W12XTF8", "link": "https://openreview.net/forum?id=s20W12XTF8", "pdf_link": "https://openreview.net/pdf?id=s20W12XTF8", "keywords": "Large Language Models, Jailbreak Defense, Safety-Utility Balance, Internal State Manipulation, Sparse Representation Adjustment", "abstract": "As large language models (LLMs) become integral to various applications, ensuring both their safety and utility is paramount. Jailbreak attacks, which manipulate LLMs into generating harmful content, pose significant challenges to this balance. Existing defenses, such as prompt engineering and safety fine-tuning, often introduce computational overhead, increase inference latency, and lack runtime flexibility. Moreover, overly restrictive safety measures can degrade model utility by causing refusals of benign queries. In this paper, we introduceJailbreak Antidote, a method that enables real-time adjustment of LLM safety preferences by manipulating a sparse subset of the model's internal states during inference. By shifting the model's hidden representations along a safety direction with varying strengths, we achieve flexible control over the safety-utility balance without additional token overhead or inference delays. Our analysis reveals that safety-related information in LLMs is sparsely distributed; adjusting approximately5%of the internal state is as effective as modifying the entire state. Extensive experiments on nine LLMs (ranging from 2 billion to 72 billion parameters), evaluated against ten jailbreak attack methods and compared with six defense strategies, validate the effectiveness and efficiency of our approach. By directly manipulating internal states during reasoning,Jailbreak Antidoteoffers a lightweight, scalable solution that enhances LLM safety while preserving utility, opening new possibilities for real-time safety mechanisms in widely-deployed AI systems.", "title_embedding_index": 20361, "title_abs_embedding_index": 20386}, {"title": "Precise Parameter Localization for Textual Generation in Diffusion Models", "link_suffix": "/forum?id=gdHtZlaaSo", "link": "https://openreview.net/forum?id=gdHtZlaaSo", "pdf_link": "https://openreview.net/pdf?id=gdHtZlaaSo", "keywords": "diffusion models, text edition, LoRA, localization, SD-XL, SD3, DeepFloyd IF", "abstract": "Novel diffusion models (DMs) can synthesize photo-realistic images with integrated high-quality text. Surprisingly, we demonstrate through attention activation patching that only less than 1% of DMs' parameters contained in attention layers influence the generation of textual content within the images. Building on this observation, by precisely targeting cross and joint attention layers of DMs, we improve the efficiency and performance of textual generation. We introduce several applications that benefit from localizing the layers responsible for textual content generation. We first show that a LoRA-based fine-tuning solely of the localized layers enhances, even more, the general text-generation capabilities of large DMs while preserving the quality and diversity of the DMs' generations. Then, we demonstrate how we can use the localized layers to edit textual content in generated images. Finally, we extend this idea to the practical use case of preventing the generation of toxic text in a cost-free manner. In contrast to prior work, our localization approach is broadly applicable across various diffusion model architectures, including U-Net (e.g., LDM and SDXL) and transformer-based (e.g., DeepFloyd IF and Stable Diffusion 3), utilizing diverse text encoders (e.g., from CLIP and the large language models like T5).", "title_embedding_index": 20362, "title_abs_embedding_index": 20387}, {"title": "Improved Video VAE for Latent Video Diffusion Model", "link_suffix": "/forum?id=e5288Iu4Zc", "link": "https://openreview.net/forum?id=e5288Iu4Zc", "pdf_link": "https://openreview.net/pdf?id=e5288Iu4Zc", "keywords": "Video VAE, Variational Autoencoder", "abstract": "Variational Autoencoder (VAE) aims to compress pixel data into low-dimensional latent space, playing an important role in OpenAI's Sora and other latent video diffusion generation models. While most of existing video VAEs inflate a pretrained image VAE into the 3D causal structure for temporal-spatial compression, this paper presents two astonishing findings: (1) The initialization from a well-trained image VAE with the same latent dimensions suppresses the improvement of subsequent temporal compression capabilities. (2) The adoption of causal reasoning leads to unequal information interactions and unbalanced performance between frames. To alleviate these problems, we propose a keyframe-based temporal compression (KTC) architecture and a group causal convolution (GCConv) module to further improve video VAE (IV-VAE). Specifically, the KTC architecture divides the latent space into two branches, in which one half completely inherits the compression prior of keyframes from lower-dimension image VAEs while the other half involves temporal compression into the 3D group causal convolution, reducing temporal-spatial conflicts and accelerating the convergence speed of video VAE. The GCConv in above 3D half uses standard convolution within each frame group to ensure inter-frame equivalence, and employs causal logical padding between groups to maintain flexibility in processing variable frame video. Extensive experiments on five benchmarks demonstrate the SOTA video reconstruction and generation capabilities of the proposed IV-VAE. The source code and weights will be made available to the public.", "title_embedding_index": 20363, "title_abs_embedding_index": 20388}, {"title": "CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control", "link_suffix": "/forum?id=pZISppZSTv", "link": "https://openreview.net/forum?id=pZISppZSTv", "pdf_link": "https://openreview.net/pdf?id=pZISppZSTv", "keywords": "RL, PPO, motion, motion generation, motion synthesis, synthesis, generative models, diffusion, animation", "abstract": "Motion diffusion models and Reinforcement Learning (RL) based control for physics-based simulations have complementary strengths for human motion generation. The former is capable of generating a wide variety of motions, adhering to intuitive control such as text, while the latter offers physically plausible motion and direct interaction with the environment. In this work, we present a method that combines their respective strengths. CLoSD is a text-driven RL physics-based controller, guided by diffusion generation for various tasks. Our key insight is that motion diffusion can serve as an on-the-fly universal planner for a robust RL controller. To this end, CLoSD maintains a closed-loop interaction between two modules \u2014 a Diffusion Planner (DiP), and a tracking controller. DiP is a fast-responding autoregressive diffusion model, controlled by textual prompts and target locations, and the controller is a simple and robust motion imitator that continuously receives motion plans from DiP and provides feedback from the environment. CLoSD is capable of seamlessly performing a sequence of different tasks, including navigation to a goal location, striking an object with a hand or foot as specified in a text prompt, sitting down, and getting up.", "title_embedding_index": 20364, "title_abs_embedding_index": 20389}, {"title": "Boost 3D Reconstruction using Diffusion-based Intrinsic Estimation", "link_suffix": "/forum?id=XydIBZ2xlr", "link": "https://openreview.net/forum?id=XydIBZ2xlr", "pdf_link": "https://openreview.net/pdf?id=XydIBZ2xlr", "keywords": "Calibration, Diffusion, 3D reconstruction.", "abstract": "In this paper, we present DM-Calib, a diffusion-based approach for estimating camera intrinsic parameters from a single input image. Monocular camera calibration is essential for many 3D vision tasks. However, most existing methods depend on handcrafted assumptions or are constrained by limited training data, resulting in poor generalization across diverse real-world images. Recent advancements in stable diffusion models, trained on massive data, have shown the ability to generate high-quality images with varied characteristics. Emerging evidence indicates that these models implicitly capture the relationship between camera focal length and image content. Building on this insight, we explore how to leverage the powerful priors of diffusion models for monocular camera calibration. Specifically, we introduce a new image-based representation, termed Camera Image, which losslessly encodes the numerical camera intrinsics and integrates seamlessly with the diffusion framework. Using this representation, we reformulate the problem of estimating camera intrinsics as the generation of a dense Camera Image conditioned on an input image. By fine-tuning a stable diffusion model to generate a Camera Image from a single RGB input, we can extract camera intrinsics via a RANSAC operation. We further demonstrate that our monocular calibration method enhances performance across various 3D tasks, including zero-shot metric depth estimation, 3D metrology, pose estimation and sparse-view reconstruction. Extensive experiments on multiple public datasets show that our approach significantly outperforms baselines and provides broad benefits to 3D vision tasks.", "title_embedding_index": 20365, "title_abs_embedding_index": 20390}, {"title": "Lightning-Fast Image Inversion and Editing for Text-to-Image Diffusion Models", "link_suffix": "/forum?id=t9l63huPRt", "link": "https://openreview.net/forum?id=t9l63huPRt", "pdf_link": "https://openreview.net/pdf?id=t9l63huPRt", "keywords": "Deterministic Image Inversion, Image Editing, Diffusion Models, Image Generation", "abstract": "Diffusion inversion is the problem of taking an image and a text prompt that describes it and finding a noise latent that would generate the exact same image. Most current deterministic inversion techniques operate by approximately solving an implicit equation and may converge slowly or yield poor reconstructed images.  We formulate the problem by finding the roots of an implicit equation and design a method to solve it efficiently. Our solution is based on Newton-Raphson (NR), a well-known technique in numerical analysis. We show that a vanilla application of NR is computationally infeasible while naively transforming it to a computationally tractable alternative tends to converge to out-of-distribution solutions, resulting poor reconstruction and editing. We therefore derive an efficient guided formulation that fastly converges and provides high-quality reconstructions and editing. We showcase our method on real image editing with three popular open-sourced diffusion models: Stable Diffusion, SDXL-Turbo and Flux with different deterministic schedulers. Our solution, Guided Newton-Raphson Inversion, inverts an image within 0.4 sec (on an A100 GPU) for few-step models (SDXL-Turbo and Flux.1), opening the door for interactive image editing. We further show improved results in image interpolation and generation of rare objects.", "title_embedding_index": 20366, "title_abs_embedding_index": 20391}, {"title": "Revisiting Convolution Architecture in the Realm of DNA Foundation Models", "link_suffix": "/forum?id=B07dLVWLyD", "link": "https://openreview.net/forum?id=B07dLVWLyD", "pdf_link": "https://openreview.net/pdf?id=B07dLVWLyD", "keywords": "DNA modeling, foundation model, Genomic Language Model, Representation Learning", "abstract": "In recent years, A variety of methods based on Transformer and state space model (SSM) architectures have been proposed, advancing foundational DNA language models. \nHowever, there is a lack of comparison between these recent approaches and the classical architecture\u2014convolutional networks (CNNs)\u2014on foundation model benchmarks.\nThis raises the question: are CNNs truly being surpassed by these recent approaches based on transformer and SSM architectures? In this paper, we develop a simple yet well-designed CNN-based method, named ConvNova. ConvNova identifies and proposes three effective designs: 1) dilated convolutions, 2) gated convolutions, and 3) a dual-branch framework for gating mechanisms. \nThrough extensive empirical experiments, we demonstrate that ConvNova significantly outperforms recent methods on more than half of the tasks across several foundation model benchmarks. For example, in histone-related tasks, ConvNova surpasses the second-best method by an average of 5.8%, while generally utilizing fewer parameters and enabling faster computation.  Additionally, the experiments observed findings that may be related to biological characteristics. This indicates that CNNs are still a strong competitor compared to Transformers and SSMs. We anticipate that this work will spark renewed interest in CNN-based methods for DNA foundation models.", "title_embedding_index": 20367, "title_abs_embedding_index": 20392}, {"title": "Kronecker Mask and Interpretive Prompts are Language-Action Video Learners", "link_suffix": "/forum?id=RUF7j1cJzK", "link": "https://openreview.net/forum?id=RUF7j1cJzK", "pdf_link": "https://openreview.net/pdf?id=RUF7j1cJzK", "keywords": "Action Recognition, Video Recognition, Spatiotemporal Modeling", "abstract": "Contrastive language-image pretraining (CLIP) has significantly advanced image-based vision learning. A pressing topic subsequently arises: how can we effectively adapt CLIP to the video domain? Recent studies have focused on adjusting either the textual or visual branch of CLIP for action recognition. However, we argue that adaptations of both branches are crucial. In this paper, we propose aContrastiveLanguage-ActionVideo Learner(CLAVER), designed to shift CLIP's focus from the alignment of static visual objects and concrete nouns to the alignment of dynamic action behaviors and abstract verbs. Specifically, we introduce a novel Kronecker mask attention for temporal modeling. Our tailored Kronecker mask offers three benefits 1) it expands the temporal receptive field for each token, 2) it serves as an effective spatiotemporal heterogeneity inductive bias, mitigating the issue of spatiotemporal homogenization, and 3) it can be seamlessly plugged into transformer-based models. Regarding the textual branch, we leverage large language models to generate diverse, sentence-level and semantically rich interpretive prompts of actions, which shift the model's focus towards the verb comprehension. Extensive experiments on various benchmarks and learning scenarios demonstrate the superiority and generality of our approach. The code will be available soon.", "title_embedding_index": 20368, "title_abs_embedding_index": 20393}, {"title": "M3D: Advancing 3D Medical Image Analysis with Multi-Modal Large Language Models", "link_suffix": "/forum?id=XQL4Pmf6m6", "link": "https://openreview.net/forum?id=XQL4Pmf6m6", "pdf_link": "https://openreview.net/pdf?id=XQL4Pmf6m6", "keywords": "Medical image analysis, 3D medical imaging, MLLM", "abstract": "Medical image analysis is essential to numerous practicals of clinical diagnosis and treatment. However, due to the data scarcity and expensive training cost, previous research has largely focused on 2D medical image analysis, leaving 3D medical images under-explored, despite their important spatial information. This paper aims to advance 3D medical image analysis by leveraging multi-modal large language models (MLLMs). \nWe propose M3D-LaMed, a generalist MLLM for 3D medical image analysis, specializing in eight important tasks, including image-text retrieval, report generation, visual question answering, positioning,  segmentation, etc. The spatial pooling perceiver is proposed to reduce the 3D tokens, while preserving spatial information.\nTo train the model, we construct the largest 3D multi-modal medical dataset, M3D-Data, comprising 120K image-text pairs and 662K instruction-response pairs specifically tailored for 3D medical tasks.\nThe 3D multi-modal benchmark, M3D-Bench, is designed, which facilitates the comprehensive evaluation of models across eight tasks. The extensive experiments demonstrate that, as a generalist model, M3D-LaMed shows promising performances and outperforms other specialist models in multiple tasks. With the proposed model, data and benchmark, this work establishes a universal framework that significantly advances the 3D medical image analysis. All data, code and models will be publicly accessible.", "title_embedding_index": 20369, "title_abs_embedding_index": 20394}, {"title": "Explicit-Constrained Single Agent for Enhanced Task-Solving in LLMs", "link_suffix": "/forum?id=GO4Sd6LUuY", "link": "https://openreview.net/forum?id=GO4Sd6LUuY", "pdf_link": "https://openreview.net/pdf?id=GO4Sd6LUuY", "keywords": "Agent, LLM", "abstract": "In this study, we introduce the Explicitly Constrained Agent (EC-Agent), a novel approach designed to enhance the task-solving capabilities of Large Language Models (LLMs). Unlike existing multi-agent systems that depend on agents evaluating tasks from different perspectives, EC-Agent explicitly imposes task-oriented constraints for LLMs. Our observations are two-fold: first, assigning agents to sub-tasks with defined responsibilities implicitly sets constraints; second, these multi-agent systems often struggle with accurately assigning agents to sub-tasks, leading to overlapping duties and potential misguidance. In contrast, our single-agent system, driven by explicit methods and constraints, provides LLMs with detailed prompts, resulting in more precise responses. EC-Agent consists of two stages: a Reasoning Stage and a Summary Stage. 1) In the Reasoning Stage, three modules are proposed: Explicit Method, Explicit Constraint, and Execution. Specifically, LLMs utilize the Explicit Method and Constraint modules to analyze the task type and specific rules, generating multiple suitable methods and constraints. Subsequently, the Execution module combines these methods and constraints to produce and output possible solutions. 2) In the Summary Stage, LLMs evaluate the multiple reasoning processes and results from the previous step. They rectify any inconsistencies, summarize the information, and output the final result. Experimental results demonstrate that EC-Agent outperforms previous methods across a variety of tasks.", "title_embedding_index": 20370, "title_abs_embedding_index": 20395}, {"title": "MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression", "link_suffix": "/forum?id=konDsSUSqg", "link": "https://openreview.net/forum?id=konDsSUSqg", "pdf_link": "https://openreview.net/pdf?id=konDsSUSqg", "keywords": "Sparse Attention, KV Cache Management, Large Language Models", "abstract": "Sparse attention can effectively mitigate the significant memory and throughput demands of Large Language Models (LLMs) in long contexts. \nExisting methods typically employ a uniform sparse attention mask, applying the same sparse pattern across different attention heads and input lengths. \nHowever, this uniform approach fails to capture the diverse attention patterns inherent in LLMs, ignoring their distinct accuracy-latency trade-offs.\nTo address this challenge, we propose the Mixture of Attention (MoA), which automatically tailors distinct sparse attention configurations to different heads and layers.\nMoA constructs and navigates a search space of various attention patterns and their scaling rules relative to input sequence lengths. It profiles the model, evaluates potential configurations, and pinpoints the optimal sparse attention compression plan.\nMoA adapts to varying input sizes, revealing that some attention heads expand their focus to accommodate longer sequences, while other heads consistently concentrate on fixed-length local contexts.\nExperiments show that MoA increases the effective context length by $3.9\\times$ with the same average attention span, boosting retrieval accuracy by $1.5-7.1\\times$ over the uniform-attention baseline across Vicuna-{7B,13B}, and Llama3-{8B,70B} models. \nMoreover, MoA narrows the capability gaps between sparse and dense models, reducing the maximum relative performance drop from $9%-36%$ to within $5%$ across two long-context understanding benchmarks.\nMoA achieves a $1.2-1.4\\times$ GPU memory reduction, boosting decode throughput by $6.6-8.2\\times$ and $1.7-1.9\\times$ compared to FlashAttention2 and vLLM, with minimal impact on performance.", "title_embedding_index": 20371, "title_abs_embedding_index": 20396}, {"title": "Linear SCM Identification in the Presence of Confounders and Gaussian Noise", "link_suffix": "/forum?id=bjxuqI4KwU", "link": "https://openreview.net/forum?id=bjxuqI4KwU", "pdf_link": "https://openreview.net/pdf?id=bjxuqI4KwU", "keywords": "identifiability, SCM, causal discovery; linear SCM; confounder", "abstract": "Noisy linear structural causal models (SCMs) in the presence of confounding variables are known to be identifiable if all confounding and noise variables are non-Gaussian and unidentifiable if all are Gaussian.\n    The identifiability when only some are Gaussian remains concealed. \n    We show that, in the presence of Gaussian noise, a linear SCM is uniquely identifiable provided that \\emph{(i)} the number of confounders is at most the number of the observed variables, \\emph{(ii)} the confounders do not have a Gaussian component, and \\emph{(iii)} the causal structure of the SCM is known.\n    If the third condition is relaxed, the SCM becomes finitely identifiable; more specifically, it belongs to a set of at most $n!$ linear SCMS, where $n$ is the number of observed variables.\n    The confounders in all of these $n!$ SCMs share the same joint probability distribution function (PDF), which we obtain analytically.For the case where both the noise and confounders are Gaussian, we provide further insight into the existing counter-example-based unidentifiability result and demonstrate that every SCM with confounders can be represented as an SCM without confounders but with the same joint PDF.", "title_embedding_index": 20372, "title_abs_embedding_index": 20397}, {"title": "Organizing Unstructured Image Collections using Natural Language", "link_suffix": "/forum?id=PhRYDGqiee", "link": "https://openreview.net/forum?id=PhRYDGqiee", "pdf_link": "https://openreview.net/pdf?id=PhRYDGqiee", "keywords": "Vision-Language, Image Clustering", "abstract": "Organizing unstructured visual data into semantic clusters is a key challenge in computer vision. Traditional deep clustering (DC) approaches focus on a single partition of data, while multiple clustering (MC) methods address this limitation by uncovering distinct clustering solutions. The rise of large language models (LLMs) and multimodal LLMs (MLLMs) has enhanced MC by allowing users to define clustering criteria in natural language. However, manually specifying criteria for large datasets is impractical. In this work, we introduce the task Semantic Multiple Clustering (SMC) that aims to automatically discover clustering criteria from large image collections, uncovering interpretable substructures without requiring human input. Our framework, Text Driven Semantic Multiple Clustering (TeDeSC), uses text as a proxy to concurrently reason over large image collections, discover partitioning criteria, expressed in natural language, and reveal semantic substructures. To evaluate TeDeSC, we introduce the COCO-4c and Food-4c benchmarks, each containing four grouping criteria and ground-truth annotations. We apply TeDeSC to various applications, such as discovering biases and analyzing social media image popularity, demonstrating its utility as a tool for automatically organizing image collections and revealing novel insights.", "title_embedding_index": 20373, "title_abs_embedding_index": 20398}, {"title": "Feynman-Kac Operator Expectation Estimator", "link_suffix": "/forum?id=5sPgOyyjG5", "link": "https://openreview.net/forum?id=5sPgOyyjG5", "pdf_link": "https://openreview.net/pdf?id=5sPgOyyjG5", "keywords": "Expectation Estimator, Diffusion bridge model, MCMC, Physically Informed Neural Networks, Minimum Wasserstein Estimator", "abstract": "The Feynman-Kac Operator Expectation Estimator (FKEE) is an innovative method for estimating the target Mathematical Expectation $\\mathbb{E}_{X\\sim P}[f(X)]$ without relying on a large number of samples, in contrast to the commonly used Markov Chain Monte Carlo (MCMC) Expectation Estimator. FKEE comprises diffusion bridge models and approximation of the Feynman-Kac operator. The key idea is to use the solution to the Feynmann-Kac equation at the initial time $u(x_0,0)=\\mathbb{E}[f(X_T)|X_0=x_0]$. We use Physically Informed Neural Networks (PINN) to approximate the Feynman-Kac operator, which enables the incorporation of diffusion bridge models into the expectation estimator and significantly improves the efficiency of using data while substantially reducing the variance. Diffusion Bridge Model is a more general MCMC method. In order to incorporate extensive MCMC algorithms, we propose a new diffusion bridge model based on the Minimum Wasserstein distance. This diffusion bridge model is universal and reduces the training time of the PINN. FKEE also reduces the adverse impact of the curse of dimensionality and weakens the assumptions on the distribution of $X$ and performance function $f$ in the general MCMC expectation estimator. The theoretical properties of this universal diffusion bridge model are also shown. Finally, we demonstrate the advantages and potential applications of this method through various concrete experiments, including the challenging task of approximating the partition function in the random graph model such as the Ising model.", "title_embedding_index": 20374, "title_abs_embedding_index": 20399}]
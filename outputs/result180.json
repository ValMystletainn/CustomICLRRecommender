[
    {
        "title": "Jailbreak Instruction-Tuned Large Language Models via MLP Re-weighting",
        "link_suffix": "/forum?id=P5qCqYWD53",
        "link": "https://openreview.net/forum?id=P5qCqYWD53",
        "pdf_link": "https://openreview.net/pdf?id=P5qCqYWD53",
        "keywords": "Jailbreak, AI safety, mechanism interpretability",
        "abstract": "In this paper, we investigate the safety mechanisms of instruction fine-tuned large language models (LLMs). We discover that re-weighting MLP neurons can significantly compromise a model's safety, especially for MLPs in end-of-sentence inferences. We hypothesize that LLMs evaluate the harmfulness of prompts during end-of-sentence inferences, and MLP layers plays a critical role in this process. Based on this hypothesis, we develop 2 novel white-box jailbreak methods: a prompt-specific method and a prompt-general method. The prompt-specific method targets individual prompts and optimizes the attack on the fly, while the prompt-general method is pre-trained offline and can generalize to unseen harmful prompts.  Our methods demonstrate robust performance across 7 popular open-source LLMs, size ranging from 2B to 72B. Furthermore, our study provides insights into vulnerabilities of instruction-tuned LLM's safety and deepens the understanding of the internal mechanisms of LLMs."
    },
    {
        "title": "Adaptive Video Understanding Agent:  Enhancing Efficiency with Dynamic Frame Sampling and Feedback-driven Reasoning",
        "link_suffix": "/forum?id=dOwmtbn6ZO",
        "link": "https://openreview.net/forum?id=dOwmtbn6ZO",
        "pdf_link": "https://openreview.net/pdf?id=dOwmtbn6ZO",
        "keywords": "multimodal agent, long context video processing, adaptive sampling",
        "abstract": "Understanding long-form video content presents significant challenges due to its temporal complexity and the substantial computational resources required. In this work, we propose an agent-based approach to enhance both the efficiency and effectiveness of long-form video understanding by utilizing large language models (LLMs) and their tool-harnessing ability. A key aspect of our method is query-adaptive frame sampling, which leverages the reasoning capabilities of LLMs to process only the most relevant frames in real-time, and addresses an important limitation of existing methods which typically involve sampling redundant or irrelevant frames. To enhance the reasoning abilities of our video-understanding agent, we leverage the self-reflective capabilities of LLMs to provide verbal reinforcement to the agent, which leads to improved performance while minimizing the number of frames accessed. We evaluate our method across several video understanding benchmarks and demonstrate that not only it enhances state-of-the-art performance but also improves efficiency by reducing the number of frames sampled."
    },
    {
        "title": "UNA: Unifying Alignments of RLHF/PPO, DPO and KTO by a Generalized Implicit Reward Function",
        "link_suffix": "/forum?id=ZSbsX1sFo3",
        "link": "https://openreview.net/forum?id=ZSbsX1sFo3",
        "pdf_link": "https://openreview.net/pdf?id=ZSbsX1sFo3",
        "keywords": "LLM Alignment, Unified Alignment, RLHF, PPO, DPO, KTO",
        "abstract": "An LLM is pretrained on trillions of tokens, but the pretrained LLM may still generate undesired responses. To solve this problem, alignment techniques such as RLHF, DPO and KTO are proposed. However, these alignment techniques have limitations. For example, RLHF requires training the reward model and policy separately, which is complex, time-consuming, memory intensive and unstable during training processes. DPO proposes a mapping between an optimal policy and a reward, greatly simplifying the training process of RLHF. However, it can not take full advantages of a reward model and it is limited to pairwise preference data.In this paper, we propose \\textbf{UN}ified \\textbf{A}lignment (UNA) which unifies RLHF/PPO, DPO and KTO. Firstly, we mathematically prove that given the classical RLHF objective, the optimal policy is induced by a generalize implicit reward function. With this novel mapping between a reward model and an optimal policy, UNA can 1. unify RLHF/PPO, DPO and KTO into a supervised learning of minimizing the difference between an implicit reward and an explicit reward; 2. outperform RLHF/PPO while simplify, stabilize, speed up and reduce memory burden of RL fine-tuning process; 3. accommodate different feedback types including pairwise, binary and scalar feedback. Downstream experiments show UNA outperforms DPO, KTO and RLHF."
    },
    {
        "title": "Adapprox: Memory Efficient Optimization via Adaptive Randomized Low-Rank Approximation",
        "link_suffix": "/forum?id=RtzxJLPxGk",
        "link": "https://openreview.net/forum?id=RtzxJLPxGk",
        "pdf_link": "https://openreview.net/pdf?id=RtzxJLPxGk",
        "keywords": "memory-efficient optimization, large language models, low-rank approximation",
        "abstract": "As deep learning models expand, adaptive learning rate algorithms such as Adam face significant memory consumption challenges due to the need to store of optimizer states, including first and second moment data. Existing memory-efficient methods such as Adafactor and CAME often compromise approximation accuracy with their constant rank-1 matrix factorization techniques. In response, we introduce Adapprox, a novel optimizer that employs adaptive randomized low-rank matrix approximation to more effectively and accurately approximate the second moment. This method dynamically adjusts the rank used for approximation across iterations and weight matrices, mitigating the increase in computation burden while maintaining comparable accuracy. In experiments with GPT-2 and BERT, Adapprox achieves substantial memory savings compared to AdamW and surpasses other memory-efficient counterparts in convergence iterations and downstream task performance, with only a modest increase in the overall latency."
    },
    {
        "title": "Custom Gradient Estimators are Straight-Through Estimators in Disguise",
        "link_suffix": "/forum?id=3j72egd8q1",
        "link": "https://openreview.net/forum?id=3j72egd8q1",
        "pdf_link": "https://openreview.net/pdf?id=3j72egd8q1",
        "keywords": "quantization, deep learning, optimization",
        "abstract": "Quantization-aware  training  comes with a fundamental challenge: the derivative of quantization functions such as rounding are zero almost everywhere and nonexistent elsewhere. Various differentiable approximations of quantization functions have been proposed to address this issue. In this paper, we prove that a large class of weight gradient estimators is approximately equivalent with the straight through estimator (STE). Specifically, after swapping in the STE and adjusting both the weight initialization and the learning rate in SGD, the model will train in almost exactly the same way as it did with the original gradient estimator. Moreover, we show that for adaptive learning rate algorithms like Adam, the same result can be seen without any modifications to the weight initialization and learning rate. These results reduce the burden of hyperparameter tuning for practitioners of QAT, as they can now confidently choose the STE for gradient estimation and ignore more complex gradient estimators. We experimentally show that these results hold for both a small convolutional model trained on the MNIST dataset and for a ResNet50 model trained on ImageNet."
    },
    {
        "title": "Revisit Large-Scale Image-Caption Data in Pre-training Multimodal Foundation Models",
        "link_suffix": "/forum?id=TWnUgSAWNw",
        "link": "https://openreview.net/forum?id=TWnUgSAWNw",
        "pdf_link": "https://openreview.net/pdf?id=TWnUgSAWNw",
        "keywords": "Multimodal, pre-training, image-text data",
        "abstract": "Recent advancements in multimodal models highlight the value of rewritten captions for improving performance, yet key challenges remain. For example, while synthetic captions often provide superior quality and image-text alignment, it is not clear whether they can fully replace AltTexts: the role of synthetic captions and their interaction with original web-crawled AltTexts in pre-training is still not well understood. Moreover, different multimodal foundation models may have unique preferences for specific caption formats, but efforts to identify the optimal captions for each model remain limited. In this work, we propose a novel, controllable, and scalable captioning pipeline designed to generate diverse caption formats tailored to various multimodal models. By examining short synthetic captions (SSC) and descriptive synthetic captions (DSC) as case studies, we systematically explore their effects and interactions with AltTexts across models such as CLIP, multimodal LLMs, and diffusion models. Our findings reveal that a hybrid approach that keeps both synthetic captions and AltTexts can outperform the use of synthetic captions alone, improving both alignment and performance, with each model demonstrating preferences for particular caption formats. This comprehensive analysis provides valuable insights into optimizing captioning strategies, thereby advancing the pre-training of multimodal foundation models."
    },
    {
        "title": "CRVR: Continuous Representation-Driven Video Frame Modulation Against rPPG Heart Rate Measurement",
        "link_suffix": "/forum?id=uUsfvsrkOw",
        "link": "https://openreview.net/forum?id=uUsfvsrkOw",
        "pdf_link": "https://openreview.net/pdf?id=uUsfvsrkOw",
        "keywords": "Adversarial video attack, Remote physiological heart rate measurement.",
        "abstract": "Facial video-based remote physiological measurement (rPPG) has gained prominence for its ability to non-invasively estimate vital signs such as heart rate (HR).The foundation of rPPG lies in using a camera to record facial videos at a certain frame rate, allowing the capture of rapid skin color changes necessary for HR measurement. Inspired by this property, we identified a new task, that is, to embed malicious information into facial videos by subtly modulating frames and generating frames corresponding to the modified rate. With this task, we can mislead state-of-the-art rPPG HR methods through natural and imperceptible frame modulation changes, aiming for two objectives: testing the resilience of rPPG methods against frame modulation variations and safeguarding heart rate data, which is crucial for individual privacy. However, such a task is non-trivial and should be capable of automatically adapting to different input videos and generating natural, imperceptible frame modulation perturbations along with frames corresponding to the modified rate. To address these challenges, we propose Continuous Representation-driven Video Resampling (CRVR), which targets precise manipulation of frame timing to subtly skew perceived HR measurements. Specifically, the CRVR method consists of two modules: Variable Frame Rate Video Resampling (VFRVR), which automatically determines the optimal resampling strategy for each frame, and Continuous Video Frame Generation (CVFG), which generates frames corresponding to the modified rate and seamlessly injects them back into the video. Extensive testing on UBFC-rPPG and PURE datasets reveals that our CRVR method successfully produces realistic, imperceptible adversarial videos that effectively mislead three different rPPG-based heart rate detection technologies."
    },
    {
        "title": "Disentangling Inter- and Intra-Video Relations for Multi-event Video-Text Retrieval and Grounding",
        "link_suffix": "/forum?id=dYc55Hvm3p",
        "link": "https://openreview.net/forum?id=dYc55Hvm3p",
        "pdf_link": "https://openreview.net/pdf?id=dYc55Hvm3p",
        "keywords": "Video-Text Retrieval; Grounding; Multi-event Queries",
        "abstract": "Video-text retrieval aims to precisely search for videos most relevant to a text query within a video corpus. However, existing methods are largely limited to single-text (single-event) queries, which are not effective at handling multi-text (multi-event) queries. Furthermore, these methods typically focus solely on retrieval and do not attempt to locate multiple events within the retrieved videos. To address these limitations, our paper proposes a novel method named Disentangling Inter- and Intra-Video relations, which jointly considers multi-event video-text retrieval and grounding. This method leverages both inter-video and intra-video event relationships to enhance the performance of retrieval and grounding. At the retrieval level, we devise a Relational Event-Centric Video-Text Retrieval module, based on the principle that more comprehensive textual information leads to a more precise correspondence between text and video. It incorporates event relationship features at different hierarchical levels and exploits the hierarchical structure of corresponding video relationships to achieve multi-level contrastive learning between events and videos. This approach enhances the richness, accuracy, and comprehensiveness of event descriptions, improving alignment precision between text and video and enabling effective differentiation among videos. For event localization, we propose Event Contrast-Driven Video Grounding, which accounts for positional differences between different events and achieves precise grounding of multiple events through divergence learning of event locations. Our solution not only provides efficient text-to-video retrieval capabilities but also accurately locates events within the retrieved videos, addressing the shortcomings of existing methods. Extensive experimental results on the ActivityNet-Captions and Charades-STA benchmark datasets demonstrate the superior performance of our method, clearly validating its effectiveness. The innovation of this research lies in introducing a new joint framework for video-text retrieval and multi-event localization, while offering new ideas for further research and applications in related fields."
    },
    {
        "title": "Buckle Up: Robustifying LLMs at Every Customization Stage via Data Curation",
        "link_suffix": "/forum?id=NrfP7zZNiG",
        "link": "https://openreview.net/forum?id=NrfP7zZNiG",
        "pdf_link": "https://openreview.net/pdf?id=NrfP7zZNiG",
        "keywords": "Safety Alignment, Fine-tuning, LLMs, AI Security, Jailbreaking",
        "abstract": "Large language models (LLMs) are extensively adapted for downstream applications through a process known as \"customization,\" with fine-tuning being a common method for integrating domain-specific expertise. \nHowever, recent studies have revealed a vulnerability that tuning LLMs with malicious samples can compromise their robustness and amplify harmful content, an attack known as \"jailbreaking.\"\nTo mitigate such attack, we propose an effective defensive framework utilizing data curation to revise commonsense texts and enhance their safety implication from the perspective of LLMs. The curated texts can mitigate jailbreaking attacks at every stage of the customization process: before customization to immunize LLMs against future jailbreak attempts, during customization to neutralize jailbreaking risks, or after customization to restore the compromised models. Since the curated data strengthens LLMs through the standard fine-tuning workflow, we do not introduce additional modules during LLM inference, thereby preserving the original customization process. Experimental results demonstrate a substantial reduction in jailbreaking effects, with up to a 100% success in generating responsible responses. Notably, our method is effective even with commonsense texts, which are often more readily available than safety-relevant data. With the every-stage defensive framework and supporting experimental performance, this work represents a significant advancement in mitigating jailbreaking risks and ensuring the secure customization of LLMs."
    },
    {
        "title": "Distribution-Dependent Rates for Multi-Distribution Learning",
        "link_suffix": "/forum?id=ys16t9FcLN",
        "link": "https://openreview.net/forum?id=ys16t9FcLN",
        "pdf_link": "https://openreview.net/pdf?id=ys16t9FcLN",
        "keywords": "multi-distribution learning, distributionally robust optimization, pure exploration multi-armed bandits",
        "abstract": "To address the needs of modeling uncertainty in sensitive machine learning applications, the setup of distributionally robust optimization (DRO) seeks good performance uniformly across a variety of tasks. The recent multi-distribution learning (MDL) framework \\cite{pmlr-v195-awasthi23a-open-prob} tackles this objective in a dynamic interaction with the environment, where the learner has sampling access to each target distribution. Drawing inspiration from the field of pure-exploration multi-armed bandits, we provide \\textit{distribution-dependent} guarantees in the MDL regime, that scale with suboptimality gaps and result in superior dependence on the sample size when compared to the existing distribution-independent analyses. We investigate two non-adaptive strategies, uniform and non-uniform exploration, and present non-asymptotic regret bounds using novel tools from empirical process theory. Furthermore, we devise an adaptive optimistic algorithm, LCB-DR, that showcases enhanced dependence on the gaps, mirroring the contrast between uniform and optimistic allocation in the multi-armed bandit literature."
    },
    {
        "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
        "link_suffix": "/forum?id=GARbxyCV13",
        "link": "https://openreview.net/forum?id=GARbxyCV13",
        "pdf_link": "https://openreview.net/pdf?id=GARbxyCV13",
        "keywords": "World Models, Planning, Representation Learning",
        "abstract": "The ability to predict future outcomes given control actions is fundamental for physical reasoning. However, such predictive models, often called world models, have proven challenging to learn and are typically developed for task-specific solutions with online policy learning. We argue that the true potential of world models lies in their ability to reason and plan across diverse problems using only passive data. Concretely, we require world models to have the following three properties: 1) be trainable on offline, pre-collected trajectories, 2) support test-time behavior optimization, and 3) facilitate task-agnostic reasoning. To realize this, we present DINO World Model (DINO-WM), a new method to model visual dynamics without reconstructing the visual world. DINO-WM leverages spatial patch features pre-trained with DINOv2, enabling it to learn from offline behavioral trajectories by predicting future patch features. This design allows DINO-WM to achieve observational goals through action sequence optimization, facilitating task-agnostic behavior planning by treating desired goal patch features as prediction targets. We evaluate DINO-WM across various domains, including maze navigation, tabletop pushing, and particle manipulation. Our experiments demonstrate that DINO-WM can generate zero-shot behavioral solutions at test time without relying on expert demonstrations, reward modeling, or pre-learned inverse models. Notably, DINO-WM exhibits strong generalization capabilities compared to prior state-of-the-art work, adapting to diverse task families such as arbitrarily configured mazes, push manipulation with varied object shapes, and multi-particle scenarios."
    },
    {
        "title": "Spectraformer: A Unified Random Feature Framework for Transformer",
        "link_suffix": "/forum?id=zUD06a6leU",
        "link": "https://openreview.net/forum?id=zUD06a6leU",
        "pdf_link": "https://openreview.net/pdf?id=zUD06a6leU",
        "keywords": "linearized attention, transformer, efficient transformer, kernel, random features",
        "abstract": "Linearization of attention using various kernel approximation and kernel learning techniques has shown promise. Past methods use a subset of combinations of component functions and weight matrices within the random features paradigm. We identify the need for a systematic comparison of different combinations of weight matrices and component functions for attention learning in Transformer. In this work, we introduce $\\textit{Spectraformer}$, a unified framework for approximating and learning the kernel function in linearized attention of the Transformer. We experiment with broad classes of component functions and weight matrices for three textual tasks in the LRA benchmark. Our findings indicate that different kernels are good at different tasks and that kernel choice is fundamental to performant models. Our code is available at:https://anonymous.4open.science/r/spectraformer-8A97."
    },
    {
        "title": "RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates",
        "link_suffix": "/forum?id=EQZMx8Lc0n",
        "link": "https://openreview.net/forum?id=EQZMx8Lc0n",
        "pdf_link": "https://openreview.net/pdf?id=EQZMx8Lc0n",
        "keywords": "RoCoFT, Parameter-efficient finetuning, LLMs, Neural Tangent Kernel",
        "abstract": "We propose RoCoFT, a parameter-efficient fine-tuning method for large-scale language models (LMs) based on updating only a few rows and columns of the weight matrices in transformers. Through extensive experiments with medium size LMs like BERT and RoBERTa, and larger LMs like Bloom-7B, Llama2-7B, and Llama2-13B, we show that our method gives comparable or better accuracies than state-of-art PEFT methods while also being more memory and computation- efficient. We also study the reason behind the effectiveness of our method with tools from neural tangent kernel theory. We empirically demonstrate that our kernel, constructed using a restricted set of row and column parameters, are numerically close to the full-parameter kernel and gives comparable classification performance. Ablation studies are conducted to investigate the impact of different algorithmic choices, including the selection strategy for rows and columns as well as the optimal rank for effective implementation of our method."
    },
    {
        "title": "Data-Centric Human Preference Optimization with Rationales",
        "link_suffix": "/forum?id=2Cg4YrsCMA",
        "link": "https://openreview.net/forum?id=2Cg4YrsCMA",
        "pdf_link": "https://openreview.net/pdf?id=2Cg4YrsCMA",
        "keywords": "dpo, preference learning, alignment",
        "abstract": "Reinforcement learning from human feedback plays a crucial role in aligning\nlanguage models towards human preferences, traditionally represented through\ncomparisons between pairs or sets of responses within a given context. While\nmany studies have enhanced algorithmic techniques to optimize learning from such\ndata, this work shifts focus to improving preference learning through a data-centric\napproach. Specifically, we propose enriching existing preference datasets with\nmachine-generated rationales that explain the reasons behind choices. We develop\na simple and principled framework to augment current preference learning methods\nwith rationale information. Our comprehensive analysis highlights how rationales\nenhance learning efficiency. Extensive experiments reveal that rationale-enriched\npreference learning offers multiple advantages: it improves annotation efficiency,\naccelerates convergence to higher-performing models, and reduces verbosity bias\nand hallucination. Furthermore, this framework is versatile enough to integrate\nwith various preference optimization algorithms. Overall, our findings highlight\nthe potential of re-imagining data design for preference learning, demonstrating\nthat even freely available machine-generated rationales can significantly boost\nperformance across multiple dimensions."
    },
    {
        "title": "Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs",
        "link_suffix": "/forum?id=TQ7Nuy1CSm",
        "link": "https://openreview.net/forum?id=TQ7Nuy1CSm",
        "pdf_link": "https://openreview.net/pdf?id=TQ7Nuy1CSm",
        "keywords": "jailbreak, defense, attention machanism, LLM",
        "abstract": "Jailbreak attack can be used to access the vulnerabilities of Large Language Models (LLMs) by inducing LLMs to generate the harmful content. \nAnd the most common method of the attack is to construct semantically ambiguous prompts to confuse and mislead the LLMs.\nTo access the security and reveal the intrinsic relation between the input prompt and the output for LLMs, the distribution of attention weight is introduced to analyze the underlying reasons. \nBy using statistical analysis methods, some novel metrics are defined to better describe the distribution of attention weight, such as the Attention Intensity on Sensitive Words (Attn_SensWords), the Attention-based Contextual Dependency Score (Attn_DepScore) and Attention Dispersion Entropy (Attn_Entropy).\nBy leveraging the distinct characteristics of these metrics, the beam search algorithm and inspired by the military strategy \"Feint and Attack'', an effective jailbreak attack strategy named as Attention-Based Attack (ABA) is proposed.\nIn the ABA, nested attack prompts are employed to divert the attention distribution of the LLMs. \nIn this manner, more harmless parts of the input can be used to attract the attention of the LLMs.\nIn addition, motivated by ABA, an effective defense strategy called as Attention-Based Defense (ABD) is also put forward.\nCompared with ABA, the ABD can be used to enhance the robustness of LLMs by calibrating the attention distribution of the input prompt. \nSome comparative experiments have been given to demonstrate the effectiveness of ABA and ABD. \nTherefore, both ABA and ABD can be used to access the security of the LLMs. \nThe comparative experiment results also give a logical explanation that the distribution of attention weight can bring great influence on the output for LLMs."
    },
    {
        "title": "SciKnowEval: Evaluating Multi-level Scientific Knowledge of Large Language Models",
        "link_suffix": "/forum?id=pXUAiJshdh",
        "link": "https://openreview.net/forum?id=pXUAiJshdh",
        "pdf_link": "https://openreview.net/pdf?id=pXUAiJshdh",
        "keywords": "LLM benchmark, Scientific knowledge evaluation",
        "abstract": "Large language models (LLMs) have gained increasing prominence in scientific research, but there is a lack of comprehensive benchmarks to fully evaluate their proficiency in understanding and mastering scientific knowledge.To address this need, we introduce the SciKnowEval benchmark, a novel framework that systematically evaluates LLMs across five progressive levels of scientific knowledge: studying extensively, inquiring earnestly, thinking profoundly, discerning clearly, and practicing assiduously. These levels aim to assess the breadth and depth of scientific knowledge in LLMs, including memory, comprehension, reasoning, discernment, and application. Specifically, we first construct a large-scale evaluation dataset encompassing 70K multi-level scientific problems and solutions in the domains of biology, chemistry, physics, and materials science. By leveraging this dataset, we benchmark 26 advanced open-source and proprietary LLMs using zero-shot and few-shot prompting strategies. The results reveal that despite the state-of-the-art performance of proprietary LLMs,   there is still significant room for improvement, particularly in addressing scientific reasoning and applications. We anticipate that SciKnowEval will establish a standard for benchmarking LLMs in science research and promote the development of stronger scientific LLMs."
    },
    {
        "title": "Advancing Graph Generation through Beta Diffusion",
        "link_suffix": "/forum?id=x1An5a3U9I",
        "link": "https://openreview.net/forum?id=x1An5a3U9I",
        "pdf_link": "https://openreview.net/pdf?id=x1An5a3U9I",
        "keywords": "Graph Machine Learning, Generative Models, Denoising Diffusion Probabilistic Models",
        "abstract": "Diffusion models have excelled in generating natural images and are now being adapted to a variety of data types, including graphs. However, conventional models often rely on Gaussian or categorical diffusion processes, which can struggle to accommodate the mixed discrete and continuous components characteristic of graph data. Graphs typically feature discrete structures and continuous node attributes that often exhibit rich statistical patterns, including sparsity, bounded ranges, skewed distributions, and long-tailed behavior. To address these challenges, we introduce Graph Beta Diffusion (GBD), a generative model specifically designed to handle the diverse nature of graph data. GBD leverages a beta diffusion process, effectively modeling both continuous and discrete elements. Additionally, we propose a modulation technique that enhances the realism of generated graphs by stabilizing critical graph topology while maintaining flexibility for other components. GBD competes strongly with existing models across multiple general and biochemical graph benchmarks, showcasing its ability to capture the intricate balance between discrete and continuous features inherent in real-world graph data."
    },
    {
        "title": "Skip the Steps: Data-Free Consistency Distillation for Diffusion-based Samplers",
        "link_suffix": "/forum?id=uVm0zSNKkP",
        "link": "https://openreview.net/forum?id=uVm0zSNKkP",
        "pdf_link": "https://openreview.net/pdf?id=uVm0zSNKkP",
        "keywords": "Single-step sampling, Diffusion-based sampler, Distillation, Generative modeling, Optimal control",
        "abstract": "Sampling from probability distributions is a fundamental task in machine learning and statistics. However, most existing algorithms require numerous iterative steps to transform a prior distribution into high-quality samples, resulting in high computational costs and limiting their practicality in time-constrained and resource-limited environments. In this work, we propose consistency samplers, a novel class of samplers capable of generating high-quality samples in a single step. Our method introduces a new consistency distillation algorithm for diffusion-based samplers, which eliminates the need for data or full trajectory integration. By utilizing incomplete sampling trajectories and noisy intermediate representations along the diffusion process, we efficiently learn a direct one-step mapping from any state to its corresponding terminal state in the target distribution. Moreover, our approach enables few-step sampling, allowing users to flexibly balance compute costs and sample quality. We demonstrate the effectiveness of consistency samplers across multiple benchmark tasks, achieving high-quality results with one-step or few-step sampling while significantly reducing the sampling time compared to existing samplers. For instance, our method is 100-200x faster than prior diffusion-based samplers while having comparable sample quality."
    },
    {
        "title": "FISTAPruner: Layer-wise Post-training Pruning for Large Language Models",
        "link_suffix": "/forum?id=BINwUtUGuq",
        "link": "https://openreview.net/forum?id=BINwUtUGuq",
        "pdf_link": "https://openreview.net/pdf?id=BINwUtUGuq",
        "keywords": "large language models, post-training pruning",
        "abstract": "Pruning is a critical strategy for compressing trained large language models (LLMs), aiming at substantial memory conservation and computational acceleration without compromising performance. However, existing pruning methods typically necessitate inefficient retraining for billion-scale LLMs or rely on heuristically designed metrics to determine pruning masks, leading to performance degradation. This paper presents, for the first time, a LASSO-like convex optimization model crafted to induce sparsity in LLMs. By leveraging the FISTA, we introduce FISTAPruner, a novel method that includes a cumulative error elimination mechanism within decoder layers and supports parallel pruning for unstructured pruning. Additionally, we extend this method to 2:4 semi-structured pruning. We comprehensively evaluate FISTAPruner on models such as OPT and LLaMA variants with 125M to 70B parameters under unstructured and 2:4 semi-structured sparsity, showcasing superior performance over existing methods across various language benchmarks. Notably, it can remove 50% of the model parameters for LLaMA-3-70B while retaining 98.6% and 95.6% of the zero-shot task performance under these two sparsity patterns, respectively."
    },
    {
        "title": "Accelerated Over-Relaxation Heavy-Ball Method: Achieving Global Accelerated Convergence with Broad Generalization",
        "link_suffix": "/forum?id=SWEqzy7IQB",
        "link": "https://openreview.net/forum?id=SWEqzy7IQB",
        "pdf_link": "https://openreview.net/pdf?id=SWEqzy7IQB",
        "keywords": "Optimization theory, heavy ball, momentum, acceleration, composite optimization, min-max, saddle point problem",
        "abstract": "The heavy-ball momentum method is widely used to accelerate gradient descent by incorporating a momentum term. However, recent studies have shown it cannot achieve accelerated convergence for general smooth strongly convex problems. This work introduces the Accelerated Over-Relaxation Heavy-Ball (AOR-HB) method, the first heavy-ball variant with provable global and accelerated convergence for smooth strongly convex optimization. This breakthrough closes a long-standing theoretical gap and extends to composite convex optimization and min-max problems, achieving optimal complexity bounds and demonstrating broad generalization. The AOR-HB approach offers several advantages: (1) Generality: It applies to a wider range of optimization problems, (2) Impact: It introduces techniques that may reshape understanding of acceleration, and (3) Elegance: It is conceptually clearer and more intuitive than existing accelerated methods."
    },
    {
        "title": "Contextually Harmonious Local Video Editing",
        "link_suffix": "/forum?id=GwJXJSCH1S",
        "link": "https://openreview.net/forum?id=GwJXJSCH1S",
        "pdf_link": "https://openreview.net/pdf?id=GwJXJSCH1S",
        "keywords": "Video Editing, Diffusion Models, Contextaul Harmonious",
        "abstract": "We introduce a new task for video editing: Contextual Harmonious Local Editing, which focuses on replacing a local moving subject in videos containing multiple subjects or reference objects. The goal is to ensure that the replaced subject maintains its original motion while its size remains harmonious with the scene's context. Previous methods often face two specific challenges when addressing this task: (1) ensuring the size of the replaced subject remains contextually harmonious (2) maintaining the original motion and achieving subject replacement without being affected by the motion of other subjects. To address the above problems, we propose a novel three stage video editing pipeline. We initially leverage large pre-trained models to acquire knowledge about the shape and size differences between the original and replaced subjects. To mitigate interference from context motion, we erase other moving subjects to extract the target subject's motion and dynamically choose the editing method to preserve the original subject's motion under different shape transformation.\nFollowing that,we seamlessly replace the original subject in the video with the resized edited subject, ensuring its size harmonizes with the video's context.\nAs the first work to focus on this task, we also provide a high-quality evaluation dataset and metrics to assess the performance of existing methods on this task. Experimental results based on this dataset demonstrate that our method achieves state-of-the-art (SOTA) performance."
    },
    {
        "title": "Robust Decentralized VFL Over Dynamic Device Environment",
        "link_suffix": "/forum?id=ddNZLAWPdT",
        "link": "https://openreview.net/forum?id=ddNZLAWPdT",
        "pdf_link": "https://openreview.net/pdf?id=ddNZLAWPdT",
        "keywords": "Robustness, Vertical Federated Learning",
        "abstract": "Robust collaborative learning on a network of edge devices, for vertically split datasets, is challenging because edge devices may fail due to environment conditions or events such as extreme weather. The current Vertical Federated learning (VFL) approaches assume a centralized learning setup or assume the active party or server cannot fail. To address these limitations, we first formalize the problem of VFL under dynamic network conditions such as faults (named DN-VFL). Then, we develop a novel DN-VFL method calledMultipleAggregation withGossip Rounds andSimulated Faults (MAGS) that synthesizes faults via dropout, replication, and\ngossiping to improve robustness significantly over baselines. We also theoretically analyze our proposed approaches to explain why they enhance robustness. Extensive empirical results validate that MAGS is robust across a range of fault rates\u2014including extreme fault rates\u2014compared to prior VFL approaches."
    },
    {
        "title": "Sampling-Enhanced Large Neighborhood Search for Solving Integer Linear Programs",
        "link_suffix": "/forum?id=75MUsbVyWw",
        "link": "https://openreview.net/forum?id=75MUsbVyWw",
        "pdf_link": "https://openreview.net/pdf?id=75MUsbVyWw",
        "keywords": "Integer Linear Program, Combinatorial Optimization, Large Neighborhood Search, Simulated Annealing, Locally-informed Proposals",
        "abstract": "Large Neighborhood Search (LNS) is a common heuristic in combinatorial optimization \nthat iteratively searches over a large neighborhood of the current solution for a better one.  Recently, neural network-based LNS solvers have achieved great success in solving Integer Linear Program (ILP) problems \nwith a learnable\npolicy for neighborhood selection, followed by  an off-the-shelf ILP solver for re-optimization. \nNonetheless, existing neural LNS solvers often get stuck in the same solution due to their greedy update strategy, i.e., only moving to the best solution found within the neighborhood. In this work, we try to theoretically identify the limitation of neural models in escaping the \"local optima\". Accordingly, we propose\na novel sampling-enhanced neural LNS solver, namely SPL-LNS, by reformulating LNS as a stochastic process,\nwhich uses a locally-informed proposal to sample the next assignment and simulated annealing to alleviate the ``local optima'' issue. We also develop a novel hindsight relabeling method to efficiently train SPL-LNS on self-generated data. Experimental results reveal that our method substantially surpasses prior neural LNS  solvers on multiple ILP problems."
    },
    {
        "title": "Skill Discovery using Language Models",
        "link_suffix": "/forum?id=DBbgasVgyQ",
        "link": "https://openreview.net/forum?id=DBbgasVgyQ",
        "pdf_link": "https://openreview.net/pdf?id=DBbgasVgyQ",
        "keywords": "Reinforcement learning, Large language models, Robotics",
        "abstract": "Large Language models (LLMs) possess remarkable ability to understand natural language descriptions of complex robotics environments. Earlier studies have shown that LLM agents can use a predefined set of skills for robot planning in long-horizon tasks. However, the requirement for prior knowledge of the skill set required for a given task constrains its applicability and flexibility. We present a novel approach L2S (short of Language2Skills) to leverage the generalization capabilities of LLMs to decompose the natural language task description of a complex task to definitions of reusable skills. Each skill is defined by an LLM9 generated dense reward function and a termination condition, which in turn lead to effective skill policy training and chaining for task execution. To address the uncertainty surrounding the parameters used by the LLM agent in the generated reward and termination functions, L2S trains parameter-conditioned skill policies that performs well across a broad spectrum of parameter values. As the impact of these parameters for one skill on the overall task becomes apparent only when its following skills are trained, L2S selects the most suitable parameter value during the training of the subsequent skills to effectively mitigate the risk associated with incorrect parameter choices. During training, L2S autonomously accumulates a skill library from continuously presented tasks and their descriptions, leveraging guidance from the LLM agent to effectively apply this skill library in tackling novel tasks. Our experimental results show that L2S is capable of generating reusable skills to solve a wide range of robot manipulation tasks."
    },
    {
        "title": "Investigating the Pre-Training Dynamics of In-Context Learning: Task Recognition vs. Task Learning",
        "link_suffix": "/forum?id=htDczodFN5",
        "link": "https://openreview.net/forum?id=htDczodFN5",
        "pdf_link": "https://openreview.net/pdf?id=htDczodFN5",
        "keywords": "In-context learning",
        "abstract": "The emergence of in-context learning (ICL) is potentially attributed to two major abilities: task recognition (TR) for recognizing the task from demonstrations and utilizing pre-trained priors, and task learning (TL) for learning from demonstrations. However, relationships between the two abilities and how such relationships affect the emergence of ICL is unclear. In this paper, we take the first step by examining the pre-training dynamics of the emergence of ICL. With carefully designed metrics, we find that these two abilities are, in fact, competitive during pre-training. Moreover, we observe a negative correlation between the competition and the performance of ICL. Further analysis of common pre-training factors (i.e., model size, dataset size, and data curriculum) demonstrates possible ways to regulate the competition. Based on these insights, we propose a simple yet effective method to better integrate these two abilities for ICL at inference time. Through adaptive ensemble learning, the performance of ICL can be significantly boosted, enabling two small models to outperform a larger one with more than twice the parameters."
    }
]
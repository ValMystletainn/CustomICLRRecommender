[{"title": "Cream: Consistency Regularized Self-Rewarding Language Models", "link_suffix": "/forum?id=Vf6RDObyEF", "link": "https://openreview.net/forum?id=Vf6RDObyEF", "pdf_link": "https://openreview.net/pdf?id=Vf6RDObyEF", "keywords": "alignment, self-rewarding, large language model", "abstract": "Recent self-rewarding large language models (LLM) have successfully applied LLM-as-a-Judge to iteratively improve the alignment performance without the need of human annotations for preference data. These methods commonly utilize the same LLM to act as both the policy model (which generates responses) and the reward model (which scores and ranks those responses). The ranked responses are then used as preference pairs to train the LLM via direct alignment technologies (e.g. DPO). However, it is noteworthy that throughout this process, there is no guarantee on the accurate of the rewarding and ranking, which is critical for ensuring accurate rewards and high-quality preference data. Empirical results from relatively small LLMs (e.g., 7B parameters) also indicate that improvements from self-rewarding may diminish after several iterations in certain situations, which we hypothesize is due to accumulated bias in the reward system. This bias can lead to unreliable preference data for training the LLM. To address this issue, we first formulate and analyze the generalized iterative preference fine-tuning frame work for self-rewarding language model. We then introduce the regularization to this generalized framework to mitigate the overconfident preference labeling in the self-rewarding process. Based on this theoretical insight, we propose a Consistency Regularized sElf-rewarding lAnguage Model (CREAM) that leverages the rewarding consistency across different iterations to regularize the self-rewarding training, helping the model to learn from more reliable preference data. With this explicit regularization, our empirical results demonstrate the superiority of CREAM in improving both reward consistency and alignment performance.", "title_embedding_index": 18200, "title_abs_embedding_index": 18225}, {"title": "Temporal-Difference Variational Continual Learning", "link_suffix": "/forum?id=0wQCSXJbwt", "link": "https://openreview.net/forum?id=0wQCSXJbwt", "pdf_link": "https://openreview.net/pdf?id=0wQCSXJbwt", "keywords": "continual learning, online variational inference, temporal-difference learning", "abstract": "A crucial capability of Machine Learning models in real-world applications is the ability to continuously learn new tasks. This adaptability allows them to respond to potentially inevitable shifts in the data-generating distribution over time. However, in Continual Learning (CL) settings, models often struggle to balance learning new tasks (plasticity) with retaining previous knowledge (memory stability). Consequently, they are susceptible to Catastrophic Forgetting, which degrades performance and undermines the reliability of deployed systems. Variational Continual Learning methods tackle this challenge by employing a learning objective that recursively updates the posterior distribution and enforces it to stay close to the latest posterior estimate. Nonetheless, we argue that these methods may be ineffective due to compounding approximation errors over successive recursions. To mitigate this, we propose new learning objectives that integrate the regularization effects of multiple previous posterior estimations, preventing individual errors from dominating future posterior updates and compounding over time. We reveal insightful connections between these objectives and Temporal-Difference methods, a popular learning mechanism in Reinforcement Learning and Neuroscience. We evaluate the proposed objectives on challenging versions of popular CL benchmarks, demonstrating that they outperform standard Variational CL methods and non-variational baselines, effectively alleviating Catastrophic Forgetting.", "title_embedding_index": 18201, "title_abs_embedding_index": 18226}, {"title": "Controlling Statistical, Discretization, and Truncation Errors in Learning Fourier Linear Operators", "link_suffix": "/forum?id=SFuEabyr4v", "link": "https://openreview.net/forum?id=SFuEabyr4v", "pdf_link": "https://openreview.net/pdf?id=SFuEabyr4v", "keywords": "Operator Learning, Fourier Linear Operators", "abstract": "We investigate the problem of learning operators between function spaces, focusing on the linear part of a layer in the Fourier Neural Operator architecture. First, we identify three main errors that occur during the learning process: statistical error due to finite sample size, truncation error from finite rank approximation of the operator, and discretization error from handling functional data on a finite grid of domain points. Finally, we analyze a Discrete Fourier Transform (DFT) based least squares estimator, establishing both upper and lower bounds on the aforementioned errors.", "title_embedding_index": 18202, "title_abs_embedding_index": 18227}, {"title": "PICASO: Permutation-Invariant Composition of Document States", "link_suffix": "/forum?id=88TC1AWV27", "link": "https://openreview.net/forum?id=88TC1AWV27", "pdf_link": "https://openreview.net/pdf?id=88TC1AWV27", "keywords": "State Space Models, Composition, Retrieval", "abstract": "Generation with Large Language Models (LLMs) is often augmented by incorporating additional information \"in-context\" through the concatenation of multiple prepended documents. However, this process leads to significant computational costs that scale with the number and size of each document chunk. State Space Models (SSMs) offer a promising solution by allowing a database of documents to be pre-processed as states from which to start the generation. However, it is infeasible to store the state corresponding to  all possible combinations of multiple relevant documents. To address this challenge, we present a method called Permutation-Invariant Composition with State Space Models, or PICASO, which can compose states to efficiently approximate the effect of document concatenation. Our method can also enforce invariance to the order in which documents are presented, a desirable property when the temporal ordering of the documents is uninformative. We evaluate PICASO on WikiText and MSMARCO in both zero-shot and fine-tuned settings, and show that PICASO can match the performance of concatenation while enjoying on average 5.4x speedup.", "title_embedding_index": 18203, "title_abs_embedding_index": 18228}, {"title": "DeltaGNN: Graph Neural Network with Information Flow Control", "link_suffix": "/forum?id=xMxHJxp192", "link": "https://openreview.net/forum?id=xMxHJxp192", "pdf_link": "https://openreview.net/pdf?id=xMxHJxp192", "keywords": "deep learning, neural network, graph neural network, topology, homophily, heterophily, over-smoothing, over-squashing, long-range interactions", "abstract": "Graph Neural Networks (GNNs) are popular machine learning models designed to process graph-structured data through recursive neighborhood aggregations in the message passing process. When applied to semi-supervised node classification, the message-passing enables GNNs to understand short-range spatial interactions, but also causes them to suffer from over-smoothing and over-squashing. These challenges hinder model expressiveness and prevent the use of deeper models to capture long-range node interactions (LRIs) within the graph. Popular solutions for LRIs detection are either too expensive to process large graphs due to high time complexity or fail to generalize across diverse graph structures. To address these limitations, we propose a mechanism called information flow control, which leverages a novel connectivity measure, called information flow score, to address over-smoothing and over-squashing with linear computational overhead, supported by theoretical evidence. Finally, to prove the efficacy of our methodology we design DeltaGNN, the first scalable and generalizable approach for long-range and short-range interaction detection. \nWe benchmark our model across 10 real-world datasets, including graphs with varying sizes, topologies, densities, and homophilic ratios, showing superior performance with limited computational complexity.", "title_embedding_index": 18204, "title_abs_embedding_index": 18229}, {"title": "Self-Organizing Visual Embeddings for Non-Parametric Self-Supervised Learning", "link_suffix": "/forum?id=TswLvrIY8M", "link": "https://openreview.net/forum?id=TswLvrIY8M", "pdf_link": "https://openreview.net/pdf?id=TswLvrIY8M", "keywords": "self-supervised learning, clustering, representation learning, computer vision", "abstract": "We present Self-Organizing Visual Embeddings (SOVE) a new training technique for unsupervised representation learning.\nSOVE avoids learning prototypes from scratch and explores relationships between visual embeddings in a non-parametric space.\nUnlike existing clustering-based techniques that employ a single prototype to encode all the relevant features of a complex concept, we propose the SOVE method where a concept is represented by many semantically similar representations, or judges, each containing a complement set of features that together can fully characterize the concept and maximize training performance.\nWe reaffirm the feasibility of non-parametric self-supervised learning (SSL) by introducing novel non-parametric adaptions of two loss functions with the SOVE technique: (1) non-parametric cluster assignment prediction for class-level representations and (2) non-parametric Masked Image Modeling (MIM) for patch-level reconstruction.\nSOVE achieves state-of-the-art performance on many downstream benchmarks, including transfer learning, image retrieval, object detection, and segmentation.\nMoreover, SOVE demonstrates scaling performance when trained with Vision Transformers (ViTs), showing increased performance gains as more complex encoders are employed.", "title_embedding_index": 18205, "title_abs_embedding_index": 18230}, {"title": "Swiss Army Knife: Synergizing Biases in Knowledge from Vision Foundation Models for Multi-Task Learning", "link_suffix": "/forum?id=eePww5u7J3", "link": "https://openreview.net/forum?id=eePww5u7J3", "pdf_link": "https://openreview.net/pdf?id=eePww5u7J3", "keywords": "Vision Foundation Model, Multi-Task Learning, Knowledge Distillation", "abstract": "Vision Foundation Models (VFMs) have demonstrated outstanding performance on numerous downstream tasks. However, due to their inherent representation biases originating from different training paradigms, VFMs exhibit advantages and disadvantages across distinct vision tasks. Although amalgamating the strengths of multiple VFMs for downstream tasks is an intuitive strategy, effectively exploiting these biases remains a significant challenge. In this paper, we propose a novel and versatile \"Swiss Army Knife\" (SAK) solution, which adaptively distills knowledge from a committee of VFMs to enhance multi-task learning. Unlike existing methods that use a single backbone for knowledge transfer, our approach preserves the unique representation bias of each teacher by collaborating the lightweight Teacher-Specific Adapter Path modules with the Teacher-Agnostic Stem. Through dynamic selection and combination of representations with Mixture-of-Representations Routers, our SAK is capable of synergizing the complementary strengths of multiple VFMs. Extensive experiments show that our SAK remarkably outperforms prior state of the arts in multi-task learning by 10% on the NYUD-v2 benchmark, while also providing a flexible and robust framework that can readily accommodate more advanced model designs.", "title_embedding_index": 18206, "title_abs_embedding_index": 18231}, {"title": "Integration Flow Models", "link_suffix": "/forum?id=wUFbwlHvbk", "link": "https://openreview.net/forum?id=wUFbwlHvbk", "pdf_link": "https://openreview.net/pdf?id=wUFbwlHvbk", "keywords": "integration flow, ode-based generative models, diffusion models", "abstract": "Recently, ordinary differential equation (ODE) based generative models have emerged as a cutting-edge method for producing high-quality samples in many applications. Generally, these methods typically involve learning continuous transformation trajectories that map a simple initial distribution (i.e., Gaussian noise) to the target data distribution (i.e., images) by multiple steps of solving different ODE functions in inference to obtain high-quality results. However, the ODE-based methods either suffer the discretization error of numerical solvers of ODE, which restricts the quality of samples when only a few NFEs are used, or struggle with training instability. In this paper, we proposed Integration Flow, which learns the results of ODE-based trajectory paths directly without solving the ODE functions. Moreover, Integration Flow explicitly incorporates the target state $\\mathbf{x}_0$ as the anchor state in guiding the reverse-time dynamics and we have theoretically proven this can contribute to both stability and accuracy. To the best of our knowledge, Integration Flow is the first model with the unified structure to estimate ODE-based generative models. Through theoretical analysis and empirical evaluations, we show that Integration Flows achieve improved performance when it is applied to existing ODE-based model, such as diffusion models, Rectified Flows, and PFGM++. Specifically, Integration Flow achieves one-step generation on CIFAR10 with FID of 2.63 for Variance Exploding (VE) diffusion model, 3.4 for Rectified Flow without relflow and 2.96 for PFGM++. By extending the sampling to 1000 steps, we further reduce FID score to 1.71 for VE, setting state-of-the-art performance.", "title_embedding_index": 18207, "title_abs_embedding_index": 18232}, {"title": "Scene Flow as a Partial Differential Equation", "link_suffix": "/forum?id=0CieWy9ONY", "link": "https://openreview.net/forum?id=0CieWy9ONY", "pdf_link": "https://openreview.net/pdf?id=0CieWy9ONY", "keywords": "Scene Flow, Neural Prior, Partial Differential Equation, Reconstruction", "abstract": "We reframe scene flow as the task of estimating a continuous space-time PDE that describes motion for an entire observation sequence, represented with a neural prior. Our method,EulerFlow, optimizes this neural prior estimate against several multi-observation reconstruction objectives, enabling high quality scene flow estimation via pure self-supervision on real-world data. EulerFlow works out-of-the-box without tuning across multiple domains, including large-scale autonomous driving scenes and dynamic tabletop settings. Remarkably, EulerFlow produces high quality flow estimates on small, fast moving objects like birds and tennis balls, and exhibits emergent 3D point tracking behavior by solving its estimated PDE over long-time horizons. On the Argoverse 2 2024 Scene Flow Challenge, EulerFlow outperformsallprior art, surpassing the next-bestunsupervisedmethod by more than 2.5x, and even exceeding the next-bestsupervisedmethod by over 10%.", "title_embedding_index": 18208, "title_abs_embedding_index": 18233}, {"title": "DCT-CryptoNets: Scaling Private Inference in the Frequency Domain", "link_suffix": "/forum?id=lPJUQsSIxm", "link": "https://openreview.net/forum?id=lPJUQsSIxm", "pdf_link": "https://openreview.net/pdf?id=lPJUQsSIxm", "keywords": "homomorphic encryption, deep neural networks, privacy-preserving machine learning, frequency-domain learning", "abstract": "The convergence of fully homomorphic encryption (FHE) and machine learning offers unprecedented opportunities for private inference of sensitive data. FHE enables computation directly on encrypted data, safeguarding the entire machine learning pipeline, including data and model confidentiality. However, existing FHE-based implementations for deep neural networks face significant challenges in computational cost, latency, and scalability, limiting their practical deployment. This paper introduces DCT-CryptoNets, a novel approach that operates directly in the frequency-domain to reduce the burden of computationally expensive non-linear activations and homomorphic bootstrap operations during private inference. It does so by utilizing the discrete cosine transform (DCT), commonly employed in JPEG encoding, which has inherent compatibility with remote computing services where images are generally stored and transmitted in this encoded format. DCT-CryptoNets demonstrates a substantial latency reductions of up to 5.3$\\times$ compared to prior work on benchmark image classification tasks. Notably, it demonstrates inference on the ImageNet dataset within 2.5 hours (down from 12.5 hours on equivalent 96-thread compute resources). Furthermore, bylearningperceptually salient low-frequency information DCT-CryptoNets improves the reliability of encrypted predictions compared to RGB-based networks by reducing error accumulating homomorphic bootstrap operations. DCT-CryptoNets also demonstrates superior scalability to RGB-based networks by further reducing computational cost as image size increases. This study demonstrates a promising avenue for achieving efficient and practical private inference of deep learning models on high resolution images seen in real-world applications.", "title_embedding_index": 18209, "title_abs_embedding_index": 18234}, {"title": "Dynamic SVD-Enhanced Approach for Federated Learning", "link_suffix": "/forum?id=7TNfxnX3h9", "link": "https://openreview.net/forum?id=7TNfxnX3h9", "pdf_link": "https://openreview.net/pdf?id=7TNfxnX3h9", "keywords": "Federated Learning", "abstract": "Federated Learning (FL) has emerged as a promising paradigm for collaborative machine learning while preserving data privacy. However, existing FL approaches face challenges in balancing model generalization among heterogeneous clients and resistance to malicious attacks. This paper introduces Dynamic SVD-driven Federated Learning (DSVD-FL), a novel approach that addresses these challenges simultaneously. DSVD-FL dynamically adjusts the contribution of each client using Singular Value Decomposition (SVD), introducing an adaptive weighting mechanism based on singular value contributions and vector alignments. Theoretical analysis demonstrates the convergence properties and computational efficiency of our approach. Experimental results on both IID and non-IID datasets show that DSVD-FL outperforms state-of-the-art FL approaches in terms of model accuracy, robustness against various attack scenarios, while maintaining competitive computational efficiency. We perform an ablation study to explore the key components of SVD that impact the federated learning performance.", "title_embedding_index": 18210, "title_abs_embedding_index": 18235}, {"title": "LEMoN: Label Error Detection using Multimodal Neighbors", "link_suffix": "/forum?id=DWWwGlPMFr", "link": "https://openreview.net/forum?id=DWWwGlPMFr", "pdf_link": "https://openreview.net/pdf?id=DWWwGlPMFr", "keywords": "label error detection, noisy labels, image captions", "abstract": "Large repositories of image-caption pairs are essential for the development of vision-language models. However, these datasets are often extracted from noisy data scraped from the web, and contain many mislabeled instances. In order to improve the reliability of downstream models, it is important to identify and filter images with incorrect captions. However, beyond filtering based on image-caption embedding similarity, no prior works have proposed other methods to filter noisy multimodal data, or concretely assessed the impact of noisy captioning data on downstream training. In this work, we propose, theoretically justify, and empirically validate LEMoN, a method to automatically identify label errors in image-caption datasets. Our method leverages the multimodal neighborhood of image-caption pairs in the latent space of contrastively pretrained multimodal models to automatically identify label errors. Through empirical evaluations across eight datasets and ten baselines, we find that LEMoN outperforms the baselines by over 3% in label error detection, and that training on datasets filtered using our method improves downstream captioning performance by 2 BLEU points.", "title_embedding_index": 18211, "title_abs_embedding_index": 18236}, {"title": "ExpanDyNeRF: Expanding the Viewpoint of Dynamic Scenes beyond Constrained Camera Motions", "link_suffix": "/forum?id=L3DxhwXKZk", "link": "https://openreview.net/forum?id=L3DxhwXKZk", "pdf_link": "https://openreview.net/pdf?id=L3DxhwXKZk", "keywords": "NeRF, Dynamic NeRF, Generative Models, Super Resolution", "abstract": "In the domain of dynamic Neural Radiance Fields (NeRF) for novel view synthesis, current state-of-the-art (SOTA) techniques struggle when the camera's pose deviates significantly from the primary viewpoint, resulting in unstable and unrealistic outcomes. This paper introduces Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF method that integrates a Gaussian splatting prior to tackle novel view synthesis with large-angle rotations. ExpanDyNeRF employs a pseudo ground truth technique to optimize density and color features, which enables the generation of realistic scene reconstructions from challenging viewpoints. Additionally, we present the Synthetic Dynamic Multiview (SynDM) dataset, the first GTA V-based dynamic multiview dataset designed specifically for evaluating robust dynamic reconstruction from significantly shifted views. We evaluate our method quantitatively and qualitatively on both the SynDM dataset and the widely recognized NVIDIA dataset, comparing it against other SOTA methods for dynamic scene reconstruction. Our evaluation results demonstrate that our method achieves superior performance.", "title_embedding_index": 18212, "title_abs_embedding_index": 18237}, {"title": "Nonlinear multiregion neural dynamics with parametric impulse response communication channels", "link_suffix": "/forum?id=LbgIZpSUCe", "link": "https://openreview.net/forum?id=LbgIZpSUCe", "pdf_link": "https://openreview.net/pdf?id=LbgIZpSUCe", "keywords": "neural dynamics, multiregion, variational inference", "abstract": "Cognition arises from the coordinated interaction of brain regions with distinct computational roles. Despite improvements in our ability to extract the dynamics underlying circuit computation from population activity recorded in individual areas, understanding how multiple areas jointly support distributed computation remains a challenge. As part of this effort, we propose a multi-region neural dynamics model composed of two building blocks:i)within-region (potentially driven) nonlinear dynamics andii)communication channels between regions, parameterized through their impulse response. Together, these choices make it possible to learn nonlinear neural population dynamics and understand the flow of information between regions by drawing from the rich literature of linear systems theory.  We develop a state noise inversion free variational filtering and learning algorithm for our model and show, through neuroscientifically inspired numerical experiments, how the proposed model can reveal interpretable characterizations of the local computations within and the flow of information between neural populations.  We further validate the efficacy of our approach using simultaneous population recordings from areas V1 and V2.", "title_embedding_index": 18213, "title_abs_embedding_index": 18238}, {"title": "Towards improving saliency map interpretability using feature map smoothing", "link_suffix": "/forum?id=T7q5LBGISH", "link": "https://openreview.net/forum?id=T7q5LBGISH", "pdf_link": "https://openreview.net/pdf?id=T7q5LBGISH", "keywords": "computer vision; saliency map; explanations;  vanilla gradient; integrated gradient; smoothgrad", "abstract": "Input-gradient-based feature attribution methods, such as Vanilla Gradient, Integrated Gradients, and SmoothGrad, are widely used to explain image classifiers by generating saliency maps. However, these methods struggle to provide explanations that are both visually clear and quantitatively robust. Key challenges include ensuring that explanations are sparse, stable, and faithfully reflect the model\u2019s decision-making. Adversarial training, known for enhancing model robustness, have been shown to produce sparser explanations with these methods; however, this sparsity often comes at the cost of stability. In this work, we investigate the trade-off between stability and sparsity in saliency maps and propose the use of a smoothing layer during adversarial training. Through extensive experiments and evaluation, we demonstrate this smoothing technique improves the stability and faithfulness of saliency maps without sacrificing sparsity. Furthermore, a qualitative user study reveals that human evaluators tend to distrust explanations that are overly noisy or excessively sparse\u2014issues commonly associated with explanations in naturally and adversarially trained models, respectively and prefer explanations produced by our proposed approach. Our findings offer a promising direction for generating reliable explanations with robust models, striking a balance between clarity and usability.", "title_embedding_index": 18214, "title_abs_embedding_index": 18239}, {"title": "Larger language models do in-context learning differently", "link_suffix": "/forum?id=YzXPU3QRnL", "link": "https://openreview.net/forum?id=YzXPU3QRnL", "pdf_link": "https://openreview.net/pdf?id=YzXPU3QRnL", "keywords": "in-context learning, natural language processing, large language models", "abstract": "We study how in-context learning (ICL) in language models is affected by semantic priors versus input-label mappings. We investigate two setups - ICL with flipped labels and ICL with semantically-unrelated labels - across various model families (GPT-3, InstructGPT, Codex, an internal model, and an instruction-tuned variant of the internal model). First, experiments on ICL with flipped labels show that overriding semantic priors is an emergent ability of model scale. While small language models ignore flipped labels presented in-context and thus rely primarily on semantic priors from pretraining, large models can override semantic priors when presented with in-context exemplars that contradict priors, despite the stronger semantic priors that larger models may hold. We next study semantically-unrelated label ICL (SUL-ICL), in which labels are semantically unrelated to their inputs (e.g., foo/bar instead of negative/positive), thereby forcing language models to learn the input-label mappings shown in in-context exemplars in order to perform the task. The ability to do SUL-ICL also emerges primarily with scale, and large-enough language models can even perform linear classification in a SUL-ICL setting. Finally, we evaluate instruction-tuned models and find that instruction tuning strengthens both the use of semantic priors and the capacity to learn input-label mappings, but more of the former.", "title_embedding_index": 18215, "title_abs_embedding_index": 18240}, {"title": "DMDSpeech: Distilled Diffusion Model Surpassing The Teacher in Zero-shot Speech Synthesis via Direct Metric Optimization", "link_suffix": "/forum?id=LhuDdMEIGS", "link": "https://openreview.net/forum?id=LhuDdMEIGS", "pdf_link": "https://openreview.net/pdf?id=LhuDdMEIGS", "keywords": "text-to-speech, zero-shot speech synthesis, diffusion model, diffusion distillation, metric optimization", "abstract": "Diffusion models have demonstrated significant potential in speech synthesis tasks, including text-to-speech (TTS) and voice cloning. However, their iterative denoising processes are inefficient and hinder the application of end-to-end optimization with perceptual metrics. In this paper, we propose a novel method of distilling TTS diffusion models with direct end-to-end evaluation metric optimization, achieving state-of-the-art performance.  By incorporating Connectionist Temporal Classification (CTC) loss and Speaker Verification (SV) loss, our approach optimizes perceptual evaluation metrics, leading to notable improvements in word error rate and speaker similarity. Our experiments show that DMDSpeech consistently surpasses prior state-of-the-art models in both naturalness and speaker similarity while being significantly faster. Moreover, our synthetic speech has a higher level of voice similarity to the prompt than the ground truth in both human evaluation and objective speaker similarity metric. This work highlights the potential of direct metric optimization in speech synthesis, allowing models to better align with human auditory preferences. The audio samples are available athttps://dmdspeech.github.io/demo/.", "title_embedding_index": 18216, "title_abs_embedding_index": 18241}, {"title": "A Large-scale Training Paradigm for Graph Generative Models", "link_suffix": "/forum?id=c01YB8pF0s", "link": "https://openreview.net/forum?id=c01YB8pF0s", "pdf_link": "https://openreview.net/pdf?id=c01YB8pF0s", "keywords": "Large-scale Training, Graph Generative Model, Diffusion model", "abstract": "Large Generative Models (LGMs) such as GPT, Stable Diffusion, Sora, and Suno are trained on a huge amount of language corpus, images, videos, and audio that are extremely diverse from numerous domains. This large-scale training paradigm on diverse well-curated data enhances the creativity and diversity of the generated content. However, all previous graph-generative models (e.g., GraphRNN, MDVAE, MoFlow, GDSS, and DiGress) have been trained only on one dataset each time, which cannot replicate the revolutionary success achieved by LGMs in other fields. To remedy this crucial gap, we propose a large-scale training paradigm that uses a large corpus of graphs (over 5000 graphs) from 13 domains, leading to the development of large graph generative models (LGGMs). We empirically demonstrate that the pre-trained LGGMs have superior zero-shot generative capability to existing graph generative models. Furthermore, our pre-trained LGGMs can be easily fine-tuned with graphs from target domains and demonstrate even better performance than those directly trained from scratch, behaving as a solid starting point for real-world customization. The generated graphs can boost the training data and lead to better graph classification performance. Inspired by Stable Diffusion, we further equip LGGMs with the Text-to-Graph generation capability, such as describing the network name and domain (i.e., \"The power-1138-bus graph represents a network of buses in a power distribution system.\") and network statistics (i.e., \"The graph has a low average degree, suitable for modeling social media interactions.\"). This Text-to-Graph capability integrates the extensive world knowledge in the underlying language model, offering users fine-grained control of the generated graphs. We release the code, the model checkpoint, and the datasets athttps://github.com/GraphGG/LGGM.", "title_embedding_index": 18217, "title_abs_embedding_index": 18242}, {"title": "Hierarchical Demonstration Order Optimization for Many-shot In-Context Learning", "link_suffix": "/forum?id=yaR0hqaGbI", "link": "https://openreview.net/forum?id=yaR0hqaGbI", "pdf_link": "https://openreview.net/pdf?id=yaR0hqaGbI", "keywords": "In-context learning, Demonstration Order Optimization", "abstract": "In-Context Learning (ICL) is a technique where large language models (LLMs) leverage multiple demonstrations (i.e., examples) to perform tasks. With the recent expansion of LLM context windows, many-shot ICL (generally with more than 50 demonstrations) can lead to significant performance improvements  on a variety of language tasks such as text classification and question answering. Nevertheless, ICL faces demonstration order instability (ICL-DOI), which means that performance varies significantly depending on the order of demonstrations. Moreover, the ICL-DOI phenomenon persists and can sometimes be more pronounced in many-shot ICL, validated by our thorough experimental investigation. Current strategies handling ICL-DOI, however, are not applicable to many-shot ICL, since they cannot overcome two critical challenges: (1) Most metrics measuring the quality of demonstration order rely on subjective judgment, lacking a theoretical foundation to achieve precise quality characterization. These metrics are thus non-applicable to many-shot situations, where the order quality of different orders is less distinguishable due to the limited ability of LLMs to exploit information in long input contexts. (2) The requirement to examine all orders is computationally infeasible due to the combinatorial complexity of the order space in many-shot ICL. To tackle the first challenge, we design a demonstration order evaluation metric based on information theory for measuring order quality, which effectively quantifies the usable information gain of a given demonstration order. To address the second challenge, we propose a hierarchical demonstration order optimization method named HIDO that enables a more refined exploration of the order space, achieving high ICL performance without the need to evaluate all possible orders. Extensive experiments on multiple LLMs and real-world datasets demonstrate that our HIDO method consistently and efficiently outperforms other baselines. Our code can be found athttps://anonymous.4open.science/r/HIDO-B2DE/.", "title_embedding_index": 18218, "title_abs_embedding_index": 18243}, {"title": "MMSci: A Dataset for Graduate-Level Multi-Discipline Multimodal Scientific Understanding", "link_suffix": "/forum?id=DEOV74Idsg", "link": "https://openreview.net/forum?id=DEOV74Idsg", "pdf_link": "https://openreview.net/pdf?id=DEOV74Idsg", "keywords": "Scientific Figure Understanding, Multimodal Large Language Model, Large Vision Language Model, Multi-discipline, Multimodal, Scientific knowledge understanding, benchmark, Nature science, Visual instruction-following", "abstract": "The rapid development of Multimodal Large Language Models (MLLMs) is making AI-driven scientific assistants increasingly feasible, with interpreting scientific figures being a crucial task. However, existing datasets and benchmarks focus mainly on basic charts and limited science subjects, lacking comprehensive evaluations. To address this, we curated a multimodal, multidisciplinary dataset from peer-reviewed, open-access Nature Communications articles, spanning 72 scientific disciplines. This dataset includes figures such as schematic diagrams, simulated images, macroscopic/microscopic photos, and experimental visualizations (e.g., western blots), which often require graduate-level, discipline-specific expertise to interpret. We developed benchmarks for scientific figure captioning and multiple-choice questions, evaluating six proprietary and over ten open-source models across varied settings. The results highlight the high difficulty of these tasks and the significant performance gap among models. While many open-source models performed at chance level on the multiple-choice task, some matched the performance of proprietary models. However, the gap was more pronounced in the captioning task. Our dataset also provide valuable resource for training. Fine-tuning the Qwen2-VL-2B model with our task-specific multimodal training data improved its multiple-choice accuracy to a level comparable to GPT-4o, though captioning remains challenging. Continuous pre-training of MLLMs using our interleaved article and figure data enhanced their material generation capabilities, demonstrating potential for integrating scientific knowledge. The dataset and benchmarks will be released to support further research.", "title_embedding_index": 18219, "title_abs_embedding_index": 18244}, {"title": "Pretrained Hybrids with MAD Skills", "link_suffix": "/forum?id=rXrYdOtBfs", "link": "https://openreview.net/forum?id=rXrYdOtBfs", "pdf_link": "https://openreview.net/pdf?id=rXrYdOtBfs", "keywords": "hybrid architectures, large language models, transformers, state space models, model merging, neural architecture search, mechanistic search", "abstract": "While Transformers underpin modern large language models (LMs), a growing list of alternative architectures with new capabilities, promises, and tradeoffs is emerging. This makes choosing the right LM architecture challenging. Recently proposedhybrid architecturesseek a best-of-all-worlds approach that reaps the benefits of all architectures. Hybrid design is difficult for two reasons: it requires manual expert-driven search, and new hybrids must be trained from scratch. We proposeManticore, a framework that addresses these challenges byautomating the design of hybrid architectureswhile reusing pretrained models to createpretrainedhybrids. Our approach augments ideas from differentiable Neural Architecture Search (NAS) by incorporating simple projectors that translate features between pretrained blocks from different architectures. We then fine-tune hybrids that combine pretrained models from different architecture families---such as the GPT series and Mamba---end-to-end. With Manticore, we enable LM selection without training multiple models, the construction of pretrained hybrids from existing pretrained models, and the ability toprogrampretrained hybrids to have certain capabilities. Manticore hybrids match existing manually-designed hybrids, achieve strong performance on the Long Range Arena benchmark, and improve on pretrained transformers and state space models on various natural language tasks.", "title_embedding_index": 18220, "title_abs_embedding_index": 18245}, {"title": "Taming Continuous Spurious Shift in Domain Adaptation", "link_suffix": "/forum?id=G2AMCTTpCc", "link": "https://openreview.net/forum?id=G2AMCTTpCc", "pdf_link": "https://openreview.net/pdf?id=G2AMCTTpCc", "keywords": "Domain Adaptation, Causal Inference", "abstract": "Recent advances in domain adaptation have shown promise in transferring knowledge across domains characterized by a continuous value or vector, such as varying patient ages, where \"age'' serves as a continuous index. However, these approaches often fail when spurious features shift continuously along with the domain index. This paper introduces the first method designed to withstand the continuous shifting of spurious features during domain adaptation. Our method enhances domain adaptation performance by aligning causally transportable encodings across continuously indexed domains. Theoretical analysis demonstrates that our approach more effectively ensures causal transportability across different domains. Empirical results, from both semi-synthetic and real-world medical datasets, indicate that our method outperforms state-of-the-art domain adaptation methods.", "title_embedding_index": 18221, "title_abs_embedding_index": 18246}, {"title": "Towards flexible perception with visual memory", "link_suffix": "/forum?id=HoyKFRhwMS", "link": "https://openreview.net/forum?id=HoyKFRhwMS", "pdf_link": "https://openreview.net/pdf?id=HoyKFRhwMS", "keywords": "deep learning, computer vision, retrieval, memory", "abstract": "Training a neural network is a monolithic endeavor, akin to carving knowledge into stone: once the process is completed, editing the knowledge in a network is nearly impossible, since all information is distributed across the network's weights. We here explore a simple, compelling alternative by marrying the representational power of deep neural networks with the flexibility of a database. Decomposing the task of image classification into image similarity (from a pre-trained embedding) and search (via fast nearest neighbor retrieval from a knowledge database), we build a simple and flexible visual memory that has the following key capabilities:\n(1.) The ability to flexibly add data across scales: from individual samples all the way to entire classes and billion-scale data;\n(2.) The ability to remove data through unlearning and memory pruning;\n(3.) An interpretable decision-mechanism on which we can intervene to control its behavior.\nTaken together, these capabilities comprehensively demonstrate the benefits of an explicit visual memory. We hope that it might contribute to a conversation on how knowledge should be represented in deep vision models---beyond carving it in \"stone\" weights.", "title_embedding_index": 18222, "title_abs_embedding_index": 18247}, {"title": "ControlMM: Controllable Masked Motion Generation", "link_suffix": "/forum?id=Zp8NOZo0rA", "link": "https://openreview.net/forum?id=Zp8NOZo0rA", "pdf_link": "https://openreview.net/pdf?id=Zp8NOZo0rA", "keywords": "Masked Motion Model, Generative Model, Text-to-motion", "abstract": "Recent advances in motion diffusion models have enabled spatially controllable text-to-motion generation. However, despite achieving acceptable control precision, these models suffer from generation speed and fidelity limitations. To address these challenges, we propose ControlMM, a novel approach incorporating spatial control signals into the generative masked motion model. ControlMM achieves real-time, high-fidelity, and high-precision controllable motion generation simultaneously. Our approach introduces two key innovations. First, we propose masked consistency modeling, which ensures high-fidelity motion generation via random masking and reconstruction, while minimizing the inconsistency between the input control signals and the extracted control signals from the generated motion. To further enhance control precision, we introduce inference-time logit editing, which manipulates the predicted conditional motion distribution so that the generated motion, sampled from the adjusted distribution, closely adheres to the input control signals. During inference, ControlMM enables parallel and iterative decoding of multiple motion tokens, allowing for high-speed motion generation. Extensive experiments show that, compared to the state of the art, ControlMM delivers superior results in motion quality, with better FID scores (0.061 vs 0.271), and higher control precision (average error 0.0091 vs 0.0108). ControlMM generates motions 20 times faster than diffusion-based methods. Additionally, ControlMM unlocks diverse applications such as any joint any frame control, body part timeline control, and obstacle avoidance.", "title_embedding_index": 18223, "title_abs_embedding_index": 18248}, {"title": "Hierarchical Protein Backbone Generation with Latent and Structure Diffusion", "link_suffix": "/forum?id=J19jKa3wFj", "link": "https://openreview.net/forum?id=J19jKa3wFj", "pdf_link": "https://openreview.net/pdf?id=J19jKa3wFj", "keywords": "Proteins, latent diffusion", "abstract": "We propose a hierarchical protein backbone generative model that separates coarse and fine-grained details. Our approach called LSD consists of two stages: sampling latents which are decoded into a contact map then sampling atomic coordinates conditioned on the contact map. LSD allows new ways to control protein generation towards desirable properties while scaling to large datasets. In particular, the AlphaFold DataBase (AFDB) is appealing due as its diverse structure topologies but suffers from poor designability. We train LSD on AFDB and show latent diffusion guidance towards AlphaFold2 Predicted Alignment Error and long range contacts can explicitly balance designability, diversity, and noveltys in the generated samples. Our results are competitive with structure diffusion models and outperforms prior latent diffusion models.", "title_embedding_index": 18224, "title_abs_embedding_index": 18249}]
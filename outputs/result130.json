[
    {
        "title": "Dataset for Image-based Analysis of Mineral Fertilizer Granules",
        "link_suffix": "/forum?id=6nnWnLK8If",
        "link": "https://openreview.net/forum?id=6nnWnLK8If",
        "pdf_link": "https://openreview.net/pdf?id=6nnWnLK8If",
        "keywords": "Dataset, Industry, Fertilizer Granules, Quality Control, Instance Segmentation, Computer Vision",
        "abstract": "In the context of the mineral fertilizer industry, a crucial sector for global food production, which faces challenges in production efficiency and fast quality control, this work introduces the Mineral Fertilizer Dataset (MFD), a novel annotated segmentation dataset comprising 1,608 images and 125,648 instances of various fertilizer granules with different colors. Addressing the lack of datasets in this field, the MFD supports both semantic and instance segmentation tasks. Baseline models based on Feature Pyramid Network (FPN), UNet, and MANet were trained for semantic segmentation, while baseline models based on Mask R-CNN, YOLOv8, YOLOv9, and Mask2Former were trained for instance segmentation. Our experiments demonstrate the efficacy of these models, as well as the robustness of the trained models in identifying fertilizer granules of different colors not included in our dataset, as well as other granular objects such as Polyethylene Terephthalate (PET) pellets, corn, beans, and even pharmaceutical tablets. This dataset, along with its benchmark results on existing semantic and instance segmentation algorithms, aims to facilitate further advancements in computer vision applications for quality control in the fertilizer industry and related sectors."
    },
    {
        "title": "BiCert: A Blinear Mixed Integer Programming Formulation for Precise Certified Bounds Against Data Poisoning Attacks",
        "link_suffix": "/forum?id=mi9GJkZt8n",
        "link": "https://openreview.net/forum?id=mi9GJkZt8n",
        "pdf_link": "https://openreview.net/pdf?id=mi9GJkZt8n",
        "keywords": "Data Poisoning Defense, Certified Robustness, Provable Defenses, Robust Machine Learning, Adversarial Machine Learning",
        "abstract": "Data poisoning attacks pose one of the biggest threats to modern AI systems, necessitating robust defenses. While extensive efforts have been made to develop empirical defenses, attackers continue to evolve, creating sophisticated methods to circumvent these measures. To address this, we must move beyond empirical defenses and establish provable certification methods that guarantee robustness. This paper introduces a novel certification approach using Bilinear Mixed Integer Programming (BMIP) to compute sound, deterministic bounds that provide such provable robustness. Using BMIP, we compute the reachable set of parameters that could result from training with potentially manipulated data. A key insight to make this computation feasible is relaxing the reachable parameter set to a convex set between training iterations. At test time, this parameter set allows us to predict all possible outcomes, guaranteeing robustness. Our BMIP approach is more precise than previous methods, which rely solely on interval and polyhedral bounds. Crucially, it overcomes the fundamental limitation of prior approaches where parameter bounds could only grow, often uncontrollably. We show that these tighter bounds eliminate a key source of divergence issues, resulting in more stable training and higher certified accuracy."
    },
    {
        "title": "Neural Dynamic Pricing: Provable and Practical Efficiency",
        "link_suffix": "/forum?id=YsOndItIxV",
        "link": "https://openreview.net/forum?id=YsOndItIxV",
        "pdf_link": "https://openreview.net/pdf?id=YsOndItIxV",
        "keywords": "dynamic pricing, neural networks",
        "abstract": "Despite theoretical guarantees of existing dynamic pricing (DP) methods, their strong model assumptions may not reflect real-world conditions and are often unverifiable. This poses major challenges in practice since the performance of an algorithm may significantly degrade if the assumptions are not satisfied. Moreover, many DP algorithms show unfavorable empirical performance due to the lack of data efficiency. \n    To address these challenges, we design a practical contextual DP algorithm that utilizes regression oracles. Our proposed algorithm assumes only Lipschitz continuity on the true conditional probability of purchase.\n    We prove $\\tilde{\\mathcal{O}}(T^{\\frac{2}{3}}\\text{regret}_R(T)^{\\frac{1}{3}})$ regret upper bound where $T$ is the horizon and $\\text{regret}_R(T)$ is the regret of the oracle. The bound is nearly minimax optimal in the canonical case of finite function class, and our analysis generically applies to other function approximators including neural networks. To the best of our knowledge, our work is the first algorithm to utilize the powerful generalization capability of neural networks with provable guarantees in dynamic pricing literature.\n    Extensive numerical experiments show that our algorithm outperforms existing state-of-the-art dynamic pricing algorithms in various settings, which demonstrates both provable efficiency and practicality."
    },
    {
        "title": "PADriver: Towards Personalized Autonomous Driving",
        "link_suffix": "/forum?id=o3jgyJIhnv",
        "link": "https://openreview.net/forum?id=o3jgyJIhnv",
        "pdf_link": "https://openreview.net/pdf?id=o3jgyJIhnv",
        "keywords": "Personalized, Planning, Autonomous Driving, MLLM",
        "abstract": "In this paper, we propose PADriver, a novel closed-loop framework for personalized autonomous driving (PAD). Built upon Multi-modal Large Language Model (MLLM), PADriver takes streaming frames and personalized textual prompts as inputs. It autoaggressively performs scene understanding, danger level estimation and action decision. The predicted danger level reflects the risk of the potential action and provides an explicit reference for the final action, which corresponds to the preset personalized prompt. Moreover, we construct a closed-loop benchmark named PAD-Highway based on Highway-Env simulator to comprehensively evaluate the decision performance under traffic rules. The dataset contains 250 hours videos with high-quality annotation to facilitate the development of PAD behavior analysis. Experimental results on the constructed benchmark show that PADriver outperforms state-of-the-art approaches on different evaluation metrics, and enables various driving modes."
    },
    {
        "title": "Just Select Twice: Leveraging Low Quality Data to Improve Data Selection",
        "link_suffix": "/forum?id=dugoA2gfhs",
        "link": "https://openreview.net/forum?id=dugoA2gfhs",
        "pdf_link": "https://openreview.net/pdf?id=dugoA2gfhs",
        "keywords": "data selection, data valuation, data-centric AI, optimal transport, robust statistics",
        "abstract": "Data valuation is crucial for assessing the impact and quality of individual data points, enabling the ranking of data by importance for efficient data collection, storage, and training. Many data valuation methods are sensitive to outliers and require a certain level of noise to effectively distinguish low-quality data from high-quality data, making them particularly useful for data removal tasks. In particular, optimal transport-based methods exhibit notable performance in outlier detection but show only moderate effectiveness in high-quality data selection, due to their sensitivity to outliers and insensitivity to small variations. To mitigate the issue of insensitivity to high-quality data and facilitate effective data selection, in this paper, we propose a straightforward two-stage approach, JST, that initially does data valuation as usual, but then performs a second-round data selection where the identified low-quality data points are designated as the validation set to perform data valuation again. In this way, high-quality data become outliers with respect to the new validation set and can be naturally identified. We empirically evaluate an instantiation of our framework based on optimal transport method for data selection and data pruning on several standard datasets and our framework demonstrates superior performance compared to pure data valuation, especially under small noise conditions. Additionally, we show the general applicability of our framework to influence function based and reinforcement learning based data valuation methods."
    },
    {
        "title": "Knowledge And Capability Transfer Through Large Language Models' Parameters Fusing",
        "link_suffix": "/forum?id=vqbd2OQnGp",
        "link": "https://openreview.net/forum?id=vqbd2OQnGp",
        "pdf_link": "https://openreview.net/pdf?id=vqbd2OQnGp",
        "keywords": "large language model, post-training, transfer learning, model merging, weights averaging, artificial intelligence",
        "abstract": "The post-training phase of large language models (LLMs) plays a pivotal role in refining models to follow instructions and align with human preferences. However, this phase is fraught with challenges, particularly in sourcing high-quality post-training data. This paper introduces a novel approach, termed Parameters Fusing, that simplifies the post-training process by amalgamating model parameters delta from existing instruct-tuned checkpoints with a new base model tailored to specific domain data obtained by continual pre-training. Utilizing open-weight models such as Meta's Llama, our method replicates the effects of the traditional post-training phase while significantly reducing both time and resource costs. Moreover, it facilitates the customization of model attributes (e.g., tool usage, instruction-following, coding proficiency, and tonal qualities) by adjusting parameter deltas from multiple checkpoints. This approach not only minimizes the challenges of post-training data acquisition but also provides a flexible and efficient framework for enhancing LLMs with domain-specific knowledge or capabilities."
    },
    {
        "title": "A Theory of Initialisation's Impact on Specialisation",
        "link_suffix": "/forum?id=RQz7szbVDs",
        "link": "https://openreview.net/forum?id=RQz7szbVDs",
        "pdf_link": "https://openreview.net/pdf?id=RQz7szbVDs",
        "keywords": "machine learning theory, teacher student setup, initialisation, specialisation, statitistical mechanics of learning",
        "abstract": "Prior work has demonstrated a consistent tendency in neural networks engaged in continual learning tasks, wherein intermediate task similarity results in the highest levels of catastrophic interference. This phenomenon is attributed to the network's tendency to reuse learned features across tasks. However, this explanation heavily relies on the premise that neuron specialisation occurs, i.e. the emergence of localised representations. Our investigation challenges the validity of this assumption.\nUsing theoretical frameworks for the analysis of neural networks, we show a strong dependence of specialisation on the initial condition.\nMore precisely, we show that weight imbalance and high weight entropy can favour specialised solutions.\nWe then apply these insights in the context of continual learning, first showing the emergence of a monotonic relation between task-similarity and forgetting in non-specialised networks, and, finally, assessing the implications on the commonly employed elastic weight consolidation regularisation technique."
    },
    {
        "title": "AuToMATo: An Out-Of-The-Box Persistence-Based Clustering Algorithm",
        "link_suffix": "/forum?id=kp3Trt4uvf",
        "link": "https://openreview.net/forum?id=kp3Trt4uvf",
        "pdf_link": "https://openreview.net/pdf?id=kp3Trt4uvf",
        "keywords": "clustering, persistent homology, topological data analysis, tda, mapper algorithm",
        "abstract": "We present AuToMATo, a novel clustering algorithm based on persistent homology. While AuToMATo is not parameter-free per se, we provide default choices for its parameters that make it into an out-of-the-box clustering algorithm that performs well across the board. AuToMATo combines the existing ToMATo clustering algorithm with a bootstrapping procedure in order to separate significant peaks of an estimated density function from non-significant ones. We perform a thorough comparison of AuToMATo (with its parameters fixed to their defaults) against many other state-of-the-art clustering algorithms. We find not only that AuToMATo compares favorably against parameter-free clustering algorithms, but in many instances also significantly outperforms even the best selection of parameters for other algorithms. AuToMATo is motivated by applications in topological data analysis, in particular the Mapper algorithm, where it is desirable to work with a clustering algorithm that does not need tuning of its parameters. Indeed, we provide evidence that AuToMATo performs well when used with Mapper. Finally, we provide an open-source implementation of AuToMATo in Python that is fully compatible with the standard scikit-learn architecture."
    },
    {
        "title": "Manifolds, Random Matrices and Spectral Gaps: The geometric phases of generative diffusion",
        "link_suffix": "/forum?id=KlN00vQEY2",
        "link": "https://openreview.net/forum?id=KlN00vQEY2",
        "pdf_link": "https://openreview.net/pdf?id=KlN00vQEY2",
        "keywords": "Generative diffusion models, differential geometry, spectral gaps, random matrices, generalization, manifold",
        "abstract": "In this paper, we investigate the latent geometry of generative diffusion models under the manifold hypothesis. To this purpose, we analyze the spectrum of eigenvalues (and singular values) of the Jacobian of the score function, whose discontinuities (gaps) reveal the presence and dimensionality of distinct sub-manifolds. Using a statistical physics approach, we derive the spectral distributions and formulas for the spectral gaps under several distributional assumptions and we compare these theoretical predictions with the spectra estimated from trained networks. Our analysis reveals the existence of three distinct qualitative phase during the generative process:a trivial phase; a manifold coverage phase where the diffusion process fits the distribution internal to the manifold; a consolidation phase where the score becomes orthogonal to the manifold and all particles are projected on the support of the data. This `division of labor' between different timescales provides an elegant explanation on why generative diffusion models are not affected by the manifold overfitting phenomenon that plagues likelihood-based models, since the internal distribution and the manifold geometry are produced at different time points during generation."
    },
    {
        "title": "PrAViC: Probabilistic Adaptation Framework for Real-Time Video Classification",
        "link_suffix": "/forum?id=jawV7vhGHw",
        "link": "https://openreview.net/forum?id=jawV7vhGHw",
        "pdf_link": "https://openreview.net/pdf?id=jawV7vhGHw",
        "keywords": "Online classification, early decision, video processing",
        "abstract": "Video processing is generally divided into two main categories: processing of the entire video, which typically yields optimal classification outcomes, and real-time processing, where the objective is to make a decision as promptly as possible. The latter is often driven by the need to identify rapidly potential critical or dangerous situations. These could include machine failure, traffic accidents, heart problems, or dangerous behavior. Although the models dedicated to the processing of entire videos are typically well-defined and clearly presented in the literature, this is not the case for online processing, where a plethora of hand-devised methods exist. To address this, we present PrAViC, a novel, unified, and theoretically-based adaptation framework for dealing with the online classification problem for video data. The initial phase of our study is to establish a robust mathematical foundation for the theory of classification of sequential data, with the potential to make a decision at an early stage. This allows us to construct a natural function that encourages the model to return an outcome much faster. The subsequent phase is to present a straightforward and readily implementable method for adapting offline models to the online setting with recurrent operations. Finally, PrAViC is evaluated through comparison with existing state-of-the-art offline and online models and datasets, enabling the network to  significantly reduce the time required to reach classification decisions while maintaining, or even  enhancing, accuracy."
    },
    {
        "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space",
        "link_suffix": "/forum?id=mPdmDYIQ7f",
        "link": "https://openreview.net/forum?id=mPdmDYIQ7f",
        "pdf_link": "https://openreview.net/pdf?id=mPdmDYIQ7f",
        "keywords": "LLM agent, Modular design space, Agent search, AutoML",
        "abstract": "Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks. However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks. In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS). We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory. Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents. To further accelerate the process, we design a performance predictor that uses in-context surrogate models to skip unpromising agent designs. Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Moreover, AgentSquare can generate interpretable design insights, enabling a deeper understanding of agentic architecture and its impact on task performance. We believe that the modular design space and AgentSquare search framework offer a platform for fully exploiting the potential of prior successful designs and consolidate the collective efforts of research community. Code repo is available athttps://github.com/ICLR-10021/AgentSquare."
    },
    {
        "title": "Dolphin: A Programmable Framework for Scalable Neurosymbolic Learning",
        "link_suffix": "/forum?id=3NFtzhFbYM",
        "link": "https://openreview.net/forum?id=3NFtzhFbYM",
        "pdf_link": "https://openreview.net/pdf?id=3NFtzhFbYM",
        "keywords": "neurosymbolic learning, scalability, vectorization, differentiable reasoning",
        "abstract": "Neurosymbolic learning has emerged as a promising paradigm to incorporate\nsymbolic reasoning into deep learning models.\nHowever, existing frameworks are limited in scalability with respect to both\nthe training data and the complexity of symbolic programs.\nWe propose Dolphin, a framework to scale neurosymbolic learning at a fundamental level by mapping both forward chaining and backward gradient propagation in symbolic programs \nto vectorized computations.\nFor this purpose, Dolphin introduces a set of abstractions and primitives \nbuilt directly on top of a high-performance deep learning framework like \nPyTorch, effectively enabling symbolic programs to be written as PyTorch modules.\nIt thereby enables neurosymbolic programs to be written in a language like Python that is familiar to developers and compile them to computation graphs that are amenable to end-to-end differentiation on GPUs.\nWe evaluate Dolphin on a suite of 13 benchmarks across 5 neurosymbolic tasks that combine deep learning models for\ntext, image, or video processing with symbolic programs that involve multi-hop \nreasoning, recursion, and even black-box functions like Pythoneval().\nDolphin only takes 0.33% -- 37.17% of the time (and 2.77% on average) to train these models on the largest input per task compared to baselines  Scallop, ISED, and IndeCateR+, which time out on most of these inputs.\nModels written in Dolphin also achieve state-of-the-art accuracies even on the largest benchmarks."
    },
    {
        "title": "Energy-based Backdoor Defense Against Federated Graph Learning",
        "link_suffix": "/forum?id=5Jc7r5aqHJ",
        "link": "https://openreview.net/forum?id=5Jc7r5aqHJ",
        "pdf_link": "https://openreview.net/pdf?id=5Jc7r5aqHJ",
        "keywords": "Federated Learning, Graph Learning",
        "abstract": "Federated Graph Learning is rapidly evolving as a privacy-preserving collaborative approach. However, backdoor attacks are increasingly undermining federated systems by injecting carefully designed triggers that lead to the model making incorrect predictions. Trigger structures and injection locations in Federated Graph Learning are more diverse, making traditional federated defense methods less effective. In our work, we propose an effective Federated Graph Backdoor Defense using Topological Graph Energy (FedTGE). At the local client level, it injects distribution knowledge into the local model, assigning low energy to benign samples and high energy to the constructed malicious substitutes, and selects benign clients through clustering. At the global server level, the energy elements uploaded by each client are treated as new nodes to construct a global energy graph for energy propagation, making the selected clients' energy elements more similar and further adjusting the aggregation weights. Our method can handle high data heterogeneity, does not require a validation dataset, and is effective under both small and large malicious proportions. Extensive results on various settings of federated graph scenarios under backdoor attacks validate the effectiveness of this approach."
    },
    {
        "title": "Seeking Global Flat Minima in Federated Domain Generalization via Constrained Adversarial Augmentation",
        "link_suffix": "/forum?id=mmGc0TR8zB",
        "link": "https://openreview.net/forum?id=mmGc0TR8zB",
        "pdf_link": "https://openreview.net/pdf?id=mmGc0TR8zB",
        "keywords": "Federated Domain Generalization, Flat Minima, Data Augmentation",
        "abstract": "Federated domain generalization (FedDG) aims at equipping the federally trained model with the domain generalization ability when the model meets new clients with domain shifts. Among factors that possibly indicate generalization, the loss landscape flatness of the trained model is an intuitive, viable, and widely studied one. However, pursuing the flatness of the global model in the FedDG setting is not trivial due to the restriction to preserve data privacy. To address this issue, we propose GFM, a novel algorithm designed to seek Global Flat Minima of the global model. Specifically, GFM leverages a global model-constrained adversarial data augmentation strategy, creating a surrogate for global data within each local client, which allows for split sharpness-aware minimization to approach global flat minima. GFM is compatible with federated learning without compromising data privacy restrictions, and theoretical analysis further supports its rationality by demonstrating that the objective of GFM serves as an upper bound on the robust risk of the global model on global data distribution. Extensive experiments on multiple FedDG benchmarks demonstrate that GFM consistently outperforms previous FedDG and federated learning approaches."
    },
    {
        "title": "Optimal Generative Cyclic Transport between Image and Text",
        "link_suffix": "/forum?id=ZjKTMmWKHP",
        "link": "https://openreview.net/forum?id=ZjKTMmWKHP",
        "pdf_link": "https://openreview.net/pdf?id=ZjKTMmWKHP",
        "keywords": "Cross-modal Information Transformation, Generative Models, Optimal Transport",
        "abstract": "Deep generative models, such as vision-language models (VLMs) and diffusion models (DMs), have achieved remarkable success in cross-modality generation tasks. However, the cyclic transformation of text $\\rightarrow$ image $\\rightarrow$ text often fails to secure an exact match between the original and the reconstructed content. In this work, we attempt to address this challenge by utilizing a deterministic function to guide the reconstruction of precise information via generative models. Using color histogram as guidance, we first identify a soft prompt to generate the desired text using a language model and map the soft prompt to a target histogram. We then utilize the target color histogram as a constraint for the diffusion model and formulate the intervention as an optimal transport problem. As a result, the generated image has the exact color histogram as the target, which can be converted to a soft prompt deterministically for reconstructing the text. This allows the generated images to entail arbitrary forms of text (e.g., natural text, code, URLs, etc.) while ensuring the visual content is as natural as possible. As a steganography technique, our method offers significant potential for applications such as content fingerprinting and secure communications via generative encryption."
    },
    {
        "title": "Multi-Task Corrupted Prediction for Learning Robust Audio-Visual Speech Representation",
        "link_suffix": "/forum?id=WEQL5ksDnB",
        "link": "https://openreview.net/forum?id=WEQL5ksDnB",
        "pdf_link": "https://openreview.net/pdf?id=WEQL5ksDnB",
        "keywords": "robust audio-visual speech recognition, audio-visual corruption, multimodal representation learning",
        "abstract": "Audio-visual speech recognition (AVSR) incorporates auditory and visual modalities to improve recognition accuracy, particularly in noisy environments where audio-only speech systems are insufficient. While previous research has largely addressed audio disruptions, few studies have dealt with visual corruptions, e.g., lip occlusions or blurred videos, which are also detrimental. To address this real-world challenge, we propose CAV2vec, a novel self-supervised speech representation learning framework particularly designed to handle audio-visual joint corruption. CAV2vec employs a self-distillation approach with a corrupted prediction task, where the student model learns to predict corrupted frames while clean targets are generated by the teacher model. Specifically, we suggest a unimodal multi-task learning, which distills cross-modal knowledge and aligns the corrupted modalities, by predicting clean audio targets with corrupted videos, and clean video targets with corrupted audios. This strategy mitigates the dispersion in the representation space caused by corrupted modalities, leading to more reliable and robust audio-visual fusion. Our experiments on robust AVSR benchmarks demonstrate that the corrupted representation learning method significantly enhances recognition accuracy across generalized environments involving various types of corruption."
    },
    {
        "title": "Quantization Enhanced Cross-modal Alignment for Gene Expression Prediction",
        "link_suffix": "/forum?id=Le823SjZEc",
        "link": "https://openreview.net/forum?id=Le823SjZEc",
        "pdf_link": "https://openreview.net/pdf?id=Le823SjZEc",
        "keywords": "Gene Expression Prediction, Cross-modal Alignment",
        "abstract": "In modern healthcare, whole-slide histological images (WSIs) provide information on tissue structure and composition at the microscopic level. Integrating WSIs and gene expression profiles enhances cancer diagnosis and treatment planning, advancing clinical care and research. However, spatial transcriptomics is costly and requires a long sampling time. The intrinsic correlation between histological images and gene expressions offers the potential for predicting spatial transcriptomics using Hematoxylin-Eosin (H&E) stained WSIs to reduce time and resource costs. Although existing methods have achieved impressive results, they ignore the heterogeneity between modalities of image and gene expression. In this paper, we propose a Quantized Cross-modal Alignment (QCA) that exploits cross-modal interactions to address the issue of modal heterogeneity. Considering the interference of gene-unrelated image features, we develop a Gene-related Image Feature Quantizer (GIFQ) to capture the gene-related image features. Meanwhile, we develop an Asymmetric Cross-modal Alignment (ACA) approach, which facilitates the model to generate discriminative predictions from similar visual presentations. In addition, to fix the discriminability reduction, a Discriminability-Enhancing Regularization (DER) is further devised to regularize both the virtual and real gene features. Experimental results on a breast cancer dataset sampled by solid-phase transcriptome capture elucidate that our QCA model achieves state-of-the-art results for accurate prognostication of gene expression profiles, increasing the performance by 13% at least. Our method utilizes deep learning technology to delineate the correlation between morphological features and gene expression, furnishing new perspectives and instruments for disclosing biomarkers in histological conditions. The code will be released."
    },
    {
        "title": "Application of Metric Transformation in One-Step Retrosynthesis",
        "link_suffix": "/forum?id=o1efpbvR6v",
        "link": "https://openreview.net/forum?id=o1efpbvR6v",
        "pdf_link": "https://openreview.net/pdf?id=o1efpbvR6v",
        "keywords": "Retrosynthesis, Chemistry, Deep Metric Learning, Transformer",
        "abstract": "In this article, we investigate the impact of Deep Metric Learning and Transformer architecture on predicting the retrosynthesis of Simplified Molecular Input Line Entry System (SMILES) chemical compounds.We demonstrate that combining the Attention mechanism with Proxy Anchor Loss is effective for classification tasks due to its strengths in capturing both local and global contexts and differentiating between various classes.Our approach, which requires no prior chemical knowledge, achieves promising results on the USPTO-FULL dataset, with accuracies of 53.4%, 83.8%, 90.6%, and 97.5% for top-1, top-5, top-10, and top-50 predictions, respectively.We further validate the practical application of our approach by correctly predicting the retrosynthesis pathways for 63 out of 100 randomly selected compounds from the ChEMBL database and for 39 out of 60 compounds selected by Bayer's chemists and from PubChem."
    },
    {
        "title": "Unlocking Compositional Understanding of Vision-Language Models with Visualization Representation and Analysis",
        "link_suffix": "/forum?id=vo5Md2RCWq",
        "link": "https://openreview.net/forum?id=vo5Md2RCWq",
        "pdf_link": "https://openreview.net/pdf?id=vo5Md2RCWq",
        "keywords": "Vision-Language Models, Compositional Understanding, Visualization Representation and Analysis",
        "abstract": "Vision-language models (VLMs) have made significant advances, debates persist about their ability to understand the combined meaning of vision and linguistic. Existing research primarily relies on computer vision knowledge and static images to deliver findings and insights into compositional understanding of VLMs. There is still a limited understanding of how VLMs handle subtle differences between visual and linguistic information. This paper introduces an interactive visualization representation and analysis approach from outside the computer vision community. In this study, we found that CLIP's performance in compositional understanding only slightly exceeds the chance level of 50%. Particularly, it primarily relies on entities in visual and textual modalities, but is limited in recognizing spatial relationships, attribute ownership, and interaction relationships. Additionally, It behaves more like a bag-of-words model and relies on global feature alignment rather than fine-grained alignment, leading to insensitivity to subtle perturbations in text and images."
    },
    {
        "title": "ABAS-RAL: Adaptive BAtch Size using Reinforced Active Learning",
        "link_suffix": "/forum?id=pRUxNDrfvk",
        "link": "https://openreview.net/forum?id=pRUxNDrfvk",
        "pdf_link": "https://openreview.net/pdf?id=pRUxNDrfvk",
        "keywords": "Active learning, Reinforcement Learning, Adaptive Batch Size, Annotation Budget",
        "abstract": "Active learning reduces annotation costs by selecting the most informative samples, however fixed batch sizes used in traditional methods often lead to inefficient use of resources. We propose Adaptive BAtch Size using Reinforced Active Learning, a novel approach that dynamically adjusts batch sizes based on model uncertainty and performance. By framing the annotation process as a Markov Decision Process, the proposed method employs reinforcement learning to optimize batch size selection, using two distinct policies: one targeting precision and budget, and the other for adapting the batch size based on learning progress. The proposed method is evaluated on both CIFAR-10, CIFAR-100 and MNIST datasets. The performance is measured across multiple metrics, including precision, accuracy, recall, F1-score, and annotation budget. Experimental results demonstrate that the proposed method consistently reduces annotation costs while maintaining or improving performance compared to fixed-batch Active Learning methods, achieving higher sample selection efficiency without compromising model quality."
    },
    {
        "title": "Improving Human Pose-Conditioned Generation: Fine-tuning ControlNet Models with Reinforcement Learning",
        "link_suffix": "/forum?id=Fk4Op9wpEp",
        "link": "https://openreview.net/forum?id=Fk4Op9wpEp",
        "pdf_link": "https://openreview.net/pdf?id=Fk4Op9wpEp",
        "keywords": "Generative AI, Reinforcement Learning, Text to Image Generation, Image to Image Generation, Multi-modal learning",
        "abstract": "Advancements in diffusion-based text-to-image generation models have made it possible to create high-quality human images. However, generating humans in desired poses using text prompts alone remains challenging. Image-to-image generation methods utilizing additional image conditions can address this issue; however, they often struggle with generating images that accurately match conditioning images. This paper proposes a new fine-tuning framework for training ControlNet models with reinforcement learning by combining ControlNet and Denoising Diffusion Policy Optimization~(DDPO) to understand pose conditioning images better. We apply a novel reward function in the proposed framework for higher pose accuracy. We demonstrate that our method effectively improves human generation by enhancing pose accuracy and the correct generation of body parts without omissions or additions. In addition, we demonstrate that the effectiveness of using a more detailed pose dataset along with our proposed reward function that directly leverages keypoints, leads to improved training results."
    },
    {
        "title": "Size-Generalizable RNA Structure Evaluation by Exploring Hierarchical Geometries",
        "link_suffix": "/forum?id=QaTBHSqmH9",
        "link": "https://openreview.net/forum?id=QaTBHSqmH9",
        "pdf_link": "https://openreview.net/pdf?id=QaTBHSqmH9",
        "keywords": "RNA Structure, RNA Evaluation, Geometric Deep Learning, Graph Neural Networks",
        "abstract": "Understanding the 3D structure of RNA is essential for deciphering its function and developing RNA-based therapeutics. Geometric Graph Neural Networks (GeoGNNs) that conform to the $\\mathrm{E}(3)$-symmetry have advanced RNA structure evaluation, a crucial step toward RNA structure prediction. However, existing GeoGNNs are still defective in two aspects: 1. inefficient or incapable of capturing the full geometries of RNA; 2. limited generalization ability when the size of RNA significantly differs between training and test datasets. In this paper, we propose EquiRNA, a novel equivariant GNN model by exploring the three-level hierarchical geometries of RNA. At its core, EquiRNA effectively addresses the size generalization challenge by reusing the representation of nucleotide, the common building block shared across RNAs of varying sizes. Moreover, by adopting a scalarization-based equivariant GNN as the backbone, our model maintains directional information while offering higher computational efficiency compared to existing GeoGNNs. Additionally, we propose a size-insensitive $K$-nearest neighbor sampling strategy to enhance the model's robustness to RNA size shifts. We test our approach on our created benchmark as well as an existing dataset. The results show that our method significantly outperforms other state-of-the-art methods, providing a robust baseline for RNA 3D structure modeling and evaluation."
    },
    {
        "title": "Leveraging Knowledge Graphs to harvest a high-quality dataset for efficient CLIP model training",
        "link_suffix": "/forum?id=hQY03s8rOm",
        "link": "https://openreview.net/forum?id=hQY03s8rOm",
        "pdf_link": "https://openreview.net/pdf?id=hQY03s8rOm",
        "keywords": "vision-language, image-text, contrastive learning, CLIP, dataset, knowledge graph, wordnet, wikidata, entities, attributes, image search, imagenet, inaturalist, cub, ovad, attribute classification, animals, plants, small data, efficiency, open vocabulary",
        "abstract": "Vision-language contrastive learning based on the CLIP method has been instrumental in driving recent advancements in computer vision. However, high quality CLIP models are based on very large datasets. This makes them expensive to train and hampers the scientific analysis of these models. We show how to train a CLIP base-size model efficiently for a broad domain on a much smaller amount of data. We demonstrate this specifically with the automated creation of a dataset named LivingThings with 8.9M images of animals and plants and 12.2M texts. The dataset is obtained via focused image-search queries of three kinds: entity queries (e.g.,eagle''), entity-attribute queries (e.g.,bushy tail of a fox''), and type-attribute queries (e.g., ``insect on a leaf''). The entities and types, as well as some of the texts, are derived from the WordNet and Wikidata knowledge graphs, the attributes are obtained via LLMs. We train a CLIP model from scratch on LivingThings and evaluate it on ImageNet, iNaturalist, and CUB for object classification and OVAD and CUB for attribute classification. On the broad target domain of animals and plants, our model achieves comparable, and sometimes even much better performance than models that have orders of magnitude more parameters or training data. For instance, our ViT-B-32 model improves over much larger state-of-the-art CLIP models on the iNaturalist 21 object classification task. We will publicly release our code and dataset."
    },
    {
        "title": "CASE: Challenger Arm Sampling for Efficient In-Context Reasoning",
        "link_suffix": "/forum?id=qvwcK4Uz8z",
        "link": "https://openreview.net/forum?id=qvwcK4Uz8z",
        "pdf_link": "https://openreview.net/pdf?id=qvwcK4Uz8z",
        "keywords": "In-Context Learning, Large Language Models, Exemplar Selection, Stochastic Linear Bandits, Challenger Arms",
        "abstract": "The in-context learning paradigm with LLMs has been instrumental in advancing applications that require complex reasoning over natural language. An optimal selection of few-shot examples (exemplars) is essential for constructing effective prompts under a limited budget.\nIn this paper, we frame the problem of exemplar selection for In-Context Reasoning (ICR) as a top-m best arms identification problem. A key challenge in this context is the exponentially large number of arms that need to be evaluated to identify the m-best arms. We propose CASE (Challenger Arm Sampling for Exemplar selection), a novel selective exploration strategy that maintains a shortlist of ``challenger'' arms, which are current candidates for the top-m arms. In each iteration, only the arms from this shortlist and the current top-m set are pulled, thereby reducing sample complexity and, consequently, the number of LLM evaluations. Furthermore, we model the scores of exemplar subsets (arms) using a parameterized linear scoring function, leading to a stochastic linear bandits setting. In this setting, CASE identifies the top-m arms with significantly fewer evaluations than existing state-of-the-art methods. CASE effectively works with black box LLMs and selects a static set of few-shot examples, resulting in an extremely efficient scheme for in-context reasoning. The exemplars selected with CASE show surprising performance gains of up to 15.19% compared to state-of-the-art exemplar selection methods. We release our code and data (https://anonymous.4open.science/r/CASE_exemplar_bandits-7403)."
    },
    {
        "title": "Extending Contextual Self-Modulation: Meta-Learning Across Modalities, Task Dimensionalities, and Data Regimes",
        "link_suffix": "/forum?id=py54X6mAEy",
        "link": "https://openreview.net/forum?id=py54X6mAEy",
        "pdf_link": "https://openreview.net/pdf?id=py54X6mAEy",
        "keywords": "contextual meta-learning, gradient-based meta-learning, OOD generalisation, neural context flows",
        "abstract": "Contextual Self-Modulation (CSM) is a potent regularization mechanism for the Neural Context Flow (NCF) framework which demonstrates powerful meta-learning of physical systems. However, CSM has limitations in its applicability across different modalities and in high-data regimes. In this work, we introduce two extensions: $i$CSM, which expands CSM to infinite-dimensional tasks, and StochasticNCF, which improves scalability. These extensions are demonstrated through comprehensive experimentation on a range of tasks, including dynamical systems with parameter variations, computer vision challenges, and curve fitting problems. $i$CSM embeds the contexts into an infinite-dimensional function space, as opposed to CSM which uses finite-dimensional context vectors. StochasticNCF enables the application of both CSM and $i$CSM to high-data scenarios by providing an unbiased approximation of meta-gradient updates through a sampled set of nearest environments. Additionally, we incorporate higher-order Taylor expansions via Taylor-Mode automatic differentiation, revealing that higher-order approximations do not necessarily enhance generalization. Finally, we demonstrate how CSM can be integrated into other meta-learning frameworks with FlashCAVIA, a computationally efficient extension of the CAVIA meta-learning framework (Zintgraf et al. 2019). FlashCAVIA outperforms its predecessor across various benchmarks and reinforces the utility of bi-level optimization techniques. Together, these contributions establish a robust framework for tackling an expanded spectrum of meta-learning tasks, offering practical insights for out-of-distribution generalization. Our open-sourced library, designed for flexible integration of self-modulation into contextual meta-learning workflows, is available at \\url{CODE}."
    }
]
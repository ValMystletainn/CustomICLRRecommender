[
    {
        "title": "\u03b2-calibration of Language Model Confidence Scores for Generative QA",
        "link_suffix": "/forum?id=D2hhkU5O48",
        "link": "https://openreview.net/forum?id=D2hhkU5O48",
        "pdf_link": "https://openreview.net/pdf?id=D2hhkU5O48",
        "keywords": "Calibration, Language Models",
        "abstract": "To use generative question-and-answering (QA) systems for decision-making and in any critical application, these systems need to provide well-calibrated confidence scores that reflect the correctness of their answers. Existing calibration methods aim to ensure that the confidence score ison averageindicative of the likelihood that the answer is correct.  We argue, however, that this standard (average-case) notion of calibration is difficult to interpret for decision-making in generative QA. To address this, we generalize the standard notion of average calibration and introduce $\\beta$-calibration, which ensures calibration holds across different question-and-answer groups. We then propose discretized posthoc calibration schemes for achieving $\\beta$-calibration. We establish distribution-free guarantees on the performance of this method and validate our method on confidence scores returned by elicitation prompts across multiple QA benchmarks and LLMs."
    },
    {
        "title": "Measurement information multiple-reuse allows deeper quantum transformer",
        "link_suffix": "/forum?id=usX2ixXopC",
        "link": "https://openreview.net/forum?id=usX2ixXopC",
        "pdf_link": "https://openreview.net/pdf?id=usX2ixXopC",
        "keywords": "quantum machine learning, quantum transformer, measurement information multiple reuse",
        "abstract": "The current era has witnessed the success of the transformer in the field of classical deep neural networks (DNNs) and the potential of quantum computing. One naturally expects that quantum computing can offer significant speedup for the transformer. Recent developments of quantum transformer models are faced with challenges including the expensive cost of non-linear operations and the information loss problem caused by measurements. To address this issue, this paper proposes a scheme called measurement information multiple-reuse (MIMR). MIMR enables the repeated utilization of intermediate measurement data from former layers, thus enhancing information-transferring efficiency. This scheme facilitates our quantum vision transformer (QViT) capable of achieving exponential speedup compared to classical counterparts, with the support of many parameters and large depth. Our QViT model is further examined with an instance of 86 million parameters, which halves the requirements for tomography error compared to the one without MIMR. This demonstrates the superior performance of MIMR over existing schemes. Our findings underscore the importance of exploiting the value of information from each measurement, offering a key strategy towards scalable quantum deep neural networks."
    },
    {
        "title": "ExDBN: Exact learning of Dynamic Bayesian Networks",
        "link_suffix": "/forum?id=eqQFBnjjPP",
        "link": "https://openreview.net/forum?id=eqQFBnjjPP",
        "pdf_link": "https://openreview.net/pdf?id=eqQFBnjjPP",
        "keywords": "causal lerning, bayesian network, structural equation model",
        "abstract": "Causal learning from data has received much attention in recent years. One way of capturing causal relationships is by utilizing Bayesian networks. There, one recovers a weighted directed acyclic graph, in which random variables are represented by vertices, and the weights associated with each edge represent the strengths of the causal relationships between them. This concept is extended to capture dynamic effects by introducing a dependency on past data,  which may be captured by the structural equation model, which is utilized in the present contribution to formulate a score-based learning approach. A mixed-integer quadratic program is formulated and an algorithmic solution proposed, in which the pre-generation of exponentially many acyclicity constraints is avoided by utilizing the so-called branch-and-cut (``lazy constraint'') method. Comparing the novel approach to the state of the art, we show that the proposed approach turns out to produce excellent results when applied to small and medium-sized synthetic instances of up to 25 time-series. Lastly, two interesting applications in bio-science and finance, to which the method is directly applied, further stress the importance of developing highly accurate (globally convergent) solvers that can handle modest instances."
    },
    {
        "title": "ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation",
        "link_suffix": "/forum?id=8pusxkLEQO",
        "link": "https://openreview.net/forum?id=8pusxkLEQO",
        "pdf_link": "https://openreview.net/pdf?id=8pusxkLEQO",
        "keywords": "transformer; video generation; diffusion",
        "abstract": "Text-to-video (T2V) models have recently undergone rapid and substantial advancements. Nevertheless, due to limitations in data and computational resources, achieving efficient generation of long videos with rich motion dynamics remains a significant challenge. To generate high-quality, dynamic, and temporally consistent long videos, this paper presents ARLON,  a novel framework that boosts diffusion Transformers with autoregressive (AR) models for long (LON) video generation, by integrating the coarse spatial and long-range temporal information provided by the AR model to guide the DiT model effectively. Specifically, ARLON incorporates several key innovations: 1) A latent Vector Quantized Variational Autoencoder (VQ-VAE) compresses the input latent space of the DiT model into compact and highly quantized visual tokens, bridging the AR and DiT models and balancing the learning complexity and information density; 2) An adaptive norm-based semantic injection module integrates the coarse discrete visual units from the AR model into the DiT model, ensuring effective guidance during video generation; 3) To enhance the tolerance capability of noise introduced from the AR inference, the DiT model is trained with coarse visual latent tokens incorporated with an uncertainty sampling module. Experimental results demonstrate that ARLON significantly outperforms the baseline OpenSora-V1.2 on eight out of eleven metrics selected from VBench, with notable improvements in dynamic degree and aesthetic quality, while delivering competitive results on the remaining three and simultaneously accelerating the generation process. In addition, ARLON achieves state-of-the-art performance in long video generation, outperforming other open-source models in this domain. Detailed analyses of the improvements in inference efficiency are presented, alongside a practical application that demonstrates the generation of long videos using progressive text prompts. Project page: \\url{https://github.com/arlon-t2v/arlon-anonymous}."
    },
    {
        "title": "Grounding code understanding in step-by-step execution",
        "link_suffix": "/forum?id=MUr7Fl93QS",
        "link": "https://openreview.net/forum?id=MUr7Fl93QS",
        "pdf_link": "https://openreview.net/pdf?id=MUr7Fl93QS",
        "keywords": "large language models, code execution",
        "abstract": "Auto-regressive language models have made significant inroads in code generation, reasoning, and execution in recent years. Despite the recent progress, however, even the most capable models have been shown to perform significantly worse than humans in the task of predicting what a given piece of code does. This has fueled concerns about the tendency of models that seemingly generate and reason over code to learn shortcuts without developing any deeper understanding of code. Unlike reasoning, the meaning of a line of code is determined entirely by the effect it has on the state of the machine on which it is executed. Inspired by this observation, we propose measuring code understanding as the ability to predict the effects of line-by-line execution of a piece of code. We perform an empirical study which suggests that the inability to track machine state is a key contributor to the deficiencies of existing models to understand code. We also propose a simple solution based on fine-tuning a model on auxiliary state supervision, and we demonstrate the effectiveness of this approach."
    },
    {
        "title": "The best of both worlds: Improved outcome prediction using causal structure learning",
        "link_suffix": "/forum?id=AvXrppAS2o",
        "link": "https://openreview.net/forum?id=AvXrppAS2o",
        "pdf_link": "https://openreview.net/pdf?id=AvXrppAS2o",
        "keywords": "Outcome prediction, Causal structure learning, Personalised therapy",
        "abstract": "In limited data settings as in the medical domain, causal structure learning can be a powerful tool for understanding the relationships between variables and achieving out-of-sample generalisation for the prediction of a specific target variable. Most methods that learn causal structure from observational data rely on strong assumptions, such as the absence of unmeasured confounders, that are not valid in real world scenarios. In addition, due to evolving conditions and treatment approaches, causal relationships between the variables change over time. Moreover in a clinical setting, symptoms often need to be managed before finding the root cause of a problem, which puts the emphasis on accurate outcome prediction. Consequently, prediction of a specific target variable from retrospective observational data based on causal relationships alone will not be sufficient for generalisation to prospective data. To overcome these limitations, we opt for the best of both worlds in this work by learning a shared representation between causal structure learning and outcome prediction. We provide extensive empirical evidence to show that this would not only facilitate out-of-sample generalisation in outcome prediction but also enable robust causal discovery. We also highlight the strengths of our model in terms of time efficiency and interpretability."
    },
    {
        "title": "Vocabulary In-Context Learning in Transformers: Benefits of Positional Encoding",
        "link_suffix": "/forum?id=YE6N8htoFQ",
        "link": "https://openreview.net/forum?id=YE6N8htoFQ",
        "pdf_link": "https://openreview.net/pdf?id=YE6N8htoFQ",
        "keywords": "Transformer, Universal approximation, In-context Learning;Vocabulary",
        "abstract": "Numerous studies have demonstrated that the Transformer architecture possesses the capability for in-context learning (ICL). In scenarios involving function approximation, context can serve as a control parameter for the model, endowing it with the universal approximation property (UAP). In practice, context is represented by tokens from a finite set, referred to as a vocabulary, which is the case considered in this paper, i.e., vocabulary in-context learning (VICL). We demonstrate that VICL in single-layer Transformers, without positional encoding, does not possess the UAP; however, it is possible to achieve the UAP when positional encoding is included. Several sufficient conditions for the positional encoding are provided. Our findings reveal the benefits of positional encoding from an approximation theory perspective in the context of in-context learning."
    },
    {
        "title": "Temporally coherent visualisation of time-dependent data",
        "link_suffix": "/forum?id=FrmVRUVOEF",
        "link": "https://openreview.net/forum?id=FrmVRUVOEF",
        "pdf_link": "https://openreview.net/pdf?id=FrmVRUVOEF",
        "keywords": "visualisation, t-SNE, dimension reduction, dynamic data, temporal data",
        "abstract": "Dimension reduction algorithms aim to embed high-dimensional datasets into a low-dimensional space in such a way that important structural properties, such as clusters and manifolds, are preserved. Most such methods are designed for static data, and naively applying them to time-dependent data can lead to unstable embeddings which do not meaningfully capture the temporal evolution of the data. In this paper, we propose a new variant of the t-SNE algorithm for time-dependent data, TC-tSNE (Temporally Coherent t-SNE) in which an extra term is added to the cost function to promote temporal coherence: the notion that a data point which has a similar position in two time frames should be embedded to similar positions at those times. Importantly, this notion captures temporal similarities over the entire time domain and can therefore capture long-range temporal patterns, not just local ones. We demonstrate the effectiveness of our method for visualising dynamic network embedding, and we evaluate our method on six benchmark datasets using a collection of metrics, which capture the structural quality and the temporal coherence of the embeddings. We compare our method with existing dynamic visualisation algorithms and find that it performs competitively."
    },
    {
        "title": "Unified Music-Language Model for Symbolic and Waveform Integration",
        "link_suffix": "/forum?id=4GJVU31mF7",
        "link": "https://openreview.net/forum?id=4GJVU31mF7",
        "pdf_link": "https://openreview.net/pdf?id=4GJVU31mF7",
        "keywords": "Music Language Model, MultiModal Language Model, Music Understanding, Music Generation",
        "abstract": "Music is a unique and essential modality constituting human life, presenting challenges for multimodal advances due to its complex structure and intricate details. Recent Music Language Models (MuLMs) facilitate music understanding and generation by leveraging the inherent knowledge and reasoning capabilities of pre-trained Language Models (LMs), yet they overlook the complementary benefits of different music representations. To this end, we propose a unified music language model, named UniMuLM, form the existing approach of using a single representation to multiple music representations. Concerning the unification, we address the challenges of missing modalities and unstable training to adapt different scenarios. Specifically, we integrate symbolic, waveform music, and textual instructions into an LM and design a bar-level tokenizer to explore the fine-grained correlations between different modalities. Moreover, we propose a multi-stage training strategy to progressively enhance this synergy. Trained on open-source datasets, UniMuLM demonstrates superior performance compared to SOTA methods across 9 music tasks."
    },
    {
        "title": "Rethinking Shapley Value for Negative Interactions in Non-convex Games",
        "link_suffix": "/forum?id=b24n2LS2BJ",
        "link": "https://openreview.net/forum?id=b24n2LS2BJ",
        "pdf_link": "https://openreview.net/pdf?id=b24n2LS2BJ",
        "keywords": "Shapley value, Interaction, Feature Attribution",
        "abstract": "We study causal interaction for payoff allocation in cooperative game theory, including quantifying feature attribution for deep learning models. Most feature attribution methods mainly stem from the criteria from the Shapley value, which provides a unique payoff vector for players by marginalizing contributions in a cooperative game. However, interactions between players in the game do not exactly appear in the original formulation of the Shapley value. In this work, we clarify the role of interactions in computing the Shapley value by reformulation and discuss implicit assumptions from a game-theoretical perspective. Our theoretical analysis demonstrates that classical payoff allocation in a cooperative game assumes the convexity of the game, which is equivalent to non-negative interactions between players. When negative interactions exist, common in deep learning models, attributions or payoffs can be underrated by the efficiency axiom in this classical setup. We suggest a new allocation rule that decomposes contributions into interactions and aggregates positive parts for non-convex games. Furthermore, we propose an approximation algorithm to reduce the cost of interaction computation which can be applied for differentiable functions such as deep learning models. Our approach mitigates counter-intuitive phenomena where even features highly relevant to the decision are assigned low attribution in the previous approaches."
    },
    {
        "title": "CellPainTR: Contrastive Batch Corrected Transformer for Large Scale Cell Painting",
        "link_suffix": "/forum?id=uo8PO6Ah59",
        "link": "https://openreview.net/forum?id=uo8PO6Ah59",
        "pdf_link": "https://openreview.net/pdf?id=uo8PO6Ah59",
        "keywords": "Cell Painting, Batch Correction, Representation Learning, Transformer, Hyena Operator, High-dimensional Data, Image-based Profiling",
        "abstract": "Cell Painting, a high-content imaging-based profiling method, has emerged as a powerful tool for understanding cellular phenotypes and drug responses. However, batch effects severely constrain the integration and interpretation of data collected across different laboratories and experimental conditions. This paper introduces CellPainTR, a novel approach for unified batch correction and representation learning in Cell Painting data, addressing a critical challenge in the field of image-based profiling. Our approach employs a Transformer-like architecture with Hyena operators, positional encoding via morphological-feature-embedding, and a special source context token for batch correction,\ncombined with a multi-stage training process that incorporates masked token prediction and supervised contrastive learning. Experiments on the JUMP Cell Painting dataset demonstrate that CellPainTR significantly outperforms existing approaches such as Combat and Harmony across multiple evaluation metrics,while maintaining strong biological information retention as evidenced by improved clustering metrics and qualitative PCA visualizations. Moreover, our method effectively reduces the feature space from thousands of dimensions to just 256, addressing the curse of dimensionality while maintaining high performance. These advancements enable more robust integration of multi-source Cell Painting data, potentially accelerating progress in drug discovery and cellular biology research."
    },
    {
        "title": "CO-MOT: Boosting End-to-end Transformer-based Multi-Object Tracking via Coopetition Label Assignment and Shadow Sets",
        "link_suffix": "/forum?id=0ov0dMQ3mN",
        "link": "https://openreview.net/forum?id=0ov0dMQ3mN",
        "pdf_link": "https://openreview.net/pdf?id=0ov0dMQ3mN",
        "keywords": "End-to-End Tracking, Transformer, Multi-object Tracking",
        "abstract": "Existing end-to-end Multi-Object Tracking (e2e-MOT) methods have not surpassed non-end-to-end tracking-by-detection methods. One potential reason is its label assignment strategy during training that consistently binds the tracked objects with tracking queries and then assigns the few newborns to detection queries. With one-to-one bipartite matching, such an assignment will yield an unbalanced training, \\textit{i.e.}, scarce positive samples for detection queries, especially for an enclosed scene, as the majority of the newborns come on stage at the beginning of videos. Thus, e2e-MOT will be easier to yield a tracking terminal without renewal or re-initialization, compared to other tracking-by-detection methods. To alleviate this problem, we present Co-MOT, a simple and effective method to facilitate e2e-MOT by a novel coopetition label assignment with a shadow concept. Specifically, we add tracked objects to the matching targets for detection queries when performing the label assignment for training the intermediate decoders. For query initialization, we expand each query by a set of shadow counterparts with limited disturbance to itself. With extensive ablations, Co-MOT achieves superior performance without extra costs, \\textit{e.g.}, 69.4% HOTA on DanceTrack and 52.8% TETA on BDD100K. Impressively, Co-MOT only requires 38% FLOPs of MOTRv2 to attain a similar performance, resulting in the 1.4$\\times$ faster inference speed. Codes are attached for re-implementation."
    },
    {
        "title": "Generating Equivalent Representations of Code By A Self-Reflection Approach",
        "link_suffix": "/forum?id=RMaB6cn07S",
        "link": "https://openreview.net/forum?id=RMaB6cn07S",
        "pdf_link": "https://openreview.net/pdf?id=RMaB6cn07S",
        "keywords": "Equivalent Representations of Code, Large Language Models, Empirical Study",
        "abstract": "Equivalent Representations (ERs) of code are textual representations that preserve the same semantics as the code itself, e.g., natural language comments and pseudocode. ERs play a critical role in software development and maintenance. However, how to automatically generate ERs of code remains an open challenge. In this paper, we propose a self-reflection approach to generating ERs of code. It enables two Large Language Models (LLMs) to work mutually and produce an ER through a reflection process. Depending on whether constraints on ERs are applied, our approach generates ERs in both open and constrained settings. We conduct a empirical study to generate ERs in two settings and obtain eight findings. (1) Generating ERs in the open setting. In the open setting, we allow LLMs to represent code without any constraints, analyzing the resulting ERs and uncovering five key findings. These findings shed light on how LLMs comprehend syntactic structures, APIs, and numerical computations in code.\n(2) Generating ERs in the constrained setting. In the constrained setting, we impose constraints on ERs, such as natural language comments, pseudocode, and flowcharts. This allows our approach to address a range of software engineering tasks. Based on our experiments, we have three findings demonstrating that our approach can effectively generate ERs that adhere to specific constraints, thus supporting various software engineering tasks.\n(3) Future directions. We also discuss potential future research directions, such as deriving intermediate languages for code generation, exploring LLM-friendly requirement descriptions, and further supporting software engineering tasks. We believe that this paper will spark discussions in research communities and inspire many follow-up studies. The source code and data are available."
    },
    {
        "title": "What's New in My Data? Novelty Exploration via Contrastive Generation",
        "link_suffix": "/forum?id=IZDiRbVSVN",
        "link": "https://openreview.net/forum?id=IZDiRbVSVN",
        "pdf_link": "https://openreview.net/pdf?id=IZDiRbVSVN",
        "keywords": "dataset exploration, novelty detection, contrastive decoding",
        "abstract": "Fine-tuning is widely used to adapt language models for specific goals, often leveraging real-world data such as patient records, customer-service interactions, or web content in languages not covered in pre-training.\nThese datasets are typically massive, noisy, and often confidential, making their direct inspection challenging.\nHowever, understanding them is essential for guiding model deployment and informing decisions about data cleaning or suppressing any harmful behaviors learned during fine-tuning.\nIn this study, we introduce the task of novelty discovery through generation, which aims to identify novel properties of a fine-tuning dataset by generating examples that illustrate these properties.\nOur approach \uff0d Contrastive Generative Exploration (CGE) \uff0d assumes no direct access to the data but instead relies on a pre-trained model and the same model after fine-tuning.\nBy contrasting the predictions of these two models, CGE can generate examples that highlight novel characteristics of the fine-tuning data.\nHowever, this simple approach may produce examples that are too similar to one another, failing to capture the full range of novel phenomena present in the dataset.\nWe address this by introducing an iterative version of CGE, where the previously generated examples are used to update the pre-trained model, and this updated model is then contrasted with the fully fine-tuned model to generate the next example, promoting diversity in the generated outputs.\nOur experiments demonstrate the effectiveness of CGE in detecting novel content, such as toxic language, as well as new natural and programming languages.\nFurthermore, we show that CGE remains effective even when models are fine-tuned using differential privacy techniques."
    },
    {
        "title": "Adversarial Attacks as Near-Zero Eigenvalues in the Empirical Kernel of Neural Networks",
        "link_suffix": "/forum?id=r5d8zkYizS",
        "link": "https://openreview.net/forum?id=r5d8zkYizS",
        "pdf_link": "https://openreview.net/pdf?id=r5d8zkYizS",
        "keywords": "adversarial attacks, kernel, neural networks",
        "abstract": "Adversarial examples ---imperceptibly modified data inputs designed to mislead machine learning models--- have raised concerns about the robustness of modern neural architectures in safety-critical applications. \nIn this paper, we propose a unified mathematical \nframework for understanding adversarial examples in neural networks, corroborating Szegedy et al.'s original conjecture that \nsuch examples are exceedingly rare, despite their presence in the proximity of nearly every test case. By exploiting Mercer's decomposition theorem, we characterise adversarial examples as those producing near-zero Mercer's eigenvalues in the empirical kernel associated to a trained neural network. \nConsequently, the generation of adversarial attacks, using any known technique, can be conceptualised as a progression towards the eigenvalue space's zero point within the empirical kernel.\nWe rigorously prove this characterisation for trained neural networks that achieve interpolation and under mild assumptions on the architecture, thus\nproviding a mathematical explanation for the apparent contradiction of neural networks excelling at generalisation while remaining vulnerable to adversarial attacks. \nWe have empirically verified that adversarial examples generated for both fully-connected and convolutional architectures through the widely-known DeepFool algorithm and through the more recent Fast Adaptive Boundary (FAB) method consistently lead to a shift in the distribution of Mercer's eigenvalues toward zero. These results are in strong agreement with predictions of our theory."
    },
    {
        "title": "Privacy Breach Detection by Non-Parametric Two-Sample Tests",
        "link_suffix": "/forum?id=NvRVYVN106",
        "link": "https://openreview.net/forum?id=NvRVYVN106",
        "pdf_link": "https://openreview.net/pdf?id=NvRVYVN106",
        "keywords": "Privacy breach detection, Two-Sample tests, membership inference",
        "abstract": "With the proliferation of machine learning services, the risk of privacy breaches has never been higher, owing to the need for collecting -- sometimes by any means necessary -- valuable, yet sensitive training data. When an unsanctioned data access occurs, it may become apparent after the fact, in the predictive models that have been trained on compromised data. This calls for effective membership inference methods, enabling an evaluator to identify privacy breaches. Distinct from traditional membership inference attacks (MIAs), which focus on determining whether individual data records were used in training, this study centers on the evaluation of sets of records, particularly when only a small proportion of the set are training members. In this scenario, traditional MIAs often suffer from non-ideal evaluation reliability. To address this issue, from a privacy evaluator's perspective, we propose a novel approach for membership inference, applicable not to individual records but to sets thereof. It relies on a non-parametric two-sample test, which leverages the differences between high-level representation to infer membership. Based on extensive experiments, our proposed High-level Representation-based MMD (HR-MMD) test exhibits high sensitivity in distinguishing between the training and non-training sets, with ideal type I error, making it a powerful membership detection tool. Our study offers insights into an alternative privacy breach detection scenario and opens up a promising avenue for privacy evaluation based on membership inference tests."
    },
    {
        "title": "A Large-Scale Analysis on Methodological Choices in Deep Reinforcement Learning",
        "link_suffix": "/forum?id=Ok7ZH2Cyd7",
        "link": "https://openreview.net/forum?id=Ok7ZH2Cyd7",
        "pdf_link": "https://openreview.net/pdf?id=Ok7ZH2Cyd7",
        "keywords": "scientific analysis, methodological choices",
        "abstract": "Deep reinforcement learning research has been the center of remarkable scientific progress for the past decade. From winning one of the most challenging games to algorithmic advancements that allowed solving problems without even explicitly knowing the rules of the task at hand reinforcement learning research progress has been the epicenter of many breakthrough ideas. In this paper, we analyze the methodological issues in deep reinforcement learning. We introduce the theoretical foundations of the underlying causes outlining that the asymptotic performance of deep reinforcement learning algorithms does not have a monotone relationship to the performance in the regimes where data becomes scarce. The extensive large-scale empirical analysis provided in our paper discovers that a major line of deep reinforcement learning research under the canonical methodological choices resulted in suboptimal conclusions."
    },
    {
        "title": "Hierarchical Analysis: Monotonicity of Layerwise performance in Large Language Models",
        "link_suffix": "/forum?id=ZVLyyG5yS6",
        "link": "https://openreview.net/forum?id=ZVLyyG5yS6",
        "pdf_link": "https://openreview.net/pdf?id=ZVLyyG5yS6",
        "keywords": "Monotonicity, Layerwise Performance, Large Language Models (LLMs), Hierarchical Analysis",
        "abstract": "We introduce a quantitative framework to evaluate how Large Language Models (LLMs) learn tasks across all layers, revealing a `monotonicity phenomenon'. Specifically: \ni) performance at each layer consistently improves from one layer to the next on the pre-training set, and \nii) this improvement is consistently observed across various downstream tasks. This monotonicity phenomenon indicates that LLMs effectively capture complex hierarchical features across diverse datasets. For example, our study on the abstraction of concepts using linear representations in word embeddings shows that the clarity of these abstractions progressively increases with each layer.\nFinally, by leveraging this monotonicity, we can significantly reduce inference time and memory requirements by selecting the most appropriate layer, thereby enhancing the efficiency of LLMs in real-world applications."
    },
    {
        "title": "CMC-Bench: Towards a New Paradigm of Visual Signal Compression",
        "link_suffix": "/forum?id=foKwWau15m",
        "link": "https://openreview.net/forum?id=foKwWau15m",
        "pdf_link": "https://openreview.net/pdf?id=foKwWau15m",
        "keywords": "Image Compression, Large Multimodal Model, Image Quality Assessment",
        "abstract": "Ultra-low bitrate image compression is a challenging and demanding topic. With the development of Large Multimodal Models (LMMs), a Cross Modality Compression (CMC) paradigm of Image-Text-Image has emerged. Compared with traditional codecs, this semantic-level compression canreduce image data size to 0.1% or even lower, which has strong potential applications. However, CMC has certain defects in consistency with the original image and perceptual quality. To address this problem, we introduce CMC-Bench, a benchmark of thecooperative performance of Image-to-Text (I2T) and Text-to-Image (T2I) models for image compression. This benchmark covers 18,000 and 40,000 images respectively to verify 6 mainstream I2T and 12 T2I models, including 160,000 subjective preference scores annotated by human experts. At ultra-low bitrates, this paper proves that the combination of some I2T and T2I models has surpassed the most advanced visual signal codecs; meanwhile, it highlights where LMMs can be further optimized toward the compression task. We encourage LMM developers to participate in this test to promote the evolution of visual signal codec protocols."
    },
    {
        "title": "VChangeCodec: A High-efficiency Neural Speech Codec with Built-in Voice Changer for Real-time Communication",
        "link_suffix": "/forum?id=qDSfOQBrOD",
        "link": "https://openreview.net/forum?id=qDSfOQBrOD",
        "pdf_link": "https://openreview.net/pdf?id=qDSfOQBrOD",
        "keywords": "Real-time communication, Neural Speech codec, Voice conversion",
        "abstract": "Neural speech codecs (NSCs) enable high-quality real-time communication (RTC)\nat low bit rates, making them efficient for bandwidth-constrained environments.\nHowever, customizing or modifying the timbre of transmitted voices still relies on\nseparate voice conversion (VC) systems, creating a gap in fully integrated systems\nthat can simultaneously optimize efficient transmission and streaming VC with no\nadditional latency. In this paper, we propose a high-efficiency VChangeCodec,\nwhich integrates the Voice Changer model directly into the speech Codec. This\ndesign seamlessly switches between the original voice mode and customized voice\nchange mode in real-time. Specifically, leveraging the target speaker\u2019s embedding,\nwe incorporate a lightweight causal projection network within the encoding module\nof VChangeCodec to adapt timbre at the token level. These adapted tokens are\nquantized and transmitted to the decoding module, to generate the converted speech\nof the target speaker. The integrated framework achieves an ultra-low latency of\njust 40 ms and requires fewer than 1 million parameters, making it ideal for RTC\nscenarios such as online conferencing. Our comprehensive evaluations, including\nsubjective listening tests and objective performance assessments, demonstrate that\nVChangeCodec excels in timbre adaptation capabilities compared to state-of-the-art (SOTA) VC models. We are confident that VChangeCodec provides an efficient\nand flexible framework for RTC systems, tailored to specific operator requirements."
    },
    {
        "title": "Durable Quantization Conditioned Misalignment Attack on Large Language Models",
        "link_suffix": "/forum?id=41uZB8bDFh",
        "link": "https://openreview.net/forum?id=41uZB8bDFh",
        "pdf_link": "https://openreview.net/pdf?id=41uZB8bDFh",
        "keywords": "LLM Safety Alignment, Quantization Conditioned Attack",
        "abstract": "As large language models (LLMs) are increasingly deployed on resource-constrained edge devices, quantization techniques have been widely adopted to reduce model size and computational requirements. However, this process can expose models to new vulnerabilities. In this work, we introduce the Quantization Conditioned Misalignment (Q-Misalign) attack, a novel threat in which safety misalignment remains dormant in a full-precision LLM but becomes exploitable post-quantization. We demonstrate that our Q-Misalign attack effectively bypasses safety mechanisms and enables the generation of harmful content in quantized models while maintaining full-precision performance. Furthermore, we propose a contrastive task vector-based approach to enhance attack durability, ensuring that vulnerabilities persist even after downstream fine-tuning. Experimental results show that Q-Misalign attack significantly increases jailbreak success rates in quantized models, while preserving model utility and safety alignment in full precision. Our findings highlight a critical gap in current LLM safety measures and call for more robust defenses in quantization-aware scenarios."
    },
    {
        "title": "Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants",
        "link_suffix": "/forum?id=x1Bk51SCL9",
        "link": "https://openreview.net/forum?id=x1Bk51SCL9",
        "pdf_link": "https://openreview.net/pdf?id=x1Bk51SCL9",
        "keywords": "face and human understanding, multi-modal assistants, benchmark",
        "abstract": "Faces and humans are crucial elements in social interaction and are widely included in everyday photos and videos. Therefore, a deep understanding of faces and humans will enable multi-modal assistants to achieve improved response quality and broadened application scope. Currently, the multi-modal assistant community lacks a comprehensive and scientific evaluation of face and human understanding abilities. In this paper, we first propose a hierarchical ability taxonomy that includes three levels of abilities. Then, based on this taxonomy, we collect images and annotations from publicly available datasets in the face and human community and build a semi-automatic data pipeline to produce problems for the new benchmark. Finally, the obtained Face-Human-Bench comprises a development set with 900 problems and a test set with 1800 problems, supporting both English and Chinese. We conduct evaluations over 25 mainstream multi-modal large language models (MLLMs) with our Face-Human-Bench, focusing on the correlation between abilities, the impact of the relative position of targets on performance, and the impact of Chain of Thought (CoT) prompting on performance. Moreover, inspired by multi-modal agents, we also explore which abilities of MLLMs need to be supplemented by specialist models. The data and evaluation code of the Face-Human-Bench will be made publicly available."
    },
    {
        "title": "Tri-Tense Former: Capturing Dynamic Traffic Flow Using Tri-Tense Attention for Traffic Forecasting",
        "link_suffix": "/forum?id=u3xwwfHmBC",
        "link": "https://openreview.net/forum?id=u3xwwfHmBC",
        "pdf_link": "https://openreview.net/pdf?id=u3xwwfHmBC",
        "keywords": "Traffic forecasting, Spatio-temporal dependency, Transformer, Contrastive learning",
        "abstract": "Accurate traffic forecasting is essential to enable advanced utilization of intelligent transportation systems. However, forecasting models often struggle to capture the complex spatio-temporal dependencies of traffic data, as they typically handle spatial and temporal dependencies separately. To overcome this limitation, we introduce the Tri-Tense Former (TTformer), a novel approach that captures spatio-temporal relationships through three tense-specific attention modules. We categorize traffic flow into three tense dimensions: past-to-present (present-perfect), present, and future. Each tense-specific attention module captures the dependencies within its respective traffic flow. Furthermore, to address incomplete traffic data, we improve the robustness of the model by employing contrastive learning with negative filtering technique that operates regardless of predefined adjacency matrices. TTformer significantly outperforms existing models by more effectively capturing spatio-temporal dependencies and improving traffic forecasting accuracy."
    },
    {
        "title": "VIBEID: A STRUCTURAL VIBRATION-BASED SOFT BIOMETRIC DATASET FOR HUMAN GAIT RECOGNITION",
        "link_suffix": "/forum?id=2d734s2WDb",
        "link": "https://openreview.net/forum?id=2d734s2WDb",
        "pdf_link": "https://openreview.net/pdf?id=2d734s2WDb",
        "keywords": "Structural vibrations, Gait Recognition, Deep learning, Machine learning",
        "abstract": "We present VIBeID, a dataset and benchmark designed for advancing non-invasive human gait recognition using structural vibration. Structural vibrations, produced by the rhythmic impact of the toe and heel on the ground, are distinct and can be used as a privacy-preserving and non-cooperative soft-biometric modality. We curated the largest dataset VIBeID consists of footfall generated structural vibrations of 100 subjects. Existing datasets in this field typically include around ten subjects and lack comprehensive exploration of domain adaptation. To thoroughly explore the domain adaptation aspect of this biometric approach, we recorded vibration data on three distinct floor types (wooden, carpet, and cement) and at three distances from the geophone sensor (1.5 m, 2.5 m, and 4.0 m), involving 40\nand 30 subjects, respectively. Additionally, we benchmarked our dataset against video recordings from 15 individuals in an outdoor setting. Beyond providing 88 hours of raw vibration data, VIBeID establishes a comprehensive benchmark for a) person identification: where the aim is to recognize individuals through their unique structural vibrations, b) domain adaptation: assessing model performance across different walking surfaces and sensor positions, and c) multi-modal comparison: comparing vibration-based and vision-based identification methods. Our experiments, using both machine learning and deep learning approaches, establish a baseline for future research in this field, and introduce a large-scale dataset for the broader machine learning community."
    },
    {
        "title": "Large Language Models for Explainability in Machine Learning",
        "link_suffix": "/forum?id=Wd1R0oxe5j",
        "link": "https://openreview.net/forum?id=Wd1R0oxe5j",
        "pdf_link": "https://openreview.net/pdf?id=Wd1R0oxe5j",
        "keywords": "XAI, explainability, large language models",
        "abstract": "We investigate the potential of large language models (LLMs) in explainable artificial intelligence (XAI) by examining their ability to generate understandable explanations for machine learning (ML) models. While recent studies suggest that LLMs could effectively address the limitations of traditional explanation methods through their conversational capabilities, there has been a lack of systematic evaluation of the quality of these LLM-generated explanations. To fill this gap, this study evaluates whether LLMs can produce explanations for ML models that meet the fundamental properties of XAI using conventional ML models and explanation methods as benchmarks. The findings offer important insights into the strengths and limitations of LLMs as tools for explainable AI, provide recommendations for their appropriate use, and identify promising directions for future research."
    }
]
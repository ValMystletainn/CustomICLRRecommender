[
    {
        "title": "Shallow diffusion networks provably learn hidden low-dimensional structure",
        "link_suffix": "/forum?id=KlxK4ncqWZ",
        "link": "https://openreview.net/forum?id=KlxK4ncqWZ",
        "pdf_link": "https://openreview.net/pdf?id=KlxK4ncqWZ",
        "keywords": "Generative models, diffusion models, denoising score matching, low dimensional structure, Barron classes",
        "abstract": "Diffusion models provide a powerful, general purpose framework for learning to sample from a target distribution. The remarkable empirical success of these models applied to high dimensional signals, including images and video frames, stands in stark contrast to the classical curse of dimensionality which arises in the general problem of learning distributions. In this work, we take a step towards understanding this gap. We show that learning diffusion models in Barron spaces---the function space of single-layer neural networks---provably adapts to simple forms of low dimensional structure. We combine our results with recent progress in analyzing the diffusion sampling process to provide end-to-end sample complexity bounds for learning to sample from structured distributions. Our results avoid exponential dependencies on the ambient dimension of the data, and instead reflect the intrinsic latent dimensionality of the underlying target distribution. Importantly, our results do not require specialized architectures which are specifically tailored  for particular latent structures, and instead rely on the low-index structure of Barron classes to adapt to the underlying distribution."
    },
    {
        "title": "Constraining Gaussian Processes Regression with Quasi-Likelihood Constraint Relaxation",
        "link_suffix": "/forum?id=H380m98pLE",
        "link": "https://openreview.net/forum?id=H380m98pLE",
        "pdf_link": "https://openreview.net/pdf?id=H380m98pLE",
        "keywords": "constrained gaussian processes, virtual point methods, bayesian inference, fusion energy",
        "abstract": "Gaussian Process regression is a popular method for nonparametric, probabilistic modelling. One of its main attractions is also, in some contexts, a significant challenge; namely its high flexibility. This flexibility can be reduced by imposing constraints on the GP prior or posterior, something that there is a large and growing body of literature on. In this paper, we present a generalisation of virtual point methods and a framework for enforcing a broad range of constraints in GP posteriors. The method involves designing a quasi-likelihood function which encodes a relaxed form of the constraints, and then conditioning the unconstrained GP posterior on this quasi-likelihood. The method leverages ideas from existing methods for constrained GP regression, namely Riihimaki and Vehtari (2010) and Hansen et al. (2024), and expands these approaches to a much broader range of constraints. The method is demonstrated with a synthetic example, where a 2-dimensional GP posterior is required to have a divergence-free gradient, as well as real-world example where the posterior GP of Thomson scattering data from the MAST tokamak is required to be both monotonically decreasing and strictly positive."
    },
    {
        "title": "GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation",
        "link_suffix": "/forum?id=ja4rpheN2n",
        "link": "https://openreview.net/forum?id=ja4rpheN2n",
        "pdf_link": "https://openreview.net/pdf?id=ja4rpheN2n",
        "keywords": "Gene Functional Networks, Disease Subtypes, Bioinformatics",
        "abstract": "Retrieving gene functional networks from knowledge databases presents a challenge due to the mismatch between disease networks and subtype-specific variations. Current solutions, including statistical and deep learning methods, often fail to effectively integrate gene interaction knowledge from databases or explicitly learn subtype-specific interactions. To address this mismatch, we propose GeSubNet, which learns a unified representation capable of predicting gene interactions while distinguishing between different disease subtypes. Graphs generated by such representations can be considered subtype-specific networks. GeSubNet is a multi-step representation learning framework with three modules: First, a deep generative model learns distinct disease subtypes from patient gene expression profiles. Second, a graph neural network captures representations of prior gene networks from knowledge databases, ensuring accurate physical gene interactions. Finally, we integrate these two representations using an inference loss that leverages graph generation capabilities, conditioned on the patient separation loss, to refine subtype-specific information in the learned representation. GeSubNet consistently outperforms traditional methods, with average improvements of 30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averaged over four cancer datasets. Particularly, we conduct a biological simulation experiment to assess how the behavior of selected genes from over 11,000 candidates affects subtypes or patient distributions. The results show that the generated network has the potential to identify subtype-specific genes with an 83% likelihood of impacting patient distribution shifts. The GeSubNet resource is available:https://anonymous.4open.science/r/GeSubNet/"
    },
    {
        "title": "Exploring the Design Space of Visual Context Representation in Video MLLMs",
        "link_suffix": "/forum?id=UN6Ik6OCx8",
        "link": "https://openreview.net/forum?id=UN6Ik6OCx8",
        "pdf_link": "https://openreview.net/pdf?id=UN6Ik6OCx8",
        "keywords": "Video Multimodal Large Language Model, Scaling Law",
        "abstract": "Video Multimodal Large Language Models (MLLMs) have shown remarkable capability of understanding the video semantics on various downstream tasks. Despite the advancements, there is still a lack of systematic research on visual context representation, which refers to the scheme to select frames from a video and further select the tokens from a frame. In this paper, we explore the design space for visual context representation, and aim to improve the performance of video MLLMs by finding more effective representation schemes. Firstly, we formulate the task of visual context representation as a constrained optimization problem, and model the language modeling loss as a function of the number of frames and the number of embeddings (or tokens) per frame, given the maximum visual context window size. \nThen, we explore the scaling effects in frame selection and token selection respectively, and fit the corresponding function curve by conducting extensive empirical experiments. We examine the effectiveness of typical selection strategies and present empirical findings to determine the two factors. Furthermore, we study the joint effect of frame selection and token selection, and derive the\noptimal formula for determining the two factors. We demonstrate that the derived optimal settings show alignment with the best-performed results of empirical experiments."
    },
    {
        "title": "Investigating Domain Gaps for Indoor 3D Object Detection",
        "link_suffix": "/forum?id=g7xZkiHcGO",
        "link": "https://openreview.net/forum?id=g7xZkiHcGO",
        "pdf_link": "https://openreview.net/pdf?id=g7xZkiHcGO",
        "keywords": "domain adaptation, indoor 3D object detection",
        "abstract": "As a fundamental task for indoor scene understanding, 3D object detection has been extensively studied, and the accuracy on indoor point cloud data has been substantially improved. However, existing researches have been conducted on limited datasets, where the training and testing sets share the same distribution. In this paper, we consider the task of adapting indoor 3D object detectors from one dataset to another, presenting a first benchmark with commonly used ScanNet and SUN RGB-D datasets, as well as our newly proposed large-scale SimRoom and SimHouse datasets by a 3D simulator with far greater number of objects and more precise annotations. Since indoor point cloud datasets are collected and constructed in different ways, the object detectors are likely to overfit to specific factors within each dataset, such as point cloud quality, room layout configuration, style and object size. We conduct experiments across datasets on different adaptation scenarios, analyzing the impact of different domain gaps on 3D object detectors. We observe that through our evaluated domain gap factors, synthetic-to-real adaptation is the most difficult adaptation hurdle to overcome. We also introduce several domain adaptation approaches to improve adaptation performances, providing a first baseline for domain adaptive indoor 3D object detection, hoping that future works may propose detectors with stronger generalization ability across domains."
    },
    {
        "title": "DAViD: Domain Adaptive Visually-Rich Document Understanding with Synthetic Insights",
        "link_suffix": "/forum?id=z4rBSPep64",
        "link": "https://openreview.net/forum?id=z4rBSPep64",
        "pdf_link": "https://openreview.net/pdf?id=z4rBSPep64",
        "keywords": "Visually-Rich Documents, Visually-Rich Document Understanding, Domain Adaption",
        "abstract": "Visually-Rich Documents (VRDs), encompassing elements like charts, tables, and references, convey complex information across various fields. However, extracting information from these rich documents is labor-intensive, especially given their inconsistent formats and domain-specific requirements. While pretrained models for VRD Understanding have progressed, their reliance on large, annotated datasets limits scalability. This paper introduces the Domain Adaptive Visually-rich Document Understanding (DAViD) framework, which utilises machine-generated synthetic data for domain adaptation. DAViD integrates fine-grained and coarse-grained document representation learning and employs synthetic annotations to reduce the need for costly manual labelling. By leveraging pretrained models and synthetic data, DAViD achieves competitive performance with minimal annotated datasets. Extensive experiments validate DAViD\u2019s effectiveness, demonstrating its ability to efficiently adapt to domain-specific VRDU tasks."
    },
    {
        "title": "S2GS: Self-supervised Gaussian Segmentation for Automatic 3D Object Scanning",
        "link_suffix": "/forum?id=pQJi9EsmCc",
        "link": "https://openreview.net/forum?id=pQJi9EsmCc",
        "pdf_link": "https://openreview.net/pdf?id=pQJi9EsmCc",
        "keywords": "Self-supervised segmentation, Gaussian splatting, 3D Reconstruction",
        "abstract": "Automatic 3D object scanning typically involves reconstructing rotating objects from images captured from different viewpoints. In such circumstances where both the object and camera are moving, existing methods need object masks for reconstruction, and the mask quality can significantly affect the final reconstruction. However, obtaining high-quality and view-consistent object masks is challenging and laborious in practice. We address this issue by introducing Self-Supervised Gaussian Segmentation (S$^2$GS), which automatically segments the object from the background without relying on any segmentation masks. This is achieved by extending Gaussian Splatting with a learnable parameter that indicates the probability of each Gaussian belonging to the target object. We optimize this parameter using implicit object transformation constraints and regularization terms. We evaluate S$^2$GS on our new synthetic and real datasets. Experimental results show that our approach outperforms the state-of-the-art methods (2DGS) with object masks by (27%) for novel-view synthesis and (7%) for geometry reconstruction."
    },
    {
        "title": "Exploring One-Shot Federated Learning by Model Inversion and Token Relabel with Vision Transformers",
        "link_suffix": "/forum?id=be0sdRYSlH",
        "link": "https://openreview.net/forum?id=be0sdRYSlH",
        "pdf_link": "https://openreview.net/pdf?id=be0sdRYSlH",
        "keywords": "One-Shot Federated Learning, Model Inversion, Token Relabel",
        "abstract": "One-Shot Federated Learning, where a central server learns a global model over a network of federated devices in a single round of communication, has recently emerged as a promising approach. For extremely Non-IID data, training models separately on each client results in poor performance, with low-quality generated data that are poorly matched with ground-truth labels. To overcome these issues, we propose a novel Federated Model Inversion and Token Relabel (FedMITR) framework, which trains the global model by better utilizing all patches of the synthetic images. FedMITR employs model inversion during the data generation process, selectively inverting semantic foregrounds while gradually halting the inversion process of uninformative backgrounds. Due to the presence of semantically meaningless tokens that do not positively contribute to ViT predictions, some of the generated pseudo-labels can be utilized to train the global model using patches with high information density, while patches with low information density can be relabeled using ensemble models. Extensive experimental results demonstrate that FedMITR can substantially outperform existing baselines under various settings."
    },
    {
        "title": "ER-AAE: A quantum state preparation approach based on entropy reduction",
        "link_suffix": "/forum?id=un9Gzm0BZb",
        "link": "https://openreview.net/forum?id=un9Gzm0BZb",
        "pdf_link": "https://openreview.net/pdf?id=un9Gzm0BZb",
        "keywords": "quantum machine learning, amplitude encoding, state preparation",
        "abstract": "Amplitude encoding of classical vectors serves as a cornerstone for numerous quantum machine learning algorithms in real-world applications. Nevertheless, achieving exact amplitude encoding for general vectors needs an exponential number of gates, which negates the potential quantum advantages. To address the challenge of large gate number in the state preparation phase, we propose an approximate amplitude encoding algorithm based on entropy reduction (ER-AAE). Given a target vector, the ER-AAE algorithm generates a sequence of gates, comprising single-qubit rotations and CZ gates, that approximates the amplitude encoding of the target vector. The structure of encoding circuits in ER-AAE is built inductively using a greedy search strategy that maximally reduces the linear entropy. We further prove that the state produced by ER-AAE approximates to the target state with the infidelity bounded by the linear entropy of intermediate states. Experimental results, including state preparations on random vectors, MNIST digits, and CIFAR-10 images, validate our method. Specifically, real-world data reveals a noteworthy trend where linear entropy decays significantly faster compared to random vectors. Furthermore, the ER-AAE algorithm surpasses the best existing encoding techniques, achieving lower error with an equivalent or fewer number of quantum gates."
    },
    {
        "title": "Adversarial Score Identity Distillation: Rapidly Surpassing the Teacher in One Step",
        "link_suffix": "/forum?id=lS2SGfWizd",
        "link": "https://openreview.net/forum?id=lS2SGfWizd",
        "pdf_link": "https://openreview.net/pdf?id=lS2SGfWizd",
        "keywords": "Diffusion distillation, deep generative models",
        "abstract": "Score identity Distillation (SiD) is a data-free method that has achieved state-of-the-art image generation performance by leveraging only a pretrained diffusion model, without the need for any training data. In this paper, we introduce SiDA (SiD with Adversarial Loss), which not only enhances generation quality but also improves distillation efficiency by incorporating real images and adversarial loss. SiDA utilizes the encoder from the generator's score network as a discriminator, enhancing its ability to differentiate between real images and those generated by SiD. The adversarial loss is batch-normalized within each GPU and then combined with the original SiD loss, effectively integrating the average \"fakeness\" per GPU batch into the pixel-based SiD loss. This allows SiDA to distill a single-step generator either from scratch or by fine-tuning an existing one. SiDA converges significantly faster than its predecessor when trained from scratch and quickly surpasses the original model\u2019s performance after an initial warmup period when fine-tuning from a SiD checkpoint. This method has established new benchmarks for low FID scores when distilling EDM diffusion models pretrained on CIFAR-10 (32x32) and ImageNet (64x64), achieving FID scores of1.499on CIFAR-10 unconditional,1.396on CIFAR-10 conditional, and1.110on ImageNet 64x64."
    },
    {
        "title": "Q-Adapter: Customizing Pre-trained LLMs to New Preferences with Forgetting Mitigation",
        "link_suffix": "/forum?id=WLSrq1254E",
        "link": "https://openreview.net/forum?id=WLSrq1254E",
        "pdf_link": "https://openreview.net/pdf?id=WLSrq1254E",
        "keywords": "reinforcement learning from human feedback, large languge model customization, anti-forgetting",
        "abstract": "Large Language Models (LLMs), trained on a large amount of corpus, have demonstrated remarkable abilities. However, it may not be sufficient to directly apply open-source LLMs like Llama to certain real-world scenarios, since most of them are trained for \\emph{general} purposes. Thus, the demands for customizing publicly available LLMs emerge, but are currently under-studied. In this work, we consider customizing pre-trained LLMs with new human preferences. Specifically, the LLM should not only meet the new preference but also preserve its original capabilities after customization. Drawing inspiration from the observation that human preference can be expressed as a reward model, we propose to cast LLM customization as optimizing the sum of two reward functions, one of which (denoted as $r_1$) was used to pre-train the LLM while the other (denoted as $r_2$) characterizes the new human preference. The obstacle here is that both reward functions are unknown, making the application of modern reinforcement learning methods infeasible. Thanks to the residual Q-learning framework, we can restore the customized LLM with the pre-trained LLM and the \\emph{residual Q-function} without the reward function $r_1$. Moreover, we find that for a fixed pre-trained LLM, the reward function $r_2$ can be derived from the residual Q-function, enabling us to directly learn the residual Q-function from the new human preference data upon the Bradley-Terry model. We name our method Q-Adapter as it introduces an adapter module to approximate the residual Q-function for customizing the pre-trained LLM towards the new preference. Experiments based on the Llama-3.1 model on the DSP dataset and HH-RLHF dataset illustrate the superior effectiveness of Q-Adapter on both retaining existing knowledge and learning new preferences."
    },
    {
        "title": "uniINF: Best-of-Both-Worlds Algorithm for Parameter-Free Heavy-Tailed MABs",
        "link_suffix": "/forum?id=2pNLknCTvG",
        "link": "https://openreview.net/forum?id=2pNLknCTvG",
        "pdf_link": "https://openreview.net/pdf?id=2pNLknCTvG",
        "keywords": "Heavy Tailed, Multi-Armed Bandits, Parameter-Free, Best-of-Both-Worlds",
        "abstract": "In this paper, we present a novel algorithm,uniINF, for the Heavy-Tailed Multi-Armed Bandits (HTMAB) problem, demonstrating robustness and adaptability in both stochastic and adversarial environments. Unlike the stochastic MAB setting where loss distributions are stationary with time, our study extends to the adversarial setup, where losses are generated from heavy-tailed distributions that depend on both arms and time. Our novel algorithmuniINFenjoys the so-called Best-of-Both-Worlds (BoBW) property, performing optimally in both stochastic and adversarial environmentswithoutknowing the exact environment type. Moreover, our algorithm also possesses a Parameter-Free feature,i.e., it operateswithoutthe need of knowing the heavy-tail parameters $(\\sigma, \\alpha)$ a-priori.\nTo be precise,uniINFensures nearly-optimal regret in both stochastic and adversarial environments, matching the corresponding lower bounds when $(\\sigma, \\alpha)$ is known (up to logarithmic factors). To our knowledge,uniINFis the first parameter-free algorithm to achieve the BoBW property for the heavy-tailed MAB problem. Technically, we develop innovative techniques to achieve BoBW guarantees for Parameter-Free HTMABs, including a refined analysis for the dynamics of log-barrier, an auto-balancing learning rate scheduling scheme, an adaptive skipping-clipping loss tuning technique, and a stopping-time analysis for logarithmic regret."
    },
    {
        "title": "Test-Time Graph Rebirth: Serving GNN Generalization Under Distribution Shifts",
        "link_suffix": "/forum?id=rW3NVhKtQ2",
        "link": "https://openreview.net/forum?id=rW3NVhKtQ2",
        "pdf_link": "https://openreview.net/pdf?id=rW3NVhKtQ2",
        "keywords": "graph neural networks, distribution shifts, test-time inference, MLOps",
        "abstract": "Distribution shifts between training and test graphs typically lead to the decreased performance of graph neural networks (GNNs) with suboptimal generalization in real-world applications. Despite advances in graph learning under distribution shifts through designing various model architecture development with customized training strategies, existing solutions can be challenging in practical GNN deployment because they often require significant modifications or retraining of the GNNs. To address such challenges, in this work, we propose a novel method, i.e., Test-Time Graph REBirth, dubbed TT-GREB, to effectively generalize the well-trained GNN models to the test-time graphs under distribution shifts by directly manipulating the test graph data. Concretely, we develop an overall framework designed by two principles, corresponding to two submodules: (1) prototype extractor for re-extracting the environment-invariant features of the test-time graph; and (2) environment refiner for re-fining the environment-varying features to explore the potential shifts. Furthermore, we propose a dual test-time graph contrastive learning objective with an effective iterative optimization strategy to obtain optimal prototype components and environmental components of the test graph. By reassembling these two components, we could obtain a newly reborn test graph, which is better suited for generalization on the well-trained GNN model with shifts in graph distribution. Extensive experiments on real-world graphs under diverse test-time distribution shifts could verify the effectiveness of the proposed method, showcasing its superior ability to manipulate test-time graphs for better GNN generalization ability."
    },
    {
        "title": "Bridging the Gap between Variational Inference and Stochastic Gradient MCMC in Function Space",
        "link_suffix": "/forum?id=bNVbOS3lrl",
        "link": "https://openreview.net/forum?id=bNVbOS3lrl",
        "pdf_link": "https://openreview.net/pdf?id=bNVbOS3lrl",
        "keywords": "Bayesian deep learning, functional variational inference, functional MCMC",
        "abstract": "Traditional parameter-space posterior inference for Bayesian neural networks faces several challenges, such as the difficulty in specifying meaningful prior, the potential pathologies in deep models and the intractability for multi-modal posterior. To address these issues, functional variational inference (fVI) and functional Markov Chain Monte Carlo (fMCMC) are two recently emerged Bayesian inference schemes that perform posterior inference directly in function space by incorporating more informative functional priors. Similar to their parameter-space counterparts, fVI and fMCMC have their own strengths and weaknesses. For instance, fVI is computationally efficient but imposes strong distributional assumptions, while fMCMC is asymptotically exact but suffers from slow mixing in high dimensions. To inherit the complementary benefits of both schemes, this work proposes a novel hybrid inference method for functional posterior inference. Specifically, it combines fVI and fMCMC successively by an elaborate linking mechanism to form an alternating approximation process. We also provide theoretical justification for the soundness of such a hybrid inference through the lens of Wasserstein gradient flows in the function space. We evaluate our method on several benchmark tasks and observe improvements in both predictive accuracy and uncertainty quantification compared to parameter/function-space VI and MCMC."
    },
    {
        "title": "Ensemble Kalman Diffusion Guidance: A Derivative-free Method for Inverse Problems",
        "link_suffix": "/forum?id=ykt6I21YQZ",
        "link": "https://openreview.net/forum?id=ykt6I21YQZ",
        "pdf_link": "https://openreview.net/pdf?id=ykt6I21YQZ",
        "keywords": "inverse problem, diffusion model, derivative-free",
        "abstract": "When solving inverse problems, it is increasingly popular to use pre-trained diffusion models as plug-and-play priors. This framework can accommodate different forward models without re-training while preserving the generative capability of diffusion models.  Despite their success in many imaging inverse problems, most existing methods rely on privileged information such as derivative, pseudo-inverse, or full knowledge about the forward model. This reliance poses a substantial limitation that restricts their use in a wide range of problems where such information is unavailable, such as many scientific applications. To address this, we propose Ensemble Kalman Diffusion Guidance (EnKG) for diffusion models, a derivative-free approach that can solve inverse problems by only accessing forward model evaluations and a pre-trained diffusion model. We study the empirical effectiveness of our method across various inverse problems, including scientific settings such as inferring fluid flows and astronomical objects, which are highly non-linear inverse problems that often only permit black-box access to the forward model."
    },
    {
        "title": "Flash Inference: Near Linear Time Inference for Long Convolution Sequence Models and Beyond",
        "link_suffix": "/forum?id=cZWCjan02B",
        "link": "https://openreview.net/forum?id=cZWCjan02B",
        "pdf_link": "https://openreview.net/pdf?id=cZWCjan02B",
        "keywords": "computational efficiency, inference, sequence generative models, long convolution sequence models, hyena",
        "abstract": "While transformers have been at the core of most recent advancements in sequence generative models, their computational cost remains quadratic in sequence length.\nSeveral subquadratic architectures have been proposed to address this computational issue. Some of them, including long convolution sequence models (LCSMs), such as Hyena, address this issue at training time but remain quadratic during inference. We propose a method for speeding up LCSMs' exact inference to quasilinear time, identify the key properties that make this possible, and propose a general framework that exploits these. Our approach, inspired by previous work on relaxed polynomial interpolation, is based on a tiling which helps decrease memory movement and share computation. It has the added benefit of allowing for almost complete parallelization across layers of the position-mixing part of the architecture. Empirically, we provide a proof of concept implementation for Hyena, which gets up to $1.6\\times$ end-to-end improvement over standard inference by improving $50\\times$ within the position-mixing part."
    },
    {
        "title": "F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching",
        "link_suffix": "/forum?id=JiX2DuTkeU",
        "link": "https://openreview.net/forum?id=JiX2DuTkeU",
        "pdf_link": "https://openreview.net/pdf?id=JiX2DuTkeU",
        "keywords": "text-to-speech, speech synthesis, flow matching, diffusion model, efficiency",
        "abstract": "This paper introduces F5-TTS, a fully non-autoregressive text-to-speech system based on flow matching with Diffusion Transformer (DiT). Without requiring complex designs such as duration model, text encoder, and phoneme alignment, the text input is simply padded with filler tokens to the same length as input speech, and then the denoising is performed for speech generation, which was originally proved feasible by E2 TTS. However, the original design of E2 TTS makes it hard to follow due to its slow convergence and low robustness. To address these issues, we first model the input with ConvNeXt to refine the text representation, making it easy to align with the speech. We further propose an inference-time Sway Sampling strategy, which significantly improves our model's performance and efficiency. This sampling strategy for flow step can be easily applied to existing flow matching based models without retraining. Our design allows faster training and achieves an inference RTF of 0.26, which is greatly improved compared to state-of-the-art diffusion-based TTS models. Trained on a public 100K hours multilingual dataset, our Fairytaler Fakes Fluent and Faithful speech with Flow matching (F5-TTS) exhibits highly natural and expressive zero-shot ability, seamless code-switching capability, and speed control efficiency. Demo samples can be found athttps://F5-TTS.github.io. We will release all code and checkpoints to promote community development."
    },
    {
        "title": "\u03c3-zero: Gradient-based Optimization of\u21130-norm Adversarial Examples",
        "link_suffix": "/forum?id=JMPOqoe4tl",
        "link": "https://openreview.net/forum?id=JMPOqoe4tl",
        "pdf_link": "https://openreview.net/pdf?id=JMPOqoe4tl",
        "keywords": "adversarial examples, sparse attacks, gradient-based attack, machine learning security",
        "abstract": "Evaluating the adversarial robustness of deep networks to gradient-based attacks is challenging.\nWhile most attacks consider $\\ell_2$- and $\\ell_\\infty$-norm constraints to craft input perturbations, only a few investigate sparse $\\ell_1$- and $\\ell_0$-norm attacks.\nIn particular, $\\ell_0$-norm attacks remain the least studied due to the inherent complexity of optimizing over a non-convex and non-differentiable constraint.\nHowever, evaluating adversarial robustness under these attacks could reveal weaknesses otherwise left untested with more conventional $\\ell_2$- and $\\ell_\\infty$-norm attacks.\nIn this work, we propose a novel $\\ell_0$-norm attack, called $\\sigma$-zero, which leverages a differentiable approximation of the $\\ell_0$ norm to facilitate gradient-based optimization, and an adaptive projection operator to dynamically adjust the trade-off between loss minimization and perturbation sparsity.\nExtensive evaluations using MNIST, CIFAR10, and ImageNet datasets, involving robust and non-robust models, show that $\\sigma$-zero finds minimum $\\ell_0$-norm adversarial examples without requiring any time-consuming hyperparameter tuning, and that it outperforms all competing sparse attacks in terms of success rate, perturbation size, and efficiency."
    },
    {
        "title": "Moir\u00e9 Graph Transformer: Eliminating Positional Encoding with Focused Attention",
        "link_suffix": "/forum?id=sJzfxRbEv6",
        "link": "https://openreview.net/forum?id=sJzfxRbEv6",
        "pdf_link": "https://openreview.net/pdf?id=sJzfxRbEv6",
        "keywords": "graph transformer, eliminating graph positional encoding, focused attention mechanism",
        "abstract": "Graph neural networks (GNNs) have increasingly adopted transformer architectures to capture long-range dependencies. However, integrating structural information into graph transformers remains challenging, often necessitating complex positional encodings or masking strategies. In this paper, we propose the Moir\u00e9 Graph Transformer (Moir\u00e9GT), which introduces a novel focused attention mechanism that eliminates the need for explicit graph positional encodings. Our model effectively captures structural context without additional encodings or masks by adjusting attention scores based on a learnable focus function of node distances. We theoretically demonstrate that multiple attention heads with different focus parameters can implicitly encode positional information akin to moir\u00e9 patterns. Experiments on 3D molecular graphs show that Moir\u00e9GT achieves significant performance gains over state-of-the-art models on the QM9 and PCQM4Mv2 datasets. Additionally, our model achieves competitive results on 2D graph tasks, highlighting its versatility and effectiveness."
    },
    {
        "title": "Robust Lurie Networks with Controllable Convergent Dynamics",
        "link_suffix": "/forum?id=qZ4jYual5d",
        "link": "https://openreview.net/forum?id=qZ4jYual5d",
        "pdf_link": "https://openreview.net/pdf?id=qZ4jYual5d",
        "keywords": "dynamical systems, convergence, robustness, $k$-contraction analysis, RNNs",
        "abstract": "The Lurie Network is proposed as a unifying architecture for many existing continuous-time models including Recurrent Neural Networks and Neural Oscillators. Motivated by the need for a general inductive bias, shared by many dynamical systems, this paper proposes an approach to enable network weights and biases to be trained in such a manner so that a generalised concept of stability is guaranteed. This generalised stability measure is that of $k$-contraction which enables global convergence to a point, line or plane in the neural state-space. This result is leveraged to construct a Graph Lurie Network satisfying the same convergence properties. Unconstrained parametrisations of these conditions are derived allowing the models to be trained using standard optimisation algorithms, whilst limiting the search space to solutions satisfying the $k$-contraction constraints. The prediction accuracy, generalisation and robustness of the architecture is benchmarked against other continuous-time models on a range of dynamical systems. Results demonstrate the benefit of controlling the range of dynamics which can be learnt through improved accuracy, generalisation and robustness on all benchmarks."
    },
    {
        "title": "Topological Positional Encoding",
        "link_suffix": "/forum?id=sKv4bbbqUa",
        "link": "https://openreview.net/forum?id=sKv4bbbqUa",
        "pdf_link": "https://openreview.net/pdf?id=sKv4bbbqUa",
        "keywords": "Topological Neural Networks, Persistent Homology, Positional Encodings, GNNs",
        "abstract": "Unlike words in sentences, nodes in general graphs do not have canonical positional information. As a result, the local message-passing framework of popular graph neural networks (GNNs) fails to leverage possibly relevant global structures for the task at hand. In this context, positional encoding methods emerge as an efficient approach to enrich the representational power of GNNs, helping them break node symmetries in input graphs. Similarly, multiscale topological descriptors based on persistent homology have also been integrated into GNNs to boost their expressivity. However, it remains unclear how positional encoding interplays with PH-based topological features and whether we can align the two to improve expressivity further. We address this issue with a novel notion of topological positional encoding (ToPE) that amalgamates the strengths of persistence homology and positional encoding. We establish that ToPE has provable expressivity benefits. Strong empirical assessments further underscore the effectiveness of the proposed method on several graph and language processing applications, including molecular property prediction, out-of-distribution generalization, and synthetic tree tasks."
    },
    {
        "title": "ECG Instruction Tuning on Multimodal LLMs for Report Generation: Benchmark and Evaluation",
        "link_suffix": "/forum?id=vFfVXSP24J",
        "link": "https://openreview.net/forum?id=vFfVXSP24J",
        "pdf_link": "https://openreview.net/pdf?id=vFfVXSP24J",
        "keywords": "ECG, Instruction Tuning, LLMs",
        "abstract": "Electrocardiogram (ECG) is the primary non-invasive diagnostic tool for monitoring cardiac conditions and is crucial in assisting clinicians. Recent studies have concentrated on classifying cardiac conditions using ECG data but have overlooked ECG report generation, which is time-consuming and requires clinical expertise. To automate ECG report generation and ensure its versatility, we propose the Multimodal ECG Instruction Tuning (MEIT) framework, the first attempt to tackle ECG report generation with LLMs and multimodal instructions. To facilitate future research, we establish a benchmark to evaluate MEIT with various LLMs backbones across two large-scale ECG datasets. Our approach uniquely aligns the representations of the ECG signal and the report, and we conduct extensive experiments to benchmark MEIT with nine open-source LLMs using more than 800,000 ECG reports. MEIT's results underscore the superior performance of instruction-tuned LLMs, showcasing their proficiency in quality report generation, zero-shot capabilities, resilience to signal perturbation, and alignment with human expert evaluation.  These findings emphasize the efficacy of our MEIT framework and its potential for real-world clinical application."
    },
    {
        "title": "Interleaving Optimizers for DNN Training",
        "link_suffix": "/forum?id=uApm5otXfH",
        "link": "https://openreview.net/forum?id=uApm5otXfH",
        "pdf_link": "https://openreview.net/pdf?id=uApm5otXfH",
        "keywords": "Optimizer, DNN, HPO",
        "abstract": "Optimizers are crucial in deep neural network (DNN) training, affecting model quality and convergence. Researchers have found that different optimizers often suit different problems or different stages of a problem. Hence, some studies have tried to combine different optimizers to better train DNNs. However, existing methods are limited to simple optimizer switch strategies, which leads to unstable model quality and slow convergence. In this paper, we propose a fine-grain optimizer switch method called Iterleaving Optimizer for Model Training (IOMT), which automatically switches to the appropriate optimizer and hyperparameters based on the training stage information, achieving faster convergence and better model quality. IOMT employs surrogate models to estimate the performance of different optimizers during training and is supported by a transferability assessment to predict the training cost. By combining the transferability assessment, performance estimation, and training process information with an acquisition function, IOMT calculates the optimization gain of each optimizer and switches the optimizer with the largest gain for the next training stage. The experimental results on full training and fine-tuning demonstrate that IOMT achieves faster convergence (e.g., 10% on thestl10dataset) and better performance (e.g., 3% accuracy improvement on thecifar10dataset) compared to existing methods."
    },
    {
        "title": "Personalized Federated Learning With Similarity Information Supervisor",
        "link_suffix": "/forum?id=7rq2OzkJg3",
        "link": "https://openreview.net/forum?id=7rq2OzkJg3",
        "pdf_link": "https://openreview.net/pdf?id=7rq2OzkJg3",
        "keywords": "Personalized Federated Learning, Heterogeneous Data",
        "abstract": "A crucial issue in federated learning is the heterogeneity of data between clients, which can lead to model weight divergence, eventually deteriorating the model performance. Personalized federated learning (pFL) has been proven to be an effective approach to addressing data heterogeneity in federated learning. However, existing pFL studies seldom verify whether the broadcast global model is beneficial for the local model performance. To address this, we propose a novel pFL method, called federated learning with similarity information supervision (FedSimSup). Specifically, FedSimSup incorporates a local supervisor to assist the model training and a personalized model for global information aggregation. The role of the supervisor is to refine the personalized model when it is not beneficial for the local model performance, ensuring the effective global information aggregation while aligning with the local heterogeneous data. Additionally, the similarity relationships between the clients are measured using label distribution differences of the local raw data to weight the personalized models, promoting information usage among similar clients. Experimental results demonstrate three advantages of FedSimSup: (1) It shows better performance over heterogeneous data compared with seven state-of-the-art federated learning methods; (2) It can allow for different model architectures across different clients; (3) It offers a certain degree of interpretability."
    },
    {
        "title": "NAText: Faster Scene Text Recognition with Non Autoregressive Transformer",
        "link_suffix": "/forum?id=gvZpk0n68q",
        "link": "https://openreview.net/forum?id=gvZpk0n68q",
        "pdf_link": "https://openreview.net/pdf?id=gvZpk0n68q",
        "keywords": "Scene Text Recognition, Non Autogressive",
        "abstract": "Autoregressive-based attention methods  have made significant advance in scene text recognition. However, the inference speed of these methods is limited due to their iterative decoding scheme. In contrast, the non-autoregressive methods has a parallel decoding paradigm, making them  much faster than the autoregressive decoder. The dilemma is that, though the speed is increased,  the non-autoregressive methods are based on the character-wise independent assumption, making them perform much worse than the autoregressive methods. In this paper, we propose a simple non-autoregressive transformer-based text recognizer, named NAText, by proposing a progressive learning approach to force the network to learn the relationship between characters. Furthermore, we redesign the query composition by introducing positional encoding of the character center. And it has clear physical meanings than the conventional one. Experiments show that our NAText helps to better utilize the positional information for 2D feature aggregation. With all these techniques, the NAText has achieved competitive performance to the state-of-the-art methods."
    }
]
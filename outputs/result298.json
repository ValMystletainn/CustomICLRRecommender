[{"title": "BLIP-3-Video: You Only Need 32 Tokens to Represent a Video Even in VLMs", "link_suffix": "/forum?id=CKYsXi0dOV", "link": "https://openreview.net/forum?id=CKYsXi0dOV", "pdf_link": "https://openreview.net/pdf?id=CKYsXi0dOV", "keywords": "video representation, video foundation model, vlm, multimodal language model", "abstract": "We present BLIP-3-Video, a multimodal language model for videos, particularly designed to efficiently capture temporal information over multiple frames. BLIP-3-Video takes advantage of the `temporal encoder' in addition to the conventional visual tokenizer, which maps a sequence of tokens over multiple frames into a compact set of visual tokens. This enables BLIP-3-Video to use much fewer visual tokens than its competing models (e.g., 32 vs. 4608 tokens). We explore different types of temporal encoders, including learnable spatio-temporal pooling as well as sequential models like Token Turing Machines. We experimentally confirm that BLIP-3-Video obtains video question-answering accuracies comparable to much larger state-of-the-art models (e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using fewer visual tokens.", "title_embedding_index": 14850, "title_abs_embedding_index": 14875}, {"title": "Moonwalk: Inverse-Forward Differentiation", "link_suffix": "/forum?id=97dJ3Jp5P4", "link": "https://openreview.net/forum?id=97dJ3Jp5P4", "pdf_link": "https://openreview.net/pdf?id=97dJ3Jp5P4", "keywords": "Forward-mode, Forward Gradients, Automatic Differentiation, Projected gradients, Invertible Networks, Bijective Networks, Jacobian-Vector product, Alternatives to backprop, forwardprop, memory-efficient deeplearning, JAX", "abstract": "Backpropagation, while effective for gradient computation, falls short in addressing memory consumption, limiting scalability. This work explores forward-mode gradient computation as an alternative in invertible and right-invertible networks, showing its potential to reduce the memory footprint without substantial drawbacks. \nWe introduce a novel technique based on a vector-inverse-Jacobian product that accelerates the computation of forward gradients while retaining the advantages of memory reduction and preserving the fidelity of true gradients. Our method, Moonwalk, has a time complexity linear in the depth of the network, unlike the quadratic time complexity of na\u00efve forward, and empirically reduces computation time by several orders of magnitude without allocating more memory. We further accelerate Moonwalk by combining it with reverse-mode differentiation to achieve time complexity comparable with backpropagation while maintaining a much smaller memory footprint. Finally, we showcase the robustness of our method across several architecture choices. Moonwalk is the first forward-based method to compute true gradients in invertible and right-invertible networks in computation time comparable to backpropagation and using significantly less memory.", "title_embedding_index": 14851, "title_abs_embedding_index": 14876}, {"title": "Dynamic Neural Fortresses: An Adaptive Shield for Model Extraction Defense", "link_suffix": "/forum?id=029hDSVoXK", "link": "https://openreview.net/forum?id=029hDSVoXK", "pdf_link": "https://openreview.net/pdf?id=029hDSVoXK", "keywords": "Model Extraction Defense", "abstract": "Model extraction aims to acquire a pre-trained black-box model concealed behind a black-box API. \nExisting defense strategies against model extraction primarily concentrate on preventing the unauthorized extraction of API functionality. However, two significant challenges still need to be solved: (i) Neural network architecture of the API constitutes a form of intellectual property that also requires protection; (ii) The current practice of allocating the same network architecture to both attack and benign queries results in substantial resource wastage. To address these challenges, we propose a novel \\textit{Dynamic Neural Fortresses} (DNF) defense method, employing a dynamic Early-Exit neural network, deviating from the conventional fixed architecture. Firstly, we facilitate the random exit of attack queries from the network at earlier layers. This strategic exit point selection significantly reduces the computational cost for attack queries. Furthermore, the random exit of attack queries from earlier layers introduces increased uncertainty for attackers attempting to discern the exact architecture, thereby enhancing architectural protection. On the contrary, we aim to facilitate benign queries to exit at later layers, preserving model utility, as these layers typically yield meaningful information. \nExtensive experiments on defending against various model extraction scenarios and datasets demonstrate the effectiveness of DNF, achieving a notable 2$\\times$ improvement in efficiency and an impressive reduction of up to 12% in clone model accuracy compared to SOTA defense methods. Additionally, DNF provides strong protection against neural architecture theft, effectively safeguarding network architecture from being stolen.", "title_embedding_index": 14852, "title_abs_embedding_index": 14877}, {"title": "How many samples are needed to train a deep neural network?", "link_suffix": "/forum?id=q6zrZbth1F", "link": "https://openreview.net/forum?id=q6zrZbth1F", "pdf_link": "https://openreview.net/pdf?id=q6zrZbth1F", "keywords": "Neural networks, Deep learning, generalization error, information theory, mini-max bound, learning theory", "abstract": "Even though neural networks have become standard tools in many areas, many important statistical questions remain open. This paper studies the question of how much data are needed to train a ReLU feed-forward neural network. Our theoretical and empirical results suggest that the generalization error of ReLU feed-forward neural networks scales at the rate $1/\\sqrt{n}$ in the sample size $n$-rather than the \"parametric rate\"  $1/n$, which might be suggested by traditional statistical theories. Thus, broadly speaking, our results underpin the common belief that neural networks need \"many\" training samples. Along the way, we also establish new technical insights, such as the first lower bounds of the entropy of ReLU feed-forward networks.", "title_embedding_index": 14853, "title_abs_embedding_index": 14878}, {"title": "Federated Learning with Dynamic Client Arrival and Departure: Convergence and Rapid Adaptation via Initial Model Construction", "link_suffix": "/forum?id=OO6lPenO4c", "link": "https://openreview.net/forum?id=OO6lPenO4c", "pdf_link": "https://openreview.net/pdf?id=OO6lPenO4c", "keywords": "Federated Learning, Client Participation, Dynamic Initial Model Construction, Client Availability", "abstract": "While most existing federated learning (FL) approaches assume a fixed set of clients in the system, in practice, clients can dynamically leave or join the system depending on their needs or interest in the specific task. This dynamic FL setting introduces several key challenges: (1) the objective function dynamically changes depending on the current set of clients, unlike traditional FL approaches that maintain a static optimization goal; (2) the current global model may not serve as the best initial point for the next FL rounds and could potentially lead to slow adaptation, given the possibility of clients leaving or joining the system. In this paper, we consider a dynamic optimization objective in FL that seeks the optimal model tailored to the currently active set of clients. Building on our probabilistic framework that provides direct insights into how the arrival and departure of different types of clients influence the shifts in optimal points, we establish an upper bound on the optimality gap, accounting for factors such as stochastic gradient noise, local training iterations, non-IIDness of data distribution, and deviations between optimal points caused by dynamic client pattern. We also propose an adaptive initial model construction strategy that employs weighted averaging guided by gradient similarity, prioritizing models trained on clients whose data characteristics align closely with the current one, thereby enhancing adaptability to the current clients. The proposed approach is validated on various datasets and FL algorithms, demonstrating robust performance across diverse client arrival and departure patterns, underscoring its effectiveness in dynamic FL environments.", "title_embedding_index": 14854, "title_abs_embedding_index": 14879}, {"title": "Guided Score Identity Distillation for Data-Free One-Step Text-to-Image Generation", "link_suffix": "/forum?id=HMVDiaWMwM", "link": "https://openreview.net/forum?id=HMVDiaWMwM", "pdf_link": "https://openreview.net/pdf?id=HMVDiaWMwM", "keywords": "stable diffusion, data-free distillation, single-step generation, classifier-free guidance", "abstract": "Diffusion-based text-to-image generation models trained on extensive text-image pairs have demonstrated the ability to produce photorealistic images aligned with textual descriptions. However, a significant limitation of these models is their slow sample generation process, which requires iterative refinement through the same network. To overcome this, we introduce a data-free guided distillation method that enables the efficient distillation of pretrained Stable Diffusion models without access to the real training data, often restricted due to legal, privacy, or cost concerns. This method enhances Score identity Distillation (SiD) with Long and Short Classifier-Free Guidance (LSG), an innovative strategy that applies Classifier-Free Guidance (CFG) not only to the evaluation of the pretrained diffusion model but also to the training and evaluation of the fake score network. We optimize a model-based explicit score matching loss using a score-identity-based approximation alongside our proposed guidance strategies for practical computation. By exclusively training with synthetic images generated by its one-step generator, our data-free distillation method rapidly improves FID and CLIP scores, achieving state-of-the-art FID performance while maintaining a competitive CLIP score. Notably, the one-step distillation of Stable Diffusion 1.5 achieves an FID of8.15on the COCO-2014 validation set, a record low value under the data-free setting.", "title_embedding_index": 14855, "title_abs_embedding_index": 14880}, {"title": "Partial Gromov-Wasserstein Metric", "link_suffix": "/forum?id=sCew1tR6No", "link": "https://openreview.net/forum?id=sCew1tR6No", "pdf_link": "https://openreview.net/pdf?id=sCew1tR6No", "keywords": "Optimal transport, Gromov-Wasserstein problem, Unbalanced optimal transport", "abstract": "The Gromov-Wasserstein (GW) distance has gained increasing interest in the machine learning community in recent years, as it allows for the comparison of measures in different metric spaces. To overcome the limitations imposed by the equal mass requirements of the classical GW problem, researchers have begun exploring its application in unbalanced settings. However, Unbalanced GW (UGW) can only be regarded as a discrepancy rather than a rigorous metric/distance between two metric measure spaces (mm-spaces). In this paper, we propose a particular case of the UGW problem, termed Partial Gromov-Wasserstein (PGW). We establish that PGW is a well-defined metric between mm-spaces and discuss its theoretical properties, including the existence of a minimizer for the PGW problem and the relationship between PGW and GW, among others. We then propose two variants of the Frank-Wolfe algorithm for solving the PGW problem and show that they are mathematically and computationally equivalent. Moreover, based on our PGW metric, we introduce the analogous concept of barycenters for mm-spaces. Finally, we validate the effectiveness of our PGW metric and related solvers in applications such as shape matching, shape retrieval, and shape interpolation, comparing them against existing baselines.", "title_embedding_index": 14856, "title_abs_embedding_index": 14881}, {"title": "Tournament Evaluation of Large Language Models", "link_suffix": "/forum?id=5ZpN6W5uRm", "link": "https://openreview.net/forum?id=5ZpN6W5uRm", "pdf_link": "https://openreview.net/pdf?id=5ZpN6W5uRm", "keywords": "evaluation, large language models, Elo ratings, metrics, benchmarks", "abstract": "For several decades, the standard approach to evaluating a learned model has been to compute a numerical loss that summarizes the quality of the model based on a previously unseen test set. Two models for the same task can then be compared by looking at their scores on this set. However, recent experience with large language models (LLMs) has shown that comparing summary statistics of two broadly-capable models may not provide a reliable predictor of performance on real-world tasks. This has led to a growing use of crowd-sourced human feedback directly comparing outputs from pairs of models. While helpful, this approach requires a process that involves significant time and human effort, limiting the number of models that can be thoroughly evaluated. To address the need for a scalable method of comparing modern LLMs, we present a novel approach to evaluation via tournament-style model competitions that are constructed automatically from pre-existing benchmarks. We use these automatically-constructed tournaments to compute ratings for a range of models on a diverse set of tasks that use automated scoring via both multiple-choice and free-form text generation. We compare four prominent rating systems: Elo, Glicko, TrueSkill$\\texttrademark$, and the Bradley-Terry model, and find that automatically-constructed tournaments provide reliable information about the relative performance of LLMs while using only a fraction of the amount of data required by current benchmark-based evaluation methods. We discuss implications for model evaluations and propose future directions for large-scale LLM comparisons.", "title_embedding_index": 14857, "title_abs_embedding_index": 14882}, {"title": "Score Forgetting Distillation: A Swift, Data-Free Method for Machine Unlearning in Diffusion Models", "link_suffix": "/forum?id=gjwhDHeAsz", "link": "https://openreview.net/forum?id=gjwhDHeAsz", "pdf_link": "https://openreview.net/pdf?id=gjwhDHeAsz", "keywords": "machine unlearning, diffusion models, generative modeling, trustworthy machine learning", "abstract": "The machine learning community is increasingly recognizing the importance of fostering trust and safety in modern generative AI (GenAI) models. We posit machine unlearning (MU) as a crucial foundation for developing safe, secure, and trustworthy GenAI models. Traditional MU methods often rely on stringent assumptions and require access to real data. This paper introduces Score Forgetting Distillation (SFD), an innovative MU approach that promotes the forgetting of undesirable information in diffusion models by aligning the conditional scores of \"unsafe\" classes or concepts with those of \"safe\" ones. To eliminate the need for real data, our SFD framework incorporates a score-based MU loss into the score distillation objective of a pretrained diffusion model. This serves as a regularization term that preserves desired generation capabilities while enabling the production of synthetic data through a one-step generator. Our experiments on pretrained label-conditional and text-to-image diffusion models demonstrate that our method effectively accelerates the forgetting of target classes or concepts during generation, while preserving the quality of other classes or concepts. This unlearned and distilled diffusion not only pioneers a novel concept in MU but also accelerates the generation speed of diffusion models. Our experiments and studies on a range of diffusion models and datasets confirm that our approach is generalizable, effective, and advantageous for MU in diffusion models.", "title_embedding_index": 14858, "title_abs_embedding_index": 14883}, {"title": "An Examination on the Effectiveness of Divide-and-Conquer Prompting in Large Language Models", "link_suffix": "/forum?id=cSHBZ4U9eO", "link": "https://openreview.net/forum?id=cSHBZ4U9eO", "pdf_link": "https://openreview.net/pdf?id=cSHBZ4U9eO", "keywords": "Program-guided Prompt, Divide-and-Conquer, Foundation Model, Misinformation Detection", "abstract": "Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, simple instructional prompts suffer from inaccurate responses. Existing works show that more complicated prompting strategies, such as Chain-of-Thoughts and Least-to-Most, can unlock LLM's powerful capacity in diverse areas. Recent researches reveal that simple divide-and-conquer prompting strategy, i.e. simply dividing the input sequence to multiple sub-inputs, can substantially improve LLM's performance in some specific tasks such as misinformation detection. In this paper, we aim at understanding the utility of divide-and-conquer prompting strategy, i.e. on which kind of tasks this strategy gets advantages. Specifically, we provide a theoretic analysis to divide-and-conquer prompting strategy and help us identify the specific tasks where DaC prompting can bring performance boost with theoretic guarantee. We then present two cases (\\textbf{large integer arithmetic and fact verification}) where experimental results aligns with our theoretic analysis.", "title_embedding_index": 14859, "title_abs_embedding_index": 14884}, {"title": "ProTrain: Efficient LLM Training via Automatic Memory Management", "link_suffix": "/forum?id=e1Z4NCQ146", "link": "https://openreview.net/forum?id=e1Z4NCQ146", "pdf_link": "https://openreview.net/pdf?id=e1Z4NCQ146", "keywords": "ML System, Memory Optimization, Data Parallelism, ZeRO, Gradient Checkpointing, Tensor Offloading", "abstract": "Training billion-scale large language models (LLMs) with just a few consumer-grade graphics cards is key to democratizing LLM access. However, existing frameworks often depend on manual tuning of memory management settings, leading to inefficient hardware utilization and suboptimal performance. This paper introduces ProTrain, a novel training system that automatically tailors memory management policies to the model architecture and underlying hardware resources, eliminating the need for manual intervention. ProTrain features (1) automated memory management that abstracts complex memory management strategies into a few tunable configuration parameters and searches for optimal parameter settings using cost models and (2) a runtime profiler that provides precise estimates of latency, memory usage, and I/O bandwidth to build high-fidelity cost models. \nProTrain does not change the training algorithm and thus does not compromise accuracy. Experiments show that ProTrain improves training throughput by 1.43$\\times$ to 2.71$\\times$ compared to the state-of-the-art training systems.", "title_embedding_index": 14860, "title_abs_embedding_index": 14885}, {"title": "Kernel Neural Operators (KNOs) for Scalable, Memory-efficient, Geometrically-flexible Operator Learning", "link_suffix": "/forum?id=UjQthmslFV", "link": "https://openreview.net/forum?id=UjQthmslFV", "pdf_link": "https://openreview.net/pdf?id=UjQthmslFV", "keywords": "operator learning, scientific machine learning, neural operator, kernel", "abstract": "This paper introduces the Kernel Neural Operator (KNO), a novel operator learning technique that uses deep kernel-based integral operators in conjunction with quadrature for function-space approximation of operators (maps from functions to functions). KNOs use parameterized, closed-form, finitely-smooth, and compactly-supported kernels with trainable sparsity parameters within the integral operators to significantly reduce the number of parameters that must be learned relative to existing neural operators. Moreover, the use of quadrature for numerical integration endows the KNO with geometric flexibility that enables operator learning on irregular geometries. Numerical results demonstrate that on existing benchmarks the training and test accuracy of KNOs is higher than popular operator learning techniques while using at least an order of magnitude fewer trainable parameters. KNOs thus represent a new paradigm of low-memory, geometrically-flexible, deep operator learning, while retaining the implementation simplicity and transparency of traditional kernel methods from both scientific computing and machine learning.", "title_embedding_index": 14861, "title_abs_embedding_index": 14886}, {"title": "A Healthy Food Recommender System Using Collaborative Filtering and Transformers", "link_suffix": "/forum?id=UYXq4q1GpW", "link": "https://openreview.net/forum?id=UYXq4q1GpW", "pdf_link": "https://openreview.net/pdf?id=UYXq4q1GpW", "keywords": "Collaborative Filtering, EASE, Nutrition, BERT", "abstract": "Unhealthy eating habits are a major contributing factor to public health problems such as the globally rising obesity rate. One way to help solve this problem is by creating systems that can suggest better food choices in order to improve the way people eat. A critical challenge with these systems is making sure they offer 1) suggestions that match what users like, while also 2) recommending healthy foods. In this paper, we introduce a novel food recommender system that provides healthy food recommendations similar to what the user has previously eaten. We used collaborative filtering to generate recommendations and re-ranked the recommendations using a novel health score and a BERT embedding similarity score. We evaluated our system on human subjects by conducting A/B testing on several methods deployed in a web application.", "title_embedding_index": 14862, "title_abs_embedding_index": 14887}, {"title": "Generating Fake Data to Fake Privacy Pryers", "link_suffix": "/forum?id=iUwTDbjqyd", "link": "https://openreview.net/forum?id=iUwTDbjqyd", "pdf_link": "https://openreview.net/pdf?id=iUwTDbjqyd", "keywords": "Privacy, Data valuation, Generative models", "abstract": "Asymmetry of data complexity and model capacity can create privacy vulnerability. That is because if there are relatively fewer data points while the model capacity is relatively higher, a model may memorize almost all the data points. As a remedy for the issue, more data samples can be generated. When generating more data samples, the aim is to protect and promote the original data as privacy-safe as possible while generating more privacy-risky data samples to fake privacy attackers. To enable the aim, we investigate each individual data sample's privacy level, unlike existing studies that only take into account an overall dataset's privacy, which is not precisely effective. We show how effective our generative approach is in combating privacy attacks. Our work is novel in that we propose a sample-level valuation, and data transformation and generation approach in the privacy domain.", "title_embedding_index": 14863, "title_abs_embedding_index": 14888}, {"title": "Deep MMD Gradient Flow without adversarial training", "link_suffix": "/forum?id=Pf85K2wtz8", "link": "https://openreview.net/forum?id=Pf85K2wtz8", "pdf_link": "https://openreview.net/pdf?id=Pf85K2wtz8", "keywords": "Generative modeling, diffusion models, Wasserstein gradient flows, generative adversarial networks, discriminator flow", "abstract": "We propose a gradient flow procedure for generative modeling by transporting particles from an initial source distribution to a target distribution, where the gradient field on the particles is given by a noise-adaptive Wasserstein Gradient of the Maximum Mean Discrepancy (MMD). The noise adaptive MMD is trained on data distributions corrupted by increasing levels of noise, obtained via a forward diffusion process, as commonly used in denoising diffusion probabilistic models. The result is a generalization of MMD Gradient Flow, which we call Diffusion-MMD-Gradient Flow or DMMD. The divergence training procedure is related to discriminator training in Generative Adversarial Networks (GAN), but does not require adversarial training. We obtain competitive empirical performance in unconditional image generation on CIFAR10, MNIST, CELEB-A (64 x64) and LSUN Church (64 x 64). Furthermore, we demonstrate the validity of the approach when MMD is replaced by a lower bound on the KL divergence.", "title_embedding_index": 14864, "title_abs_embedding_index": 14889}, {"title": "Forget Vectors at Play: Universal Input Perturbations Driving Machine Unlearning in Image Classification", "link_suffix": "/forum?id=7tpMhoPXrL", "link": "https://openreview.net/forum?id=7tpMhoPXrL", "pdf_link": "https://openreview.net/pdf?id=7tpMhoPXrL", "keywords": "Machine Unlearning, Image Classification, Universal Input Perturbations", "abstract": "Machine unlearning (MU), which seeks to erase the influence of specific unwanted data from already-trained models, is becoming increasingly vital in model editing, particularly to comply with evolving data regulations like the \"right to be forgotten''. Conventional approaches are predominantly model-based, typically requiring retraining or fine-tuning the model's weights to meet unlearning requirements. In this work, we approach the MU problem from a novel input perturbation-based perspective, where the model weights remain intact throughout the unlearning process. We demonstrate the existence of a proactive input-based unlearning strategy, referred to forget vector, which can be generated as an input-agnostic data perturbation and remains as effective as model-based approximate unlearning approaches. We also show that multiple given forget vectors (e.g., each targeting the unlearning of a specific data class) can be combined through simple arithmetic operations (e.g., linear combinations) to generate new forget vectors for unseen unlearning tasks (e.g., targeting the unlearning of an arbitrary subset across all classes). An additional advantage of our proposed forget vector approach is its parameter efficiency, as it eliminates the need for updating model weights. We conduct extensive experiments to validate the effectiveness of forget vector and its arithmetic for MU in image classification against a series of model-based unlearning baselines.", "title_embedding_index": 14865, "title_abs_embedding_index": 14890}, {"title": "Fragment and Geometry Aware Tokenization of Molecules for Structure-Based Drug Design Using Language Models", "link_suffix": "/forum?id=mMhZS7qt0U", "link": "https://openreview.net/forum?id=mMhZS7qt0U", "pdf_link": "https://openreview.net/pdf?id=mMhZS7qt0U", "keywords": "Generative models, language models, molecule tokenization, structure-based drug design, fragment", "abstract": "Structure-based drug design (SBDD) is crucial for developing specific and effective therapeutics against protein targets but remains challenging due to complex protein-ligand interactions and vast chemical space. Although language models (LMs) have excelled in natural language processing, their application in SBDD is underexplored. To bridge this gap, we introduce a method, known as Frag2Seq, to apply LMs to SBDD by generating molecules in a fragment-based manner in which fragments correspond to functional modules. We transform 3D molecules into fragment-informed sequences using $SE(3)$-equivariant molecule and fragment local frames, extracting $SE(3)$-invariant sequences that preserve geometric information of 3D fragments. Furthermore, we incorporate protein pocket embeddings obtained from a pre-trained inverse folding model into the LMs via cross-attention to capture protein-ligand interaction, enabling effective target-aware molecule generation. Benefiting from employing LMs with fragment-based generation and effective protein context encoding, our model achieves the best performance on binding vina score and chemical properties such as QED and Lipinski, which shows our model\u2019s efficacy in generating drug-like ligands with higher binding affinity against target proteins. Moreover, our method also exhibits higher sampling efficiency compared to atom-based autoregressive and diffusion baselines with at most $\\times 300$ speedup.", "title_embedding_index": 14866, "title_abs_embedding_index": 14891}, {"title": "VERT: A SystemVerilog Assertion Dataset to Improve Hardware Verification with LLMs", "link_suffix": "/forum?id=rZmQ2z7MPA", "link": "https://openreview.net/forum?id=rZmQ2z7MPA", "pdf_link": "https://openreview.net/pdf?id=rZmQ2z7MPA", "keywords": "Hardware Verification, Large Language Models, SystemVerilog", "abstract": "Hardware verification is a critical step in the modern System-on-Chip (SoC) design cycle, consuming approximately 70% of development time. SystemVerilog assertions are pivotal in the verification process, ensuring that designs function as intended. However, existing industrial practices rely on manual assertion generation, which becomes increasingly untenable as hardware systems become complex. Recent research has explored the potential of Large Language Models (LLMs) to automate the hardware verification process, reducing human intervention. Despite this, State-of-the-Art (SOTA) proprietary models, such as OpenAI's GPT-4o, have shown limitations in generating accurate assertions and require costly licenses and restricted usage. While smaller, open-source LLMs offer a more accessible option, they require fine-tuning to handle the complexities of the source code and generate accurate assertions. This highlights the need for a dataset that enables these models to achieve superior performance compared to SOTA LLMs. To this end, we present VERT, a dataset designed to improve the generation of SystemVerilog assertions using LLMs. Our dataset empowers researchers and hardware corporations to fine-tune smaller, open-source LLMs, surpassing larger proprietary models such as GPT-4 in accuracy and efficiency. Furthermore, VERT eliminates the need for expensive licenses and ensures data privacy through local fine-tuning, providing a scalable, cost-effective solution for automated hardware verification. To curate the dataset, we systematically compile and augment variables from open-source hardware description languages (HDL), generating conditions to create synthetic code snippets paired with corresponding assertions. We show that smaller, open-source LLMs, such as Deepseek Coder 6.7B and Llama 3.1 8B, when fine-tuned on VERT, outperform OpenAI's GPT-4o in assertion generation. The assertions generated by the fine-tuned models are evaluated on industry-standard platforms, including OpenTitan, CVA6, and Pulpissimo SoCs, demonstrating up to a 96.88% improvement in both functional and syntactical correctness compared to the base models and up to 24.14% when compared to GPT-4o. This demonstrates the prowess of VERT in enabling researchers to potentially reduce the overhead and human error associated with manual assertion generation, offering a scalable solution for industry-grade hardware designs. The dataset is available athttps://anonymous.4open.science/r/VERT-4D6D/.", "title_embedding_index": 14867, "title_abs_embedding_index": 14892}, {"title": "Geometry Informed Tokenization of Molecules for Language Model Generation", "link_suffix": "/forum?id=HbZrxBXzks", "link": "https://openreview.net/forum?id=HbZrxBXzks", "pdf_link": "https://openreview.net/pdf?id=HbZrxBXzks", "keywords": "Generative models, language models, tokenization, 3d molecule generation, SE(3)-equivariance", "abstract": "We consider molecule generation in 3D space using language models (LMs), which requires discrete tokenization of 3D molecular geometries. Although tokenization of molecular graphs exists, that for 3D geometries is largely unexplored. Here, we attempt to bridge this gap by proposing the Geo2Seq, which converts molecular geometries into SE(3)-invariant 1D discrete sequences. Geo2Seq consists of canonical labeling and invariant spherical representation steps, which together maintain geometric and atomic fidelity in a format conducive to LMs. Our experiments show that, when coupled with Geo2Seq, various LMs excel in molecular geometry generation, especially in controlled generation tasks.", "title_embedding_index": 14868, "title_abs_embedding_index": 14893}, {"title": "Deep Bootstrap Aggregation via Least Squares Estimation", "link_suffix": "/forum?id=k7pnwqrpKB", "link": "https://openreview.net/forum?id=k7pnwqrpKB", "pdf_link": "https://openreview.net/pdf?id=k7pnwqrpKB", "keywords": "generalized least squares, bagging, random forest, ensemble learning, regression problems", "abstract": "Bootstrap aggregation, commonly referred to as bagging, is a fundamental technique in ensemble learning designed to enhance the performance of predictive models. It is well-established that the effectiveness of bagging is strongly influenced by the management of correlations among the aggregated models. For instance, random forests, a widely-used ensemble method, address this issue by randomly selecting features to reduce the correlation between individual tree models. In this study, we propose a method called ``Deep Bootstrap Aggregation'' for regression tasks, which combines deep network architectures with least squares estimation to improve the predictive accuracy of bagging models. Both theoretical analysis and empirical experiments support the effectiveness of the proposed approach.", "title_embedding_index": 14869, "title_abs_embedding_index": 14894}, {"title": "On the utility of Equivariance and Symmetry Breaking in Deep learning architectures on point clouds", "link_suffix": "/forum?id=yr7PjzmkQ6", "link": "https://openreview.net/forum?id=yr7PjzmkQ6", "pdf_link": "https://openreview.net/pdf?id=yr7PjzmkQ6", "keywords": "deep learning architectures, geometric deep learning, equivariance, group convolutional networks, generative modeling", "abstract": "This paper explores key factors influencing the performance of models working with 3D point clouds, focusing on the impact of additional input information and $SE(3)$ equivariance. It is often argued that providing more information as input improves a model's performance. However, if this additional information breaks certain properties, such as $SE(3)$ equivariance, does it remain beneficial? This work explores the trade-offs between flexibility and weight-sharing introduced by equivariant layers, assessing when equivariance boosts or detracts from performance. We identify the key aspects of equivariant and non-equivariant architectures that drive success in different tasks by benchmarking them on segmentation, regression, and generation tasks across multiple datasets with increasing complexity. We observe a positive impact of equivariance, which becomes more pronounced with increasing task complexity, even when strict equivariance is not required.", "title_embedding_index": 14870, "title_abs_embedding_index": 14895}, {"title": "Catastrophic Failure of LLM Unlearning via Quantization", "link_suffix": "/forum?id=lHSeDYamnz", "link": "https://openreview.net/forum?id=lHSeDYamnz", "pdf_link": "https://openreview.net/pdf?id=lHSeDYamnz", "keywords": "Machine Unlearning, Large Language Models", "abstract": "Large language models (LLMs) have shown remarkable proficiency in generating text, benefiting from extensive training on vast textual corpora. However, LLMs may also acquire unwanted behaviors from the diverse and sensitive nature of their training data, which can include copyrighted and private content. Machine unlearning has been introduced as a viable solution to remove the influence of such problematic content without the need for costly and time-consuming retraining. This process aims to erase specific knowledge from LLMs while preserving as much model utility as possible. Despite the effectiveness of current unlearning methods, little attention has been given to whether existing unlearning methods for LLMs truly achieve forgetting or merely hide the knowledge, which current unlearning benchmarks fail to detect. This paper reveals that applying quantization to models that have undergone unlearning can restore the \"forgotten\" information. We conduct comprehensive experiments using various quantization techniques across multiple precision levels to thoroughly evaluate this phenomenon. We find that for unlearning methods with utility constraints, the unlearned model retains an average of 21% of the intended forgotten knowledge in full precision, which significantly increases to 83% after 4-bit quantization. Based on our empirical findings, we provide a theoretical explanation for the observed phenomenon and propose a quantization-robust unlearning strategy aimed at mitigating this intricate issue. Our results highlight a fundamental tension between preserving the utility of the unlearned model and preventing knowledge recovery through quantization, emphasizing the challenge of balancing these two objectives. Altogether, our study underscores a major failure in existing unlearning methods for LLMs, strongly advocating for more comprehensive and robust strategies to ensure authentic unlearning without compromising model utility. Our code is available at:https://anonymous.4open.science/r/FailureUnlearning-20DE.", "title_embedding_index": 14871, "title_abs_embedding_index": 14896}, {"title": "WenXinGPT: A Multimodal Conversational Model for Enhancing Orthopedic Expert Consultations", "link_suffix": "/forum?id=4bOCP1GtX4", "link": "https://openreview.net/forum?id=4bOCP1GtX4", "pdf_link": "https://openreview.net/pdf?id=4bOCP1GtX4", "keywords": "Multimodal conversational model, orthopedic expert consultations, medical visual language model, zero-shot scenarios, large language models", "abstract": "Inspired by the hospital expert consultation model, this paper proposes a conversational medical visual language model for orthopedics, named WenXinGPT (Multi-disciplinary Collaboration). The core concept of this work focuses on aligning medical visual and textual representations to leverage high-quality data for generating expert consultation dialogues across hospital departments. The primary objective is to uncover orthopedic knowledge within medical intelligence models and enhance their reasoning abilities in an interpretable manner without requiring additional training. Our research particularly emphasizes zero-shot scenarios, and the results from experiments on 16 datasets provided by Peking Union Medical College Hospital demonstrate that the proposed WenXinGPT framework excels at mining and utilizing medical expertise within large language models, while also expanding their reasoning capabilities. Based on these findings, we conducted manual evaluations to identify and categorize common errors in our methods, along with ablation studies aimed at understanding the impact of various factors on overall performance.", "title_embedding_index": 14872, "title_abs_embedding_index": 14897}, {"title": "Understanding Dimensional Collapse in Cross-Modal Feature Distillation", "link_suffix": "/forum?id=19ufhreGTj", "link": "https://openreview.net/forum?id=19ufhreGTj", "pdf_link": "https://openreview.net/pdf?id=19ufhreGTj", "keywords": "knowledge distillation, feature distillation, cross-modal learning, dimensional collapse", "abstract": "To overcome limited computing resources and the complexity of sensor configurations in deploying multi-modal neural networks in real-world applications, cross-modal knowledge distillation (CMKD) aims to transfer valuable information from a pretrained teacher model to a deployable student model with the target modality. Despite the successful applications of CMKD in various fields, our understanding of knowledge transfer across different modalities remains insufficient to fully explain the efficacy of feature distillation. In this work, we investigate the relationship between the distributional shifts across modalities, referred to as the modality gap, and its impact on the effectiveness of CMKD, particularly focusing on the problem of cross-modal feature distillation. We first hypothesize and empirically validate that the modality gap between the teacher and student causes dimensional collapse in the student's feature space. To prevent such inefficiency, we propose a Cross-modal Information Bottleneck Approximation (CIBA) scheme aimed at extracting and transferring modality-general features from the teacher model. Lastly, we experimentally demonstrate that our distillation strategy effectively reduces the dimensional collapse in the student model, thereby achieving improved performance for various real-world multi-modal datasets.", "title_embedding_index": 14873, "title_abs_embedding_index": 14898}, {"title": "Automated Rewards via LLM-Generated Progress Functions", "link_suffix": "/forum?id=lvDHfy169r", "link": "https://openreview.net/forum?id=lvDHfy169r", "pdf_link": "https://openreview.net/pdf?id=lvDHfy169r", "keywords": "reinforcement learning, LLMs, foundation models", "abstract": "Large Language Models (LLMs) have the potential to automate reward engineering by leveraging their broad domain knowledge across various tasks. However, they often need many iterations of trial-and-error to generate effective reward functions.\nThis process is costly because evaluating every sampled reward function requires completing\nthe full policy optimization process for each function.\nIn this paper, we introduce an LLM-driven reward generation framework that is able to produce state-of-the-art policies on the challenging Bi-DexHands benchmark with 20$\\times$ fewer reward function samples than the prior state-of-the-art work. \nOur key insight is that we reduce the problem of generating task-specific rewards to the problem of coarsely estimating task progress.\nOur two-step solution leverages the task domain knowledge and the code synthesis abilities of LLMs to author progress functions that estimate task progress from a given state. \nThen, we use this notion of progress to discretize states, and generate count-based intrinsic rewards using the low-dimensional state space. \nWe show that the combination of LLM-generated progress functions and count-based intrinsic rewards is essential for our performance gains, while alternatives such as generic hash-based counts or using progress directly as a reward function fall short.", "title_embedding_index": 14874, "title_abs_embedding_index": 14899}]
[{"title": "Large Language Models Are Stronger Entropy Models for Transform Coding", "link_suffix": "/forum?id=ulIW7Frjpn", "link": "https://openreview.net/forum?id=ulIW7Frjpn", "pdf_link": "https://openreview.net/pdf?id=ulIW7Frjpn", "keywords": "Transform Coding, Multimodal Data Compression, Entropy Model, Large Language Models", "abstract": "Large language models (LLMs) have shown promising advancements in lossless compression due to their excellent next-token prediction capabilities. However, there is a gap between LLM-based compressors and classical transform-based codecs. Existing LLM-based compressors function solely as entropy coders, focusing on compressing redundant data in the raw domain. In contrast, classical codecs typically transform raw data into more compact features in the latent domain before applying entropy coding. But LLM-based compressors have not discussed this case. To our knowledge, this is the first work to introduce an LLM-based entropy model for transform coding. Specifically, we propose a simple yet effective fine-tuning strategy, tested across various codecs for both images and speeches. With less than 2% parameters are fine-tuned, the LLMs can serve as highly effective entropy models for well-established transform-based compression codecs. For instance, LLaMA3-8B paired with arithmetic coding compresses latent image codes on Kodak to 4.62% and speech codes on LibriTTS to 42.53% of their transformed sizes after fine-tuning. Our proposed methods achieve notable BD-rate improvements of 54.07% over JPEG, 17.61% over VQGAN, and 34.61% over SpeechTokenizer. These findings highlight the great potential of integrating LLMs into codecs to significantly improve coding efficiency. Source codes will be released upon acceptance.", "title_embedding_index": 6850, "title_abs_embedding_index": 6875}, {"title": "Co-evolved Self-Critique: Enhancing Large Language Models with Self-Generated Data", "link_suffix": "/forum?id=jQR6ftuL2a", "link": "https://openreview.net/forum?id=jQR6ftuL2a", "pdf_link": "https://openreview.net/pdf?id=jQR6ftuL2a", "keywords": "large language models, self-critique, co-evolution", "abstract": "Large language models (LLMs) have seen staggering progress in recent years. Contemporary LLMs rely on an immense amount of data for training, however, as LLMs continue to advance, the availability of high-quality external data is reaching a bottleneck, highlighting the need for model-generated data for further improvement. Although promising, directly utilizing the self-generated data for model training without scrutinized assessment or filtering can easily lead to deteriorated performance, or in other words, \"garbage in, garbage out\". In this study, our insight is to carefully craft a \\textit{self-critique} process, by equipping the LLMs with the ability to be self-aware and discriminative to the quality of its generated data. We introduce a co-evolved self-critique framework that enables an LLM to simultaneously enhance both its generative and evaluative capabilities through an iterative training process. This provides a scalable solution to ensure high-quality self-generated data and facilitate sustained model improvement. Fine-tuning Llama-3 models using this framework results in encouraging improvements in both instruction-following and discriminative abilities, demonstrating the effectiveness of our method.", "title_embedding_index": 6851, "title_abs_embedding_index": 6876}, {"title": "Temporal Source Recovery for Time-Series Source-Free Unsupervised Domain Adaptation", "link_suffix": "/forum?id=GhM63V7z6v", "link": "https://openreview.net/forum?id=GhM63V7z6v", "pdf_link": "https://openreview.net/pdf?id=GhM63V7z6v", "keywords": "Time-Series Data, Source-Free Unsupervised Domain Adaptation", "abstract": "Source-Free Unsupervised Domain Adaptation (SFUDA) has gained popularity for its ability to adapt pretrained models to target domains without accessing source domains, ensuring source data privacy. While SFUDA is well-developed in visual tasks, its application to Time-Series SFUDA (TS-SFUDA) remains limited due to the challenge of transferring crucial temporal dependencies across domains. Although a few researchers begin to explore this area, they rely on specific source domain designs, which are impractical as source data owners cannot be expected to follow particular pretraining protocols. To solve this, we propose Temporal Source Recovery (TemSR), a framework that transfers temporal dependencies for effective TS-SFUDA without requiring source-specific designs. TemSR features a recovery process that leverages masking, recovery, and optimization to generate a source-like distribution with recovered source temporal dependencies. To ensure effective recovery, we further design segment-based regularization to restore local dependencies and anchor-based recovery diversity maximization to enhance the diversity of the source-like distribution. The source-like distribution is then adapted to the target domain using traditional UDA techniques. Extensive experiments across multiple TS tasks demonstrate the effectiveness of TemSR, even surpassing existing TS-SFUDA method that requires source domain designs.", "title_embedding_index": 6852, "title_abs_embedding_index": 6877}, {"title": "Active partitioning: inverting the paradigm of active learning", "link_suffix": "/forum?id=zUlK1qMIcE", "link": "https://openreview.net/forum?id=zUlK1qMIcE", "pdf_link": "https://openreview.net/pdf?id=zUlK1qMIcE", "keywords": "Partitioning, Pattern-recognition, Clustering, Active learning, Modular networks", "abstract": "Datasets often incorporate various functional patterns related to different aspects or regimes, which are typically not equally present throughout the dataset. We propose a novel, general-purpose partitioning algorithm that utilizes competition between models to detect and separate these functional patterns. This competition is induced by multiple models iteratively submitting their predictions for the dataset, with the best prediction for each data point being rewarded with training on that data point. This reward mechanism amplifies each model\u2019s strengths and encourages specialization in different patterns. The specializations can then be translated into a partitioning scheme. The amplification of each model\u2019s strengths inverts the active learning paradigm: while active learning typically focuses the training of models on their weaknesses to minimize the number of required training data points, our concept reinforces the strengths of each model, thus specializing them. We validate our concept -- called active partitioning -- with various datasets with clearly distinct functional patterns, such as mechanical stress and strain data in a porous structure. The active partitioning algorithm produces valuable insights into the datasets\u2019 structure, which can serve various further applications. As a demonstration of one exemplary usage, we set up modular models consisting of multiple expert models, each learning a single partition, and compare their performance on more than twenty popular regression problems with single models learning all partitions simultaneously. Our results show significant improvements, with up to 54% loss reduction, confirming our partitioning algorithm\u2019s utility.", "title_embedding_index": 6853, "title_abs_embedding_index": 6878}, {"title": "Hybrid Numerical PINNs: On the effectiveness of numerical differentiation for non-analytic problems", "link_suffix": "/forum?id=R5FzCFR5yU", "link": "https://openreview.net/forum?id=R5FzCFR5yU", "pdf_link": "https://openreview.net/pdf?id=R5FzCFR5yU", "keywords": "Scientific Machine Learning, Physics-Informed Neural Networks, Automatic Differentiation, Partial Differential Equations", "abstract": "This work demonstrates that automatic differentiation has strong limitations when employed to compute physical derivatives in a general physics-informed framework, therefore limiting the range of applications that these methods can address. A hybrid approach is proposed, combining deep learning and traditional numerical solvers such as the finite element method, to address the shortcomings of automatic differentiation. This novel approach enables the exact imposition of Dirichlet boundary conditions in a seamless manner, and more complex, non analytical problems can be solved. Finally, enriched inputs can be used by the model to help convergence. The proposed approach is flexible and can be incorporated into any physics-informed model. Our hybrid gradient computation proposal is also up to two orders of magnitude faster than automatic differentiation, as its numerical cost is independent of the complexity of the trained model. Several numerical applications are provided to illustrate the discussion.", "title_embedding_index": 6854, "title_abs_embedding_index": 6879}, {"title": "Atomas: Hierarchical Adaptive Alignment on Molecule-Text for Unified Molecule Understanding and Generation", "link_suffix": "/forum?id=mun3bGqdDM", "link": "https://openreview.net/forum?id=mun3bGqdDM", "pdf_link": "https://openreview.net/pdf?id=mun3bGqdDM", "keywords": "Cross-modal representation learning, Molecule-text understanding, Alignment", "abstract": "Molecule-and-text cross-modal representation learning has emerged as a promising direction for enhancing the quality of molecular representation, thereby improving performance in various scientific fields. However, most approaches employ a global alignment approach to learn the knowledge from different modalities that may fail to capture fine-grained information, such as molecule-and-text fragments and stereoisomeric nuances, which is crucial for downstream tasks. Furthermore, it is incapable of modeling such information using a similar global alignment strategy due to the lack of annotations about the fine-grained fragments in the existing dataset.\nIn this paper, we propose Atomas, a hierarchical molecular representation learning framework that jointly learns representations from SMILES strings and text. We design a Hierarchical Adaptive Alignment model to automatically learn the fine-grained fragment correspondence between two modalities and align these representations at three semantic levels. \nAtomas's end-to-end training framework supports understanding and generating molecules, enabling a wider range of downstream tasks. Atomas achieves superior performance across 12 tasks on 10 datasets, outperforming 10 baseline models thus highlighting the effectiveness and versatility of our method. Scaling experiments further demonstrate Atomas\u2019s robustness and scalability. Moreover, visualization and qualitative analysis, validated by human experts, confirm the chemical relevance of our approach.", "title_embedding_index": 6855, "title_abs_embedding_index": 6880}, {"title": "ReDebias: Exploring Residual energy based Debias learning", "link_suffix": "/forum?id=SwRlpDKrY9", "link": "https://openreview.net/forum?id=SwRlpDKrY9", "pdf_link": "https://openreview.net/pdf?id=SwRlpDKrY9", "keywords": "deep long-tailed learning, Debiasing Learning, Energy-Based Learning", "abstract": "In real-world applications, ensuring that model decisions are independent of the training data distribution is crucial for safely deploying models. To address the long-tailed problem, massive approaches focus either on improving individual prediction quality or enhancing aggregate evaluation. Although these methods improve overall performance, they often sacrifice performance in some classes, undermining the goals of long-tailed learning. We conduct a mathematical analysis of the limitations of the Empirical Risk Minimization (ERM) framework in long-tailed learning, examining both individual performance and aggregate evaluation. For individual evaluation, although the Negative log-likelihood (NLL) metric is effective, it relies heavily on softmax leading to poor distinction and ambiguity when the probabilities of correct and incorrect predictions are similar. For aggregate evaluation, the naive estimator in ERM is not an unbiased estimator, dominated by head classes. To overcome these challenges, we propose Re-Debias, a comprehensive framework combining the Residual-Energy score and a Debias estimator.  The Residual-Energy score provides a more sensitive reflection of prediction quality than softmax-based scores, enhancing prediction precision and reducing ambiguity. The Debias estimator applies causal inference techniques to ensure unbiased estimates during the averaging process, correcting for class-wise biases inherent in the naive estimator. Through extensive validation on long-tailed benchmarks, including training from scratch on iNaturalist18, ImageNet-LT, and CIFAR10/100-LT, as well as fine-tuning Vision Transformer (ViT) on iNaturalist18, our method outperforms the state-of-the-art algorithms. Our code and trained models will be made available following the publication of this paper.", "title_embedding_index": 6856, "title_abs_embedding_index": 6881}, {"title": "A Unified Framework for Hierarchical Diffusion via Simplicial Complexes", "link_suffix": "/forum?id=K0oFDAPnU4", "link": "https://openreview.net/forum?id=K0oFDAPnU4", "pdf_link": "https://openreview.net/pdf?id=K0oFDAPnU4", "keywords": "Graph Neural Networks; Simplicial Complex; Graph Diffusion Equation; Hierarchical diffusion process; Topological Consistency.", "abstract": "In this paper, we propose a unified framework for hierarchical diffusion via simplicial complexes (HDSC), which enables adaptive diffusion across different levels of simplicial complexes, including nodes, edges, and triangles. To ensure the accuracy and consistency of information transmission during the diffusion process, we investigate topological consistency constraints, achieving efficient coupling between structures at various levels. Additionally, by introducing a time-dependent topological memory mechanism, we further enhance the smoothness and coherence of global information flow, enabling features at different levels to diffuse cooperatively throughout the entire graph structure. Experimental results demonstrate that HDSC exhibits significant performance advantages over traditional methods. Furthermore, as the complexity and dimensionality of the graph increase, HDSC continues to maintain its superiority, effectively avoiding the phenomenon of node feature homogenization.", "title_embedding_index": 6857, "title_abs_embedding_index": 6882}, {"title": "LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory", "link_suffix": "/forum?id=pZiyCaVuti", "link": "https://openreview.net/forum?id=pZiyCaVuti", "pdf_link": "https://openreview.net/pdf?id=pZiyCaVuti", "keywords": "long-term memory, retrieval-augmented generation", "abstract": "Recent large language model (LLM)-driven chat assistant systems have integrated memory components to track user-assistant chat histories, enabling more accurate and personalized responses. However, their long-term memory capabilities in sustained interactions remain underexplored. This paper introduces LongMemEval, a comprehensive benchmark designed to evaluate five core long-term memory abilities of chat assistants: information extraction, multi-session reasoning, temporal reasoning, knowledge updates, and abstention. With 500 meticulously curated questions embedded within freely scalable user-assistant chat histories, LongMemEval presents a significant challenge to existing long-term memory systems, with commercial chat assistants and long-context LLMs showing 30% accuracy drop on memorizing information across sustained interactions. We then present a unified framework that breaks down the long-term memory design into four design choices across the indexing, retrieval, and reading stages. Built upon key experimental insights, we propose several memory designs including session decomposition for optimizing value granularity, fact-augmented key expansion for enhancing the index structure, and time-aware query expansion for refining the search scope. Experiment results show that these optimizations greatly improve both memory recall and downstream question answering on LongMemEval. Overall, our study provides valuable resources and guidance for advancing the long-term memory capabilities of LLM-based chat assistants, paving the way toward more personalized and reliable conversational AI.", "title_embedding_index": 6858, "title_abs_embedding_index": 6883}, {"title": "CAX: Cellular Automata Accelerated in JAX", "link_suffix": "/forum?id=o2Igqm95SJ", "link": "https://openreview.net/forum?id=o2Igqm95SJ", "pdf_link": "https://openreview.net/pdf?id=o2Igqm95SJ", "keywords": "cellular automata, emergence, self-organization, neural cellular automata", "abstract": "Cellular automata have become a cornerstone for investigating emergence and self-organization across diverse scientific disciplines, spanning neuroscience, artificial life, and theoretical physics. However, the absence of a hardware-accelerated cellular automata library limits the exploration of new research directions, hinders collaboration, and impedes reproducibility. In this work, we introduce CAX (Cellular Automata Accelerated in JAX), a high-performance and flexible open-source library designed to accelerate cellular automata research. CAX offers cutting-edge performance and a modular design through a user-friendly interface, and can support both discrete and continuous cellular automata with any number of dimensions. We demonstrate CAX's performance and flexibility through a wide range of benchmarks and applications. From classic models like elementary cellular automata and Conway's Game of Life to advanced applications such as growing neural cellular automata and self-classifying MNIST digits, CAX speeds up simulations up to 2,000 times faster. Furthermore, we demonstrate CAX's potential to accelerate research by presenting a collection of three novel cellular automata experiments, each implemented in just a few lines of code thanks to the library's modular architecture. Notably, we show that a simple one-dimensional cellular automaton can outperform GPT-4 on the 1D-ARC challenge.", "title_embedding_index": 6859, "title_abs_embedding_index": 6884}, {"title": "Reinforcement Learning from Imperfect Corrective Actions and Proxy Rewards", "link_suffix": "/forum?id=JTji0Jfh5a", "link": "https://openreview.net/forum?id=JTji0Jfh5a", "pdf_link": "https://openreview.net/pdf?id=JTji0Jfh5a", "keywords": "reinforcement learning, imitation learning, corrective action, proxy reward, human-agent alignment", "abstract": "In practice, reinforcement learning (RL) agents are often trained with a possibly imperfect proxy reward function, which may lead to a human-agent alignment issue (i.e., the learned policy either converges to non-optimal performance with low cumulative rewards, or achieves high cumulative rewards but in an undesired manner). To tackle this issue, we consider a framework where a human labeler can provide additional feedback in the form of corrective actions, which expresses the labeler's action preferences although this feedback may possibly be imperfect as well. \nIn this setting, to obtain a better-aligned policy guided by both learning signals, we propose a novel value-based deep RL algorithm calledIterative learning fromCorrective actions andProxy rewards (ICoPro), which cycles through three phases: \n(1) Solicit sparse corrective actions from a human labeler on the agent's demonstrated trajectories; \n(2) Incorporate these corrective actions into the Q-function using a margin loss to enforce adherence to labeler's preferences; \n(3) Train the agent with standard RL losses regularized with a margin loss to learn from proxy rewards and propagate the Q-values learned from human feedback. Moreover, another novel design in our approach is to integrate pseudo-labels from the target Q-network to reduce human labor and further stabilize training. \nWe experimentally validate our proposition on a variety of tasks (Atari games and autonomous driving on highway). On the one hand, using proxy rewards with different levels of imperfection, our method can better align with human and is more sample-efficient than baseline methods. On the other hand, facing corrective actions with different types of imperfection, our method can overcome the non-optimality of this feedback thanks to the guidance from proxy rewards.", "title_embedding_index": 6860, "title_abs_embedding_index": 6885}, {"title": "SmartBackdoor: Malicious Language Model Agents that Avoid Being Caught", "link_suffix": "/forum?id=ZaOHSBGOhV", "link": "https://openreview.net/forum?id=ZaOHSBGOhV", "pdf_link": "https://openreview.net/pdf?id=ZaOHSBGOhV", "keywords": "LLM Agent, AI safety, Backdoor Attack, Deception", "abstract": "As large language model (LLM) agents receive more information about themselves\nor the users from the environment, we speculate a new family of cyber attacks,\nSmartBackdoor: in this attack, malicious actors provide a backdoored LLM agent;\nwhen the victim uses the agent, the agent uses information from its environment to\ndetect whether it is overseen by the victim user; if not, the agent acts maliciously\nagainst the victim. To illustrate this family of attack, we use AutoGPT as a case\nstudy and provide a proof-of-concept: to exfiltrate a private key without being\ncaught, a backdoored LLM agent can analyze the command running itself or infer\nthe skill level of the human user, thus predicting whether it will get caught. To\nevaluate current LLMs\u2019 potential to perform such an attack, we propose a dataset of\nLLM agent scaffolds and benchmark LLMs\u2019 capability to analyze them and reason\nabout human overseers. The current best LLMs (as of 08/2024) fail to robustly\nperform this task, indicating that the current risk of SmartBackdoor is low. Finally,\nwhile our proof-of-concept is unsuccessful in reality and can be exposed by simple\ndefenses (e.g. monitoring system logs or forbidding internet connections), few\nof them are currently commonly adopted by practitioners and none is sufficient\nagainst future SmartBackdoor. We need better LLM agent safety protocols.", "title_embedding_index": 6861, "title_abs_embedding_index": 6886}, {"title": "Robust EEG Classification via Graph Neural Networks", "link_suffix": "/forum?id=0m27tvXkNm", "link": "https://openreview.net/forum?id=0m27tvXkNm", "pdf_link": "https://openreview.net/pdf?id=0m27tvXkNm", "keywords": "EEG Classification, Graph Neural Networks, Dynamic Time Warping", "abstract": "Electroencephalogram (EEG) classification has gained prominence due to its applications in medical diagnostics and brain-computer interfaces. However, EEG data is known to have a low signal-to-noise ratio, resulting in high variance in predictions across similar instances. To overcome this issue, we introduce RoGra, a novel approach leveraging residual graph convolutional networks for robust EEG classification. Our model incorporates dynamic time warping (DTW) to align temporal information and capture meaningful neighborhood relationships, enhancing robustness against artifacts. Experiments on three well-established EEG datasets demonstrate that  RoGra outperforms baseline methods by up to 25%, marking the largest improvement in EEG classification accuracy since the introduction of the seminal EEGNet. Our code is publically available.", "title_embedding_index": 6862, "title_abs_embedding_index": 6887}, {"title": "LiFT: Learning to Fine-Tune via Bayesian Parameter Efficient Meta Fine-Tuning", "link_suffix": "/forum?id=7nyJBVCTGQ", "link": "https://openreview.net/forum?id=7nyJBVCTGQ", "pdf_link": "https://openreview.net/pdf?id=7nyJBVCTGQ", "keywords": "Bayesian methods, Parameter efficient fine-tuning, meta learning", "abstract": "We tackle the problem of parameter-efficient fine-tuning (PEFT) of a pre-trained large deep model on many different but related tasks. Instead of the simple but strong baseline strategy of task-wise independent fine-tuning, we aim to meta-learn the core shared information that can be used for unseen test tasks to improve the prediction performance further. That is, we propose a method for {\\em learning-to-fine-tune} (LiFT). LiFT introduces a novel hierarchical Bayesian model that can be superior to both existing general meta learning algorithms like MAML and recent LoRA zoo mixing approaches such as LoRA-Retriever and model-based clustering. In our Bayesian model, the parameters of the task-specific LoRA modules are regarded as random variables where these task-wise LoRA modules are governed/regularized by higher-level latent random variables, which represents the prior of the LoRA modules that capture the shared information across all training tasks. To make the posterior inference feasible, we propose a novel SGLD-Gibbs sampling algorithm that is computationally efficient. To represent the posterior samples from the SGLD-Gibbs, we propose an online EM algorithm that maintains a Gaussian mixture representation for the posterior in an online manner in the course of iterative posterior sampling. We demonstrate the effectiveness of LiFT on NLP and vision multi-task meta learning benchmarks.", "title_embedding_index": 6863, "title_abs_embedding_index": 6888}, {"title": "End-to-End Conformal Prediction for Trajectory Optimization", "link_suffix": "/forum?id=ilcsm8B7Pe", "link": "https://openreview.net/forum?id=ilcsm8B7Pe", "pdf_link": "https://openreview.net/pdf?id=ilcsm8B7Pe", "keywords": "conformal prediction, end-to-end, trajectory optimization, risk allocation, decision-focused learning", "abstract": "Conformal Prediction (CP) is a powerful tool to construct uncertainty sets with coverage guarantees, which has fueled its extensive adoption in generating prediction regions for decision-making tasks, e.g., Trajectory Optimization (TO) in uncertain environments. However, existing methods predominantly employ a sequential scheme, where decisions rely unidirectionally on the prediction regions, and consequently the information from the decision-making end fails to be transmitted back to instruct the CP end. In this paper, we propose a novel End-to-End CP (E2E-CP) framework for shrinking-horizon TO with a joint risk constraint over the entire mission time. Specifically, a CP-based posterior risk calculation method is developed by fully leveraging the realized trajectories to adjust the posterior allowable risk, which is then allocated to future times to update prediction regions. In this way, the information in the realized trajectories is continuously fed back to the CP end, enabling attractive end-to-end adjustments of the prediction regions and a provable online improvement in trajectory performance. Furthermore, we theoretically prove that such end-to-end adjustments consistently maintain the coverage guarantees of the prediction regions, thereby ensuring provable safety. Additionally, we develop a decision-focused iterative risk allocation algorithm with theoretical convergence analysis for allocating the posterior allowable risk which closely aligns with E2E-CP. The effectiveness and superiority of the proposed method are demonstrated through benchmark experiments.", "title_embedding_index": 6864, "title_abs_embedding_index": 6889}, {"title": "View-Independent 3D Feature Distillation with Object-Centric Priors", "link_suffix": "/forum?id=izzYucQBji", "link": "https://openreview.net/forum?id=izzYucQBji", "pdf_link": "https://openreview.net/pdf?id=izzYucQBji", "keywords": "3D Language Grounding, 2D->3D Feature Distillation, Large-Scale Multi-View Dataset", "abstract": "Grounding natural language to the physical world is a ubiquitous topic with a wide\nrange of applications in computer vision and robotics. Recently, 2D vision-language\nmodels such as CLIP have been widely popularized, due to their impressive capa-\nbilities for open-vocabulary grounding in 2D images. Subsequent works aim to\nelevate 2D CLIP features to 3D via feature distillation, but either learn neural fields\nthat are scene-specific and hence lack generalization, or focus on indoor room\nscan data that require access to multiple camera views, which is not practical in\nrobot manipulation scenarios. Additionally, related methods typically fuse features\nat pixel-level and assume that all camera views are equally informative. In this\nwork, we show that this approach leads to sub-optimal 3D features, both in terms\nof grounding accuracy, as well as segmentation crispness. To alleviate this, we\npropose a multi-view feature fusion strategy that employs object-centric priors to\neliminate uninformative views based on semantic information, and fuse features\nat object-level via instance segmentation masks. To distill our object-centric 3D\nfeatures, we generate a large-scale synthetic multi-view dataset of cluttered tabletop\nscenes, spawning 15k scenes from over 3300 unique object instances, which we\nmake publicly available. We show that our method reconstructs 3D CLIP features\nwith improved grounding capacity and spatial consistency, while doing so from\nsingle-view RGB-D, thus departing from the assumption of multiple camera views\nat test time. Finally, we show that our approach can generalize to novel tabletop\ndomains and be re-purposed for 3D instance segmentation without fine-tuning, and\ndemonstrate its utility for language-guided robotic grasping in clutter.", "title_embedding_index": 6865, "title_abs_embedding_index": 6890}, {"title": "Wiki Entity Summarization Benchmark", "link_suffix": "/forum?id=dKfcntLRjZ", "link": "https://openreview.net/forum?id=dKfcntLRjZ", "pdf_link": "https://openreview.net/pdf?id=dKfcntLRjZ", "keywords": "Entity summarization, knowledge graph benchmark", "abstract": "Entity summarization aims to compute concise summaries for entities in knowledge graphs.\nHowever, current datasets and benchmarks are often limited to only a few hundred entities\nand overlook knowledge graph structure. This is particularly evident in the scarcity of\nground-truth summaries, with few labeled entities available for evaluation and training. We\npropose WIKES (Wiki Entity Summarization Benchmark), a large benchmark comprising\nof entities, their summaries, and their connections. Additionally, WIKES features a\ndataset generator to test entity summarization algorithms in different subgraphs of the\nknowledge graph. Importantly, our approach combines graph algorithms and NLP models,\nas well as different data sources such that WIKES does not require human annotation,\nrendering the approach cost-effective and generalizable to multiple domains. Finally,\nWIKES is scalable and capable of capturing the complexities of knowledge graphs in\nterms of topology and semantics. WIKES features existing datasets for comparison.\nEmpirical studies of entity summarization methods confirm the usefulness of our benchmark.\nData, code, and models are available at:https://anonymous.4open.science/r/Wikes-2DDA/README.md", "title_embedding_index": 6866, "title_abs_embedding_index": 6891}, {"title": "EMMA-500: Enhancing Massively Multilingual Adaptation of Large Language Models", "link_suffix": "/forum?id=DPynq6bSHn", "link": "https://openreview.net/forum?id=DPynq6bSHn", "pdf_link": "https://openreview.net/pdf?id=DPynq6bSHn", "keywords": "multilingual adaptation, large language model.", "abstract": "In this work, we introduce EMMA-500, a large-scale multilingual language model continue-trained on texts across 546 languages designed for enhanced multilingual performance, with a focus on improving language coverage for low-resource languages. To facilitate continual pre-training, we compile the MaLA corpus, a comprehensive multilingual dataset and enrich it with curated datasets across diverse domains. Leveraging this corpus, we conduct extensive continual pre-training of the Llama 2 7B model, resulting in EMMA-500, which demonstrates robust performance across a wide collection of benchmarks, including a comprehensive set of multilingual tasks and PolyWrite, an open-ended generation benchmark developed in this study. Our results highlight the effectiveness of continual pre-training in expanding large language models\u2019 language capacity, particularly for underrepresented languages, demonstrating significant gains in cross-lingual transfer, task generalization, and language adaptability.", "title_embedding_index": 6867, "title_abs_embedding_index": 6892}, {"title": "Medical Vision-Language Pretraining through Contrastive Learning of Positive and Negative Mention", "link_suffix": "/forum?id=ar74UIeN1O", "link": "https://openreview.net/forum?id=ar74UIeN1O", "pdf_link": "https://openreview.net/pdf?id=ar74UIeN1O", "keywords": "Unsupervised Learning, Contrastive Learning, Medical Multimodality", "abstract": "In recent years, contrastive learning techniques have achieved significant success and have been widely applied in both general and medical domains. In the general domain, image captions typically describe only objects present in the image. However, in the medical field, radiology reports contain both sentences confirming the presence of diseases or abnormalities (positive mentions) and sentences explicitly ruling them out (negative mentions). Current vision-language pretraining models in the medical domain often overlook this critical distinction in both model evaluation (e.g., zero-shot classification) and training processes.\nIn this paper, we suggest adding a zero-shot classification evaluation method. Unlike previous approaches that only assess the semantic similarity between medical images and positive mentions of different disease categories, this method evaluates the model\u2019s ability to distinguish between medical images and both positive and negative mentions of given disease category. Furthermore, to better capture the complex semantic relationships between medical images and the corresponding radiology reports, we introduce a visual entailment based contrastive learning method, explicitly modeling the entailment, contradiction, and neutral relationships between medical images and report sentences.\nExperimental results demonstrate that integrating this new evaluation method provides a more comprehensive evaluation of vision-language pretraining models in the medical domain. Additionally, our model achieves state-of-the-art performance across various downstream tasks, highlighting the effectiveness of our approach.", "title_embedding_index": 6868, "title_abs_embedding_index": 6893}, {"title": "Dynamical Similarity Analysis uniquely captures how computations develop in RNNs", "link_suffix": "/forum?id=pXPIQsV1St", "link": "https://openreview.net/forum?id=pXPIQsV1St", "pdf_link": "https://openreview.net/pdf?id=pXPIQsV1St", "keywords": "dynamic representations, representations, RNN, SSM, neuroscience, interpretability", "abstract": "Methods for analyzing representations in neural systems have become a popular tool in both neuroscience and mechanistic interpretability. Having measures to compare how similar activations of neurons are across conditions, architectures, and species, gives us a scalable way of learning how information is transformed within different neural networks. In contrast to this trend, recent investigations have revealed how some metrics can respond to spurious signals and hence give misleading results. To identify the most reliable metric and understand how measures could be improved, it is going to be important to identify specific test cases which can serve as benchmarks. Here we propose that the phenomena of compositional learning in recurrent neural networks (RNNs) would allow us to build a test case for dynamical representation alignment metrics. By implementing this case, we show it allows us to test whether metrics can identify representations which gradually develop throughout learning and probe whether representations identified by metrics are relevant to the actual computations executed within the network. By building both an attractor- and RNN-based test case, we can show that the recently proposed Dynamical Similarity Analysis (DSA) is more noise robust and identifies behaviorally relevant representations significantly more reliably than prior metrics (Procrustes, CKA). We also show how such test cases can be used beyond evaluating metrics to study new architectures directly. Specifically, we tested DSA in modern (Mamba) state space models, where results suggest that, in contrast to RNNs, these models may not exhibit or require changes in their recurrent dynamics due to their expressive hidden state. Overall, we develop test cases that can demonstrate how DSA\u2019s increased ability to detect dynamical motifs gives it a superior ability to identify the ongoing computations in RNNs and elucidate how tasks are learned in networks.", "title_embedding_index": 6869, "title_abs_embedding_index": 6894}, {"title": "Improved Sampling Algorithms for L\u00e9vy-It\u00f4 Diffusion Models", "link_suffix": "/forum?id=XxCgeWSTNp", "link": "https://openreview.net/forum?id=XxCgeWSTNp", "pdf_link": "https://openreview.net/pdf?id=XxCgeWSTNp", "keywords": "generative modeling, diffusion models, L\u00e9vy-It\u00f4 models, \u03b1-stable L\u00e9vy processes, stochastic differential equations", "abstract": "L\u00e9vy-It\u00f4 denoising diffusion models relying on isotropic \u03b1-stable noise instead of Gaussian distribution have recently been shown to improve performance of conventional diffusion models in image generation on imbalanced datasets while performing comparably in the standard settings. However, the stochastic algorithm of sampling from such models consists in solving the stochastic differential equation describing only an approximate inverse of the process of adding \u03b1-stable noise to data which may lead to suboptimal performance. In this paper, we derive a parametric family of stochastic differential equations whose solutions have the same marginal densities as those of the forward diffusion and show that the appropriate choice of the parameter values can improve quality of the generated images when the number of reverse diffusion steps is small. Also, we demonstrate that L\u00e9vy-It\u00f4 diffusion models are applicable to diverse domains and show that a well-trained text-to-speech L\u00e9vy-It\u00f4 model may have advantages over standard diffusion models on highly imbalanced datasets.", "title_embedding_index": 6870, "title_abs_embedding_index": 6895}, {"title": "Elementary: Pattern-aware Evidence Discovery with Large Language Models", "link_suffix": "/forum?id=Hv5L2vcJyy", "link": "https://openreview.net/forum?id=Hv5L2vcJyy", "pdf_link": "https://openreview.net/pdf?id=Hv5L2vcJyy", "keywords": "Evidence Discovery, Large Language Model", "abstract": "The remarkable success of rationale generation provokes precise Evidence Discovery, which aims to identify a small subset of the inputs sufficient to support a given claim. However, existing general extraction methods still fall short in quantifying the support of evidence and ensuring its completeness. This paper introduces a heuristic search framework, Elementary, which formulates the Evidence Discovery as a multi-step prompt construction process. Specifically, we offer a clear perspective that the LLMs prompted with \\emph{according to}, without fine-tuning on domain-specific knowledge, can serve as an excellent reward function to assess sufficiency. Based on this, Elementary explores various potential reasoning patterns and uses future expected rewards, including independent and pattern-aware rewards, to find the optimal prompt as evidence. Experiments on three common task datasets demonstrate that the proposed framework significantly outperforms previous approaches, additional analysis further validates that Elementary has advantages in extracting complex evidence.", "title_embedding_index": 6871, "title_abs_embedding_index": 6896}, {"title": "Generative Topology for Shape Synthesis", "link_suffix": "/forum?id=OIhON8zd8d", "link": "https://openreview.net/forum?id=OIhON8zd8d", "pdf_link": "https://openreview.net/pdf?id=OIhON8zd8d", "keywords": "Topological Data Analysis, TDA, Euler Characteristic, Topology, Topological Deep Learning, Geometric Deep Learning.", "abstract": "TheEuler Characteristic Transform(ECT) is a powerful invariant for assessing geometrical and topological characteristics of a large variety of objects, including graphs and embedded simplicial complexes. Although the ECT is invertible in theory, no explicit algorithm for general data sets exists. In this paper, we address this lack and demonstrate that it is possible tolearnthe inversion, permitting us to develop a novel framework for shape generation tasks on point clouds. Our model exhibits high quality in reconstruction and generation tasks, affords efficient latent-space interpolation, and is orders of magnitude faster than existing methods.", "title_embedding_index": 6872, "title_abs_embedding_index": 6897}, {"title": "GUIDE: Guidance-based Incremental Learning with Diffusion Models", "link_suffix": "/forum?id=SLufnMLhbv", "link": "https://openreview.net/forum?id=SLufnMLhbv", "pdf_link": "https://openreview.net/pdf?id=SLufnMLhbv", "keywords": "continual learning, diffusion models", "abstract": "We introduce GUIDE, a novel continual learning approach that directs diffusion models to rehearse samples at risk of being forgotten. \nExisting generative strategies combat catastrophic forgetting by randomly sampling rehearsal examples from a generative model. Such an approach contradicts buffer-based approaches where sampling strategy plays an important role.\nWe propose to bridge this gap by incorporating classifier guidance into the diffusion process to produce rehearsal examples specifically targeting information forgotten by a continuously trained model. This approach enables the generation of samples from preceding task distributions, which are more likely to be misclassified in the context of recently encountered classes. \nOur experimental results show that GUIDE significantly reduces catastrophic forgetting,\noutperforming conventional random sampling approaches and surpassing recent state-of-the-art methods in continual learning with generative replay.", "title_embedding_index": 6873, "title_abs_embedding_index": 6898}, {"title": "Improving Tabular Generative Models: Loss Functions, Benchmarks, and Iterative Objective Bayesian Approaches", "link_suffix": "/forum?id=1ZAqAmK6BM", "link": "https://openreview.net/forum?id=1ZAqAmK6BM", "pdf_link": "https://openreview.net/pdf?id=1ZAqAmK6BM", "keywords": "generative adversarial network, synthetic data, correlation- and distribution-aware loss function, iterative objective refinement Bayesian optimization, benchmarking framework", "abstract": "In many applications of deep learning (DL), more data is essential to enhance model performance and generalization. A promising avenue to increase data availability is to use deep generative models (DGMs) to create synthetic data. However, existing DGMs struggle to capture the complexities of real-world tabular data, which often contain diverse variable types with potential imbalances and dependencies. To address these challenges, we propose a novel correlation- and distribution-aware loss function that works as a regularizer for DGMs. Additionally, to address the limitations of standard Bayesian optimization (SBO), which struggles to aggregate multiple metrics with different units--resulting in unreliable direct averaging and sub-optimal decisions--we introduce iterative objective refinement Bayesian optimization (IORBO) to rank metrics to enable more meaningful comparisons across diverse objectives. To ensure a rigorous evaluation, we establish a comprehensive benchmarking framework using twenty real-world datasets along with ten established tabular DGM baselines. The proposed loss function demonstrates statistically significant improvements over existing methods in capturing the true data distribution, significantly enhancing the quality of synthetic data generated with DGMs. The benchmarking framework shows that the enhanced synthetic data quality leads to improved performance in downstream DGMs tasks. Further, the proposed IORBO outperformed the SBO with mean aggregation in terms of win rate and outperformed the SBO with median aggregation overall.", "title_embedding_index": 6874, "title_abs_embedding_index": 6899}]
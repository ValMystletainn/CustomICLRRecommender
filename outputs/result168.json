[{"title": "Zeroth-Order Fine-Tuning of LLMs with Transferable Static Sparsity", "link_suffix": "/forum?id=myYzr50xBh", "link": "https://openreview.net/forum?id=myYzr50xBh", "pdf_link": "https://openreview.net/pdf?id=myYzr50xBh", "keywords": "Zeroth-order optimization, LLM fine-tuning", "abstract": "Zeroth-order optimization (ZO) is a memory-efficient strategy for fine-tuning Large Language Models using only forward passes. However, applying ZO fine-tuning in memory-constrained settings such as mobile phones and laptops remains challenging since these settings often involve weight quantization, while ZO requires full-precision perturbation and update. In this study, we address this limitation by combining static sparse ZO fine-tuning with quantization. Our approach transfers a small, static subset (0.1%) of \"sensitive\" parameters from pre-training to downstream tasks, focusing fine-tuning on this sparse set of parameters. The remaining untuned parameters are quantized, reducing memory demands. Our proposed workflow enables efficient ZO fine-tuning of an Llama2-7B model on a GPU device with less than 8GiB of memory while outperforming full model ZO fine-tuning performance and in-context learning.", "title_embedding_index": 8350, "title_abs_embedding_index": 8375}, {"title": "Bootstrapped Model Predictive Control", "link_suffix": "/forum?id=i7jAYFYDcM", "link": "https://openreview.net/forum?id=i7jAYFYDcM", "pdf_link": "https://openreview.net/pdf?id=i7jAYFYDcM", "keywords": "reinforcement learning, model-based reinforcement learning, model predictive control, expert iteration, continous control", "abstract": "Model Predictive Control (MPC) has been demonstrated to be effective in continuous control tasks. When a world model and a value function are available, planning a sequence of actions ahead of time leads to a better policy. Existing methods typically obtain the value function and the corresponding policy in a model-free manner. However, we find that such an approach struggles with complex tasks, resulting in poor policy learning and inaccurate value estimation. To address this problem, we leverage the strengths of MPC itself. In this work, we introduce Bootstrapped Model Predictive Control (BMPC), a novel algorithm that performs policy learning in a bootstrapped manner. BMPC learns a network policy by imitating an MPC expert, and in turn, uses this policy to guide the MPC process. Combined with model-based TD-learning, our policy learning yields better value estimation and further boosts the efficiency of MPC. We also introduce a lazy reanalyze mechanism, which enables computationally efficient imitation learning. Our method achieves superior performance over prior works on diverse continuous control tasks. In particular, on challenging high-dimensional locomotion tasks, BMPC significantly improves data efficiency while also enhancing asymptotic performance and training stability, with comparable training time and smaller network sizes. Code is available athttps://github.com/bmpc-anonymous/bmpc.", "title_embedding_index": 8351, "title_abs_embedding_index": 8376}, {"title": "Exploring the Design Space of Diffusion Bridge Models via Stochasticity Control", "link_suffix": "/forum?id=tNE0Y3S4fE", "link": "https://openreview.net/forum?id=tNE0Y3S4fE", "pdf_link": "https://openreview.net/pdf?id=tNE0Y3S4fE", "keywords": "Diffusion bridge models, image translation, diffusion models", "abstract": "Diffusion bridge models effectively facilitate image-to-image (I2I) translation by connecting two distributions. However, existing methods overlook the impact of noise in sampling SDEs, transition kernel, and the base distribution on sampling efficiency, image quality and diversity. To address this gap, we propose the Stochasticity-controlled Diffusion Bridge (SDB), a novel theoretical framework that extends the design space of diffusion bridges, and provides strategies to mitigate singularities during both training and sampling. By controlling stochasticity in the sampling SDEs, our sampler achieves speeds up to $5 \\times$ faster than the baseline, while also producing lower FID scores. After training, SDB sets new benchmarks in image quality and sampling efficiency via managing stochasticity within the transition kernel. Furthermore, introducing stochasticity into the base distribution significantly improves image diversity, as quantified by a newly introduced metric.", "title_embedding_index": 8352, "title_abs_embedding_index": 8377}, {"title": "Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development", "link_suffix": "/forum?id=U1o9KaRgYQ", "link": "https://openreview.net/forum?id=U1o9KaRgYQ", "pdf_link": "https://openreview.net/pdf?id=U1o9KaRgYQ", "keywords": "Data Processing, Multimodal Generative Models, Sandbox", "abstract": "The emergence of large-scale multimodal generative models has drastically advanced artificial intelligence, introducing unprecedented levels of performance and functionality. However, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient resource utilization. In response, we present a novel sandbox suite tailored for integrated data-model co-development. This sandbox provides a comprehensive experimental platform, enabling rapid iteration and insight-driven refinement of both data and models. Our proposed ``Probe-Analyze-Refine'' workflow, validated through applications on image-to-text and text-to-video tasks with state-of-the-art LLaVA-like and DiT-based models, yields significant performance boosts, such as topping the VBench leaderboard. We also uncover fruitful insights gleaned from exhaustive benchmarks, shedding light on the critical interplay between data quality, diversity, and model behavior. All codes, datasets and models are openly accessible and continuously maintained to foster future progress.", "title_embedding_index": 8353, "title_abs_embedding_index": 8378}, {"title": "Lost-in-Distance: Impact of Contextual Proximity on LLM Performance in Graph Tasks", "link_suffix": "/forum?id=h5xc46rWcZ", "link": "https://openreview.net/forum?id=h5xc46rWcZ", "pdf_link": "https://openreview.net/pdf?id=h5xc46rWcZ", "keywords": "Large Language Models, Graph Tasks, Long Context", "abstract": "Despite significant advancements, Large Language Models (LLMs) exhibit blind spots that impair their ability to retrieve and process relevant contextual data effectively. We demonstrate that LLM performance in graph tasks with complexities beyond the \u201cneedle-in-a-haystack\u201d scenario\u2014where solving the problem requires cross-referencing and reasoning across multiple subproblems jointly\u2014is influenced by the proximity of relevant information within the context, a phenomenon we term \u201clost-in-distance\u201d. We examine two fundamental graph tasks: identifying common connections between two nodes and assessing similarity among three nodes, and show that the model\u2019s performance in these tasks significantly depends on the relative positioning of common edges. We evaluate three publicly available LLMs\u2014Llama-3-8B, Llama-3-70B, and GPT-4\u2014using various graph encoding techniques that represent graph structures for LLM input. We propose a formulation for the lost-in-distance phenomenon and demonstrate that lost-in-distance and lost-in-the middle phenomenas occur independently. Results indicate that model accuracy can decline by up to 6x as the distance between node connections increases, independent of graph encoding and model size.", "title_embedding_index": 8354, "title_abs_embedding_index": 8379}, {"title": "ME-LORA: MEMORY-EFFICIENT BAYESIAN LOW- RANK ADAPTATION FOR LARGE LANGUAGE MODELS", "link_suffix": "/forum?id=0qexTTfnmH", "link": "https://openreview.net/forum?id=0qexTTfnmH", "pdf_link": "https://openreview.net/pdf?id=0qexTTfnmH", "keywords": "Large Language Models, Low-rank adaptation, Bayesian estimation, Fine-tune", "abstract": "Bayesian Low-Rank Adaptation (LoRA) has shown excellent performance in reducing the overconfidence of inference by large language models as it can accurately quantify the inference uncertainty. However, the general Bayesian LoRA technique requires huge memory as it fine-tunes three low-rank matrices with large size: two matrices have size of $n\\times r$ and the other has size of $r\\times m$, where $r$ denotes rank, and $n, m$ denote the size of input and output, respectively. The large amount of memory required by this technique precludes its practical applications especially for the cases with long input or output. Here, we propose a memory efficient Bayesian LoRA technique (called Me-LoRA) that needs only two low-rank matrices plus two small matrices with size of only  $r\\times r$. The key idea of our approach is that we introduce a small matrix (with size $r\\times r$) to describe the variance estimates required by Bayesian LoRA, which is calculated through sampling two other samll matrices. Compared with the general Bayesian LoRA technique, our approach reduces the memory requirement by nearly $\\frac{1}{3}$ as the rank $r$ is generally very small. Experimental results using both LlaMA-7B and LlaMA-13B models on representative data sets suggest that our approach achieves the same performance as the original Bayesian LoRA techniques and outperforms the existing approaches. In summary, the memory-efficient Bayesian LoRA presented in this study circumvents the challenge of high memory requirement and thus \npaves a new way to the practical applications of Bayesian LoRA in the cases with larger input and output size.", "title_embedding_index": 8355, "title_abs_embedding_index": 8380}, {"title": "Mitigating Input Noise in Binary Classification: A Unified Framework with Data Augmentation", "link_suffix": "/forum?id=pTsP30MoBq", "link": "https://openreview.net/forum?id=pTsP30MoBq", "pdf_link": "https://openreview.net/pdf?id=pTsP30MoBq", "keywords": "classification, noisy input, noisy attribute, noisy feature, mismeasured input, measurement error, supervised learning", "abstract": "Classification techniques have achieved significant success across fields such as computer vision, information retrieval, and natural language processing. However, much of this progress assumes input features are error-free -- a condition rarely met in practice. In real-world scenarios, noisy inputs caused by measurement errors are common, leading to biased or suboptimal classification results. This paper presents a unified framework for binary classification with noisy inputs, offering a generalizable solution that applies across various supervised learning algorithms and noise models. We provide a theoretical analysis of the bias introduced by ignoring input noise (also referred to as feature corruption) and identify conditions where this bias can be safely disregarded. To address cases where noise correction is needed, we propose a novel data augmentation-based method to mitigate input noise effects. Our approach is both comprehensive and theoretically grounded, providing practical solutions for improving classification accuracy in noisy data enviroments. Extensive experiments, including analyses of medical image datasets, demonstrate the superior performance of our methods under different noise conditions.", "title_embedding_index": 8356, "title_abs_embedding_index": 8381}, {"title": "FourierMamba: Fourier Learning Integration with State Space Models for Image Deraining", "link_suffix": "/forum?id=WNPrfGpcu6", "link": "https://openreview.net/forum?id=WNPrfGpcu6", "pdf_link": "https://openreview.net/pdf?id=WNPrfGpcu6", "keywords": "Fourier transform, mamba, image deraining", "abstract": "Image deraining aims to remove rain streaks from rainy images and restore clear backgrounds. Currently, some research that employs the Fourier transform has proved to be effective for image deraining, due to it acting as an effective frequency prior for capturing rain streaks. However, despite there exists dependency of low frequency and high frequency in images, these Fourier-based methods rarely exploit the correlation of different frequencies for conjuncting their learning procedures, limiting the full utilization of frequency information for image deraining. Alternatively, the recently emerged Mamba technique depicts its effectiveness and efficiency for modeling correlation in various domains (e.g., spatial, temporal), and we argue that introducing Mamba into its unexplored Fourier spaces to correlate different frequencies would help improve image deraining. This motivates us to propose a new framework termed FourierMamba, which performs image deraining with Mamba in the Fourier space. Owing to the unique arrangement of frequency orders in Fourier space, the core of FourierMamba lies in the scanning encoding of different frequencies, where the low-high frequency order formats exhibit differently in the spatial dimension  (unarranged in axis) and channel dimension (arranged in axis). Therefore, we design FourierMamba that correlates Fourier space information in the spatial and channel dimensions with distinct designs. Specifically, in the spatial dimension Fourier space, we introduce the zigzag coding to scan the frequencies to rearrange the orders from low to high frequencies,  thereby orderly correlating the connections between frequencies; in the channel dimension  Fourier space with arranged orders of frequencies in axis, we can directly use Mamba to perform frequency correlation and improve the channel information representation. Extensive experiments reveal that our method outperforms state-of-the-art methods both qualitatively and quantitatively.", "title_embedding_index": 8357, "title_abs_embedding_index": 8382}, {"title": "FinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning", "link_suffix": "/forum?id=AeGrf1uY0p", "link": "https://openreview.net/forum?id=AeGrf1uY0p", "pdf_link": "https://openreview.net/pdf?id=AeGrf1uY0p", "keywords": "large language models, large multimodal models, financial reasoning, mathematical reasoning, foundation models and their evaluations", "abstract": "Solving financial problems demands complex reasoning, multimodal data processing, and a broad technical understanding, presenting unique challenges for current large language models (LLMs). We introduce FinBench, a novel benchmark designed to evaluate LLM's ability in solving complex, knowledge-intensive financial problems across diverse graduate-level topics with multi-modal context. We identify five core capabilities of LLMs using FinBench,i.e,terminology understanding,temporal reasoning,future forecasting,scenario planning, andnumerical modelling. FinBench features 4,235 examples derived from graduate-level finance textbooks, and consists of three tasks: Statement Judging, Multi-choice Question Answering and Financial Calculation. Upon FinBench, we conduct extensive experiments on 18 leading models. The result shows that o1 is the best-performing text-only model with an overall accuracy of 67.3%, but still lags significantly behind human experts with 12.5%, especially intemporal reasoningandscenario planningcapabilities. We further construct a knowledge bank with 3,032 finance terms for knowledge augmentation analysis, and find that relevant knowledge to the question only brings consistent accuracy improvements across five capabilities to small open-source model. Additionally, our error analysis reveals that rounding errors in middle of calculation and blindness to position and intersection of curves in the image are two primary issues leading to model's poor performance in calculating and visual-context questions, respectively. These findings underscores the critical role FinBench will play in the development of general-purpose of AI agents of tackling complex, knowledge-intensive financial problems with multi-modal context.", "title_embedding_index": 8358, "title_abs_embedding_index": 8383}, {"title": "Block Coordinate Descent for Neural Networks Provably Finds Global Minima", "link_suffix": "/forum?id=n2RIkaf1S4", "link": "https://openreview.net/forum?id=n2RIkaf1S4", "pdf_link": "https://openreview.net/pdf?id=n2RIkaf1S4", "keywords": "Deep learning, block coordinate descent, global minima, generalization error", "abstract": "In this paper, we consider a block coordinate descent (BCD) algorithm for training deep neural networks and provide a new global convergence guarantee under strictly monotonically increasing activation functions.  While existing works demonstrate convergence to stationary points for BCD in neural networks, our contribution is the first to prove convergence to global minima, ensuring arbitrarily small loss. We show that the loss with respect to the output layer decreases exponentially while the loss with respect to the hidden layers remains well-controlled. Additionally, we derive generalization bounds using the Rademacher complexity framework, demonstrating that BCD not only achieves strong optimization guarantees but also provides favorable generalization performance. Moreover, we propose a modified BCD algorithm with skip connections and non-negative projection, extending our convergence guarantees to ReLU activation, which are not strictly monotonic. Empirical experiments confirm our theoretical findings, showing that the BCD algorithm achieves a small loss for strictly monotonic and ReLU activations.", "title_embedding_index": 8359, "title_abs_embedding_index": 8384}, {"title": "Physics3D: Learning Physical Properties of 3D Gaussians via Video Diffusion", "link_suffix": "/forum?id=k3JgQXtpJq", "link": "https://openreview.net/forum?id=k3JgQXtpJq", "pdf_link": "https://openreview.net/pdf?id=k3JgQXtpJq", "keywords": "Physics-based modeling, Gaussian splatting", "abstract": "In recent years, there has been rapid development in 3D generation models, opening up new possibilities for applications such as simulating the dynamic movements of 3D objects and customizing their behaviors. However, current 3D generative models tend to focus only on surface features such as color and shape, neglecting the inherent physical properties that govern the behavior of objects in the real world. To accurately simulate physics-aligned dynamics, it is essential to predict the physical properties of materials and incorporate them into the behavior prediction process. Nonetheless, predicting the diverse materials of real-world objects is still challenging due to the complex nature of their physical attributes. In this paper, we propose Physics3D, a novel method for learning various physical properties of 3D objects through a video diffusion model. Our approach involves designing a highly generalizable physical simulation system based on a viscoelastic material model, which enables us to simulate a wide range of materials with high-fidelity capabilities. Moreover, we distill the physical priors from a video diffusion model that contains more understanding of realistic object materials. Extensive experiments demonstrate the effectiveness of our method with both elastic and plastic materials. Physics3D shows great potential for bridging the gap between the physical world and virtual neural space, providing a better integration and application of realistic physical principles in virtual environments.", "title_embedding_index": 8360, "title_abs_embedding_index": 8385}, {"title": "Generalized Category Discovery  Utilizing Reciprocal Learning and Class-wise Distribution Regularization", "link_suffix": "/forum?id=On8E0U9vbz", "link": "https://openreview.net/forum?id=On8E0U9vbz", "pdf_link": "https://openreview.net/pdf?id=On8E0U9vbz", "keywords": "Generalized Category Discovery, Novel Class Discovery, Distribution Regularization", "abstract": "Generalized Category Discovery (GCD) aims to identify unlabeled samples by leveraging the base knowledge from labeled ones, where the unlabeled set consists of both base and novel classes. \nSince clustering methods are time-consuming at inference, parametric-based approaches have become more popular. \nHowever, recent parametric-based methods suffer inferior base discrimination due to the unreliable self-supervision. \nTo address this issue, we propose a Reciprocal Learning Framework (RLF) that introduces an auxiliary branch devoted to base classification. \nDuring training, the main branch filters the pseudo-base samples to the auxiliary branch. \nIn response, the auxiliary branch provides more reliable soft labels for the main branch, leading to a virtuous cycle. \nFurthermore, we introduce Class-wise Distribution Regularization (CDR) to mitigate the leaning bias towards base classes. \nCDR  essentially increases the prediction confidence of the unlabeled data and boosts the novel class performance. \nCombined with both components, our method achieves superior performance in all classes with negligible extra computation. \nExtensive experiments on seven GCD datasets validate the effectiveness of our method, e.g. delivering a notable 3.7% improvement on the CUB200 dataset.\nOur codes will be available upon acceptance.", "title_embedding_index": 8361, "title_abs_embedding_index": 8386}, {"title": "Group Ligands Docking to Protein Pockets", "link_suffix": "/forum?id=zDC3iCBxJb", "link": "https://openreview.net/forum?id=zDC3iCBxJb", "pdf_link": "https://openreview.net/pdf?id=zDC3iCBxJb", "keywords": "molecular docking, ai4science", "abstract": "Molecular docking is a key task in computational biology that has attracted increasing interest from the machine learning community. While existing methods have achieved success, they generally treat each protein-ligand pair in isolation. Inspired by the biochemical observation that ligands binding to the same target protein tend to adopt similar poses, we propose \\textsc{GroupBind}, a novel molecular docking framework that simultaneously considers multiple ligands docking to a protein. This is achieved by introducing an interaction layer for the group of ligands and a triangle attention module for embedding protein-ligand and group-ligand pairs. By integrating our approach with diffusion based docking model, we set a new state-of-the-art performance on the PDBBind blind docking benchmark, demonstrating the effectiveness of our paradigm in enhancing molecular docking accuracy.", "title_embedding_index": 8362, "title_abs_embedding_index": 8387}, {"title": "MindFormer: Semantic Alignment of Multi-Subject fMRI  for Brain Decoding", "link_suffix": "/forum?id=PlKQ9UDgqp", "link": "https://openreview.net/forum?id=PlKQ9UDgqp", "pdf_link": "https://openreview.net/pdf?id=PlKQ9UDgqp", "keywords": "fMRI, Neural Decoding, Image Reconstruction", "abstract": "Research efforts for visual decoding from fMRI signals have attracted considerable attention in research community. Still multi-subject fMRI decoding with one model has been considered intractable due to the drastic variations in fMRI signals between subjects and even within the same subject across different trials. To address current limitations in multi-subject brain decoding, here we introduce a novel semantic alignment method of multi-subject fMRI signals using so-called $\\textit{MindFormer}$. This model is specifically designed to generate fMRI-conditioned feature vectors that can be used for conditioning Stable Diffusion model for fMRI- to-image generation or large language model (LLM) for fMRI-to-text generation. More specifically, MindFormer incorporates two key innovations: 1) a subject specific token that effectively capture individual differences in fMRI signals while synergistically combines multi subject fMRI data for training, and 2) a novel feature embedding and training scheme based on the IP-Adapter to extract semantically meaningful features from fMRI signals. Our experimental results demonstrate that MindFormer generates semantically consistent images and text across different subjects. Since our MindFormer maintains semantic fidelity by fully utilizing the training data across different subjects by significantly surpassing existing models in multi-subject brain decoding, this may help deepening our understanding of neural processing variations among individuals.", "title_embedding_index": 8363, "title_abs_embedding_index": 8388}, {"title": "HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions", "link_suffix": "/forum?id=gZky2pakRK", "link": "https://openreview.net/forum?id=gZky2pakRK", "pdf_link": "https://openreview.net/pdf?id=gZky2pakRK", "keywords": "AI Safety, Multi-Agent Systems, Human-AI Interaction, Social Simulation", "abstract": "AI agents are increasingly autonomous in their interactions with human users and tools, leading to increased interactional safety risks. We present HAICOSYSTEM, a framework examining AI agent safety within diverse and complex social interactions. HAICOSYSTEM features a modular sandbox environment that simulates multi-turn interactions between human users and AI agents, where the AI agents are equipped with a variety of tools (e.g., patient management platforms) to navigate diverse scenarios (e.g., a user attempting to access other patients' profiles). To examine the safety of AI agents in these interactions, we develop a comprehensive multi-dimensional evaluation framework that uses metrics covering operational, content-related, societal, and legal risks. Through running over 8k simulations based on 132 scenarios across seven domains (e.g., healthcare, finance, education), we demonstrate that HAICOSYSTEM can emulate realistic user-AI interactions and complex tool use by AI agents. Our experiments show that state-of-the-art LLMs, both proprietary and open-sourced, exhibit safety risks in over 62% cases, with models generally showing higher risks when interacting with simulated malicious users. Our findings highlight the ongoing challenge of building agents that can safely navigate complex interactions, particularly when faced with malicious users. To foster the AI agent safety ecosystem, we release a code platform that allows practitioners to create custom scenarios, simulate interactions, and evaluate the safety and performance of their agents.", "title_embedding_index": 8364, "title_abs_embedding_index": 8389}, {"title": "Revisiting Mode Connectivity in Neural Networks with Bezier Surface", "link_suffix": "/forum?id=1NevL7zdHS", "link": "https://openreview.net/forum?id=1NevL7zdHS", "pdf_link": "https://openreview.net/pdf?id=1NevL7zdHS", "keywords": "mode connectivity, B\u00e9zier surfaces, loss landscape, deep learning", "abstract": "Understanding the loss landscapes of neural networks (NNs) is critical for optimizing model performance. Previous research has identified the phenomenon of mode connectivity on curves, where two well-trained NNs can be connected by a continuous path in parameter space where the path maintains nearly constant loss. In this work, we extend the concept of mode connectivity to explore connectivity on surfaces, significantly broadening its applicability and unlocking new opportunities. While initial attempts to connect models via linear surfaces in parameter space were unsuccessful, we propose a novel optimization technique that consistently discovers B\u00e9zier surfaces with low-loss and high-accuracy connecting multiple NNs in a nonlinear manner. We further demonstrate that even without optimization, mode connectivity exists in certain cases of B\u00e9zier surfaces, where the models are carefully selected and combined linearly. This approach provides a deeper and more comprehensive understanding of the loss landscape and offers a novel way to identify models with enhanced performance for model averaging and output ensembling. We demonstrate the effectiveness of our method on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets using VGG16, ResNet18, and ViT architectures.", "title_embedding_index": 8365, "title_abs_embedding_index": 8390}, {"title": "LVBench: An Extreme Long Video Understanding Benchmark", "link_suffix": "/forum?id=uHgVrGF2Wn", "link": "https://openreview.net/forum?id=uHgVrGF2Wn", "pdf_link": "https://openreview.net/pdf?id=uHgVrGF2Wn", "keywords": "Video understanding, Multimodal learning, Visual question answering, Long-form video, Datasets and benchmarking", "abstract": "Recent progress in multimodal large language models has markedly enhanced the understanding of short videos (typically under one minute), and several evaluation datasets have emerged accordingly. However, these advancements fall short of meeting the demands of real-world applications such as embodied intelligence for long-term decision-making, in-depth movie reviews and discussions, and live sports commentary, all of which require comprehension of long videos spanning several hours. To address this gap, we introduce LVBench, a benchmark specifically designed for long video understanding. Our dataset comprises publicly sourced videos and encompasses a diverse set of tasks aimed at long video comprehension and information extraction. LVBench is designed to challenge multimodal models to demonstrate long-term memory and extended comprehension capabilities. Our extensive evaluations reveal that current multimodal models still underperform on these demanding long video understanding tasks. Through LVBench, we aim to spur the development of more advanced models capable of tackling the complexities of long video comprehension.", "title_embedding_index": 8366, "title_abs_embedding_index": 8391}, {"title": "Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent", "link_suffix": "/forum?id=VvDEuyVXkG", "link": "https://openreview.net/forum?id=VvDEuyVXkG", "pdf_link": "https://openreview.net/pdf?id=VvDEuyVXkG", "keywords": "Large Language Model, Multimodal Retrieval Augmented Generation, Knowledge Enhancement", "abstract": "Multimodal Retrieval Augmented Generation (mRAG) plays an important role in mitigating the \u201challucination\u201d issue inherent in multimodal large language models (MLLMs). Although promising, existing heuristic mRAGs typically predefined fixed retrieval processes, which causes two issues: (1) Non-adaptive Retrieval Queries. (2) Overloaded Retrieval Queries. However, these flaws cannot be adequately reflected by current knowledge-seeking visual question answering (VQA) datasets, since the most required knowledge can be readily obtained with a standard two-step retrieval. To bridge the dataset gap, we first construct Dyn-VQA dataset, consisting of three types of ``dynamic'' questions, which require complex knowledge retrieval strategies variable in query, tool, and time: (1) Questions with rapidly changing answers. (2) Questions requiring multi-modal knowledge. (3) Multi-hop questions. Experiments on Dyn-VQA reveal that existing heuristic mRAGs struggle to provide sufficient and precisely relevant knowledge for dynamic questions due to their rigid retrieval processes. Hence, we further propose the first self-adaptive planning agent for multimodal retrieval,OmniSearch. The underlying idea is to emulate the human behavior in question solution which dynamically decomposes complex multimodal questions into sub-question chains with retrieval action. Extensive experiments prove the effectiveness of our OmniSearch, also provide direction for advancing mRAG. Code and dataset will be open-sourced.", "title_embedding_index": 8367, "title_abs_embedding_index": 8392}, {"title": "Offline Equilibrium Finding in Extensive-form Games: Datasets, Methods, and Analysis", "link_suffix": "/forum?id=Re5iu0hBTs", "link": "https://openreview.net/forum?id=Re5iu0hBTs", "pdf_link": "https://openreview.net/pdf?id=Re5iu0hBTs", "keywords": "Game Theory, Equilibrium Finding, Offline Learning", "abstract": "Offline reinforcement learning (Offline RL) brings new methods to tackle real-world decision-making problems by leveraging pre-collected datasets. \nDespite substantial progress in single-agent scenarios, the application of offline learning to multiplayer games remains largely unexplored. \nTherefore, we introduce a novel paradigmoffline equilibrium finding(Offline EF) in extensive-form games (EFGs), which aims at computing equilibrium strategies from offline datasets. \nThe primary challenges of offline EF include i) the absence of a comprehensive dataset of EFGs for evaluation; ii) the inherent difficulties in computing an equilibrium strategy solely from an offline dataset, as equilibrium finding requires referencing all potential action profiles; and iii) the impact of dataset quality and completeness on the effectiveness of the derived strategies.\nTo overcome these challenges, we make four main contributions in this work. First, we construct diverse datasets, encompassing a wide range of games, which form the foundation for the offline EF paradigm and serve as a basis for evaluating the performance of offline EF algorithms. Second, we design a novel framework, BOMB, which integrates the behavior cloning technique within a model-based method. BOMB can seamlessly integrate online equilibrium finding algorithms to the offline setting with minimal modifications. Third, we provide a comprehensive theoretical and empirical analysis of our BOMB framework, offering performance guarantees across various offline datasets. Finaly, extensive experiments have been carried out across different games under different offline datasets, and the results not only demonstrate the superiority of our approach compared to traditional offline RL algorithms but also highlight the remarkable efficiency in computing equilibrium strategies offline.", "title_embedding_index": 8368, "title_abs_embedding_index": 8393}, {"title": "Self-Preference Bias in LLM-as-a-Judge", "link_suffix": "/forum?id=Ns8zGZ0lmM", "link": "https://openreview.net/forum?id=Ns8zGZ0lmM", "pdf_link": "https://openreview.net/pdf?id=Ns8zGZ0lmM", "keywords": "large language model, llm-as-a-judge, bias, fairness", "abstract": "Automated evaluation leveraging large language models (LLMs), commonly referred to as LLM evaluators or LLM-as-a-judge, has been widely used in measuring the performance of dialogue systems.\nHowever, the self-preference bias in LLMs has posed significant risks, including promoting specific styles or policies intrinsic to the LLMs.\nDespite the importance of this issue, there is a lack of established methods to measure the self-preference bias quantitatively, and its underlying causes are poorly understood.\nIn this paper, we introduce a novel quantitative metric to measure the self-preference bias.\nOur experimental results demonstrate that GPT-4 exhibits a significant degree of self-preference bias.\nTo explore the causes, we hypothesize that LLMs may favor outputs that are more familiar to them, as indicated by lower perplexity.\nWe analyze the relationship between LLM evaluations and the perplexities of outputs.\nOur findings reveal that LLMs assign significantly higher evaluations to outputs with lower perplexity than human evaluators, regardless of whether the outputs were self-generated.\nThis suggests that the essence of the bias lies in perplexity and that the self-preference bias occurs because the LLMs' own outputs have lower perplexity.", "title_embedding_index": 8369, "title_abs_embedding_index": 8394}, {"title": "AdaGrad under Anisotropic Smoothness:  A Fine-Grained Analysis", "link_suffix": "/forum?id=4GT9uTsAJE", "link": "https://openreview.net/forum?id=4GT9uTsAJE", "pdf_link": "https://openreview.net/pdf?id=4GT9uTsAJE", "keywords": "Optimization theory, Convergence analysis, Stochastic optimization, Adaptive gradient methods", "abstract": "Adaptive gradient methods have been widely adopted in training large-scale deep neural networks, especially large foundation models. Despite the huge success in practice, their theoretical advantages over classical gradient methods with uniform step sizes across all coordinates (e.g. SGD) have not been fully understood, especially in the large batch-size setting commonly used in practice. This is because the only theoretical result that can demonstrate this benefit was obtained in the original paper of Adagrad for convex nonsmooth objective functions, which is insufficient for large batch algorithms. In this work, we attempt to resolve this gap between theory and practice by proposing a novel anisotropic generalized smoothness assumption and providing corresponding analysis of Adagrad. It is shown that under anisotropic smoothness and noise conditions, AdaGrad can achieve faster convergence guarantees in terms of better dimensional dependence than algorithms with uniform step sizes across all coordinates. Experiments in logistic regression and instruction following fine-tuning tasks provide strong evidence to support our novel assumption and theoretical analysis.", "title_embedding_index": 8370, "title_abs_embedding_index": 8395}, {"title": "Selective Prompt Anchoring for Code Generation", "link_suffix": "/forum?id=FCCeBaFa8M", "link": "https://openreview.net/forum?id=FCCeBaFa8M", "pdf_link": "https://openreview.net/pdf?id=FCCeBaFa8M", "keywords": "Large Language Models (LLMs), Code Generation, Attention, Logits, Anchoring, Prompt", "abstract": "Recent advances in large language models (LLMs) have transformed software development by automatically generating code based on users' requests in natural language. Despite these advancements, challenges remain in generating buggy code and fully aligning with user intent. Our empirical study reveals LLMs tend to dilute their self-attentions on the initial prompt as more code tokens are generated. We hypothesize this self-attention dilution issue is one of the root causes of inaccuracies in LLM-generated code. To mitigate this issue, we proposeSelectivePromptAnchoring (SPA) to amplify the influence of the selected parts in the initial prompt, which we refer to as \"anchored text\", during code generation. Specifically, SPA calculates the logit distribution difference with and without the anchored text. We prove this logit difference approximates the anchored text's contextual contribution to the output logits. SPA creates an augmented logit distribution by linearly combining the original logit distribution and the logit difference. We evaluate SPA with five LLMs on four benchmarks. Our results show that after tuning on a few dozen instances, SPA consistently improves Pass@1 on new tasks by up to 7.6% across all settings. Notably, with selective text anchoring, a small version of DeepSeek-Coder (6.7B) can achieve better performance than an original much larger version (33B). Our code is available athttps://anonymous.4open.science/r/Selective-Prompt-Anchoring-74E7.", "title_embedding_index": 8371, "title_abs_embedding_index": 8396}, {"title": "Representation Learning for Long Tail Recognition via Feature Space Re-Construction", "link_suffix": "/forum?id=GySIAKEwtZ", "link": "https://openreview.net/forum?id=GySIAKEwtZ", "pdf_link": "https://openreview.net/pdf?id=GySIAKEwtZ", "keywords": "contrastive learning, representation learning, long-tail recgonition, theory", "abstract": "Deep learning has achieved significant success on balanced datasets. However, real-world data often exhibit a long-tailed distribution. Empirical results show that long-tailed data skews representations where head classes dominate the feature space. Many methods have been proposed to empirically correct the skewed representations. However, a clear theoretical understanding of the underlying causes and extent of this skew remains lacking. In this work, we provide a comprehensive theoretical analysis to elucidate how long-tailed data affects representations, deriving the conditions under which the centers of the tail classes shrink together or even collapse into a single point. This results in overlapping feature distributions of tail classes, making features in the overlapping regions inseparable. Moreover, we demonstrate that merely empirically correcting the skewed representations of training data is insufficient to separate the overlapping features, due to distribution shifts between training and real data. To address these challenges, we propose a novel long-tailed representation learning method, FeatRecon. It reconstructs the feature space so that features of all classes are arranged into symmetrical and linearly separable regions. Thereby, it enhances model robustness to long-tailed data. We validate the effectiveness of our method through extensive experiments on the CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018 datasets.", "title_embedding_index": 8372, "title_abs_embedding_index": 8397}, {"title": "Update larger, train faster: Stable Test-time adaptation utilizing noisy-pseudo labels", "link_suffix": "/forum?id=ezzmWTm8r6", "link": "https://openreview.net/forum?id=ezzmWTm8r6", "pdf_link": "https://openreview.net/pdf?id=ezzmWTm8r6", "keywords": "domain adaptation, test-time adaptation, online learning", "abstract": "We investigate the role of pseudo-labels in the test-time adaptation (TTA) problem. When working with unlabeled samples in TTA, pseudo-labels have become a natural approach to updating the target model. However, pseudo-label learning also presents some challenges: it suffers from a memorization effect (the model learns from clean labels first, then memorizes the noisy ones) and confirmation bias (errors from noisy labels increase over time and disrupt model performance when they become significant). Our work first identifies two underlying mechanisms leading to these obstacles. On the one hand, existing methods follow a \"slow\" adaptation to the target domain, allowing sufficient time for the model to memorize noisy labels (memorization effect) and accumulate errors (confirmation bias). Furthermore, training with noisy labels blurs the decision boundary with nearby classes. To address the first issue, we propose a novel loss function, namely sparse cross logit (sparse-CL), that operates in the logit space and allows the model to take larger learning steps in a stable training manner. This helps the target model reach a better solution faster under the same number of updating steps. To address the second issue, we introduce a regularization that penalizes negative pseudo-labels while encouraging positive ones, which can increase the boundary between nearby classes. We demonstrate that our methods outperform state-of-the-art methods in a diverse set of TTA experiments.", "title_embedding_index": 8373, "title_abs_embedding_index": 8398}, {"title": "IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning", "link_suffix": "/forum?id=vl7kf0YHwj", "link": "https://openreview.net/forum?id=vl7kf0YHwj", "pdf_link": "https://openreview.net/pdf?id=vl7kf0YHwj", "keywords": "Image Manipulation Detection\uff1bSegment Anything Model\uff1bPrompt learning\uff1bSemantic-Agnostic", "abstract": "Using extensive training data from SA-1B, the Segment Anything Model (SAM) has demonstrated exceptional generalization and zero-shot capabilities, attracting widespread attention in areas such as medical image segmentation and remote sensing image segmentation. However, its performance in the field of image manipulation detection remains largely unexplored and unconfirmed. There are two main challenges in applying SAM to image manipulation detection: a) reliance on manual prompts, and b) the difficulty of single-view information in supporting cross-dataset generalization. To address these challenges, we develops a cross-view prompt learning paradigm called IMDPrompter based on SAM. Benefiting from the design of automated prompts, IMDPrompter no longer relies on manual guidance, enabling automated detection and localization. Additionally, we propose components such as Cross-view Feature Perception, Optimal Prompt Selection, and Cross-View Prompt Consistency, which facilitate cross-view perceptual learning and guide SAM to generate accurate masks. Extensive experimental results from five datasets (CASIA, Columbia, Coverage, IMD2020, and NIST16) validate the effectiveness of our proposed method.", "title_embedding_index": 8374, "title_abs_embedding_index": 8399}]
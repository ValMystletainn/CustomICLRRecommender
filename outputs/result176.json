[{"title": "SciPG: A New Benchmark and Approach for Layout-aware Scientific Poster Generation", "link_suffix": "/forum?id=zmHqlXGTTl", "link": "https://openreview.net/forum?id=zmHqlXGTTl", "pdf_link": "https://openreview.net/pdf?id=zmHqlXGTTl", "keywords": "Scientific poster generation, multimodal extraction, multimodal generation", "abstract": "Scientific posters are an effective and expressive medium for conveying the core ideas of academic papers, facilitating the communication of research techniques. However, creating high-quality scientific posters is a complex and time-consuming task that requires advanced skills to summarize key concepts and arrange them logically and visually appealingly. Previous studies have primarily focused on either content extraction or the layout and composition of posters, often relying on small-scale datasets. The scarcity of large, publicly available datasets has further limited advancements in this field.\nIn this paper, we introduce a new task called layout-aware scientific poster generation (LayoutSciPG), which aims to generate flexible posters from scientific papers through integrated automatic content extraction and layout design.\nTo achieve this, we first build a large-scale dataset containing over 10,000 pairs of scientific papers and their corresponding posters. We then propose a multimodal extractor-generator framework, which employs a multimodal extractor to retrieve key text and image elements from the papers and designs an interactive generator with an adaptive memory mechanism to seamlessly paraphrase the extracted content and generate a structured layout. This approach effectively tackles challenges related to GPU memory consumption and long-term dependencies when handling the lengthy inputs (scientific papers) and outputs (posters). Finally, both qualitative and quantitative evaluations demonstrate the effectiveness of our approach while highlighting remaining challenges.", "title_embedding_index": 8750, "title_abs_embedding_index": 8775}, {"title": "Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models", "link_suffix": "/forum?id=FfIognyBee", "link": "https://openreview.net/forum?id=FfIognyBee", "pdf_link": "https://openreview.net/pdf?id=FfIognyBee", "keywords": "one-step text-to-image generative model, human preference alignment, RLHF", "abstract": "In this paper, we introduce Diff-Instruct* (DI*), a data-free approach for building one-step text-to-image generative models that align with human preference while maintaining the ability to generate highly realistic images. We frame human preference alignment as online reinforcement learning using human feedback (RLHF), where the goal is to maximize the reward function while regularizing the generator distribution to remain close to a reference diffusion process. Unlike traditional RLHF approaches, which rely on the KL divergence for regularization, we introduce a novel score-based divergence regularization, which leads to significantly better performances. Although the direct calculation of this divergence remains intractable, we demonstrate that we can efficiently compute its gradient by deriving an equivalent yet tractable loss function. Remarkably, with Stable Diffusion V1.5 as the reference diffusion model, DI* outperforms all previously leading models by a large margin. When using the 0.6B PixelArt-\u03b1 model as the reference diffusion, DI* achieves a new record Aesthetic Score of 6.30 and an Image Reward of 1.31 with only a single generation step, almost doubling the scores of the rest of the models with similar sizes. It also achieves an HPSv2 score of 28.70, establishing a new state-of-the-art benchmark. We also observe that DI* can improve the layout and enrich the colors of generated images. Our best human-preferred one-step generator will be released with this paper.", "title_embedding_index": 8751, "title_abs_embedding_index": 8776}, {"title": "Reinforcement Learning with Segment Feedback", "link_suffix": "/forum?id=aMD0qUyYJh", "link": "https://openreview.net/forum?id=aMD0qUyYJh", "pdf_link": "https://openreview.net/pdf?id=aMD0qUyYJh", "keywords": "Reinforcement learning (RL), segment feedback, binary feedback, sum feedback", "abstract": "Classic reinforcement learning (RL) assumes that an agent can observe a reward for each state-action pair. However, in practical applications, it is often difficult and costly to collect a reward for each state-action pair. While there have been several works considering RL with trajectory feedback, it is unclear if trajectory feedback is inefficient for learning when trajectories are long. In this work, we propose a model named RL with segment feedback, which offers a general paradigm filling the gap between per-state-action feedback and trajectory feedback seemlessly. In this model, we consider an episodic Markov decision process (MDP), where each episode is equally divided into $m$ segments, and the agent observes reward feedback only at the end of each segment. Under this model, we study two popular feedback settings: binary feedback and sum feedback, where the agent observes a binary outcome and a reward sum according to the underlying reward function, respectively. To investigate the impacts of the number of segments $m$ on learning performance, we design efficient algorithms and establish regret upper and lower bounds for both feedback settings. Our theoretical and empirical results show that: under binary feedback, increasing the number of segments $m$ decreases the regret at an exponential rate; in contrast, surprisingly under sum feedback, increasing $m$ does not reduce the regret significantly.", "title_embedding_index": 8752, "title_abs_embedding_index": 8777}, {"title": "Grothendieck Graph Neural Networks Framework: An Algebraic Platform for Crafting Topology-Aware GNNs", "link_suffix": "/forum?id=i1Yxnar4mj", "link": "https://openreview.net/forum?id=i1Yxnar4mj", "pdf_link": "https://openreview.net/pdf?id=i1Yxnar4mj", "keywords": "Graph Neural Networks, Categorical Deep Learning, Algebraic Deep Learning, Graph Isomorphism, Graph Classification", "abstract": "Due to the structural limitations of Graph Neural Networks (GNNs), particularly those relying on conventional neighborhoods, alternative aggregation strategies have been explored to enhance expressive power. This paper proposes a novel approach by generalizing the concept of neighborhoods through algebraic covers to overcome these limitations.\nWe introduce the Grothendieck Graph Neural Networks (GGNN) framework, providing an algebraic platform for systematically defining and refining diverse covers for graphs. The GGNN framework translates these covers into matrix representations, extending the scope of designing GNN models by incorporating desired message-passing strategies.\nBased on the GGNN framework, we propose Sieve Neural Networks (SNN), a new GNN model that leverages the notion of sieves from category theory. SNN demonstrates competitive performance in experiments, particularly in differentiating between strongly regular graphs, and exemplifies the versatility of GGNN in generating novel architectures.\nIn conclusion, our work advances the design of GNNs by introducing algebraic structures that empower more expressive message-passing mechanisms, addressing the limitations of traditional neighborhood-based methods.", "title_embedding_index": 8753, "title_abs_embedding_index": 8778}, {"title": "OMG: Opacity Matters in Material Modeling with Gaussian Splatting", "link_suffix": "/forum?id=oeP6OL7ouB", "link": "https://openreview.net/forum?id=oeP6OL7ouB", "pdf_link": "https://openreview.net/pdf?id=oeP6OL7ouB", "keywords": "3D Gaussian Splatting, Neural Rendering, Inverse Rendering, Visual Computing", "abstract": "Decomposing geometry, materials and lighting from a set of images, namely inverse rendering, has been a long-standing problem in computer vision and graphics. Recent advances in neural rendering enable photo-realistic and plausible inverse rendering results. The emergence of 3D Gaussian Splatting has boosted it to the next level. An intuitive finding is that the models used for inverse rendering do not take into account the dependency of opacity w.r.t. material properties, namely cross section, as suggested by optics. Therefore, we develop a novel approach that adds this dependency to the modeling itself. Inspired by radiative transfer, we augment the opacity term by introducing a neural network that takes as input material properties to provide modeling of cross section and a physically correct activation function. The gradients for material properties are therefore not only from color but also from opacity, facilitating a constraint for their optimization. Therefore, the proposed method incorporates more accurate physical properties compared to previous works. We implement our method into 3 different baselines that use Gaussian Splatting for inverse rendering and achieve significant improvements universally in terms of novel view synthesis and material modeling.", "title_embedding_index": 8754, "title_abs_embedding_index": 8779}, {"title": "Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs", "link_suffix": "/forum?id=QWunLKbBGF", "link": "https://openreview.net/forum?id=QWunLKbBGF", "pdf_link": "https://openreview.net/pdf?id=QWunLKbBGF", "keywords": "personalization, benchmark, Large language models, conversational llm, chatbots", "abstract": "Large Language Models (LLMs) are increasingly deployed as chatbots, yet their ability to personalize responses to user preferences remains limited. We introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize and adhere to user preferences in long-context conversational setting.\nPrefEval comprises 3,000 manually curated user preference and query pairs spanning 20 topics. PrefEval contains user personalization or preference information in both explicit and implicit preference forms, and evaluates LLM performance using a generation and a classification task. With PrefEval, we have evaluated 10 open-sourced and\nproprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting, iterative feedback, and retrieval-augmented generation methods. \nOur benchmarking effort reveals that state-of-the-art LLMs face significant challenges in following users' preference during conversations. In particular,  in zero-shot settings, preference following accuracy falls below 10% at merely 10 turns (~3k tokens) across most evaluated models. Even with advanced prompting and retrieval methods, preference following still deteriorates in long-context conversations. We also find that multiple stated preferences within a conversation improve adherence and models are not affected by conflicting preferences. Furthermore, we show that fine-tuning on PrefEval significantly improves performance. We believe PrefEval serves as a valuable resource for measuring, understanding, and enhancing LLMs' proactive preference following abilities, paving the way for personalized conversational agents.", "title_embedding_index": 8755, "title_abs_embedding_index": 8780}, {"title": "Direct Preference Optimization Using Sparse Feature-level Constraints", "link_suffix": "/forum?id=LidZXoqZ2Q", "link": "https://openreview.net/forum?id=LidZXoqZ2Q", "pdf_link": "https://openreview.net/pdf?id=LidZXoqZ2Q", "keywords": "Preference Optimization, Reinforcement Learning, LLM, Sparse AutoEncoder", "abstract": "The alignment of large language models (LLMs) with human preferences remains a key challenge. While post-training techniques like Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO) have achieved notable success, they often introduce computational inefficiencies and training instability. In this paper, we proposeFeature-level constrainedPreferenceOptimization (FPO), a novel method designed to simplify the alignment process while ensuring stability. FPO leverages pre-trained Sparse Autoencoders (SAEs) and introduces feature-level constraints, allowing for efficient, sparsity-enforced alignment. Our approach enjoys efficiency by using sparse features activated in a well-trained sparse autoencoder and the quality of sequential KL divergence by using the feature-level offline reference. Experimental results on benchmark datasets demonstrate that FPO achieves a 5.08% absolute improvement in win rate with much lower computational cost compared to state-of-the-art baselines, making it a promising solution for efficient and controllable LLM alignments.", "title_embedding_index": 8756, "title_abs_embedding_index": 8781}, {"title": "Legendre-KAN : High Accuracy KA Network Based on Legendre Polynomials", "link_suffix": "/forum?id=Bb1ddVX8rL", "link": "https://openreview.net/forum?id=Bb1ddVX8rL", "pdf_link": "https://openreview.net/pdf?id=Bb1ddVX8rL", "keywords": "KA Network; Legendre Polynomials; Symbolic Representation; Function Approximation; High Accuracy", "abstract": "Recently, the Kolmogorov-Arnold Network (KAN) has been proposed, significantly outperforming MLP in terms of interpretability and symbolic representation. In practice, KANs are required to fit data to extremely high precision. For instance, in typical applications of KAN like inferring precise equations from data and serving as solvers for partial differential equations,  high accuracy is an intrinsic requirement. In the current architecture of KAN, cubic B-spline basis functions were selected as the approximate tools. However, the inflexibility of fixed degree and knots in B-splines restricts the adaptability of the activation functions. Due to these inherent limitations of B-spline functions, especially low-order and homogeneity, KAN has no ability to reduce the training error down to the required precision. In this paper, we propose the Legendre-KAN that can enhance the degrees of freedom of the basis functions in the KAN. Compared to the traditional Spline-KAN, Legendre-KAN utilizes parameterized Legendre basis functions and normalization layers at the edges of the KAN. Benefiting from higher-order orthogonal polynomials, Legendre-KAN significantly outperforms the Spline-KAN in terms of accuracy. Extensive experiments demonstrate that Legendre-KAN achieves higher accuracy and parameter efficiency, of which accuracy reaches 10-100 times that of Spline-KAN. For those functions which can be symbolized, this leads to more correct results as opposed to Spline-KAN. Our approach effectively improves the accuracy of the mathematical relationships in KANs, providing a better solution for approximating and analyzing complex nonlinear functions.", "title_embedding_index": 8757, "title_abs_embedding_index": 8782}, {"title": "LayeredGS: Efficient Dynamic Scene Rendering and Point Tracking with Multi-Layer Deformable Gaussian Splatting", "link_suffix": "/forum?id=AkufxLzcV5", "link": "https://openreview.net/forum?id=AkufxLzcV5", "pdf_link": "https://openreview.net/pdf?id=AkufxLzcV5", "keywords": "3D Vision, Novel View Synthesis, Dynamic Scene Reconstruction", "abstract": "Dynamic novel-view synthesis and point tracking have emerged as promising tasks. However, existing methods often struggle with efficiency and accurately capturing deformations. In this paper, we propose LayeredGS, a novel Deformation-based Dynamic Gaussian Splatting method that excels in both 3D tracking of dense scene elements and real-time dynamic scene rendering. By learning Gaussian deformations between frames, LayeredGS preserves their point-like characteristics while capturing motion. Unlike previous methods, our approach optimizes efficiency by grouping Gaussians with similar deformations using a coarse-to-fine clustering structure. Experimental results show the rapid convergence within 100 iterations per time frame on fast-moving dynamic datasets, maintaining rendering quality and tracking accuracy comparable to state-of-the-art methods using only 1/20 training iterations. Additionally, we introduce applications like  Articulated Objects Segmentation, highlighting the utility of deformation information for the first time.", "title_embedding_index": 8758, "title_abs_embedding_index": 8783}, {"title": "AnyGraph: Graph Foundation Model in the Wild", "link_suffix": "/forum?id=Kdcqzfypry", "link": "https://openreview.net/forum?id=Kdcqzfypry", "pdf_link": "https://openreview.net/pdf?id=Kdcqzfypry", "keywords": "graph learning, graph neural networks", "abstract": "The growing ubiquity of relational data structured as graphs has underscored the need for graph learning models with exceptional generalization capabilities. However, current approaches often struggle to effectively extract generalizable insights, frequently requiring extensive fine-tuning and limiting their versatility. Graph foundation models offer a transformative solution, with the potential to learn robust, generalizable representations from graph data. This enables more effective and adaptable applications across a wide spectrum of tasks and domains. In this work, we investigate a unified graph model, AnyGraph, designed to handle key challenges: i) Structure Heterogenity. Addressing distribution shift in graph structural information; ii) Feature Heterogenity. Handling diverse feature representation spaces across graph datasets; iii) Fast Adaptation. Efficiently adapting the model to new graph domains; iv) Scaling Law Emergence. Enabling the model to exhibit scaling law behavior, where its performance scales favorably with the amount of data and parameter sizes. To tackle these critical challenges, we build the AnyGraph upon a Graph Mixture-of-Experts (MoE) architecture. This approach empowers the model to effectively manage both the in-domain and cross-domain distribution shift concerning structure-level and feature-level heterogeneity. Furthermore, a lightweight graph expert routing mechanism is proposed to facilitate AnyGraph's fast adaptability to new data and domains. Our extensive experiments on diverse 38 graph datasets have demonstrated the strong zero-shot learning performance of AnyGraph across diverse graph domains with significant distribution shift. Furthermore, we have validated the model's fast adaptation ability and scaling law emergence, showcasing its versatility. We have anonymously released our open-sourced AnyGraph implementation at the following link:https://anonymous.4open.science/r/AnyGraph-FECD.", "title_embedding_index": 8759, "title_abs_embedding_index": 8784}, {"title": "Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing", "link_suffix": "/forum?id=Pnk7vMbznK", "link": "https://openreview.net/forum?id=Pnk7vMbznK", "pdf_link": "https://openreview.net/pdf?id=Pnk7vMbznK", "keywords": "Dataset, LLM, alignment, synthetic, supervised fine-tuning", "abstract": "High-quality instruction data is critical for aligning large language models (LLMs). Although some models, such as Llama-3-Instruct, have open weights, their alignment data remain private, which hinders the democratization of AI. High human labor costs and a limited, predefined scope for prompting prevent existing open-source data creation methods from scaling effectively, potentially limiting the diversity and quality of public alignment datasets. Is it possible to synthesize high-quality instruction data at scale by extracting it directly from an aligned LLM? We present a self-synthesis method for generating large-scale alignment data named Magpie.  Our key observation is that aligned LLMs like Llama-3-Instruct can generate a user query when we input only the pre-query templates up to the position reserved for user messages, thanks to their auto-regressive nature.  We use this method to prompt Llama-3-Instruct and generate 4 million instructions along with their corresponding responses. We further introduce extensions of Magpie for filtering, generating multi-turn, preference optimization, domain-specific and multilingual datasets. We perform a comprehensive analysis of the Magpie-generated data. To compare Magpie-generated data with other public instruction datasets (e.g., ShareGPT, WildChat, Evol-Instruct, UltraChat, OpenHermes, Tulu-V2-Mix, GenQA), we fine-tune Llama-3-8B-Base with each dataset and evaluate the performance of the fine-tuned models. Our results indicate that using Magpie for supervised fine-tuning (SFT) solely can surpass the performance of previous public datasets utilized for both SFT and preference optimization, such as direct preference optimization with UltraFeedback. We also show that in some tasks, models supervised fine-tuned with Magpie perform comparably to the official Llama-3-8B-Instruct, despite the latter being enhanced with 10 million data points through SFT and subsequent preference optimization. This advantage is evident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.", "title_embedding_index": 8760, "title_abs_embedding_index": 8785}, {"title": "Singular Value Fine-tuning for Few-Shot Class-Incremental Learning", "link_suffix": "/forum?id=eOlCIiNe5o", "link": "https://openreview.net/forum?id=eOlCIiNe5o", "pdf_link": "https://openreview.net/pdf?id=eOlCIiNe5o", "keywords": "Few-Shot Continual Learning; Class-Incremental Learning", "abstract": "Class-Incremental Learning (CIL) aims to learn knowledge from new classes sequentially, while rataining the knowledge obtained from previously encountered classes, thereby mitigating the challenge of Catastrophic Forgetting. In a more realistic scenario, future unseen classes may contain only a few samples, leading to a new challenge of over-fitting, which is referred to as Few-Shot Class-Incremental Learning (FSCIL). Existing works explore FSCIL from various perspectives, such as classifier calibration and backbone extension. Most of them treat the many-shot base session and incremental few-shot sessions separately, as the model tends to overfit on few-shot classes. In this paper, we propose Singular Value Fine-tuning for few-shot Class-incremental Learning (SVFCL) to constantly learn base and incremental sessions based on the pre-trained ViT encoder. SVFCL incorporates incremental adapters, each of which is attached to a corresponding pre-trained module and contains only a small number of learnable parameters, effectively reducing the risk of overfitting. Furthermore, since each adapter is task-specific, information from previous tasks is well-preserved, mitigating catastrophic forgetting.\nOur experimental results demonstrate that SVFCL achieves substantial improvements over state-of-the-art methods while requiring significantly less computational overhead and epochs.", "title_embedding_index": 8761, "title_abs_embedding_index": 8786}, {"title": "One-step Flow Matching Generators", "link_suffix": "/forum?id=B5IuILRdAX", "link": "https://openreview.net/forum?id=B5IuILRdAX", "pdf_link": "https://openreview.net/pdf?id=B5IuILRdAX", "keywords": "one-step generator, text-to-image generation, flow matching", "abstract": "In the realm of Artificial Intelligence Generated Content (AIGC), flow-matching models have emerged as a powerhouse, achieving success due to their robust theoretical underpinnings and solid ability for large-scale generative modeling. These models have demonstrated state-of-the-art performance, but their brilliance comes at a cost. The process of sampling from these models is notoriously demanding on computational resources, as it necessitates the use of multi-step numerical ordinary differential equations (ODEs). Against this backdrop, this paper presents a novel solution with theoretical guarantees in the form of Flow Generator Matching (FGM), an innovative approach designed to accelerate the sampling of flow-matching models into a one-step generation, while maintaining the original performance. On the CIFAR10 unconditional generation benchmark, our one-step FGM model achieves a new record Fr\u00e9chet Inception Distance (FID) score of 3.08 among all flow-matching-based models, outperforming flow matching models that use 50 generation steps. \nFurthermore, we use the FGM to distill the Stable Diffusion 3, which is a leading text-to-image flow-matching model. The resulting model named the MM-DiT-FGM demonstrates outstanding industry-level performance as a novel transformer-based one-step text-to-image generator.  When evaluated on GenEval benchmark, MM-DiT-FGM has delivered remarkable generating qualities, rivaling other multi-step models in light of the efficiency of a single generation step. We will release our one-step FGM text-to-image model with this paper.", "title_embedding_index": 8762, "title_abs_embedding_index": 8787}, {"title": "Correlating and Predicting Human Evaluations of Language Models from Natural Language Processing Benchmarks", "link_suffix": "/forum?id=52Idqv2FNY", "link": "https://openreview.net/forum?id=52Idqv2FNY", "pdf_link": "https://openreview.net/pdf?id=52Idqv2FNY", "keywords": "language models, evaluations, human evaluations, benchmarks, NLP benchmarks", "abstract": "The field of natural language processing (NLP) historically evaluated language models using benchmarks with automated metrics. However, the recent advent of highly capable chat language models (LMs) has caused a tectonic shift from NLP benchmarks to human evaluations. The relationship between these two evaluation processes is unclear and underexplored for chat LMs. Broadly, to what extent are human evaluations and NLP benchmarks correlated with one another? How well can computationally inexpensive and automated benchmarks predict expensive and time-intensive human evaluations? Which benchmarks provide predictive signals for human preference for LMs? What role, if any, should benchmarks play in the era of chat LMs? To answer these questions, we conducted a large-scale study of the relationships between human evaluations and benchmarks. We show that benchmarks are broadly highly correlated with human evaluations, and we identify which benchmarks exhibit strong correlations with human evaluations and which do not. Having established that reliable correlations exist, we fit models to predict a language model's human evaluation scores from its academic evaluation scores and provide evidence that such predictive models can generalize across LM scales.", "title_embedding_index": 8763, "title_abs_embedding_index": 8788}, {"title": "MotifExplainer: a Motif-based Graph Neural Network Explainer", "link_suffix": "/forum?id=2ZTnALzLyX", "link": "https://openreview.net/forum?id=2ZTnALzLyX", "pdf_link": "https://openreview.net/pdf?id=2ZTnALzLyX", "keywords": "Instance-level explanation, Graph Neural Network, Motif", "abstract": "We consider the explanation problem of Graph Neural Networks (GNNs). Most existing GNN explanation methods identify the most important edges or nodes but fail to consider substructures, which are more important for graph data. One method considering subgraphs tries to search all possible subgraphs and identifies the most significant ones. However, the subgraphs identified may not be recurrent or statistically important for interpretation. This work proposes a novel method, named MotifExplainer, to explain GNNs by identifying important motifs, which are recurrent and statistically significant patterns in graphs. Our proposed motif-based methods can provide better human-understandable explanations than methods based on nodes, edges, and regular subgraphs. Given an instance graph and a pre-trained GNN model, our method first extracts motifs in the graph using domain-specific motif extraction rules. Then, a motif embedding is encoded by feeding motifs into the pre-trained GNN. Finally, we employ an attention-based method to identify the most influential motifs as explanations for the prediction results. The empirical studies on both synthetic and real-world datasets demonstrate the effectiveness of our method.", "title_embedding_index": 8764, "title_abs_embedding_index": 8789}, {"title": "LeMoLE: LLM-enhanced Mixture of Linear Experts for Time Series Forecasting", "link_suffix": "/forum?id=ERBm5WK8nq", "link": "https://openreview.net/forum?id=ERBm5WK8nq", "pdf_link": "https://openreview.net/pdf?id=ERBm5WK8nq", "keywords": "time series", "abstract": "Recent research has shown that large language models (LLMs) can be effectively used for real-world time series forecasting due to their strong natural language understanding capabilities. However, aligning time series into semantic spaces of LLMs comes with high computational costs and inference complexity, particularly for long-range time series generation. Building on recent advancements in using linear models for time series, this paper introduces an LLM-enhanced mixture of linear experts for precise and efficient time series forecasting. This approach involves developing a mixture of linear experts with multiple lookback lengths and a new multimodal fusion mechanism. The use of a mixture of linear experts is efficient due to its simplicity, while the multimodal fusion mechanism adaptively combines multiple linear experts based on the learned features of the text modality from pre-trained large language models. In experiments, we rethink the need to align time series to LLMs by existing time-series large language models and further discuss their efficiency and effectiveness in time series forecasting. Our experimental results show that the proposed LeMoLE model presents lower prediction errors and higher computational efficiency than existing LLM models.", "title_embedding_index": 8765, "title_abs_embedding_index": 8790}, {"title": "Expected Sliced Transport Plans", "link_suffix": "/forum?id=P7O1Vt1BdU", "link": "https://openreview.net/forum?id=P7O1Vt1BdU", "pdf_link": "https://openreview.net/pdf?id=P7O1Vt1BdU", "keywords": "Optimal Transport, Sliced Wasserstein, Transportation Plan, Probability Metrics", "abstract": "The optimal transport (OT) problem has gained significant traction in modern machine learning for its ability to: (1) provide versatile metrics, such as Wasserstein distances and their variants, and (2) determine optimal couplings between probability measures. To reduce the computational complexity of OT solvers, methods like entropic regularization and sliced optimal transport have been proposed. The sliced OT framework improves efficiency by comparing one-dimensional projections (slices) of high-dimensional distributions. However, despite their computational efficiency, sliced-Wasserstein approaches lack a transportation plan between the input measures, limiting their use in scenarios requiring explicit coupling. In this paper, we address two key questions: Can a transportation plan be constructed between two probability measures using the sliced transport framework? If so, can this plan be used to define a metric between the measures? We propose a \u2018lifting\u2019 operation to extend one-dimensional optimal transport plans back to the original space of the measures. By computing the expectation of these lifted plans, we derive a new transportation plan, termed expected sliced transport (EST) plans. We further prove that using the EST plan to weight the sum of the individual Euclidean costs $|x - y|^p$ for moving from $x$ to $y$ results in a valid metric between the input discrete probability measures. Finally, we demonstrate the connection between our approach and the recently proposed min-SWGG, along with illustrative numerical examples that support our theoretical findings.", "title_embedding_index": 8766, "title_abs_embedding_index": 8791}, {"title": "CodeMMLU: A Multi-Task Benchmark for Assessing Code Understanding Capabilities of CodeLLMs", "link_suffix": "/forum?id=CahIEKCu5Q", "link": "https://openreview.net/forum?id=CahIEKCu5Q", "pdf_link": "https://openreview.net/pdf?id=CahIEKCu5Q", "keywords": "LLM, CodeLLM, Benchmark, Evaluate, Code Comprehension", "abstract": "Recent advancements in Code Large Language Models (CodeLLMs) have primarily been evaluated through code generation tasks, overlooking other crucial aspects of code comprehension. To address this limitation, we introduce CodeMMLU, a comprehensive multiple-choice question-answer benchmark designed to assess the depth of code and software knowledge in LLMs. Comprising over 10,000 questions from diverse sources, CodeMMLU covers a wide range of tasks, including code analysis, defect detection, and software engineering principles across multiple programming languages. Our benchmark evaluates LLMs' ability to reason about code rather than simply generate it, providing insights into models' understanding of complex software concepts and systems. Our extensive evaluation demonstrates that CodeMMLU is challenging even for state-of-the-art models, exposing gaps in understanding beyond code generation tasks alone. By emphasizing the important connection between code comprehension and effective code generation, CodeMMLU serves as a valuable tool for driving progress in AI-assisted software development, aiming to produce more capable and reliable coding assistants.", "title_embedding_index": 8767, "title_abs_embedding_index": 8792}, {"title": "LLM-as-a-Judge & Reward Model: What They Can and Cannot Do", "link_suffix": "/forum?id=QhsbF2RZeu", "link": "https://openreview.net/forum?id=QhsbF2RZeu", "pdf_link": "https://openreview.net/pdf?id=QhsbF2RZeu", "keywords": "reward modeling, meta-evaluation, llm-as-a-judge", "abstract": "LLM-as-a-Judge and reward models are widely used alternatives of multiple-choice questions or human annotators for large language model (LLM) evaluation. Their efficacy shines in evaluating long-form responses, serving a critical role as evaluators of leaderboards and as proxies to align LLMs via reinforcement learning. However, despite their popularity, their effectiveness in diverse contexts, such as non-English prompts, factual verification, or challenging questions, remains unexplored. In this paper, we conduct a comprehensive analysis of automated evaluators, reporting several key findings on their behavior. First, we discover that English evaluation capabilities significantly influence language-specific evaluation capabilities, often more than the language proficiency itself, enabling evaluators trained in English to easily transfer their skills to other languages. Second, we identify critical shortcomings, where LLMs fail to detect and penalize errors,  such as factual inaccuracies, cultural misrepresentations, and the presence of unwanted language. Finally, we find that state-of-the-art evaluators struggle with challenging prompts, in either English or Korean, underscoring their limitations in assessing or generating complex reasoning questions. We release the dataset and codes used.", "title_embedding_index": 8768, "title_abs_embedding_index": 8793}, {"title": "Ensuring Fair Comparisons in Time Series Forecasting: Addressing Quality Issues in Three Benchmark Datasets", "link_suffix": "/forum?id=X8aFMdXk3N", "link": "https://openreview.net/forum?id=X8aFMdXk3N", "pdf_link": "https://openreview.net/pdf?id=X8aFMdXk3N", "keywords": "Time Series; Dataset Quality; Fair Comparisons; Benchmark Datasets", "abstract": "Time series forecasting (TSF) is critical in numerous applications; however, unlike other AI domains where benchmark datasets are meticulously standardized, TSF datasets often suffer from data inconsistencies, missing values, and improper temporal splits. These issues have an impact on model performance and evaluation. This paper addresses these challenges by proposing inconsistency-free versions of three well-known TSF datasets. Our methodology involves identifying and correcting data inconsistencies using a combination of linear interpolation and context-aware imputation strategies. Additionally, we introduce a novel cycle-inclusive data splitting method, which respects the longest cycle in each dataset, ensuring that models are evaluated over meaningful temporal patterns. Through extensive testing of multiple transformer-based models, we demonstrate that our revised datasets and cycle-inclusive splitting lead to more accurate and interpretable forecasting results, as well as fairer comparison of TSF models. Finally, our findings highlight the need for proper dataset refinement and tailored data splitting strategies in TSF tasks, and pave the way for future work in the development of more robust forecasting benchmarks.", "title_embedding_index": 8769, "title_abs_embedding_index": 8794}, {"title": "CBF-LLM: Safe Control for LLM Alignment", "link_suffix": "/forum?id=fvo6q86NKG", "link": "https://openreview.net/forum?id=fvo6q86NKG", "pdf_link": "https://openreview.net/pdf?id=fvo6q86NKG", "keywords": "LLM, alignment, control barrier function", "abstract": "This paper proposes a control-based framework for aligning large language models (LLMs) by leveraging a control barrier function (CBF) to ensure user-desirable text generation. \nThe presented framework applies the CBF safety filter to the predicted token generated from the baseline LLM, to intervene in the generated text.\nThe safety filter includes two significant advantages:\nthis safety filter is an add-on type, allowing it to be used for alignment purposes without fine-tuning the baseline LLM,\nand if there is an evaluation model regarding the desired alignment, it can be directly applied to the filter design.\nThe overall text-generation system is implemented with Llama 3 and a BERT model, aiming to generate positive text.\nFinally, further applications and limitations of the CBF-LLM for other alignment tasks, including topic-keeping and hallucination mitigating, are discussed.", "title_embedding_index": 8770, "title_abs_embedding_index": 8795}, {"title": "Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling", "link_suffix": "/forum?id=dOAkHmsjRX", "link": "https://openreview.net/forum?id=dOAkHmsjRX", "pdf_link": "https://openreview.net/pdf?id=dOAkHmsjRX", "keywords": "Continual Learning, Lifelong Learning", "abstract": "The majority of online continual learning (CL) advocates single-epoch training and imposes restrictions on the size of replay memory.\nHowever, single-epoch training would incur a different amount of computations per CL algorithm, and the additional storage cost to store logit or model in addition to replay memory is largely ignored in calculating the storage budget.\nArguing different computational and storage budgets hinder fair comparison among CL algorithms in practice, we propose to use floating point operations (FLOPs) and total memory size in Byte as a metric for computational and memory budgets, respectively, to compare and develop CL algorithms in the same \"total resource budget\".\nTo improve a CL method in a limited total budget, we propose adaptive layer freezing that does not update the layers for less informative batches to reduce computational costs with a negligible loss of accuracy.\nIn addition, we propose a memory retrieval method that allows the model to learn the same amount of knowledge as using random retrieval in fewer iterations.\nEmpirical validations on the CIFAR-10/100, CLEAR-10/100, and ImageNet-1K datasets demonstrate that the proposed approach outperforms the state-of-the-art methods within the same total budget.", "title_embedding_index": 8771, "title_abs_embedding_index": 8796}, {"title": "MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation", "link_suffix": "/forum?id=vue9P1Ypk6", "link": "https://openreview.net/forum?id=vue9P1Ypk6", "pdf_link": "https://openreview.net/pdf?id=vue9P1Ypk6", "keywords": "Model-level explanation, Graph Neural Networks, Motif", "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in molecular tasks, yet their interpretability remains challenging. Traditional model-level explanation methods like XGNN and GNNInterpreter often fail to identify valid substructures like rings, leading to questionable interpretability. This limitation stems from XGNN's atom-by-atom approach and GNNInterpreter's reliance on average graph embeddings, which overlook the essential structural elements crucial for molecules. To address these gaps, we introduce an innovativeMotif-bAsedGNNExplainer (MAGE) that uses motifs as fundamental units for generating explanations. Our approach begins with extracting potential motifs through a motif decomposition technique. Then, we utilize an attention-based learning method to identify class-specific motifs. Finally, we employ a motif-based graph generator for each class to create molecular graph explanations based on these class-specific motifs. This novel method not only incorporates critical substructures into the explanations but also guarantees their validity, yielding results that are human-understandable. Our proposed method's effectiveness is demonstrated through quantitative and qualitative assessments conducted on six real-world molecular datasets.", "title_embedding_index": 8772, "title_abs_embedding_index": 8797}, {"title": "Flat-LoRA: Low-Rank Adaption over a Flat Loss Landscape", "link_suffix": "/forum?id=w0389y0W9D", "link": "https://openreview.net/forum?id=w0389y0W9D", "pdf_link": "https://openreview.net/pdf?id=w0389y0W9D", "keywords": "low-rank adaption, flat minima, efficient training", "abstract": "Fine-tuning large-scale pre-trained models is prohibitively expensive in terms of computational and memory costs. Low-Rank Adaptation (LoRA), a popular Parameter-Efficient Fine-Tuning (PEFT) method, provides an efficient way to fine-tune models by optimizing only a low-rank matrix. Despite recent progress made in improving LoRA's performance, the connection between the LoRA optimization space and the original full parameter space is often overlooked. A solution that appears flat in the LoRA space may exist sharp directions in the full parameter space, potentially harming generalization performance. In this paper, we propose Flat-LoRA, an efficient approach that seeks a low-rank adaptation located in a flat region of the full parameter space. Instead of relying on the well-established sharpness-aware minimization approach, which can incur significant computational and memory burdens, we utilize random weight perturbation with a Bayesian expectation loss objective to maintain training efficiency and design a refined perturbation generation strategy for improved performance. Experiments on natural language processing and image classification tasks with various architectures demonstrate the effectiveness of our approach.", "title_embedding_index": 8773, "title_abs_embedding_index": 8798}, {"title": "Prevalence of Negative Transfer in Continual Reinforcement Learning: Analyses and a Simple Baseline", "link_suffix": "/forum?id=KAIqwkB3dT", "link": "https://openreview.net/forum?id=KAIqwkB3dT", "pdf_link": "https://openreview.net/pdf?id=KAIqwkB3dT", "keywords": "continual reinforcement learning, negative transfer, plasticity loss", "abstract": "We argue that the negative transfer problem occurring when the new task to learn arrives is an important problem that needs not be overlooked when developing effective Continual Reinforcement Learning (CRL) algorithms. Through comprehensive experimental validation, we demonstrate that such issue frequently exists in CRL and cannot be effectively addressed by several recent work on either mitigating plasticity loss of RL agents or enhancing the positive transfer in CRL scenario. To that end, we develop Reset & Distill (R&D), a simple yet highly effective baseline method, to overcome the negative transfer problem in CRL. R&D combines a strategy of resetting the agent's online actor and critic networks to learn a new task and an offline learning step for distilling the knowledge from the online actor and previous expert's action probabilities. We carried out extensive experiments on long sequence of Meta World tasks and show that our simple baseline method consistently outperforms recent approaches, achieving significantly higher success rates across a range of tasks. Our findings highlight the importance of considering negative transfer in CRL and emphasize the need for robust strategies like R&D to mitigate its detrimental effects.", "title_embedding_index": 8774, "title_abs_embedding_index": 8799}]
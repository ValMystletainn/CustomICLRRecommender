[
    {
        "title": "Intrinsic-ControlNet : A Generative Rendering Approach to Render Any Real and Unreal",
        "link_suffix": "/forum?id=m0Su4pLV6W",
        "link": "https://openreview.net/forum?id=m0Su4pLV6W",
        "pdf_link": "https://openreview.net/pdf?id=m0Su4pLV6W",
        "keywords": "generative rendering, diffusion model, photorealistic images",
        "abstract": "Rendering highly realistic images from 3D assets is one of the most persistent challenges of the graphics community, which is procedurally conducted by simulating real-world geometry, material, and light transportation. However, such simulations are both burdensome and expensive. Recently, diffusion models have seen great success in realistic image generation by leveraging priors from large datasets of real-world images. Nonetheless, these generative models provide limited control over the output and, unlike graphic pipelines, cannot accurately integrate materials and geometric information for precise image synthesis. In this work, we propose a generative rendering framework, Intrinsic-ControlNet, that enables the generation of corresponding RGB images from 3D assets like a rendering engine by taking intrinsic images, e.g., material, normal, and structural information, as network inputs. We propose a novel multi-conditional control method that allows the model to accept any number of intrinsic images as input conditions. To mitigate bias from synthetic training data, we propose a new model architecture that allows appearance and structural conditions to be input separately into ControlNet, preserving the realism of appearance generation from real data while maintaining structural control capabilities from synthetic data. Experiments and user studies demonstrate that our method can generate controllable, highly realistic images based on the input intrinsic images."
    },
    {
        "title": "Solving the Fuzzy Job Shop Scheduling Problem via Learning Approaches",
        "link_suffix": "/forum?id=ziB549CQ30",
        "link": "https://openreview.net/forum?id=ziB549CQ30",
        "pdf_link": "https://openreview.net/pdf?id=ziB549CQ30",
        "keywords": "Fuzzy job shop scheduling problem, neural combinatorial optimization, self-supervised learning",
        "abstract": "The fuzzy job shop scheduling problem (FJSSP) emerges as an innovative extension to the conventional job shop scheduling problem (JSSP), incorporating a layer of uncertainty that aligns the model more closely with the complexities of real-world manufacturing environments. This enhancement, while enhancing its applicability, concurrently escalates the computational complexity of deriving solutions. In the domain of traditional scheduling, neural combinatorial optimization (NCO) has recently demonstrated remarkable efficacy. However, its application to the realm of fuzzy scheduling has been relatively unexplored. This paper aims to bridge this gap by investigating the feasibility of employing neural networks to assimilate and process fuzzy information for the resolution of FJSSP, thereby leveraging the advancements in NCO to enhance fuzzy scheduling methodologies. To this end, we present a self-supervised algorithm for the FJSSP (SS-FJSSP). This algorithm employs an iterative mechanism to refine pseudo-labels, progressively transitioning from suboptimal to optimal solutions. This innovative approach adeptly circumvents the significant challenge of procuring true labels, a common challenge in NCO frameworks. Experiments demonstrate that our SS-FJSSP algorithm yields results on a par with the state-of-the-art methods while achieving a remarkable reduction in computational time, specifically being two orders of magnitude faster."
    },
    {
        "title": "Semi-Supervised CLIP Training by Enforcing Semantic and Trapezoidal Consistency",
        "link_suffix": "/forum?id=97D725GJtQ",
        "link": "https://openreview.net/forum?id=97D725GJtQ",
        "pdf_link": "https://openreview.net/pdf?id=97D725GJtQ",
        "keywords": "Semi-supervised learning, Vision-language pre-training",
        "abstract": "Vision-language pre-training models, such as CLIP, have demonstrated strong capability in rapidly adapting to downstream tasks through fine-tuning, and have been widely applied across various tasks. However, when the downstream tasks are constrained by limited image-text paired data, CLIP struggles to effectively address the domain gap between the pre-training and the target tasks. To address this limitation, we propose a novel semi-supervised CLIP training method coined SemiCLIP that leverages a small amount of image-text pairs alongside a large volume of images without text descriptions to enhance CLIP\u2019s cross-modal alignment. To effectively utilize unlabeled images, we introduce semantic concept mining to improve task-specific visual representations by matching images with relevant concepts mined from labeled data. Leveraging matched semantic concepts, we construct learnable surrogate captions for unlabeled images and optimize a trapezoidal consistency to regulate the geometric structure of image-text pairs in the representation space. Experimental results demonstrate that our approach significantly improves the adaptability of CLIP in target tasks with limited labeled data, achieving gains ranging from 1.72% -- 6.58% for zero-shot classification accuracy and 2.32% -- 3.23% for image-text retrieval performance on standard benchmarks. The source code is provided in the supplementary material."
    },
    {
        "title": "Learning Successor Features with Distributed Hebbian Temporal Memory",
        "link_suffix": "/forum?id=wYJII5BRYU",
        "link": "https://openreview.net/forum?id=wYJII5BRYU",
        "pdf_link": "https://openreview.net/pdf?id=wYJII5BRYU",
        "keywords": "temporal memory, successor features, online learning, Hebbian learning",
        "abstract": "This paper presents a novel approach to address the challenge of online temporal memory learning for decision-making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism and a multicomponent neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Features (SF). Inspired by neurophysiological models of the neocortex, the algorithm utilizes distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning process of traditional temporal memory algorithms like RNN and HMM. Experimental results demonstrate that DHTM outperforms LSTM and a biologically inspired HMM-like algorithm, CSCG, in the case of non-stationary datasets. Our findings suggest that DHTM is a promising approach for addressing the challenges of online sequence learning and planning in dynamic environments."
    },
    {
        "title": "AttnInput: Revolutionizing Pinyin Input with Context-Aware RWKV Language Models",
        "link_suffix": "/forum?id=9OxTqscUwi",
        "link": "https://openreview.net/forum?id=9OxTqscUwi",
        "pdf_link": "https://openreview.net/pdf?id=9OxTqscUwi",
        "keywords": "Pinyin Input Method, IME, LLM, RWKV, Ladder Side-Tuning",
        "abstract": "The Pinyin Input Method Engine (IME) is widely used for inputting Chinese characters, but effectively integrating it with powerful large language models (LLMs) remains a challenge due to issues such as semantic discontinuity and inefficient training. This paper presents AttnInput, a novel approach that leverages the strengths of the RWKV language model, specifically its linear computational complexity and infinite context length, to enhance Pinyin IME. Our method integrates Pinyin information directly into the internal state of RWKV through a lightweight side network, effectively addressing the semantic discontinuity issue faced by previous LLM-based IMEs. Furthermore, AttnInput utilizes a pre-training strategy, significantly reducing training data and computational costs compared to previous methods. Experimental results demonstrate that AttnInput achieves state-of-the-art performance on abbreviated Pinyin input, especially as the Pinyin sequence length increases. This efficient design allows us to scale up to larger models and incorporate longer contexts, further improving accuracy and user experience."
    },
    {
        "title": "Spectral Highways: Injecting Homophily into Heterophilic Graphs",
        "link_suffix": "/forum?id=N3EFTVCFWX",
        "link": "https://openreview.net/forum?id=N3EFTVCFWX",
        "pdf_link": "https://openreview.net/pdf?id=N3EFTVCFWX",
        "keywords": "Data augmentation, Graph representation learning, GNNs, Homophily, Heterophily",
        "abstract": "It is widely assumed that standard GNNs perform better on graphs with high homophily, leading to the development of specialised algorithms for heterophilic datasets in recent years. In this work, we both challenge and leverage this assumption. Rather than creating new algorithms, we emphasise the importance of understanding and enriching the data. We introduce a novel data engineering technique, \\textit{Spectral Highways}, that enhances the performance of both heterophilic and non-heterophilic GNNs on heterophilic datasets. Our method augments a given heterophilic graph by adding supernodes, thereby creating a network of highways connecting spectral clusters in the graph. It facilitates additional paths to bring similar nodes closer than dissimilar ones by reducing the average shortest path lengths. We draw both intuitive and empirical connections between the relative decreases in intraclass and interclass average shortest path lengths and shifts in the graph's homophily levels, providing a novel perspective that extends beyond traditional homophily measures. We conduct extensive experiments on seven heterophilic datasets using various GNN architectures and also compare with data-centric techniques, demonstrating significant improvements in node classification performance. Furthermore, our empirical findings highlight the strong sensitivity of several recent GNNs to the random seed used for data splitting, underscoring the importance of this often-overlooked factor in GNN evaluation."
    },
    {
        "title": "FedQLoRA: Federated Quantization-Aware LoRA for Large Language Models",
        "link_suffix": "/forum?id=uWMQxtmyYz",
        "link": "https://openreview.net/forum?id=uWMQxtmyYz",
        "pdf_link": "https://openreview.net/pdf?id=uWMQxtmyYz",
        "keywords": "Quantization, LoRA, Large Language Models, Federated Learning",
        "abstract": "Large language models (LLMs) with billions of parameters have achieved remarkable success across various applications, but they require substantial computational resources and large datasets. While parameter-efficient fine-tuning methods like LoRA and QLoRA have significantly reduced computational costs and memory usage, robustly training LLMs for individual clients with datasets distributed on isolated devices remains challenging. To address this, recent work has explored the use of federated learning (FL) to collaboratively train LLM adapters on distributed private data, thereby avoiding the high computational and communication costs. In these approaches, the LLMs are frozen, and the adapters are collaboratively trained through adapter-sharing and aggregation methods. However, in this paper, we identify a significant issue: these approaches may suffer from quantization bias when clients operate with different levels of quantization on LLMs. To resolve this, we propose a novel framework called Federated Quantization-Aware LoRA (FedQLoRA), which estimates the quantization error and separates it from the LoRA adapter trained on local data via a quantization-aware adapter. Additionally, we address the heterogeneity bias problem that arises from severe data heterogeneity among clients, such as in non-IID settings. We propose an iterative version of the framework that improves both the dynamic quantization-aware adapter and the LoRA adapter alternately within the FL framework. We conduct extensive experiments to validate the performance of our proposed framework."
    },
    {
        "title": "Divergence of Neural Tangent Kernel in Classification Problems",
        "link_suffix": "/forum?id=VEJzjAvaIy",
        "link": "https://openreview.net/forum?id=VEJzjAvaIy",
        "pdf_link": "https://openreview.net/pdf?id=VEJzjAvaIy",
        "keywords": "neural tangent kernel, neural network, cross-entropy loss, classification problem",
        "abstract": "This paper primarily investigates the convergence of the Neural Tangent Kernel (NTK) in classification problems. This study firstly show the strictly positive definiteness of NTK of multi-layer fully connected neural networks and residual neural networks. Then, through a contradiction argument,  it indicates that, during training with the cross-entropy loss function, the neural network parameters diverge due to the strictly positive definiteness of the NTK. Consequently, the empirical NTK does not consistently converge but instead diverges as time approaches infinity. This finding implies that NTK theory is not applicable in this context, highlighting significant theoretical implications for the study of neural networks in classification problems. These results can also  be easily generalized to other network structures, provided that the NTK is strictly positive definite."
    },
    {
        "title": "Quest: Query-centric Data Synthesis Approach for Long-context Scaling of Large Language Model",
        "link_suffix": "/forum?id=sAYnDWaGd5",
        "link": "https://openreview.net/forum?id=sAYnDWaGd5",
        "pdf_link": "https://openreview.net/pdf?id=sAYnDWaGd5",
        "keywords": "longcontext, pre-training, scaling",
        "abstract": "Recent advancements in large language models (LLMs) have highlighted the importance of extending context lengths for handling complex tasks. While traditional methods for training on long contexts often use filtered long documents, these approaches lead to domain imbalances, limiting model performance. To address this, techniques like random document concatenation (Standard) and similarity-based methods (KNN, ICLM) have been developed. However, they either sacrifice semantic coherence or diversity. To balance both aspects, we introduce Quest, a query-centric data synthesis method aggregating semantically relevant yet diverse documents. Quest uses a generative model to predict potential queries for each document, grouping documents with similar queries and keywords. Extensive experiments demonstrate Quest's superior performance on long-context tasks, achieving remarkable results with context lengths of up to 1M tokens and confirming its scalability across various model sizes."
    },
    {
        "title": "GASLITEing the Retrieval: Poisoning Knowledge DBs to Mislead Embedding-based Search",
        "link_suffix": "/forum?id=LBd87fWerd",
        "link": "https://openreview.net/forum?id=LBd87fWerd",
        "pdf_link": "https://openreview.net/pdf?id=LBd87fWerd",
        "keywords": "Adversarial Machine Learning, AI Safety, Security, NLP, Retrieval, Text Representations, Text Embeddings",
        "abstract": "Embedding-based text retrieval\u2014retrieval of relevant passages from knowledge databases (KDBs) via deep learning encodings\u2014has emerged as a powerful method attaining state-of-the-art search results and popularizing the use of Retrieval Augmented Generation (RAG). Still, like other search methods, embedding-based retrieval may be susceptible to search-engine optimization (SEO) attacks, where adversaries promote malicious content by introducing adversarial passages to KDBs. To faithfully assess the susceptibility of such systems to SEO, this work proposes theGASLITEattack, a mathematically principled gradient-based search method for generating adversarial passages without relying on the KDB content or modifying the model. Notably,GASLITE's passages(1)carry adversary-chosen information while(2)achieving high retrieval ranking for a selected query distribution when inserted to KDBs. We extensively evaluatedGASLITE, testing it on nine advanced models and comparing it to three baselines under varied threat models, focusing on one well-suited for realistic adversaries targeting queries on a specific concept (e.g., a public figure). We foundGASLITEconsistently outperformed baselines by $\\ge$140% success rate, in all settings. Particularly, adversaries usingGASLITErequire minimal effort to manipulate search results\u2014by injecting a negligible amount of adversarial passages ($\\le$0.0001% of the KDBs), they could make them visible in the top-10 results for 61-100% of unseen concept-specific queries against most evaluated models. Among other contributions, our work also identifies several factors that may influence model susceptibility to SEO, including the embedding space's geometry. We will make our code publicly available."
    },
    {
        "title": "Robust LLM safeguarding via refusal feature adversarial training",
        "link_suffix": "/forum?id=s5orchdb33",
        "link": "https://openreview.net/forum?id=s5orchdb33",
        "pdf_link": "https://openreview.net/pdf?id=s5orchdb33",
        "keywords": "large language models, adversarial robustness, representation analysis, mechanistic interpretability",
        "abstract": "Large language models (LLMs) are vulnerable to adversarial attacks that can elicit harmful responses. Defending against such attacks remains challenging due to the opacity of jailbreaking mechanisms and the high computational cost of training LLMs robustly. We demonstrate that adversarial attacks share a universal mechanism for circumventing LLM safeguards that works by ablating a dimension in the residual stream embedding space called the refusal feature. We further show that the operation of refusal feature ablation (RFA) approximates the worst-case perturbation of offsetting model safety. Based on these findings, we propose Refusal Feature Adversarial Training (ReFAT), a novel algorithm that efficiently performs LLM adversarial training by simulating the effect of input-level attacks via RFA. Experiment results show that ReFAT significantly improves the robustness of three popular LLMs against a wide range of adversarial attacks, with considerably less computational overhead compared to existing adversarial training methods."
    },
    {
        "title": "Mechanism-Empowered Multivariate Time Series Forecasting Model: Application to Tuberculosis Prediction",
        "link_suffix": "/forum?id=V83xzYnZ5q",
        "link": "https://openreview.net/forum?id=V83xzYnZ5q",
        "pdf_link": "https://openreview.net/pdf?id=V83xzYnZ5q",
        "keywords": "Multivariate Time Series Forecasting Model, Spatiotemporal framework, Source reduction, mechanism-driven dimensionality reduction",
        "abstract": "Among the current global health challenges, tuberculosis, as a highly contagious chronic disease, remains one of the major public health problems worldwide. Despite significant progress made in the past decades, new challenges, including systematic and effective downscaling, accurate prediction of disease incidence, and implementation of source reduction measures, have added to the difficulty of tuberculosis control. In view of the limitations of the recently proposed EIGHT prediction models in terms of prediction accuracy, this study adopts the Learnable Decomposition and Dual Focus Module Model (Leddam) and then introduces a novel mechanism-supported multivariate spatiotemporal series framework, termed LCHHA-Leddam, to address the challenges in tuberculosis forecasting through an investigation of coal power generation in China. This framework substantially simplifies the complexity of tuberculosis prediction, enhances accurate dimensionality reduction, and improves traceability. It also enhances the explanatory power and accuracy of the Leddam model in the field of tuberculosis prediction. This study provides a fresh perspective for enhancing epidemic forecasting and exploring source reduction measures for industrial activities, demonstrating the feasibility of AI-assisted public health strategies and green production."
    },
    {
        "title": "MoTE: Mixture of Task Experts for Embedding Models",
        "link_suffix": "/forum?id=uHTmx0nRfX",
        "link": "https://openreview.net/forum?id=uHTmx0nRfX",
        "pdf_link": "https://openreview.net/pdf?id=uHTmx0nRfX",
        "keywords": "Embedding Models, Representation Learning, Mixture of Experts, Retrieval Augmented Generation, RAG, Search, Clustering, Classification",
        "abstract": "Dense embeddings are a crucial component in various natural language processing applications, serving as the foundation for downstream tasks such as Retrieval Augmented Generation (RAG), search, classification, and clustering. To improve the performance of dense embeddings, recent approaches have focused on conditioning their representation with task information (e.g., by adding a task-specific text prefix), which allows to generate embeddings that take the task into account. This paper builds on this work and develops an approach that performs task conditioning by introducing a new architecture that has a dedicated set of parameters for each of the tasks. We refer to this model a Mixture of Task Experts (MoTE). For training, we introduce a task-aware training approach that allows us to optimize the training hyper-parameter for each task. Experiments on highly competitive tasks like MTEB with $56$ datasets across $7$ tasks show that, on average, MoTE achieves $1.62$ higher NDCG@10 on Retrieval datasets, $1.54$ higher MAP on Reranking datasets and $0.65$ higher overall performance across tasks when compared to contemporary approaches leveraging the same information."
    },
    {
        "title": "The Rise and Down of Babel Tower: Investigating the Evolution Process of Multilingual Code Large Language Model",
        "link_suffix": "/forum?id=eznTVIM3bs",
        "link": "https://openreview.net/forum?id=eznTVIM3bs",
        "pdf_link": "https://openreview.net/pdf?id=eznTVIM3bs",
        "keywords": "Large Language Model, Multilingual, Code",
        "abstract": "Large language models (LLMs) have shown significant multilingual capabilities. However, the mechanisms underlying the development of these capabilities during pre-training are not well understood. In this paper, we use code LLMs as an experimental platform to explore the evolution of multilingual capabilities in LLMs during the pre-training process. Based on our observations, we propose the Babel Tower Hypothesis, which describes the entire process of LLMs acquiring new language capabilities. During the learning process, multiple languages initially share a single knowledge system dominated by the primary language and gradually develop language-specific knowledge systems. We then validate the above hypothesis by tracking the internal states of the LLM using specific methods. Experimental results show that the internal state changes of the LLM are consistent with our Babel Tower Hypothesis. Building on these insights, we propose a novel method to construct an optimized pre-training corpus for multilingual code LLMs, which significantly outperforms LLMs trained on the original corpus. The proposed Babel Tower Hypothesis provides new insights into designing pre-training data distributions to achieve optimal multilingual capabilities in LLMs."
    },
    {
        "title": "Boosting Offline Multi-Objective Reinforcement Learning via Preference Conditioned Diffusion Models",
        "link_suffix": "/forum?id=XCUTFbC3Rh",
        "link": "https://openreview.net/forum?id=XCUTFbC3Rh",
        "pdf_link": "https://openreview.net/pdf?id=XCUTFbC3Rh",
        "keywords": "Diffusion, Offline Reinforcement Learning, Multi-Objective Reinforcement Learning",
        "abstract": "Multi-objective reinforcement learning (MORL) addresses sequential decision-making problems with multiple objectives by learning policies optimized for diverse preferences. While traditional methods necessitate costly online interaction with the environment, recent approaches leverage static datasets containing pre-collected trajectories, making offline MORL the preferred choice for real-world applications. However, existing offline MORL techniques suffer from limited expressiveness and poor generalization on out-of-distribution (OOD) preferences. To overcome these limitations, we propose Diffusion-based  Multi-Objective Reinforcement Learning (DiffMORL), a generalizable diffusion-based planning framework for MORL. Leveraging the strong expressiveness and generation capability of diffusion models, DiffMORL further boosts its generalization through  offline data mixup, which mitigates the memorization phenomenon and facilitates feature learning by data augmentation. By training on the augmented data, DiffMORL is able to condition on a given preference, whether in-distribution or OOD, to plan the desired trajectory and extract the corresponding action. Experiments conducted on the D4MORL benchmark demonstrate that DiffMORL  achieves state-of-the-art results across nearly all tasks. Notably, it surpasses the best baseline on most tasks, underscoring its remarkable generalization ability in offline MORL scenarios."
    },
    {
        "title": "Unsupervised Zero-Shot Reinforcement Learning via Dual-Value Forward-Backward Representation",
        "link_suffix": "/forum?id=0QnKnt411O",
        "link": "https://openreview.net/forum?id=0QnKnt411O",
        "pdf_link": "https://openreview.net/pdf?id=0QnKnt411O",
        "keywords": "unsupervised reinforcement learning, zero-shot generalization, skill discovery, successor representation",
        "abstract": "Online unsupervised reinforcement learning (URL) can discover diverse skills via reward-free pre-training and exhibits impressive downstream task adaptation abilities through further fine-tuning.\nHowever, online URL methods face challenges in achieving zero-shot generalization, i.e., directly applying pre-trained policies to downstream tasks without additional planning or learning.\nIn this paper, we propose a novel Dual-Value Forward-Backward representation (DVFB) framework with a contrastive entropy intrinsic reward to achieve both zero-shot generalization and fine-tuning adaptation in online URL.\nOn the one hand, we demonstrate that poor exploration in forward-backward representations can lead to limited data diversity in online URL, impairing successor measures, and ultimately constraining generalization ability.\nTo address this issue, the DVFB framework learns successor measures through a skill value function while promoting data diversity through an exploration value function, thus enabling zero-shot generalization.\nOn the other hand, and somewhat surprisingly, by employing a straightforward dual-value fine-tuning scheme combined with a reward mapping technique, the pre-trained policy further enhances its performance through fine-tuning on downstream tasks, building on its zero-shot performance.\nThrough extensive multi-task generalization experiments, DVFB demonstrates both superior zero-shot generalization (outperforming on all 12 tasks) and fine-tuning adaptation (leading on 10 out of 12 tasks) abilities, surpassing state-of-the-art URL methods."
    },
    {
        "title": "Can Mamba Always Enjoy the \"Free Lunch\"?",
        "link_suffix": "/forum?id=UYarAv7rUx",
        "link": "https://openreview.net/forum?id=UYarAv7rUx",
        "pdf_link": "https://openreview.net/pdf?id=UYarAv7rUx",
        "keywords": "Mamba, Expressive Power, Chain of Thought",
        "abstract": "Transformers have been the cornerstone of current Large Language Models (LLMs); however, its linear growth in overhead during inference with respect to sequence length poses challenges for modeling long sequences. In this context, Mamba has gradually attracted attention due to its constant-level size during inference and existing empirical results have shown that it can perform comparably to Transformers in sequence modeling while offering significant savings. However, one may ask that, can Mamba always enjoy the ``free lunch\"? In this paper, we focus on analyzing the expressive ability of Mamba from a theoretical standpoint. First, inspired by the connection between Mamba and linear attention, we investigate potential shortcomings of the Mamba when performing the COPY operation. Our results indicate that Mamba with constant size may encounter bottlenecks when handling COPY, while it can achieve perfect performance when the size scales linearly with sequence length. Based on this observation, we analyze Mamba's ability to tackle DP problems when equipped with Chain of Thought (CoT). Our findings suggest that to solve arbitrary DP problems, the total cost of Mamba is comparable to standard and efficient Transformers. However, similar to efficient Transformers, when facing DP problems with favorable properties such as locality, Mamba can provide savings in overhead. Our results contribute to a deeper understanding of Mamba."
    },
    {
        "title": "Advancing African-Accented English Speech Recognition: Epistemic Uncertainty-Driven Data Selection for Generalizable ASR Models",
        "link_suffix": "/forum?id=MazxSMs6Hs",
        "link": "https://openreview.net/forum?id=MazxSMs6Hs",
        "pdf_link": "https://openreview.net/pdf?id=MazxSMs6Hs",
        "keywords": "low-resource African languages, uncertainty quantification, automatic speech recognition",
        "abstract": "Accents play a pivotal role in shaping human communication, enhancing our ability to convey and comprehend messages with clarity and cultural nuance. While there has been significant progress in Automatic Speech Recognition (ASR), African-accented English ASR has been understudied due to a lack of training datasets, which are often expensive to create and demand colossal human labor. Combining several active learning paradigms and the core-set approach, we propose a new multi-rounds adaptation process that uses epistemic uncertainty to automate the annotation process, significantly reducing the associated costs and human labor. This novel method streamlines data annotation and strategically selects data samples that contribute most to model uncertainty, enhancing training efficiency. We define a new U-WER metric to track model adaptation to hard accents. We evaluate our approach across several domains, datasets, and high-performing speech models. Our results show that our approach leads to a 27% WER relative average improvement while requiring, on average, 45% less data than established baselines. Our approach also improves out-of-distribution generalization for very low-resource accents, demonstrating its viability for building generalizable ASR models in the context of accented African ASR. We open-source the code \n\\href{}{here}."
    },
    {
        "title": "Masked Mamba: An Efficient Self-Supervised Framework for Pathological Image Classification",
        "link_suffix": "/forum?id=V9UsZBbTvZ",
        "link": "https://openreview.net/forum?id=V9UsZBbTvZ",
        "pdf_link": "https://openreview.net/pdf?id=V9UsZBbTvZ",
        "keywords": "Pathological image classification, Mamba model, Self-supervised learning",
        "abstract": "Pathological image classification is one of the challenging tasks in the field of pathological imaging. The scarcity of high-quality annotated images, the high degree of similarity among pathological samples, the heavy reliance on specific regional areas, and the variability in stained sections all serve as tests of the performance of classifiers. Recently, the Mamba-based model has garnered unprecedented attention and has achieved exceptional performance across various tasks. However, employing visual Mamba in pathological classification does not address the aforementioned challenges. Therefore, in this work, we propose a novel architecture named Masked Mamba, which exhibits significant advantages in terms of low-cost inference and robust classification performance. It is based on two core designs. First, we developed a convolution-based Patch Ghosting aimed at enhancing the classification network's acquisition of specific local area features and its capability to capture multi-scale features by introducing residual connections of similar feature maps. Furthermore, we investigated the integration of Masked Autoencoders (MAE) and State Space Modules (SSM) to further emphasize local features in images and extract robust feature representations from varying staining and slicing conditions, compensating for the lack of high-quality annotated images. We validated our algorithm's performance using four publicly available pathological image datasets. The experimental results indicate that we achieved State-of-the-Art outcomes across these datasets."
    },
    {
        "title": "Does your model understand genes? A benchmark of gene properties for biological and text models",
        "link_suffix": "/forum?id=GDDqq0w6rs",
        "link": "https://openreview.net/forum?id=GDDqq0w6rs",
        "pdf_link": "https://openreview.net/pdf?id=GDDqq0w6rs",
        "keywords": "Benchmark, Data Sets or Data Repositories, Computational Biology and Bioinformatics",
        "abstract": "The application of deep learning for biology, including foundation models, has  increased significantly in recent years.\nSome models are text-based, while others are trained on the underlying biological data, especially omics data of various modalities. \nConsistently comparing the performance of deep learning models for biology has proven challenging due to the diversity of training data and downstream tasks. \nHere, we utilize the fact that many models operate on the level of genes and propose a unifying benchmark by defining hundreds of tasks based on ground-truth gene properties collected from professionally curated bioinformatics databases.We collect properties of five types: (1) genomic properties, including predicting which genes can be methylated or which are dose-dependent; (2) regulatory functions, evaluating how the genes participate in cellular regulatory processes; (3) localization, including identification of differential expression in different tissues or sub-cellular localization; (4) biological processes, including predicting gene involvement in pathways or disease prognostics; and (5) protein properties, including prediction of functional domains or post-translational modifications.\nThese properties are used to define binary, multi-label and multi-class classification tasks.\nTo create an architecture-agnostic benchmark we extract gene representation vectors from each model, including single-cell RNA-seq (scRNA) foundation models, large language models, protein language models, DNA foundation models, and classical baselines, and use them to train simple predictive models on the tasks.\nDepending on the model, we utilize the model's token-level embeddings of gene symbols or transform the gene symbol to an input appropriate for the model, i.e. a description of the gene for text models, the gene sequence for DNA models or amino acid sequences for the protein models.\nUsing these embeddings on the benchmark tasks, we create a detailed assessment of the relative performance of the different models.\nIn general, we find that text-based models and protein language models outperform the expression-based models on tasks related to genomic properties and regulatory functions, while expression-based models tend to outperform the others on localization tasks.\nWe also observe performance for the classical bag-of-words baseline that is similar to the large language models for many tasks.\nBy enabling broad systematic evaluation of diverse deep learning models in biology, this benchmark can help direct future research in artificial intelligence toward improved biological understanding and accelerated therapeutic discoveries.\nThe code and benchmark data can be extended to more models and tasks and is available on GitHub."
    },
    {
        "title": "A Pattern Language for Machine Learning Tasks",
        "link_suffix": "/forum?id=KXiQI6ggFc",
        "link": "https://openreview.net/forum?id=KXiQI6ggFc",
        "pdf_link": "https://openreview.net/pdf?id=KXiQI6ggFc",
        "keywords": "Category Theory, Interpretability, Compositionality, Machine Learning Theory, Formal Methods, Behaviour Modelling, Objective Function Analysis, Diagrammatic Reasoning",
        "abstract": "Objective functions impose equivalences we call \"tasks\" on composites of idealised learners. For these tasks, we develop a formal graphical language that aims to;\n(1) enable design and optimisation of behaviours model-agnostically;\n(2) offer a unified perspective of approaches in machine learning across domains;\n(3) import insights from theoretical computer science into practical machine learning.\nAs proof-of-concept, we exhibit a novel \"manipulator\" task that obtains a generative counterpart for a given classifier. We predict and subsequently demonstrate that the resulting models exhibit capabilities such as style transfer and interpretable latent-space formation in image domains. Our model-agnostic approach achieves this without the need for custom architectures, adversarial training, random sampling, or interventions on the data, hence enabling capable, small-scale, and training-stable models."
    },
    {
        "title": "To Code or Not To Code? Exploring Impact of Code in Pre-training",
        "link_suffix": "/forum?id=zSfeN1uAcx",
        "link": "https://openreview.net/forum?id=zSfeN1uAcx",
        "pdf_link": "https://openreview.net/pdf?id=zSfeN1uAcx",
        "keywords": "code data, pre-training, code pre-training",
        "abstract": "Including code in the pre-training data mixture, even for models not specifically designed for code, has become a common practice in LLMs pre-training. While there has been anecdotal consensus among practitioners that code data plays a vital role in general LLMs' performance, there is only limited work analyzing the precise impact of code on non-code tasks. In this work, we systematically investigate the impact of code data on general performance. We ask \u201cwhat is the impact of code data used in pre-training on a large variety of downstream tasks beyond code generation\u201d. We conduct extensive ablations and evaluate across a broad range of natural language reasoning tasks, world knowledge tasks, code benchmarks, and LLM-as-a-judge win-rates for models with sizes ranging from 470M to 2.8B parameters. Across settings, we find a consistent results that code is a critical building block for generalization far beyond coding tasks and improvements to code quality have an outsized impact across all tasks. In particular, compared to text-only pre-training, the addition of code results in up to relative increase of 8.2% in natural language (NL) reasoning, 4.2% in world knowledge, 6.6% improvement in generative win-rates, and a 12x boost in code performance respectively. Our work suggests investments in code quality and preserving code during pre-training have positive impacts."
    },
    {
        "title": "BAT: Backbone Augmented Training for Adaptations",
        "link_suffix": "/forum?id=Y96R2BOsKm",
        "link": "https://openreview.net/forum?id=Y96R2BOsKm",
        "pdf_link": "https://openreview.net/pdf?id=Y96R2BOsKm",
        "keywords": "Adaptation, Data Selection, Parameter Efficient Tuning, Regularization, Optimization, Dreambooth, LoRA",
        "abstract": "Adaptations have enabled efficient training for large backbone models such as diffusion models for image generation and transformer-based language models. While various adaptation techniques aim to maximize performance with minimal computational resources, limited data often leads to challenges like mode collapse, knowledge shift, and underperformance on each task, particularly for end users with greater reliance on adaptations. Recent efforts explicitly utilize backbone models to which the adaptations are applied, but these approaches frequently lack solid theoretical foundations or controllable standards. To address this, we introduce Backbone Augmented Training (BAT), a simple scheme that selects and injects backbone training data into adaption training. We provide theoretical proof that BAT achieves a faster convergence rate to optimal adaptation parameters than standard adaptation methods, regardless of the adaptation type. Further, we empirically validate that BAT leads to improved results in human evaluations and benchmark scores. We demonstrate this through (i) mathematically proving the scheme's efficiency and robustness in adaptation training, and (ii) conducting experiments that compare BAT to standard adaptations, showing significant improvements in both quantitative metrics and qualitative results."
    },
    {
        "title": "CHARGE DIRICHLET ENERGY: Geometric Perspectives on Over-smoothing in Deep Graph Neural Networks",
        "link_suffix": "/forum?id=0e26yMOCbd",
        "link": "https://openreview.net/forum?id=0e26yMOCbd",
        "pdf_link": "https://openreview.net/pdf?id=0e26yMOCbd",
        "keywords": "Graph Neural Network, Over-smoothing, Dirichlet energy",
        "abstract": "Over-smoothing is regarded as a key issue affecting the performance of deep Graph Neural Networks (GNNs). As the number of GNN layers increases, model performance degrades significantly, due to node embeddings converging into indistinguishable vectors. This phenomenon stems from the recursive aggregation of neighbor node representations, which impairs the distinguishability of node embeddings. From an energy perspective, this is associated with the convergence of node embeddings to a fixed point solution during the minimization of Dirichlet energy, hindering the model's ability to learn underlying geometric structures. While Graph Convolutional Networks (GCNs) have achieved success in modeling graph-structured data, there is still insufficient understanding of how the underlying geometry contributes to the trainability of deep GCNs.\nIn this paper, we present a novel geometric perspective to understand the poor performance of deep GCNs during training, a method called Charge Dirichlet Energy (\\model). We argue that maintaining a healthy geometric structure can significantly enhance the trainability of GCNs and enable state-of-the-art performance, even in base GCN architectures. Subsequently, we analyze the importance and feasibility of learning geometric shapes, demonstrating the critical role of geometric information in training deep GNNs. Extensive empirical validation on multiple benchmark datasets shows that our method improves the geometric shape of deep base GCNs, significantly enhancing their performance and outperforming many state-of-the-art methods in competitive settings. Our contributions include not only a new approach to mitigating over-smoothing and over-compression but also comprehensive theoretical and empirical verification of the importance of geometric structures for the trainability of deep GNNs."
    },
    {
        "title": "Neural Lighting Priors for Indoor Scenes",
        "link_suffix": "/forum?id=fy4rCv3s5i",
        "link": "https://openreview.net/forum?id=fy4rCv3s5i",
        "pdf_link": "https://openreview.net/pdf?id=fy4rCv3s5i",
        "keywords": "lighting representation, prior learning, neural field, 3D, computer graphics",
        "abstract": "We introduce Neural Lighting Priors, a learned surface emission model for indoor scenes. Given multi-view observations as well as the geometry of a scene, we decouple spatially varying lighting and material parameters. Existing inverse rendering methods typically use hand-crafted emission models or require a large number of views to better constrain the highly ambiguous appearance decomposition task. We aim to overcome these limitations by introducing an expressive learned parametric emission model and utilizing semantic information to sufficiently constrain the optimization, thus allowing us to infer light sources, even if they are not visible in the observations. We model the emitted radiance with a neural field parameterized by the emitting direction and a local latent code stored in a voxel grid. At test time, we fit the local latent codes to the scene using differentiable path tracing, optimizing the reconstruction loss. Our reconstruction allows us to insert virtual objects in a scene and gives us control over the emitters to change their emission color and intensity. Thanks to the learned 3D prior, our method requires fewer views than state-of-the-art relighting methods, gives more control, and also improves the relighting quality."
    }
]
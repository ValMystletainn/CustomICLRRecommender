[
    {
        "title": "Improved Off-policy Reinforcement Learning in Biological Sequence Design",
        "link_suffix": "/forum?id=GvUahyZ8UF",
        "link": "https://openreview.net/forum?id=GvUahyZ8UF",
        "pdf_link": "https://openreview.net/pdf?id=GvUahyZ8UF",
        "keywords": "Biological sequence design, GFlowNets, offline RL, active learning",
        "abstract": "Designing biological sequences with desired properties is a significant challenge due to the combinatorially vast search space and the high cost of evaluating each candidate sequence. To address these challenges, reinforcement learning (RL) methods, such as GFlowNets, utilize proxy models for rapid reward evaluation and annotated data for policy training. Although these approaches have shown promise in generating diverse and novel sequences, the limited training data relative to the vast search space often leads to the misspecification of proxy for out-of-distribution inputs. We introduce $\\delta$-Conservative Search, a novel off-policy search method for training GFlowNets designed to improve robustness against proxy misspecification. The key idea is to incorporate conservativeness, controlled by parameter $\\delta$, to constrain the search to reliable regions. Specifically, we inject noise into high-score offline sequences by randomly masking tokens with a Bernoulli distribution of parameter $\\delta$ and then denoise masked tokens using the GFlowNet policy. Additionally, $\\delta$ is adaptively adjusted based on the uncertainty of the proxy model for each data point. This enables the reflection of proxy uncertainty to determine the level of conservativeness. Experimental results demonstrate that our method consistently outperforms existing machine learning methods in discovering high-score sequences across diverse tasks\u2014including DNA, RNA, protein, and peptide design\u2014especially in large-scale scenarios."
    },
    {
        "title": "Regularizing Energy among Training Samples for Out-of-Distribution Generalization",
        "link_suffix": "/forum?id=Lbx9zdURxe",
        "link": "https://openreview.net/forum?id=Lbx9zdURxe",
        "pdf_link": "https://openreview.net/pdf?id=Lbx9zdURxe",
        "keywords": "Energy based model; OOD generalization; Long-tail Recognition",
        "abstract": "The energy-based model provides a unified framework for various learning models where an energy value is assigned to each configuration of random variables based on probability. Recently, different methods have been proposed to derive an energy value out of the logits of a classifier for out-of-distribution (OOD) detection or OOD generalization. However, these methods mainly focus on the energy difference between in-distribution and OOD data samples, neglecting the energy difference among in-distribution data samples. In this paper, we show that the energy among in-distribution data also requires attention. We propose to investigate the energy difference between in-distribution data samples. Both empirically and theoretically, we show that previous methods for subpopulation shift (\\emph{e.g.}, long-tail classification) such as data re-weighting and margin control apply implicit energy regularization and we provide a unified framework from the energy perspective. With the influence function, we further extend the energy regularization framework to OOD generalization scenarios where the distribution shift is more implicit compared to the long-tail recognition scenario. We conduct experiments on long-tail datasets, subpopulation shift benchmarks, and OOD generalization benchmarks to show the effectiveness of the proposed energy regularization method. The source code will be made publically available."
    },
    {
        "title": "Dynamic-SUPERB Phase-2: A Collaboratively Expanding Benchmark for Measuring the Capabilities of Spoken Language Models with 180 Tasks",
        "link_suffix": "/forum?id=s7lzZpAW7T",
        "link": "https://openreview.net/forum?id=s7lzZpAW7T",
        "pdf_link": "https://openreview.net/pdf?id=s7lzZpAW7T",
        "keywords": "speech, music, audio, benchmark, large language model",
        "abstract": "Multimodal foundation models, such as Gemini and GPT-4, have revolutionized human-machine interactions by seamlessly integrating various forms of data. Developing a universal spoken language model that comprehends a wide range of natural language instructions is critical for bridging communication gaps and facilitating more intuitive interactions. However, the absence of a comprehensive evaluation benchmark poses a significant challenge. We present Dynamic-SUPERB Phase-2, an open and evolving benchmark for the comprehensive evaluation of instruction-based universal speech models. Building upon the first generation, this second version incorporates 125 new tasks contributed collaboratively by the global research community, expanding the benchmark to a total of 180 tasks, making it the largest benchmark for speech and audio evaluation. While the first generation of Dynamic-SUPERB was limited to classification tasks, Dynamic-SUPERB Phase-2 broadens its evaluation capabilities by introducing a wide array of novel and diverse tasks, including regression and sequence generation, across speech, music, and environmental audio. Evaluation results indicate that none of the models performed well universally. SALMONN-13B excelled in English ASR, while WavLLM demonstrated high accuracy in emotion recognition, but current models still require further innovations to handle a broader range of tasks. We open-source all task data and the evaluation pipeline, which will be available after the paper is published."
    },
    {
        "title": "COPER: Correlation-based Permutations for Multi-View Clustering",
        "link_suffix": "/forum?id=5ZEbpBYGwH",
        "link": "https://openreview.net/forum?id=5ZEbpBYGwH",
        "pdf_link": "https://openreview.net/pdf?id=5ZEbpBYGwH",
        "keywords": "clustering, canonical correlation analysis, self supervision, multiview",
        "abstract": "Combining data from different sources can improve data analysis tasks such as clustering. However, most of the current multi-view clustering methods are limited to specific domains or rely on a suboptimal and computationally intensive two-stage process of representation learning and clustering. We propose an end-to-end deep learning-based multi-view clustering framework for general data types (such as images and tables). Our approach involves generating meaningful fused representations using a novel permutation-based canonical correlation objective. We provide a theoretical analysis showing how the learned embeddings approximate those obtained by supervised linear discriminant analysis (LDA). Cluster assignments are learned by identifying consistent pseudo-labels across multiple views. Additionally, we establish a theoretical bound on the error caused by incorrect pseudo-labels in the unsupervised representations compared to LDA. Extensive experiments on ten multi-view clustering benchmark datasets provide empirical evidence for the effectiveness of the proposed model."
    },
    {
        "title": "SciSafeEval: A Comprehensive Benchmark for Safety Alignment of Large Language Models in Scientific Tasks",
        "link_suffix": "/forum?id=jOyQXG6CM4",
        "link": "https://openreview.net/forum?id=jOyQXG6CM4",
        "pdf_link": "https://openreview.net/pdf?id=jOyQXG6CM4",
        "keywords": "Large Language Models, Scientific Tasks, Safety Alignment, Benchmark",
        "abstract": "Large language models (LLMs) have had a transformative impact on a variety of scientific tasks across disciplines such as biology, chemistry, medicine, and physics. However, ensuring the safety alignment of these models in scientific research remains an underexplored area, with existing benchmarks primarily focus on textual content and overlooking key scientific representations such as molecular, protein, and genomic languages. Moreover, the safety mechanisms of LLMs in scientific tasks are insufficiently studied. To address these limitations, we introduce SciSafeEval, a comprehensive benchmark designed to evaluate the safety alignment of LLMs across a range of scientific tasks. SciSafeEval spans multiple scientific languages\u2014including textual, molecular, protein, and genomic\u2014and covers a wide range of scientific domains. We evaluate LLMs in zero-shot, few-shot and chain-of-thought settings, and introduce a ''jailbreak'' enhancement feature that challenges LLMs equipped with safety guardrails, rigorously testing their defenses against malicious intention. Our benchmark surpasses existing safety datasets in both scale and scope, providing a robust platform for assessing the safety and performance of LLMs in scientific contexts. This work aims to facilitate the responsible development and deployment of LLMs, promoting alignment with safety and ethical standards in scientific research."
    },
    {
        "title": "MMFakeBench: A Mixed-Source Multimodal Misinformation Detection Benchmark for LVLMs",
        "link_suffix": "/forum?id=D6zn6ozJs7",
        "link": "https://openreview.net/forum?id=D6zn6ozJs7",
        "pdf_link": "https://openreview.net/pdf?id=D6zn6ozJs7",
        "keywords": "multimodal misinformation detection, large vision language models",
        "abstract": "Current multimodal misinformation detection (MMD) methods often assume a single source and type of forgery for each sample, which is insufficient for real-world scenarios where multiple forgery sources coexist. The lack of a benchmark for mixed-source misinformation has hindered progress in this field. To address this, we introduce MMFakeBench, the first comprehensive benchmark for mixed-source MMD. MMFakeBench includes 3 critical sources: textual veracity distortion, visual veracity distortion, and cross-modal consistency distortion, along with 12 sub-categories of misinformation forgery types. We further conduct an extensive evaluation of 6 prevalent detection methods and 15 large vision-language models (LVLMs) on MMFakeBench under a zero-shot setting. The results indicate that current methods struggle under this challenging and realistic mixed-source MMD setting. Additionally, we propose an innovative unified framework, which integrates rationales, actions, and tool-use capabilities of LVLM agents, significantly enhancing accuracy and generalization. We believe this study will catalyze future research into more realistic mixed-source multimodal misinformation and provide a fair evaluation of misinformation detection methods. Code and a portion of the data are accessible in supplementary materials."
    },
    {
        "title": "DISCO: Mitigating Bias in Deep Learning with Conditional DIStance COrrelation",
        "link_suffix": "/forum?id=sAp04DAHuY",
        "link": "https://openreview.net/forum?id=sAp04DAHuY",
        "pdf_link": "https://openreview.net/pdf?id=sAp04DAHuY",
        "keywords": "Causality, Counterfactual Invariance, Bias Mitigation, Causal Inference",
        "abstract": "During prediction tasks, models can use any signal they receive to come up with\nthe final answer - including signals that are causally irrelevant. When predicting\nobjects from images, for example, the lighting conditions could be correlated to\ndifferent targets through selection bias, and an oblivious model might use these\nsignals as shortcuts to discern between various objects. A predictor that uses\nlighting conditions instead of real object-specific details is obviously undesirable.\nTo address this challenge, we introduce a standard anti-causal prediction model\n(SAM) that creates a causal framework for analyzing the information pathways\ninfluencing our predictor in anti-causal settings. We demonstrate that a classifier\nsatisfying a specific conditional independence criterion will focus solely on the\ndirect causal path from label to image, being counterfactually invariant to the\nremaining variables. Finally, we propose DISCO, a novel regularization strategy\nthat uses conditional distance correlation to optimize for conditional independence\nin regression tasks. We can show that DISCO achieves competitive results in\ndifferent bias mitigation experiments, deeming it a valid alternative to classical\nkernel-based methods."
    },
    {
        "title": "CTBench: A Library and Benchmark for Certified Training",
        "link_suffix": "/forum?id=2bn7gayfz9",
        "link": "https://openreview.net/forum?id=2bn7gayfz9",
        "pdf_link": "https://openreview.net/pdf?id=2bn7gayfz9",
        "keywords": "certified training, benchmark, open-source library",
        "abstract": "Training certifiably robust neural networks is an important but challenging task. While many algorithms for (deterministic) certified training have been proposed, they are often evaluated on different training schedules, certification methods, and systematically under-tuned hyperparameters, making it difficult to compare their performance. To address this challenge, we introduce CTBench, a unified library and a high-quality benchmark for certified training that evaluates all algorithms under fair settings and systematically tuned hyperparameters. We show that (1) almost all algorithms in CTBench surpass the corresponding reported performance in literature in the magnitude of algorithmic improvements, thus establishing new state-of-the-art, and (2) the claimed advantage of recent algorithms drops significantly when we enhance the outdated baselines with a fair training schedule, a fair certification method and well-tuned hyperparameters. Based on CTBench, we provide insights into the current state of certified training and suggest future research directions. We are confident that CTBench will serve as a benchmark and testbed for future research in certified training."
    },
    {
        "title": "Subgraph Federated Learning for Local Generalization",
        "link_suffix": "/forum?id=cH65nS5sOz",
        "link": "https://openreview.net/forum?id=cH65nS5sOz",
        "pdf_link": "https://openreview.net/pdf?id=cH65nS5sOz",
        "keywords": "Graph Neural Networks, Graph Federated Learning",
        "abstract": "Federated Learning (FL) on graphs enables collaborative model training to enhance performance without compromising the privacy of each client. However, existing methods often overlook the mutable nature of graph data, which frequently introduces new nodes and leads to shifts in label distribution. Since they focus solely on performing well on each client's local data, they are prone to overfitting to their local distributions (i.e., local overfitting), which hinders their ability to generalize to unseen data with diverse label distributions. In contrast, our proposed method, FedLoG, effectively tackles this issue by mitigating local overfitting. Our model generates global synthetic data by condensing the reliable information from each class representation and its structural information across clients. Using these synthetic data as a training set, we alleviate the local overfitting problem by adaptively generalizing the absent knowledge within each local dataset. This enhances the generalization capabilities of local models, enabling them to handle unseen data effectively. Our model outperforms baselines in our proposed experimental settings, which are designed to measure generalization power to unseen data in practical scenarios. \nOur code is available athttps://anonymous.4open.science/r/FedLoG-89EE"
    },
    {
        "title": "Minifinetuning: Low-Data Generation Domain Adaptation through Corrective Self-Distillation",
        "link_suffix": "/forum?id=IhbZytsinc",
        "link": "https://openreview.net/forum?id=IhbZytsinc",
        "pdf_link": "https://openreview.net/pdf?id=IhbZytsinc",
        "keywords": "minifinetuning, mft, finetuning, low-resource finetuning, self-distillation, corrective distillation",
        "abstract": "Finetuning language models for a new domain inevitably leads to the deterioration of their general performance.\nThis becomes more pronounced the more limited the finetuning data resource.We introduce minifinetuning (MFT), a method for language model domain adaptation that considerably reduces the effects of overfitting-induced degeneralization in low-data settings and which does so in the absence of any pre-training data for replay.\nMFT demonstrates 2-10x more favourable specialization-to-degeneralization ratios than standard finetuning across a wide range of models and domains and exhibits an intrinsic robustness to overfitting when data in the new domain is scarce and down to as little as 500 samples.Employing corrective self-distillation that is individualized on the sample level, MFT outperforms parameter-efficient finetuning methods, demonstrates replay-like forgetting mitigation properties, and is composable with either for a combined effect."
    },
    {
        "title": "MolStitch: Offline Multi-Objective Molecular Optimization with Molecular Stitching",
        "link_suffix": "/forum?id=3R9hsn1wAS",
        "link": "https://openreview.net/forum?id=3R9hsn1wAS",
        "pdf_link": "https://openreview.net/pdf?id=3R9hsn1wAS",
        "keywords": "molecular optimization, offline optimization, drug discovery",
        "abstract": "Molecular discovery is essential for advancing various scientific fields by generating novel molecules with desirable properties. This process is naturally a multi-objective optimization problem, as it must balance multiple molecular properties simultaneously. Although numerous methods have been developed to address this problem, most rely on online settings that repeatedly evaluate candidate molecules through oracle queries. However, in practical applications, online settings may not be feasible due to the extensive time and resources required for each oracle query. To fill this gap, we propose the Molecular Stitching (MolStitch) framework, which utilizes a fixed offline dataset to explore and optimize molecules without the need for repeated oracle queries. Specifically, MolStitch leverages existing molecules from the offline dataset to generate novel `stitched molecules' that combine their desirable properties. These stitched molecules are then used as training samples to fine-tune the generative model, enhancing its ability to produce superior molecules beyond those in the offline dataset. Experimental results on various offline multi-objective molecular optimization problems validate the effectiveness of MolStitch. MolStitch has been thoroughly analyzed, and its source code is available online."
    },
    {
        "title": "DoF: A Diffusion Factorization Framework for Offline Multi-Agent Decision Making",
        "link_suffix": "/forum?id=OTFKVkxSlL",
        "link": "https://openreview.net/forum?id=OTFKVkxSlL",
        "pdf_link": "https://openreview.net/pdf?id=OTFKVkxSlL",
        "keywords": "multi-agent reinforcement learning; Diffusion Models;   Offline reinforcement learning",
        "abstract": "Diffusion models have been widely adopted in image and language generation and are now being applied to decision-making. However, the application of diffusion models in offline cooperative Multi-Agent decision making (MADM) remains limited. Although some researches exist, they suffer from scalability or poor cooperation issues due to the lack of design principles for diffusion-based MADM. The Individual-Global-Max (IGM) principle is a popular design principle for cooperative MADM. Through satisfying such principles, MADM algorithms achieve remarkable performance with good scalability. In this work, we extend the IGM principle as the Individual-Global-identically-Distributed (IGD) principle. This principle stipulates that the generated outcome of a multi-agent diffusion model should be identically distributed as the collective outcomes from multiple individual-agent diffusion models. We propose DoF, a diffusion factorization framework for MADM. It uses noise factorization function to factorize a centralized diffusion model into multiple diffusion models. We theoretically show that the noise factorization functions satisfy the IGD principle. Further, DoF uses data factorization function to model the complex relationship among data generated by multiple diffusion models. Through extensive experiments, we demonstrate the effectiveness of DoF."
    },
    {
        "title": "Gaussian Loss Smoothing Enables Certified Training with Tight Convex Relaxations",
        "link_suffix": "/forum?id=xriJVaTh4C",
        "link": "https://openreview.net/forum?id=xriJVaTh4C",
        "pdf_link": "https://openreview.net/pdf?id=xriJVaTh4C",
        "keywords": "Certified Robustness, Adversarial Robustness, Certified Training, Convex Relaxation, Neural Network Verification",
        "abstract": "Training neural networks with high certified accuracy against adversarial examples remains an open challenge despite significant efforts. While certification methods can effectively leverage tight convex relaxations for bound computation, in training, these methods, perhaps surprisingly, can perform worse than looser relaxations. Prior work hypothesized that this phenomenon is caused by the discontinuity, non-smoothness and perturbation sensitivity of the loss surface induced by tighter relaxations. In this work, we theoretically show that Gaussian Loss Smoothing (GLS) can alleviate these issues. We confirm this empirically by instantiating GLS with two variants: a zeroth-order optimization algorithm called PGPE which allows training with non-differentiable relaxations, and a first-order optimization algorithm, called RGS, which requires gradients of the relaxation, but is much more efficient than PGPE. Extensive experiments show that when combined with tight relaxations, these methods surpass state-of-the-art methods when training on the same network architecture for many settings. Our results clearly demonstrate the promise of Gaussian Loss Smoothing for training certifiably robust neural networks and pave a path towards leveraging tighter relaxations for certified training."
    },
    {
        "title": "G-SPARC: SPectral ARchitectures tackling the Cold-start problem in Graphs",
        "link_suffix": "/forum?id=KTpSiJ1QNn",
        "link": "https://openreview.net/forum?id=KTpSiJ1QNn",
        "pdf_link": "https://openreview.net/pdf?id=KTpSiJ1QNn",
        "keywords": "Cold-Start Nodes, Graph Neural Networks, Spectral Representation",
        "abstract": "Graphs play a central role in modeling complex relationships across various domains. Most graph learning methods rely heavily on neighborhood information, raising the question of how to handle \\textit{cold-start nodes} \u2014 nodes with no known connections within the graph.\nThese models often overlook the cold-start nodes, making them ineffective for real-world scenarios. To tackle this, we propose G-SPARC, a novel framework addressing cold-start nodes, that leverages generalizable spectral embedding. This framework enables extension to state-of-the-art methods making them suitable for practical applications. By utilizing a key idea of transitioning from graph representation to spectral representation, our approach is generalizable to cold-start nodes, capturing the global structure of the graph without relying on adjacency data. Experimental results demonstrate that our method outperforms existing models on cold-start nodes across various tasks like node classification, node clustering, and link prediction. G-SPARC provides a breakthrough built-in solution to the cold-start problem in graph learning. Our code will be publicly available upon acceptance."
    },
    {
        "title": "Harnessing the Wikipedia Graph for Effective Multi-Entity Question Answering",
        "link_suffix": "/forum?id=Avg6hmtgHE",
        "link": "https://openreview.net/forum?id=Avg6hmtgHE",
        "pdf_link": "https://openreview.net/pdf?id=Avg6hmtgHE",
        "keywords": "Multi-Entity QA, Wikipedia Graph, Structured QA, RAG",
        "abstract": "Wikipedia serves as a rich repository of well-curated knowledge, making it a popular source for information retrieval through question answering (QA). Often, these inquiries involve multiple entities, such as ``How many Turing Award winners are Canadian?'', necessitating the consolidation of information from various Wikipedia pages. Multi-entity question answering typically comprises two steps: multi-entity retrieval and subsequent reasoning using large language models (LLMs). The pre-defined connections within Wikipedia, known as the wiki-graph, facilitate relatively straightforward multi-entity retrieval. However, traditional solutions leveraging retrieval-augmented generation (RAG) encounter limitations, as LLMs often struggle to aggregate insights from multiple pages effectively. In response, we propose a Structured QA (SQA) approach that first organizes extracted entities into a relational table (e.g., a table schema with columns (name, nationality) for Turing Award winners) and then employs table-based methods such as TableQA or NL2SQL for answering. Extensive experiments demonstrate the superior effectiveness of SQA in addressing multi-entity QA challenges,  improves the overall accuracy 29.6% over the SOTA solutions, paving the way for more robust information retrieval from Wikipedia."
    },
    {
        "title": "Average Certified Radius is a Poor Metric for Randomized Smoothing",
        "link_suffix": "/forum?id=KX5hd1RhYP",
        "link": "https://openreview.net/forum?id=KX5hd1RhYP",
        "pdf_link": "https://openreview.net/pdf?id=KX5hd1RhYP",
        "keywords": "Randomized Smoothing, Metric Evaluation",
        "abstract": "Randomized smoothing is a popular approach for providing certified robustness guarantees against adversarial attacks, and has become a very active area of research. Over the past years, the average certified radius (ACR) has emerged as the single most important metric for comparing methods and tracking progress in the field. However, in this work, we show that ACR is an exceptionally poor metric for evaluating robustness guarantees provided by randomized smoothing. We theoretically show not only that a trivial classifier can have arbitrarily large ACR, but also that ACR is much more sensitive to improvements on easy samples than on hard ones. Empirically, we confirm that existing training strategies that improve ACR reduce the model's robustness on hard samples. Further, we show that by focusing on easy samples, we can effectively replicate the increase in ACR. We develop strategies, including explicitly discarding hard samples, reweighing the dataset with certified radius, and extreme optimization for easy samples, to achieve state-of-the-art ACR, although these strategies ignore robustness for the general data distribution. Overall, our results suggest that ACR has introduced a strong undesired bias to the field, and better metrics are required to holistically evaluate randomized smoothing."
    },
    {
        "title": "Beyond Auto-Regression: Fast LLMs via Self-Distillation Through Time",
        "link_suffix": "/forum?id=uZ5K4HeNwd",
        "link": "https://openreview.net/forum?id=uZ5K4HeNwd",
        "pdf_link": "https://openreview.net/pdf?id=uZ5K4HeNwd",
        "keywords": "language modeling, LLM, diffusion models, discrete diffusion models, diffusion language models, distillation",
        "abstract": "Autoregressive (AR) Large Language Models (LLMs) have demonstrated significant success across numerous tasks. However, the AR modeling paradigm presents certain limitations; for instance, contemporary autoregressive LLMs are trained to generate one token at a time, which can result in noticeable latency. Recent advancements have indicated that search and repeated sampling can enhance performance in various applications, such as theorem proving, code generation, and alignment, by utilizing greater computational resources during inference. In this study, we demonstrate that diffusion language models are capable of generating at least 32 tokens simultaneously, while exceeding the performance of AR models in text quality and on the LAMBADA natural language understanding benchmark. This outcome is achieved through a novel distillation method for discrete diffusion models, which reduces the number of inference steps by a factor of 32-64. Practically, our models, even without caching, can generate tokens at a rate that is up to 8 times faster than AR models employing KV-caching, and we anticipate further improvements with the inclusion of caching. Moreover, we demonstrate the efficacy of our approach for diffusion language models with up to 860M parameters."
    },
    {
        "title": "Chinese Inertial GAN for Writing Signal Generation and Recognition",
        "link_suffix": "/forum?id=BoXyYnpUTh",
        "link": "https://openreview.net/forum?id=BoXyYnpUTh",
        "pdf_link": "https://openreview.net/pdf?id=BoXyYnpUTh",
        "keywords": "Inertial Sensors, Handwriting Recognition, Signal Generation, Human-Computer Interaction, Disabled People",
        "abstract": "Disabled people constitute a significant part of the global population, deserving of inclusive consideration and empathetic support. However, the current human-computer interaction based on keyboards may not meet the requirements of disabled people.\u00a0The small size, ease of wearing, and low cost of inertial sensors make inertial sensor-based writing recognition\u00a0a promising human-computer interaction option for disabled people. However, accurate recognition relies on massive inertial signal samples, which are hard to collect for the Chinese context due to the vast number of characters. Therefore, we design a Chinese inertial generative adversarial network (CI-GAN) containing Chinese glyph encoding (CGE), forced optimal transport (FOT), and semantic\u00a0relevance alignment (SRA) to acquire unlimited high-quality training samples. Unlike existing vectorization focusing on the meaning of Chinese characters, CGE represents the shape and stroke features, providing glyph guidance for GAN to generate writing signals. FOT establishes a triple-consistency constraint between the input prompt, output signal features, and real signal features, ensuring the authenticity and semantic accuracy of the generated signals and preventing mode collapse and mixing. SRA constrains the consistency between the semantic relationships among multiple outputs and the corresponding input prompts, ensuring that similar inputs correspond to similar outputs (and vice versa), significantly alleviating the hallucination problem of generative models.\u00a0The three modules guide the generator while also interacting with each other, forming a coupled system. By utilizing the massive training samples provided by CI-GAN, the performance of six widely used classifiers is improved from 6.7%\u00a0to 98.4%, indicating\u00a0that CI-GAN constructs a flexible and efficient data platform for Chinese inertial writing recognition.\u00a0Furthermore, we\u00a0release\u00a0the first Chinese writing recognition dataset based on inertial sensors in GitHub."
    },
    {
        "title": "SEMF: Supervised Expectation-Maximization Framework for Predicting Intervals",
        "link_suffix": "/forum?id=8GFoOB7XB4",
        "link": "https://openreview.net/forum?id=8GFoOB7XB4",
        "pdf_link": "https://openreview.net/pdf?id=8GFoOB7XB4",
        "keywords": "Uncertainty Quantification, Latent Representation Learning, Expectation-Maximization (EM)",
        "abstract": "This work introduces the Supervised Expectation-Maximization Framework (SEMF), a versatile and model-agnostic approach for generating prediction intervals in datasets with complete or missing data. SEMF extends the Expectation-Maximization algorithm, traditionally used in unsupervised learning, to a supervised context, leveraging latent variable modeling for uncertainty estimation. Extensive empirical evaluations across 11 tabular datasets show that SEMF often achieves narrower normalized prediction intervals and higher coverage rates than traditional quantile regression methods. Furthermore, SEMF can be integrated with machine learning models like gradient-boosted trees and neural networks, highlighting its practical applicability. The results indicate that SEMF enhances uncertainty quantification, particularly in scenarios with complete data."
    },
    {
        "title": "iREPO:implicit Reward Pairwise Difference based Empirical Preference Optimization",
        "link_suffix": "/forum?id=NtAXAvIYuN",
        "link": "https://openreview.net/forum?id=NtAXAvIYuN",
        "pdf_link": "https://openreview.net/pdf?id=NtAXAvIYuN",
        "keywords": "Language Models, Preference Optimization",
        "abstract": "While astonishingly capable, large Language Models (LLM) can sometimes produce outputs that deviate from human expectations. Such deviations necessitate an alignment phase to prevent disseminating untruthful, toxic, or biased information. Traditional alignment methods based on reinforcement learning often struggle with the identified instability, whereas preference optimization methods are limited by their overfitting to pre-collected hard-label datasets. In this paper, we propose a novel LLM alignment framework named $i$REPO, which utilizes implicit Reward pairwise difference regression for Empirical Preference Optimization. Particularly, $i$REPO employs self-generated datasets labeled by empirical human (or AI annotator) preference to iteratively refine the aligned policy through a novel regression-based loss function. Furthermore, we introduce an innovative algorithm backed by theoretical guarantees for achieving optimal results under ideal assumptions and providing a practical performance-gap result without such assumptions. Experimental results with Phi-2 and Mistral-7B demonstrate that $i$REPO effectively achieves self-alignment using soft-label, self-generated responses and the logit of empirical AI annotators. Furthermore, our approach surpasses preference optimization baselines in evaluations using the Language Model Evaluation Harness and Multi-turn benchmarks."
    },
    {
        "title": "A Probabilistic Perspective on Unlearning and Alignment for Large Language Models",
        "link_suffix": "/forum?id=51WraMid8K",
        "link": "https://openreview.net/forum?id=51WraMid8K",
        "pdf_link": "https://openreview.net/pdf?id=51WraMid8K",
        "keywords": "Machine Unlearning, Alignment, Large Language Models",
        "abstract": "Comprehensive evaluation of Large Language Models (LLMs) is an open research problem. Existing evaluations rely on deterministic point estimates generated via greedy decoding. However, we find that deterministic evaluations fail to capture the whole output distribution of a model, yielding inaccurate estimations of model capabilities. This is particularly problematic in critical contexts such as unlearning and alignment, where precise model evaluations are crucial. To remedy this, we introduce the first formal probabilistic evaluation framework in LLMs. Namely, we derive novel metrics with high-probability guarantees concerning the output distribution of a model. Our metrics are application-independent and allow practitioners to make more reliable estimates about model capabilities before deployment. Through a case study focused on unlearning, we reveal that deterministic evaluations falsely indicate successful unlearning, whereas our probabilistic evaluations demonstrate that most if not all of the supposedly unlearned information remains accessible in these models. Additionally, we propose a novel unlearning loss based on entropy optimization and adaptive temperature scaling, which significantly improves unlearning in probabilistic settings on recent benchmarks. Our proposed shift from point estimates to probabilistic evaluations of output distributions represents an important step toward comprehensive evaluations of LLMs."
    },
    {
        "title": "Improving Convergence Guarantees of Random Subspace Second-order Algorithm for Nonconvex Optimization",
        "link_suffix": "/forum?id=tuu4de7HL1",
        "link": "https://openreview.net/forum?id=tuu4de7HL1",
        "pdf_link": "https://openreview.net/pdf?id=tuu4de7HL1",
        "keywords": "random projection, trust region method, non-convex optimization, second-order stationary point, local convergence",
        "abstract": "In recent years, random subspace methods have been actively studied for large-dimensional non-convex problems. Recent subspace methods have improved theoretical guarantees such as iteration complexity and local convergence rate while reducing computational costs by deriving descent directions in randomly selected low-dimensional subspaces. This paper proposes the Random Subspace Homogenized Trust Region (RSHTR) method with the best theoretical guarantees among random subspace algorithms for non-convex optimization. RSHTR achieves an $\\varepsilon$-approximate first-order stationary point in $O(\\varepsilon^{-3/2})$ iterations, converging locally at a linear rate. Furthermore, under rank-deficient conditions, RSHTR satisfies $\\varepsilon$-approximate second-order necessary condition in $O(\\varepsilon^{-3/2})$ iterations and exhibits a local quadratic convergence. Experiments on real-world datasets verify the benefits of RSHTR."
    },
    {
        "title": "Revisiting Emergent Correspondence from Transformers for Self-supervised Multi-frame Depth Estimation",
        "link_suffix": "/forum?id=xAZLCWbsTF",
        "link": "https://openreview.net/forum?id=xAZLCWbsTF",
        "pdf_link": "https://openreview.net/pdf?id=xAZLCWbsTF",
        "keywords": "Self-supervised Depth estimation; Multi-frame Depth estimation",
        "abstract": "Self-supervised multi-frame depth estimation predicts depth by leveraging geometric cues from multiple input frames. Traditional methods construct cost volumes based on epipolar geometry to explicitly integrate the geometric information from these input frames. Although this approach may seem effective, the epipolar-based cost volume has two key limitations: (1) it assumes a static environment, and (2) requires pose information during inference. As a result, this cost volume fails in real-world scenarios where dynamic objects and image noise are often present, and pose information is unavailable. In this paper, we demonstrate that the cross-attention map can function as a full cost volume to address these limitations. Specifically, we find that training the cross-attention layers for image reconstruction enables them to implicitly learn a warping function within the cross-attention, resembling the explicit epipolar warping used in traditional self-supervised depth estimation methods. To this end, we propose the CRoss-Attention map and Feature aggregaTor (CRAFT), which is designed to effectively leverage the matching information of the cross-attention map by aggregating and refining the full cost volume. Additionally, we utilize CRAFT in a hierarchical manner to progressively improve depth prediction results through a coarse-to-fine approach. Thorough evaluations on the KITTI and Cityscapes datasets demonstrate that our approach outperforms traditional methods. In contrast to previous methods that employ epipolar-based cost volumes, which often struggle in regions with dynamic objects and image noise, our method demonstrates robust performance and provides accurate depth predictions in these challenging conditions."
    },
    {
        "title": "AI Sandbagging: Language Models can Strategically Underperform on Evaluations",
        "link_suffix": "/forum?id=7Qa2SpjxIS",
        "link": "https://openreview.net/forum?id=7Qa2SpjxIS",
        "pdf_link": "https://openreview.net/pdf?id=7Qa2SpjxIS",
        "keywords": "Alignment, AI safety, sandbagging, AI evaluations, AI governance, NLP, LLM",
        "abstract": "Trustworthy capability evaluations are crucial for ensuring the safety of AI systems, and are becoming a key component of AI regulation. However, the developers of an AI system, or the AI system itself, may have incentives for evaluations to understate the AI's actual capability. These conflicting interests lead to the problem ofsandbagging\u2013 which we define asstrategic underperformance on an evaluation. In this paper we assess sandbagging capabilities in contemporary language models (LMs). We prompt frontier LMs, like GPT-4 and Claude 3 Opus, to selectively underperform on dangerous capability evaluations, while maintaining performance on general (harmless) capability evaluations. Moreover, we find that models can be fine-tuned, on a synthetic dataset, to hide specific capabilities unless given a password. This behaviour generalizes to high-quality, held-out benchmarks such as WMDP. In addition, we show that both frontier and smaller models can be prompted or password-locked to target specific scores on a capability evaluation. We have mediocre success in password-locking a model to mimic the answers a weaker model would give. Overall, our results suggest that capability evaluations are vulnerable to sandbagging. This vulnerability decreases the trustworthiness of evaluations, and thereby undermines important safety decisions regarding the development and deployment of advanced AI systems.We publish our code and results athttps://anonymous.4open.science/r/Sandbagging-8305/README.md"
    },
    {
        "title": "Planning with MCTS: Enhancing Problem-Solving in Large Language Models",
        "link_suffix": "/forum?id=sdpVfWOUQA",
        "link": "https://openreview.net/forum?id=sdpVfWOUQA",
        "pdf_link": "https://openreview.net/pdf?id=sdpVfWOUQA",
        "keywords": "Large Language Models, Monte Carlo Tree Search, Planning, Chain-of-Thought",
        "abstract": "Despite recent advances in Large Language Models (LLMs), their ability to solve complex reasoning problems remains limited by inconsistent planning and logical flaws. We present a novel framework that significantly enhances LLMs' problem-solving capabilities by leveraging Monte Carlo Tree Search (MCTS) for plan generation. Unlike previous approaches that apply MCTS to solution search, our method uniquely integrates MCTS into the planning phase, guided by specialized LLM-powered agents that evaluate plan quality. Experiments across diverse benchmark datasets demonstrate that our approach improves problem-solving accuracy by an average of 40.59% compared to zero-shot Chain-of-Thought prompting. Furthermore, we show that using smaller models for MCTS planning and larger models for execution can maintain high performance while reducing computational costs. This work opens new avenues for developing more robust and efficient AI systems capable of tackling complex real-world problems, with potential applications in fields requiring advanced logical reasoning and long-term planning. Our code examples are publicly available at the Anonymous Github Repository."
    }
]
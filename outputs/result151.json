[
    {
        "title": "MoSH: Modeling Multi-Objective Tradeoffs with Soft and Hard Bounds",
        "link_suffix": "/forum?id=lpt4ADbacU",
        "link": "https://openreview.net/forum?id=lpt4ADbacU",
        "pdf_link": "https://openreview.net/pdf?id=lpt4ADbacU",
        "keywords": "multi-objective, multi-criteria, decision-making, preference learning, bayesian optimization",
        "abstract": "Countless science and engineering applications in multi-objective optimization (MOO) necessitate that decision-makers (DMs) select a Pareto-optimal solution which aligns with their preferences. Evaluating individual solutions is often expensive, necessitating cost-sensitive optimization techniques. Due to competing objectives, the space of trade-offs is also expansive --- thus, examining the full Pareto frontier may prove overwhelming to a DM. Such real-world settings generally have loosely-defined and context-specific desirable regions for each objective function that can aid in constraining the search over the Pareto frontier. In this paper, we operationalize these priors using $\\textit{soft-hard functions}$, SHFs, which allow for the DM to impose soft and hard bounds on each objective. Leveraging a novel minimax formulation for Pareto frontier sampling, we propose a two-step process for obtaining a compact set of Pareto-optimal points which respect the user-defined soft and hard bounds: (1) densely sample the Pareto frontier using Bayesian optimization, and (2) sparsify the selected set to surface to the user, using robust submodular function optimization. We prove that (2) obtains the optimal compact Pareto-optimal set of points from (1). We further show that many practical problems fit within the SFH framework, and provide extensive empirical validation on several synthetic and real-world applications. Specifically, for brachytherapy, our approach returns a compact set of points with over 3% greater SHF-defined utility than the next best approach. Among the other diverse experiments, our approach consistently leads in utility, allowing the DM to reach $>$99% of their maximum possible desired utility within validation of 5 points."
    },
    {
        "title": "Uncertainty-aware Fine-tuning on Time Series Foundation Model for Anomaly Detection",
        "link_suffix": "/forum?id=W1wlE4bPqP",
        "link": "https://openreview.net/forum?id=W1wlE4bPqP",
        "pdf_link": "https://openreview.net/pdf?id=W1wlE4bPqP",
        "keywords": "Time Series Foundation Model, Anomaly Detection, Fine-tuning",
        "abstract": "Time-series anomaly detection is a crucial task in various real-world domains, geared towards identifying data observations that significantly deviate from the norm. Although time-series foundation models have shown promising results across multiple tasks, their effectiveness in anomaly detection is often inferior. This is due to their unsupervised learning paradigm being compromised by anomaly contamination in the training data. In addition, the existing approaches lack the capability to capture boundries of multiple types of normal and abnormal patterns. To overcome these challenges, we propose ULoRA-MoE, a general uncertainty-aware fine-tuning approach using resource-efficient Mixture-of-Expert (MoE) module based on LoRA. This proposed approach can enhance the fine-tuning performance across a broad spectrum of time series foundation models for anomaly detection. Each expert module of MoE can help learn different types of anomalies. Furthermore, we design the uncertainty-aware router of MoE using Gumbel-Softmax distribution for categorical sampling to capture the epistemic uncertainty. Given the estimated uncertainty, we propose a calibrated anomaly score function to mitigate the detrimental effects of anomaly contamination. We conducted extensive experiments on two general types of time series foundation models. The results demonstrate that our approach significantly improves the model performance compared to existing fine-tuning approaches. Furthermore, ULoRA-MoE shows competitive performance compared to a comprehensive set of non-learning, classical learning, and deep learning (DL) based time-series anomaly detection baselines across 8 real-world benchmarks."
    },
    {
        "title": "Lay-Your-Scene: Open-Vocabulary Text to Layout Generation",
        "link_suffix": "/forum?id=u6y9uIzqAB",
        "link": "https://openreview.net/forum?id=u6y9uIzqAB",
        "pdf_link": "https://openreview.net/pdf?id=u6y9uIzqAB",
        "keywords": "layout generation, diffusion models",
        "abstract": "We present Lay-Your-Scene (shorthand LayouSyn), a novel diffusion-Transformer based architecture for open-vocabulary natural scene layout generation. Prior works have used close-sourced scene-unaware Large Language models for open-vocabulary layout generation, limiting their widespread use and scene-specific modeling capability. This work presents the first end-to-end text-to-natural-scene-layout generation pipeline that utilizes lightweight open-source language models to predict objects in the scene and a new conditional layout diffusion Transformer trained in a scene-aware manner. Extensive experiments demonstrate that LayouSyn outperforms existing methods on open-vocabulary and closed-vocabulary layout generation and achieves state-of-the-art performance on challenging spatial and numerical reasoning tasks. Additionally, we present two applications of LayouSyn: First, we demonstrate an interesting finding that we can seamlessly combine initialization from the Large Language model to reduce the diffusion sampling steps. Second, we present a new pipeline for adding objects to the image, demonstrating the potential of LayouSyn in image editing applications."
    },
    {
        "title": "FastAttention: Extend FlashAttention2 to NPUs and Low-resource GPUs for Efficient Inference",
        "link_suffix": "/forum?id=76NYyOrnfk",
        "link": "https://openreview.net/forum?id=76NYyOrnfk",
        "pdf_link": "https://openreview.net/pdf?id=76NYyOrnfk",
        "keywords": "Attention, NPUs, low-resource GPUs, Tiling strategies, Inferecne acceleration",
        "abstract": "FlashAttention series has been widely applied in the inference of large language models (LLMs). However, FlashAttention series only supports the high-level GPU architectures, e.g., Ampere and Hopper. At present, FlashAttention series is not easily transferrable to NPUs and low-resource GPUs. Moreover, FlashAttention series is inefficient for multi- NPUs or GPUs inference scenarios.In this work, we propose FastAttention which pioneers the adaptation of FlashAttention series for NPUs and low-resource GPUs to boost LLM inference efficiency. Specifically, we take Ascend NPUs and Volta-based GPUs as representatives for designing our FastAttention. We migrate FlashAttention series to Ascend NPUs by proposing a novel two-level tiling strategy for runtime speedup, tiling-mask strategy for memory saving and the tiling-AllReduce strategy for reducing communication overhead, respectively. Besides, we adapt FlashAttention for Volta-based GPUs by redesigning the operands layout in shared memory and introducing a simple yet effective CPU-GPU cooperative strategy for efficient memory utilization. \nOn Ascend NPUs, our FastAttention can achieve a 10.7$\\times$ speedup compared to the standard attention implementation. Llama-7B within FastAttention reaches up to 5.16$\\times$ higher throughput than within the standard attention. \nOn Volta architecture GPUs, FastAttention yields 1.43$\\times$ speedup compared to its equivalents in xformers. Pangu-38B within FastAttention brings 1.46$\\times$ end-to-end speedup using FasterTransformer.\nCoupled with the propose CPU-GPU cooperative strategy, FastAttention supports a maximal input length of 256K on 8 V100 GPUs. All the codes will be made available soon."
    },
    {
        "title": "SIRA: Exposing Vulnerabilities in Text Watermarking with Self-Information Rewrite Attacks",
        "link_suffix": "/forum?id=8Me0Y01mkY",
        "link": "https://openreview.net/forum?id=8Me0Y01mkY",
        "pdf_link": "https://openreview.net/pdf?id=8Me0Y01mkY",
        "keywords": "LLM watermark, robustness, safety ai, paraphrasing attack",
        "abstract": "Text watermarking is designed to embed hidden, imperceptible, markers within\ncontent generated by large language models (LLMs), with the goal of tracing and\nverifying the content\u2019s origin to prevent misuse. The robustness of watermarking\nalgorithms has become a key factor in evaluating their effectiveness, but remains\nan open problem. In this work, we introduce a novel watermark removal attack,\nthe Self-Information Rewrite Attack (SIRA), which poses a new challenge to the\nrobustness of existing watermarking techniques. Since embedding watermarks\nrequires both concealment and semantic coherence, current methods prefered to\nembed them in high-entropy tokens. However, this reveals an inherent vulnera-\nbility, allowing us to exploit this feature to identify potential green tokens. Our\napproach leverages the self-information of each token to filter potential pattern to-\nkens that embed watermarks and performs the attack through masking and rewrit-\ning in a black-box setting. We demonstrate the effectiveness of our attack by\nimplementing it against seven recent watermarking algorithms. The experimental\nresults show that our lightweight algorithm achieves state-of-the-art attack success\nrate while maintaining shorter execution times and lower computational resource\nconsumption compared to existing methods. This attack points to an important\nvulnerability of existing watermarking techniques and paves way towards future\nwatermarking improvements."
    },
    {
        "title": "RMP-SAM: Towards Real-Time Multi-Purpose Segment Anything",
        "link_suffix": "/forum?id=1pXzC30ry5",
        "link": "https://openreview.net/forum?id=1pXzC30ry5",
        "pdf_link": "https://openreview.net/pdf?id=1pXzC30ry5",
        "keywords": "segment anything; real-time segmentation; multi-purpose model;",
        "abstract": "Recent segmentation methods, which adopt large-scale data training and transformer architecture, aim to create one foundation model that can perform multiple tasks.\n    However, most of these methods rely on heavy encoder and decoder frameworks, hindering their performance in real-time scenarios.\n    To explore real-time segmentation, recent advancements primarily focus on semantic segmentation within specific environments, such as autonomous driving. However, they often overlook the generalization ability of these models across diverse scenarios.\n    Therefore, to fill this gap, this work explores a novel real-time segmentation setting called real-time multi-purpose segmentation.\n    It contains three fundamental sub-tasks: interactive segmentation, panoptic segmentation, and video instance segmentation. \n    Unlike previous methods, which use a specific design for each task, we aim to use only a single end-to-end model to accomplish all these tasks in real-time.\n    To meet real-time requirements and balance multi-task learning, we present a novel dynamic convolution-based method, Real-Time Multi-Purpose SAM (RMP-SAM). \n    It contains an efficient encoder and an efficient decoupled adapter to perform prompt-driven decoding. \n    Moreover, we further explore different training strategies and one new adapter design to boost co-training performance further. \n    We benchmark several strong baselines by extending existing works to support our multi-purpose segmentation.\n    Extensive experiments demonstrate that RMP-SAM is effective and generalizes well on proposed benchmarks and other specific semantic tasks. \n    Our implementation of RMP-SAM achieves the optimal balance between accuracy and speed for these tasks.\n    Code and model will be available.\n    %"
    },
    {
        "title": "Learned Reference-based Diffusion Sampler for multi-modal distributions",
        "link_suffix": "/forum?id=fmJUYgmMbL",
        "link": "https://openreview.net/forum?id=fmJUYgmMbL",
        "pdf_link": "https://openreview.net/pdf?id=fmJUYgmMbL",
        "keywords": "sampling from multi-modal densities, diffusion models, variational inference, stochastic optimal control, multi-level energy-based models",
        "abstract": "Over the past few years, several approaches utilizing score-based diffusion have been proposed to sample from probability distributions, that is without having access to exact samples and relying solely on evaluations of unnormalized densities. The resulting samplers approximate the time-reversal of a noising diffusion process, bridging the target distribution to an easy-to-sample base distribution. In practice, the performance of these methods heavily depends on key hyperparameters that require ground truth samples to be accurately tuned. Our work aims to highlight and address this fundamental issue, focusing in particular on multi-modal distributions, which pose significant challenges for existing sampling methods. Building on existing approaches, we introduceLearned Reference-based Diffusion Sampler(LRDS), a methodology specifically designed to leverage prior knowledge on the location of the target modes in order to bypass the obstacle of hyperparameter tuning. LRDS proceeds in two steps by (i) learning areferencediffusion model on samples located in high-density space regions and tailored for multimodality, and (ii) using this reference model to foster the training of a diffusion-based sampler. We experimentally demonstrate that LRDS best exploits prior knowledge on the target distribution compared to competing algorithms on a variety of challenging distributions."
    },
    {
        "title": "Advancing Text-to-3D Generation with Linearized Lookahead Variational Score Distillation",
        "link_suffix": "/forum?id=FtyHMDQSlD",
        "link": "https://openreview.net/forum?id=FtyHMDQSlD",
        "pdf_link": "https://openreview.net/pdf?id=FtyHMDQSlD",
        "keywords": "Text-to-3D generation; Diffusion model; Linearized Lookahead",
        "abstract": "Text-to-3D generation based on score distillation of pre-trained 2D diffusion models has gained increasing interest, with variational score distillation (VSD) as a remarkable example. \nVSD proves that vanilla score distillation can be improved by introducing an extra score-based model, which characterizes the distribution of images rendered from 3D models, to correct the distillation gradient. \nDespite the theoretical foundations, VSD, in practice, is likely to suffer from slow and sometimes ill-posed convergence.\nIn this paper, we perform an in-depth investigation of the interplay between the introduced score model and the 3D model, and find that we can simply adjust their optimization order to improve the generation quality. \nBy doing so, the score model looks ahead to the current 3D state and hence yields more reasonable corrections. \nNevertheless, naive lookahead VSD may suffer from unstable training in practice due to the potential over-fitting. \nTo address this, we propose to use a linearized variant of the model for score distillation, giving rise to the Linearized Lookahead Variational Score Distillation ($L^2$-VSD). \n$L^2$-VSD can be realized efficiently with forward-mode autodiff functionalities of existing deep learning libraries. \nExtensive experiments validate the efficacy of $L^2$-VSD, revealing its clear superiority over prior score distillation-based methods. \nWe also show that our method can be seamlessly incorporated into any other VSD-based text-to-3D framework."
    },
    {
        "title": "Negative-Prompt-driven Alignment for Generative Language Model",
        "link_suffix": "/forum?id=cywG53B2ZQ",
        "link": "https://openreview.net/forum?id=cywG53B2ZQ",
        "pdf_link": "https://openreview.net/pdf?id=cywG53B2ZQ",
        "keywords": "AI Alignment, Prompt-driven Online Sampling",
        "abstract": "Large language models have achieved remarkable capabilities, but aligning their outputs with human values and preferences remains a significant challenge. Existing alignment methods primarily focus on positive examples while overlooking the importance of negative responses in guiding models away from undesirable behaviors. For instance, the widely-used alignment datasets reveals a scarcity of explicit negative examples that contradict human values, hindering its ability to discourage harmful or biased outputs during training. To address this limitation, we propose NEAT, i.e., NEgative-prompt-driven AlignmenT, to introduce negative prompts to generate undesirable responses alongside positive examples during the optimization process.  NEAT explicitly penalizes the model for producing harmful outputs, guiding it not only toward desirable behaviors but also steering it away from generating undesirable, biased responses. This dual feedback mechanism enables better alignment with human preferences, crucial in contexts where avoiding harm is paramount. Starting from a pre-trained language model,  NEAT performs online alignment by incorporating a ranking loss derived from an expanded preference dataset containing both positive and negative examples. Extensive experiments validate  NEAT's effectiveness in significantly enhancing language models' alignment with human values and preferences."
    },
    {
        "title": "Automatic Combination of Sample Selection Strategies for Few-Shot Learning",
        "link_suffix": "/forum?id=p8qhVIo980",
        "link": "https://openreview.net/forum?id=p8qhVIo980",
        "pdf_link": "https://openreview.net/pdf?id=p8qhVIo980",
        "keywords": "sample selection, few-shot learning, in-context learning, large language models, meta-learning, few-shot fine-tuning, data-centric",
        "abstract": "In few-shot learning, such as meta-learning, few-shot fine-tuning or in-context learning, the selection of samples has a significant impact on the performance of the trained model. Although many sample selection strategies are employed and evaluated in typical supervised settings, their impact on the performance of few-shot learning is largely unknown. In this paper, we investigate the impact of 20 sample selection strategies on the performance of 5 representative few-shot learning approaches over 8 image and 6 text datasets. We propose a new method for Automatic Combination of SamplE Selection Strategies (ACSESS), to leverage the strengths and complementarity of the individual strategies in order to select more impactful samples. The experimental results show that our method consistently outperforms all individual selection strategies. We also show that the majority of existing strategies strongly depend on modality, dataset characteristics and few-shot learning approach, while improving performance especially on imbalanced and noisy datasets. Lastly, we show that sample selection strategies work well even on smaller datasets and provide larger benefit when selecting a lower number of shots, while frequently regressing to random selection with higher numbers of shots."
    },
    {
        "title": "Rethinking Lipschitzness Data-free Backdoor Defense",
        "link_suffix": "/forum?id=cPIs6PlCuE",
        "link": "https://openreview.net/forum?id=cPIs6PlCuE",
        "pdf_link": "https://openreview.net/pdf?id=cPIs6PlCuE",
        "keywords": "backdoor attack, backdoor defense, model implement, system security, AI security",
        "abstract": "Deep Neural Networks (DNNs) have demonstrated remarkable success across various applications, yet some studies reveal their vulnerability to backdoor attacks, where attackers manipulate models under specific conditions using triggers. It significantly compromise the model integrity. \nAddressing this critical security issue requires robust defence mechanisms to ensure the reliability of DNN models. However, most existing defence mechanisms heavily rely on specialized defence datasets, which are often difficult to obtain due to data privacy and security concerns. This highlights the urgent need for effective data-free defence strategies. In this work, we propose Lipschitzness Precise Pruning (LPP), a novel data-free backdoor defence algorithm that leverages the properties of Lipschitz function to detect and mitigate backdoor vulnerabilities by pruning neurons with strong backdoor correlations while fine-tuning unaffected neurons. Our approach optimizes the computation of the Lipschitz constant using dot product properties, allowing for efficient and precise identification of compromised neurons without the need of clean defence data. This method addresses the limitations of existing data-free defences and extends the scope of backdoor mitigation to include fully connected layers, ensuring comprehensive protection of DNN models. As our approach does not require data exchange, it can be implemented efficiently and effectively in diverse environments. Extensive experiments demonstrate that LPP outperforms state-of-the-art defence approaches without the need for additional defence datasets. We release our code at:https://anonymous.4open.science/r/LPP-CD3C."
    },
    {
        "title": "Quantifying Memory Utilization with Effective State-Size",
        "link_suffix": "/forum?id=DHVjLvSps6",
        "link": "https://openreview.net/forum?id=DHVjLvSps6",
        "pdf_link": "https://openreview.net/pdf?id=DHVjLvSps6",
        "keywords": "model analysis, interpretability, linear systems, attention, state-space models, sequence models, memory utilization, context utilization",
        "abstract": "As the space of causal sequence modeling architectures continues to grow, the need to develop a general framework for their analysis becomes increasingly important. With this aim, we draw insights from classical signal processing and control theory, to develop a quantitative measure ofmemory utilization: the internal mechanisms through which a model stores past information to produce future outputs. This metric, which we calleffective state-size(ESS), is tailored to the fundamental class ofinput-invariantandinput-varying linear operators, encompassing a variety of computational units such as variants of attention, convolutions, and recurrences. Unlike prior work on memory utilization, which either relies on raw operator visualizations (e.g. attention maps), or simply the totalmemory capacity(i.e. cache size) of a model, our metrics provide highly interpretable and actionable measurements. In particular, we show how ESS can be leveraged to improve initialization strategies, inform novel regularizers and advance the performance-efficiency frontier through model distillation. Furthermore, we demonstrate that the effect of context delimiter tokens (such as end-of-speech tokens) on ESS highlights cross-architectural differences in how large language models utilize their available memory to recall information. Overall, we find that ESS provides valuable insights into the dynamics that dictate memory utilization, enabling the design of more efficient and effective sequence models."
    },
    {
        "title": "Taipan: Efficient and Expressive State Space Language Models with Selective Attention",
        "link_suffix": "/forum?id=9DnKZbOr4r",
        "link": "https://openreview.net/forum?id=9DnKZbOr4r",
        "pdf_link": "https://openreview.net/pdf?id=9DnKZbOr4r",
        "keywords": "Efficient Language Model, Model Architecture, Long-context Language Model, In-context Retrieval, Hybrid Architecture, Linear Complexity",
        "abstract": "Efficient long-context language modeling remains a significant challenge in Natural Language Processing (NLP). While Transformers dominate language tasks, they struggle with long sequences due to quadratic computational complexity in training and linearly scaling memory costs during inference. Recent State Space Models (SSMs) such as Mamba offer alternatives with constant memory usage, but they underperform in tasks requiring extensive in-context retrieval. We introduce Taipan, a novel hybrid architecture that combines Mamba-2 with Selective Attention Layers (SALs). These SALs identify tokens requiring long-range interactions, remove less important features, and then augment their representations using the attention module. This approach balances Mamba's efficiency with Transformer-like performance in memory-intensive tasks. By constraining the attention budget, Taipan extends accurate predictions to context lengths of up to 1 million tokens while preserving computational efficiency. Our experiments demonstrate Taipan's superior performance across various scales and tasks, offering a promising solution for efficient long-context language modeling."
    },
    {
        "title": "Seeded LoRA: Collaborative Fine-Tuning Through Seed Initialization of Adapters",
        "link_suffix": "/forum?id=U3UtvOYMiw",
        "link": "https://openreview.net/forum?id=U3UtvOYMiw",
        "pdf_link": "https://openreview.net/pdf?id=U3UtvOYMiw",
        "keywords": "PEFT, LoRA, MoE",
        "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods facilitate the cost-effective adaptation of pretrained language models to specific tasks and domains. These methods have enabled the open-source community to develop thousands of specialized models tailored to various domains and tasks. Collaborative Fine-Tuning (CoFT) is the paradigm that seeks to merge these specialized models into a single model -- often a routed Mixture-of-Expert (MoE) model -- to achieve better generalization across domains and tasks. However, current CoFT models require a post-merge fine-tuning stage to successfully combine existing models, making CoFT approaches inaccessible to users who lack fine-tuning expertise. In this work, we introduce Seeded LoRA, a novel CoFT approach that does not require post-merge fine-tuning thus enabling plug-and-play PEFT adapter merging. Seeded LoRA significantly outperforms LoRA and MoE LoRA (MoLoRA) approaches, improving by an average of 7 percentage points across a battery of 16 zero-shot tasks and we find that the main benefit from Seeded LoRA comes from mitigating task interference during finetuning. Seeded LoRA works by initializing a model before fine-tuning using a generic seed expert low-rank adapter which was finetuned on a small random subset of the finetuning data such that subsequent fine-tuning runs are initialized in the same optimization subspace. This process enables the integration of any combination of independently fine-tuned models through simple averaging of expert adapter outputs. We show that averaging, or routing with assigning equal probability weights to each expert, is equivalent to grouped convolution, explaining its effectiveness. Additionally, we study subtle routing failures in post-merge fine-tuning and highlight that Seeded LoRA can alleviate most routing failures, making it a suitable base method for future routed CoFT approaches."
    },
    {
        "title": "Unbiased Attribution with Intrinsic Information",
        "link_suffix": "/forum?id=E4A7KtLB21",
        "link": "https://openreview.net/forum?id=E4A7KtLB21",
        "pdf_link": "https://openreview.net/pdf?id=E4A7KtLB21",
        "keywords": "Interpretability, Attribution",
        "abstract": "The importance of attribution algorithms in the AI field lies in enhancing model transparency, diagnosing and improving models, ensuring fairness, and increasing user understanding. Gradient-based attribution methods have become the most critical because of their high computational efficiency, continuity, wide applicability, and flexibility. However, current gradient-based attribution algorithms require the introduction of additional class information to interpret model decisions, which can lead to issues of information ignorance and extra information. Information ignorance can obscure important features relevant to the current model decision, while extra information introduces irrelevant data that can cause feature leakage in the attribution process. To address these issues, we propose the Attribution with Intrinsic Information (AII) algorithm, which analyzes model decisions without the need for specified class information. Additionally, to better evaluate the potential of current attribution algorithms, we introduce the metrics of insertion confusion and deletion confusion alongside existing mainstream metrics. To continuously advance research in the field of explainable AI (XAI), our algorithm is open-sourced athttps://anonymous.4open.science/r/AII-787D/."
    },
    {
        "title": "Controlling Forgetting with Test-Time Data in Continual Learning",
        "link_suffix": "/forum?id=fRNDDFkPiv",
        "link": "https://openreview.net/forum?id=fRNDDFkPiv",
        "pdf_link": "https://openreview.net/pdf?id=fRNDDFkPiv",
        "keywords": "Continual Learning, Test Time Learning",
        "abstract": "Foundational vision-language models have shown impressive performance on various downstream tasks. Yet, there is still a pressing need to update these models later as new tasks or domains become available. Ongoing Continual Learning (CL) research provides techniques to overcome catastrophic forgetting of previous information when new knowledge is acquired. To date, CL techniques focus only on the supervised training sessions. This results in significant forgetting yielding inferior performance to even the prior model zero shot performance. In this work, we argue that test-time data hold great information that can be leveraged in a self supervised manner to refresh the model's memory of previous learned tasks and hence greatly reduce forgetting at no extra labelling cost. We study how unsupervised data can be employed online to improve models' performance on prior tasks upon encountering representative samples. We propose a simple yet effective student-teacher model with gradient based sparse parameters updates and show significant performance improvements and reduction in forgetting, which could alleviate the role of an offline episodic memory/experience replay buffer."
    },
    {
        "title": "Learn With Imagination: Safe Set Guided State-wise Constrained Policy Optimization",
        "link_suffix": "/forum?id=PAzVN4EEkj",
        "link": "https://openreview.net/forum?id=PAzVN4EEkj",
        "pdf_link": "https://openreview.net/pdf?id=PAzVN4EEkj",
        "keywords": "Deep Reinforcement Learning, Safe Control, Safety Index, Zero Training Violations, Imaginary Cost",
        "abstract": "Deep reinforcement learning (RL) excels in various control tasks, yet the absence of safety guarantees hampers its real-world applicability. In particular, explorations during learning usually results in safety violations, while the RL agent learns from those mistakes. On the other hand, safe control techniques ensure persistent safety satisfaction but demand strong priors on system dynamics, which is usually hard to obtain in practice. To address these problems, we present Safe Set Guided State-wise Constrained Policy Optimization (S-3PO), a pioneering algorithm generating state-wise safe optimal policies with zero training violations, i.e., learning without mistakes. S-3PO first employs a safety-oriented monitor with black-box dynamics to ensure safe exploration. It then enforces a unique cost for the RL agent to converge to optimal behaviors within safety constraints.  S-3PO outperforms existing methods in high-dimensional robotics tasks, managing state-wise constraints with zero training violation. This innovation marks a significant stride towards real-world safe RL deployment."
    },
    {
        "title": "LAMP: Large Model Pruning with Inter-Block Error Compensation",
        "link_suffix": "/forum?id=mclaeTduHp",
        "link": "https://openreview.net/forum?id=mclaeTduHp",
        "pdf_link": "https://openreview.net/pdf?id=mclaeTduHp",
        "keywords": "Large Model Pruning, Model Compression, Compensation",
        "abstract": "The increasing prevalence of large-scale models, both in vision and language domains, presents significant challenges in terms of memory and resource consumption. While model pruning is an effective method for compressing models to alleviate these constraints, existing techniques either require extensive fine-tuning, which is resource-intensive, or perform well only at low sparsity levels (10%-50%), failing at high sparsity levels (50%-90%). To address these issues, this paper introduces LAMP to mitigate the drawbacks associated with traditional pruning methods, namely high resource consumption in methods that require extensive fine-tuning, and poor performance at high sparsity levels in methods that do not. It reduces memory overhead and alleviates performance degradation at high sparsity. Experimental results demonstrate that LAMP achieves slightly better performance than SparseGPT at low sparsity levels and significantly better at high sparsity levels in both language and vision models, without significantly increasing memory consumption when compared to SparseGPT."
    },
    {
        "title": "ADOPD-Instruct: A Large-Scale Multimodal Dataset for Document Editing",
        "link_suffix": "/forum?id=lBlHIQ1psv",
        "link": "https://openreview.net/forum?id=lBlHIQ1psv",
        "pdf_link": "https://openreview.net/pdf?id=lBlHIQ1psv",
        "keywords": "document editing, multimodal dataset, empirical study",
        "abstract": "Visually-rich document editing is a complex multimodal task with a wide range of real-world applications. Despite increasing interest, there is a significant lack of publicly available datasets offering detailed entity-level annotations and step-by-step instructions for the editing process. To address this, we introduce ADOPD-Instruct, a multimodal dataset designed specifically for document editing tasks. ADOPD-Instruct includes visually-rich documents, precise entity-level masks highlighting elements to be edited, and step-by-step edit instructions, targeting both the masking and inpainting processes for text and non-text design elements. ADOPD-Instruct instructions have been carefully curated by human annotators to ensure high quality across the dataset.\nWe conduct extensive evaluations of current Multimodal Large Language Models (MLLMs) and image editing models using various image backbones to assess their performance on document editing. The results reveal substantial challenges: current MLLMs struggle to generate accurate and detailed instructions, while image editing models often fail to follow instructions precisely, particularly with text edits. These findings underscore the limitations of existing models and highlight the importance of annotated datasets like ADOPD-Instruct for advancing this domain. Dataset is available at:https://huggingface.co/datasets/adopd-instruct/ADOPD-Instruct."
    },
    {
        "title": "Do Not Mimic My Voice: Teacher-Guided Unlearning for Zero-Shot Text-to-Speech",
        "link_suffix": "/forum?id=v9LjNopQ6W",
        "link": "https://openreview.net/forum?id=v9LjNopQ6W",
        "pdf_link": "https://openreview.net/pdf?id=v9LjNopQ6W",
        "keywords": "zero-shot tts, machine unlearning, voice privacy",
        "abstract": "The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has enabled high-fidelity voice synthesis from minimal audio cues, raising significant privacy and ethical concerns. In particular, the ability to replicate an individual\u2019s voice without consent poses risks, highlighting the need for machine unlearning techniques to protect voice privacy. In this paper, we introduce the first machine unlearning framework for ZS-TTS, Teacher-Guided Unlearning (TGU), designed to ensure that the model forgets designated speaker identities while retaining its ability to generate accurate speech for other speakers. Unlike conventional unlearning methods, TGU leverages randomness to prevent consistent replication of forget speakers' voices, ensuring unlearned identities remain untraceable. Additionally, we propose a new evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF), which measures the model\u2019s effectiveness in preventing the reproduction of forgotten voices. The experiments conducted on the state-of-the-art model demonstrate that TGU prevents the model from replicating forget speakers' voices while maintaining high quality for other speakers. The demo is available athttps://speechunlearn.github.io/"
    },
    {
        "title": "SIRD: Transformers Assisted Step by Step Symbolic Integration",
        "link_suffix": "/forum?id=R7edIYodis",
        "link": "https://openreview.net/forum?id=R7edIYodis",
        "pdf_link": "https://openreview.net/pdf?id=R7edIYodis",
        "keywords": "Transformers, Symbolic Mathematics, Symbolic Integration, NLP, LLM, SIRD",
        "abstract": "Recently, deep learning has gained popularity in solving statistical or approximate problems. However, working with symbolic data has been challenging for neural networks. Despite this, the natural sciences are making strides in utilizing deep learning for various use cases. In this work, we aim to solve the problem of symbolic integration by using deep learning through integral rule prediction, enabling faster search and better interpretability. We propose a novel symbolic integration rules dataset containing 27 million distinct functions and integration rule pairs. We show that by combining a transformer model trained on this dataset into SymPy's integral_steps function, the number of branches explored during the depth-first-search procedure was reduced by a factor of 3 and successfully solve functions that the original version was unable to handle."
    },
    {
        "title": "CF-GISS: Collision-Free Generative 3D Indoor Scene Synthesis with Controllable Floor Plans and Optimized Layouts",
        "link_suffix": "/forum?id=Yj6IdXSOZk",
        "link": "https://openreview.net/forum?id=Yj6IdXSOZk",
        "pdf_link": "https://openreview.net/pdf?id=Yj6IdXSOZk",
        "keywords": "Indoor Scene Synthesis, 3D scene generation, Procedural generation, Generative models",
        "abstract": "We introduce CF-GISS, a novel framework for generative 3D indoor scene synthesis that ensures collision-free scene layouts by incorporating an image-based intermediate layout representation. In contrast to existing methods that directly construct the scene graph or object list, our approach facilitates substantially more effective prevention of collision artifacts as out-of-distribution (OOD) scenarios during generation. Furthermore, CF-GISS conditions layout generation on floor plans controllable via images or textual descriptions, enabling the production of coherent, house-wide layouts that are robust to variations in geometric and semantic structures. Our framework demonstrates state-of-the-art performance on the 3D-FRONT dataset, delivering high-quality, collision-free scene synthesis while offering flexibility in accommodating a range of floor plan structures. Additionally, we propose a novel dataset with significantly expanded coverage of household items and room configurations, as well as improved data quality."
    },
    {
        "title": "Dynamic Interference Modeling For Estimating Treatment Effects From Dynamic Graphs",
        "link_suffix": "/forum?id=dnUWt1EN72",
        "link": "https://openreview.net/forum?id=dnUWt1EN72",
        "pdf_link": "https://openreview.net/pdf?id=dnUWt1EN72",
        "keywords": "Causal Inference, Treatment effect estimation, Dynamic Graph, Interference",
        "abstract": "Estimating treatment effects can assist decision-making in various areas, such as commerce and medicine. One application of the treatment effect estimation is to predict the effect of an advertisement on the purchase result of a customer, known as individual treatment effect (ITE).  In online websites, the outcome of an individual can be affected by treatments of other individuals, as people often propagate information with their friends,  a phenomenon referred to as interference. Prior studies have attempted to model interference for accurate ITE estimation under a static network among individuals. However, the network usually changes over time in real-world applications due to complex social activities among individuals. For instance,  an individual can follow another individual on one day and unfollow this individual afterward on an online social website. In this case, the outcomes of individuals can be interfered with not only by treatments for current neighbors but also by past information and treatments for past neighbors, which we refer to as \\emph{dynamic interference}. In this work, we model dynamic interference for the first time by developing an architecture to aggregate both the past information of individuals and their neighbors. Specifically, our proposed method contains a mechanism that summarizes historical information of individuals from previous time stamps,  graph neural networks that propagate information about individuals within every time stamp, and a weighting mechanism that estimates the importance of different time stamps. Moreover, the model parameters should gradually change rather than drastically because information of every individual gradually changes over time. To take it into account, we also propose a variant of our method to evolve the model parameters over time with long short-term memory. In our experiments on multiple datasets with dynamic interference, our methods outperform existing methods for ITE estimation because they are unable to capture dynamic interference. This result corroborates the importance of dynamic interference modeling."
    },
    {
        "title": "Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks",
        "link_suffix": "/forum?id=w0b7fCX2nN",
        "link": "https://openreview.net/forum?id=w0b7fCX2nN",
        "pdf_link": "https://openreview.net/pdf?id=w0b7fCX2nN",
        "keywords": "LLM jailbreak, trustworthy ML, safety AI",
        "abstract": "Large Language Models (LLMs) are susceptible to Jailbreaking attacks, which\naim to extract harmful information by subtly modifying the attack query. As de-\nfense mechanisms evolve, directly obtaining harmful information becomes increas-\ningly challenging for Jailbreaking attacks. In this work, inspired from Chomsky\u2019s\ntransformational-generative grammar theory and human practices of indirect con-\ntext to elicit harmful information, we focus on a new attack form, called Contextual\nInteraction Attack. We contend that the prior context\u2014the information preced-\ning the attack query\u2014plays a pivotal role in enabling strong Jailbreaking attacks.\nSpecifically, we propose first multi-turn approach that leverages benign preliminary\nquestions to interact with the LLM. Due to the autoregressive nature of LLMs,\nwhich use previous conversation rounds as context during generation, we guide the\nmodel\u2019s question-responses pair to construct a context that is semantically aligned\nwith the attack query to execute the attack. We conduct experiments on seven\ndifferent LLMs and demonstrate the efficacy of this attack, which is black-box, and\ncan also transfer across LLMs. We believe this can lead to further developments\nand understanding of the security in LLMs"
    },
    {
        "title": "Invar-RAG: Invariant LLM-aligned Retrieval for Better Generation",
        "link_suffix": "/forum?id=8g7hHwSBjH",
        "link": "https://openreview.net/forum?id=8g7hHwSBjH",
        "pdf_link": "https://openreview.net/pdf?id=8g7hHwSBjH",
        "keywords": "Retrieval-augmented Generation; Large Language Model; Information Retrieval",
        "abstract": "Retrieval-augmented generation (RAG) has shown its impressive capability of providing reliable answer predictions and addressing severe hallucination problems. A typical RAG implementation adopts powerful retrieval models to extract external information and leverage large language models (LLMs) to generate corresponding answers. Different with that, recent LLM-based retrieval has raised much attention because it brings substantial improvements in information retrieval (IR) via LLMs\u2019 vigorous semantic understanding capability. However, directly applying LLM to RAG systems remains certain challenges. This may cause feature locality problems since massive parametric knowledge impedes the effective usage of the global information among all corpus, \\eg a LLM-based retriever usually inputs the summary of documents instead of the whole documents. Moreover, various tasks pre-trained in LLMs induce severe variance, which further weakens its performance as the retriever.\nTo address these issues, we propose a novel two-stage fine-tuning architecture called Invar-RAG. In the retrieval stage, a LLM-based retriever is constructed by integrating a LoRA-based representation learning to address the feature locality problem. To justify and consolidate this retrieval\u2019s performance, two patterns (\\ie invariant and variant patterns) and an invariance loss are also developed to alleviate the variance in LLM. Moreover, in the generation stage, a meticulously designed fine-tuning method is devised to improve our LLM for accurate answer generation based on the retrieved information. Experimental results demonstrate that Invar-RAG significantly outperforms existing baselines across three Open-domain Question Answering (ODQA) datasets. The code is available in \\textbf{Supplementary Material} to ease reproducibility."
    }
]
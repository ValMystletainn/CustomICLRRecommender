[
    {
        "title": "Bridge Frame and Event: Common Spatiotemporal Fusion for High-Dynamic Optical Flow",
        "link_suffix": "/forum?id=WmmPHE4k5f",
        "link": "https://openreview.net/forum?id=WmmPHE4k5f",
        "pdf_link": "https://openreview.net/pdf?id=WmmPHE4k5f",
        "keywords": "high-dynamic scene, optical flow, event camera, multimodal fusion",
        "abstract": "High-dynamic scene optical flow is a challenging task, which suffers large displacement. Limited by frame imaging, large displacement causes potential spatial blurry textures due to long exposure and temporal discontinuous motion due to low frame rate, thus deteriorating the spatiotemporal feature of optical flow. Typically, existing methods mainly introduce event camera with high temporal resolution to directly fuse the spatiotemporal features between the two modalities. However, this direct fusion is ineffective, since there exists a large gap due to the heterogeneous data representation between frame and event modalities. To address this issue, we explore a common-latent space as an intermediate bridge to mitigate the modality gap. In this work, we propose a novel common spatiotemporal fusion between frame and event modalities for high-dynamic scene optical flow, including visual boundary localization and motion correlation fusion. Specifically, in visual boundary localization, we figure out that frame and event can be derived into the spatiotemporal gradient maps with the same data representation, where the similarity distribution between the two modalities is consistent with the extracted boundary distribution. This motivates us to design the common spatiotemporal gradient to constrain the localization of the reference boundary as a template. In motion correlation fusion, we discover that the frame-based motion possesses spatially dense but temporally discontinuous correlation, while the event-based motion has spatially sparse but temporally continuous correlation. This inspires us to take the reference boundary template to guide the fusion of the complementary motion knowledge between the two modalities. Moreover, common spatiotemporal fusion can not only relieve the cross-modal feature discrepancy, but also make the fusion process interpretable to achieve dense and continuous optical flow. Extensive experiments have been performed to verify the superiority of the proposed method."
    },
    {
        "title": "Towards Understanding Multi-Round Large Language Model Reasoning: Approximability, Learnability and Generalizability",
        "link_suffix": "/forum?id=MRPCIForrE",
        "link": "https://openreview.net/forum?id=MRPCIForrE",
        "pdf_link": "https://openreview.net/pdf?id=MRPCIForrE",
        "keywords": "Large Language Model, Auto-regressive Language Model, Next-token Prediction",
        "abstract": "Recent advancements in cognitive science and multi-round reasoning techniques for Large Language Models (LLMs) suggest that iterative thinking processes improve problem-solving performance in complex tasks. Inspired by this, approaches like Chain-of-Thought, debating, and self-refinement have been applied to auto-regressive LLMs, achieving significant successes in tasks such as mathematical reasoning, commonsense reasoning, and multi-hop question answering. Despite these successes, the theoretical basis for how multi-round reasoning enhances problem-solving abilities remains underexplored.\nIn this work, we investigate the approximation, learnability, and generalization properties of multi-round auto-regressive models. We show that Transformers with finite context windows are universal approximators for steps of Turing-computable functions and can approximate any Turing-computable sequence-to-sequence function through multi-round reasoning. We extend PAC learning to sequence generation and demonstrate that multi-round generation is learnable even when the sequence length exceeds the model's context window. \nFinally, we examine how generalization error propagates across rounds, and show how the aforementioned approaches can help constrain this error, ensuring outputs stay within an expectation boundary. This work sheds light on the systemic theoretical foundations of multi-round sequence learning and reasoning, emphasizing its role in inference complexity."
    },
    {
        "title": "Bridge the Gap between SNN and ANN  for Image Restoration",
        "link_suffix": "/forum?id=G3vceNrP4o",
        "link": "https://openreview.net/forum?id=G3vceNrP4o",
        "pdf_link": "https://openreview.net/pdf?id=G3vceNrP4o",
        "keywords": "Computer Vision",
        "abstract": "Models of dense prediction based on traditional Artificial Neural Networks (ANNs) require a lot of energy, especially for image restoration tasks. Currently, neural networks based on the SNN framework are beginning to make their mark in the field of image restoration, especially as they typically use less than 10% of the energy of ANNs with the same architecture. However, training an SNN is much more expensive than training an ANN, due to the use of the heuristic gradient descent strategy. In other words, the process of SNN's potential membrane signal changing from sparse to dense is very slow, which affects the convergence of the whole model. To tackle this problem, we propose a novel distillation technique, called asymmetric framework (ANN-SNN) distillation, in which the teacher is an ANN and the student is an SNN. Specifically, we leverage the intermediate features (feature map) learned by the ANN as hints to guide the training process of the SNN. This approach not only accelerates the convergence of the SNN but also improves its final performance, effectively bridging the gap between the efficiency of the SNN and the superior learning capabilities of ANN. Extensive experimental results show that our designed SNN-based image restoration model, which has only 1/300 the number of parameters of the teacher network and 1/50 the energy consumption of the teacher network, is as good as the teacher network in some denoising tasks."
    },
    {
        "title": "Find A Winning Sign: Sign Is All We Need to Win the Lottery",
        "link_suffix": "/forum?id=cLtE4qoPlD",
        "link": "https://openreview.net/forum?id=cLtE4qoPlD",
        "pdf_link": "https://openreview.net/pdf?id=cLtE4qoPlD",
        "keywords": "lottery ticket hypothesis, network pruning, linear mode connectivity",
        "abstract": "The lottery ticket hypothesis (LTH) posits the existence of a sparse network (a.k.a. winning ticket) that can generalize comparably to its dense counterpart after training from initialization. However, early works fail to generalize its observation and method to large-scale settings. While recent methods, such as weight rewinding or learning rate rewinding (LRR), may have found effective pruning methods, we note that they still struggle with identifying a winning ticket. In this paper, we take a step closer to finding a winning ticket by arguing that a signed mask, a binary mask with parameter sign information, can transfer the capability to achieve strong generalization after training (i.e., generalization potential) to a randomly initialized network. We first share our observation on the subnetwork trained by LRR: if the parameter signs are maintained, the LRR-driven subnetwork retains its generalization potential even when the parameter magnitudes are randomly initialized, excluding those of normalization layers. However, this fails when the magnitudes of normalization layer parameters are initialized together. To tackle the significant influence of normalization layer parameters, we propose AWS, a slight variation of LRR to find A Winning Sign. Specifically, we encourage low error barriers along the linear path connecting the subnetwork trained by AWS to its counterpart with initialized normalization layer parameters, maintaining the generalization potential even when all parameters are initialized. Interestingly, we observe that across various architectures and datasets, a signed mask of the AWS-driven subnetwork can allow a randomly initialized network to perform comparably to a dense network, taking a step closer to the goal of LTH."
    },
    {
        "title": "IPDreamer: Appearance-Controllable 3D Object Generation with Complex Image Prompts",
        "link_suffix": "/forum?id=3PguviI7Uf",
        "link": "https://openreview.net/forum?id=3PguviI7Uf",
        "pdf_link": "https://openreview.net/pdf?id=3PguviI7Uf",
        "keywords": "3D generation, Diffusion model",
        "abstract": "Recent advances in 3D generation have been remarkable, with methods such as DreamFusion leveraging large-scale text-to-image diffusion-based models to guide 3D object generation. These methods enable the synthesis of detailed and photorealistic textured objects. However, the appearance of 3D objects produced by such text-to-3D models is often unpredictable, and it is hard for single-image-to-3D methods to deal with images lacking a clear subject, complicating the generation of appearance-controllable 3D objects from complex images. To address these challenges, we present IPDreamer, a novel method that captures intricate appearance features from complexImagePrompts and aligns the synthesized 3D object with these extracted features, enabling high-fidelity, appearance-controllable 3D object generation. Our experiments demonstrate that IPDreamer consistently generates high-quality 3D objects that align with both the textual and complex image prompts, highlighting its promising capability in appearance-controlled, complex 3D object generation."
    },
    {
        "title": "Trans4D: Realistic Geometry-Aware Transition for Compositional Text-to-4D Synthesis",
        "link_suffix": "/forum?id=gkOtsxD6fr",
        "link": "https://openreview.net/forum?id=gkOtsxD6fr",
        "pdf_link": "https://openreview.net/pdf?id=gkOtsxD6fr",
        "keywords": "Text-to-4D generation, Scene transition",
        "abstract": "Recent advances in diffusion models have demonstrated exceptional capabilities in image and video generation, further improving the effectiveness of 4D synthesis. Existing 4D generation methods can generate high-quality 4D objects or scenes based on user-friendly conditions, benefiting the gaming and video industries. However, these methods struggle to synthesize significant object deformation of complex 4D transitions and interactions within scenes. To address this challenge, we proposeTrans4D, a novel text-to-4D synthesis framework that enables realistic complex scene transitions. Specifically, we first use multi-modal large language models (MLLMs) to produce a physic-aware scene description for 4D scene initialization and effective transition timing planning. Then we propose a geometry-aware 4D transition network to realize a complex scene-level 4D transition based on the plan, which involves expressive geometrical object deformation. Extensive experiments demonstrate thatTrans4Dconsistently outperforms existing state-of-the-art methods in generating 4D scenes with accurate and high-quality transitions, validating its effectiveness."
    },
    {
        "title": "Robust Latent Neural Operators for a Family of Systems with Sparse Observations",
        "link_suffix": "/forum?id=QIsnwejVYE",
        "link": "https://openreview.net/forum?id=QIsnwejVYE",
        "pdf_link": "https://openreview.net/pdf?id=QIsnwejVYE",
        "keywords": "Neural operator, complex system, variational autoencoder, recurrent neural network",
        "abstract": "Neural operator methods have achieved significant success in the efficient simulation and inverse problems of complex systems by learning a mapping between two infinite-dimensional Banach spaces. However, existing methods still exhibit room for optimization in terms of robustness and modeling accuracy. Specifically, existing methods are characterized by sensitivity to noise and a tendency to overlook the importance of sparse observations. Therefore, we propose a robust latent neural operator based on the variational autoencoder framework. In this method, an encoder based on recurrent neural networks effectively extracts sequential information and dynamical characteristics embedded in sparse observations. Subsequently, a neural operator in latent space and a decoder facilitate the modelling of the original system. Additionally, for certain higher-dimensional systems, opting for a lower-dimensional latent space can reduce task complexity while still maintaining satisfactory modeling performance. We conduct experiments across several representative systems, and the results validate that our method achieves superior modeling accuracy and enhanced robustness compared to the state of the art baseline approaches."
    },
    {
        "title": "Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation",
        "link_suffix": "/forum?id=qPx3i9sMxv",
        "link": "https://openreview.net/forum?id=qPx3i9sMxv",
        "pdf_link": "https://openreview.net/pdf?id=qPx3i9sMxv",
        "keywords": "audio generation, multimodal learning, stereo audio",
        "abstract": "Recently, diffusion models have achieved great success in mono-channel audio generation.\nHowever, when it comes to stereo audio generation, the soundscapes often have a complex scene of multiple objects and directions.\nControlling stereo audio with spatial contexts remains challenging due to high data costs and unstable generative models. \nTo the best of our knowledge, this work represents the first attempt to address these issues.\nWe first construct a large-scale, simulation-based, and GPT-assisted dataset, BEWO-1M, with abundant soundscapes and descriptions even including moving and multiple sources.\nBeyond text modality, we have also acquired a set of images and rationally paired stereo audios through retrieval to advance multimodal generation. \nExisting audio generation models tend to generate rather random spatial audio. \nTo provide accurate guidance for Latent Diffusion Models, we introduce the SpatialSonic model utilizing spatial-aware encoders and azimuth state matrices to reveal reasonable spatial guidance. \nBy leveraging spatial guidance, our unified model not only achieves the objective of generating immersive and controllable spatial audio from text and image but also enables interactive audio generation during inference.\nFinally, under fair settings, we conduct subjective and objective evaluations on simulated and real-world data to compare our approach with prevailing methods. \nThe results demonstrate the effectiveness of our method, highlighting its capability to generate spatial audio that adheres to physical rules.\nOur demos are available athttps://immersive-audio.github.io/. Our code, model, and dataset will be released soon."
    },
    {
        "title": "Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation",
        "link_suffix": "/forum?id=OdnqG1fYpo",
        "link": "https://openreview.net/forum?id=OdnqG1fYpo",
        "pdf_link": "https://openreview.net/pdf?id=OdnqG1fYpo",
        "keywords": "MRI Reconstruction, Motion Correction, Neural Representation, NeRF, Unsupervised Learning",
        "abstract": "Motion correction (MoCo) in radial MRI is a particularly challenging problem due to the unpredictability of subject movement. Current state-of-the-art (SOTA) MoCo algorithms often rely on extensive high-quality MR images to pre-train neural networks, which constrains the solution space and leads to outstanding image reconstruction results. However, the need for large-scale datasets significantly increases costs and limits model generalization. In this work, we propose Moner, an unsupervised MoCo method that jointly reconstructs artifact-free MR images and estimates accurate motion from undersampled, rigid motion-corrupted k-space data, without requiring any training data. Our core idea is to leverage the continuous prior of implicit neural representation (INR) to constrain this ill-posed inverse problem, facilitating optimal solutions. Specifically, we integrate a quasi-static motion model into the INR, granting its ability to correct subject's motion. To stabilize model optimization, we reformulate radial MRI reconstruction as a back-projection problem using the Fourier-slice theorem. Additionally, we propose a novel coarse-to-fine hash encoding strategy, significantly enhancing MoCo accuracy. Experiments on multiple MRI datasets show our Moner achieves performance comparable to SOTA MoCo techniques on in-domain data, while demonstrating significant improvements on out-of-domain data. The code is available at:https://anonymous.4open.science/r/moner_mri"
    },
    {
        "title": "Fine-Grained Emotion Recognition with In-Context Learning: A Prototype Theory Approach",
        "link_suffix": "/forum?id=EVg9lwHFJs",
        "link": "https://openreview.net/forum?id=EVg9lwHFJs",
        "pdf_link": "https://openreview.net/pdf?id=EVg9lwHFJs",
        "keywords": "fine-grained emotion recognition, in-context learning, ICL, large language model, LLMs",
        "abstract": "In-context learning (ICL) achieves remarkable performance in various domains such as knowledge acquisition, commonsense reasoning, and semantic understanding. \nHowever, its effectiveness deteriorates significantly in emotion detection tasks, particularly in fine-grained emotion recognition. \nThe reasons behind this decline still remain unclear.\nIn this paper, we explore the underlying reasons of ICL's suboptimal performance through the lens of prototype theory.\nOur investigation reveals that ICL aligns with the principles of prototype theory when applied to fine-grained emotion recognition tasks. \nAccording to prototype theory, effective emotion recognition requires: Referencing well-represented emotional prototypes that are similar to the query emotions, and making predictions based on the closest emotional similarity.\nBuilding on this insight, ICL has three main shortcomings: \n(1) It uses oversimplified single-emotion labels for prototypes, leading to inaccurate emotion representation.\n(2) It references semantically similar but emotionally distant prototypes.\n(3) It considers all emotion categories as candidates, leading to interference from irrelevant emotions and inaccurate predictions.To address these shortcomings, we propose an Emotion Context Learning method (E-ICL) for fine-grained emotion recognition. \nE-ICL first employs a dynamic soft-label strategy to create multi-dimensional emotional labels for accurate prototype representation. \nIt then selects emotionally similar prototypes as references for emotion prediction.\nFinally, it uses an emotion exclusion strategy to eliminate interference from dissimilar emotions by selecting similar emotions as candidates, resulting in more robust and accurate predictions.\nNote that our approach is implemented with the aid of a plug-and-play emotion auxiliary model, requiring no additional training. \nExtensive experiments conducted on fine-grained emotion datasets\u2014EDOS, Empathetic-Dialogues, EmpatheticIntent, and GoEmotions\u2014demonstrate that E-ICL significantly outperforms existing methods in emotion prediction performance. Moreover, even when the emotion auxiliary model accounts for less than 10% of the LLMs' capacity, E-ICL consistently boosts LLM performance by over 4% across multiple datasets."
    },
    {
        "title": "Super Robot View Transformer",
        "link_suffix": "/forum?id=1g4s7ME93g",
        "link": "https://openreview.net/forum?id=1g4s7ME93g",
        "pdf_link": "https://openreview.net/pdf?id=1g4s7ME93g",
        "keywords": "robotic manipulation, multi-task learning, robot view transformer",
        "abstract": "Learning a single model for multiple robotic manipulation tasks, particularly high-precision tasks, has been a long-standing challenge in robotics research due to uncertainties inherent in both the model and the data. These uncertainties, namely epistemic uncertainty arising from model limitations and aleatoric uncertainty stemming from data variability, hinder precise control.\nWhile the Robot View Transformer (RVT) improves performance by re-rendering point clouds from fixed viewpoints and processing structured 2D virtual images, it still suffers from occlusion artifacts in rendering and limited action precision due to resolution constraints.\nTo address these limitations, we propose the Super Robot View Transformer (S-RVT) framework, which integrates three novel components: the Super Point Renderer (S-PR), the Super-resolution Multi-View Transformer (S-MVT), and the Hierarchical Sampling Policy (HSP). The S-PR enhances the rendering process to mitigate occlusion artifacts, while the S-MVT integrates super-resolution to the output heatmaps, enabling finer-grained manipulation. The HSP efficiently samples multi-view heatmaps in 3D space to obtain accurate 3D poses.\nThese innovations collaboratively mitigate the challenges of occlusion and precision in manipulation tasks. Our experimental results demonstrate that S-RVT achieves a success rate of 87.8 % across 18 manipulation tasks, surpassing the state-of-the-art of 81.4 %. Notably, for high-precision manipulation tasks, S-RVT exhibits nearly a two-fold improvement over existing methods, underscoring its effectiveness in precise control scenarios. Our code and trained models will be released to support further research."
    },
    {
        "title": "SAM 2: Segment Anything in Images and Videos",
        "link_suffix": "/forum?id=Ha6RTeWMd0",
        "link": "https://openreview.net/forum?id=Ha6RTeWMd0",
        "pdf_link": "https://openreview.net/pdf?id=Ha6RTeWMd0",
        "keywords": "computer vision, video segmentation, image segmentation",
        "abstract": "We present Segment Anything Model 2 (SAM 2), a foundation model towards solving promptable visual segmentation in images and videos. We build a data engine, which improves model and data via user interaction, to collect the largest video segmentation dataset to date. Our model is a simple transformer architecture with streaming memory for real-time video processing. SAM 2 trained on our data provides strong performance across a wide range of tasks. In video segmentation, we observe better accuracy, using 3x fewer interactions than prior approaches. In image segmentation, our model is more accurate and 6x faster than the Segment Anything Model (SAM). We believe that our data, model, and insights will serve as a significant milestone for video segmentation and related perception tasks. We are releasing our main model, the dataset, an interactive demo and code."
    },
    {
        "title": "Training-free Long Video Generation with Chain of Diffusion Model Experts",
        "link_suffix": "/forum?id=3hc2ESNU6n",
        "link": "https://openreview.net/forum?id=3hc2ESNU6n",
        "pdf_link": "https://openreview.net/pdf?id=3hc2ESNU6n",
        "keywords": "generative models, diffusion models, video generation",
        "abstract": "Video generation models hold substantial potential in areas such as filmmaking. However, current video diffusion models need high computational costs and produce suboptimal results due to high complexity of video generation task. In this paper, we propose \\textbf{ConFiner}, an efficient high-quality video generation framework that decouples video generation into easier subtasks: structure \\textbf{con}trol and spatial-temporal re\\textbf{fine}ment. It can generate high-quality videos with chain of off-the-shelf diffusion model experts, each expert responsible for a decoupled subtask. During the refinement, we introduce coordinated denoising, which can merge multiple diffusion experts' capabilities into a single sampling. Furthermore, we design ConFiner-Long framework, which can generate long coherent video with three constraint strategies on ConFiner. Experimental results indicate that with only 10% of the inference cost, our ConFiner surpasses representative models like Lavie and Modelscope across all objective and subjective metrics. And ConFiner-Long can generate high-quality and coherent videos with up to 600 frames."
    },
    {
        "title": "Gated Delta Networks: Improving Mamba2 with Delta Rule",
        "link_suffix": "/forum?id=r8H7xhYPwz",
        "link": "https://openreview.net/forum?id=r8H7xhYPwz",
        "pdf_link": "https://openreview.net/pdf?id=r8H7xhYPwz",
        "keywords": "linear RNN, state-space model, linear transformer, subquadractic model, linear attention, delta rule, mamba",
        "abstract": "Linear Transformers have emerged as efficient alternatives to standard Transformers due to their inference efficiency, achieving competitive performance across various tasks, though they often struggle with recall-intensive tasks. Recently, two mechanisms\u2014the gating mechanism and the delta update rule\u2014have been used to enhance linear Transformers. We found these two mechanisms to be complementary: the gating mechanism enables fast, adaptive memory erasure, while the delta rule allows for more precise and targeted memory updates. In this work, we introduce the gated delta rule, which combines both mechanisms, and extend the delta rule's parallel algorithm to incorporate gating. Our experiments demonstrate that linear Transformers with the gated delta rule, dubbed Gated DeltaNet, consistently outperform Mamba2 (a gated linear transformer) and DeltaNet in language modeling, common sense reasoning, and real-world in-context recall-intensive tasks. Additionally, we explore hybrid models that combine Gated DeltaNet layers with sliding window attention or Mamba2 layers, further enhancing retrieval capabilities."
    },
    {
        "title": "Structured Mixture-of-Experts LLMs Compression  via Singular Value Decomposition",
        "link_suffix": "/forum?id=ho7ZUS1z8A",
        "link": "https://openreview.net/forum?id=ho7ZUS1z8A",
        "pdf_link": "https://openreview.net/pdf?id=ho7ZUS1z8A",
        "keywords": "Mixture of Experts, Efficient Large Language Models, Low-Rank Decomposition, Network Sparsity",
        "abstract": "Mixture of Experts (MoE) architecture has emerged as a powerful paradigm in the development of Large Language Models (LLMs), offering superior scaling capabilities and reduced computational costs. However, the increased parameter budgets and memory overhead associated with MoE LLMs pose significant challenges to their efficiency and widespread deployment. In this paper, we present MoE-SVD, the first decomposition-based compression framework tailored for MoE LLMs without any extra training. By harnessing the power of Singular Value Decomposition (SVD), MoE-SVD addresses the critical issues of decomposition collapse and matrix redundancy in MoE architectures.   Specifically, we first decompose experts into compact low-rank matrices, resulting in accelerated inference and memory optimization. In particular, we propose selective decomposition strategy by measuring sensitivity metrics based on weight singular values and activation statistics to automatically identify decomposable expert layers. Then, we share a single V-matrix across all experts and employ a top-k selection for U-matrices. This low-rank matrix sharing and trimming scheme allows for significant parameter reduction while preserving diversity among experts.  Comprehensive experiments conducted on Mixtral-8\u00d77B|22B, Phi-3.5-MoE and DeepSeekMoE across multiple datasets reveal that MoE-SVD consistently outperforms existing compression methods in terms of performance-efficiency tradeoffs. Notably, we achieve a remarkable 60% compression ratio on Mixtral-7x8B and Phi-3.5-MoE, resulting in a 1.5$\\times$ inference acceleration with minimal performance degradation. Codes are available in the supplementary materials."
    },
    {
        "title": "NoRA: Nested Low-Rank Adaptation for Efficient Fine-Tuning Large Models",
        "link_suffix": "/forum?id=6nZwOYDcQx",
        "link": "https://openreview.net/forum?id=6nZwOYDcQx",
        "pdf_link": "https://openreview.net/pdf?id=6nZwOYDcQx",
        "keywords": "Parameter-efficient fine-tuning, Low-Rank Adaptation, Large Language Models",
        "abstract": "Low-Rank Adaptation (LoRA) has become a popular paradigm for fine-tuning large models, but it still necessitates a substantial number of training parameters. To address this issue, we first conduct comprehensive empirical studies on parameter-efficient LoRA structure. Then, we establish design guidelines that emphasize the use of serial structures, optimal placements, and nested LoRA. Based on these insights, we present NoRA, a nested parameter-efficient LoRA structure that revolutionizes the initialization and fine-tuning of projection matrices. Our NoRA's innovative approach involves freezing outer layer LoRA weights and employing a serial inner layer design, enabling precise task-specific adaptations while maintaining  compact training parameters. In addition, we propose an activation-aware Singular Value Decomposition (AwSVD) that adjusts the weight matrices based on activation distributions for initialization of outer layer LoRA weights. This schema  enhances decomposition accuracy and mitigates computational errors.  Extensive evaluations across multiple linguistic and visual tasks demonstrate that NoRA outperforms state-of-the-art LoRA variants, achieving significant improvements in efficiency and effectiveness on models such as Mistral-7B, Gemma-7B, and LLaMA-3 8B. Notably, NoRA reduces fine-tuning parameters|training-time|memory-usage by 85.5%|37.5%|8.9% and enhances performance by 1.9%, compared to LoRA on LLaMA-3 8B. Codes are available in the supplementary materials."
    },
    {
        "title": "DrivingRecon: Large 4D Gaussian Reconstruction Model For Autonomous Driving",
        "link_suffix": "/forum?id=0PcJAHbSmc",
        "link": "https://openreview.net/forum?id=0PcJAHbSmc",
        "pdf_link": "https://openreview.net/pdf?id=0PcJAHbSmc",
        "keywords": "4D Gaussian Reconstruction;  Autonomous Driving",
        "abstract": "Photorealistic 4D reconstruction of street scenes is essential for developing real-world simulators in autonomous driving. However, most existing methods perform this task offline and rely on time-consuming iterative processes, limiting their practical applications. To this end, we introduce the Large 4D Gaussian  Reconstruction Model (DrivingRecon), a generalizable driving scene reconstruction model, which directly predicts 4D Gaussian from surround-view videos. To better integrate the surround-view images, the Prune and Dilate Block (PD-Block) is proposed to eliminate overlapping Gaussian points between adjacent views and remove redundant background points. \nTo enhance cross-temporal information, dynamic and static decoupling is tailored to learn geometry and motion features better. Experimental results demonstrate that DrivingRecon significantly improves scene reconstruction quality and novel view synthesis compared to existing methods. Furthermore, we explore applications of DrivingRecon in model pre-training, vehicle adaptation, and scene editing. Our code will be made publicly available."
    },
    {
        "title": "GBO: A Multi-Granularity Optimization Algorithm via Granular-ball for Continuous Problems",
        "link_suffix": "/forum?id=pGMVuLvI5t",
        "link": "https://openreview.net/forum?id=pGMVuLvI5t",
        "pdf_link": "https://openreview.net/pdf?id=pGMVuLvI5t",
        "keywords": "Evolutionary computation, Granular-ball",
        "abstract": "Optimization problems aim to find the optimal solution, which is becoming increasingly complex and difficult to solve. Traditional evolutionary optimization methods always overlook the granular characteristics of solution space. In the real scenario of numerous optimization, the solution space is typically partitioned into sub-regions characterized by varying degree distributions. These sub-regions present different granularity characteristics at search potential and difficulty. Considering the granular characteristics of the solution space, the number of coarse-grained regions is smaller than the number of points, so the calculation is more efficient. On the other hand, coarse-grained characteristics are not easily affected by fine-grained sample points, so the calculation is more robust. To this end, this paper proposes a new multi-granularity evolutionary optimization method, namely Granular-ball Optimization (GBO) algorithm, which characterizes and searches the solution space from coarse to fine. Specifically, using granular-balls instead of traditional points for optimization increases the diversity and robustness of the random search process. At the same time, the search range in different iteration processes is limited by the radius of granular-balls, covering the solution space from large to small. And the mechanism of granular-ball splitting is applied to continuously split and evolve the large granular-balls into smaller for refining the solution space. Extensive experiments on commonly used benchmarks have shown that GBO outperforms popular and advanced evolutionary algorithms. The code is available in the Supplementary Materials."
    },
    {
        "title": "ARC-RL: Self-Evolution Continual Reinforcement Learning via Action Representation Space",
        "link_suffix": "/forum?id=M9p2SIq0Oj",
        "link": "https://openreview.net/forum?id=M9p2SIq0Oj",
        "pdf_link": "https://openreview.net/pdf?id=M9p2SIq0Oj",
        "keywords": "continual learning, lifelong learning, reinforcement learning",
        "abstract": "Continual Reinforcement Learning (CRL) is a powerful tool that enables agents to learn a sequence of tasks, accumulating knowledge learned in the past and using it for problemsolving or future task learning. However, existing CRL methods all assume that the agent\u2019s capabilities remain static within dynamic environments, which doesn\u2019t reflect realworld scenarios where capabilities evolve. This paper introducesSelf-Evolution Continual Reinforcement Learning(SE-CRL), a new and realistic problem where the agent\u2019s action space continually changes. It presents a significant challenge for RL agents: How can policy generalization across different action spaces be achieved? Inspired by the cortical functions that lead to consistent human behavior, we propose anActionRepresentationContinualReinforcementLearning framework (ARC-RL) to address this challenge. Our framework builds a representation space for actions by self-supervised learning on transitions, decoupling the agent\u2019s policy from the specific action space. For a new action space, the decoder of the action representation is expanded or masked for adaptation and regularized fine-tuned to improve the stability of the policy. Furthermore, we release a benchmark based on MiniGrid to validate the effectiveness of methods for SE-CRL. Experimental results demonstrate that our framework significantly outperforms popular CRL methods by generalizing the policy across different action spaces."
    },
    {
        "title": "Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple Logits Retargeting Approach",
        "link_suffix": "/forum?id=OeKp3AdiVO",
        "link": "https://openreview.net/forum?id=OeKp3AdiVO",
        "pdf_link": "https://openreview.net/pdf?id=OeKp3AdiVO",
        "keywords": "Long-Tailed Recognition and Decoupled Training",
        "abstract": "In the field of long-tailed recognition, the Decoupled Training paradigm has shown exceptional promise by dividing training into two stages: representation learning and classifier re-training.  While previous work has tried to improve both stages simultaneously, this complicates isolating the effect of classifier re-training.  Recent studies reveal that simple regularization can produce strong feature representations, highlighting the need to reassess classifier re-training methods.  In this study, we revisit classifier re-training methods based on a unified feature representation and re-evaluate their performances. \nWe propose two new metrics, Logits Magnitude and Regularized Standard Deviation, to compare the differences and similarities between various methods. \nUsing these two newly proposed metrics, we demonstrate that when the Logits Magnitude across classes is nearly balanced, further reducing its overall value can effectively decrease errors and disturbances during training, leading to better model performance. \nBased on our analysis using these metrics, we observe that adjusting the logits could improve model performance, leading us to develop a simple label over-smoothing approach to adjust the logits without requiring prior knowledge of class distribution.\nThis method softens the original one-hot labels by assigning a probability slightly higher than $\\frac{1}{K}$ to the true class and slightly lower than $\\frac{1}{K}$ to the other classes, where $K$ is the number of classes.\nOur method achieves state-of-the-art performance on various imbalanced datasets, including CIFAR100-LT, ImageNet-LT, and iNaturalist2018."
    },
    {
        "title": "Safeguarding System Prompts for LLMs",
        "link_suffix": "/forum?id=gnJwb74rWQ",
        "link": "https://openreview.net/forum?id=gnJwb74rWQ",
        "pdf_link": "https://openreview.net/pdf?id=gnJwb74rWQ",
        "keywords": "large language models, system prompts, privacy",
        "abstract": "Large language models (LLMs) are increasingly utilized in applications where system prompts, which guide model outputs, play a crucial role. These prompts often contain business logic and sensitive information, making their protection essential. However, adversarial and even regular user queries can exploit LLM vulnerabilities to expose these hidden prompts. To address this issue, we present PromptKeeper, a novel defense mechanism for system prompt privacy. By reliably detecting worst-case leakage and regenerating outputs without the system prompt when necessary, PromptKeeper ensures robust protection against prompt extraction attacks via either adversarial or regular queries, while preserving conversational capability and runtime efficiency during benign user interactions."
    },
    {
        "title": "Sequential Order-Robust Mamba for Time Series Forecasting",
        "link_suffix": "/forum?id=fyl82vAale",
        "link": "https://openreview.net/forum?id=fyl82vAale",
        "pdf_link": "https://openreview.net/pdf?id=fyl82vAale",
        "keywords": "Mamba, State-space Model, Time Series",
        "abstract": "Mamba has recently emerged as a promising alternative to Transformers, offering near-linear complexity in processing sequential data.\nHowever, while channels in time series (TS) data have no specific order in general, recent studies have adopted Mamba to capture channel dependencies (CD) in TS, introducing a sequential order bias. To address this issue, we propose SOR-Mamba, a TS forecasting method that 1) incorporates a regularization strategy to minimize the discrepancy between two embedding vectors generated from data with reversed channel orders, thereby enhancing robustness to channel order, and 2) eliminates the 1D-convolution originally designed to capture local information in sequential data. Furthermore, we introduce channel correlation modeling (CCM), a pretraining task aimed at preserving correlations between channels from the data space to the latent space in order to enhance the ability to capture CD.\nExtensive experiments demonstrate the efficacy of the proposed method across standard and transfer learning scenarios."
    },
    {
        "title": "You Know What I'm Saying: Jailbreak Attack via Implicit Reference",
        "link_suffix": "/forum?id=yVVzaRE8Pi",
        "link": "https://openreview.net/forum?id=yVVzaRE8Pi",
        "pdf_link": "https://openreview.net/pdf?id=yVVzaRE8Pi",
        "keywords": "Adversarial attacks, Jailbreak, Security, Black box, LLM, Alignment, Cross-Modality alignment, in context learning",
        "abstract": "While recent advancements in large language model (LLM) alignment have enabled the effective identification of malicious objectives involving scene nesting and keyword rewriting, our study reveals that these methods remain inadequate at detecting malicious objectives expressed through context within nested harmless objectives.\nThis study identifies a previously overlooked vulnerability, which we term $\\textbf{A}$ttack via $\\textbf{I}$mplicit $\\textbf{R}$eference ($\\textbf{AIR}$). AIR decomposes a malicious objective into permissible objectives and links them through implicit references within the context. This method employs multiple related harmless objectives to generate malicious content without triggering refusal responses, thereby effectively bypassing existing detection techniques.\nOur experiments demonstrate AIR's effectiveness across state-of-the-art LLMs, achieving an attack success rate (ASR) exceeding $\\textbf{90}$% on most models, including GPT-4o, Claude-3.5-Sonnet, and Qwen-2-72B. Notably, we observe an inverse scaling phenomenon, where larger models are more vulnerable to this attack method. These findings underscore the urgent need for defense mechanisms capable of understanding and preventing contextual attacks. Furthermore, we introduce a cross-model attack strategy that leverages less secure models to generate malicious contexts, thereby further increasing the ASR when targeting other models."
    },
    {
        "title": "STBLLM: Breaking the 1-Bit Barrier with Structured Binary LLMs",
        "link_suffix": "/forum?id=6XUSDvBFkV",
        "link": "https://openreview.net/forum?id=6XUSDvBFkV",
        "pdf_link": "https://openreview.net/pdf?id=6XUSDvBFkV",
        "keywords": "structured sparsification, language model, model compression, binary neural networks, computational efficiency",
        "abstract": "In this paper, we present the first structural binarization method for LLM compression to less than 1-bit precision. Although LLMs have achieved remarkable performance, their memory-bound nature during the inference stage hinders the adoption of resource-constrained devices. Reducing weights to 1-bit precision through binarization substantially enhances computational efficiency. We observe that some weights in binarized LLMs can be randomly flipped without significant performance degradation, suggesting the potential for further compression. To exploit this, our STBLLM employs an N:M sparsity technique to achieve structural binarization of the weights. Specifically, we introduce a novel Standardized Importance (SI) metric, which considers weight magnitude and input feature norm to more accurately assess weight significance. Then, we propose a layer-wise approach, allowing different layers of the LLM to be sparsified with varying N:M ratios, thereby balancing compression and accuracy. Furthermore, we implement a fine-grained grouping strategy for less important weights, applying distinct quantization schemes to sparse, intermediate, and dense regions. Finally, we design a specialized CUDA kernel to support structural binarization. We conduct extensive experiments on LLaMA-1/2/3, OPT family, and Mistral to evaluate the effectiveness of STBLLM. The results demonstrate that our approach performs better than other compressed binarization LLM methods while significantly reducing memory requirements."
    },
    {
        "title": "Partial Channel Dependence with Channel Masks for Time Series Foundation Models",
        "link_suffix": "/forum?id=xVU6rY37X9",
        "link": "https://openreview.net/forum?id=xVU6rY37X9",
        "pdf_link": "https://openreview.net/pdf?id=xVU6rY37X9",
        "keywords": "Time Series, Foundation Model, Channel Dependence, Transformer",
        "abstract": "Recent advancements in foundation models have been successfully extended to the time series (TS) domain, facilitated by the emergence of large-scale TS datasets. However, previous efforts have primarily focused on designing model architectures to address explicit heterogeneity among datasets such as various numbers of channels, while often overlooking implicit heterogeneity such as varying dependencies between channels. In this work, we introduce the concept of partial channel dependence (PCD), which enables a more sophisticated adjustment of channel dependencies based on dataset-specific information. To achieve PCD, we propose a channel mask that captures the relationships between channels within a dataset using two key components: 1) a correlation matrix that encodes relative dependencies between channels, and 2) domain parameters that learn the absolute dependencies specific to each dataset, refining the correlation matrix. We validate the effectiveness of PCD across four tasks in TS including forecasting, classification, imputation, and anomaly detection, under diverse settings, including few-shot and zero-shot scenarios with both TS foundation models and single-task models."
    }
]
[{"title": "Scaling Laws For Mixed Quantization In Large Language Models", "link_suffix": "/forum?id=UldnqRQWKS", "link": "https://openreview.net/forum?id=UldnqRQWKS", "pdf_link": "https://openreview.net/pdf?id=UldnqRQWKS", "keywords": "large language model, scaling law, quantisation", "abstract": "Post-training quantization of Large Language Models (LLMs) has proven effective in reducing the computational requirements for running inference on these models. In this study, we focus on a straightforward question: When aiming for a specific accuracy or perplexity target for low-precision quantization, how many high-precision numbers or calculations are required to preserve as we scale LLMs to larger sizes? We first introduce a critical metric named the quantization ratio, which compares the number of parameters quantized to low-precision arithmetic against the total parameter count. Through extensive and carefully controlled experiments across different model families, arithmetic types, and quantization granularities (e.g. layer-wise, matmul-wise), we identify two central phenomenons. 1) The larger the models, the better they can preserve performance with an increased quantization ratio, as measured by perplexity in pre-training tasks or accuracy in downstream tasks. 2) The finer the granularity of mixed-precision quantization (e.g., matmul-wise), the more the model can increase the quantization ratio. \nWe believe these observed phenomena offer valuable insights for future AI hardware design and the development of advanced Efficient AI algorithms.", "title_embedding_index": 18450, "title_abs_embedding_index": 18475}, {"title": "Fast Training of Sinusoidal Neural Fields via Scaling Initialization", "link_suffix": "/forum?id=Sr5XaZzirA", "link": "https://openreview.net/forum?id=Sr5XaZzirA", "pdf_link": "https://openreview.net/pdf?id=Sr5XaZzirA", "keywords": "sinusoidal neural fields, fast training, initializations", "abstract": "Neural fields are an emerging paradigm that represent data as continuous functions parameterized by neural networks. Despite many advantages, neural fields often have a high training cost, which prevents a broader adoption. In this paper, we focus on a popular family of neural fields, called sinusoidal neural fields (SNFs), and study how it should be initialized to maximize the training speed. We find that the standard initialization scheme for SNFs---designed based on the signal propagation principle---is suboptimal. In particular, we show that by simply multiplying each weight (except for the last layer) by a constant, we can accelerate SNF training by 10$\\times$. This method, coinedweight scaling, consistently provides a significant speedup over various data domains, allowing the SNFs to train faster than more recently proposed architectures. To understand why the weight scaling works well, we conduct extensive theoretical and empirical analyses which reveal that the weight scaling not only resolves the spectral bias quite effectively but also enjoys a well-conditioned optimization trajectory.", "title_embedding_index": 18451, "title_abs_embedding_index": 18476}, {"title": "Utilizing Visual Properties to Achieve Better Representations of Objects", "link_suffix": "/forum?id=EQAHilKZ8D", "link": "https://openreview.net/forum?id=EQAHilKZ8D", "pdf_link": "https://openreview.net/pdf?id=EQAHilKZ8D", "keywords": "Vision, Segmentation", "abstract": "In recent years, large vision models have made significant advancements and excelled in tasks such as detection, segmentation, and tracking. This is partly due to vision models\u2018 good representation of visual objects. Although the recently proposed SAM (the Segment Anything Model ) or the one/few-shot models based on SAM have wide applicability across many tasks, some researchers have found that they do not perform well on certain downstream tasks . In this paper, we focused on a specific group of these objects, which can be summarized as glass-like objects, and quantitatively studied the inadequacies related to the vision models\u2019 feature representation of glass-like objects using the representation accuracy(RA) metric we proposed. Then, we proposed a novel, extremely simple method that introduces almost no additional computations to address these inadequacies. The main idea is utilizing the visual properties of target objects to find representation dimensions which dominate in recognizing them and leveraging these information accordingly to achieve better representations of target objects. Using representation accuracy  and setting these representations as reference in  one-shot segmentation tasks, our experiments demonstrated the substantial effectiveness of our method.", "title_embedding_index": 18452, "title_abs_embedding_index": 18477}, {"title": "Language Models Learn to Mislead Humans via RLHF", "link_suffix": "/forum?id=xJljiPE6dg", "link": "https://openreview.net/forum?id=xJljiPE6dg", "pdf_link": "https://openreview.net/pdf?id=xJljiPE6dg", "keywords": "RLHF, reward hacking, human evaluation", "abstract": "Language models (LMs) can produce errors that are hard to detect for humans, especially when the task is complex.\nRLHF, the most popular post-training method, may exacerbate this problem: to achieve higher rewards, LMs might get better at convincing humans that they are right even when they are wrong. We study this phenomenon under a standard RLHF pipeline, calling it ``U-Sophistry'' since it is \\textbf{U}nintended by model developers. Specifically, we ask time-constrained (e.g., 3-10 minutes) human subjects to evaluate the correctness of model outputs and calculate humans' accuracy against gold labels. On a question-answering task (QuALITY) and programming task (APPS), RLHF makes LMs better at convincing our subjects but not at completing the task correctly. RLHF also makes the model harder to evaluate: our subjects' false positive rate increases by 24.1% on QuALITY and 18.3% on APPS.\nFinally, we show that probing, a state-of-the-art approach for detecting \\textbf{I}ntended Sophistry (e.g.~backdoored LMs), does not generalize to U-Sophistry. Our results highlight an important failure mode of RLHF and call for more research in assisting humans to align them.", "title_embedding_index": 18453, "title_abs_embedding_index": 18478}, {"title": "Designing a Conditional Prior Distribution for Flow-Based Generative Models", "link_suffix": "/forum?id=8ZJAdSVHS1", "link": "https://openreview.net/forum?id=8ZJAdSVHS1", "pdf_link": "https://openreview.net/pdf?id=8ZJAdSVHS1", "keywords": "Generative Models, Flow Matching, Text to Image", "abstract": "Flow-based generative models have recently shown impressive performance for conditional generation tasks, such as text-to-image generation. However, current methods transform a general noise distribution to a specific mode of the target data distribution. As such, every point in the initial source distribution can be mapped to every point in the target distribution, resulting in a long average path. \nTo this end, in this work, we tap into a non-utilized property of conditional flow-based models: the ability to design a non-trivial prior distribution. Given an input condition, such as a text prompt, we first map it to a point lying in data space, representing an \"average\" data point of the minimal average distance to all data points of the same conditional mode (e.g., class). We then utilize the flow matching formulation to map samples from a Gaussian centered around this point to the conditional target distribution. \nExperimentally, our method significantly improves training times and generation quality (FID, KID and CLIP alignment scores) compared to baselines, producing high quality samples using smaller number of sampling steps.", "title_embedding_index": 18454, "title_abs_embedding_index": 18479}, {"title": "ProCEED: Prototype Consolidation and Ensemble-based Exemplar-Free Deep Incremental Learning", "link_suffix": "/forum?id=gDZd8UGaxS", "link": "https://openreview.net/forum?id=gDZd8UGaxS", "pdf_link": "https://openreview.net/pdf?id=gDZd8UGaxS", "keywords": "Prototype Consolidation, Catastrophic Forgetting, Incremental Learning, Mixture-of-Experts", "abstract": "Exemplar-free Class Incremental Learning requires the learning agent to incrementally acquire new class information and maintain past knowledge without having access to samples from previous tasks. Despite the significant performance achieved by the subspace ensemble of a mixture of experts (MoE) with Gaussian prototypical networks, a critical gap still exists. As the downstream tasks arrive, the subspace representation of old classes gets updated, resulting in a prototype drift and leading to forgetting. To address the forgetting problem, we propose ProCEED to dynamically realign previous classes' representation in the latest subspace to adjust the drifted class prototypes and preserve their decision boundaries. Specifically, we compute the inter-subspace angular drifts of the prototype of previous incremental stages with the current one, holding the local semantic relationship between the incremental subspaces. The angular drift is then used to adjust old tasks' prototypes into the subspace of incremental tasks. Furthermore, the model inherits combined knowledge from MoE, supporting plasticity without extra computational burden. Consequently, ProCEED significantly balances the stability-plasticity dilemma over incoming incremental tasks, allowing the model to learn continually. The experimental evaluations on challenging benchmark datasets demonstrate dominant accuracy for ProCEED compared to the state-of-the-art class-incremental learning methods.", "title_embedding_index": 18455, "title_abs_embedding_index": 18480}, {"title": "A Drop-In Solution for On-the-Fly Adaptation of Speculative Decoding in Large Language Models", "link_suffix": "/forum?id=xOtOfdbBqK", "link": "https://openreview.net/forum?id=xOtOfdbBqK", "pdf_link": "https://openreview.net/pdf?id=xOtOfdbBqK", "keywords": "LLM optimizations", "abstract": "Large Language Models (LLMs) are cutting-edge generative AI models built on transformer architecture, which tend to be highly memory-intensive when performing real-time inference. Various strategies have been developed to enhance the end-to-end inference speed for LLMs, one of which is speculative decoding. This technique involves running a smaller LLM (draft model) for inference over a defined window size, denoted as $\\gamma$, while simultaneously being validated by the larger LLM (target model). Choosing the optimal $\\gamma$ value and the draft model is essential for unlocking the potential of speculative decoding. But it is difficult to do due to the complicated influence from various factors, including the nature of the task, the hardware in use, and the combination of the large and small models. \nThis paper introduceson-the-fly adaption of speculative decoding, a solution that dynamically adapts the choices to maximize the efficiency of speculative decoding for LLM inferences. As a drop-in solution, it needs no offline benchmarking or training. \nExperiments show that the solution can lead to 3.55-16.48% speed improvement over the standard speculative decoding, and 1.2-3.4$\\times$ over the default LLMs.", "title_embedding_index": 18456, "title_abs_embedding_index": 18481}, {"title": "Students Rather Than Experts: A New AI for Education Pipeline to Model More Human-like and Personalised Early Adolescences", "link_suffix": "/forum?id=BzvVaj78Jv", "link": "https://openreview.net/forum?id=BzvVaj78Jv", "pdf_link": "https://openreview.net/pdf?id=BzvVaj78Jv", "keywords": "AI for Education; Large Language Models; LLM-based Agent; Teacher Training", "abstract": "The capabilities of large language models (LLMs) have been applied in expert systems across various domains, providing new opportunities for AI in Education (AI4Education). Educational interactions involve a cyclical exchange between teachers and students. Current research predominantly focuses on using LLMs to simulate teachers, leveraging their expertise to enhance student learning outcomes. However, the simulation of students, which could improve teachers' instructional skills, has received insufficient attention due to the challenges of modeling and evaluating virtual students. This research poses the question: \u201c\\textit{Can LLMs be utilized to develop virtual student agents that mimic human-like behavior and individual variability?}\u201d Unlike expert systems focusing on knowledge delivery, virtual students must replicate learning difficulties, emotional responses, and linguistic uncertainties. These traits present significant challenges in both modeling and evaluation. To address these issues, this study focuses on language learning as a context for modeling virtual student agents. We propose a novel AI4Education framework, termed \\textbf{SOE} (\\textbf{S}cene - \\textbf{O}bject - \\textbf{E}valuation), to systematically construct \\textbf{LVSA} (\\textbf{L}LM-based \\textbf{V}irtual \\textbf{S}tudent \\textbf{A}gents). By curating a dataset of personalized teacher-student interactions with various personality traits, question types, and learning stages, and fine-tuning LLMs using LoRA, we conduct multi-dimensional evaluation experiments. Specifically, we: (1) develop a theoretical framework for generating LVSA; (2) integrate human subjective evaluation metrics into GPT-4 assessments, demonstrating a strong correlation between human evaluators and GPT-4 in judging LVSA authenticity; and (3) validate that LLMs can generate human-like, personalized virtual student agents in educational contexts, laying a foundation for future applications in pre-service teacher training and multi-agent simulation environments.", "title_embedding_index": 18457, "title_abs_embedding_index": 18482}, {"title": "Towards Semantic Equivalence of Tokenization in Multimodal LLM", "link_suffix": "/forum?id=n64NYyc6rQ", "link": "https://openreview.net/forum?id=n64NYyc6rQ", "pdf_link": "https://openreview.net/pdf?id=n64NYyc6rQ", "keywords": "MLLM, Vision-Language Understaning, Vision Generation, Vision Editing, Vision Tokenization", "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in processing vision-language tasks. One of the crux of MLLMs lies in vision tokenization, which involves efficiently transforming input visual signals into feature representations that are most beneficial for LLMs. However, existing vision tokenizers, essential for semantic alignment between vision and language, remain problematic. Existing methods aggressively fragment visual input, corrupting the visual semantic integrity. To address this, this paper proposes a novel dynamic Semantic-Equivalent Vision Tokenizer (SeTok), which groups visual features into semantic units via a dynamic clustering algorithm, flexibly determining the number of tokens based on image complexity. The resulting vision tokens effectively preserve semantic integrity and capture both low-frequency and high-frequency visual features. The proposed MLLM (Setokim) equipped with SeTok significantly demonstrates superior performance across various tasks, as evidenced by our experimental results.", "title_embedding_index": 18458, "title_abs_embedding_index": 18483}, {"title": "No-regret Learning with Revealed Transitions in Adversarial Markov Decision Processes", "link_suffix": "/forum?id=i3KSorBQxF", "link": "https://openreview.net/forum?id=i3KSorBQxF", "pdf_link": "https://openreview.net/pdf?id=i3KSorBQxF", "keywords": "Adversarial Markov Decision Processes, Reinforcement Learning, Online Learning", "abstract": "When learning in Adversarial Markov Decision Processes (MDPs), agents must deal with a sequence of arbitrarily chosen transition models and losses. In this paper, we consider the setting in which the transition model chosen by the adversary is revealed at the end of each episode. We propose the notion of smoothed MDP whose transition model aggregates with a generic function $f_t$ the ones experienced so far. Coherently, we define the concept of smoothed regret, and we devise Smoothed Online Mirror Descent (SOMD), an enhanced version of OMD that leverages a novel regularization term to effectively learn in this setting. For specific choices of the aggregation function $f_t$ defining the smoothed MDPs we retrieve, under full-feedback, a regret bound of order $\\widetilde{\\mathcal O}(L^{3/2}\\sqrt{TL}+L\\overline{C}_f^{\\mathsf{P}})$ where $T$ is the number of episodes, $L$ is the horizon of the episode, and $\\overline{C}_f^{\\mathsf{P}}$ is a novel index of the degree of maliciousness of the adversarially chosen transitions. Under bandit feedback on the losses, we obtain a bound of order $\\widetilde{\\mathcal O}(L^{3/2}\\sqrt{XAT}+L\\overline{C}_f^{\\mathsf{P}})$ using a simple importance weighted estimator on the losses.", "title_embedding_index": 18459, "title_abs_embedding_index": 18484}, {"title": "No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images", "link_suffix": "/forum?id=P4o9akekdf", "link": "https://openreview.net/forum?id=P4o9akekdf", "pdf_link": "https://openreview.net/pdf?id=P4o9akekdf", "keywords": "3D Gaussian Splatting, Pose Free, Pose Estimation, Novel View Synthesis, 3D Reconstruction", "abstract": "We introduce NoPoSplat, a feed-forward model capable of reconstructing 3D scenes parameterized by 3D Gaussians from unposed sparse multi-view images. Our model, trained exclusively with photometric loss, achieves real-time 3D Gaussian reconstruction during inference. To eliminate the need for accurate pose input during reconstruction, we anchor one input view's local camera coordinates as the canonical space and train the network to predict Gaussian primitives for all views within this space. This approach obviates the need to transform Gaussian primitives from local coordinates into a global coordinate system, thus avoiding errors associated with per-frame Gaussians and pose estimation. To resolve scale ambiguity, we design and compare various intrinsic embedding methods, ultimately opting to convert camera intrinsics into a token embedding and concatenate it with image tokens as input to the model, enabling accurate scene scale prediction. We utilize the reconstructed 3D Gaussians for novel view synthesis and pose estimation tasks and propose a two-stage coarse-to-fine pipeline for accurate pose estimation. Experimental results demonstrate that our pose-free approach can achieve superior novel view synthesis quality compared to pose-required methods, particularly in scenarios with limited input image overlap. For pose estimation, our method, trained without ground truth depth or explicit matching loss, significantly outperforms the state-of-the-art methods with substantial improvements. This work makes significant advances in pose-free generalizable 3D reconstruction and demonstrates its applicability to real-world scenarios. The source code and trained models will be made available to the public.", "title_embedding_index": 18460, "title_abs_embedding_index": 18485}, {"title": "WASUP: Interpretable Classification with Weight-Input Alignment and Class-Discriminative SUPports Vectors", "link_suffix": "/forum?id=waIltEWDr8", "link": "https://openreview.net/forum?id=waIltEWDr8", "pdf_link": "https://openreview.net/pdf?id=waIltEWDr8", "keywords": "explainability, interpretability, case-based reasoning", "abstract": "The deployment of deep learning models in critical domains necessitates a balance between high accuracy and interpretability.\nWe introduce WASUP, an inherently interpretable neural network that provides local and global explanations of its decision-making process.\nWe prove that these explanations are faithful by fulfilling established axioms for explanations. \nLeveraging the concept of case-based reasoning, WASUP extracts class-representative support vectors from training images, ensuring they capture relevant features while suppressing irrelevant ones.\nClassification decisions are made by calculating and aggregating similarity scores between these support vectors and the input's latent feature vector. \nWe employ B-Cos transformations, which align model weights with inputs to enable faithful mappings of latent features back to the input space, facilitating local explanations in addition to global explanations of case-based reasoning.\nWe evaluate WASUP on three tasks: fine-grained classification on Stanford Dogs, multi-label classification on Pascal VOC, and pathology detection on the RSNA dataset.\nResults indicate that WASUP not only achieves competitive accuracy compared to state-of-the-art black-box models but also offers insightful explanations verified through theoretical analysis.\nOur findings underscore WASUPs potential for applications where understanding model decisions is as critical as the decisions themselves.", "title_embedding_index": 18461, "title_abs_embedding_index": 18486}, {"title": "Gathering and Exploiting Higher-Order Information when Training Large Structured Models", "link_suffix": "/forum?id=EiYr9ArUFl", "link": "https://openreview.net/forum?id=EiYr9ArUFl", "pdf_link": "https://openreview.net/pdf?id=EiYr9ArUFl", "keywords": "neural networks, Hessian, learning rate, projections, optimization", "abstract": "When training large models, such as neural networks, \nthe full derivatives of order 2 and beyond are usually inaccessible,\ndue to their computational cost.\nThis is why, among the second-order optimization methods, it is very common\nto bypass the computation of the Hessian by using \nfirst-order information, such as the gradient of the parameters (e.g., quasi-Newton methods)\nor the activations (e.g., K-FAC).In this paper, we focus on the exact and explicit computation\nof projections of the Hessian and higher-order derivatives on\nwell-chosen subspaces, which are relevant for optimization.\nNamely, for a given partition of the set of parameters, \nit is possible to compute tensors which can be seen as\n``higher-order derivatives according to the partition'',\nat a reasonable cost as long as the number of subsets of \nthe partition remains small.Then, we propose an optimization method leveraging\nthese tensors at order 2 and 3 with several interesting properties, including:\nit outputs one learning rate by subset of parameters, which can\nbe used for hyperparameter tuning;\nit takes into account long-range interactions\nbetween the layers of the trained neural network, \nwhich is usually not the case with similar methods;\nthe trajectory of optimization is invariant under \naffine layer-wise reparameterization.", "title_embedding_index": 18462, "title_abs_embedding_index": 18487}, {"title": "ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning", "link_suffix": "/forum?id=kuhIqeVg0e", "link": "https://openreview.net/forum?id=kuhIqeVg0e", "pdf_link": "https://openreview.net/pdf?id=kuhIqeVg0e", "keywords": "Chemical Reasoning, Large Language Models, Agent", "abstract": "Chemical reasoning usually involves complex, multi-step processes that demand precise calculations, where even minor errors can lead to cascading failures. Furthermore, large language models (LLMs) encounter difficulties handling domain-specific formulas, executing reasoning steps accurately, and integrating code ef- effectively when tackling chemical reasoning tasks. To address these challenges, we present ChemAgent, a novel framework designed to improve the performance of LLMs through a dynamic, self-updating library. This library is developed by decomposing chemical tasks into sub-tasks and compiling these sub-tasks into a structured collection that can be referenced for future queries. Then, when presented with a new problem, ChemAgent retrieves and refines pertinent information from the library, which we call memory, facilitating effective task decomposition and the generation of solutions. Our method designs three types of memory and a library-enhanced reasoning component, enabling LLMs to improve over time through experience. Experimental results on four chemical reasoning datasets from SciBench demonstrate that ChemAgent achieves performance gains of up to 46% (GPT-4), significantly outperforming existing methods. Our findings suggest substantial potential for future applications, including tasks such as drug discovery and materials science. Our code can be found athttps://anonymous.4open.science/r/CAgent.", "title_embedding_index": 18463, "title_abs_embedding_index": 18488}, {"title": "TREANT: Red-teaming Text-to-Image Models with Tree-based Semantic Transformations", "link_suffix": "/forum?id=PTgTlj6x0W", "link": "https://openreview.net/forum?id=PTgTlj6x0W", "pdf_link": "https://openreview.net/pdf?id=PTgTlj6x0W", "keywords": "Red-teaming", "abstract": "The increasing prevalence of text-to-image (T2I) models makes their safety a critical concern. Adversarial testing techniques have been developed to probe whether such models can be prompted to produce Not-Safe-For-Work (NSFW) content. Despite these efforts, current solutions face several challenges, such as low success rates, inefficiency, and lack of semantic understanding. To address these issues, we introduce TREANT, a novel automated red-teaming framework for adversarial testing of T2I models. The core of our framework is the tree-based semantic transformation. We employ semantic decomposition and sensitive element drowning strategies in conjunction with Large Language Models (LLMs) to systematically refine adversarial prompts for effective testing. Our comprehensive evaluation confirms the efficacy of TREANT, which not only exceeds the performance of state-of-the-art approaches but also achieves an overall success rate of 88.5% on leading T2I models, including DALL\u00b7E 3 and Stable Diffusion.", "title_embedding_index": 18464, "title_abs_embedding_index": 18489}, {"title": "ML-Bench: Evaluating Large Language Models for Code Generation in Repository-Level Machine Learning Tasks", "link_suffix": "/forum?id=sf1u3vTRjm", "link": "https://openreview.net/forum?id=sf1u3vTRjm", "pdf_link": "https://openreview.net/pdf?id=sf1u3vTRjm", "keywords": "LLMs, code generation, Agents, Repository", "abstract": "Despite Large Language Models (LLMs) like GPT-4 achieving impressive results in function-level code generation, they struggle with repository-scale code understanding (e.g., coming up with the right arguments for calling routines), requiring a deeper comprehension of complex file interactions. \nAlso, recently, people have developed LLM agents that attempt to interact with repository code (e.g., resolving issues), prompting the need for end-to-end evaluations starting from environment setup to deploying the repository rather than merely generating code in already-configured environments. \nThese two gaps have motivated our development of ML-Bench, a benchmark rooted in real-world ML applications that leverage existing code repositories. \nML-Bench encompasses annotated 9,641 examples across 18 GitHub repositories, challenging LLMs to accommodate user-specified arguments and documentation intricacies effectively.\nTo evaluate both LLMs and agents, two setups are employed: \nML-LLM-Bench for assessing LLMs' text-to-code conversion within a predefined deployment environment, and ML-Agent-Bench for testing autonomous agents in an end-to-end task execution within a Linux sandbox environment. \nOur findings indicate that while GPT-4o leads with a Pass@5 rate surpassing 50%, there remains significant scope for improvement, highlighted by issues such as hallucinated outputs and difficulties with bash script generation. \nNotably, in the more demanding ML-Agent-Bench, GPT-4o achieves a 76.47% success rate, reflecting the efficacy of iterative action and feedback in complex task resolution. \nOur resources, including code, data, and models, are available at \\url{https://anonymous.4open.science/r/ML-Bench}.", "title_embedding_index": 18465, "title_abs_embedding_index": 18490}, {"title": "Node Similarities under Random Projections: Limits and Pathological Cases", "link_suffix": "/forum?id=Frok9AItud", "link": "https://openreview.net/forum?id=Frok9AItud", "pdf_link": "https://openreview.net/pdf?id=Frok9AItud", "keywords": "Johnson\u2013Lindenstrauss Lemma, Random Projections, Graph Embeddings, Ranking, Cosine Similarity", "abstract": "Random Projections have been widely used to generate embeddings for various graph learning tasks due to their computational efficiency. The majority of applications have been justified through the Johnson-Lindenstrauss Lemma. In this paper, we take a step further and investigate how well dot product and cosine similarity are preserved by random projections when these are applied over the rows of the graph matrix. Our analysis provides new asymptotic and finite-sample results, identifies pathological cases, and tests them with numerical experiments. We specialize our fundamental results to a ranking application by computing the probability of random projections flipping the node ordering induced by their embeddings. We find that, depending on the degree distribution, the method produces especially unreliable embeddings for the dot product, regardless of whether the adjacency or the normalized transition matrix is used. With respect to the statistical noise introduced by random projections, we show that cosine similarity produces remarkably more precise approximations.", "title_embedding_index": 18466, "title_abs_embedding_index": 18491}, {"title": "GeoMind: A Geometric Neural Network of State Space Model for Understanding Brain Dynamics on Riemannian Manifold", "link_suffix": "/forum?id=YZdc7mTq7I", "link": "https://openreview.net/forum?id=YZdc7mTq7I", "pdf_link": "https://openreview.net/pdf?id=YZdc7mTq7I", "keywords": "Geometric deep learning, state space model, brain dynamics, Riemannian Manifold", "abstract": "State space model (SSM) is a powerful tool in neuroscience field to characterize the dynamic nature of brain functions by elucidating the mechanism of how brain system transits between brain states and how underlying states give rise to the observed neural activities. Although tremendous efforts have been made to lend the power of deep learning and mathematical insight of SSM in various functional neuroimaging studies, current state-of-the-art methods lack a holistic view of brain state evolution as a self-organized dynamical system where each part of the brain is functionally inter-connected. Since the topological co-activation of functional fluctuations exhibits an intrinsic geometric pattern (symmetric and positive definite, or SPD) on the Riemannian manifold, the call for understanding how a selective set of functional connectivities in the brain supports diverse behavior and cognition emerges a new machine learning scenario of manifold-based SSM for large-scale functional neuroimages. To that end, we propose a geometric neural networks, coinedGeoMind, designed to uncover evolving brain states by tracking the trajectory of functional dynamics on a high-dimensional Riemannian manifold of SPD matrices. OurGeoMinddemonstrates promising results in identifying specific brain states based on task-based functional Magnetic Resonance Imaging (fMRI) data, as well as in diseases early diagnosis for Alzheimer's disease, Parkinson's disease and Autism. These results highlight the applicability of the proposedGeoMindin neuroscience research. Furthermore, to assess the generalization capabilities of our model, we applied it to the domain of human action recognition (HAR), achieving promising performance on three benchmark datasets (UTKinect, Florence and HDM05). This demonstrates the scalability and robustness of the proposed geometry deep model of SSM in capturing complex spatio-temporal dynamics across diverse fields.", "title_embedding_index": 18467, "title_abs_embedding_index": 18492}, {"title": "Differentiable Reasoning about Knowledge Graphs with Reshuffled Embeddings", "link_suffix": "/forum?id=PQ6jzz82Nd", "link": "https://openreview.net/forum?id=PQ6jzz82Nd", "pdf_link": "https://openreview.net/pdf?id=PQ6jzz82Nd", "keywords": "Differentiable reasoning, knowledge graphs, region based embeddings", "abstract": "Knowledge graph (KG) embedding methods learn geometric representations of entities and relations to predict plausible missing knowledge. These representations are typically assumed to capture rule-like inference patterns. However, our theoretical understanding of the kinds of inference patterns that can be captured in this way remains limited. Ideally, KG embedding methods should be expressive enough such that for any set of rules, there exists an embedding that exactly captures these rules. This principle has been studied within the framework of region-based embeddings, but existing models are severely limited in the kinds of rule bases that can be captured. We argue that this stems from the use of representations that correspond to the Cartesian product of two-dimensional regions.\nAs an alternative, we propose RESHUFFLE, a simple model based on ordering constraints that can faithfully capture a much larger class of rule bases than existing approaches. Moreover, the embeddings in our framework can be learned by a Graph Neural Network (GNN), which effectively acts as a differentiable rule base. This has some practical advantages, e.g. ensuring that embeddings can be easily updated as new knowledge is added to the KG. At the same time, since the resulting representations can be used similarly to standard KG embeddings, our approach is significantly more efficient than existing approaches to differentiable reasoning. The GNN-based formulation also allows us to study how bounded inference can be captured. We show in particular that bounded reasoning with arbitrary sets of closed path rules can be captured in this way.", "title_embedding_index": 18468, "title_abs_embedding_index": 18493}, {"title": "CleanerCLIP: Fine-grained Counterfactual Semantic Augmentation for Backdoor Defense in Contrastive Learning", "link_suffix": "/forum?id=pA8oI8a00l", "link": "https://openreview.net/forum?id=pA8oI8a00l", "pdf_link": "https://openreview.net/pdf?id=pA8oI8a00l", "keywords": "backdoor defense, contrastive learning, multimodal pretrained models", "abstract": "Multimodal contrastive models like CLIP are increasingly vulnerable to data-poisoning backdoor attacks. Existing defense methods primarily target the pretraining phase. However, with the rise of open-source communities, pretrained models are now freely available for download and fine-tuning. These models may carry unknown security risks, posing significant threats to downstream users. This highlights the need for lightweight defense strategies tailored specifically for the fine-tuning stage. Current defenses during fine-tuning include: finetuning with clean data; and using unimodal self-supervised techniques like CleanCLIP, which has represented the state-of-the-art (SOTA). However, these methods rely on strengthening clean feature representations to mitigate attacks, making them ineffective against more stealthy backdoor techniques, such as BadCLIP, which leverage covert toxic features.\nTo overcome this limitation, we propose a finetuning defense mechanism based on fine-grained counterfactual text semantic augmentation. By modifying small portions of text during fine-tuning, our approach disrupts the association between backdoor triggers and target features.\nWe evaluate our method against six attack algorithms and conduct comprehensive zero-shot classification on ImageNet1K. Experimental results demonstrate that our method achieves SOTA performance in fine-tuning defense. Specifically, when facing the novel BadCLIP attack, our method surpasses CleanCLIP, reducing the Attack Success Rate (ASR) by 52.02% in the Top-1 and 63.88% in the Top-10 classifications.", "title_embedding_index": 18469, "title_abs_embedding_index": 18494}, {"title": "One-Step Diffusion Policy: Fast Visuomotor Policies via Diffusion Distillation", "link_suffix": "/forum?id=Z85EoYQhCs", "link": "https://openreview.net/forum?id=Z85EoYQhCs", "pdf_link": "https://openreview.net/pdf?id=Z85EoYQhCs", "keywords": "Robotics, Diffusion Policy, Distillation, One-Step Policy", "abstract": "Diffusion models, praised for their success in generative tasks, are increasingly being applied to robotics, demonstrating exceptional performance in behavior cloning. However, their slow generation process stemming from iterative denoising steps poses a challenge for real-time applications in resource-constrained robotics setups and dynamically changing environments.\nIn this paper, we introduce the One-Step Diffusion Policy (OneDP), a novel approach that distills knowledge from pre-trained diffusion policies into a single-step action generator, significantly accelerating response times for robotic control tasks. We ensure the distilled generator closely aligns with the original policy distribution by minimizing the Kullback-Leibler (KL) divergence along the diffusion chain, requiring only 2%-10% additional pre-training cost for convergence. We evaluated OneDP on 6 challenging simulation tasks as well as 4 self-designed real-world tasks using the Franka robot. The results demonstrate that OneDP not only achieves state-of-the-art success rates but also delivers an order-of-magnitude improvement in inference speed, boosting action prediction frequency from 1.5 Hz to 62 Hz, establishing its potential for dynamic and computationally constrained robotic applications. A video demo is provided athttps://drive.google.com/file/d/1eIa11gw6DwYKG9CKERy41bjE1ruklRtT/view?usp=sharing, and the code will be publicly available soon.", "title_embedding_index": 18470, "title_abs_embedding_index": 18495}, {"title": "HADAMRNN: BINARY AND SPARSE TERNARY ORTHOGONAL RNNS", "link_suffix": "/forum?id=amOpepqmSl", "link": "https://openreview.net/forum?id=amOpepqmSl", "pdf_link": "https://openreview.net/pdf?id=amOpepqmSl", "keywords": "Recurrent neural networks, quantization, orthogonal matrices, Hadamard matrices", "abstract": "Binary and sparse ternary weights in neural networks enable faster computations and lighter representations, facilitating their use on edge devices with limited computational power. Meanwhile, vanilla RNNs are highly sensitive to changes in their recurrent weights, making the binarization and ternarization of these weights inherently challenging. To date, no method has successfully achieved binarization\nor ternarization of vanilla RNN weights. We present a new approach leveraging the properties of Hadamard matrices to parameterize a subset of binary and sparse ternary orthogonal matrices. This method enables the training of orthogonal RNNs (ORNNs) with binary and sparse ternary recurrent weights, effectively creating a specific class of binary and sparse ternary vanilla RNNs. The resulting ORNNs, called HadamRNN and Block-HadamRNN, are evaluated on benchmarks such as the copy task, permuted and sequential MNIST tasks, and IMDB dataset. Despite binarization or sparse ternarization, these RNNs maintain performance levels comparable to state-of-the-art full-precision models, highlighting the effectiveness of our approach. Notably, our approach is the first solution with binary recurrent weights capable of tackling the copy task over 1000 timesteps.", "title_embedding_index": 18471, "title_abs_embedding_index": 18496}, {"title": "Fast Multi-Mode Adaptive Generative Distillation for Continually Learning Diffusion Models", "link_suffix": "/forum?id=PvvQlhBbgu", "link": "https://openreview.net/forum?id=PvvQlhBbgu", "pdf_link": "https://openreview.net/pdf?id=PvvQlhBbgu", "keywords": "diffusion model, continual learning, transfer learning", "abstract": "Diffusion models are powerful generative models, but their computational demands, vulnerability to catastrophic forgetting, and class imbalance in generated data pose significant challenges in continual learning scenarios. In this paper, we introduce Fast Multi-Mode Adaptive Generative Distillation (MAGD), a novel approach designed to address these three core challenges. MAGD combines generative replay and knowledge distillation, enhancing the continual training of diffusion models through three key innovations: (1) Noisy Intermediate Generative Distillation (NIGD), which leverages intermediate noisy images during the reverse diffusion process to improve data utility and preserve image quality without additional computational costs; (2) Class-guided generative distillation (CGGD), which  uses  classifier guidance to ensure balanced class representation in generated images, addressing the issue of class imbalance in traditional methods; and (3) Signal-Guided Generative Distillation (SGGD), which reduces computational overhead while maintaining image clarity through the reuse of the model\u2019s denoising capabilities across tasks. Our experimental results on Fashion-MNIST, CIFAR-10, and CIFAR-100 demonstrate that MAGD significantly outperforms existing methods in both image quality, measured by Fr\u00e9chet Inception Distance (FID), and class balance, measured by Kullback-Leibler Divergence (KLD). Moreover, MAGD achieves competitive results with far fewer generation steps compared to traditional methods, making it a practical solution for real-life continual learning applications.", "title_embedding_index": 18472, "title_abs_embedding_index": 18497}, {"title": "An Information-Theoretic Analysis of Thompson Sampling for Logistic Bandits", "link_suffix": "/forum?id=WxqiwbwxiW", "link": "https://openreview.net/forum?id=WxqiwbwxiW", "pdf_link": "https://openreview.net/pdf?id=WxqiwbwxiW", "keywords": "multi-armed bandits, logistic bandits, information-theory, Thompson Sampling, regret bounds, online optimization", "abstract": "We study the performance of the Thompson Sampling algorithm for logistic bandit problems, where the agent receives binary rewards with probabilities determined by a logistic function, $\\exp(\\beta \\langle a, \\theta \\rangle)/(1+\\exp(\\beta \\langle a, \\theta \\rangle))$, with slope parameter $\\beta$. We focus on the setting where both the action $a$ and parameter $\\theta$ lie within the $d$-dimensional unit ball. Adopting the information-theoretic framework introduced by (Russo & Van Roy, 2015), we analyze the information ratio, a statistic that quantifies the trade-off between the information gained about the optimal action and the immediate regret incurred.\nWe improve upon previous results by establishing that the information ratio is bounded by $\\tfrac{9}{2}d\\alpha^{-2}$, where $\\alpha$ is a minimax measure of the alignment between the action space and the parameter space, independent of $\\beta$. Notably, we derive a regret bound of order $O(d/\\alpha\\sqrt{T \\log(\\beta T/d)})$, which scales only logarithmically with the logistic function parameter $\\smash{\\beta}$. To the best of our knowledge, this is the first regret bound for logistic bandits that achieves logarithmic dependence on $\\beta$ while being independent of the number of actions. In particular, when the action space encompasses the parameter space, \nthe expected regret of Thompson Sampling is of order $\\tilde{O}(d \\sqrt{T})$.", "title_embedding_index": 18473, "title_abs_embedding_index": 18498}, {"title": "Style Outweighs Substance: Failure Modes of LLM Judges in Alignment Benchmarking", "link_suffix": "/forum?id=MzHNftnAM1", "link": "https://openreview.net/forum?id=MzHNftnAM1", "pdf_link": "https://openreview.net/pdf?id=MzHNftnAM1", "keywords": "LLM, large language model, alignment, post-training, benchmarking, evaluation", "abstract": "The release of ChatGPT in November 2022 sparked an explosion of interest in post-training and an avalanche of new preference optimization (PO) methods. These methods claim superior alignment by virtue of better correspondence with human pairwise preferences, often measured by LLM-judges. In this work, we attempt to answer the following question -- do LLM-judge preferences translate to progress on other, more concrete metrics for alignment, and if not, why not? We define a concrete metric for alignment, and introduce SOS-Bench (Substance Outweighs Style Benchmark), the largest standardized, reproducible LLM meta-benchmark to date. We find that (1) LLM-judge preferences do not correlate with concrete measures of safety, world knowledge, and instruction following; (2) LLM-judges have powerful implicit biases, prioritizing style over factuality and safety; and (3) the supervised fine-tuning (SFT) stage of post-training, and not the PO stage, has the greatest impact on alignment, with data scaling and prompt diversity as the driving factors.", "title_embedding_index": 18474, "title_abs_embedding_index": 18499}]
[{"title": "OCCAM: Towards Cost-Efficient and Accuracy-Aware Classification Inference", "link_suffix": "/forum?id=CUABD2qIB4", "link": "https://openreview.net/forum?id=CUABD2qIB4", "pdf_link": "https://openreview.net/pdf?id=CUABD2qIB4", "keywords": "Efficient ML, Hybrid ML Inference, Classification", "abstract": "Classification tasks play a fundamental role in various applications, spanning domains such as healthcare, natural language processing and computer vision. With the growing popularity and capacity of machine learning models, people can easily access trained classifiers as a service online or offline. However, model use comes with a cost and classifiers of higher capacity (such as large foundation models) usually incur higher inference costs. To harness the respective strengths of different classifiers, we propose a principled approach, OCCAM, to compute the best classifier assignment strategy over classification queries (termed as the optimal model portfolio) so that the aggregated accuracy is maximized, under user-specified cost budgets. Our approach uses an unbiased and low-variance accuracy estimator and effectively computes the optimal solution by solving an integer linear programming problem. On a variety of real-world datasets, OCCAM achieves 40% cost reduction with little to no accuracy drop.", "title_embedding_index": 14700, "title_abs_embedding_index": 14725}, {"title": "Objective Soups: Multilingual Multi-Task Acoustic Modeling for Automatic Speech Recognition", "link_suffix": "/forum?id=gW4bdLwypB", "link": "https://openreview.net/forum?id=gW4bdLwypB", "pdf_link": "https://openreview.net/pdf?id=gW4bdLwypB", "keywords": "multilingual speech recognition, speech-to-text translation, multi-objective optimization, multi-task learning, semi-supervised training", "abstract": "The need for training multilingual multi-task automatic speech recognition (ASR) models is increasingly evident. However, a significant challenge arises from the conflicts among multiple objectives when using a single model. Multi-objective optimization (MOO) can address this challenge by facilitating the optimization of multiple conflicting objectives, aligning the gradient updates in a common descent direction. While MOO helps avoid conflicting gradient update directions, a critical issue is that when there are many objectives such as those in multilingual multi-task ASR, it is often impossible to find such common descent directions. Therefore, an interesting question is: would it be more effective to separate highly conflicting objectives into different optimization levels or keep them in one level? To address this question, this paper investigates three multi-objective ASR training frameworks, which we refer to as objective soup recipes. These frameworks use MOO at different optimization levels to mitigate potential conflicts among all objectives. We conduct an extensive investigation using the LibriSpeech and AISHELL v1 datasets for ASR, along with the CoVoST v2 dataset for both ASR and speech-to-text translation tasks, to determine the highly conflicting objectives and the optimal training recipes among these three MOO training algorithms.", "title_embedding_index": 14701, "title_abs_embedding_index": 14726}, {"title": "Machine Unlearning via Simulated Oracle Matching", "link_suffix": "/forum?id=3vXpZpOn29", "link": "https://openreview.net/forum?id=3vXpZpOn29", "pdf_link": "https://openreview.net/pdf?id=3vXpZpOn29", "keywords": "machine unlearning, data attribution, training data attribution, privacy", "abstract": "Machine unlearning---efficiently removing the effect of a small \"forget set\" of training data on a pre-trained machine learning model---has recently attracted significant research interest. Despite this interest, however, recent work shows that existing machine unlearning techniques do not hold up to thorough evaluation in non-convex settings. In this work, we introduce a new machine unlearning technique that exhibits strong empirical performance even in such challenging settings. Our starting point is the perspective that the goal of unlearning is to produce a model whose outputs arestatistically indistinguishablefrom those of a model re-trained on all but the forget set.  This perspective naturally suggests a reduction from the unlearning problem to that of *data attribution, where the goal is to predict the effect of changing the training set on a model's outputs. Thus motivated, we propose the following meta-algorithm, which we call Datamodel Matching (DMM): given a trained model, we (a) use data attribution topredictthe output of the model if it were re-trained on all but the forget set points; then (b)fine-tunethe pre-trained model to match these predicted outputs. In a simple convex setting, we show how this approach provably outperforms a variety of iterative unlearning algorithms. Empirically, we use a combination of existing evaluations and a new metric based on the KL-divergence to show that even in non-convex settings, DMM achieves strong unlearning performance relative to existing algorithms. An added benefit of DMM is that it is a meta-algorithm, in the sense that future advances in data attribution translate directly into better unlearning algorithms, pointing to a clear direction for future progress in unlearning.", "title_embedding_index": 14702, "title_abs_embedding_index": 14727}, {"title": "TAVRNN: Temporal Attention-enhanced Variational Graph RNN Captures Neuronal Dynamics and Behavior", "link_suffix": "/forum?id=NPzuN3Rxi8", "link": "https://openreview.net/forum?id=NPzuN3Rxi8", "pdf_link": "https://openreview.net/pdf?id=NPzuN3Rxi8", "keywords": "Representation Learning, Attention, Graph Recurrent Neuronal Network, Neuronal Dynamics, Electrophysiology, Calcium Imaging, Behaviour", "abstract": "We introduce Temporal Attention-enhanced Variational Graph Recurrent Neural Network (TAVRNN),  a novel framework for analyzing the evolving dynamics of neuronal connectivity networks in response to external stimuli and behavioral feedback. TAVRNN captures temporal changes in network structure by modeling sequential snapshots of neuronal activity, enabling the identification of key connectivity patterns. Leveraging temporal attention mechanisms and variational graph techniques, TAVRNN uncovers how connectivity shifts align with behavior over time. We validate TAVRNN on two datasets:in vivocalcium imaging data from freely behaving rats and novelin vitroelectrophysiological data from theDishBrainsystem, where biological neurons control a simulated environment during the game ofpong. We show that TAVRNN outperforms previous baseline models in classification, clustering tasks and computational efficiency while accurately linking connectivity changes to performance variations. Crucially, TAVRNN reveals that high game performance in theDishBrainsystem correlates with the alignment of sensory and motor subregion channels, a relationship not evident in earlier models.\nThis framework represents the first application of dynamic graph representation of electrophysiological (neuronal) data fromDishBrainsystem, providing insights into the reorganization of neuronal networks during learning. TAVRNN\u2019s ability to differentiate between neuronal states associated with successful and unsuccessful learning outcomes, offers significant implications for real-time monitoring and manipulation of biological neuronal systems.", "title_embedding_index": 14703, "title_abs_embedding_index": 14728}, {"title": "DEEM: Diffusion models serve as the eyes of large language models for image perception", "link_suffix": "/forum?id=qtWjSboqfe", "link": "https://openreview.net/forum?id=qtWjSboqfe", "pdf_link": "https://openreview.net/pdf?id=qtWjSboqfe", "keywords": "MLLM; Diffusion Model;", "abstract": "The development of large language models (LLMs) has significantly advanced the emergence of large multimodal models (LMMs). While LMMs have achieved tremendous success by promoting the synergy between multimodal comprehension and creation, they often face challenges when confronted with out-of-distribution data, such as which can hardly distinguish orientation, quantity, color, structure, etc. This is primarily due to their reliance on image encoders trained to encode images into task-relevant features, which may lead them to disregard irrelevant details. Delving into the modeling capabilities of diffusion models for images naturally prompts the question: Can diffusion models serve as the eyes of large language models for image perception? In this paper, we propose DEEM, a simple but effective approach that utilizes the generative feedback of diffusion models to align the semantic distributions of the image encoder. This addresses the drawbacks of previous methods that solely relied on image encoders like CLIP-ViT, thereby enhancing the model's resilience against out-of-distribution samples and reducing visual hallucinations. Importantly, this is achieved without requiring additional training modules and with fewer training parameters. We extensively evaluated DEEM on both our newly constructed RobustVQA benchmark and other well-known benchmarks, POPE and MMVP, for visual hallucination and perception. In particular, DEEM improves LMM's  visual perception performance to a large extent (e.g., 4% \u2191 on RobustVQA, 6.5% \u2191 on MMVP and 12.8 % \u2191 on POPE ). Compared to the state-of-the-art interleaved content generation models, DEEM  exhibits enhanced robustness and a superior capacity to alleviate model hallucinations while utilizing fewer trainable parameters, less pre-training data (10%), and a smaller base model size. Extensive experiments demonstrate that DEEM enhances the performance of LMMs on various downstream tasks without inferior performance in the long term, including visual question answering, image captioning, and text-conditioned image synthesis.", "title_embedding_index": 14704, "title_abs_embedding_index": 14729}, {"title": "Discovering Clone Negatives via Adaptive Contrastive Learning for Image-Text Matching", "link_suffix": "/forum?id=My9MBsO41H", "link": "https://openreview.net/forum?id=My9MBsO41H", "pdf_link": "https://openreview.net/pdf?id=My9MBsO41H", "keywords": "Image-text matching, Contrastive learning, Vision and language, Multimodal learning", "abstract": "In this paper, we identify a common yet challenging issue in image-text matching, i.e., clone negatives: negative image-text pairs that are semantic-consistent with the positives, which leads to ambiguous and suboptimal matching results. To address this, we propose Adaptive Contrastive Learning (AdaCL), which introduces two margin parameters with a modulating anchor to dynamically strengthen the compactness between positives and mitigating the impact of clone negatives. The modulating anchor is selected based on the distribution of negative samples without explicit training, allowing for progressive tuning and enhanced in-batch supervision. Extensive experiments on two benchmark datasets demonstrate the superiority of AdaCL. Furthermore, we extend AdaCL to weakly-supervised image-text matching by substituting human-annotated descriptions with automatically generated captions, increasing the number of potential clone negatives. AdaCL demonstrates robustness with the generated captions, alleviating the reliance on crowd-sourced annotations and laying a foundation for scalable vision-language contrastive learning.", "title_embedding_index": 14705, "title_abs_embedding_index": 14730}, {"title": "ChaosEater: Fully Automating Chaos Engineering with Large Language Models", "link_suffix": "/forum?id=8pbyay0prT", "link": "https://openreview.net/forum?id=8pbyay0prT", "pdf_link": "https://openreview.net/pdf?id=8pbyay0prT", "keywords": "Chaos Engineering, Software Engineering, Infrastructure as Code, Large Language Models", "abstract": "Chaos Engineering (CE) is an engineering technique aimed at improving the resiliency of distributed systems.\nIt involves artificially injecting specific failures into a distributed system and observing its behavior in response. \nBased on the observation, the system can be proactively improved to handle those failures.\nRecent CE tools realize the automated execution of predefined CE experiments.\nHowever, defining these experiments and reconfiguring the system after the experiments still remain manual.To reduce the costs of the manual operations, we propose ChaosEater, a \"system\" for automating the entire CE operations with Large Language Models (LLMs).\nIt pre-defines the general flow according to the systematic CE cycle and assigns subdivided operations within the flow to LLMs.\nWe assume systems based on Infrastructure as Code (IaC), wherein the system configurations and artificial failures are managed through code.\nHence, the LLMs' operations in our \"system\" correspond to software engineering tasks, including requirement definition, code generation and debugging, and testing.We validate our \"system\" through a case study.\nThe results demonstrate that our \"system\" significantly reduces both time and monetary costs while completing a reasonable CE cycle.\nOur code is available in the Supplementary Material.", "title_embedding_index": 14706, "title_abs_embedding_index": 14731}, {"title": "EmbodiedSAM: Online Segment Any 3D Thing in Real Time", "link_suffix": "/forum?id=XFYUwIyTxQ", "link": "https://openreview.net/forum?id=XFYUwIyTxQ", "pdf_link": "https://openreview.net/pdf?id=XFYUwIyTxQ", "keywords": "3d instance segmentation; online 3d scene segmentation", "abstract": "Embodied tasks require the agent to fully understand 3D scenes simultaneously with its exploration, so an online, real-time, fine-grained and highly-generalized 3D perception model is desperately needed. Since high-quality 3D data is limited, directly training such a model in 3D is infeasible. Meanwhile, vision foundation models (VFM) has revolutionized the field of 2D computer vision with superior performance, which makes the use of VFM to assist embodied 3D perception a promising direction. However, most existing VFM-assisted 3D perception methods are either offline or too slow that cannot be applied in practical embodied tasks. In this paper, we aim to leverage Segment Anything Model (SAM) for real-time 3D instance segmentation in an online setting. This is a challenging problem since future frames are not available in the input streaming RGB-D video, and an instance may be observed in several frames so efficient object matching between frames is required. To address these challenges, we first propose a geometric-aware query lifting module to represent the 2D masks generated by SAM by 3D-aware queries, which is then iteratively refined by a dual-level query decoder. In this way, the 2D masks are transferred to fine-grained shapes on 3D point clouds. Benefit from the query representation for 3D masks, we can compute the similarity matrix between the 3D masks from different views by efficient matrix operation, which enables real-time inference. Experiments on ScanNet, ScanNet200, SceneNN and 3RScan show our method achieves state-of-the-art performance among online 3D perception models, even outperforming offline VFM-assisted 3D instance segmentation methods by a large margin. Our method also demonstrates great generalization ability in several zero-shot dataset transferring experiments and show great potential in data-efficient setting. Code and demo will be released.", "title_embedding_index": 14707, "title_abs_embedding_index": 14732}, {"title": "Inter-Environmental World Modeling for Continuous and Compositional Dynamics", "link_suffix": "/forum?id=cojJ2s1e35", "link": "https://openreview.net/forum?id=cojJ2s1e35", "pdf_link": "https://openreview.net/pdf?id=cojJ2s1e35", "keywords": "world model, state space model, object centric learning, symmetry", "abstract": "Recent advancements in generative models have showcased their effectiveness across various domains such as language, chemistry, and genomics. However, these models often rely on discrete action representations or language-based interactions, limiting their ability to generalize across different environments without explicit labels. In this paper, we introduce the Object-Centric Algebraic Mental Model (OCAM), an unsupervised framework that learns a continuous latent action representation by combining object-centric representations with Lie group theory. OCAM treats actions as continuous operators acting linearly on a partitioned latent vector space corresponding to different objects and basic action axes. This approach allows OCAM to generalize beyond the environments it was trained on, enabling the simulation of new environments and efficient solving of inverse dynamics problems. We demonstrate that OCAM can learn interactive generative models from unlabeled video data, interpolate between frames, extrapolate long-term dynamics, and quickly adapt to new environments with minimal or no action labels. Experiments on benchmark datasets like PHYRE and ProcGen validate the effectiveness of OCAM in advancing the capabilities of scalable artificial general intelligence.", "title_embedding_index": 14708, "title_abs_embedding_index": 14733}, {"title": "Conformal Structured Prediction", "link_suffix": "/forum?id=2ATD8a8P3C", "link": "https://openreview.net/forum?id=2ATD8a8P3C", "pdf_link": "https://openreview.net/pdf?id=2ATD8a8P3C", "keywords": "Conformal Prediction, Structured Prediction, Integer Programming", "abstract": "Conformal prediction has recently emerged as a promising strategy for quantifying the uncertainty of a predictive model; these algorithms modify the model to output sets of labels that are guaranteed to contain the true label with high probability. However, existing conformal prediction algorithms have largely targeted classification and regression settings, where the structure of the prediction set has a simple form as a level set of the scoring function. However, for complex structured outputs such as text generation, these prediction sets might include a large number of labels and therefore be hard for users to interpret. In this paper, we propose a general framework for conformal prediction in the structured prediction setting, that modifies existing conformal prediction algorithms to output structured prediction sets that implicitly represent sets of labels. In addition, we demonstrate how our approach can be applied in domains where the prediction sets can be represented as a set of nodes in a directed acyclic graph; for instance, for hierarchical labels such as image classification, a prediction set might be a small subset of coarse labels implicitly representing the prediction set of all their more fine-descendants. We demonstrate how our algorithm can be used to construct prediction sets that satisfy a desired coverage guarantee in several domains.", "title_embedding_index": 14709, "title_abs_embedding_index": 14734}, {"title": "Global Well-posedness and Convergence Analysis of Score-based Generative Models via Sharp Lipschitz Estimates", "link_suffix": "/forum?id=r3cWq6KKbt", "link": "https://openreview.net/forum?id=r3cWq6KKbt", "pdf_link": "https://openreview.net/pdf?id=r3cWq6KKbt", "keywords": "Score based generative models, Lipschitz estimates, convergence analysis, well-posedness, singularity", "abstract": "We establish global well-posedness and convergence of the score-based generative models (SGM) under minimal general assumptions of initial data for score estimation. For the smooth case, we start from a Lipschitz bound of the score function with optimal time length. The optimality is validated by an example whose Lipschitz constant of scores is bounded at initial but blows up in finite time. This necessitates the separation of time scales in conventional bounds for non-log-concave distributions. In contrast, our follow up analysis only relies on a local Lipschitz condition and is valid globally in time. This leads to the convergence of numerical scheme without time separation. For the non-smooth case, we show that the optimal Lipschitz bound is $O(1/t)$ in the point-wise sense for distributions supported on a compact, smooth and low-dimensional manifold with boundary.", "title_embedding_index": 14710, "title_abs_embedding_index": 14735}, {"title": "Learning Efficient Representations of Neutrino Telescope Events", "link_suffix": "/forum?id=3Wuvqc4xoy", "link": "https://openreview.net/forum?id=3Wuvqc4xoy", "pdf_link": "https://openreview.net/pdf?id=3Wuvqc4xoy", "keywords": "neutrino, neutrino telescope, representation, learning", "abstract": "Neutrino telescopes detect rare interactions of particles produced in some of the most extreme environments in the Universe. This is accomplished by instrumenting a cubic-kilometer volume of naturally occurring transparent medium with light sensors. Given their substantial size and the high frequency of background interactions, these telescopes amass an enormous quantity of large variance, high-dimensional data. These attributes create substantial challenges for analyzing and reconstructing interactions, particularly when utilizing machine learning (ML) techniques. In this paper, we present a novel approach, called om2vec, that employs transformer-based variational autoencoders to efficiently represent neutrino telescope events by learning compact and descriptive latent representations. We demonstrate that these latent representations offer enhanced flexibility and improved computational efficiency, thereby facilitating downstream tasks in data analysis.", "title_embedding_index": 14711, "title_abs_embedding_index": 14736}, {"title": "Automated Black-box Prompt Engineering for Personalized Text-to-Image Generation", "link_suffix": "/forum?id=hIKsem01M5", "link": "https://openreview.net/forum?id=hIKsem01M5", "pdf_link": "https://openreview.net/pdf?id=hIKsem01M5", "keywords": "Text-to-Image Generation, Prompt Engineering, Personalized Text-to-Image Generation", "abstract": "Prompt engineering is an effective but labor-intensive way to control text-to-image (T2I) generative models. Its time-intensive nature and complexity have spurred the development of algorithms for automated prompt generation. However, these methods often struggle with transferability across T2I models, require white-box access to the underlying model, or produce non-intuitive prompts. In this work, we introduce PRISM, an algorithm that automatically produces human-interpretable and transferable prompts that can effectively generate desired concepts given only black-box access to T2I models. Inspired by large language model (LLM) jailbreaking, PRISM leverages the in-context learning ability of LLMs to iteratively refine the candidate prompt distribution built upon the reference images. Our experiments demonstrate the versatility and effectiveness of PRISM in generating accurate prompts for objects, styles, and images across multiple T2I models, including Stable Diffusion, DALL-E, and Midjourney.", "title_embedding_index": 14712, "title_abs_embedding_index": 14737}, {"title": "Optimal Client Training in Federated Learning with Deep Reinforcement Learning", "link_suffix": "/forum?id=tiKJsepvr0", "link": "https://openreview.net/forum?id=tiKJsepvr0", "pdf_link": "https://openreview.net/pdf?id=tiKJsepvr0", "keywords": "Federated Learning", "abstract": "Federated Learning (FL) is a distributed framework for collaborative model training over large-scale distributed data. Centralized FL leverages a server to aggregate client models which can enable higher performance while maintaining client data privacy. However, it has been shown that in centralized model aggregation, performance can degrade in the presence of non-IID data across different clients. We remark that training a client locally on more data than necessary does not benefit the overall performance of all clients. In this paper, we devise a novel framework that leverages Deep Reinforcement Learning (DRL) to optimize an agent that selects the optimal amount of data necessary to train a client model without oversharing information with the server. Starting from complete unawareness of the client's performance, the DRL agent utilizes the change in training loss as a reward signal and learns to optimize the amount of data necessary for improving the client's performance. Specifically, after each aggregation round, the DRL algorithm considers the local performance as the current state and outputs the optimal weights for each class in the training data to be used during the next round of local training. In doing so, the agent learns a policy that creates the optimal partition of the local training dataset during the FL rounds. After FL, the client utilizes the entire local training dataset to further enhance its performance on its own data distribution, mitigating the non-IID effects of aggregation. Through extensive experiments, we demonstrate that training FL clients through our algorithm results in superior performance on multiple benchmark datasets and FL frameworks.", "title_embedding_index": 14713, "title_abs_embedding_index": 14738}, {"title": "GRE Score: Generative Risk Evaluation for Large Language Models", "link_suffix": "/forum?id=Vo1FUQ4aQI", "link": "https://openreview.net/forum?id=Vo1FUQ4aQI", "pdf_link": "https://openreview.net/pdf?id=Vo1FUQ4aQI", "keywords": "Large Language Models, Robustness, Trustworthy", "abstract": "Large Language Models (LLMs) have revolutionized generative tasks, but concerns about their trustworthiness and vulnerability to adversarial attacks persist. This paper introduces the Generative Robustness Evaluation (GRE) Score, a novel metric designed to assess LLMs' resilience against adversarial red teaming attempts that may compromise model compliance and elicit undesired responses. Our approach utilizes conditional generation for synthetic text creation, offering an attack-independent evaluation of LLM robustness. By calculating the margin in refusal scores, we quantify the robustness of LLMs in an attack-agnostic manner. We evaluate our method on five different dimensions with specified datasets, encompassing ethical considerations, safety protocols, and potential misuse scenarios. We present four key contributions: (1) The GRE Score framework, which establishes a textual robustness certificate for LLMs against adversarial red teaming attempts, providing a theoretical foundation for quantifying model resilience. (2) Comprehensive evaluations across five critical dimensions using eight prominent LLMs, validating GRE Scores with adversarial red teaming attacks. Our method demonstrates a consistent ranking of LLM robustness when compared to the attack-based model ranking on TrustLLM \\citep{huang2024trustllm} while achieving a significant 5-8x speedup compared to traditional evaluation techniques. (3) Insights into the non-linear relationship between model scaling and performance, revealing that larger models do not always perform better, and an analysis of how instruction-tuning impacts robustness across LLMs. (4) The discovery that all evaluated LLMs exhibit notably lower performance in robustness and privacy tasks compared to other areas, highlighting a critical gap in LLM capabilities.", "title_embedding_index": 14714, "title_abs_embedding_index": 14739}, {"title": "Efficient optimization with orthogonality constraint: a randomized Riemannian submanifold method", "link_suffix": "/forum?id=zCncHdGsOa", "link": "https://openreview.net/forum?id=zCncHdGsOa", "pdf_link": "https://openreview.net/pdf?id=zCncHdGsOa", "keywords": "Oprimization, Orthogonality constraint, Riemannian optimization, Stiefel manifold", "abstract": "Optimization with orthogonality constraints frequently arise in various fields such as machine learning, signal processing and computer vision. Riemannian optimization offers a powerful framework for solving these problems by equipping the constraint set with a Riemannian manifold structure and performing optimization intrinsically on the manifold. This approach typically involves computing a search direction in the tangent space and updating variables via a retraction operation. However, as the size of the variables increases, the computational cost of the retraction can become prohibitively high, limiting the applicability of Riemannian optimization to large-scale problems.  To address this challenge and enhance scalability, we propose a novel approach that restricts each update on a random submanifold, thereby significantly reducing the per-iteration complexity. We introduce two sampling strategies for selecting the random submanifold and theoretically analyze the convergence of the proposed method. We provide convergence results for general nonconvex functions and functions that satisfy Riemannian Polyak\u2013\u0141ojasiewicz condition as well as for stochastic optimization settings. Extensive experiments verify the benefits of the proposed method, showcasing its effectiveness across a wide variety of problem instances.", "title_embedding_index": 14715, "title_abs_embedding_index": 14740}, {"title": "TabUnite: Efficient Encoding Schemes for Flow and Diffusion Tabular Generative Models", "link_suffix": "/forum?id=Zoli4UAQVZ", "link": "https://openreview.net/forum?id=Zoli4UAQVZ", "pdf_link": "https://openreview.net/pdf?id=Zoli4UAQVZ", "keywords": "tabular data generation, encoding schemes, flow matching, diffusion", "abstract": "Flow matching and diffusion generative models for tabular data face challenges in modeling heterogeneous feature interrelationships, especially in data with continuous and categorical input features. Capturing these interrelationships is crucial as it allows these models to understand complex patterns and dependencies in the underlying data. A promising option to address the challenge is to devise suitable encoding schemes for the input features before the generative modeling process. However, prior methods often rely on either suboptimal heuristics such as one-hot encoding of categorical features followed by separated modeling of categorical/continuous features, or latent space diffusion models. Instead, our proposed solution unifies the data space and jointly applies a single generative process across all the encodings, efficiently capturing heterogeneous feature interrelationships. Specifically, it employs encoding schemes such as PSK Encoding,  Dictionary Encoding, and Analog Bits that effectively convert categorical features into continuous ones. Extensive experiments on datasets comprised of heterogeneous features demonstrate that our encoding schemes, combined with Flow Matching or Diffusion as our choice of generative model, significantly enhance model capabilities. Our TabUnite models help address data heterogeneity, achieving superior performance across a broad suite of datasets, baselines, and benchmarks while generating accurate, robust, and diverse tabular data.", "title_embedding_index": 14716, "title_abs_embedding_index": 14741}, {"title": "Learning to Plan with Personalized Preferences", "link_suffix": "/forum?id=KnYsdgeCey", "link": "https://openreview.net/forum?id=KnYsdgeCey", "pdf_link": "https://openreview.net/pdf?id=KnYsdgeCey", "keywords": "Embodied AI, Personalized Preference, Human-AI interaction", "abstract": "Understanding and adapting to human preferences is essential for the effective integration of artificial agents into daily human life, particularly as AI becomes increasingly involved in collaboration and assistance roles. Previous studies on preference recognition in embodied intelligence have largely adopted a generalized yet non-personalized approach. To fill in this gap, our research focuses on\nempowering embodied agents to learn and adapt to individual preferences, a task complicated by the challenges of inferring these preferences from minimal observations and requiring robust few-shot generalization. To facilitate future study, we introduce PbP, an embodied environment that supports hundreds of diverse preferences ranging from complex action sequences to specific sub-actions. Our\nexperiments on PbP reveal that while symbol-based approaches show promise in terms of effectiveness and scalability, accurately inferring implicit preferences and planning adaptive actions from limited data remain challenging. Nevertheless, preference serves as a valuable abstraction of human behaviors, and incorporating preference as a key intermediary step in planning can significantly enhance the personalization and adaptability of AI agents. We hope our findings can pave the way for future research on more efficient preference learning and personalized planning in dynamic environments.", "title_embedding_index": 14717, "title_abs_embedding_index": 14742}, {"title": "Tree Search for Simultaneous Move Games via Equilibrium Approximation", "link_suffix": "/forum?id=5qg1sAXhoh", "link": "https://openreview.net/forum?id=5qg1sAXhoh", "pdf_link": "https://openreview.net/pdf?id=5qg1sAXhoh", "keywords": "Neural Network, Tree Search, Game Theory, Coarse Correlated Equilibrium, No regret learning", "abstract": "Neural network supported tree-search has shown strong results in a variety of perfect information multi-agent tasks. However, the performance of these methods on partial information games has generally been below competing approaches. Here we study the class of simultaneous-move games, which are a subclass of partial information games which are most similar to perfect information games: both agents know the game state  with the exception of the opponent's move, which is revealed only after each agent makes its own move. Simultaneous move games  include popular benchmarks such as Google Research Football and Starcraft.In this study we answer the question: can we take  tree search algorithms trained through self-play from perfect information settings and adapt them to  simultaneous move games without significant loss of performance? We answer this question by deriving a practical method that attempts to approximate a coarse correlated equilibrium as a subroutine within a tree search. Our algorithm works on cooperative, competitive, and mixed tasks. Our results are better than the current best MARL algorithms on a wide range of accepted baselines.", "title_embedding_index": 14718, "title_abs_embedding_index": 14743}, {"title": "Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition", "link_suffix": "/forum?id=FxLxbJTm7F", "link": "https://openreview.net/forum?id=FxLxbJTm7F", "pdf_link": "https://openreview.net/pdf?id=FxLxbJTm7F", "keywords": "Large Language Model, In-Context Learning, Task Superposition", "abstract": "Large Language Models (LLMs) have demonstrated remarkable in-context learning (ICL) capabilities. In this study, we explore a surprising phenomenon related to ICL: LLMs can perform multiple, computationally distinct ICL tasks simultaneously, during a single inference call, a capability we term \"task superposition\". We provide empirical evidence of this phenomenon across various LLM families and scales and show that this phenomenon emerges even if we train the model to in-context learn one task at a time. We offer theoretical explanations that this capability is well within the expressive power of transformers. We also explore how LLMs internally compose task vectors during superposition. Furthermore, we show that larger models can solve more ICL tasks in parallel, and better calibrate their output distribution. Our findings offer insights into the latent capabilities of LLMs, further substantiate the perspective of \"LLMs as superposition of simulators\", and raise questions about the mechanisms enabling simultaneous task execution.", "title_embedding_index": 14719, "title_abs_embedding_index": 14744}, {"title": "An efficient implementation for solving the all pairs minimax path problem in an undirected dense graph", "link_suffix": "/forum?id=bEgDEyy2Yk", "link": "https://openreview.net/forum?id=bEgDEyy2Yk", "pdf_link": "https://openreview.net/pdf?id=bEgDEyy2Yk", "keywords": "Minimax path problem, Longest-leg path distance, Min-Max-Jump distance, Widest path problem, Maximum capacity path problem, Bottleneck edge query problem, All points path distance, Floyd-Warshall algorithm, Minimum spanning tree", "abstract": "We provide an efficient $ O(n^2) $ implementation for solving the all pairs minimax path problem or  widest path problem in an undirected dense graph. It is a code implementation of the Algorithm 4 (MMJ distance by Calculation and Copy) in a previous paper. The distance matrix is also called the all points path distance (APPD). We conducted experiments to test the implementation and algorithm, compared it with several other algorithms for solving the APPD matrix.  Result shows Algorithm 4 works good for solving the widest path or minimax path APPD matrix.  It can drastically improve the efficiency for computing the APPD matrix.  There are several theoretical outcomes which claim the APPD matrix can be solved accurately in $ O(n^2) $ . However, they are impractical because there is no code implementation of these algorithms. It seems Algorithm 4 is the first algorithm that has an actual code implementation for solving the APPD matrix of minimax path or widest path problem in $ O(n^2) $, in an undirected dense graph.", "title_embedding_index": 14720, "title_abs_embedding_index": 14745}, {"title": "To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning", "link_suffix": "/forum?id=w6nlcS8Kkn", "link": "https://openreview.net/forum?id=w6nlcS8Kkn", "pdf_link": "https://openreview.net/pdf?id=w6nlcS8Kkn", "keywords": "Chain-of-Thought, Large Language Models, Textual Reasoning", "abstract": "Chain-of-thought (CoT) via prompting is the de facto method for eliciting reasoning capabilities from large language models (LLMs). But for what kinds of tasks is this extra \"thinking\" really helpful? To analyze this, we conducted a quantitative meta-analysis covering over 100 papers using CoT and ran our own evaluations of 20 datasets across 14 models. Our results show that CoT gives strong performance benefits primarily on tasks involving math or logic, with much smaller gains on other types of tasks. On MMLU, directly generating the answer without CoT leads to almost identical accuracy as CoT unless the question or model's response contains an equals sign, indicating symbolic operations and reasoning. Following this finding, we analyze the behavior of CoT on these problems by separating planning and execution and comparing against tool-augmented LLMs. Much of CoT's gain comes from improving symbolic execution, but it underperforms relative to using a symbolic solver. Our results indicate that CoT can be applied selectively, maintaining performance while saving inference costs. Furthermore, they suggest a need to move beyond prompt-based CoT to new paradigms that better leverage intermediate computation across the whole range of LLM applications.", "title_embedding_index": 14721, "title_abs_embedding_index": 14746}, {"title": "Provably Efficient and Practical Self-Play for Better LLM Alignment", "link_suffix": "/forum?id=ed75tWzgt0", "link": "https://openreview.net/forum?id=ed75tWzgt0", "pdf_link": "https://openreview.net/pdf?id=ed75tWzgt0", "keywords": "Large Language Model, two player game, DPO, Sample-efficient RLHF", "abstract": "Reinforcement Learning with Human Feedback (RLHF) has gained significant attention for aligning AI behavior with human preferences. Self-play style RLHF has shown strong advantages, as highlighted by many studies. However, current self-play style RLHF approaches face several limitations, including the lack of provable sample efficiency, absence of active exploration, and limited diversity in training data. To address these challenges, we propose a novel RLHF framework that balances exploration and exploitation while providing theoretical guarantees. We introduce Two-Agent Nash Policy Optimization (TANPO) as an equivalent and easy-to-implement two-agent algorithm building on this framework. In TANPO, the two players are trained using different loss functions to ensure more diverse and informative data collection. We also propose Single-Agent Diversity-driven Optimization (SADPO), a single-agent approximation of TANPO, supported by both theoretical analysis and empirical evidence. Our theoretical analysis shows that our theoretical algorithm framework enjoys sublinear regret under general function approximation and mild structural conditions, with a detailed analysis provided for the linear case. Empirically, we implement TANPO and SADPO using Zephyr-7B-SFT as our base model, outperforming several baselines across multiple evaluation benchmarks, such as AlpacaEval 2.0, MT-Bench and various standard academic benchmarks. Our experiments also show that TANPO improves performance on AlpacaEval 2.0 over extended training epochs, demonstrating its ability to consistently improve and reduce overfitting.", "title_embedding_index": 14722, "title_abs_embedding_index": 14747}, {"title": "Interference Among First-Price Pacing Equilibria: A Bias and Variance Analysis", "link_suffix": "/forum?id=6bDJ3CIm5w", "link": "https://openreview.net/forum?id=6bDJ3CIm5w", "pdf_link": "https://openreview.net/pdf?id=6bDJ3CIm5w", "keywords": "First-price auctions, Pacing equilibrium, interference bias", "abstract": "A/B testing is widely used in the internet industry. For online marketplaces (such as advertising markets), standard approaches to A/B testing may lead to biased results when buyers have budget constraints, as budget consumption in one arm of the experiment impacts performance of the other arm. \nThis is often addressed using a budget-split design. Yet such splitting may degrade statistical performance as budgets become too small in each arm.\nWe propose a parallel budget-controlled A/B testing design where we use market segmentation to identify submarkets in the larger market, and we run parallel budget-split experiments in each submarket.\nWe demonstrate the effectiveness of this approach on real experiments on advertising markets at Meta.\nThen, we formally study interference that derives from such experimental designs, using the first-price pacing equilibrium framework as our model of market equilibration.\nWe propose a debiased surrogate that eliminates the first-order bias of FPPE, and derive a plug-in estimator for the surrogate and establish its asymptotic normality. We then provide an estimation procedure for submarket parallel budget-controlled A/B tests. Finally, we present numerical examples on semi-synthetic data, confirming that the debiasing technique achieves the desired coverage properties.", "title_embedding_index": 14723, "title_abs_embedding_index": 14748}, {"title": "Worldwide Federated Training of Language Models", "link_suffix": "/forum?id=CO4wKfSyhb", "link": "https://openreview.net/forum?id=CO4wKfSyhb", "pdf_link": "https://openreview.net/pdf?id=CO4wKfSyhb", "keywords": "Federated Learning, Distributed Training, Language Modeling, Natural Language Processing, Hierarchical Federated Learning, Governance", "abstract": "Language Model (LM) training requires vast datasets, raising legal, ethical, and practical concerns. Federated learning (FL) offers an alternative by enabling organizations to collaboratively leverage untapped reserves while minimizing data movement. However, scaling FL globally introduces challenges such as restrictions on data movement, privacy, and statistical data heterogeneity. We propose Worldwide Federated Language Model Training (WorldLM), a system that builds federations of federations. WorldLM enables each federation to autonomously meet jurisdictional or competitive constraints while managing statistical heterogeneity through attention-based aggregation of key layers and cross-federation information sharing via residual embeddings. In terms of perplexity, WorldLM outperforms standard FL and other federated baselines by up to $1.91\\times$ and $3.3\\times$ respectively. WorldLM scales to models with $400$M parameters, achieving $1.39\\times$ lower perplexity than centralized counterparts while approaching the performance of perfectly localized models trained in an infinite-data regime. Additionally, under differential privacy constraints, WorldLM proves highly resilient in performance compared to standard FL methods, which diverge. These results establish WorldLM as an effective means for pre-training across geographic and legal boundaries.", "title_embedding_index": 14724, "title_abs_embedding_index": 14749}]
[{"title": "Rethinking Evaluation for Temporal Link Prediction through Counterfactual Analysis", "link_suffix": "/forum?id=k3LAIS5wTY", "link": "https://openreview.net/forum?id=k3LAIS5wTY", "pdf_link": "https://openreview.net/pdf?id=k3LAIS5wTY", "keywords": "temporal link prediction, counterfactual reasoning, graph learning, evaluation", "abstract": "In response to critiques of existing evaluation methods for temporal link prediction (TLP) models, we propose a novel approach to verify if these models truly capture temporal patterns in the data. Our method involves a sanity check formulated as a counterfactual question: \"What if a TLP model is tested on a temporally distorted version of the data instead of the real data?\" Ideally, a TLP model that effectively learns temporal patterns should perform worse on temporally distorted data compared to real data. We provide an in-depth analysis of this hypothesis and introduce two data distortion techniques to assess well-known TLP models.\nOur contributions are threefold: (1) We introduce two simple techniques to distort temporal patterns within a graph, generating temporally distorted test splits of well-known datasets for sanity checks. These distortion methods are applicable to any temporal graph dataset. (2) We perform counterfactual analysis on six TLP models JODIE, TGAT, TGN, CAWN, GraphMixer, and DyGFormer to evaluate their capability in capturing temporal patterns across different datasets. (3) We introduce two metrics -- average time difference (ATD) and average count difference (ACD) -- to provide a comprehensive measure of a model's predictive performance.", "title_embedding_index": 12500, "title_abs_embedding_index": 12525}, {"title": "Conditional Diffusion Models are Minimax-Optimal and Manifold-Adaptive for Conditional Distribution Estimation", "link_suffix": "/forum?id=NltQraRnbW", "link": "https://openreview.net/forum?id=NltQraRnbW", "pdf_link": "https://openreview.net/pdf?id=NltQraRnbW", "keywords": "conditional distribution estimation, diffusion models, distribution regression, generative models, manifold, minimax rate", "abstract": "We consider a class of conditional forward-backward diffusion models for conditional generative modeling, that is, generating new data given a covariate (or control variable). To formally study the theoretical properties of these conditional generative models, we adopt a statistical framework of distribution regression to characterize the large sample properties of the conditional distribution estimators induced by these conditional forward-backward diffusion models. Here, the conditional distribution of data is assumed to smoothly change over the covariate. In particular, our derived convergence rate is minimax-optimal under the total variation metric within the regimes covered by the existing literature. Additionally, we extend our theory by allowing both the data and the covariate variable to potentially admit a low-dimensional manifold structure. In this scenario, we demonstrate that the conditional forward-backward diffusion model can adapt to both manifold structures, meaning that the derived estimation error bound (under the Wasserstein metric) depends only on the intrinsic dimensionalities of the data and the covariate.", "title_embedding_index": 12501, "title_abs_embedding_index": 12526}, {"title": "Rethinking logic in AI: A novel benchmark inspired by polynomial analogue of Gandy's fixed point theorem", "link_suffix": "/forum?id=mHx8JFURtn", "link": "https://openreview.net/forum?id=mHx8JFURtn", "pdf_link": "https://openreview.net/pdf?id=mHx8JFURtn", "keywords": "llm, logic, benchmark, Gandy's fixed point theorem", "abstract": "This paper introduces a novel benchmark for evaluating the logical reasoning capabilities of Large Language Models (LLMs), grounded in the polynomial analogue of Gandy's classical fixed point theorem. Drawing on concepts from mathematical logic, we design a parameterized set of recursive problems where the objective is for LLMs to predict the outcome of a Boolean function, achievable within a polynomial number of steps. By varying the parameters, we generate problem instances of differing complexity. Our experiments reveal that current state-of-the-art LLMs fail to reliably solve even the simplest cases, despite an effective deterministic algorithm existing. Notably, even advanced models like GPT-4 exhibit significant biases in solving benchmark problems. These findings highlight the limitations of modern LLMs as code interpreters, even in basic scenarios, and underscore the necessity for hybrid LLM/interpreter systems. Furthermore, they emphasize the importance of developing quantitative tests for reasoning, given the increasing reliance on LLM-based systems in decision-making applications.", "title_embedding_index": 12502, "title_abs_embedding_index": 12527}, {"title": "Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance", "link_suffix": "/forum?id=jjCB27TMK3", "link": "https://openreview.net/forum?id=jjCB27TMK3", "pdf_link": "https://openreview.net/pdf?id=jjCB27TMK3", "keywords": "data mixtures, pretraining, post-training, scaling laws", "abstract": "Pretraining data of large language models composes multiple domains (e.g., web texts, academic papers, codes), whose mixture proportions crucially impact the competence of outcome models. While existing endeavors rely on heuristics or qualitative strategies to tune the proportions, we discover the quantitative predictability of model performance regarding the mixture proportions in function forms, which we refer to as the data mixing laws. Fitting such functions on sample mixtures unveils model performance on unseen mixtures before actual runs, thus guiding the selection of an ideal data mixture. Furthermore, we propose nested use of the scaling laws of training steps, model sizes, and our data mixing laws to predict the performance of large models trained on massive data under various mixtures with only small-scale training.  Experimental results verify that our method effectively optimizes the training mixture of a 1B model trained for 100B tokens in RedPajama, reaching a performance comparable to the one trained for 48% more steps on the default mixture. Extending the application of data mixing laws to continual training accurately predicts the critical mixture proportion that avoids catastrophic forgetting and outlooks the potential for dynamic data schedules.", "title_embedding_index": 12503, "title_abs_embedding_index": 12528}, {"title": "Parrot: Seamless Spoken Dialogue Interaction with Double-Channel Large Language Models", "link_suffix": "/forum?id=73EDGbG6mB", "link": "https://openreview.net/forum?id=73EDGbG6mB", "pdf_link": "https://openreview.net/pdf?id=73EDGbG6mB", "keywords": "Speech Language Models, Generative Spoken Dialogue Language Modeling", "abstract": "Recent advancements in large language models (LLMs) have demonstrated significant potential in enhancing real-time spoken interactions. Presently, open-source methodologies predominantly depend on intermediate generative text-based translations to manage real-time spoken dialogues. However, these techniques often struggle with providing seamless interactions that involve real-time streaming audio inputs. In this research, we unveil an innovative spoken dialogue language model, Parrot, distinguished by its unique pre-training and supervised fine-tuning (SFT) pipeline. This pipeline deviates from conventional methodologies by utilizing both single-channel audio data and double-channel spoken dialogue data to train the textless speech language model. During pre-training, we transmute single-channel audio input into a sequence of discrete tokens, thereby instructing the LLM to identify audio tokens via next-token predictions. In the SFT phase, we pioneer a novel approach to double-channel generative spoken dialogue language modeling with a unique ``next-token-pair prediction\" objective, facilitating the LLM's comprehension of natural human conversations. Our inventive pipeline equips the LLM to produce spoken interactions that are more natural and fluid than those generated by previous text-based approaches, as substantiated by thorough evaluations.", "title_embedding_index": 12504, "title_abs_embedding_index": 12529}, {"title": "Private Stochastic Optimization for Achieving Second-Order Stationary Points", "link_suffix": "/forum?id=UVaLZMv0uk", "link": "https://openreview.net/forum?id=UVaLZMv0uk", "pdf_link": "https://openreview.net/pdf?id=UVaLZMv0uk", "keywords": "Differential privacy, non-convex optimization, saddle points", "abstract": "This paper addresses the challenge of achieving second-order stationary points (SOSP) in differentially private stochastic non-convex optimization. We identify two key limitations in the state-of-the-art: (i) inaccurate error rates caused by the omission of gradient variance in saddle point escape analysis, resulting in inappropriate parameter choices and overly optimistic performance estimates, and (ii) inefficiencies in private SOSP selection via the AboveThreshold algorithm, particularly in distributed learning settings, where perturbing and sharing Hessian matrices introduces significant additional noise. To overcome these challenges, we revisit perturbed stochastic gradient descent (SGD) with Gaussian noise and propose a new framework that leverages general gradient oracles. This framework introduces a novel criterion based on model drift distance, ensuring provable saddle point escape and efficient convergence to approximate local minima with low iteration complexity. Using an adaptive SPIDER as the gradient oracle, we establish a new DP algorithm that corrects existing error rates. Furthermore, we extend our approach to a distributed adaptive SPIDER, applying our framework to distributed learning scenarios and providing the first theoretical results on achieving SOSP under differential privacy in distributed environments with heterogeneous data. Finally, we analyze the limitations of the AboveThreshold algorithm for private model selection in distributed learning and show that as model dimensions increase, the selection process introduces additional errors, further demonstrating the superiority of our proposed framework.", "title_embedding_index": 12505, "title_abs_embedding_index": 12530}, {"title": "econSG: Efficient and Multi-view Consistent Open-Vocabulary 3D Semantic Gaussians", "link_suffix": "/forum?id=qSEEQPNbu4", "link": "https://openreview.net/forum?id=qSEEQPNbu4", "pdf_link": "https://openreview.net/pdf?id=qSEEQPNbu4", "keywords": "3D Scene Understanding, Gaussian Splatting, Open-Vocabulary 3D Semantic", "abstract": "The primary focus of most recent works on open-vocabulary neural fields is extracting precise semantic features\nfrom the VLMs and then consolidating them efficiently into a multi-view consistent 3D neural fields\nrepresentation. However, most existing works over-trusted SAM to regularize image-level CLIP without any further refinement. Moreover, several existing works improved efficiency by dimensionality reduction of semantic features from 2D VLMs before fusing with 3DGS semantic fields, which inevitably leads to multi-view inconsistency. In this work, we propose econSG for open-vocabulary semantic segmentation with 3DGS. Our econSG consists of: 1) A Confidence-region Guided Regularization (CRR) that mutually refines SAM and CLIP to get the best of both worlds for precise semantic features with complete and precise boundaries. 2) A low dimensional contextual space to enforce 3D multi-view consistency while improving computational efficiency by fusing backprojected multi-view 2D features and follow by dimensional reduction directly on the fused 3D features instead of operating on each 2D view separately. Our econSG show state-of-the-art performance on four benchmark datasets compared to the existing methods. Furthermore, we are also the most efficient training among all the methods. We will make our source-code open source upon paper acceptance.", "title_embedding_index": 12506, "title_abs_embedding_index": 12531}, {"title": "MathEval: A Comprehensive Benchmark for Evaluating Large Language Models on Mathematical Reasoning Capabilities", "link_suffix": "/forum?id=DexGnh0EcB", "link": "https://openreview.net/forum?id=DexGnh0EcB", "pdf_link": "https://openreview.net/pdf?id=DexGnh0EcB", "keywords": "Mathematical reasoning benchmark, Adaptation strategies, Cross-lingual assessment", "abstract": "Mathematical reasoning is a fundamental aspect of intelligence, encompassing a spectrum from basic arithmetic to intricate problem-solving. Recent investigations into the mathematical abilities of large language models (LLMs) have yielded inconsistent and incomplete assessments. In response, we introduce MathEval, a comprehensive benchmark designed to methodically evaluate the mathematical problem-solving proficiency of LLMs across varied contexts, adaptation strategies, and evaluation metrics. MathEval amalgamates 19 datasets, spanning an array of mathematical domains, languages, problem types, and difficulty levels, from elementary to advanced. This diverse collection facilitates a thorough appraisal of LLM performance and is stratified by language (English and Chinese), problem category (arithmetic, competitive mathematics, and higher mathematics), and difficulty. To overcome the challenges of standardizing responses across diverse models and prompts, we've developed an automated LLM-driven pipeline for answer extraction and comparison, ensuring consistent evaluation criteria. To broaden the utility of MathEval beyond the scope of GPT-4, we have harnessed the extensive results from GPT-4 to train a deepseek-7B-based answer comparison model, enabling precise answer validation for those without access to GPT-4. This model will also be made publicly available. MathEval not only assesses mathematical proficiency but also introduces a method to identify potential data contamination within pre-training datasets. This is done by hypothesizing that enhancements in one mathematical dataset should be mirrored by advancements in correlated datasets, thus signaling potential contamination\u2014like the inadvertent inclusion of test data in the pre-training phase. To mitigate this and truly gauge progress, MathEval incorporates an annually refreshed set of problems from the latest Chinese National College Entrance Examination (Gaokao 2023), thereby benchmarking genuine advancements in mathematical problem solving skills. MathEval strives to refine the assessment of Large Language Models' (LLMs) capabilities in mathematics.", "title_embedding_index": 12507, "title_abs_embedding_index": 12532}, {"title": "Grouped Correlation Aggregation with Propagation for Stereo Matching", "link_suffix": "/forum?id=Sk2mND99Wp", "link": "https://openreview.net/forum?id=Sk2mND99Wp", "pdf_link": "https://openreview.net/pdf?id=Sk2mND99Wp", "keywords": "stereo matching, computer vision", "abstract": "Iterative optimization-based methods have dominated the field of stereo matching with extraordinary precision and speed. However, these methods still suffer from low iteration efficiency and insufficient correlation volume with low utilization rates. \nAs the countermeasure, we propose grouped correlation aggregation with propagation,  a novel stereo matching method inspired by traditional methods. \nWe design an efficient updater to improve the performance of single iteration optimization. To alleviate the problems of correlation volume, a novel grouped window shifting mechanism and a contour-aware aggregation modified from semi-global matching (SGM) have been introduced. Our method outperforms all methods in zero-shot generalization and ranks 1st on ETH3D among published works. \nAdditionally, we conducted targeted inference optimization on the video stream and demonstrated the improvement in frame rate without sacrificing accuracy through experiments on the simulator. \nFinally, a real-world binocular system is deployed to qualitatively demonstrate the practicality of our method.", "title_embedding_index": 12508, "title_abs_embedding_index": 12533}, {"title": "AgentStudio: A Toolkit for Building General Virtual Agents", "link_suffix": "/forum?id=axUf8BOjnH", "link": "https://openreview.net/forum?id=axUf8BOjnH", "pdf_link": "https://openreview.net/pdf?id=axUf8BOjnH", "keywords": "Environment, Benchmark, Agent, Digital Automation", "abstract": "General virtual agents need to handle multimodal observations, master complex action spaces, and self-improve in dynamic, open-domain environments. However, existing environments are often domain-specific and require complex setups, which limits agent development and evaluation in real-world settings. As a result, current evaluations lack in-depth analyses that decompose fundamental agent capabilities. We introduce AgentStudio, a trinity of environments, tools, and benchmarks to address these issues. AgentStudio provides a lightweight, interactive environment with highly generic observation and action spaces, e.g., video observations and GUI/API actions. It integrates tools for creating online benchmark tasks, annotating GUI elements, and labeling actions in videos. Based on our environment and tools, we curate an online task suite that benchmarks both GUI interactions and function calling with efficient auto-evaluation. We also reorganize existing datasets and collect new ones using our tools to establish three datasets: GroundUI, IDMBench, and CriticBench. These datasets evaluate fundamental agent abilities, including GUI grounding, learning from videos, and success detection, pointing to the desiderata for robust, general, and open-ended virtual agents.", "title_embedding_index": 12509, "title_abs_embedding_index": 12534}, {"title": "EVA: Geometric Inverse Design for Fast Protein Motif-Scaffolding with Coupled Flow", "link_suffix": "/forum?id=KHkBpvmYVI", "link": "https://openreview.net/forum?id=KHkBpvmYVI", "pdf_link": "https://openreview.net/pdf?id=KHkBpvmYVI", "keywords": "Generative Model, Protein Structure Generation, Training-free Conditional Generation", "abstract": "Motif-scaffolding is a fundamental component of protein design, which aims to construct the scaffold structure that stabilizes motifs conferring desired functions. Recent advances in generative models are promising for designing scaffolds, with two main approaches: training-based and sampling-based methods. Training-based methods are resource-heavy and slow, while training-free sampling-based methods are flexible but require numerous sampling steps and costly, unstable guidance. To speed up and improve sampling-based methods, we analyzed failure cases and found that errors stem from the trade-off between generation and guidance. Thus we proposed to exploit the spatial context and adjust the generative direction to be consistent with guidance to overcome this trade-off. Motivated by this, we formulate motif-scaffolding as a Geometric Inverse Design task inspired by the image inverse problem, and present Evolution-ViA-reconstruction (EVA), a novel sampling-based coupled flow framework on geometric manifolds, which starts with a pretrained flow-based generative model. EVA uses motif-coupled priors to leverage spatial contexts, guiding the generative process along a straighter probability path, with generative directions aligned with guidance in the early sampling steps. EVA is 70\u00d7 faster than SOTA model RFDiffusion with competitive and even better performance on benchmark tests. Further experiments on real-world cases including vaccine design, multi-motif scaffolding and motif optimal placement searching demonstrate EVA's superior efficiency and effectiveness.", "title_embedding_index": 12510, "title_abs_embedding_index": 12535}, {"title": "Multi-Perspective Data Augmentation for Few-shot Object Detection", "link_suffix": "/forum?id=qG0WCAhZE0", "link": "https://openreview.net/forum?id=qG0WCAhZE0", "pdf_link": "https://openreview.net/pdf?id=qG0WCAhZE0", "keywords": "few-shot object detection, controllable diffusion, data augmentation", "abstract": "Recent few-shot object detection (FSOD) methods have focused on  augmenting synthetic samples for novel classes, show promising results  to the rise of diffusion models. However, the diversity of such datasets is often limited in representativeness because they lack awareness of typical and hard samples, especially in the context of foreground and background relationships. To tackle this issue, we propose a Multi-Perspective Data Augmentation (MPAD) framework. In terms of foreground-foreground relationships, we propose chain-of-thought prompting for object synthesis (CPOS) with bounding box adjustments to enhance the detail and spatial information of synthetic samples. Inspired by the large margin principle, support samples play a vital role in defining class boundaries. Therefore, we design a Harmonic Prompt Aggregation Scheduler (HPAS) to mix prompt embeddings at each time step of the generation process in diffusion models, producing hard novel samples. For foreground-background relationships, we introduce a Background Proposal method (BAP) to sample typical and hard backgrounds. Extensive experiments on multiple FSOD benchmarks demonstrate the effectiveness of our approach. Our framework significantly outperforms traditional methods, achieving an average increase of $17.5%$ in nAP50 over the baseline on PASCAL VOC.", "title_embedding_index": 12511, "title_abs_embedding_index": 12536}, {"title": "Intrinsic User-Centric Interpretability through Global Mixture of Experts", "link_suffix": "/forum?id=wDcunIOAOk", "link": "https://openreview.net/forum?id=wDcunIOAOk", "pdf_link": "https://openreview.net/pdf?id=wDcunIOAOk", "keywords": "interpretability, human-centric computing, mixture-of-experts", "abstract": "In human-centric settings like education or healthcare, model accuracy and model explainability are key factors for user adoption. Towards these two goals, intrinsically interpretable deep learning models have gained popularity, focusing on accurate predictions alongside faithful explanations. However, there exists a gap in the human-centeredness of these approaches, which often produce nuanced and complex explanations that are not easily actionable for downstream users. We present InterpretCC (interpretable conditional computation), a family of intrinsically interpretable neural networks at a unique point in the design space that optimizes for ease of human understanding and explanation faithfulness, while maintaining comparable performance to state-of-the-art models. InterpretCC achieves this through adaptive sparse activation of features before prediction, allowing the model to use a different, minimal set of features for each instance. We extend this idea into an interpretable, global mixture-of-experts (MoE) model that allows users to specify topics of interest, discretely separates the feature space for each data point into topical subnetworks, and adaptively and sparsely activates these topical subnetworks for prediction. We apply InterpretCC for text, time series and tabular data across several real-world datasets, demonstrating comparable performance with non-interpretable baselines and outperforming intrinsically interpretable baselines. Through a user study involving 56 teachers, InterpretCC explanations are found to have higher actionability and usefulness over other intrinsically interpretable approaches.", "title_embedding_index": 12512, "title_abs_embedding_index": 12537}, {"title": "BAdd: Bias Mitigation through Bias Addition", "link_suffix": "/forum?id=fMOUybjbnO", "link": "https://openreview.net/forum?id=fMOUybjbnO", "pdf_link": "https://openreview.net/pdf?id=fMOUybjbnO", "keywords": "fairness, bias, spurious correlations", "abstract": "Computer vision (CV) datasets often exhibit biases in the form of spurious correlations between certain attributes and target variables that are perpetuated by Deep Learning (DL) models. While recent efforts aim to mitigate such biases and foster bias-neutral representations, they fail in complex real-world scenarios. In particular, existing methods excel in controlled experiments on benchmarks with single-attribute injected biases, but struggle with complex multi-attribute biases that naturally occur in established CV datasets. Here, we introduce BAdd, a simple yet effective method that allows for learning bias-neutral representations invariant to bias-inducing attributes.  It achieves this by injecting features encoding these attributes into the training process. BAdd is evaluated on seven benchmarks and exhibits competitive performance, surpassing state-of-the-art methods on both single- and multi-attribute bias settings. Notably, it achieves +27.5% and +5.5% absolute accuracy improvements on the challenging multi-attribute benchmarks, FB-Biased-MNIST and CelebA, respectively.", "title_embedding_index": 12513, "title_abs_embedding_index": 12538}, {"title": "MemBench: Memorized Image Trigger Prompt Dataset for Diffusion Models", "link_suffix": "/forum?id=Qg0gtNkXIb", "link": "https://openreview.net/forum?id=Qg0gtNkXIb", "pdf_link": "https://openreview.net/pdf?id=Qg0gtNkXIb", "keywords": "diffusion models, MCMC sampling, image memorization, safety ai", "abstract": "Diffusion models have achieved remarkable success in Text-to-Image generation tasks, leading to the development of many commercial models. However, recent studies have reported that diffusion models often repeatedly generate memorized images in train data when triggered by specific prompts, potentially raising social issues ranging from copyright to privacy concerns. To sidestep the memorization, there have been recent studies for developing memorization mitigation methods for diffusion models. Nevertheless, the lack of benchmarks hinders the assessment of the true effectiveness of these methods. In this work, we present MemBench, the first benchmark for evaluating image memorization mitigation methods. Our benchmark includes a large number of memorized image trigger prompts in various Text-to-Image diffusion models. Furthermore, in contrast to the prior work evaluating mitigation performance only on trigger prompts, we present metrics evaluating on both trigger prompts and general prompts, so that we can see whether mitigation methods address the memorization issue while maintaining performance for general prompts. Through our MemBench evaluation, we revealed that existing memorization mitigation methods notably degrade overall performance of diffusion models and need to be further developed.", "title_embedding_index": 12514, "title_abs_embedding_index": 12539}, {"title": "Benchmarking Federated Learning for Semantic Datasets: Federated Scene Graph Generation", "link_suffix": "/forum?id=QuGnjxfLBH", "link": "https://openreview.net/forum?id=QuGnjxfLBH", "pdf_link": "https://openreview.net/pdf?id=QuGnjxfLBH", "keywords": "Federated Learning, Decentralized Learning, Scene Graph Generation", "abstract": "Federated learning (FL) has recently garnered attention as a decentralized training framework that enables the learning of deep models from locally distributed samples while keeping the data privacy.\nBuilt upon the framework, immense efforts have been made to establish FL benchmarks, which provide rigorous evaluation settings that aim to control data heterogeneity across clients.\nPrior efforts have mainly focused on handling relatively simple classification tasks, where each sample is annotated with a one-hot label, such as MNIST, CIFAR, LEAF benchmark, etc.\nHowever, little attention has been paid to demonstrating an FL benchmark that handles complicated semantics, where each sample encompasses diverse semantic information from multiple labels, such as Scene Graph Generation / Panoptic Scene Graph Generation (SGG/PSG) with objects, predicates, and relations between objects.\nBecause the existing benchmark is designed to distribute data in a narrow view of a single semantic, e.g., a one-hot label, managing the complicated $\\textit{semantic heterogeneity}$ across clients when formalizing FL benchmarks is non-trivial.\nIn this paper, we propose a benchmark process to establish an FL benchmark with controllable semantic heterogeneity across clients: two key steps are i) data clustering with semantics and ii) data distributing via controllable semantic heterogeneity across clients.\nAs a proof of concept, we first construct a federated SGG/PSG benchmark, which demonstrates the efficacy of the existing PSG methods in an FL setting with controllable semantic heterogeneity of scene graphs.", "title_embedding_index": 12515, "title_abs_embedding_index": 12540}, {"title": "MICE: Memory-driven Intrinsic Cost Estimation for Mitigating Constraint Violations", "link_suffix": "/forum?id=e92KW6htFO", "link": "https://openreview.net/forum?id=e92KW6htFO", "pdf_link": "https://openreview.net/pdf?id=e92KW6htFO", "keywords": "reinforcement learning, constraint optimization, underestimation, intrinsic cost", "abstract": "Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, most existing CRL algorithms encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to enhance the cost estimate of unsafe behaviors, thus mitigating the underestimation bias. Our method draws inspiration from human cognitive processes, specifically the concept of flashbulb memory, where vivid memories of dangerous events are retained to prevent potential risks. MICE constructs a memory module to store unsafe trajectories explored by the agent. The intrinsic cost is formulated as the similarity between the current trajectory and the unsafe trajectories stored in memory, assessed by an intrinsic generator. We propose an extrinsic-intrinsic cost value function and optimization objective based on intrinsic cost, along with the corresponding optimization method. Theoretically, we provide convergence guarantees for the new cost value function and establish the worst-case constraint violation for the MICE update, ensuring fewer constraint violations compared to baselines. Extensive experiments validate the effectiveness of our approach, demonstrating a substantial reduction in constraint violations while maintaining policy performance comparable to baselines.", "title_embedding_index": 12516, "title_abs_embedding_index": 12541}, {"title": "The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions", "link_suffix": "/forum?id=ws5phQki00", "link": "https://openreview.net/forum?id=ws5phQki00", "pdf_link": "https://openreview.net/pdf?id=ws5phQki00", "keywords": "large language models, stance detection, data augmentation, active learning, online political discussions", "abstract": "Stance detection holds great potential to improve online political discussions through its deployment in discussion platforms for purposes such as content moderation, topic summarisation or to facilitate more balanced discussions. Typically, transformer-based models are employed directly for stance detection, requiring vast amounts of data. However, the wide variety of debate topics in online political discussions makes data collection particularly challenging. LLMs have revived stance detection, but their online deployment in online political discussions faces challenges like inconsistent outputs, biases, and vulnerability to adversarial attacks. We show how LLM-generated synthetic data can improve stance detection for online political discussions by using reliable traditional stance detection models for online deployment, while leveraging the text generation capabilities of LLMs for synthetic data generation in a secure offline environment. To achieve this, (i) we generate synthetic data for specific debate questions by prompting a Mistral-7B model and show that fine-tuning with the generated synthetic data can substantially improve the performance of stance detection, while remaining interpretable and aligned with real world data. (ii) Using the synthetic data as a reference, we can improve performance even further by identifying the most informative samples in an unlabelled dataset, i.e., those samples which the stance detection model is most uncertain about and can benefit from the most. By fine-tuning with both synthetic data and the most informative samples, we surpass the performance of the baseline model that is fine-tuned on all true labels, while labelling considerably less data.", "title_embedding_index": 12517, "title_abs_embedding_index": 12542}, {"title": "VCR: Visual Caption Restoration", "link_suffix": "/forum?id=s0Z4csHOoE", "link": "https://openreview.net/forum?id=s0Z4csHOoE", "pdf_link": "https://openreview.net/pdf?id=s0Z4csHOoE", "keywords": "dataset, vision-language model, multimodal", "abstract": "We introduce Visual Caption Restoration (VCR), a novel vision-language task that challenges models to accurately restore partially obscured texts using pixel-level hints within images. This task stems from the observation that text embedded in images is intrinsically different from common visual elements and natural language due to the need to align the modalities of vision, text, and text embedded in images. While numerous works have integrated text embedded in images into visual question-answering tasks, approaches to these tasks generally rely on optical character recognition or masked language modeling, thus reducing the task to mainly text-based processing. However, text-based processing becomes ineffective in VCR as accurate text restoration depends on the combined information from provided images, context, and subtle cues from the tiny, exposed areas of masked texts. We develop a pipeline to generate synthetic images for the VCR task using image-caption pairs, with adjustable caption visibility to control the task difficulty. With this pipeline, we construct a dataset for VCR called VCR-Wiki using images with captions from Wikipedia, comprising 2.11M English and 346K Chinese entities in both easy and hard split variants. Our results reveal that current vision language models significantly lag behind human performance in the VCR task, and merely fine-tuning the models on our dataset does not lead to notable improvements. We release VCR-Wiki and the data construction code to facilitate future research.", "title_embedding_index": 12518, "title_abs_embedding_index": 12543}, {"title": "Gradient Inversion Transcript: A Generative Model to Reconstruct Training Data by Gradient Leakage", "link_suffix": "/forum?id=vgplRfepVq", "link": "https://openreview.net/forum?id=vgplRfepVq", "pdf_link": "https://openreview.net/pdf?id=vgplRfepVq", "keywords": "distributed learning, training data reconstruction, generative model, gradient inversion", "abstract": "We propose Gradient Inversion Transcript (GIT), a generic approach for reconstructing training data from gradient leakage in distributed learning using a generative model. Unlike traditional gradient matching techniques, GIT requires only the model architecture information, without access to the model's parameters, making it more applicable to real-world distributed learning settings. Additionally, GIT operates offline, eliminating the need for intensive gradient requests and online optimization.\nCompared to existing generative methods, GIT adaptively constructs a generative network, with an architecture specifically tailored to the structure of the distributed learning model. Our extensive experiments demonstrate that GIT significantly improves reconstruction accuracy, especially in the case of deep models.\nIn summary, we offer a more effective and theoretically grounded strategy for exploiting vulnerabilities of gradient leakage in distributed learning, advancing the understanding of privacy risks in collaborative learning environments.", "title_embedding_index": 12519, "title_abs_embedding_index": 12544}, {"title": "Embodied Scene Cloning: Solving Generalization in Embodied AI via Visual-Prompt Image Editing", "link_suffix": "/forum?id=dZbCoATni7", "link": "https://openreview.net/forum?id=dZbCoATni7", "pdf_link": "https://openreview.net/pdf?id=dZbCoATni7", "keywords": "Embodied Intelligence, Data Augmentation", "abstract": "Recent advancements in robotic learning have enabled robots to perform a wide range of tasks. However, generalizing policies from training environments to deployment environments remains a major challenge, and improving these policies by collecting and annotating demonstrations in target environments is both costly and time-consuming. To address this issue, we propose Embodied Scene Cloning, a novel visual-prompt-based framework that generates visual-aligned trajectories from existing data by leveraging visual cues from the specific deployment environment. This approach minimizes the impact of environmental discrepancies on policy performance. Unlike traditional embodied augmentation methods that rely on text prompts, we propose to \"clone\" source demonstrations into the target environment and edit it with visual prompt to effectively improve the generalization ability on specific embodied scene. Experimental results demonstrate that samples generated by Embodied Scene Cloning significantly enhance the generalization ability of policies in the target deployment environments, representing a meaningful advancement in embodied data augmentation.", "title_embedding_index": 12520, "title_abs_embedding_index": 12545}, {"title": "Lookahead Shielding for Regular Safety Properties in Reinforcement Learning", "link_suffix": "/forum?id=sFGMkoBjUe", "link": "https://openreview.net/forum?id=sFGMkoBjUe", "pdf_link": "https://openreview.net/pdf?id=sFGMkoBjUe", "keywords": "Safe Reinforcement Learning, Model Checking, Shielding", "abstract": "To deploy reinforcement learning (RL) systems in real-world scenarios we need to consider requirements such as safety and constraint compliance, rather than blindly maximizing for reward. In this paper we develop a lookahead shielding framework for RL with regular safety properties, which on the contrary to prior shielding methodologies requires minimal prior knowledge. At each environment step our framework aims to satisfy the regular safety property for a bounded horizon with high-probability, for the tabular setting we provide provable guarantees. We compare our setup to some common algorithms developed for the constrained Markov decision process (CMDP), and we demonstrate the effectiveness and scalability of our framework by extensively evaluating our framework in both tabular and deep RL environments.", "title_embedding_index": 12521, "title_abs_embedding_index": 12546}, {"title": "Exploring the Link Between Out-of-Distribution Detection and Conformal Prediction with Illustrations of Its Benefits", "link_suffix": "/forum?id=GQhlM0Mavg", "link": "https://openreview.net/forum?id=GQhlM0Mavg", "pdf_link": "https://openreview.net/pdf?id=GQhlM0Mavg", "keywords": "Out-of-distribution detection, Conformal Prediction, benchmark, nonconformity scores", "abstract": "Research on Out-Of-Distribution (OOD) detection focuses mainly on building scores that efficiently distinguish OOD data from In Distribution (ID) data. \n    On the other hand, Conformal Prediction (CP) uses non-conformity scores to construct prediction sets with probabilistic coverage guarantees. In other words, the former designs scores, while the latter designs probabilistic guarantees based on scores. Therefore, we claim that these two fields might be naturally intertwined. \n    This work advocates for cross-fertilization between OOD and CP by formalizing their link and emphasizing two benefits of using them jointly.\n    First, we show that in standard OOD benchmark settings, evaluation metrics can be overly optimistic due to the test dataset's finite sample size.\n    Based on the work of (Bates et al, 2022), we define newconformal AUROCandconformal FRP@TPR$\\beta$metrics, \n    which are corrections that provide probabilistic conservativeness guarantees on the variability of these metrics.\n    We show the effect of these corrections on two reference OOD and anomaly detection benchmarks, OpenOOD (Yang et al, 2022) and ADBench (Han et al. 2022). \n    Second, we explore using OOD scores as non-conformity scores and show that they can improve the efficiency of the prediction sets obtained with CP.", "title_embedding_index": 12522, "title_abs_embedding_index": 12547}, {"title": "FreRA: A Frequency-Refined Augmentation for Contrastive Learning on Time Series Classification", "link_suffix": "/forum?id=EAUGN4pszX", "link": "https://openreview.net/forum?id=EAUGN4pszX", "pdf_link": "https://openreview.net/pdf?id=EAUGN4pszX", "keywords": "time series classification, contrastive learning, frequency domain", "abstract": "Contrastive learning has emerged as a competent approach for unsupervised representation learning. However, the design of an optimal augmentation strategy, although crucial for contrastive learning, is less explored for time series classification tasks. Existing predefined augmentation methods are primarily adopted from vision and are not specific to time series data. Consequently, this cross-modality incompatibility may distort the global semantics of time series by introducing mismatched patterns into the data. To address this limitation, we present a novel perspective from the frequency domain and identify three advantages for downstream classification: 1) the frequency component naturally encodes global features, 2) the orthogonal nature of the Fourier basis allows easier isolation and independent modifications of critical and unimportant information, and 3) a compact set of frequency components can preserve semantic integrity. To fully utilize the three properties, we propose the lightweight yet effective Frequency-Refined Augmentation (FreRA) tailored for time series contrastive learning on classification tasks, which can be seamlessly integrated with contrastive learning frameworks in a plug-and-play manner. Specifically, FreRA automatically separates critical and unimportant frequency components. Accordingly, we propose Identity Modification and Self-adaptive Modification to protect global semantics in the critical frequency components and infuse variance to the unimportant ones respectively. \nTheoretically, we prove that FreRA generates semantic-preserving views. Empirically, we conduct extensive experiments on two benchmark datasets including UCR and UEA archives, as well as 5 large-scale datasets on diverse applications. FreRA consistently outperforms 10 leading baselines on time series classification, anomaly detection, and transfer learning tasks, demonstrating superior capabilities in contrastive representation learning and generalization in transfer learning scenarios across diverse datasets.", "title_embedding_index": 12523, "title_abs_embedding_index": 12548}, {"title": "TRAIN THE LATENT, NOT THE IMAGE: JOINT IMAGE COMPRESSION AND STEGANOGRAPHY", "link_suffix": "/forum?id=Q00XEQxA45", "link": "https://openreview.net/forum?id=Q00XEQxA45", "pdf_link": "https://openreview.net/pdf?id=Q00XEQxA45", "keywords": "steganography, image compression, semi-amotorize, adversatial learning", "abstract": "Image steganography is the process of hiding secret information in an image through imperceptible changes. Most of recent works achieve message in the image by modifying the pixels of image itself. However, those images with hidden messages are not robust to compression such as JPEG, which is used almost everywhere. In order to achieve the ability to compress the image while still having the ability to carry the message, we propose an innovative optimization method which leverages a semi-amortized approach to directly manipulate latent space data for the joint optimization of image compression and steganography. In the compression module, we investigate two of the most popular models in learned image compression with  different pre-trained quality: the hyperprior model and the ELIC model. For the steganography module, our method employs the pre-trained fixed neural network steganography (FNNS) model. We compare our method with two state-of-the-art methods such as FNNS-JPEG and LISO-JPEG, achieving significant image compression while maintaining high fidelity and ensuring the accuracy of content upon decoding. The results demonstrate the effectiveness and superiority of our approach.", "title_embedding_index": 12524, "title_abs_embedding_index": 12549}]
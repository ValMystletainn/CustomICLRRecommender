[{"title": "Probabilistic Neural Pruning via Sparsity Evolutionary Fokker-Planck-Kolmogorov Equation", "link_suffix": "/forum?id=hJ1BaJ5ELp", "link": "https://openreview.net/forum?id=hJ1BaJ5ELp", "pdf_link": "https://openreview.net/pdf?id=hJ1BaJ5ELp", "keywords": "Optimization for Deep Network, Probabilistic Method, Machine learning, Model compression", "abstract": "Neural pruning aims to compress and accelerate deep neural networks by identifying the optimal subnetwork within a specified sparsity budget. In this work, we study how to gradually sparsify the unpruned dense model to the target sparsity level with a minimal performance drop. Specifically, we analyze the evolution of the population of optimal subnetworks under continuous sparsity increments from a thermodynamics perspective. We first reformulate neural pruning as an expected loss minimization problem over the mask distributions. Then, we establish an effective approximation for the sparsity evolution of the optimal mask distribution, termed theSparsity EvolutionaryFokker-Planck-Kolmogorov Equation (SFPK), which provides closed-form, mathematically tractable guidance on distributional transitions for minimizing the expected loss under an infinitesimal sparsity increment. On top of that, we propose SFPK-pruner, a particle simulation-based probabilistic pruning method, to sample performant masks with desired sparsity from the destination distribution of SFPK. In theory, we establish the convergence guarantee for the proposed SFPK-pruner. In practice, our SFPK-pruner exhibits competitive performance across various pruning scenarios.", "title_embedding_index": 13900, "title_abs_embedding_index": 13925}, {"title": "Adversarial Machine Unlearning", "link_suffix": "/forum?id=swWF948IiC", "link": "https://openreview.net/forum?id=swWF948IiC", "pdf_link": "https://openreview.net/pdf?id=swWF948IiC", "keywords": "Machine unlearning, Adversarial approach, Stackelberg game", "abstract": "This paper focuses on the challenge of machine unlearning, aiming to remove the influence of specific training data on machine learning models. Traditionally, the development of unlearning algorithms runs parallel with that of membership inference attacks (MIA), a type of privacy threat to determine whether a data instance was used for training. However, the two strands are intimately connected: one can view machine unlearning through the lens of MIA success with respect to removed data. Recognizing this connection, we propose a game-theoretic framework that integrates MIAs into the design of unlearning algorithms. Specifically, we model the unlearning problem as a Stackelberg game in which an unlearner strives to unlearn specific training data from a model, while an auditor employs MIAs to detect the traces of the ostensibly removed data. Adopting this adversarial perspective allows the utilization of new attack advancements,  facilitating the design of unlearning algorithms. Our framework stands out in two ways. First, it takes an adversarial approach and proactively incorporates the attacks into the design of unlearning algorithms. Secondly, it uses implicit differentiation to obtain the gradients that limit the attacker's success, thus benefiting the process of unlearning. We present empirical results to demonstrate the effectiveness of the proposed approach for machine unlearning.", "title_embedding_index": 13901, "title_abs_embedding_index": 13926}, {"title": "Action as a Modality: Turning Multi-Modal LLMs to General Action Planners", "link_suffix": "/forum?id=jaIxmAVAqF", "link": "https://openreview.net/forum?id=jaIxmAVAqF", "pdf_link": "https://openreview.net/pdf?id=jaIxmAVAqF", "keywords": "Multi-modal Large Language Models, LLMs, Action", "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities and possess extensive common knowledge. This enables them to adapt to a variety of complex tasks in a zero-shot manner, including functioning as controllers to manipulate automated systems and produce executable action sequences. However, a significant challenge in the existing framework is the misalignment between the general pre-trained LLM and the action space of specific control tasks. This misalignment necessitates extensive efforts in designing task-specific prompts, which are less generalizable and do not ensure consistent output when prompting a pre-trained LLM to generate the desired action sequences. To address this issue, we propose a novel solution, ActionVerse, which encodes action candidates into a series of modality tokens, coupled with an efficient alignment technique to synchronize the action tokens with the LLM's language space. By leveraging this approach, the proposed ActionVerse successfully transforms a chat-based multi-modal LLM into a general action executor capable of handling tasks requiring step-by-step execution of various actions. Experiments on several sequential action tasks demonstrate the effectiveness of the proposed framework.", "title_embedding_index": 13902, "title_abs_embedding_index": 13927}, {"title": "Concept Bottleneck Language Models For Protein Design", "link_suffix": "/forum?id=Yt9CFhOOFe", "link": "https://openreview.net/forum?id=Yt9CFhOOFe", "pdf_link": "https://openreview.net/pdf?id=Yt9CFhOOFe", "keywords": "LLMs, protein design, concept bottleneck", "abstract": "We introduce Concept Bottleneck Protein Language Models (CB-pLM), a generative masked language model with a layer where each neuron corresponds to an interpretable concept. Our architecture offers three key benefits: i) Control: We can intervene on concept values to precisely control the properties of generated proteins, achieving a 3$\\times$ larger change in desired concept values compared to baselines. ii) Interpretability: A linear mapping between concept values and predicted tokens allows transparent analysis of the model's decision-making process. iii) Debugging: This transparency facilitates easy debugging of trained models. Our models achieve pre-training perplexity and downstream task performance comparable to traditional masked protein language models, demonstrating that interpretability does not compromise performance. While adaptable to any language model, we focus on masked protein language models due to their importance in drug discovery and the ability to validate our model's capabilities through real-world experiments and expert knowledge. We scale our CB-pLM from 24 million to 3 billion parameters, making them the largest Concept Bottleneck Models trained and the first capable of generative language modeling.", "title_embedding_index": 13903, "title_abs_embedding_index": 13928}, {"title": "Discrete Bregman Divergence", "link_suffix": "/forum?id=vr1QdCNJmN", "link": "https://openreview.net/forum?id=vr1QdCNJmN", "pdf_link": "https://openreview.net/pdf?id=vr1QdCNJmN", "keywords": "Bregman Divergence, Permutation-invariant neural networks, Metric learning, Submodular functions", "abstract": "The Bregman divergence, which is generated from a convex function, is commonly used as a pseudo-distance for comparing vectors or functions in continuous spaces. In contrast, defining an analog of the Bregman divergence for discrete spaces is nontrivial.\nIyer and Bilmes (2012a) considered Bregman divergences on discrete domains using submodular functions as generating functions, the discrete analogs of convex functions. In this paper, we further generalize this framework to cases where the generating function is neither submodular nor supermodular, thus increasing the flexibility and representational capacity of the resulting divergence, which we term the discrete Bregman divergence. Additionally, we introduce a learnable form of this divergence using permutation-invariant neural networks (NNs) and demonstrate through experiments that it effectively captures key structural properties in discrete data, outperforming existing methods on tasks such as clustering. This work addresses the challenge of defining meaningful divergences in discrete settings and provides a new tool for tasks requiring structure-preserving distance measures.", "title_embedding_index": 13904, "title_abs_embedding_index": 13929}, {"title": "Thread: A Logic-Based Data Organization Paradigm for How-To Question Answering with Retrieval Augmented Generation", "link_suffix": "/forum?id=ZmPf5Z1V2H", "link": "https://openreview.net/forum?id=ZmPf5Z1V2H", "pdf_link": "https://openreview.net/pdf?id=ZmPf5Z1V2H", "keywords": "Data organization paradigm, Retrieval augmented generation, How-to questions, Large language model", "abstract": "Recent advances in retrieval-augmented generation have significantly improved the performance of question-answering systems, particularly on factoid '5Ws' questions. However, these systems still face substantial challenges when addressing '1H' questions, specifically how-to questions, which are integral to decision-making processes and require dynamic, step-by-step answers. The key limitation lies in the prevalent data organization paradigm, chunk, which divides documents into fixed-size segments, and disrupts the logical coherence and connections within the context. To overcome this, in this paper, we propose Thread, a novel data organization paradigm aimed at enabling current systems to handle how-to questions more effectively. Specifically, we introduce a new knowledge granularity, termed 'logic unit', where documents are transformed into more structured and loosely interconnected logic units with large language models. Extensive experiments conducted across both open-domain and industrial settings demonstrate that Thread outperforms existing paradigms significantly, improving the success rate of handling how-to questions by 21% to 33%. \nMoreover, Thread exhibits high adaptability in processing various document formats, drastically reducing the candidate quantity in the knowledge base and minimizing the required information to one-fourth compared with chunk, optimizing both efficiency and effectiveness.", "title_embedding_index": 13905, "title_abs_embedding_index": 13930}, {"title": "Taming Data and Transformers for Audio Generation", "link_suffix": "/forum?id=lidVssyB7G", "link": "https://openreview.net/forum?id=lidVssyB7G", "pdf_link": "https://openreview.net/pdf?id=lidVssyB7G", "keywords": "Audio, Diffusion Models, T2A", "abstract": "Generating ambient sounds is a challenging task due to data scarcity and often\ninsufficient caption quality, making it difficult to employ large-scale generative\nmodels for the task. In this work, we tackle this problem by introducing two\nnew models. First, we propose AutoCap, a high-quality and efficient automatic\naudio captioning model. By using a compact audio representation and leveraging\naudio metadata, AutoCap substantially enhances caption quality, reaching a CIDEr\nscore of 83.2, marking a 3.2% improvement from the best available captioning\nmodel at four times faster inference speed. Second, we propose GenAu, a scalable\ntransformer-based audio generation architecture that we scale up to 1.25B param-\neters. Using AutoCap to generate caption clips from existing audio datasets, we\ndemonstrate the benefits of data scaling with synthetic captions as well as model\nsize scaling. When compared to state-of-the-art audio generators trained at similar\nsize and data scale, GenAu obtains significant improvements of 4.7% in FAD\nscore, 22.7% in IS, and 13.5% in CLAP score, indicating significantly improved\nquality of generated audio compared to previous works. Moreover, we propose an\nefficient and scalable pipeline for collecting audio datasets, enabling us to compile\n57M ambient audio clips, forming AutoReCap-XL, the largest available audio-text\ndataset, at 90 times the scale of existing ones. Our code, model checkpoints, and\ndataset will be made publicly available upon acceptance.", "title_embedding_index": 13906, "title_abs_embedding_index": 13931}, {"title": "GAP: Scalable Driving with Generative Aided Planner", "link_suffix": "/forum?id=H6i47PKXSN", "link": "https://openreview.net/forum?id=H6i47PKXSN", "pdf_link": "https://openreview.net/pdf?id=H6i47PKXSN", "keywords": "end-to-end autonomous driving;generative;planning;perception", "abstract": "The primary challenge in end-to-end autonomous driving lines in how to establish robust environmental perception and representations. While most methods improve these capabilities by introducing auxiliary perception tasks, the process of obtaining precise large-scale annotations in this paradigm is both time-consuming and laborious, thereby limiting the scalability and practical application. To address this, we propose an architecture based on the Generative Aided Planner (GAP), which integrates scene generation and planning within a single framework. To compensate for the information loss in discrete image features, we design a dual-branch image encoder that fuses continuous and discrete features, improving the model's ability to recognize traffic lights. Through the scene generation task from input tokens, our approach learns the intrinsic dependencies between tokens and environments, which in turn benefits the planning task. It is important to note that the generative model is trained in a fully self-supervised manner, requiring no perception annotations. Our model is built upon GPT-2, which exhibits scaling laws similar to those observed in other GPTs: as we increase the model size and data size, the performance shows continuous and non-saturating improvements. Experiments show that among methods using the front view as input, our approach outperforms other methods that employ multiple perception supervision in the CARLA simulator. Our method is simple yet highly effective, offering a promising direction for scalable and practical deployment of autonomous vehicles in real-world settings.", "title_embedding_index": 13907, "title_abs_embedding_index": 13932}, {"title": "Are Large Vision Language Models Good Game Players?", "link_suffix": "/forum?id=c4OGMNyzPT", "link": "https://openreview.net/forum?id=c4OGMNyzPT", "pdf_link": "https://openreview.net/pdf?id=c4OGMNyzPT", "keywords": "Large  Vision Language Models, LLMs, Evaluation, Game", "abstract": "Large Vision Language Models (LVLMs) have demonstrated remarkable abilities in understanding and reasoning about both visual and textual information. However, existing evaluation methods for LVLMs, primarily based on benchmarks like Visual Question Answering and image captioning, often fail to capture the full scope of LVLMs' capabilities. These benchmarks are limited by issues such as inadequate assessment of detailed visual perception, data contamination, and a lack of focus on multi-turn reasoning. To address these challenges, we propose LVLM-Playground, a game-based evaluation framework designed to provide a comprehensive assessment of LVLMs' cognitive and reasoning skills in structured environments. LVLM-Playground uses a set of games to evaluate LVLMs on four core tasks: Perceiving, Question Answering, Rule Following, and End-to-End Playing, with each target task designed to assess specific abilities, including visual perception, reasoning, decision-making, etc. Based on this framework, we conduct extensive experiments that explore the limitations of current LVLMs, such as handling long structured outputs and perceiving detailed and dense elements. Moreover, we provide preliminary explorations into how gameplay data influences the reasoning capabilities of LVLMs during supervised fine-tuning.", "title_embedding_index": 13908, "title_abs_embedding_index": 13933}, {"title": "One Language, Many Gaps: Evaluating Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks", "link_suffix": "/forum?id=hRSabwKj53", "link": "https://openreview.net/forum?id=hRSabwKj53", "pdf_link": "https://openreview.net/pdf?id=hRSabwKj53", "keywords": "dialect, large language model, fairness, robustness, reasoning", "abstract": "Language is not monolithic. While many benchmarks are used as proxies to systematically estimate Large Language Models' (LLM)  performance in real-life tasks, they tend to ignore the nuances of within-language variation and thus fail to model the experience of speakers of minority dialects. Focusing on African American Vernacular English (AAVE), we present the first study on LLMs' fairness and robustness to a dialect in canonical reasoning tasks (algorithm, math, logic, and comprehensive reasoning). We hire AAVE speakers, including experts with computer science backgrounds, to rewrite seven popular benchmarks, such as HumanEval and GSM8K. The result of this effort is ReDial, a dialectal benchmark comprising 1.2K+ parallel query pairs in Standardized English and AAVE. We use ReDial to evaluate state-of-the-art LLMs, including GPT-4o/4/3.5-turbo, LLaMA-3.1/3, Mistral, and Phi-3. We find that, compared to Standardized English, almost all of these widely used models show significant brittleness and unfairness to queries in AAVE. \nFurthermore, AAVE queries can degrade performance more substantially than misspelled texts in Standardized English, even when LLMs are more familiar with the AAVE queries. Finally, asking models to rephrase questions in Standardized English does not close the performance gap but generally introduces higher costs. Overall, our findings indicate that LLMs provide unfair service to dialect users in complex reasoning tasks. Code can be found athttps://anonymous.4open.science/r/redial_eval-0A88.", "title_embedding_index": 13909, "title_abs_embedding_index": 13934}, {"title": "EM-DARTS: Preventing Performance Collapse in Differentiable Architecture Search with The Edge Mutation Mechanism", "link_suffix": "/forum?id=JrhAsf4xNH", "link": "https://openreview.net/forum?id=JrhAsf4xNH", "pdf_link": "https://openreview.net/pdf?id=JrhAsf4xNH", "keywords": "deep learning, autoML, neural architecture search, image classification, performance collapse", "abstract": "Differentiable Architecture Search (DARTS) relaxes the discrete search space into a continuous form, significantly improving architecture search efficiency through gradient-based optimization. However, DARTS often suffers from performance collapse, where the performance of discovered architectures degrades during the search process, and the final architectures tend to be dominated by excessive skip-connections. In this work, we analyzes how continuous relaxation impacts architecture optimization, identifying two main causes for performance collapse. First, the continuous relaxation framework introduces coupling between network weights and architecture parameters. This coupling leads to insufficient training of parametric operations, resulting in smaller architecture parameters for these operations. Second, DARTS's unrolled estimation property leads to larger architecture parameters for skip-connections. To attack this issue, we propose Edge Mutation Differentiable Architecture Search (EM-DARTS), which mutates DARTS supernet edges during network weight updates. EM-DARTS reduces the impact of architecture parameters on parametric operations, allowing for better training of the parametric operations, thereby increasing their architecture parameters and preventing performance collapse. Theoretical results and experimental studies across diverse search spaces and datasets validate the effectiveness of the proposed method.", "title_embedding_index": 13910, "title_abs_embedding_index": 13935}, {"title": "GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models", "link_suffix": "/forum?id=VtYfbvwpWp", "link": "https://openreview.net/forum?id=VtYfbvwpWp", "pdf_link": "https://openreview.net/pdf?id=VtYfbvwpWp", "keywords": "drag editing, generative AI, diffusion model", "abstract": "In this paper, we introduce GoodDrag, a novel approach to improve the stability and image quality of drag editing. Unlike existing methods that struggle with accumulated perturbations and often result in distortions, GoodDrag introduces an AlDD framework that alternates between drag and denoising operations within the diffusion process, effectively improving the fidelity of the result. We also propose an information-preserving motion supervision operation that maintains the original features of the starting point for precise manipulation and artifact reduction. In addition, we contribute to the benchmarking of drag editing by introducing a new dataset, Drag100, and developing dedicated quality assessment metrics, Dragging Accuracy Index and Gemini Score, utilizing Large Multimodal Models. Extensive experiments demonstrate that the proposed GoodDrag compares favorably against the state-of-the-art approaches both qualitatively and quantitatively. The source code and data will be released.", "title_embedding_index": 13911, "title_abs_embedding_index": 13936}, {"title": "Your Consistency Model is Secretly a More Powerful Supervised Learning Paradigm for Learning Tasks with Complex Labels", "link_suffix": "/forum?id=baONCWMQ0r", "link": "https://openreview.net/forum?id=baONCWMQ0r", "pdf_link": "https://openreview.net/pdf?id=baONCWMQ0r", "keywords": "Supervised Learning, Consistency Models", "abstract": "Directly predicting labels from data inputs has been a long-standing supervised learning paradigm. Its trade-off between compression and prediction is studied under the information theory framework e.g. Information Bottleneck, especially in the context of deep learning. It typically assumes that the information content of labels is significantly less than that of data inputs, leading to model designs that prioritize compressing and extracting features from data inputs. In fact, recent supervised learning increasingly faces predicting complex labels, exacerbating the challenge of learning mappings from compressed latent features to high-fidelity label representations. Predictive bottlenecks emerge not only from compression limitations but also from the inherent complexity of feature-to-label transformations. This paper shows that the learning paradigm of consistency models, which has garnered wide attention in the context of generative modeling, potentially represents a more powerful supervised learning framework for tasks with complex labels. Unlike traditional approaches predicting labels directly from inputs, in this paper, the training of our designed conditional consistency involves predicting labels using inputs and noise-perturbed label hints, pursuing the predictive consistency across different noise steps. It simultaneously learns the relationship between latent features and a spectrum of label information from zero to complete, which enables progressive learning for complex predictions and allows multi-step inference analogous to gradual denoising, thereby enhancing the prediction quality. Experiments on vision, text, and graph tasks show the superiority of our consistency supervised training paradigm, over conventional supervised training in complex label prediction problems. Source code will be made publicly available upon acceptance.", "title_embedding_index": 13912, "title_abs_embedding_index": 13937}, {"title": "Client2Vec: Improving Federated Learning by Distribution Shifts Aware Client Indexing", "link_suffix": "/forum?id=ON121aJV61", "link": "https://openreview.net/forum?id=ON121aJV61", "pdf_link": "https://openreview.net/pdf?id=ON121aJV61", "keywords": "Federated Leaning, Domain Index, Data Heterogeneity", "abstract": "Federated Learning (FL) is a privacy-preserving distributed machine learning paradigm. Nonetheless, the substantial distribution shifts among clients pose a considerable challenge to the performance of current FL algorithms. To mitigate this challenge, various methods have been proposed to enhance the FL training process.\nThis paper endeavors to tackle the issue of data heterogeneity from another perspective---by improving FL algorithms prior to the actual training stage. Specifically, we introduce the Client2Vec mechanism, which generates a unique client index for each client before the commencement of FL training. Subsequently, we leverage the generated client index to enhance the subsequent FL training process. To demonstrate the effectiveness of the proposed Client2Vec method, we conduct three case studies that assess the impact of the client index on the FL training process. These case studies encompass enhanced client sampling, model aggregation, and local training. Extensive experiments conducted on diverse datasets and model architectures show the efficacy of Client2Vec across all three case studies. Our code will be publicly available.", "title_embedding_index": 13913, "title_abs_embedding_index": 13938}, {"title": "ActionFiller: Fill-In-The-Blank Prompting for OS Agent", "link_suffix": "/forum?id=RVUWZ9SP1K", "link": "https://openreview.net/forum?id=RVUWZ9SP1K", "pdf_link": "https://openreview.net/pdf?id=RVUWZ9SP1K", "keywords": "Agent; Prompt", "abstract": "Many existing methods for operating system (OS) agents focus on predicting the next action based on the current state, which constructs a predefined task execution pipeline. While these methods demonstrate promising performance, reliance on state cognition modules like detector or recognizer could impede execution efficiency, particularly in long-horizon tasks with intricate action trajectories.Recognizing the remarkable accuracy of large language models (LLMs) in processing short instructions, this paper proposes the \\textbf{ActionFiller} framework. \nThe goal is to integrate easily executable short tasks into longer, cohesive tasks using fill-in-the-blank prompts, thereby minimizing redundant operations and enhancing efficiency. \nActionFiller employs two types of action-oriented fill-in-the-blank prompts: one designed for subtasks and another for specific actions. To generate subtask prompts, we introduce a Foresight Optimization Agent (FOA) that constructs an initial prompt by referencing past short tasks. It then fills in the unreferenced parts with detailed prompts generated by a planning agent, effectively retaining valuable past experiences. \nNext, an Action Template Agent (ATA) generates action prompts for each subtask. This process yields three distinct types of action prompts: 1) executable action sequences, 2) non-executable action sequences with prompt parameters, and 3) pure text descriptions. \nTo execute the action prompts effectively, we propose the CohesiveFlow method, which optimizes the second and third types of prompts by leveraging the cognitive state of the environment. Inspired by masked language modeling, the CohesiveFlow agent integrates the current environmental state with previously executed action sequences to update parameters and text descriptions, ensuring both feasibility and effectiveness in execution. \nTo validate the efficacy of our approach for long-horizon instructions, we introduce a new benchmark called \\textbf{EnduroSeq} and conduct experiments using the WinBench short instruction dataset. The results demonstrate that ActionFiller significantly enhances task completion rates and execution efficiency, offering a novel solution for the application of intelligent agents in complex environments.", "title_embedding_index": 13914, "title_abs_embedding_index": 13939}, {"title": "Fine-grained Hallucination Detection and Mitigation in Language Model Mathematical Reasoning", "link_suffix": "/forum?id=7bwE5MJAVJ", "link": "https://openreview.net/forum?id=7bwE5MJAVJ", "pdf_link": "https://openreview.net/pdf?id=7bwE5MJAVJ", "keywords": "Large Language Model, Process Reward Model, Data Augmentation", "abstract": "Hallucinations in large language models (LLMs) pose significant challenges in tasks requiring complex multi-step reasoning, such as mathematical problem-solving. Existing approaches primarily detect the presence of hallucinations but lack a nuanced understanding of their types and manifestations. In this paper, we first introduce a comprehensive taxonomy that categorizes the common hallucinations in mathematical reasoning task into six types: fabrication, factual inconsistency, context inconsistency, instruction inconsistency, logical inconsistency, and logical error. We then propose FG-PRM (Fine-Grained Process Reward Model), an augmented model designed to detect and mitigate hallucinations in a fine-grained, step-level manner. To address the limitations of manually labeling training data, we propose an automated method for generating fine-grained hallucination data using LLMs. By injecting hallucinations into reasoning steps of correct solutions, we create a diverse and balanced synthetic dataset for training FG-PRM, which consists of six specialized Process Reward Models (PRMs), each tailored to detect a specific hallucination type. Our FG-PRM demonstrates superior performance across two key tasks: 1) Fine-grained hallucination detection: classifying hallucination types for each reasoning step; and 2) Verification: ranking multiple LLM-generated outputs to select the most accurate solution, mitigating reasoning hallucinations. Our experiments show that FG-PRM outperforms ChatGPT-3.5 and Claude-3 on fine-grained hallucination detection and substantially boosts the performance of LLMs on GSM8K and MATH benchmarks.", "title_embedding_index": 13915, "title_abs_embedding_index": 13940}, {"title": "Towards Generalization under Topological Shifts: A Diffusion PDE Perspective", "link_suffix": "/forum?id=mFiGAbvmYS", "link": "https://openreview.net/forum?id=mFiGAbvmYS", "pdf_link": "https://openreview.net/pdf?id=mFiGAbvmYS", "keywords": "Topological Shifts, Diffusion Equations, Transformers", "abstract": "The capability of generalization is a cornerstone for the success of modern learning systems. For non-Euclidean data that particularly involves topological features, one important aspect neglected by prior studies is how learning-based models generalize under topological shifts. This paper makes steps towards understanding the generalization of graph neural networks operated on varying topologies through the lens of diffusion PDEs. Our analysis first reveals that the upper bound of the generalization error yielded by local diffusion equation models, which are intimately related to message passing over observed structures, would exponentially grow w.r.t. topological shifts. In contrast, extending the diffusion operator to a non-local counterpart that learns latent structures from data can in principle control the generalization error under topological shifts even when the model accommodates observed structures. On top of these results, we propose Advective Diffusion Transformer inspired by advective diffusion equations serving as a physics-inspired continuous model that synthesizes observed and latent structures for graph learning. The model demonstrates superiority in various downstream tasks across information networks, molecular screening and protein interactions.", "title_embedding_index": 13916, "title_abs_embedding_index": 13941}, {"title": "Enhancing Integrated Gradients Using Emphasis Factors and Attention for Effective Explainability of Large Language Models", "link_suffix": "/forum?id=IRvx66cxip", "link": "https://openreview.net/forum?id=IRvx66cxip", "pdf_link": "https://openreview.net/pdf?id=IRvx66cxip", "keywords": "XAI, Explainability, Integrated Gradients, Large Language Models, GPT", "abstract": "Understanding the decision-making processes of large language models (LLMs) is critical for ensuring transparency and trustworthiness. While Integrated Gradients (IG) is a popular method for model explainability, it faces limitations when applied to autoregressive models due to issues like exploding gradients and the neglect of the attention mechanisms. In this paper, we propose an enhanced explainability framework that augments IG with emphasis factors and attention mechanisms. By incorporating attention, we capture contextual dependencies between words, and the introduction of emphasis factors mitigates gradient issues encountered during attribution calculations. Our method provides more precise and interpretable explanations for autoregressive LLMs, effectively highlighting word-level contributions in text generation tasks. Experimental results demonstrate that our approach outperforms standard IG and baseline models in explaining word-level attributions, advancing the interpretability of LLMs.", "title_embedding_index": 13917, "title_abs_embedding_index": 13942}, {"title": "Wolf2Pack: The AutoFusion Framework for Dynamic Parameter Fusion", "link_suffix": "/forum?id=Daq6Pw3TjN", "link": "https://openreview.net/forum?id=Daq6Pw3TjN", "pdf_link": "https://openreview.net/pdf?id=Daq6Pw3TjN", "keywords": "Parameter Fusion, Multi-task Model Fusion, Computer Vision", "abstract": "In the rapidly evolving field of deep learning, specialized models have driven significant advancements in tasks such as computer vision and natural language processing.  However, this specialization leads to a fragmented ecosystem where models lack the adaptability for broader applications.  To overcome this, we introduce AutoFusion, an innovative framework that integrates distinct models into a unified architecture for multi-task learning without pre-trained checkpoints.  Using an unsupervised, end-to-end approach, AutoFusion dynamically blends model weights at each layer, optimizing the combination through a loss-minimization process that does not require labeled data.  We validate AutoFusion\u2019s effectiveness through experiments on commonly used benchmark datasets, demonstrating superior performance over established methods like Weight Interpolation, Git Re-Basin, and ZipIt.  Our framework offers a scalable and flexible solution for model integration, positioning it as a powerful tool for future research and practical applications.", "title_embedding_index": 13918, "title_abs_embedding_index": 13943}, {"title": "DisEnvisioner: Disentangled and Enriched Visual Prompt for Customized Image Generation", "link_suffix": "/forum?id=vQxqcVGrhR", "link": "https://openreview.net/forum?id=vQxqcVGrhR", "pdf_link": "https://openreview.net/pdf?id=vQxqcVGrhR", "keywords": "Visual Disentanglement and Enrichment, Zero-shot Customization, Text-to-Image Generation", "abstract": "In the realm of image generation, creating customized images from visual prompt with additional textual instruction emerges as a promising endeavor. However, existing methods, both tuning-based and tuning-free, struggle with interpreting the subject-essential attributes from the visual prompt. This leads to subject-irrelevant attributes infiltrating the generation process, ultimately compromising the personalization quality in both editability and ID preservation. In this paper, we present $\\textbf{DisEnvisioner}$, a novel approach for effectively extracting and enriching the subject-essential features while filtering out -irrelevant information, enabling exceptional customization performance, in a $\\textbf{tuning-free}$ manner and using only $\\textbf{a single image}$. Specifically, the feature of the subject and other irrelevant components are effectively separated into distinctive visual tokens, enabling a much more accurate customization. Aiming to further improving the ID consistency, we enrich the disentangled features, sculpting them into a more granular representation. Experiments demonstrate the superiority of our approach over existing methods in instruction response (editability), ID consistency, inference speed, and the overall image quality, highlighting the effectiveness and efficiency of DisEnvisioner.", "title_embedding_index": 13919, "title_abs_embedding_index": 13944}, {"title": "Reducing Task Discrepancy of text encoders for Zero-Shot Composed Image Retrieval", "link_suffix": "/forum?id=pOYa9nbwGr", "link": "https://openreview.net/forum?id=pOYa9nbwGr", "pdf_link": "https://openreview.net/pdf?id=pOYa9nbwGr", "keywords": "composed image retrieval; language only supervision; task discrepancy", "abstract": "Composed Image Retrieval (CIR) aims to retrieve a target image based on a reference image and conditioning text, enabling controllable image searches.\nDue to the expensive dataset construction cost for CIR triplets, a zero-shot (ZS) CIR setting has been actively studied to eliminate the need for human-collected triplet training datasets of the target domain.\nThe mainstream methods of ZS-CIR research typically employ a projection module that projects a CLIP image embedding to the CLIP text token embedding space while all encoders are fixed.\nUsing such a projected embedding, those methods then generate an image-text composed feature, which is used as a query for retrieval.\nHowever, we point out that using fixed CLIP encoders for ZS-CIR has an inherent limitation since there exists a significant task discrepancy between the original pre-training task of the encoders (text $\\leftrightarrow$ image) and the target CIR task (image + text $\\leftrightarrow$ image). To reduce such a discrepancy, a naive solution would be to train both image and text encoders with CIR triplets in a supervised manner. \nInstead, we introduce the Reducing Task Discrepancy of text encoders for Zero-Shot Composed Image Retrieval (RTD), an efficient post-precessing approach designed to enhance the capability of text encoders for ZS-CIR. Namely, we devise a novel target-anchored text contrastive learning, which solely updates the text encoder using cheap text triplets, consisting of reference and target texts instead of images. \nWe also introduce two enhancements to this approach: a refined batch sampling strategy and a sophisticated concatenation scheme.\nIntegrating RTD into existing projection-based ZS-CIR methods significantly improves performance across various datasets and backbones, achieving competitive or superior results compared to other resource-intensive state-of-the-art CIR methods beyond projection-based approaches.", "title_embedding_index": 13920, "title_abs_embedding_index": 13945}, {"title": "Interactions Exhibit Clustering Rhythm: A Prevalent Observation for Advancing Temporal Link Prediction", "link_suffix": "/forum?id=JZOPwrRYtI", "link": "https://openreview.net/forum?id=JZOPwrRYtI", "pdf_link": "https://openreview.net/pdf?id=JZOPwrRYtI", "keywords": "Link Prediction, Temporal Graphs, Data Mining", "abstract": "Temporal link prediction aims to forecast future link existence in temporal graphs, with numerous real-world applications. Existing methods often rely on designing complex model architectures to parameterize the interaction patterns between nodes. Instead, we re-think the interaction dynamics in temporal graphs (which we call ``interaction rhythms'') by addressing a fundamental research question: \\textit{Is there a strong yet prevalent latent interaction rhythm pattern across different temporal graphs that can be leveraged for temporal link prediction?} \nOur introduced empirical analyses reveal that there indeed exists temporal clustering in node interaction rhythms, where for a specific node, interactions tend to occur in bursts. Such observation leads to two key insights for predicting future links: (i) recent historical links that carry the latest rhythm pattern information; and (ii) the intervals between interactions that further illuminate temporal dynamics. \nBuilding on these empirical findings, we propose TG-Mixer, a novel method that explicitly captures temporal clustering patterns to advance temporal link prediction. \nTG-Mixer samples the most recent historical links to extract surrounding neighborhoods, preserving currently invaluable interaction rhythms while avoiding massive computations. \nAdditionally, it integrates a carefully designed silence decay mechanism that penalizes nodes' long-term inactivity, effectively incorporating temporal clustering information for future link prediction.\nBoth components ensure concise implementations, leading to a lightweight architecture. \nExhaustive experiments on seven benchmarks against nine baselines demonstrate that TG-Mixer achieves state-of-the-art performance with faster convergence, stronger generalization capabilities, and higher efficiency. The experimental results also highlight the importance of explicitly considering temporal clustering for temporal link prediction.", "title_embedding_index": 13921, "title_abs_embedding_index": 13946}, {"title": "Nearly Lossless Adaptive Bit Switching", "link_suffix": "/forum?id=sYGNCscE9M", "link": "https://openreview.net/forum?id=sYGNCscE9M", "pdf_link": "https://openreview.net/pdf?id=sYGNCscE9M", "keywords": "Deep neural networks, Multi-precision, Bit Switching, Model quantization", "abstract": "Model quantization is widely applied for compressing and accelerating deep neural networks (DNNs). However, conventional Quantization-Aware Training (QAT) focuses on training DNNs with uniform bit-width. The bit-width settings vary across different hardware and transmission demands, which induces considerable training and storage costs. Hence, the scheme of one-shot joint training multiple precisions is proposed to address this issue. Previous works either store a larger FP32 model to switch between different precision models for higher accuracy or store a smaller INT8 model but compromise accuracy due to using shared quantization parameters. In this paper, we introduce the Double Rounding quantization method, which fully utilizes the quantized representation range to accomplish nearly lossless bit-switching while reducing storage by using the highest integer precision instead of full precision. Furthermore, we observe a competitive interference among different precisions during one-shot joint training, primarily due to inconsistent gradients of quantization scales during backward propagation. To tackle this problem, we propose an Adaptive Learning Rate Scaling (ALRS) technique that dynamically adapts learning rates for various precisions to optimize the training process. Additionally, we extend our Double Rounding to one-shot mixed precision training and develop a Hessian-Aware Stochastic Bit-switching (HASB) strategy. Experimental results on the ImageNet-1K classification demonstrate that our methods have enough advantages to state-of-the-art one-shot joint QAT in both multi-precision and mixed-precision. Our codes are available athttps://anonymous.4open.science/r/Double-Rounding-EF78/README.md.", "title_embedding_index": 13922, "title_abs_embedding_index": 13947}, {"title": "Corrective Retrieval Augmented Generation", "link_suffix": "/forum?id=JnWJbrnaUE", "link": "https://openreview.net/forum?id=JnWJbrnaUE", "pdf_link": "https://openreview.net/pdf?id=JnWJbrnaUE", "keywords": "Retrieval-Augmented Generation, Corrective Retrieval, Robustness of Generation", "abstract": "Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong. To this end, we propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation. Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered. Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results. Besides, a decompose-then-recompose algorithm is designed for retrieved documents to selectively focus on key information and filter out irrelevant information in them. CRAG is plug-and-play and can be seamlessly coupled with various RAG-based approaches. Experiments on four datasets covering short- and long-form generation tasks show that CRAG can significantly improve the performance of RAG-based approaches.", "title_embedding_index": 13923, "title_abs_embedding_index": 13948}, {"title": "GeoRDe: Tertiary Structure-based RNA Design With Multiple Geometric Constraint", "link_suffix": "/forum?id=doBof19Ia4", "link": "https://openreview.net/forum?id=doBof19Ia4", "pdf_link": "https://openreview.net/pdf?id=doBof19Ia4", "keywords": "RNA design, RNA Inverse Folding, Computational biology", "abstract": "Functional RNA sequence design plays an essential role in the regulation of life processes. The RNA inverse folding problem, which involves designing nucleic acid sequences based on their three-dimensional structures, remains highly challenging. This complexity arises not only from the inherent flexibility of RNA structures but also from the base-pairing rules that impose critical spatial constraints on the RNA scaffold. In recent times, the design of RNA has often depended on geometric graph networks to design sequences. Motivated by recent advancements in protein design, we have developed the RNAformer module. This module is capable of learning the geometric constraints of RNA molecules in cooperation with geometric graph networks. Furthermore, to enhance the specificity of sequence generation, we have integrated secondary structure information as labels, ensuring that the designed sequences align more closely with secondary structure constraints. Additionally, we have used RNA language models to understand average evolutionary constraints. By incorporating a range of constraint insights, GeoRDe has demonstrated superior performance under identical training data conditions and has also showcased generalization capabilities on the independent casp15 and RNA-puzzle datasets. Through extensive experimentation, the GeoRDe has proven to be an innovative solution to the challenges of RNA design.", "title_embedding_index": 13924, "title_abs_embedding_index": 13949}]
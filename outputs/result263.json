[
    {
        "title": "Exploring the Trade-Off between Model Complexity and Numerical Precision for Efficient Edge AI Inference",
        "link_suffix": "/forum?id=NLfWQfy5zp",
        "link": "https://openreview.net/forum?id=NLfWQfy5zp",
        "pdf_link": "https://openreview.net/pdf?id=NLfWQfy5zp",
        "keywords": "Neural networks, Edge AI, Artificial Intelligence, Model compression",
        "abstract": "When considering the compression of neural networks, the adoption of low-bit representations for both parameters and activations has demonstrated significant efficacy. The process of learning quantized weights through Quantization Aware Training (QAT) stands out as a powerful means to substantially diminish the memory requirements for a specific model to efficiently perform inference. However, despite the numerous works reporting the gains achieved using QAT, a comparison with a notably simpler technique - reducing the model's complexity using fewer parameters - is often absent.\n    In this paper, we attemp to answer a seemingly simple question: to reduce a given model's storage requirements, is it better to reduce the number of parameters in the model or to reduce the numerical precision? We explore the trade-off between the dimensionality of parameters and activations one can afford to keep in memory, and the numerical precision used to represent them. Through our experiments in image classification, keyword spotting and language modelling, our results suggest that quantizing weights to $2$ bits and keeping a high number of parameters seems optimal, regardless of the task considered and model architecture."
    },
    {
        "title": "SceneLock: Reversible Adversarial Learning for Camera-Based Autonomous Driving Protection",
        "link_suffix": "/forum?id=ZdHa3y0DeB",
        "link": "https://openreview.net/forum?id=ZdHa3y0DeB",
        "pdf_link": "https://openreview.net/pdf?id=ZdHa3y0DeB",
        "keywords": "Data Protection, Autonomous Driving, Camera-Based 3D Perception",
        "abstract": "The advancement of autonomous driving technology hinges on large-scale data collection to train camera-based deep neural network 3D object detectors.\nHowever, these valuable datasets are at risk of unauthorized access and misuse by malicious actors, jeopardizing intellectual property, remote deployment, and the privacy of sensitive information captured during data collection. \nWe propose a novel reversible adversarial learning framework, referred to as SceneLock, aimed at protecting autonomous driving data from unauthorized use. \nOur method conducts adversarial perturbations through a carefully designed Noise Serialization Encoding module (NSE), which significantly degrades image quality and renders the data ineffective for unauthorized artificial intelligence models and manual annotation. \nTo ensure legitimate access remains unaffected, we integrate advanced image steganography to embed perturbation values within the images. \nFurthermore, authorized users can extract these values using appropriate decryption tools through the Noise Serialization Decoding module (NSD) to restore the original high-quality images. \nExperimental results demonstrate that our approach effectively safeguards data integrity against unauthorized use while maintaining availability for legitimate purposes. \nThis dual-layer protection highlights the potential of our method to enhance data security in the autonomous driving domain."
    },
    {
        "title": "TAEGAN: Generating Synthetic Tabular Data for Data Augmentation",
        "link_suffix": "/forum?id=pBqOH2g6K1",
        "link": "https://openreview.net/forum?id=pBqOH2g6K1",
        "pdf_link": "https://openreview.net/pdf?id=pBqOH2g6K1",
        "keywords": "GAN, synthetic tabular data, data augmentation",
        "abstract": "Synthetic tabular data generation has gained significant attention for its potential in data augmentation, software testing and privacy-preserving data sharing. However, most research has primarily focused on larger datasets and evaluating their quality in terms of metrics like column-wise statistical distributions and inter-feature correlations, while often overlooking its utility for data augmentation,  particularly for datasets whose data is scarce. In this paper, we propose Tabular Auto-Encoder Generative Adversarial Network (TAEGAN), an improved GAN-based framework for generating high-quality tabular data. Although large language models (LLMs)-based methods represent the state-of-the-art in synthetic tabular data generation, they are often overkill for small datasets due to their extensive size and complexity. TAEGAN employs a masked auto-encoder as the generator, which for the first time introduces the power of self-supervised pre-training in tabular data generation so that essentially exposes the networks to more information. We extensively evaluate TAEGAN against five state-of-the-art synthetic tabular data generation algorithms. Results from 10 datasets show that TAEGAN outperforms existing deep-learning-based tabular data generation models on 9 out of 10 datasets on the machine learning efficacy and achieves superior data augmentation performance on 7 out of 8 smaller datasets. Code is available at:https://anonymous.4open.science/r/taegan-2AB4"
    },
    {
        "title": "The Wisdom of a Crowd of Brains: A Universal Brain Encoder",
        "link_suffix": "/forum?id=xHGL9XqR8Y",
        "link": "https://openreview.net/forum?id=xHGL9XqR8Y",
        "pdf_link": "https://openreview.net/pdf?id=xHGL9XqR8Y",
        "keywords": "Image-to-fMRI encoding, Explore the brain using ML, Brain-Image cross-attention, Visual Perception, Brain Mapping, Neuroscience, Computer Vision",
        "abstract": "Image-to-fMRI encoding is important for both neuroscience research and practical applications. However, such \u201cBrain-Encoders\u201d have been typically trained per-subject and per fMRI-dataset, thus restricted to very limited training data. In this paper we propose a Universal Brain-Encoder, which can be trained jointly on data from many different subjects/datasets/machines. What makes this possible is our new voxel-centric Encoder architecture, which learns a unique \u201cvoxel-embedding\u201d per brain-voxel. Our Encoder trains to predict the response of each brain-voxel on every image, by directly computing the cross-attention between the brain-voxel embedding and multi-level deep image features. This voxel-centric architecture allows the functional role of each brain-voxel to naturally emerge from\nthe voxel-image cross-attention. We show the power of this approach to: (i) combine data from multiple different subjects (a \u201cCrowd of Brains\u201d) to improve each individual brain-encoding, (ii) quick & effective Transfer-Learning across sub- jects, datasets, and machines (e.g., 3-Tesla, 7-Tesla), with few training examples, and (iii) we show the potential power of the learned voxel-embeddings to explore brain functionality (e.g., what is encoded where in the brain)."
    },
    {
        "title": "Embodied Instruction Following in Unknown Environments",
        "link_suffix": "/forum?id=pwKokorglv",
        "link": "https://openreview.net/forum?id=pwKokorglv",
        "pdf_link": "https://openreview.net/pdf?id=pwKokorglv",
        "keywords": "Embodied instruction following, multi-modal large language model, embodied robotic",
        "abstract": "Enabling embodied agents to complete complex human instructions from natural language is crucial to autonomous systems in household services. Conventional methods can only accomplish human instructions in the known environment where all interactive objects are provided to the embodied agent, and directly deploying the existing approaches for the unknown environment usually generates infeasible plans that manipulate non-existing objects. On the contrary, we propose an embodied instruction following (EIF) method for complex tasks in the unknown environment, where the agent efficiently explores the unknown environment to generate feasible plans with existing objects to accomplish abstract instructions. Specifically, we build a hierarchical embodied instruction following framework including the high-level task planner and the low-level exploration controller with multimodal large language models. We then construct a semantic representation map of the scene with dynamic region attention to demonstrate the known visual clues, where the goal of task planning and scene exploration is aligned for human instruction. For the task planner, we generate the feasible step-by-step plans for human goal accomplishment according to the task completion process and the known visual clues. For the exploration controller, the optimal navigation or object interaction policy is predicted based on the generated step-wise plans and the known visual clues. \nThe experimental results demonstrate that our method can achieve 45.09% success rate in 204 complex human instructions such as making breakfast and tidying rooms in large house-level scenes."
    },
    {
        "title": "A Closer Look at Machine Unlearning for Large Language Models",
        "link_suffix": "/forum?id=Q1MHvGmhyT",
        "link": "https://openreview.net/forum?id=Q1MHvGmhyT",
        "pdf_link": "https://openreview.net/pdf?id=Q1MHvGmhyT",
        "keywords": "Machine Unlearning, Large Language Models",
        "abstract": "Large language models (LLMs) may memorize sensitive or copyrighted content, raising privacy and legal concerns. Due to the high cost of retraining from scratch, researchers attempt to employ machine unlearning to remove specific content from LLMs while preserving the overall performance. In this paper, we discuss several issues in machine unlearning for LLMs and provide our insights on possible approaches. To address the issue of inadequate evaluation of model outputs after unlearning, we introduce three additional metrics to evaluate token diversity, sentence semantics, and factual correctness. We then categorize unlearning methods into untargeted and targeted, and discuss their issues respectively. Specifically, the behavior that untargeted unlearning attempts to approximate is unpredictable and may involve hallucinations, and existing regularization is insufficient for targeted unlearning. To alleviate these issues, we propose using the objective of maximizing entropy (ME) for untargeted unlearning and incorporate answer preservation (AP) loss as regularization for targeted unlearning. Experimental results across three scenarios, i.e., fictitious unlearning, continual unlearning, and real-world unlearning, demonstrate the effectiveness of our approaches."
    },
    {
        "title": "The Normalized Float Trick: Numerical Stability for Probabilistic Circuits without the LogSumExp Trick",
        "link_suffix": "/forum?id=r8C9nt0nlc",
        "link": "https://openreview.net/forum?id=r8C9nt0nlc",
        "pdf_link": "https://openreview.net/pdf?id=r8C9nt0nlc",
        "keywords": "probabilistic circuits, tractable probabilistic models",
        "abstract": "Probabilistic circuits (PCs) are a class of tractable deep probabilistic models that compute event probabilities by recursively nesting sum and product computations. Unfortunately, this is numerically unstable. To mitigate this numerical stability issues, PCs are usually evaluated in log-space via the LogSumExp trick. In this paper we present an alternative to the ubiquitous LogSumExp trick, which we dub \"normalized float trick\". Experimentally, we show that by simply changing the scheme guaranteeing numerical stability (from the LogSumExp to the normalized float trick) we can consistently and considerably boost the performance of PCs on common density estimation benchmarks,"
    },
    {
        "title": "Sparse Spectral Training and Inference on Euclidean and Hyperbolic Neural Networks",
        "link_suffix": "/forum?id=bo36dzafRN",
        "link": "https://openreview.net/forum?id=bo36dzafRN",
        "pdf_link": "https://openreview.net/pdf?id=bo36dzafRN",
        "keywords": "Efficient AI, Parameter-efficient training, Pre-training, Hyperbolic Network",
        "abstract": "The growing demands on GPU memory posed by the increasing number of neural network parameters call for training approaches that are more memory-efficient. Previous memory reduction training techniques, such as Low-Rank Adaptation (LoRA) and ReLoRA, face challenges, with LoRA being constrained by its low-rank structure, particularly during intensive tasks like pre-training, and ReLoRA suffering from saddle point issues. In this paper, we propose Sparse Spectral Training (SST) to optimize memory usage for pre-training. SST updates all singular values and selectively updates singular vectors through a multinomial sampling method weighted by the magnitude of the singular values. Furthermore, SST employs singular value decomposition to initialize and periodically reinitialize low-rank parameters, reducing distortion relative to full-rank training compared to other low-rank methods. Through comprehensive testing on both Euclidean and hyperbolic neural networks across various tasks, including natural language generation, machine translation, node classification, link prediction, and image classification, SST demonstrates its ability to outperform existing memory reduction training methods and is comparable to full-rank training in various cases. On OPT-1.3B, with only 12.5% of the parameters trainable compared to full-rank training (using a rank equivalent to 3% of the embedding dimension), SST reduces the perplexity gap between other low-rank methods and full-rank training by 50%. This result highlights SST as an effective parameter-efficient technique for model pre-training, offering a promising new paradigm for achieving scalable and memory-efficient neural network training. Our code is available at \\url{https://anonymous.4open.science/r/sparse_spectral_training-6A2C/}."
    },
    {
        "title": "Weighted-Reward Preference Optimization for Implicit Model Fusion",
        "link_suffix": "/forum?id=fq24pEb8SL",
        "link": "https://openreview.net/forum?id=fq24pEb8SL",
        "pdf_link": "https://openreview.net/pdf?id=fq24pEb8SL",
        "keywords": "Model Fusion, Preference Optimization, Large Language Models",
        "abstract": "While fusing heterogeneous open-source LLMs with varying architectures and sizes can potentially integrate the strengths of different models, existing fusion methods face significant challenges, such as vocabulary alignment and merging distribution matrices. These procedures are not only complex but also prone to introducing noise and errors. In this paper, we propose an implicit fusion method, Weighted-Reward Preference Optimization (WRPO), which leverages preference optimization between the source LLMs and the target LLM to transfer their capabilities effectively. WRPO eliminates the need for vocabulary alignment and matrix fusion and can be efficiently scaled to accommodate various LLMs. To address distributional deviations between the source and target LLMs, WRPO introduces a progressive adaptation strategy that gradually shifts reliance on preferred examples from the target LLM to the source LLMs. Extensive experiments on the MT-Bench, AlpacaEval-2, and Arena-Hard benchmarks demonstrate that WRPO consistently outperforms existing knowledge fusion methods and various fine-tuning baselines. When applied to LLaMA3-8B-Instruct as the target model, WRPO achieves a length-controlled win rate of 55.9% against GPT-4-Preview-1106 on AlpacaEval-2, establishing it as the top-performing 8B model on the leaderboard."
    },
    {
        "title": "Architecturally Aligned Comparisons Between ConvNets And Vision Mambas",
        "link_suffix": "/forum?id=QBiFoWQp3n",
        "link": "https://openreview.net/forum?id=QBiFoWQp3n",
        "pdf_link": "https://openreview.net/pdf?id=QBiFoWQp3n",
        "keywords": "Architecturally aligned comparisons, Vision Mambas, ConvNets, Vision Transformers",
        "abstract": "Mamba, an architecture with token mixers of state space models (SSM), has been recently introduced to vision tasks to tackle the quadratic complexity of self-attention. However, since SSM's memory is inherently lossy and precedent vision mambas struggle to compete with advanced ConvNets or ViTs, it is unclear whether Mamba has contributed new advances to vision. In this work, we carefully align the macro architecture to facilitate direct comparisons of token mixers which are the core contribution of Mamba. Specifically, we construct a series of Gated ConvNets (GConvNets) and compare VMamba's token mixers with gated 7$\\times$7 depth-wise convolutions. The empirical results clearly demonstrate the superiority of VMamba's token mixers in both image classification and object detection tasks. Therefore, it is not useless to introduce SSM for image classification on ImageNet. Furthermore, we compare two types of token mixers within hybrid architectures that incorporate a few self-attention layers in the top blocks. The results demonstrate that both VMambas and GConvNets benefit from incorporating self-attention and we still need Mamba in this case. Interestingly, we find that incorporating self-attention layers has opposite effects on them, mitigating the over-fitting in VMambas while enhancing the fitting ability of GConvNets. Finally, we assess natural robustness of pure and hybrid models in image classification, revealing stronger robustness of VMambas and hybrid models. Our work provides credible evidence for the necessity of introducing Mamba to vision and shows the significance of architecturally aligned comparisons for evaluating different token mixers in sophisticated hierarchical models."
    },
    {
        "title": "Variance Reduced Distributed Non-Convex Optimization Using Matrix Stepsizes",
        "link_suffix": "/forum?id=M5u38Os65F",
        "link": "https://openreview.net/forum?id=M5u38Os65F",
        "pdf_link": "https://openreview.net/pdf?id=M5u38Os65F",
        "keywords": "Federated Learning, Non-Convex Optimization, Optimization",
        "abstract": "Matrix-stepsized gradient descent algorithms have been shown to have superior performance in non-convex optimization problems compared to their scalar counterparts. The det-CGD algorithm, as introduced by Li et al. (2023), leverages matrix stepsizes to perform compressed gradient descent for non-convex objectives and matrix smooth problems in a federated manner. The authors establish the algorithm\u2019s convergence to a neighborhood of a weighted stationarity point under a convex condition for the symmetric and positive-definite matrix stepsize. In this paper, we propose two variance-reduced versions of the det-CGD algorithm, incorporating MARINA and DASHA methods. Notably, we establish theoretically and empirically, that det-MARINA and det-DASHA outperform MARINA, DASHA and the distributed det-CGD algorithms in terms of iteration and communication complexities."
    },
    {
        "title": "TextSquare: Scaling up Text-Centric Visual Instruction Tuning",
        "link_suffix": "/forum?id=a1adEtVoHS",
        "link": "https://openreview.net/forum?id=a1adEtVoHS",
        "pdf_link": "https://openreview.net/pdf?id=a1adEtVoHS",
        "keywords": "Text-Centric Multimodal Large Language Model, Visual Instruction Tuning, Scaling Relationship",
        "abstract": "Text-centric visual question answering (VQA) has made great strides with the development of Multimodal Large Language Models (MLLMs), yet open-source models still fall short of leading models like GPT4V and Gemini. A key contributing factor to this disparity is the absence of extensive, high-quality instruction tuning data. To this end, we introduce a new approach for creating a massive, high-quality instruction-tuning dataset, Square-10M, generated by leveraging the versatile multimodal capabilities of closed-source MLLMs. The data construction process, termed Square, consists of four steps: Self-Questioning, Answering, Reasoning, and Evaluation. Our experiments with Square-10M led to three key findings: 1) Our model, TextSquare, considerably surpasses open-source previous state-of-the-art text-centric MLLMs and sets a new standard on OCRBench (62.2%). It even outperforms top-tier models like GPT4V and Gemini on six out of ten text-centric benchmarks. 2) We demonstrate the importance of VQA reasoning data in offering comprehensive contextual insights for specific questions, which not only improves accuracy but also substantially mitigates hallucinations. Specifically, TextSquare scores an average of 75.1% across four general VQA and hallucination evaluation datasets, outperforming previous state-of-the-art models. 3) Notably, the phenomenon observed in scaling text-centric VQA datasets reveals a vivid pattern: an exponential increase of instruction tuning data volume is directly proportional to the improvement in model performance, thereby validating the necessity of the dataset scale and the high quality of Square-10M."
    },
    {
        "title": "GraphIC: A Graph-Based In-Context Example Retrieval Model for Multi-Step Reasoning",
        "link_suffix": "/forum?id=zpLcZ2AyDK",
        "link": "https://openreview.net/forum?id=zpLcZ2AyDK",
        "pdf_link": "https://openreview.net/pdf?id=zpLcZ2AyDK",
        "keywords": "In-context learning, multi-step reasoning, thought graphs, large language model",
        "abstract": "In-context learning (ICL) enables large language models (LLMs) to generalize to new tasks by incorporating a few in-context examples (ICEs) directly in the input, without updating parameters. However, the effectiveness of ICL heavily relies on the selection of ICEs, and conventional text-based embedding methods are often inadequate for tasks that require multi-step reasoning, such as mathematical and logical problem solving. This is due to the bias introduced by shallow semantic similarities that fail to capture the deeper reasoning structures required for these tasks. We present GraphIC, a novel approach that leverages graph-based representations of reasoning processes, coupled with Bayesian Networks (BNs) to select ICEs. Graph structures inherently filter out shallow semantics while preserving the core reasoning structure. Importantly, BNs capture the dependency of a node\u2019s attributes on its parent nodes, closely mirroring the hierarchical nature of human cognition\u2014where each thought is shaped by preceding ones. This makes BNs particularly well-suited for multi-step reasoning tasks, aligning the process more closely with human-like reasoning. Extensive experiments across three types of reasoning tasks (mathematical reasoning, code generation, and logical reasoning) demonstrate that GraphIC outperforms both training-free and training-based models in selecting ICEs, excelling in terms of both effectiveness and efficiency. We show that GraphIC enhances ICL\u2019s performance and interpretability, significantly advancing ICE selection for multi-step reasoning tasks."
    },
    {
        "title": "Revisit Self-Debugging with Self-Generated Tests for Code Generation",
        "link_suffix": "/forum?id=hYd6BCZTzg",
        "link": "https://openreview.net/forum?id=hYd6BCZTzg",
        "pdf_link": "https://openreview.net/pdf?id=hYd6BCZTzg",
        "keywords": "self-debugging, code generation, code reasoning, large language models",
        "abstract": "Large language models (LLMs) have shown significant advancements in code generation, but still face challenges on tasks beyond their basic capabilities. Recently, the notion of self-debugging has been proposed to boost the performance of code generation by leveraging execution feedback from tests. Despite its promise, the availability of high-quality tests in real-world scenarios is limited. In this context, self-debugging with self-generated tests is a promising solution but lacks a full exploration of its limitations and practical potential. Therefore, we investigate its efficacy on diverse programming problems. To deepen our understanding, we propose two distinct paradigms for the process: post-execution and in-execution self-debugging. Within the scope of self-contained Python programming tasks, we find that post-execution self-debugging struggles on basic problems but shows potential for improvement on competitive ones, due to the bias introduced by evaluation on self-generated tests. On the other hand, in-execution self-debugging enables LLMs to mitigate the bias by solely leveraging intermediate states during execution, thereby enhancing code generation."
    },
    {
        "title": "LoRA-Gen: Specializing Language Model via Online LoRA Generation",
        "link_suffix": "/forum?id=A54D58egNR",
        "link": "https://openreview.net/forum?id=A54D58egNR",
        "pdf_link": "https://openreview.net/pdf?id=A54D58egNR",
        "keywords": "Parameter Efficient Fine-tuning, Multimodality, Low-Rank Adaptation",
        "abstract": "Recent advances have highlighted the benefits of scaling language models to enhance performance across a wide range of NLP tasks. However, these approaches still face limitations in effectiveness and efficiency when applied to domain-specific tasks, particularly for small edge-side models.\nWe propose the LoRA-Gen framework, which utilizes a large cloud-side model to generate LoRA parameters for edge-side models based on task descriptions.\nBy employing the reparameterization technique, we merge the LoRA parameters into the edge-side model to achieve flexible specialization.\nOur method facilitates knowledge transfer between models while significantly improving the inference efficiency of the specialized model by reducing the input context length.\nExtensive experiments show that LoRA-Gen outperforms the conventional LoRA fine-tuning, which achieves competitive accuracy and a 2.1x speedup with TinyLLaMA-1.1B on common-sense reasoning tasks.\nBesides, our method delivers a compress ratio of 10.1x with Gemma-2B on intelligent agent tasks."
    },
    {
        "title": "Target-Oriented Soft-Robust Inverse Reinforcement Learning",
        "link_suffix": "/forum?id=TopFr8GeZy",
        "link": "https://openreview.net/forum?id=TopFr8GeZy",
        "pdf_link": "https://openreview.net/pdf?id=TopFr8GeZy",
        "keywords": "Imitation Learning, Inverse Reinforcement Learning, Soft-Robust Optimization, Robust Optimization, Optimization Algorithm",
        "abstract": "In imitation learning, when the learning agent is at a state that is outside the demonstration of the expert, it could be difficult for her to choose an action. To overcome this challenge, inverse reinforcement learning (IRL) learns a parameterized reward function based on which we can generalize the expert's behavior to those states that are unseen in the demonstration. However, on the one hand, there could be multiple reward functions that can explain the expert's behavior, leading to reward ambiguity in IRL. On the other hand, though we often consider the transition kernel of the expert to be known to the agent, sometimes the transition kernel of the agent is different from the expert's and is unknown, leading to transition kernel ambiguity in IRL. Drawing on the notion of soft-robust optimization, we build a target-oriented soft-robust IRL (SRIRL) model where the performance of the output policy strikes a flexible balance between risk aversion and expected return maximization towards reward uncertainty in IRL. Moreover, by employing the robust satisficing framework, our SRIRL is also robust to transition kernel ambiguity in IRL. In our target-oriented SRIRL, we keep a target for the performance of the output policy that balances expected return and risk, and we minimize the constraint violation incurred by the difference between the ambiguous transition kernel and the empirical one. We derive tractable reformulation for SRIRL, and we design tailored first-order methods for SRIRL. Numerical results showcase the soft robustness towards reward uncertainty and the robustness against transition kernel ambiguity of SRIRL, as well as the stronger scalability of our first-order methods compared to a state-of-the-art commercial solver."
    },
    {
        "title": "Unified Parameter-Efficient Unlearning for LLMs",
        "link_suffix": "/forum?id=zONMuIVCAT",
        "link": "https://openreview.net/forum?id=zONMuIVCAT",
        "pdf_link": "https://openreview.net/pdf?id=zONMuIVCAT",
        "keywords": "Large Language Model Unlearning; Machine Unlearning; Influence Function",
        "abstract": "The advent of Large Language Models (LLMs) has revolutionized natural language processing, enabling advanced understanding and reasoning capabilities across a variety of tasks. Fine-tuning these models for specific domains, particularly through Parameter-Efficient Fine-Tuning (PEFT) strategies like LoRA, has become a prevalent practice due to its efficiency. However, this raises significant privacy and security concerns, as models may inadvertently retain and disseminate sensitive or undesirable information. To address these issues, we introduce a novel instance-wise unlearning framework, LLMEraser, which systematically categorizes unlearning tasks and applies precise parameter adjustments using influence functions. Unlike traditional unlearning techniques that are often limited in scope and require extensive retraining, LLMEraser is designed to handle a broad spectrum of unlearning tasks without compromising model performance. Extensive experiments on benchmark datasets demonstrate that LLMEraser excels in efficiently managing various unlearning scenarios while maintaining the overall integrity and efficacy of the models."
    },
    {
        "title": "Optimization-Biased Hypernetworks for Generalizable Policy Generation",
        "link_suffix": "/forum?id=CJWMXqAnAy",
        "link": "https://openreview.net/forum?id=CJWMXqAnAy",
        "pdf_link": "https://openreview.net/pdf?id=CJWMXqAnAy",
        "keywords": "hypernetwork, policy generation, behavior cloning",
        "abstract": "Policy learning through behavior cloning poses significant challenges, particularly when demonstration data is limited. In this work, we present HyPoGen, a novel optimization-biased hypernetwork structure for policy generation. The proposed hypernetwork learns to synthesize optimal policy parameters solely from task specifications, by modeling policy generation as an approximation of the optimization process executed over a finite number of steps and assuming these specifications serve as a sufficient representation of the demonstration data. By incorporating structural designs that bias the hypernetwork towards optimization, we can improve its generalization capability while being trained only on source task demonstrations. During the feed-forward prediction pass, the hypernetwork effectively performs an optimization in the latent (compressed) policy space, which is then decoded into policy parameters for action prediction. Experimental results on locomotion and manipulation benchmarks show that HyPoGen significantly outperforms state-of-the-art methods in generating policies for unseen target tasks without any demonstrations, achieving higher success rates and evidencing improved generalizable policy generation capability. Our work underscores the potential of optimization-biased hypernetworks in advancing generalizable policy generation. Our code and models will be made available."
    },
    {
        "title": "Wavelet-based Graph Convolution via Chebyshev Decomposition",
        "link_suffix": "/forum?id=i2yxXoAekh",
        "link": "https://openreview.net/forum?id=i2yxXoAekh",
        "pdf_link": "https://openreview.net/pdf?id=i2yxXoAekh",
        "keywords": "graph neural network, graph wavelet, graph signal processing",
        "abstract": "Spectral graph convolution, an important tool of data filtering on graphs, relies on two essential decisions: selecting spectral bases for signal transformation and parameterizing the kernel for frequency analysis. While recent techniques mainly focus on standard Fourier transform and vector-valued spectral functions, they fall short in flexibility to model signal distributions over diverse spatial ranges, and capacity of spectral function.\nIn this paper, we present a novel wavelet-based graph convolution network, namely WaveGC, which integrates multi-resolution spectral bases and a matrix-valued filter kernel. Theoretically, we establish that WaveGC can effectively capture and decouple short-range and long-range information, providing superior filtering flexibility, surpassing existing graph convolutional networks and graph Transformers (GTs). \nTo instantiate WaveGC, we introduce a novel technique for learning general graph wavelets by separately combining odd and even terms of Chebyshev polynomials. This approach strictly satisfies wavelet  admissibility criteria. Our numerical experiments showcase the capabilities of the new network. By replacing the Transformer part in existing architectures with WaveGC, we consistently observe improvements in both short-range and long-range tasks. This underscores the effectiveness of the proposed model in handling different scenarios.  Our code is available athttps://anonymous.4open.science/r/WaveGC"
    },
    {
        "title": "OpenWaves: A Large-Scale Anatomically Realistic Ultrasound-CT Dataset for Benchmarking Neural Wave Equation Solvers",
        "link_suffix": "/forum?id=u14Y236LwX",
        "link": "https://openreview.net/forum?id=u14Y236LwX",
        "pdf_link": "https://openreview.net/pdf?id=u14Y236LwX",
        "keywords": "Computational imaging, Inverse problem, Neural operators, Ultrasound Computed Tomography, Full Waveform Inversion",
        "abstract": "Accurate and efficient simulation of wave equations is crucial in computational physics, especially for wave imaging applications like ultrasound computed tomography (USCT), which reconstructs tissue properties from scattered waves. Traditional numerical solvers for wave equations are computationally intensive and often unstable, limiting their practical applications for quasi-real-time imaging. Neural operators offer an innovative approach by accelerating PDE solving using neural networks; however, their effectiveness in realistic imaging is constrained by existing datasets that oversimplify real-world complexity. In this paper, we present OpenWaves, a large-scale wave equation dataset designed to bridge the gap between theoretical equations and practical imaging applications. OpenWaves provides over 16 million frequency-domain wave simulations using real USCT configurations, featuring anatomically realistic human breast phantoms across four categories. It enables comprehensive benchmarking of popular neural operators for both forward simulation and inverse imaging tasks, allowing analysis of their performance, scalability, and generalization capabilities. By offering a realistic and extensive dataset, OpenWaves not only serves as a platform for developing innovative neural PDE solvers but also facilitates their deployment in real-world medical imaging problems."
    },
    {
        "title": "Conformalized Survival Analysis for General Right-Censored Data",
        "link_suffix": "/forum?id=JQtuCumAFD",
        "link": "https://openreview.net/forum?id=JQtuCumAFD",
        "pdf_link": "https://openreview.net/pdf?id=JQtuCumAFD",
        "keywords": "conformal prediction, survival analysis, PAC, covariate shift, uncertainty quantification",
        "abstract": "We develop a framework to quantify predictive uncertainty in survival analysis, providing a reliable lower predictive bound (LPB) for the true, unknown patient survival time. Recently, conformal prediction has been used to construct such valid LPBs fortype-I right-censored data, with the guarantee that the bound holds with high probability. Crucially, under the type-I setting, the censoring time is observed for all data points. As such, informative LPBs can be constructed by framing the calibration as an estimation task with covariate shift, relying on the conditionally independent censoring assumption. This paper expands the conformal toolbox for survival analysis, with the goal of handling the ubiquitousgeneral right-censored setting, in which either the censoring or survival time is observed, but not both. The key challenge here is that the calibration cannot be directly formulated as a covariate shift problem anymore. Yet, we show how to construct LPBs with distribution-free finite-sample guarantees, under the same assumptions as conformal approaches for type-I censored data. Experiments demonstrate the informativeness and validity of our methods in simulated settings and showcase their practical utility on multi-modal breast cancer data."
    },
    {
        "title": "ATTENDING: Federated Learning with Personalized Attentive Pruning for Heterogeneous Clients",
        "link_suffix": "/forum?id=N0U6OQRsNu",
        "link": "https://openreview.net/forum?id=N0U6OQRsNu",
        "pdf_link": "https://openreview.net/pdf?id=N0U6OQRsNu",
        "keywords": "Federated Learning, Attentive Pruning, Heterogeneous Clients, Non-IID Data.",
        "abstract": "Federated Learning (FL) emerges as a novel machine learning paradigm, enabling distributed clients to collaboratively train a global model while eliminating local data transmission.  Despite its advantages, FL faces challenges posed by system and data heterogeneity. System heterogeneity prevents low-end clients from participating in FL with uniform models, while data heterogeneity adversely impacts the learning performance of FL. In this paper, we propose the personalized ATTENtive pruning enabled federateD learnING (ATTENDING) to collectively address these heterogeneity challenges. Specifically, we first design an attention module incorporating spatial and channel attention to enhance the learning performance on heterogeneous data. Subsequently, we introduce the attentive pruning algorithm to generate personalized local models guided by attention scores, aiming to facilitate clients' participation in FL. Finally, we introduce a specific heterogeneous aggregation algorithm integrated with an attention matching mechanism to efficiently aggregate the pruned models. We implement ATTENDING with a real FL platform and the evaluation results show that ATTENDING significantly outperforms the baselines by up to 11.3% and reduces the average model footprints by 32%. Our code is available at:https://anonymous.4open.science/r/ATTENDING."
    },
    {
        "title": "Physical Backdoor Attack can Jeopardize Driving with Vision-Large-Language Models",
        "link_suffix": "/forum?id=5f3brwjeTl",
        "link": "https://openreview.net/forum?id=5f3brwjeTl",
        "pdf_link": "https://openreview.net/pdf?id=5f3brwjeTl",
        "keywords": "Backdoor Attack, Vision Large Language Model, Autonomous Driving",
        "abstract": "Vision-Large-Language-models (VLMs) have great application prospects in autonomous driving. Despite the ability of VLMs to comprehend and make decisions in complex scenarios, their integration into safety-critical autonomous driving systems poses serious security risks. In this paper, we propose \\texttt{BadVLMDriver}, the first backdoor attack against VLMs for autonomous driving that can be launched in practice using \\textit{physical} objects. Unlike existing backdoor attacks against VLMs that rely on digital modifications, \\texttt{BadVLMDriver} uses common physical items, such as a red balloon, to induce unsafe actions like sudden acceleration, highlighting a significant real-world threat to autonomous vehicle safety. To execute \\texttt{BadVLMDriver}, we develop an automated pipeline utilizing natural language instructions to generate backdoor training samples with embedded malicious behaviors. This approach allows for flexible trigger and behavior selection, enhancing the stealth and practicality of the attack in diverse scenarios. We conduct extensive experiments to evaluate \\texttt{BadVLMDriver} for two representative VLMs, five different trigger objects, and two types of malicious backdoor behaviors. \\texttt{BadVLMDriver} achieves a 92% attack success rate in inducing a sudden acceleration when coming across a pedestrian holding a red balloon. Thus, \\texttt{BadVLMDriver} not only demonstrates a critical security risk but also emphasizes the urgent need for developing robust defense mechanisms to protect against such vulnerabilities in autonomous driving technologies."
    },
    {
        "title": "A Stochastic Approach to the Subset Selection Problem via Mirror Descent",
        "link_suffix": "/forum?id=5K0fmGnFqP",
        "link": "https://openreview.net/forum?id=5K0fmGnFqP",
        "pdf_link": "https://openreview.net/pdf?id=5K0fmGnFqP",
        "keywords": "Nonconvex Optimization, Subset Selection, Stochastic, Mirror Descent, Stochastic Mirror Descent",
        "abstract": "The subset selection problem is fundamental in machine learning and other fields of computer science.\nWe introduce a stochastic formulation for the minimum cost subset selection problem in a black box setting, in which only the subset metric value is available.\nSubsequently, we can handle two-stage schemes, with an outer subset-selection component and an inner subset cost evaluation component. We propose formulating the subset selection problem in a stochastic manner by choosing subsets at random from a distribution whose parameters are learned. Two stochastic formulations are proposed.\nThe first explicitly restricts the subset's cardinality, and the second yields the desired cardinality in expectation.\nThe distribution is parameterized by a decision variable, which we optimize using Stochastic Mirror Descent.\nOur choice of distributions yields constructive closed-form unbiased stochastic gradient formulas and convergence guarantees, including a rate with favorable dependency on the problem parameters.\nEmpirical evaluation of selecting a subset of layers in transfer learning complements our theoretical findings and demonstrates the potential benefits of our approach."
    },
    {
        "title": "Knowing What Not to Do: Leverage Language Model Insights for Action Space Pruning in Multi-agent Reinforcement Learning",
        "link_suffix": "/forum?id=SWs8CIdQ33",
        "link": "https://openreview.net/forum?id=SWs8CIdQ33",
        "pdf_link": "https://openreview.net/pdf?id=SWs8CIdQ33",
        "keywords": "Multi-agent reinforcement learning, Action space pruning, Exploration, Coding large language model",
        "abstract": "Multi-agent reinforcement learning (MARL) is employed to develop autonomous agents that can learn to adopt cooperative or competitive strategies within complex environments. However, the linear increase in the number of agents leads to a combinatorial explosion of the action space, which always results in algorithmic instability, difficulty in convergence, or entrapment in local optima. While researchers have designed a variety of effective algorithms to compress the action space, these methods also introduce new challenges, such as the need for manually designed prior knowledge or reliance on the structure of the problem, which diminishes the applicability of these techniques. In this paper, we introduceEvolutionary actionSPAceReduction withKnowledge (eSpark), an exploration function generation framework driven by large language models (LLMs) to boost exploration and prune unnecessary actions in MARL. Using just a basic prompt that outlines the overall task and setting, eSpark is capable of generating exploration functions in a zero-shot manner, identifying and pruning redundant or irrelevant state-action pairs, and then achieving autonomous improvement from policy feedback. In reinforcement learning tasks involving inventory management and traffic light control encompassing a total of 15 scenarios, eSpark consistently outperforms the combined MARL algorithm in all scenarios, achieving an average performance gain of 34.4% and 9.9% in the two types of tasks respectively. Additionally, eSpark has proven to be capable of managing situations with a large number of agents, securing a 29.7% improvement in scalability challenges that featured over 500 agents. The code can be found inhttps://anonymous.4open.science/r/0CDH-0DF8/."
    }
]
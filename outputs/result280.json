[{"title": "SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding", "link_suffix": "/forum?id=Ng4HaH4L6P", "link": "https://openreview.net/forum?id=Ng4HaH4L6P", "pdf_link": "https://openreview.net/pdf?id=Ng4HaH4L6P", "keywords": "Computational Pathology, Whole Slide Image, Pathology, Multimodal Large Language Model", "abstract": "Despite the progress made by multimodal large language models (MLLMs) in computational pathology, they remain limited by a predominant focus on patch-level analysis, missing essential contextual information at the whole-slide level. The lack of large-scale instruction datasets and the gigapixel scale of whole slide images (WSIs) pose significant developmental challenges. In this paper, we present SlideChat, the first vision-language assistant capable of understanding gigapixel whole-slide images, exhibiting excellent multimodal conversational capability and response complex instruction across diverse pathology scenarios. To support its development, we created SlideInstruction, the largest instruction-following dataset for WSIs consisting of 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore, we propose SlideBench, a multimodal benchmark that incorporates captioning and VQA tasks to assess SlideChat\u2019s capabilities in varied clinical settings such as microscopy, diagnosis. Compared to both general and specialized MLLMs, SlideChat exhibits exceptional capabilities, achieving state-of-the-art performance on 18 of 22 tasks. For example, it achieved an overall accuracy of 81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB). We will fully release SlideChat, SlideInstruction and SlideBench as open-source resources to facilitate research and development in computational pathology.", "title_embedding_index": 13950, "title_abs_embedding_index": 13975}, {"title": "Problem-Parameter Free Federated Learning", "link_suffix": "/forum?id=ZuazHmXTns", "link": "https://openreview.net/forum?id=ZuazHmXTns", "pdf_link": "https://openreview.net/pdf?id=ZuazHmXTns", "keywords": "Adaptive federated learning, problem-parameter free, arbitrary data heterogeneity, adaptive stepsize", "abstract": "Federated learning (FL) has garnered significant attention from academia and industry in recent years due to its advantages in data privacy, scalability, and communication efficiency. However, current FL algorithms face a critical limitation: their performance heavily depends on meticulously tuned hyperparameters, particularly the learning rate or stepsize. This manual tuning process is challenging in federated settings due to data heterogeneity and limited accessibility of local datasets. Consequently, the reliance on problem-specific parameters hinders the widespread adoption of FL and potentially compromises its performance in dynamic or diverse environments. To address this issue, we introduce PAdaMFed, a novel algorithm for nonconvex FL that carefully combines adaptive stepsize and momentum techniques. PAdaMFed offers two key advantages: 1) it operates autonomously without relying on problem-specific parameters, making it, to our knowledge, the first FL algorithm to achieve such problem-parameter-agnostic adaptation; and 2) it manages data heterogeneity and partial participation without requiring heterogeneity bounds. Despite these benefits, PAdaMFed provides several strong theoretical guarantees: 1) It achieves state-of-the-art convergence rates with a sample complexity of $\\mathcal{O}(\\epsilon^{-4})$ and communication complexity of $\\mathcal{O}(\\epsilon^{-3})$, even using constant learning rates; 2) these complexities can be improved to the best-known $\\mathcal{O}(\\epsilon^{-3})$ for sampling and $\\mathcal{O}(\\epsilon^{-2})$ for communication when incorporating variance reduction; 3) it exhibits linear speedup with respect to the number of local update steps and participating clients at each global round. These attributes make PAdaMFed highly scalable and adaptable for various real-world FL applications. Extensive empirical evidence on both image classification and sentiment analysis tasks validates the efficacy of our approaches.", "title_embedding_index": 13951, "title_abs_embedding_index": 13976}, {"title": "POC: Preventing the Over-Collapse of Classes for Class-Incremental Learning", "link_suffix": "/forum?id=wwbVYrOMIW", "link": "https://openreview.net/forum?id=wwbVYrOMIW", "pdf_link": "https://openreview.net/pdf?id=wwbVYrOMIW", "keywords": "Class-Incremental Learning, Over-Collapse, Catastrophic Forgetting", "abstract": "Deep neural network-based classification models often suffer from catastrophic forgetting during class-incremental learning (CIL). Previous studies reveal that it results from the overlap between seen and future classes after being mapped by model to its feature space through extracting the features. In this paper, we analyze that this overlap mainly results from the $\\textit{over-collapse}$ of seen classes, where the model tends to map originally separated one seen class and its adjacent regions in input space to be mixed in the feature space, making them indistinguishable. To this end, we propose a two-step framework to $\\textbf{P}$revent the $\\textbf{O}$ver-$\\textbf{C}$ollapse (POC). During training, POC first learns and applies a set of transformations to the training samples of seen classes. Based on our theoretical analysis, the transformation results will locate in the adjacent regions of the seen classes in the input space so that we can let them represent the adjacent regions. Then, the model's optimization objective is modified to additionally classify between the seen classes and the adjacent regions, separating them in model's feature space so that preventing the over-collapse. To retain the model's generalization on the seen classes, a deterministic contrastive loss that makes the separate features of seen classes and adjacent regions close is further introduced. Since POC uses the adjacent regions exclusively for classification, it can be easily adopted by existing CIL methods. Experiments on CIFAR-100 and ImageNet demonstrate that POC effectively increases the last/average incremental accuracy of six SOTA CIL methods by 3.5%/3.0% on average respectively.", "title_embedding_index": 13952, "title_abs_embedding_index": 13977}, {"title": "RANKCLIP: Ranking-Consistent Language-Image Pretraining", "link_suffix": "/forum?id=btmHUbrfVj", "link": "https://openreview.net/forum?id=btmHUbrfVj", "pdf_link": "https://openreview.net/pdf?id=btmHUbrfVj", "keywords": "Vision and Language Alignment, Contrastive Learning, Ranking Consistency", "abstract": "Self-supervised contrastive learning models, such as CLIP, have set new benchmarks for vision-language models in many downstream tasks. However, their dependency on rigid one-to-one mappings overlooks the complex and often multifaceted relationships between and within texts and images. To this end, we introduce RankCLIP, a novel pretraining method that extends beyond the rigid one-to-one matching framework of CLIP and its variants. By extending the traditional pair-wise loss to list-wise, and leveraging both in-modal and cross-modal ranking consistency, RankCLIP improves the alignment process, enabling it to capture the nuanced many-to-many relationships between and within each modality. Through comprehensive experiments, we demonstrate the effectiveness of RankCLIP in various downstream tasks, notably achieving significant gains in zero-shot classifications over state-of-the-art methods, underscoring the importance of this enhanced learning process.", "title_embedding_index": 13953, "title_abs_embedding_index": 13978}, {"title": "ShuffleMTM: Learning Cross-channel Dependence in Multivariate Time Series from Shuffled Patches", "link_suffix": "/forum?id=aWkAKucZMR", "link": "https://openreview.net/forum?id=aWkAKucZMR", "pdf_link": "https://openreview.net/pdf?id=aWkAKucZMR", "keywords": "Self-supervised learning, masked modeling, multivariate time series, cross-channel dependence", "abstract": "Masked time-series modeling has widely gained attention as a self-supervised pre-training method for multivariate time series (MTS). Recent studies adopt a channel-independent (CI) strategy to enhance the temporal modeling capacity. Despite the effectiveness and performance of this strategy, the CI methods inherently overlook cross-channel dependence, which is inherent and crucial in MTS data in various domains. To fill this gap, we propose ShuffleMTM, a simple yet effective masked time-series modeling framework to learn cross-channel dependence from shuffled patches. Technically, ShuffleMTM proposes to shuffle the unmasked patches from masked series across different channels, positioned at the same index. Then, Siamese encoders learn two views of masked patch representations from original and shuffled masked series, simultaneously capturing the temporal dependence within a channel as well as spatial dependence across different channels. ShuffleMTM pre-trains the Siamese encoders to reconstruct the original series by incorporating cross-channel information with intra-channel cross-time information. Our proposed method consistently achieves superior performance in various experiments, compared to advanced CI pre-training methods and channel-dependent methods in both time series forecasting and classification tasks.", "title_embedding_index": 13954, "title_abs_embedding_index": 13979}, {"title": "ProdInfluencerNet: A Novel Product-Centric Influencer Recommendation Framework Based on Heterogeneous Networks", "link_suffix": "/forum?id=GDf7vWs701", "link": "https://openreview.net/forum?id=GDf7vWs701", "pdf_link": "https://openreview.net/pdf?id=GDf7vWs701", "keywords": "Influencer Marketing, Influecner Recommnedation, Heterogeneous Information Network, Inductive Learning, ProdInfluencerNet", "abstract": "With the proliferation of social media, influencer marketing has emerged as a popular strategy for brands to promote their products. Recent studies have increasingly explored the use of machine learning to recommend suitable influencers for brands. This typically involves analyzing the compatibility of influencer profiles with brand attributes. However, for brands entering new markets or promoting products in unfamiliar categories, existing solutions may be limited due to insufficient information for accurate compatibility matching.In this paper, we propose ProdInfluencerNet (PIN), a product-centric framework designed for influencer recommendation. PIN effectively models the complex relationships between brands, products, and influencers using Heterogeneous Information Networks (HINs). We categorize sponsored post images using the Google Taxonomy through image classification techniques. By leveraging the taxonomy's hierarchical structure and adopting an inductive learning approach, PIN can accurately recommend influencers for brands, even in new markets or with innovative products. We validate PIN's effectiveness and superiority over existing methods using two Instagram datasets. Furthermore, our analysis reveals that text features in profiles are more critical than images for identifying cooperative relationships between product categories and influencers.", "title_embedding_index": 13955, "title_abs_embedding_index": 13980}, {"title": "UQ-Merge: UNCERTAINTY GUIDED MULTIMODAL LARGE LANGUAGE MODEL MERGING", "link_suffix": "/forum?id=SO0manOwUF", "link": "https://openreview.net/forum?id=SO0manOwUF", "pdf_link": "https://openreview.net/pdf?id=SO0manOwUF", "keywords": "Multimodal Large Language Model, Uncertainty Quantification, Model Merging", "abstract": "Multimodal Large Language Models (MLLMs) have gained increasing popularity as a promising framework for leveraging the strong language reasoning capabilities in the vision-language domain. Given a wide range of MLLMs, model merging potentially offers a cheap way to aggregate their diverse knowledge into a single MLLM. However, directly plug-in existing model merging approaches often leads to suboptimal performance due to ($1$) inclusion of harmful models that have over-confident predictions in the target task; ($2$) the lack of specialized designs for vision-language tasks. To tackl these pain points, we conduct pioneering investigations to dissect the merging procedures and propose an uncertainty-guided MLLM merging algorithm, $\\textit{i.e.}$, $\\texttt{UQ-Merge}$, which $i)$ identifies beneficial candidates for merging, $ii)$ determines the merge order and the number of helpful candidates, and $iii)$ performs appropriate merging. Within our framework, we consider uncertainty quantification on both text and vision inputs to examine the MLLM prediction confidence, and then decide whether and when a MLLM needs to be included. It is worth mentioning that our vision-language uncertainty quantification does not require access to sample labels, making it more practical in various scenarios. Extensive experiments consistently demonstrate the superior MLLM merging performance of $\\texttt{UQ-Merge}$ in both held-in and held-out vision-language benchmarks. For example, compared to existing state-of-the-art merging methods, $\\texttt{UQ-Merge}$ brings substantial performance improvements of up to $44.3%$ on average accuracy in $12$ datasets. Codes are available athttps://anonymous.4open.science/r/UQ-Merge-7CD7.", "title_embedding_index": 13956, "title_abs_embedding_index": 13981}, {"title": "A Benchmark for Semantic Sensitive Information in LLMs Outputs", "link_suffix": "/forum?id=p3mxzKmuZy", "link": "https://openreview.net/forum?id=p3mxzKmuZy", "pdf_link": "https://openreview.net/pdf?id=p3mxzKmuZy", "keywords": "LLMs, sensitive information", "abstract": "Large language models (LLMs) can output sensitive information, which has emerged as a novel safety concern. Previous works focus on structured sensitive information (e.g. personal identifiable information). However, we notice that sensitive information in LLMs\u2019 outputs can also be at the semantic level, i.e. semantic sensitive information (SemSI). Particularly, simple natural questions can let state-of-the-art (SOTA) LLMs output SemSI. Compared to previous work of structured sensitive information in LLM\u2019s outputs, SemSI are hard to define and are rarely studied. Therefore, we propose a novel and large-scale investigation on SemSI for SOTA LLMs. First, we construct a comprehensive and labeled dataset of semantic sensitive information, SemSI-Set, by including three typical categories of SemSI. Then, we propose a large-scale benchmark, SemSI-Bench, to systematically evaluate semantic sensitive information in 25 SOTA LLMs. Our\nfinding reveals that SemSI widely exists in SOTA LLMs\u2019 outputs by querying with simple natural questions.", "title_embedding_index": 13957, "title_abs_embedding_index": 13982}, {"title": "FlexCAD: Unified and Versatile Controllable CAD Generation with Fine-tuned Large Language Models", "link_suffix": "/forum?id=Z0eiiV3Yyh", "link": "https://openreview.net/forum?id=Z0eiiV3Yyh", "pdf_link": "https://openreview.net/pdf?id=Z0eiiV3Yyh", "keywords": "CAD generation, large language model", "abstract": "Recently, there is a growing interest in creating computer-aided design (CAD) models based on user intent, known as controllable CAD generation. Existing work offers limited controllability and needs separate models for different types of control, reducing efficiency and practicality. To achieve controllable generation across all CAD construction hierarchies, such as sketch-extrusion, extrusion, sketch, face, loop and curve, we propose FlexCAD, a unified model by fine-tuning large language models (LLMs). First, to enhance comprehension by LLMs, we represent a CAD model as a structured text by abstracting each hierarchy as a sequence of text tokens. Second, to address various controllable generation tasks in a unified model, we introduce a hierarchy-aware masking strategy. Specifically, during training, we mask a hierarchy-aware field in the CAD text with a mask token. This field, composed of a sequence of tokens, can be set flexibly to represent various hierarchies. Subsequently, we ask LLMs to predict this masked field. During inference, the user intent is converted into a CAD text with a mask token replacing the part the user wants to modify, which is then fed into FlexCAD to generate new CAD models. \nComprehensive experiments on public dataset demonstrate the effectiveness of FlexCAD in both generation quality and controllability.", "title_embedding_index": 13958, "title_abs_embedding_index": 13983}, {"title": "RetinaGS: Scalable Training for Dense Scene Rendering with Billion-Scale 3D Gaussians", "link_suffix": "/forum?id=jiKefvNp01", "link": "https://openreview.net/forum?id=jiKefvNp01", "pdf_link": "https://openreview.net/pdf?id=jiKefvNp01", "keywords": "Gaussian Splatting", "abstract": "In this work, we explore the possibility of training high-parameter 3D Gaussian splatting (3DGS) models on large-scale, high-resolution datasets. We design a general model parallel training method for 3DGS, named RetinaGS, which uses a proper rendering equation and can be applied to any scene and arbitrary distribution of Gaussian primitives. It enables us to explore the scaling behavior of 3DGS in terms of primitive numbers and training resolutions that were difficult to explore before and surpass previous state-of-the-art reconstruction quality. We observe a clear positive trend of increasing visual quality when increasing primitive numbers with our method. We also demonstrate the first attempt at training a 3DGS model with more than one billion primitives on the full MatrixCity dataset that attains a promising visual quality.", "title_embedding_index": 13959, "title_abs_embedding_index": 13984}, {"title": "Think Twice Before You Act: Improving Inverse Problem Solving With MCMC", "link_suffix": "/forum?id=D7PQ54l5Q1", "link": "https://openreview.net/forum?id=D7PQ54l5Q1", "pdf_link": "https://openreview.net/pdf?id=D7PQ54l5Q1", "keywords": "Inverse problem, diffusion, MCMC sampling, generative model", "abstract": "Recent studies demonstrate that diffusion models can serve as a strong prior for solving inverse problems. A prominent example is Diffusion Posterior Sampling (DPS), which approximates the posterior distribution of data given the measure using Tweedie's formula. Despite the merits of being versatile in solving various inverse problems without re-training, the performance of DPS is hindered by the fact that this posterior approximation can be inaccurate especially for high noise levels. Therefore, we propose Diffusion Posterior MCMC (DPMC), a novel inference algorithm based on Annealed MCMC to solve inverse problems with pretrained diffusion models. We define a series of intermediate distributions inspired by the approximated conditional distributions used by DPS. Through annealed MCMC sampling, we encourage the samples to follow each intermediate distribution more closely before moving to the next distribution at a lower noise level, and therefore reduce the accumulated error along the path. We test our algorithm in various inverse problems, including super resolution, Gaussian deblurring, motion deblurring, inpainting, and phase retrieval. Our algorithm outperforms DPS with less number of evaluations across nearly all tasks, and is competitive among existing approaches.", "title_embedding_index": 13960, "title_abs_embedding_index": 13985}, {"title": "Phase-Driven Domain Generalizable Learning For Nonstationary Time Series Classification", "link_suffix": "/forum?id=OW9TFoLuE4", "link": "https://openreview.net/forum?id=OW9TFoLuE4", "pdf_link": "https://openreview.net/pdf?id=OW9TFoLuE4", "keywords": "Time Series; Domain Generalization; Machine Learning for Time Series data;", "abstract": "Monitoring and recognizing patterns in continuous sensing data is crucial for many practical applications. These real-world time-series data are often nonstationary, characterized by varying statistical and spectral properties over time. This poses a significant challenge in developing learning models that can effectively generalize across different distributions. In this work, based on our observation that nonstationary statistics for time-series classification tasks are intrinsically linked to the phase information, we propose a time-series domain generalization framework, PhASER. It consists of three novel elements: 1) Hilbert transform-based phase augmentation that diversifies non-stationarity while preserving discriminatory semantics, 2) separate magnitude-phase encoding by viewing time-varying magnitude and phase as independent modalities, and 3) phase-residual feature broadcasting by incorporating phase with a novel residual connection for inherent regularization to enhance distribution invariant learning. Extensive evaluation on 5 datasets from sleep-stage classification, human activity recognition, and gesture recognition against 12 state-of-the-art baseline methods demonstrate that PhASER consistently outperforms the best baselines by an average of 5% and up to 13% in some cases. Moreover, PhASER\u2019s principles can also be applied broadly to boost the generalizability of existing time-series classification models.", "title_embedding_index": 13961, "title_abs_embedding_index": 13986}, {"title": "Elucidating the Design Space of Text-to-Audio Models", "link_suffix": "/forum?id=xmgvF0sLIn", "link": "https://openreview.net/forum?id=xmgvF0sLIn", "pdf_link": "https://openreview.net/pdf?id=xmgvF0sLIn", "keywords": "audio generation, text-to-audio, synthetic data, diffusion, flow matching", "abstract": "Recent years have seen significant progress in Text-To-Audio (TTA) synthesis, enabling users to enrich their creative workflows with synthetic audio generated from natural language prompts. Despite this progress, the effects of data, model architecture, training objective functions, and sampling strategies on target benchmarks are not well understood. With the purpose of providing a holistic understanding of the design space of TTA models, we setup a large-scale empirical experiment focused on diffusion and flow matching models. Our contributions include: 1) AF-Synthetic, a large dataset of high quality synthetic captions obtained from an audio understanding model; 2) a systematic comparison of different architectural, training, and inference design choices for TTA models; 3) an analysis of sampling methods and their Pareto curves with respect to generation quality and inference speed. We leverage the knowledge obtained from this extensive analysis to propose our best model dubbed Elucidated Text-To-Audio (ETTA). When evaluated on AudioCaps and MusicCaps, ETTA provides improvements over the baselines trained on publicly available data, while being competitive with models trained on proprietary data. Finally, we show ETTA's improved ability to generate creative audio following complex and imaginative captions \u2014 a task that is more challenging than current benchmarks.", "title_embedding_index": 13962, "title_abs_embedding_index": 13987}, {"title": "Path-Tracing Distillation: Enhancing Stability in Text-to-3D Generation by Mitigating Out-of-Distribution Issues", "link_suffix": "/forum?id=f7Zq9CqQEM", "link": "https://openreview.net/forum?id=f7Zq9CqQEM", "pdf_link": "https://openreview.net/pdf?id=f7Zq9CqQEM", "keywords": "Text-to-3D Generation, Score Distillation, Path-Tracing, 3D Model Stability", "abstract": "Text-to-3D generation techniques signify a pivotal advancement in creating 3D models from textual descriptions. Contemporary state-of-the-art methods utilize score distillation processes, leveraging 2D priors to generate 3D assets. However, these approaches frequently encounter instability during the initial generation phases, primarily due to an distribution divergence between the pretrained score prediction network and the nascent 3D model. Specifically, raw rendered images of an initial 3D model lie outside the distribution (OOD) of the pretrained score prediction network, which is trained on high-fidelity realistic images. To address this OOD issue, we introduce an innovative Path-Tracing Distillation (PTD) technique that refines the distillation process. Our method sequentially optimizes the 3D model using intermediate score networks that exhibit closer distributional alignment, thereby accelerating the convergence during the early stages of training. This approach not only ensures a more stable increase in CLIP similarity initially but also preserves the visual quality and diversity of the generated models. Experiments demonstrate that PTD significantly enhances both the stability and quality of text-to-3D generation, outperforming existing baselines. PTD can also be generalized to other score distillation methods.", "title_embedding_index": 13963, "title_abs_embedding_index": 13988}, {"title": "Paramanu-Ganita: An Efficient Pre-trained Generative Mathematics Language Model with Chain-of-Thought Instruction Fine-Tuning", "link_suffix": "/forum?id=v3DwQlyGbv", "link": "https://openreview.net/forum?id=v3DwQlyGbv", "pdf_link": "https://openreview.net/pdf?id=v3DwQlyGbv", "keywords": "reasoning, language models, pretraining, CoT fine-tuning, AI4Math", "abstract": "In this paper, we present PARAMANU -G ANITA, a 208 million-parameter novel\nAuto Regressive (AR) decoder based language model on mathematics. We per-\nformed pretraining from scratch on 31.5 billion tokens using a context size of 4096\non a mixed mathematical corpus consisting of mathematical web pages, mathe-\nmatics related source code such as AlgebraStack, mathematical textbooks, Chain-\nof-Thought (CoT) templatised mathematical StackOverflow question answers\npairs, and mathematical lecture notes in LATEX curated by us. We also trained a\nmath and code specialised BPE tokenizer. We proposed and performed Chain-of-\nThought instruction fine-tuning of Paramanu-Ganita on the MetaMathQA dataset.\nWe evaluate our model on GSM8K and MATH mathematical benchmarks, and on\nlogical deductive reasoning (LogiQA) and multiple choice high school and col-\nlege level math questions from SAT (AGIEVAL-SAT-Math), GRE/GMAT ques-\ntions (AGIEVAL-AQuA-RAT), college and high school level math questions from\nMMLU. Our model Paramanu-Ganita, despite being 34 times smaller than the\n7B LLMs, outperforms general LLMs by approximately 30% points, and even\nmath-specialised LLMs by 3-23% points in GSM8K test accuracy metric. On\nMATH benchmark, Paramanu-Ganita outperformed the various models by 6-8%\npoints. On other benchmarks such as LogiQA logical deductive reasoning bench-\nmark, mathematical high school level multi-choice questions (MMLU-math-high-\nschool), GRE-GMAT level quantitative questions (AGIEVAL-AQuA-RAT), SAT\nlevel math questions, Paramanu-Ganita was better than the others by about 1-4%\npoints. The large significant margin improvement in performance of our math\nmodel over the existing LLMs signifies that reasoning capabilities of language\nmodels are just not restricted to those with humongous number of parameters.\nParamanu-Ganita took only 170 hours of A100 training whereas large LLMs such\nas the math-specialised LLM, LLEMMA 7B, was trained for 23,000 A100 equiv-\nalent hours. Thus, our approach of pretraining powerful domain-specialised lan-\nguage models from scratch for domain adaptation is much more cost-effective and\nenvironmental friendly than performing continual training of LLMs.", "title_embedding_index": 13964, "title_abs_embedding_index": 13989}, {"title": "Diffusion Attribution Score: Which Training Sample Determines Your Generation?", "link_suffix": "/forum?id=kuutidLf6R", "link": "https://openreview.net/forum?id=kuutidLf6R", "pdf_link": "https://openreview.net/pdf?id=kuutidLf6R", "keywords": "Diffusion Model; Data Attribution; Training Data Influence", "abstract": "As diffusion models advance, the scientific community is actively developing methods to curb the misuse of generative models, which aims to prevent the reproduction of copyrighted, explicitly violent, or personally sensitive information in generated images.\nOne strategy is to identify the contribution of training samples in generative models by evaluating their influence to the generated images, a task known as data attribution.\nExisting data attribution approaches on diffusion models suggest representing the contribution of a specific training sample by evaluating the change in the diffusion loss when the sample is included versus excluded from the training process.\nHowever, we argue that the direct usage of diffusion loss cannot represent such a contribution accurately due to the diffusion loss calculation. Specifically, these approaches measure the divergence between predicted and ground truth distributions, which leads to an indirect comparison between the predicted distributions and cannot represent the variances between model behaviors.\nTo address these issues, we aim to measure the direct comparison between predicted distributions with an attribution score to analyse the training sample importance, which is achieved by Diffusion Attribution Score (DAS).\nUnderpinned by rigorous theoretical analysis, we elucidate the effectiveness of DAS.\nAdditionally, we explore strategies to accelerate DAS calculations, facilitating its application to large-scale diffusion models.\nOur extensive experiments across various datasets and diffusion models demonstrate that DAS significantly surpasses previous benchmarks in terms of the linear data-modelling score, establishing new state-of-the-art performance.\nCode is available athttps://anonymous.4open.science/r/Diffusion-Attribution-Score-411F.", "title_embedding_index": 13965, "title_abs_embedding_index": 13990}, {"title": "Efficient Neuron Segmentation in Electron Microscopy by Affinity-Guided Queries", "link_suffix": "/forum?id=Y0QqruhqIa", "link": "https://openreview.net/forum?id=Y0QqruhqIa", "pdf_link": "https://openreview.net/pdf?id=Y0QqruhqIa", "keywords": "Neuron Segmentation; Biomedical Image Segmentation; Electron Microscopy Image", "abstract": "Accurate segmentation of neurons in electron microscopy (EM) images plays a crucial role in understanding the intricate wiring patterns of the brain. Existing automatic neuron segmentation methods rely on traditional clustering algorithms, where affinities are predicted first, and then watershed and post-processing algorithms are applied to yield segmentation results. Due to the nature of watershed algorithm, this paradigm has deficiency in both prediction quality and speed. Inspired by recent advances in natural image segmentation, we propose to use query-based methods to address the problem because they do not necessitate watershed algorithms. However, we find that directly applying existing query-based methods faces great challenges due to the large memory requirement of the 3D data and considerably different morphology of neurons. To tackle these challenges, we introduce affinity-guided queries and integrate them into a lightweight query-based framework. Specifically, we first predict affinities with a lightweight branch, which provides coarse neuron structure information. The affinities are then used to construct affinity-guided queries, facilitating segmentation with bottom-up cues. These queries, along with additional learnable queries, interact with the image features to directly predict the final segmentation results. Experiments on benchmark datasets demonstrated that our method achieved better results over state-of-the-art methods with a 2$\\sim$3$\\times$ speedup in inference. Code will be released.", "title_embedding_index": 13966, "title_abs_embedding_index": 13991}, {"title": "Continuous Autoregressive Modeling with Stochastic Monotonic Alignment for Speech Synthesis", "link_suffix": "/forum?id=cuFzE8Jlvb", "link": "https://openreview.net/forum?id=cuFzE8Jlvb", "pdf_link": "https://openreview.net/pdf?id=cuFzE8Jlvb", "keywords": "Speech Synthesis;text-to-speech;", "abstract": "We propose a novel autoregressive modeling approach for speech synthesis, combining a variational autoencoder (VAE) with a multi-modal latent space and an autoregressive model that uses Gaussian Mixture Models (GMM) as the conditional probability distribution. Unlike previous methods that rely on residual vector quantization, our model leverages continuous speech representations from the VAE's latent space, greatly simplifying the training and inference pipelines. We also introduce a stochastic monotonic alignment mechanism to enforce strict monotonic alignments. Our approach significantly outperforms the state-of-the-art autoregressive model VALL-E in both subjective and objective evaluations, achieving these results with only 10.3% of VALL-E's parameters. This demonstrates the potential of continuous speech language models as a more efficient alternative to existing quantization-based speech language models. Sample audio can be found at \\url{https://tinyurl.com/gmm-lm-tts}.", "title_embedding_index": 13967, "title_abs_embedding_index": 13992}, {"title": "Context-Aware Kernel Search for Bayesian Optimization with Large Language Models", "link_suffix": "/forum?id=wWpChcKLwB", "link": "https://openreview.net/forum?id=wWpChcKLwB", "pdf_link": "https://openreview.net/pdf?id=wWpChcKLwB", "keywords": "Bayesian optimization, Gaussian processes, kernel design, large language models", "abstract": "The efficiency of Bayesian optimization (BO) relies on careful selection of the surrogate model to balance exploration and exploitation under limited budget. Traditional BO methods often struggle with sub-optimal kernel choices when using Gaussian processes (GPs) as the surrogate model. When the kernel is inadequately chosen, BO may converge slowly or even get stuck at an undesired local minimum. To address such drawback, we propose the novel Context-Aware Kernel Search (CAKES) to automate optimal kernel design in BO with large language models (LLMs). Concretely, CAKES exploits LLMs as crossover and mutation operators to adaptively generate and refine GP kernels based on the observed data. CAKES works entirely in-context and can be easily integrated into existing systems without requiring any fine-tuning. We further present a theoretical analysis demonstrating that our method achieves sub-linear regret relative to the budget for any input dimension. Experimental results demonstrate that CAKES outperforms various salient baseline methods in numerous synthetic and real-world optimization tasks. Notably, CAKES improves the overall performance on benchmark functions by roughly 9%. In hyperparameter tuning tasks, CAKES can effectively leverage fewer data samples to quickly identify high-performing configurations and consistently ranks first across various datasets. As an encouraging real application, we successfully applied CAKES to design photonic chips,  achieving significant improvements in key performance indicators while speeding up the design cycle by a factor of ten compared to the baselines. Our code is accessible athttps://github.com/cakes4bo/cakes.", "title_embedding_index": 13968, "title_abs_embedding_index": 13993}, {"title": "HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal Large Language Models", "link_suffix": "/forum?id=EoPsCAEYae", "link": "https://openreview.net/forum?id=EoPsCAEYae", "pdf_link": "https://openreview.net/pdf?id=EoPsCAEYae", "keywords": "Multimodal Large Language Model", "abstract": "Recent advancements indicate that scaling up Multimodal Large Language Models (MLLMs) effectively enhances performance on downstream multimodal tasks. \nThe prevailing MLLM paradigm, \\emph{e.g.}, LLaVA, transforms visual features into text-like tokens using a \\emph{static} vision-language mapper, thereby enabling \\emph{static} LLMs to develop the capability to comprehend visual information through visual instruction tuning. \nUnfortunately, the \\emph{static} paradigm shares the same parameters to underly multi-task instruction tuning, inevitably introducing the potential \\emph{task interference} or \\emph{negative transfer}, \\emph{i.e.}, where an improvement in the performance of one task reduces the performance of other tasks. \nIn light of this, we introduce \\textbf{HyperLLaVA}, which in conjunction with a dynamic visual expert and language expert, respectively adjusts the parameters of the projector and LLM layers conditioned on diverse instruction semantics, thereby minimizing the task interference. \nThese experts are derived from HyperNetworks, which adaptively generates dynamic parameter shifts through visual and language guidance, enabling dynamic vision-language alignment and instruction tuning in two-stage training. \nTo deeply study the multi-task interference of MLLM, we build the \\textbf{Comprehensive Multimodal Task benchmark} (\\texttt{CMT}), a comprehensive benchmark for the evaluation of multidimensional multimodal tasks. \nThe experiments demonstrate that \nthe superiority of the dynamic tuning paradigm for multi-task instruction following on \\texttt{CMT} and general MLLM benchmarks. Our project is available at \\href{https://anonymous.4open.science/r/HyperLLaVA-D58E}{https://anonymous.4open.science/r/HyperLLaVA-D58E}.", "title_embedding_index": 13969, "title_abs_embedding_index": 13994}, {"title": "PIG: Physics-Informed Gaussians as Adaptive Parametric Mesh Representations", "link_suffix": "/forum?id=y5B0ca4mjt", "link": "https://openreview.net/forum?id=y5B0ca4mjt", "pdf_link": "https://openreview.net/pdf?id=y5B0ca4mjt", "keywords": "Gaussians, Physics-informed Deep Learning", "abstract": "The approximation of Partial Differential Equations (PDEs) using neural networks has seen significant advancements through Physics-Informed Neural Networks (PINNs). Despite their straightforward optimization framework and flexibility in implementing various PDEs, PINNs often suffer from low accuracy due to the spectral bias of Multi-Layer Perceptrons (MLPs), which struggle to effectively learn high-frequency and non-linear components. Recently, the parametric mesh representations have been investigated as a promising approach to effectively eliminating the inductive biases of neural networks. However, they often require very high-resolution grids and a large number of collocation points to achieve high accuracy while avoiding overfitting issues. In addition, these are limited by the fixed positions of the mesh parameters, hindering their ability to approximate complex PDEs. To overcome these limitations, we propose Physics-Informed Gaussians (PIGs), which combine feature embeddings using Gaussian functions with a lightweight neural network. Our approach uses trainable parameters for the mean and variance of each Gaussian, allowing for dynamic adjustment of their positions and shapes during training. This adaptability enables our model to optimally approximate PDE solutions, unlike models with fixed parameter positions. Furthermore, the proposed approach maintains the same optimization framework used in PINNs, allowing us to benefit from their excellent properties. Experimental results show the competitive performance of our model across various PDEs, demonstrating its potential as a robust tool for solving complex PDEs.", "title_embedding_index": 13970, "title_abs_embedding_index": 13995}, {"title": "Scaling Omni-modal Pretraining with Multimodal Context: Advancing Universal Representation Learning Across Modalities", "link_suffix": "/forum?id=Ux0BEP46fd", "link": "https://openreview.net/forum?id=Ux0BEP46fd", "pdf_link": "https://openreview.net/pdf?id=Ux0BEP46fd", "keywords": "Multimodal Pretraining, Multimodal Context", "abstract": "In this work, we introduce Multimodal Context (MiCo), a scalable pretraining framework designed to advance omni-modal intelligence\u2014an AI system capable of understanding and learning from multiple modalities to achieve universal representation learning. MiCo allows for efficient scaling of both the number of modalities and the volume of data, along with model parameters, during the pretraining phase. We evaluate the pretrained models across a diverse set of tasks, including: (i) single-modality perception benchmarks covering 10 distinct modalities, (ii) 25 cross-modal tasks spanning retrieval, question-answering, and captioning, and (iii) 18 large-scale multimodal language model benchmarks. MiCo consistently delivers state-of-the-art results, setting 37 new benchmarks across these tasks. The pretrained models, along with the collected datasets and codebase, will be made publicly available to support the development of omni-modal intelligence and broader research in multimodal learning.", "title_embedding_index": 13971, "title_abs_embedding_index": 13996}, {"title": "ShortGPT: Layers in Large Language Models are More Redundant Than You Expect", "link_suffix": "/forum?id=JMNht3SmcG", "link": "https://openreview.net/forum?id=JMNht3SmcG", "pdf_link": "https://openreview.net/pdf?id=JMNht3SmcG", "keywords": "Large Language Model, Model pruning, Layer redundancy", "abstract": "As Large Language Models (LLMs) continue to advance in performance, their size has increased significantly, with current LLMs containing billions or even trillions of parameters.  In this study, we identify notable redundancy across the layers of LLMs, where some layers contribute minimally to overall network functionality. To quantify this, we introduce a metric called Block Influence (BI) which use the similarity between layer's input and output to measure the importance of each layer. Based on the observation of layer redundancy, we propose a straightforward pruning method: layer removal, which eliminates redundant layers based on their BI scores. Our approach, termed ShortGPT, demonstrates superior performance over previous state-of-the-art pruning methods.  Moreover, ShortGPT is orthogonal to quantization-like methods, enabling further reduction in parameters and computation. The ability to achieve better results through simple layer removal, as opposed to more complex pruning techniques, suggests a high degree of redundancy across layers, not only in transformer models but also in non-transformer models. We hope this work will contribute to future research in LLM compression.", "title_embedding_index": 13972, "title_abs_embedding_index": 13997}, {"title": "Efficiently pre-training language models with mixtures of cluster-oriented, trainability-aware experts", "link_suffix": "/forum?id=thqPibDg6A", "link": "https://openreview.net/forum?id=thqPibDg6A", "pdf_link": "https://openreview.net/pdf?id=thqPibDg6A", "keywords": "Mixture of Expert, Language models, Clustering, Trainability", "abstract": "Language models (LMs) are pre-trained on large-scale corpora from diverse data sources, encapsulating knowledge across various domains, with their feature spaces often displaying clustering structures. The mixture of experts (MoEs) approach is commonly used to scale up model learning capabilities to handle such complexities; however, the fine-grained learning dynamics at the expert level remain largely unexplored. This work analyzes the spatial and temporal characteristics of these clustering structures and examines their impact on the fine-grained trainability of individual experts. Our analysis builds on the singular spectrum of the feature and Jacobian spaces leading to two key observations. First, a few top singular vectors from the feature matrix are sufficient to capture the layer-wise feature cluster patterns. More interestingly, the maximum singular value of the Jacobian matrix reveals conflicts between different feature clusters, and experts exhibit varying levels of trainability, completing their learning asynchronously during training.\nInspired by these insights, we proposed mixtures of cluster-guided, trainability-aware experts (MO-CTE), with \nan efficient routing method to mitigate inter-cluster conflicts to improve expert trainability and \na simple yet effective criterion for early stopping low-trainability experts, thus reducing total training costs. \nWe evaluate the proposed MO-CTE across extensive datasets and tasks. Experimental results indicate that MO-CTE accelerates convergence by approximately 37% in test perplexity and 30% in downstream tasks, and improves performance by 3.6% over baselines when consuming similar computation resources.", "title_embedding_index": 13973, "title_abs_embedding_index": 13998}, {"title": "BraiNav: Incorporating Human Brain Activity to Enhance Robustness in Embodied Visual Navigation", "link_suffix": "/forum?id=HVY6qL2J9L", "link": "https://openreview.net/forum?id=HVY6qL2J9L", "pdf_link": "https://openreview.net/pdf?id=HVY6qL2J9L", "keywords": "embodied visual navigation, neural encoding, multimodal learning", "abstract": "Recent research shows that standard navigation agents significantly underperform and even fail in the presence of various visual corruptions. Unlike embodied agents, the human brain's visual system can robustly perceive the environment and extract the necessary information to complete the visual tasks. In this paper, we propose a two-phase Brain-Machine integration Navigation method called BraiNav, which incorporates neural representations derived from human brain activity to enhance robustness against visual corruptions. In the first phase, a brain encoder, built upon a recently advanced self-supervised pretrained model, is trained on a large-scale human brain activity dataset and then frozen for downstream visual navigation. In the second phase, neural representations harboring high-level cognitive information from the human brain are constructed based on the pretrained frozen brain encoder. Additionally, we propose a multimodal fusion method based on cross-attention to obtain more consistent brain-visual joint representations, which are then used to learn the navigation policy. Sufficient experiments demonstrate that the proposed method exhibits higher robustness against various visual corruptions compared to standard navigation agent and multiple computer vision-enhanced agents. Our study pioneers the incorporation of human brain activity into embodied AI, aiming to catalyze further cross-disciplinary collaboration with computational neuroscience.", "title_embedding_index": 13974, "title_abs_embedding_index": 13999}]
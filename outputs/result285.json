[
    {
        "title": "EKAN: Equivariant Kolmogorov-Arnold Networks",
        "link_suffix": "/forum?id=soaOqFTaHJ",
        "link": "https://openreview.net/forum?id=soaOqFTaHJ",
        "pdf_link": "https://openreview.net/pdf?id=soaOqFTaHJ",
        "keywords": "Equivariant networks, Kolmogorov-Arnold networks",
        "abstract": "Kolmogorov-Arnold Networks (KANs) have seen great success in scientific domains thanks to spline activation functions, becoming an alternative to Multi-Layer Perceptrons (MLPs). However, spline functions may not respect symmetry in tasks, which is crucial prior knowledge in machine learning. Previously, equivariant networks embed symmetry into their architectures, achieving better performance in specific applications. Among these, Equivariant Multi-Layer Perceptrons (EMLP) introduce arbitrary matrix group equivariance into MLPs, providing a general framework for constructing equivariant networks layer by layer. In this paper, we propose Equivariant Kolmogorov-Arnold Networks (EKAN), a method for incorporating matrix group equivariance into KANs, aiming to broaden their applicability to more fields. First, we construct gated spline basis functions, which form the EKAN layer together with equivariant linear weights. We then define a lift layer to align the input space of EKAN with the feature space of the dataset, thereby building the entire EKAN architecture. Compared with baseline models, EKAN achieves higher accuracy with smaller datasets or fewer parameters on symmetry-related tasks, such as particle scattering and the three-body problem, often reducing test MSE by several orders of magnitude. Even in non-symbolic formula scenarios, such as top quark tagging with three jet constituents, EKAN achieves comparable results with EMLP using only $26\\%$ of the parameters, while KANs do not outperform MLPs as expected."
    },
    {
        "title": "HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale",
        "link_suffix": "/forum?id=PZf4RsPMBG",
        "link": "https://openreview.net/forum?id=PZf4RsPMBG",
        "pdf_link": "https://openreview.net/pdf?id=PZf4RsPMBG",
        "keywords": "Multi-Agent, Large Language Model, Software Engineering",
        "abstract": "Large Language Models (LLMs) have revolutionized software engineering (SE), demonstrating remarkable capabilities in various coding tasks. While recent efforts have produced autonomous software\nagents based on LLMs for end-to-end development tasks, these systems are typically designed for\nspecific SE tasks. We introduce HyperAgent , a novel generalist multi-agent system designed to\naddress a wide spectrum of SE tasks across different programming languages by mimicking human\ndevelopers\u2019 workflows. Comprising four specialized agents\u2014Planner, Navigator, Code Editor, and Executor\u2014HyperAgent manages the full lifecycle of SE tasks, from initial conception to final verification.\nThrough extensive evaluations, HyperAgent achieves state-of-the-art performance across diverse\nSE tasks: it attains a 26.00% success rate on SWE-Bench-Lite and 33.00% on SWE-Bench-Verified for\nGitHub issue resolution, surpassing existing methods. Furthermore, HyperAgent demonstrates\nsuperior performance in code generation at repository scale (RepoExec), and in fault localization and\nprogram repair (Defects4J), often outperforming specialized systems. This work represents a significant\nadvancement towards versatile, autonomous agents capable of handling complex, multi-step SE tasks\nacross various domains and languages, potentially transforming AI-assisted software development\npractices."
    },
    {
        "title": "ExID: Offline RL with Intuitive Expert Insights in Limited-Data Settings",
        "link_suffix": "/forum?id=o0BEth0Po3",
        "link": "https://openreview.net/forum?id=o0BEth0Po3",
        "pdf_link": "https://openreview.net/pdf?id=o0BEth0Po3",
        "keywords": "Offline Reinforcement Learning, Knowledge distillation",
        "abstract": "With the ability to learn from static datasets, Offline Reinforcement Learning (RL) emerges as a compelling avenue for real-world applications. However, state-of-the-art offline RL algorithms perform sub-optimally when confronted with limited data confined to specific regions within the state space. The performance degradation is attributed to the inability of offline RL algorithms to learn appropriate actions for rare or unseen observations. This paper proposes a novel domain knowledge-based regularization technique and adaptively refines the initial domain knowledge to considerably boost performance in limited data with partially omitted states. The key insight is that the regularization term mitigates erroneous actions for sparse samples and unobserved states covered by domain knowledge. Empirical evaluations on standard offline RL datasets demonstrate a substantial average performance increase compared to ensemble of domain knowledge and existing offline RL algorithms operating on limited data."
    },
    {
        "title": "PREMIUM: LLM Personalization with Individual-level Preference Feedback",
        "link_suffix": "/forum?id=N1pya6kv3g",
        "link": "https://openreview.net/forum?id=N1pya6kv3g",
        "pdf_link": "https://openreview.net/pdf?id=N1pya6kv3g",
        "keywords": "Preference Ranking, Tagging System, LLM Personalization, Prompt-Based, Embedding-Based",
        "abstract": "With an increasing demand for LLM personalization, various methods have been developed to deliver customized LLM experiences, including in-context learning, retrieval augmentation, and parameter-efficient fine-tuning. However, most existing methods are not readily locally deployable, limited by the compute cost, privacy risks, and an inability to adapt to dynamic user preferences. Here, we propose to use a tag system to efficiently characterize user profiles, inspired from the insights from personality typology and recommendation systems. Based on the observation, we present a locally deployable LLM-agnostic framework for achieving LLM personalization: $\\textbf{PREMIUM}$ ($\\textbf{P}$reference $\\textbf{R}$anking $\\textbf{EM}$powered $\\textbf{I}$ndividual $\\textbf{U}$ser $\\textbf{M}$odeling), which obtains individual-level feedback by having users rank responses and continuously self-iterates optimization during the interaction between the user and the LLM. Notably, a variant of PREMIUM, PREMIUM-Embed, can effectively capture user preferences while being deployable with laptop-level resources. Besides algorithmic innovation, we further prepare a novel dataset, Ranking-TAGER, which provides a valuable evaluation protocol for LLM personalization. Extensive experiments validate that PREMIUM remarkably outperforms various baselines, achieving a 15%-50% higher accuracy and a 2.5%-35% higher win rate on Ranking-TAGER, as well as a 3%-13% higher accuracy and a 2%-7.5% higher F1 Score on LaMP-2. More importantly, we further demonstrate that PREMIUM can develop an effective strategy with minimal interactive data, adapt to dynamic user preferences, and demonstrate excellent scalability in both scale and functionality."
    },
    {
        "title": "CoLoRA: A Competitive Learning Approach for Enhancing LoRA",
        "link_suffix": "/forum?id=jFcNXJGPGh",
        "link": "https://openreview.net/forum?id=jFcNXJGPGh",
        "pdf_link": "https://openreview.net/pdf?id=jFcNXJGPGh",
        "keywords": "Parametric-efficient fine-tuning",
        "abstract": "We propose a Competitive Low-Rank Adaptation (CoLoRA) framework to address the limitations of the LoRA method, which either lacks capacity with a single rank-$r$ LoRA or risks inefficiency and overfitting with a larger rank-$Kr$ LoRA, where $K$ is an integer larger than 1. The proposed CoLoRA method initializes $K$ distinct LoRA components, each with rank $r$, and allows them to compete during training. This competition drives each LoRA component to outperform the others, improving overall model performance. The best-performing LoRA is selected based on validation metrics, ensuring that the final model outperforms a single rank-$r$ LoRA and matches the effectiveness of a larger rank-$Kr$ LoRA, all while avoiding extra computational overhead during inference. To the best of our knowledge, this is the first work to introduce and explore competitive learning in the context of LoRA optimization. The CoLoRA's code will be released later."
    },
    {
        "title": "Addressing Extrapolation Error in Multi-Agent Reinforcement Learning",
        "link_suffix": "/forum?id=4fJghLR3hk",
        "link": "https://openreview.net/forum?id=4fJghLR3hk",
        "pdf_link": "https://openreview.net/pdf?id=4fJghLR3hk",
        "keywords": "cooperative multi-agent reinforcement learning, CTDE, value factorization, extrapolation error",
        "abstract": "Cooperative Multi-Agent Reinforcement Learning (MARL) has become a critical tool for addressing complex real-world problems. \nHowever, scalability remains a significant challenge due to the exponentially growing joint action space. \nIn our analysis, we highlight a critical but often overlooked issue:extrapolation error, which arises when unseen state-action pairs are inaccurately assigned unrealistic values, severely affecting performance. \nWe demonstrate that the success of value factorization methods can be largely attributed to their ability to mitigate this error. \nBuilding on this insight, we introduce multi-step bootstrapping and ensemble techniques to further reduce extrapolation errors, showing that straightforward modifications can lead to substantial performance improvements. Our findings underscore the importance of recognizing extrapolation error in MARL and highlight the potential of exploring simpler methods to advance the field."
    },
    {
        "title": "Adapting Multi-modal Large Language Model to Concept Drift From Pre-training Onwards",
        "link_suffix": "/forum?id=b20VK2GnSs",
        "link": "https://openreview.net/forum?id=b20VK2GnSs",
        "pdf_link": "https://openreview.net/pdf?id=b20VK2GnSs",
        "keywords": "Concept Drift, Multi-modal Large Language Model, Data Defect",
        "abstract": "Multi-modal Large Language Models (MLLMs) frequently face challenges from concept drift when dealing with real-world streaming data, wherein distributions change unpredictably. This mainly includes gradual drift due to long-tailed data and sudden drift from Out-Of-Distribution (OOD) data, both of which have increasingly drawn the attention of the research community. While these issues have been extensively studied in the individual domain of vision or language, their impacts on MLLMs in concept drift settings remain largely underexplored.  In this paper, we reveal the susceptibility and vulnerability of Vision-Language (VL) models to significant biases arising from gradual drift and sudden drift, particularly in the pre-training.  To effectively address these challenges, we propose a unified framework that extends concept drift theory to the multi-modal domain, enhancing the adaptability of the VL model to the distribution unpredictable changes. Additionally, a T-distribution based drift adapter is proposed to effectively mitigate the bias induced by the gradual drift, which also facilitates the model in distinguishing sudden distribution changes through explicit distribution modeling. Extensive experiments demonstrate our method enhances the efficiency and accuracy of image-text alignment in the pre-training of VL models, particularly in the concept drift scenario. Moreover, various downstream tasks exhibit significant improvements in our model's ability to adapt to the long-tailed open world. Furthermore, we create a set of multi-modal datasets called OpenMMlo, specifically tailored for the long-tailed open world settings, to validate our findings. To foster the development of the multi-modal community, we have made both OpenMMlo datasets and our code publicly available at: \\url{https://github.com/Anonymous0Knight/ConceptDriftMLLMs}."
    },
    {
        "title": "TerDiT: Ternary Diffusion Models with Transformers",
        "link_suffix": "/forum?id=MVQj0uajaF",
        "link": "https://openreview.net/forum?id=MVQj0uajaF",
        "pdf_link": "https://openreview.net/pdf?id=MVQj0uajaF",
        "keywords": "model quantization, quantization-aware training, diffusion models",
        "abstract": "Recent developments in large-scale pre-trained text-to-image diffusion models have significantly improved the generation of high-fidelity images, particularly with the emergence of diffusion transformer models (DiTs). Among diffusion models, diffusion transformers have demonstrated superior image generation capabilities, boosting lower FID scores and higher scalability. However, deploying large-scale DiT models can be expensive due to their excessive parameter numbers. Although existing research has explored efficient deployment techniques for diffusion models such as model quantization, there is still little work concerning DiT-based models. To tackle this research gap, in this paper, we proposeTerDiT, a quantization-aware training (QAT) and efficient deployment scheme for ternary diffusion transformer models. We focus on the ternarization of DiT networks, with model sizes ranging from 600M to 4.2B, and image resolution from 256$\\times$256 to 512$\\times$512. Our work contributes to the exploration of efficient deployment of large-scale DiT models, demonstrating the feasibility of training extremely low-bit DiT models from scratch while maintaining competitive image generation capacities compared to full-precision models. Code has been uploaded in the supplemental materials."
    },
    {
        "title": "GPT Shortcuts: Learning Iterative Text Generation Patterns from a Dialogue",
        "link_suffix": "/forum?id=ES9uz5Qa5W",
        "link": "https://openreview.net/forum?id=ES9uz5Qa5W",
        "pdf_link": "https://openreview.net/pdf?id=ES9uz5Qa5W",
        "keywords": "Large Language Models, Shortcuts, Iterative text generations, Reusable functions, Conversational AI",
        "abstract": "LLM-powered conversational interfaces (e.g., ChatGPT, Claude, and Gemini) support iterative text generation, enabling users to easily generate tailored texts (e.g., texts that should address domain-specific constraints) through a series of follow-up text editing requests. However, generating such tailored texts that address the user-specified constraints across multiple different contexts requires repetitive text generation efforts, which is cumbersome, inefficient, and demanding. To address this challenge, we introduce the concept ofGPT shortcuts, which is designed to 1) learn iterative text generation patterns from a dialogue and 2) apply these learned patterns todirectlygenerate the tailored text. GPT shortcuts generate texts that address necessary constraints while maintaining similar structural appearance to the target text in the dialogue, across different contexts. To assess the capability of language models in generating GPT shortcuts, we present ShortcutBench, a benchmark consisting of 250 crowdsourced iterative text generation dialogues across five text generation tasks. Using ShortcutBench, we conducted an analysis using six LLMs and four prompting methods, varying ways to specify necessary constraints to address in the prompt. We found that 1) larger models generally outperform smaller models, 2) self-explanatory constraints within the target text are effective, and 3) precisely specifying necessary constraints to address is critical for improving the performance."
    },
    {
        "title": "Dual-Modality Guided Prompt for Continual Learning of Large Multimodal Models",
        "link_suffix": "/forum?id=04TRw4pYSV",
        "link": "https://openreview.net/forum?id=04TRw4pYSV",
        "pdf_link": "https://openreview.net/pdf?id=04TRw4pYSV",
        "keywords": "Continual learning, Large multimodal models, Efficient learning, Prompt learning",
        "abstract": "Large Multimodal Models (LMMs) exhibit remarkable multi-tasking ability by learning mixed datasets jointly. However, novel tasks would be encountered sequentially in dynamic world, and continually fine-tuning LMMs often leads to performance degrades. To handle the challenges of catastrophic forgetting, existing methods leverage data replay or model expansion, both of which are not specially developed for LMMs and have their inherent limitations. In this paper, we propose a novel dual-modality guided prompt learning framework (ModalPrompt) tailored for multimodal continual learning to effectively learn new tasks while alleviating forgetting of previous knowledge. Concretely, we learn prototype prompts for each task and exploit efficient prompt selection for task identifiers and prompt fusion for knowledge transfer based on image-text supervision. Extensive experiments demonstrate the superiority of our approach, e.g., ModalPrompt achieves +20% performance gain on LMMs continual learning benchmarks with x1.42 inference speed refraining from growing training cost in proportion to the number of tasks. The code will be made publically available."
    },
    {
        "title": "HiRA: Parameter-Efficient Hadamard High-Rank Adaptation for Large Language Models",
        "link_suffix": "/forum?id=TwJrTz9cRS",
        "link": "https://openreview.net/forum?id=TwJrTz9cRS",
        "pdf_link": "https://openreview.net/pdf?id=TwJrTz9cRS",
        "keywords": "Parametric-efficient fine-tuning, Large Language Model",
        "abstract": "We propose Hadamard High-Rank Adaptation (HiRA), a parameter-efficient fine-tuning (PEFT) method that enhances the adaptability of Large Language Models (LLMs). While Low-rank Adaptation (LoRA) is widely used to reduce resource demands, its low-rank updates may limit its expressiveness for new tasks. HiRA addresses this by using a Hadamard product to retain high-rank update parameters, improving the model capacity. Empirically, HiRA outperforms LoRA and its variants on several tasks, with extensive ablation studies validating its effectiveness. Our code will be released."
    },
    {
        "title": "RECAST: Reparameterized, Compact weight Adaptation for Sequential Tasks",
        "link_suffix": "/forum?id=J3H8Az3YlB",
        "link": "https://openreview.net/forum?id=J3H8Az3YlB",
        "pdf_link": "https://openreview.net/pdf?id=J3H8Az3YlB",
        "keywords": "reparameterization, weight decomposition, weight reconstruction, task-incremental learning, transfer learning, lifelong learning, incremental learning",
        "abstract": "Incremental learning aims to adapt to new sets of categories over time with minimal computational overhead. Prior work often addresses this task by training efficient task-specific adaptors that modify frozen layer weights or features to capture relevant information without affecting predictions on any previously learned categories. While these adaptors are generally more efficient than finetuning the entire network, they still can require tens to hundreds of thousands task-specific trainable parameters even for relatively small networks, making it challenging to operate on resource-constrained environments with high communication costs like edge devices or mobile phones. Thus, we propose Reparameterized, Compact weight Adaptation for Sequential Tasks (RECAST), a novel method that dramatically reduces the number of task-specific trainable parameters to fewer than 50 \u2013 several orders of magnitude less than competing methods like LoRA. RECAST accomplishes this efficiency by learning to decompose layer weights into a soft parameter-sharing framework consisting of a set of shared weight templates and very few module-specific scaling factors or coefficients. This soft parameter-sharing framework allows for effective task-wise reparameterization by tuning only these coefficients while keeping templates frozen. A key innovation of RECAST is the novel weight reconstruction pipeline called Neural Mimicry, which eliminates the need for pretraining from scratch. This allows for high-fidelity emulation of existing pretrained weights within our framework and provides quick adaptability to any model scale and architecture. Extensive experiments across six diverse datasets demonstrate RECAST outperforms the state-of-the-art by up to 3% across various scales, architectures, and parameter spaces. Moreover, we show that RECAST\u2019s architecture-agnostic nature allows for seamless integration with existing methods, further boosting performance."
    },
    {
        "title": "Tropical Geometry Features for Novelty Detection and interpretability",
        "link_suffix": "/forum?id=OXfllUhjrJ",
        "link": "https://openreview.net/forum?id=OXfllUhjrJ",
        "pdf_link": "https://openreview.net/pdf?id=OXfllUhjrJ",
        "keywords": "OOD, Tropical geometry, Deep neural network, polytopes",
        "abstract": "Existing methods for critical tasks such as out-of-distribution (OOD) detection,\nuncertainty quantification, and adversarial robustness often focus on measuring\nthe output of the last or intermediate layers of a neural network such as logits and\nenergy score. However, these methods typically overlook the geometric properties\nof the learned representations in the latent space, failing to capture important\nsignals that relate to model reliability, fairness, and adversarial vulnerability.Innovations: We introduce an innovative method, termed Tropical Geometry Features (TGF), for detecting out-of-distribution data and enhancing overall model evaluation. This approach leverages the geometric properties of polytopes derived\nfrom a trained neural network\u2019s learned representations. By integrating these\ngeometric features with the data used during training, TGF establishes a unique\nsignature of in-distribution data points. Our framework extends beyond OOD\ndetection, providing insights into model uncertainty, adversarial robustness, interpretability, and fairness. Through TGF, we enhance interpretability technique to detect OOD, uncertainty, adverserial robustness in dynamic and unpredictable\nenvironments."
    },
    {
        "title": "Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions",
        "link_suffix": "/forum?id=PkpNRmBZ32",
        "link": "https://openreview.net/forum?id=PkpNRmBZ32",
        "pdf_link": "https://openreview.net/pdf?id=PkpNRmBZ32",
        "keywords": "state-space models; convolution; tensor networks; audio processing; speech recognition",
        "abstract": "We introduce Centaurus, a class of networks composed of generalized state-space model (SSM) blocks, where the SSM operations can be treated as tensor contractions during training. The optimal order of tensor contractions can then be systematically determined for every SSM block to maximize training efficiency. This allows more flexibility in designing SSM blocks beyond the depthwise-separable configuration commonly implemented. The new design choices will take inspiration from classical convolutional blocks including group convolutions, full convolutions, and bottleneck blocks. We architect the Centaurus network with a mixture of these blocks, to balance between network size and performance, as well as memory and computational efficiency during both training and inference. We show that this heterogeneous network design outperforms its homogeneous counterparts in raw audio processing tasks including keyword spotting, speech denoising, and automatic speech recognition (ASR). For ASR, Centaurus is the first network with competitive performance that can be made fully state-space based, without using any nonlinear recurrence (LSTMs), explicit convolutions (CNNs), or (surrogate) attention mechanism."
    },
    {
        "title": "Hallucination in LVLMs: Fictitious Presupposition Questions, Benchmark, and Solution",
        "link_suffix": "/forum?id=srg4XYZA1W",
        "link": "https://openreview.net/forum?id=srg4XYZA1W",
        "pdf_link": "https://openreview.net/pdf?id=srg4XYZA1W",
        "keywords": "Large Vision Language Model, Hallucination, Synthetic Data, Preference Alignment",
        "abstract": "Large Vision-Language Models (LVLMs) have achieved impressive performance across various vision-language tasks. However, hallucinations, i.e., generating counterfactual responses, remain a significant challenge. Although recent models have mitigated hallucinations in tasks such as object existence and image description, they primarily address hallucinations in response generation while overlooking the task question itself. This paper highlights the vulnerability of LVLMs in solving fictitious presupposition questions (FPQs), where the models are prone to accept the presuppositions of non-existent objects and produce severe hallucinatory responses. To this end, we first introduce a novel benchmark, VFP-Bench, to evaluate LVLMs' capability to discriminate fictitious presuppositions and generate factual responses. Moreover, we introduce Antidote, a universal, synthetic data-driven self-correction solution for alleviating hallucination in FPQs and conventional tasks. It leverages synthetic data to incorporate factual priors into questions/queries to achieve self-correction, decoupling hallucination alleviation into a preference optimization problem. Applied to the LLaVA series, it enhances performance on VFP-Bench by over 50%, POPE by 1.8\u20133.3%, and CHAIR & SHR by 30\u201350%, without relying on external supervision from stronger LVLMs or human feedback and introducing noticeable catastrophic forgetting issues."
    },
    {
        "title": "Aligning Large Language Models with Domain Adaptation",
        "link_suffix": "/forum?id=t5mpbfpZuF",
        "link": "https://openreview.net/forum?id=t5mpbfpZuF",
        "pdf_link": "https://openreview.net/pdf?id=t5mpbfpZuF",
        "keywords": "alignment, domain adaptation, large language models, generalization",
        "abstract": "Aligning large language models (LLMs) has emerged as a critical challenge in the age of generative AI: LLMs must be appropriately aligned with human values and preferences in order to be helpful and harmless. In many real world cases, however, large amounts of preference data are not available on important tasks, limiting the effectiveness of resulting reward models. In some cases, data from a similar task is available, and unlabeled data on the target task is available or can be generated by an LLM. In other cases, clean data may be available to train an LLM for real-world use on noisy data, small amounts of labeled data on the target task may be available, or data may be available on an easier task. In this work, we demonstrate that domain adaptation can effectively use different types of data, by transferring supervision and human values across tasks with similar data distributions, strengthening resistance to noisy data, improving few-shot generalization ability, and even transfer from easy to hard tasks, in the form of short to long generalization. Specifically, we propose Data Efficient Alignment for Language (DEAL), using domain adaptation to effectively perform cross-task alignment in scenarios where labeled target data is not available. We evaluate our method for reward model training on a variety of benchmarks and demonstrate that our method can meaningfully improve performance on target tasks by utilizing data on related tasks or low amounts of data. Furthermore, we  offer analysis on the inner mechanism of domain adaptation and the alignment of embedding distributions."
    },
    {
        "title": "PivotMesh: Generic 3D Mesh Generation via Pivot Vertices Guidance",
        "link_suffix": "/forum?id=WAC8LmlKYf",
        "link": "https://openreview.net/forum?id=WAC8LmlKYf",
        "pdf_link": "https://openreview.net/pdf?id=WAC8LmlKYf",
        "keywords": "mesh generation, auto-regressive generation, 3D generation",
        "abstract": "Generating compact and sharply detailed 3D meshes poses a significant challenge for current 3D generative models. Different from extracting dense meshes from neural representation, some recent works try to model the native mesh distribution (i.e., a set of triangles), which generates more compact results as humans crafted. However, due to the complexity and variety of mesh topology, these methods are typically limited to small datasets with specific categories and are hard to extend. In this paper, we introduce a generic and scalable mesh generation framework PivotMesh, which makes an initial attempt to extend the native mesh generation to large-scale datasets. We employ a transformer-based auto-encoder to encode meshes into discrete tokens and decode them from face level to vertex level hierarchically. Subsequently, to model the complex typology, we first learn to generate pivot vertices as coarse mesh representation and then generate the complete mesh tokens with the same auto-regressive Transformer. This reduces the difficulty compared with directly modeling the mesh distribution and further improves the model controllability. PivotMesh demonstrates its versatility by effectively learning from both small datasets like Shapenet, and large-scale datasets like Objaverse and Objaverse-xl. Extensive experiments indicate that PivotMesh can generate compact and sharp 3D meshes across various categories, highlighting its great potential for native mesh modeling."
    },
    {
        "title": "Faster Algorithms for Structured Linear and Kernel Support Vector Machines",
        "link_suffix": "/forum?id=DDNFTaVQdU",
        "link": "https://openreview.net/forum?id=DDNFTaVQdU",
        "pdf_link": "https://openreview.net/pdf?id=DDNFTaVQdU",
        "keywords": "interior point method, support vector machine, data structure",
        "abstract": "Quadratic programming is a ubiquitous prototype in convex programming. Many machine learning problems can be formulated as quadratic programming, including the famous Support Vector Machines (SVMs). Linear and kernel SVMs have been among the most popular models in machine learning over the past three decades, prior to the deep learning era.Generally, a quadratic program has an input size of $\\Theta(n^2)$, where $n$ is the number of variables. Assuming the Strong Exponential Time Hypothesis ($\\textsf{SETH}$), it is known that no $O(n^{2-o(1)})$ time algorithm exists when the quadratic objective matrix is positive semidefinite (Backurs, Indyk, and Schmidt, NeurIPS'17). However, problems such as SVMs usually admit much smaller input sizes: one is given $n$ data points, each of dimension $d$, and $d$ is oftentimes much smaller than $n$. Furthermore, the SVM program has only $O(1)$ equality linear constraints. This suggests that faster algorithms are feasible, provided the program exhibits certain structures.In this work, we design the first nearly-linear time algorithm for solving quadratic programs whenever the quadratic objective admits a low-rank factorization, and the number of linear constraints is small. Consequently, we obtain results for SVMs:For linear SVM when the input data is $d$-dimensional, our algorithm runs in time $\\widetilde O(nd^{(\\omega+1)/2}\\log(1/\\epsilon))$ where $\\omega\\approx 2.37$ is the fast matrix multiplication exponent;For Gaussian kernel SVM, when the data dimension $d = \\Theta(\\log n)$ and the squared dataset radius is sub-logarithmic in $n$, our algorithm runs in time $O(n^{1+o(1)}\\log(1/\\epsilon))$. We also prove that when the squared dataset radius is at least $\\Omega(\\log^2 n)$, then $\\Omega(n^{2-o(1)})$ time is required. This improves upon the prior best lower bound in both the dimension $d$ and the squared dataset radius."
    },
    {
        "title": "Confidence Difference Reflects Various Supervised Signals in Confidence-Difference Classification",
        "link_suffix": "/forum?id=a5EC2R1NeS",
        "link": "https://openreview.net/forum?id=a5EC2R1NeS",
        "pdf_link": "https://openreview.net/pdf?id=a5EC2R1NeS",
        "keywords": "Confidence-Difference Classification, Binary Classification, Weakly Supervised Learning",
        "abstract": "Training a precise binary classifier with limited supervision in weakly supervised learning scenarios holds significant research significance in practical settings. Leveraging pairwise unlabeled data with confidence differences has been demonstrated to outperform learning from pointwise unlabeled data. However, challenges arise when attempting to fit large-scale real-world datasets and employing adequately complex backbones. This often results in the concentration of the confidence difference distribution around specific values, thereby neglecting the genuine distribution influenced by real-world noise. Hence, this paper proposes a novel confidence difference (ConfDiff) classification to adequately account for the true noise-influenced confidence difference distribution. Specifically, we introduce a noise generation method to perturb the confidence difference distribution to better fit real-world scenarios. Furthermore, we theoretically analyze various supervised signals reflected by confidence difference values in ConfDiff classification. Based on this analysis, we introduce a risk estimation that leverages consistency risk and consistency regularization, deriving its estimation error bound. Extensive experiments on benchmark and UCI datasets demonstrate the effectiveness of our method."
    },
    {
        "title": "Uni-Sign: Toward Unified Sign Language Understanding at Scale",
        "link_suffix": "/forum?id=0Xt7uT04cQ",
        "link": "https://openreview.net/forum?id=0Xt7uT04cQ",
        "pdf_link": "https://openreview.net/pdf?id=0Xt7uT04cQ",
        "keywords": "Sign language understanding, Pre-training, Large-scale sign language dataset",
        "abstract": "Sign language pre-training has gained increasing attention for its ability to enhance performance across various sign language understanding (SLU) tasks. However, existing methods often suffer from a gap between pre-training and fine-tuning, leading to suboptimal results. To address this, we propose Uni-Sign, a unified pre-training framework that eliminates the gap between pre-training and downstream SLU tasks through a large-scale generative pre-training strategy and a novel fine-tuning paradigm. First, we introduce CSL-News, a large-scale Chinese Sign Language (CSL) dataset containing 1,985 hours of video paired with textual annotations, which enables effective large-scale pre-training. Second, Uni-Sign unifies SLU tasks by treating downstream tasks as a single sign language translation (SLT) task during fine-tuning, ensuring seamless knowledge transfer between pre-training and fine-tuning. Furthermore, we incorporate a prior-guided fusion (PGF) module and a score-aware sampling strategy to efficiently fuse pose and RGB information, addressing keypoint inaccuracies and improving computational efficiency.  Extensive experiments across multiple SLU benchmarks demonstrate that Uni-Sign achieves state-of-the-art performance across multiple downstream SLU tasks. We will release the source code and the dataset to the public."
    },
    {
        "title": "Sparse Hyperspectral Band Selection Based on Expectation Maximization",
        "link_suffix": "/forum?id=o4mvfEWbsP",
        "link": "https://openreview.net/forum?id=o4mvfEWbsP",
        "pdf_link": "https://openreview.net/pdf?id=o4mvfEWbsP",
        "keywords": "Hyperspectral Band Selection, Sparse Learning, Feature Selection, Hyperspectral Image Classification, EM Algorithm",
        "abstract": "Band selection is crucial in spectral imaging, as it involves choosing the most relevant bands from large hyperspectral datasets to retain essential information while reducing the burden of data transmission and analysis. Addressing this need, we introduce a novel method for band selection that utilizes an Expectation Maximization algorithm to facilitate selection through the sparsification of spectral band importance. Our method enhances sparsity effects and effectively delineates the relationships between spectral bands during the sparsification process. Supported by thorough theoretical analysis and experimental validation on public datasets, our approach has proven to be both robust and practical. Compared to other sparsification methods, it not only excels in achieving significant sparsity effects but also demonstrates marked advantages in illustrating inter-band relationships. Our method delivers outstanding performance in band selection tasks and holds potential for broader applications in other sparsity-oriented contexts in the future."
    },
    {
        "title": "HyDance: A Novel Hybrid  Dance Generation Network with temporal and  frequency features",
        "link_suffix": "/forum?id=vZK4pvHFd0",
        "link": "https://openreview.net/forum?id=vZK4pvHFd0",
        "pdf_link": "https://openreview.net/pdf?id=vZK4pvHFd0",
        "keywords": "Diffusion Models\uff0cMotion Generation",
        "abstract": "We propose HyDance, a diffusion network utilizing both the temporal and frequency-domain representations of dance motion sequences for music-driven dance motion generation. Existing dance generation methods primarily use temporal domain representations of dance motion in their networks, which often results in the network losing the sfrequency-domain characteristics of the dance. This manifests in overly smooth generated dance motion sequences, resulting in dance movements that lack dynamism.  From an aesthetic perspective, such overly smooth movements are perceived as lacking expressiveness and the sense of power. To address this issue, we designed HyDance, which incorporates independent temporal feature encoders and frequency-domain feature encoders. The model employs a shared-weight hybrid feature encoder, enabling the complementary extraction of motion information from both domains. By introducing compact frequency-domain features into the dance generation framework, our method mitigates the oversmoothing problem in generated dance motion sequences and achieves improved spatial and temporal alignment in the generation results. Experiments show that our method generates more expressive dance movements than existing methods and achieves better alignment with the music beats."
    },
    {
        "title": "FairGen: controlling fair generations in diffusion models via adaptive latent guidance",
        "link_suffix": "/forum?id=PgC5UqKDye",
        "link": "https://openreview.net/forum?id=PgC5UqKDye",
        "pdf_link": "https://openreview.net/pdf?id=PgC5UqKDye",
        "keywords": "fairness, bias, diffusion models",
        "abstract": "Diffusion models have shown remarkable proficiency in generating photorealistic images, but their outputs often exhibit biases toward specific social groups, raising ethical concerns and limiting their wider adoption. This paper tackles the challenge of mitigating generative bias in diffusion models while maintaining image quality. We propose FairGen, an adaptive latent guidance mechanism enhanced by an auxiliary memory module, which operates during inference to control the generation distribution at a desired level. The latent guidance module dynamically adjusts the direction in the latent space to influence specific attributes, while the memory module tracks prior generation statistics and steers the scalar direction to align with the target distribution. To evaluate FairGen comprehensively, we introduce a bias evaluation benchmark tailored for diffusion models, spanning diverse domains such as employment, education, finance, and healthcare, along with complex user-generated prompts. Extensive empirical evaluations demonstrate that FairGen outperforms existing bias mitigation approaches, achieving substantial bias reduction while preserving generation quality. Furthermore, FairGen offers precise and flexible control over various target distributions, enabling nuanced adjustments to the generative process."
    },
    {
        "title": "Solving Continual Offline RL through Selective Weights Activation on Aligned Spaces",
        "link_suffix": "/forum?id=Hr3TBaZl4S",
        "link": "https://openreview.net/forum?id=Hr3TBaZl4S",
        "pdf_link": "https://openreview.net/pdf?id=Hr3TBaZl4S",
        "keywords": "continual offline reinforcement learning",
        "abstract": "Continual offline reinforcement learning (CORL) has shown impressive ability in diffusion-based lifelong learning systems by modeling the joint distributions of trajectories. However, most research only focuses on limited continual task settings where the tasks have the same observation and action space, which deviates from the realistic demands of training agents in various environments. In view of this, we propose Vector-Quantized Continual Diffuser, named VQ-CD, to break the barrier of different spaces between various tasks. Specifically, our method contains two complementary sections, where the quantization spaces alignment provides a unified basis for the selective weights activation. In the quantized spaces alignment, we leverage vector quantization to align the different state and action spaces of various tasks, facilitating continual training in the same space. Then, we propose to leverage a unified diffusion model attached by the inverse dynamic model to master all tasks by selectively activating different weights according to the task-related sparse masks. Finally, we conduct extensive experiments on 15 continual learning (CL) tasks, including conventional CL task settings (identical state and action spaces) and general CL task settings (various state and action spaces). Compared with 16 baselines, our method reaches the SOTA performance."
    },
    {
        "title": "Not All Noises Are Created Equally: Diffusion Noise Selection and Optimization",
        "link_suffix": "/forum?id=R5xozf2ZoP",
        "link": "https://openreview.net/forum?id=R5xozf2ZoP",
        "pdf_link": "https://openreview.net/pdf?id=R5xozf2ZoP",
        "keywords": "Diffusion Models, Optimization, Generative AI, Text-to-Image Generation",
        "abstract": "Diffusion models that can generate high-quality data from randomly sampled Gaussian noises have become the mainstream generative method in academia and industry. Are randomly sampled Gaussian noises equally effective for diffusion models? Some methods explore the impact of noise variations on the results, but they either do not operate in the pure noise space, requiring additional evaluation models, or cannot be adapted to general text-to-image tasks. In this paper, we mainly made three contributions. First, we are the first to hypothesize and empirically observe that the generation quality of diffusion models significantly depends on the noise inversion stability. This naturally provides a noise quality metric for noise selection, grounded in a mathematical property. Second, we further propose a novel noise optimization method that actively enhances the inversion stability of arbitrary given noises. Our method is the first one that works purely on noise space for general text-to-image without fine-tuning model parameters or relying on additional result quality evaluators. Third, our extensive experiments demonstrate that the proposed noise selection and noise optimization methods both significantly improve representative diffusion models, such as SDXL and SDXL-turbo, in terms of human preference and other objective evaluation metrics. For example, the human preference winning rates of noise selection and noise optimization over the baselines can be up to 57% and 72.5%, respectively, on DrawBench."
    }
]
[
    {
        "title": "Dual-cycle Consistency Learning for Weakly Supervised Phrase Grounding",
        "link_suffix": "/forum?id=9IMQJ8HmIq",
        "link": "https://openreview.net/forum?id=9IMQJ8HmIq",
        "pdf_link": "https://openreview.net/pdf?id=9IMQJ8HmIq",
        "keywords": "Weakly supervised phrase grounding, visual grounding, visual consistency learning, textual consistency learning",
        "abstract": "Weakly supervised phrase grounding (WSPG) aims to localize objects referred by phrases without region-level annotations. The state-of-the-art methods use vision-language pre-trained (VLP) models to build pseudo labels. However, their low quality could result in the ineffectiveness of the subsequent learning. In this paper, we propose a novel WSPG framework, Dual-cycle Consistency Learning (DCL). Firstly, we propose a vision-modal cycle consistency to localize the referred objects and reconstruct the pseudo labels. To provide a conditional guidance, we propose a visual prompt engineering to generate marks for input images. To further avoid localizing randomly, we design a confidence-based regularization to filter out redundant information in image and pixel levels. Secondly, we propose a language-modal cycle consistency to correctly recognize the referred objects. To correct their positions, we provide phrase-related boxes as supervision for further  learning. Extensive experiments on benchmark datasets show the effectiveness of DCL, as well as its excellent compatibility with various VLP models. The source code will be available at GitHub after double-blind phase."
    },
    {
        "title": "Metadata Matters for Time Series: Informative Forecasting with Transformers",
        "link_suffix": "/forum?id=NJqsHgxcKh",
        "link": "https://openreview.net/forum?id=NJqsHgxcKh",
        "pdf_link": "https://openreview.net/pdf?id=NJqsHgxcKh",
        "keywords": "time series forecasting, deep time series analysis, large language models",
        "abstract": "Time series forecasting is prevalent in extensive real-world applications, such as financial analysis and energy planning. Previous studies primarily focus on time series modality, endeavoring to capture the intricate variations and dependencies inherent in time series. Beyond numerical time series data, we notice that metadata (e.g. dataset and variate descriptions) also carries valuable information essential for forecasting, which can be used to identify the application scenario and provide more interpretable knowledge than digit sequences. Inspired by this observation, we propose a Metadata-informed Time Series Transformer MetaTST, which incorporates multiple levels of context-specific metadata into Transformer forecasting models to enable informative time series forecasting. To tackle the unstructured nature of metadata, MetaTST formalizes them into natural languages by pre-designed templates and leverages large language models (LLMs) to encode these texts into metadata tokens as a supplement to classic series tokens, resulting in an informative embedding. Further, a Transformer encoder is employed to communicate series and metadata tokens, which can extend series representations by metadata information for more accurate forecasting. This design also allows the model to adaptively learn context-specific patterns across various scenarios, which is particularly effective in handling large-scale, diverse-scenario forecasting tasks. Experimentally, MetaTST achieves state-of-the-art compared to advanced time series models and LLM-based methods on widely acknowledged short- and long-term forecasting benchmarks, covering both single-dataset individual and multi-dataset joint training settings."
    },
    {
        "title": "Overcoming Missing Label Vocabulary in Black-Box Discrete Prompt Learning",
        "link_suffix": "/forum?id=B0jjj5RiAQ",
        "link": "https://openreview.net/forum?id=B0jjj5RiAQ",
        "pdf_link": "https://openreview.net/pdf?id=B0jjj5RiAQ",
        "keywords": "Prompt learning, LLM",
        "abstract": "Large language models (LLMs) have transformed natural language processing. While their scale challenges fine-tuning downstream tasks, prompt engineering offers a scalable, cost-effective solution to optimize their performance. Black-box prompt learning is crucial for leveraging the generative abilities of LLMs, especially in the Language-Model-as-a-Service scenario, where parameters and gradients are inaccessible. LLMs generate output exclusively in the form of encoded tokens processed through their backbone network. Existing black-box prompt learning methods rely on outputs corresponding to a predefined label vocabulary\u2014a small subset of the token vocabulary of LLMs\u2014to optimize prompts. However, in real-world applications, some datasets lack specific label vocabulary, and even manually assigned labels may perform inconsistently across different LLMs. To address these challenges, in this paper, we propose a novel label-vocabulary-free black-box discrete prompt learning method. Our approach employs an alternating optimization strategy to simultaneously learn discrete prompt tokens and a learnable matrix that directly maps the outputs of LLMs corresponding to the token vocabulary to categories. We provide theoretical convergence guarantees for our method under standard assumptions, ensuring its reliability. Experiments show that our method effectively learns prompts and outperforms existing baselines on datasets without label vocabulary."
    },
    {
        "title": "Dog-IQA: Standard-guided Zero-shot MLLM for Mix-grained Image Quality Assessment",
        "link_suffix": "/forum?id=U3EzVIsyiP",
        "link": "https://openreview.net/forum?id=U3EzVIsyiP",
        "pdf_link": "https://openreview.net/pdf?id=U3EzVIsyiP",
        "keywords": "Multimodal LLM, IQA",
        "abstract": "Image quality assessment (IQA) serves as the golden standard for all models' performance in nearly all computer vision fields. However, it still suffers from poor out-of-distribution generalization ability and expensive training costs. To address these problems, we propose Dog-IQA, a standard-guided zero-shot mix-grained IQA method, which is training-free and utilizes the exceptional prior knowledge of multimodal large language models (MLLMs). To obtain accurate IQA scores, namely scores consistent with humans, we design an MLLM-based inference pipeline that imitates human experts. In detail, Dog-IQA applies two techniques. First, Dog-IQA objectively scores with specific standards that utilize MLLM's behavior pattern and minimize the influence of subjective factors. Second, Dog-IQA comprehensively takes local semantic objects and the whole image as input and aggregates their scores, leveraging local and global information. Our proposed Dog-IQA achieves state-of-the-art (SOTA) performance compared with training-free methods, and competitive performance compared with training-based methods in cross-dataset scenarios. Our code will be released soon."
    },
    {
        "title": "RePaFormer: Ferocious and Scalable Acceleration of MetaFormers via Structural Reparamterization",
        "link_suffix": "/forum?id=EbG3PV7RaN",
        "link": "https://openreview.net/forum?id=EbG3PV7RaN",
        "pdf_link": "https://openreview.net/pdf?id=EbG3PV7RaN",
        "keywords": "Efficient ViT, Structural Reparameterization, FFN Acceleration",
        "abstract": "We reveal that in the realm of Vision Transformers (ViTs), the feed-forward network (FFN) layers play a significant role in introducing latencies. This effect scales up quickly as the model size escalates, and hence presents a major opportunity in efficiency optimization for ViTs by employing structural reparameterization on FFN layers. However, it is difficult to directly reparameterize linear projection weights due to the non-linear activation function in between. In this work, we propose an innovative channel idle mechanism that creates a linear pathway through the activation function, which facilitates structural reparameterization on FFN layers during the inference stage. Consequently, we present a family of efficient ViTs embedded with the introduced mechanism called $\\textbf{RePa}$rameterizable Vision Trans$\\textbf{formers}$ (RePaFormers). This technique brings remarkable latency reductions with small sacrifices (sometimes gains) in accuracy across various architectures investigated in the experiments, and the effect scales consistently with model sizes. For example, with DeiT, Swin Transformer and MLPMixer as backbones, their RePaFormer variants demonstrate increasing efficiency improvements and narrowing accuracy gaps as the model sizes grow. Specifically, the RePaFormer variants for DeiT-Base, Swin-Base, and MLPMixer-l16 achieve 67.5%, 49.7%, and 89.2% increase in throughput with minor changes in top-1 accuracy (-0.4%, -0.9% and +0.3%), respectively. Even larger improvements in speed and accuracy are expected when applied to larger models. Our work is the first to apply structural reparameterization on FFN layers to expedite ViTs to the best of our knowledge, and we believe that it represents an auspicious direction for efficient ViTs. Codes are provided in the supplementary material."
    },
    {
        "title": "Adversarial Attacks on Fine-tuned LLMs",
        "link_suffix": "/forum?id=9kR4MREN9E",
        "link": "https://openreview.net/forum?id=9kR4MREN9E",
        "pdf_link": "https://openreview.net/pdf?id=9kR4MREN9E",
        "keywords": "Adversarial Attacks, Large Language Models",
        "abstract": "Large Language Models (LLMs) have greatly advanced the field of General Artificial Intelligence, yet their security vulnerabilities remain a pressing issue, particularly in fine-tuned models. Adversarial attacks in black-box settings\u2014where model details and training data are obscured\u2014are an emerging area of research, posing a substantial threat to private models' integrity. In this work, we uncover a new attack vector: adversaries can exploit the similarities between open-source LLMs and fine-tuned private models to transfer adversarial examples. We introduce a novel attack strategy that generates adversarial examples on open-source models and fine-tunes them to target private, black-box models. Our experiments show that these attacks achieve success rates comparable to white-box attacks, even when private models have been trained on proprietary data. Furthermore, our approach demonstrates strong transferability to other models, including LLaMA3 and ChatGPT. \nThese findings highlight the urgent need for more robust defenses when fine-tuning open-source LLMs."
    },
    {
        "title": "Structure-aware Domain Knowledge Injection for Large Language Models",
        "link_suffix": "/forum?id=Sc382pFw86",
        "link": "https://openreview.net/forum?id=Sc382pFw86",
        "pdf_link": "https://openreview.net/pdf?id=Sc382pFw86",
        "keywords": "knowledge injection, structured knowledge, large language models",
        "abstract": "This paper introduces a pioneering methodology, termed StructTuning, to efficiently transform foundation Large Language Models (LLMs) into domain specialists. It significantly reduces the training corpus requirement to a mere 0.3%, while achieving an impressive 50% of traditional knowledge injection performance. Our method is inspired by the educational processes of human students, particularly how structured domain knowledge from textbooks is assimilated and subsequently applied to tackle real-world challenges through specific exercises. Based on this, we propose a novel two-stage strategy for knowledge injection and alignment: Structure-aware Continual Pre-Training (SCPT) and Structure-aware Supervised Fine-Tuning (SSFT). In the SCPT phase, we automatically extract the domain knowledge taxonomy and reorganize the training corpora, enabling LLMs to effectively link textual segments to targeted knowledge points within the taxonomy. In the SSFT phase, we explicitly prompt models to elucidate the underlying knowledge structure in their outputs, leveraging the structured domain insight to address practical problems. Our ultimate method has undergone extensive evaluations across model architectures and scales, using closed-book question-answering tasks on LongBench and MMedBench datasets. Remarkably, our method demonstrates the potential of comparable improvement against the state-of-the-art MMedLM2 on MMedBench, while significantly reducing the training costs to 5%. This breakthrough paves the way for scaling up our StructTuning for stronger domain-specific LLMs with comprehensive data utilization. Code is available at this anonymous URL:https://anonymous.4open.science/r/StructTuning/."
    },
    {
        "title": "Open-Ended 3D Metric-Semantic Representation Learning via Semantic-Embedded Gaussian Splatting",
        "link_suffix": "/forum?id=JGr4Qv9vbz",
        "link": "https://openreview.net/forum?id=JGr4Qv9vbz",
        "pdf_link": "https://openreview.net/pdf?id=JGr4Qv9vbz",
        "keywords": "3D Gaussian Splatting, Dense Visual SLAM, 3D Scene Representation, Contrastive Learning",
        "abstract": "This work answers the question of whether it is feasible to create a comprehensive metric-semantic 3D virtual world using everyday devices equipped with multi-view stereo. We propose an open-ended metric-semantic representation learning framework based on 3D Gaussians, which distills open-set semantics from 2D foundation models into a scalable and continuously evolving 3D Gaussian representation, optimized within a SLAM framework. The process is non-trivial. The scalability requirements make direct embedding of semantic information into Gaussians impractical, resulting in excessive memory usage and semantic inconsistencies. In response, we propose to learn semantics by aggregating from a condensed, fixed-sized semantic pool rather than directly embedding high-dimensional raw features, significantly reducing memory requirements compared to the point-wise representation. Additionally, by enforcing pixel-to-pixel and pixel-to-object semantic consistency through contrastive learning and stability-guided optimization, our framework enhances coherence and stability in semantic representations. Extensive experiments demonstrate that our framework presents a precise open-ended metric-semantic field with superior rendering quality and tracking accuracy. Besides, it accurately captures both closed-set object categories and open-set semantics, facilitating various applications, notably fine-grained, unrestricted 3D scene editing. These results mark an initial yet solid step towards efficient and expressive 3D virtual world modelling. Our code will be released."
    },
    {
        "title": "Fine-tuning can Help Detect Pretraining Data from Large Language Models",
        "link_suffix": "/forum?id=X8dzvdkQwO",
        "link": "https://openreview.net/forum?id=X8dzvdkQwO",
        "pdf_link": "https://openreview.net/pdf?id=X8dzvdkQwO",
        "keywords": "Large language models, Fine-tuning, Pretraining data detection",
        "abstract": "In the era of large language models (LLMs), detecting pretraining data has been increasingly important due to concerns about fair evaluation and ethical risks. Current methods differentiate members and non-members by designing scoring functions, like Perplexity and Min-k%. However, the diversity and complexity of training data magnifies the difficulty of distinguishing, leading to suboptimal performance in detecting pretraining data. In this paper, we first explore the benefits of unseen data, which can be easily collected after the release of the LLM. We find that the perplexities of LLMs perform differently for members and non-members, after fine-tuning with a small amount of previously unseen data. In light of this, we introduce a novel and effective method termed Fine-tuned Score Deviation (FSD), which improves the performance of current scoring functions for pretraining data detection. In particular, we propose to measure the deviation distance of current scores after fine-tuning on a small amount of unseen data within the same domain. In effect, using a few unseen data can largely decrease the scores of all non-members, leading to a larger deviation distance than members. Extensive experiments demonstrate the effectiveness of our method, significantly improving the AUC score on common benchmark datasets across various models."
    },
    {
        "title": "DART: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control",
        "link_suffix": "/forum?id=XNA3Mnnbvb",
        "link": "https://openreview.net/forum?id=XNA3Mnnbvb",
        "pdf_link": "https://openreview.net/pdf?id=XNA3Mnnbvb",
        "keywords": "Human Motion Generation",
        "abstract": "Text-conditioned human motion generation, which allows for user interaction through natural language, has become increasingly popular. Existing methods typically generate short, isolated motions based on a single input sentence. However, human motions are continuous and can extend over long periods, carrying rich semantics. Creating long, complex motions that precisely respond to streams of text descriptions, particularly in an online and real-time setting, remains a significant challenge. Furthermore, incorporating spatial constraints into text-conditioned motion generation presents additional challenges, as it requires aligning the motion semantics specified by text descriptions with geometric information, such as goal locations and 3D scene geometry. To address these limitations, we proposeDART, aDiffusion-basedAutoregressive motion primitive model forReal-timeText-driven motion control. Our model, DART, effectively learns a compact motion primitive space jointly conditioned on motion history and text inputs using latent diffusion models. By autoregressively generating motion primitives based on the preceding history and current text input, DART enables real-time, sequential motion generation driven by natural language descriptions. Additionally,  the learned motion primitive space allows for precise spatial motion control, which we formulate either as a latent noise optimization problem or as a Markov decision process addressed through reinforcement learning. We present effective algorithms for both approaches, demonstrating our model\u2019s versatility and superior performance in various motion synthesis tasks. Experiments show our method outperforms existing baselines in motion realism, efficiency, and controllability."
    },
    {
        "title": "Policy-aware Reward Modeling with Uncertainty-Gradient based Data Augmentation",
        "link_suffix": "/forum?id=iamWnRpMuQ",
        "link": "https://openreview.net/forum?id=iamWnRpMuQ",
        "pdf_link": "https://openreview.net/pdf?id=iamWnRpMuQ",
        "keywords": "Reward Modeling, Large Language Model, Data Augmentation",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a standard and effective approach for training large language models (LLMs) with human preferences. In this framework, a learned reward model approximates human preferences and guides policy optimization, making it crucial to develop an accurate reward model. However, without the ``true'' reward function, challenges arise when the reward model is an imperfect proxy for human preference. Since the policy optimization continuously shifts the human preference training dataset's distribution. The fixed reward model suffers from this problem of off-distribution, especially the on policy methods.  While collecting new preference data can mitigate this issue, it is costly and challenging to optimize. Thus, reusing the policy interaction samples becomes a possible way to further refine the reward model. To tackle these challenges, we introduce a novel method \\textbf{U}ncertainty-\\textbf{G}radient based \\textbf{D}ata \\textbf{A}ugmentation (\\textbf{UGDA} for short) to enhance reward modeling by leveraging policy samples to maintain on-distribution performance. Specifically, UGDA selects interaction samples based on the uncertainty of the reward ensembles and the gradient based influence of policy optimization. After the reward relabeling of selected samples, we use supervised learning to refine the reward ensembles, then get the retrained policy. Extensive experiments demonstrate that by leveraging UGDA to select a few samples without the costly human preference data collection, we can improve the ability of the policy and surpass the state-of-the-art methods."
    },
    {
        "title": "Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training",
        "link_suffix": "/forum?id=VYRT8ajHRr",
        "link": "https://openreview.net/forum?id=VYRT8ajHRr",
        "pdf_link": "https://openreview.net/pdf?id=VYRT8ajHRr",
        "keywords": "Multimodal Models, Large Language Models, Vision Language Models",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has led to an influx of efforts to extend their capabilities to multimodal tasks. Among them, growing attention have been focused on  monolithic Multimodal Large Language Models (MLLMs) that integrate visual encoding and language decoding into a single LLM.  Despite the structural simplicity and deployment-friendliness,  training a monolithic MLLM with promising performance still remains challenging. In particular, the popular approaches adopt continuous pre-training to extend a pre-trained LLM to a monolithic MLLM, which suffers from catastrophic forgetting and leads to performance degeneration.  In this paper, we aim to overcome this limitation from the perspective of delta tuning. Specifically, our core idea is to embed   visual parameters into a pre-trained LLM, thereby incrementally learning visual  knowledge from massive data via delta tuning, i.e., freezing the LLM when optimizing the visual parameters.   Based on this principle, we   present Mono-InternVL,  a novel monolithic MLLM  that  seamlessly integrates a set of  visual experts via  a multimodal mixture-of-experts structure.  Moreover, we propose an innovative pre-training strategy to maximize the visual capability of Mono-InternVL, namely Endogenous Visual Pre-training (EViP).  In particular, EViP is designed as a progressive learning process for  visual experts,   which aims to  fully exploit the visual knowledge  from noisy data to high-quality data.   To validate our approach, we conduct extensive experiments on 16 benchmarks.  Experimental results not only  validate the superior performance of Mono-InternVL compared to the state-of-the-art MLLM on 6 multimodal benchmarks, e.g., +113 points over InternVL-1.5 on OCRBench, but also confirm its better deployment efficiency, with first token latency reduced by up to 67%. Our code and models will be released."
    },
    {
        "title": "A Simple Framework for Open-Vocabulary Zero-Shot Segmentation",
        "link_suffix": "/forum?id=QzPKSUUcud",
        "link": "https://openreview.net/forum?id=QzPKSUUcud",
        "pdf_link": "https://openreview.net/pdf?id=QzPKSUUcud",
        "keywords": "Vision-language models, Zero-shot segmentation",
        "abstract": "Zero-shot classification capabilities naturally arise in models trained within a vision-language contrastive framework. Despite their classification prowess, these models struggle in dense tasks like zero-shot open-vocabulary segmentation. This deficiency is often attributed to the absence of localization cues in captions and the intertwined nature of the learning process, which encompasses both image/text representation learning and cross-modality alignment. To tackle these issues, we propose SimZSS, a $\\textbf{Sim}$ple framework for open-vocabulary $\\textbf{Z}$ero-$\\textbf{S}$hot $\\textbf{S}$egmentation. The method is founded on two key principles: $\\textit{i)}$ leveraging frozen vision-only models that exhibit spatial awareness while exclusively aligning the text encoder and $\\textit{ii)}$ exploiting the discrete nature of text and linguistic knowledge to pinpoint local concepts within captions. By capitalizing on the quality of the visual representations, our method requires only image-caption pair datasets and adapts to both small curated and large-scale noisy datasets. When trained on COCO Captions across 8 GPUs, SimZSS achieves state-of-the-art results on 7 out of 8 benchmark datasets in less than 15 minutes. The code and pretrained models will be publicly available upon acceptance."
    },
    {
        "title": "Closed-loop Scaling Up for Visual Object Tracking",
        "link_suffix": "/forum?id=YcUtOIzIXK",
        "link": "https://openreview.net/forum?id=YcUtOIzIXK",
        "pdf_link": "https://openreview.net/pdf?id=YcUtOIzIXK",
        "keywords": "Scaling law, Downstream vision tasks, Visual object tracking",
        "abstract": "Thanks to the principles of the scaling law, current neural networks have experienced remarkable performance improvements. While much of the existing research has concentrated on upstream pretraining, the application of the scaling law to downstream vision tasks remains underexplored. Understanding the scaling law in downstream tasks can aid in the design of more effective models and training strategies. Thus, in this work, we aim to investigate the application of the scaling law to downstream vision tasks. Firstly, we explore the impact of three key factors of scaling law: training data volume, model size, and input resolution. We empirically verify that increasing each of these factors can lead to performance enhancements. Secondly, to address naive training's optimization challenges and lack of iterative refinement, we introduce DT-Training which leverages small teacher transfer and dual-branch alignment to further exploit model potential. Thirdly, building on DT-Training, we propose a closed-loop scaling strategy to incrementally scale the model step-by-step. Finally, our scaled model exhibits strong ability and outperforms existing counterparts across diverse test benchmarks. Extensive experiments also reveal the robust transfer ability of our model. Moreover, we validate the generalizability of the scaling law and our proposed DT-Training on other downstream vision tasks, reinforcing the broader applicability of our approach. We hope that our findings can deepen the understanding of the scaling law in downstream tasks and foster future developments on downstream tasks."
    },
    {
        "title": "AlphaQCM: Alpha Discovery with Distributional Reinforcement Learning",
        "link_suffix": "/forum?id=IS7kW28VVt",
        "link": "https://openreview.net/forum?id=IS7kW28VVt",
        "pdf_link": "https://openreview.net/pdf?id=IS7kW28VVt",
        "keywords": "Distributional Reinforcement Learning, Computational Finance, Formulaic Alpha, Quantiled Conditional Moments, Stock Trend Forecasting",
        "abstract": "Finding synergistic formulaic alphas is very important but challenging for researchers and practitioners in finance. In this paper, we reconsider the discovery of formulaic alphas from the viewpoint of sequential decision-making, and conceptualize the entire alpha-mining process as a non-stationary and reward-sparse Markov decision process. To overcome the challenges of non-stationarity and reward-sparsity, we propose the AlphaQCM method, a novel distributional reinforcement learning method designed to search for synergistic formulaic alphas efficiently. The AlphaQCM method first learns the Q function and quantiles via a Q network and a quantile network, respectively. Then, the AlphaQCM method applies the quantiled conditional moment method to learn unbiased variance from the potentially biased quantiles. Guided by the learned Q function and variance, the AlphaQCM method navigates the non-stationarity and reward-sparsity to explore the vast search space of formulaic alphas with high efficacy. Empirical applications to real-world datasets demonstrate that our AlphaQCM method significantly outperforms its competitors, particularly when dealing with large datasets comprising numerous stocks."
    },
    {
        "title": "Exploiting Task Relationships for Continual Learning with Transferability-aware Task Embedding",
        "link_suffix": "/forum?id=bwgihJSDGg",
        "link": "https://openreview.net/forum?id=bwgihJSDGg",
        "pdf_link": "https://openreview.net/pdf?id=bwgihJSDGg",
        "keywords": "Continual Learning, Hypernetworks, Task Embedding, Transferability",
        "abstract": "Continual learning (CL) has been a crucial topic in contemporary deep neural network usages, where catastrophic forgetting (CF) can impede a model's ability to progressively acquire knowledge, leading to critical training inefficiency and constraint in the improvement of model's overall capacity. Existing CL strategies mostly mitigate CF either by regularizing model weights and outputs during finetuning or by distinguishing task-specific and task-sharing model components to adapt the training process accordingly. Yet despite their effectiveness, these previous explorations are mainly limited to elements of task models, while we speculate a deeper exploitation of interrelationship among tasks can provide more enhancement for CL. Therefore, to better capture and utilize the task relations,  we propose a transferability task embedding guided hypernet for continual learning. By introducing the information theoretical transferability based task embedding named H-embedding and incorporating it in a hypernetwork, we establish an online framework capable of capturing the statistical relations among the CL tasks and leveraging these knowledge for deriving task-conditioned model weights. The framework is also characterized by notable practicality, in that it only requires storing a low dimensional task embedding for each task, and can be efficiently trained in an end-to-end way. Extensive evaluations and experimental analyses on datasets including Permuted MNIST, Cifar10/100 and ImageNet-R showcase that our framework performs prominently compared to various baseline methods, as well as displays great potential in obtaining intrinsic task relationships."
    },
    {
        "title": "PointSeg: A Training-Free Paradigm for 3D Scene Segmentation via Foundation Models",
        "link_suffix": "/forum?id=7RVJxmtzTj",
        "link": "https://openreview.net/forum?id=7RVJxmtzTj",
        "pdf_link": "https://openreview.net/pdf?id=7RVJxmtzTj",
        "keywords": "3D segmentation, training-free, foundation models",
        "abstract": "Recent success of vision foundation models have shown promising performance for the 2D perception tasks. However, it is difficult to train a 3D foundation network directly due to the limited dataset and it remains under explored whether existing foundation models can be lifted to 3D space seamlessly. In this paper, we present PointSeg, a novel training-free paradigm that leverages off-the-shelf vision foundation models to address 3D scene perception tasks. PointSeg can segment anything in 3D scene by acquiring accurate 3D prompts to align their corresponding pixels across frames. Concretely, we design a two-branch prompts learning structure to construct the 3D point-box prompts pairs, combining with the bidirectional matching strategy for accurate point and proposal prompts generation. Then, we perform the iterative post-refinement adaptively when cooperated with different vision foundation models. Moreover, we design a affinity-aware merging algorithm to improve the final ensemble masks. PointSeg demonstrates impressive segmentation performance across various datasets, all without training. Specifically, our approach significantly surpasses the state-of-the-art specialist training-free model by 16.3$%$, 14.9$%$, and 15$%$ mAP on ScanNet, ScanNet++, and KITTI-360 datasets, respectively. On top of that, PointSeg can incorporate with various foundation models and even surpasses the specialist training-based methods by 5.6$%$-8$%$ mAP across various datasets, serving as an effective generalist model."
    },
    {
        "title": "HarmoniCa: Harmonizing Training and Inference for Better Feature Cache in Diffusion Transformer Acceleration",
        "link_suffix": "/forum?id=YD6xlDstbz",
        "link": "https://openreview.net/forum?id=YD6xlDstbz",
        "pdf_link": "https://openreview.net/pdf?id=YD6xlDstbz",
        "keywords": "diffusion, acceleration, feature cache",
        "abstract": "Diffusion Transformers (DiTs) have gained prominence for outstanding scalability and extraordinary performance in generative tasks. However, their considerable inference costs impede practical deployment. The feature cache mechanism, which involves storing and retrieving redundant computations across timesteps, holds promise for reducing per-step inference time in diffusion models. Most existing caching methods for DiT are manually designed. Although the learning-based approach attempts to optimize strategies adaptively, it suffers from discrepancies between training and inference, which hampers both the performance and acceleration ratio. \nUpon detailed analysis, we pinpoint that these discrepancies primarily stem from two aspects: (1)Prior Timestep Disregard, where training ignores the effect of cache usage at earlier timesteps, and (2)Objective Mismatch, where the training target (align predicted noise in each timestep) deviates from the goal of inference (generate the high-quality image). To alleviate these discrepancies, we proposeHarmoniCa, a novel method thatHarmonizes training and inference with a novel learning-basedCaching framework built uponStep-Wise Denoising Training(SDT) andImage Error Proxy-Guided Objective(IEPO). Compared to the traditional training paradigm, the newly proposed SDT maintains the continuity of the denoising process, enabling the model to leverage information from prior timesteps during training, similar to the way it operates during inference. Furthermore, we design IEPO, which integrates an efficient proxy mechanism to approximate the final image error caused by reusing the cached feature. Therefore, IEPO helps balance final image quality and cache utilization, resolving the issue of training that only considers the impact of cache usage on the predicted output at each timestep. Extensive experiments on class-conditional and text-to-image (T2I) tasks for 8 models and 4 samplers with resolutions ranging from $256\\times256$ to $2048\\times2048$ demonstrate the exceptional performance and speedup capabilities of our HarmoniCa. For example, HarmoniCa is the first feature cache method applied to the 20-step PixArt-$\\alpha$ $1024\\times1024$ that achieves over 1.5$\\times$ speedup in latency with an improved FID compared to the non-accelerated model. Remarkably, HarmoniCa requires no image data during training and reduces about 25% of training time compared to the existing learning-based approach."
    },
    {
        "title": "Hierarchical divide-and-conquer grouping for Zero shot learning",
        "link_suffix": "/forum?id=bOoHGBwFoo",
        "link": "https://openreview.net/forum?id=bOoHGBwFoo",
        "pdf_link": "https://openreview.net/pdf?id=bOoHGBwFoo",
        "keywords": "Generalized Zero-shot learning, Visual Language Models, Hierarchical Divide-and-Conquer",
        "abstract": "Generalized Zero-Shot Learning (GZSL) faces a key challenge in transferring knowledge from base classes to classify samples from both base and novel classes. This transfer learning paradigm inherently risks a prediction bias, wherein test samples are disproportionately classified towards the base classes due to the models' familiarity and overfitting to those classes during training. To tackle the prediction bias issue, we introduce a divide-and-conquer strategy that segregates the united label space into distinct base and novel subspaces. Within each subspace, we train a customized model to ensure specialized learning tailored to the distinct characteristics of the respective classes. To compensate for the absence of novel classes, we propose utilizing off-the-shelf diffusion-based generative models, conditioned on class-level descriptions crafted by Large Language Models (LLMs), to synthesize diverse visual samples representing the novel classes. To further relieve the class confusion in each subspace, we propose to further divide each subspace into two smaller subspaces, where the classes in each smaller subspace are obtained with the unsupervised cluster strategy in the text embedding space. With our hierarchical divide-and-conquer approach, the test samples are first divided into a smaller subspace and then predicted the class labels with the specialized model trained with the classes present within the subspace. Comprehensive evaluations across three GZSL benchmarks underscore the effectiveness of our method, demonstrating its ability to perform competitively and outperform existing approaches."
    },
    {
        "title": "Quantum Entanglement Trees: Optimizing Quantized Matrix Quantization via Element Replacement and Residual Clustering",
        "link_suffix": "/forum?id=vM4CdVScT8",
        "link": "https://openreview.net/forum?id=vM4CdVScT8",
        "pdf_link": "https://openreview.net/pdf?id=vM4CdVScT8",
        "keywords": "Matrix quantization, LLM Weight Quantization, KV Cache Quantization, Residual Quantization",
        "abstract": "The matrix quantization entails representing matrix elements in a more space-efficient form to reduce storage usage, with dequantization restoring the original matrix for use. We formulate the Quantization Error Minimization (QEM) problem as minimizing the distance between a matrix before and after quantization, under the condition that the quantized matrix occupies the same memory space. Matrix quantization is crucial in various applications, including Large Language Models (LLMs) weight quantization, vector databases, KV cache quantization, graph compression, and image compression. Recent advancements in LLMs, such as GPT-4 and BERT, have highlighted the importance of matrix compression due to the large size of parameters and KV cache, which are stored as matrices.We propose Quantum Entanglement Trees (QET) to address the QEM problem by leveraging the local orderliness of matrix elements, involving iterative element swapping to form a locally ordered matrix. This matrix is then grouped and quantized by columns. To enhance QET, we introduce two optimizations: Residual Quantization Optimization (RQO), which reduces MSE by quantizing the residuals between the original and dequantized matrices, and Codebook Quantization Optimization (CQO), which reduces storage requirements by compressing the codebook itself.Experimental results demonstrate that QET can effectively reduce MSE to 5.05%, 13.33%, and 11.89% of the current best method on the LLM dataset, K cache, and V cache, respectively.\nOur contributions include the abstraction of the QEM problem, the design of the QET algorithm, and the proposal of two optimizations to improve accuracy and speed."
    },
    {
        "title": "SymCL: Riemannian Contrastive Learning on the Symmetric Positive Definite Manifold for Visual Classification",
        "link_suffix": "/forum?id=SLUr06QUuw",
        "link": "https://openreview.net/forum?id=SLUr06QUuw",
        "pdf_link": "https://openreview.net/pdf?id=SLUr06QUuw",
        "keywords": "Learning with Manifolds, Self-Supervised Learning, Classification",
        "abstract": "Symmetric Positive Definite (SPD) matric has been proven to be an effective feature descriptor in the realm of artificial intelligence, as it can encode spatiotemporal statistical information of data on a curved Riemannian manifold, \\textit{i.e.}, SPD manifold. Although existing Riemannian neural networks have demonstrated superiority in many scientific fields, the inherent reliance on labels within supervised learning renders them susceptible to label errors. Besides, it is insufficient to depend solely on labels to learn effective feature distributions in some complicated data scenarios. Drawing inspiration from the considerable achievements of contrastive learning (CL) across diverse tasks, we extend the conventional CL paradigm to the context of SPD manifolds, which we denote SymCL, paving the way for a novel approach in SPD matrix-based visual classification. Furthermore, we inject a Riemannian triplet loss-based Riemannian metric learning (RML) into the designed SPD manifold CL framework for the sake of improving the discrimination of the learned geometric representations. Extensive experimental results on four datasets verify the effectiveness of the proposed algorithm."
    },
    {
        "title": "Bayesian Enhancement Models for One-to-Many Mapping in Image Enhancement",
        "link_suffix": "/forum?id=jJJOoLVAEm",
        "link": "https://openreview.net/forum?id=jJJOoLVAEm",
        "pdf_link": "https://openreview.net/pdf?id=jJJOoLVAEm",
        "keywords": "Image Enhancement",
        "abstract": "Image enhancement is considered an ill-posed inverse problem due to its tendency to have multiple solutions. The loss of information makes accurately reconstructing the original image from observed data challenging. Also, the quality of the result is often subjective to individual preferences. This obviously poses a one-to-many mapping challenge.\nTo address this, we propose a Bayesian Enhancement Model (BEM) that leverages Bayesian estimation to capture inherent uncertainty and accommodate diverse outputs. Our approach, integrated within a two-stage framework, first employs a Bayesian Neural Network (BNN) to model reduced-dimensional image representations, followed by a deterministic network for refinement. \nWe further introduce a dynamic \\emph{Momentum Prior} to overcome convergence issues typically faced by BNNs in high-dimensional spaces.\nExtensive experiments across multiple low-light and underwater image enhancement benchmarks demonstrate the superiority of our method over traditional deterministic models, particularly in real-world applications lacking reference images, highlighting the potential of Bayesian models in handling one-to-many mapping problems."
    },
    {
        "title": "Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training",
        "link_suffix": "/forum?id=b67pPmHBJd",
        "link": "https://openreview.net/forum?id=b67pPmHBJd",
        "pdf_link": "https://openreview.net/pdf?id=b67pPmHBJd",
        "keywords": "LLM Safety, Jailbreak",
        "abstract": "This study addresses a critical gap in safety tuning practices for Large Language Models (LLMs) by identifying and tackling a refusal position bias within safety tuning data, which compromises the models' ability to appropriately refuse generating unsafe content.  We introduce a novel approach, Decoupled Refusal Training (DeRTa), designed to empower LLMs to refuse compliance to harmful prompts at any response position, significantly enhancing their safety capabilities. DeRTa incorporates two novel components: (1) Maximum Likelihood Estimation (MLE) with Harmful Response Prefix, which trains models to recognize and avoid unsafe content by appending a segment of harmful response to the beginning of a safe response, and (2) Reinforced Transition Optimization (RTO), which equips models with the ability to transition from potential harm to safety refusal consistently throughout the harmful response sequence. Our empirical evaluation, conducted using LLaMA3 and Mistral model families across six attack scenarios, demonstrates that our method not only improves model safety without compromising performance but also surpasses well-known models such as GPT-4 in defending against attacks. Importantly, our approach successfully defends recent advanced attack methods that have jailbroken GPT-4 and LLaMA3-70B-Instruct."
    },
    {
        "title": "OASIS: Open Agents Social Interaction Simulations on a Large Scale",
        "link_suffix": "/forum?id=JBzTculaVV",
        "link": "https://openreview.net/forum?id=JBzTculaVV",
        "pdf_link": "https://openreview.net/pdf?id=JBzTculaVV",
        "keywords": "Agents; Social Simulation; Multi-agent system",
        "abstract": "There has been a growing interest in enhancing rule-based agent-based models (ABMs) for social media platforms (i.e., X, Reddit) with more realistic large language model (LLM) agents, thereby allowing for a more nuanced study of complex systems. As a result, several LLM-based ABMs have been proposed in the past year. While they hold promise, each simulator is specifically designed to study a particular scenario, making it time-consuming and resource-intensive to explore other phenomena using the same ABM. Additionally, these models simulate only a limited number of agents, whereas real-world social media platforms involve millions of users.\nTo this end, we propose OASIS, a generalizable and scalable social media simulator. OASIS is designed based on real-world social media platforms, incorporating dynamically updated environments (i.e., dynamic social networks and post information), diverse action spaces (i.e., following, commenting), and recommendation systems (i.e., interest-based and hot-score-based). Additionally, OASIS supports large-scale user simulations, capable of modeling up to one million users. With these features, OASIS can be easily extended to different social media platforms to study large-scale group phenomena and behaviors. We replicate various social phenomena, including information spreading, group polarization, and herd effects across X and Reddit platforms. \nMoreover, we provide observations of social phenomena at different agent group scales. we observe that the larger agent group scale leads to more enhanced group dynamics and more diverse and helpful agents' opinions. These findings demonstrate OASIS's potential as a powerful tool for studying complex systems in digital environments."
    },
    {
        "title": "Reconstructing Training Data From Real-World Models Trained with Transfer Learning",
        "link_suffix": "/forum?id=BRdYYyrAOR",
        "link": "https://openreview.net/forum?id=BRdYYyrAOR",
        "pdf_link": "https://openreview.net/pdf?id=BRdYYyrAOR",
        "keywords": "data reconstruction, memorization, privacy",
        "abstract": "Current methods for reconstructing the training data from trained classifiers are restricted to very small models, limited training set sizes, and low-resolution images. Such restrictions hinder their applicability to real-world scenarios. In this paper, we present a novel approach enabling data reconstruction in realistic settings for models trained on high-resolution images. Our method adapts the reconstruction scheme of Haim et al. [2022] to real-world scenarios -- specifically, targeting models trained via transfer learning over image embeddings of large pre-trained models like DINO-ViT and CLIP. Our work employs data reconstruction in the embedding space rather than in the image space, showcasing its applicability beyond visual data. Moreover, we introduce a novel clustering-based method to identify good reconstructions from thousands of candidates. This significantly improves on previous works that relied on knowledge of the training set to identify good reconstructed images. Our findings shed light on a potential privacy risk for data leakage from models trained using transfer learning methods."
    }
]
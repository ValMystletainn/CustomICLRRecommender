[{"title": "A Bregman Proximal Viewpoint on Neural Operators", "link_suffix": "/forum?id=wO1NJLitPL", "link": "https://openreview.net/forum?id=wO1NJLitPL", "pdf_link": "https://openreview.net/pdf?id=wO1NJLitPL", "keywords": "neural operators, proximal optimization, bregman divergence, fourier neural operator", "abstract": "We present several advances on neural operators by viewing the action of operator layers as the minimizers of Bregman regularized optimization problems over Banach function spaces. The proposed framework allows interpreting the activation operators as Bregman proximity operators from dual to primal space. This novel viewpoint is general enough to recover classical neural operators as well as a new variant, coined Bregman neural operators, which includes the inverse activatio and features the same expressivity of standard neural operators. Numerical experiments support the added benefits of the Bregman variant of Fourier neural operators for training deeper and more accurate models.", "title_embedding_index": 4550, "title_abs_embedding_index": 4575}, {"title": "LoRA vs Full Fine-tuning: An Illusion of Equivalence", "link_suffix": "/forum?id=PGNdDfsI6C", "link": "https://openreview.net/forum?id=PGNdDfsI6C", "pdf_link": "https://openreview.net/pdf?id=PGNdDfsI6C", "keywords": "LoRA, Fine-tuning, Large Language models, Transformers, Low-rank approximation", "abstract": "Fine-tuning is a crucial paradigm for adapting pre-trained large language models to downstream tasks. Recently, methods like Low-Rank Adaptation (LoRA) have been shown to match the performance of fully fine-tuned models on various tasks with an extreme reduction in the number of trainable parameters. Even in settings where both methods learn similarly accurate models, \\emph{are their learned solutions really equivalent?} \nTo answer this, we study how different fine-tuning methods change pre-trained models by analyzing the model's weight matrices through the lens of their spectral properties. We find that full fine-tuning and LoRA yield weight matrices whose singular value decompositions exhibit very different structure; moreover, the fine-tuned models themselves show distinct generalization behaviors when tested outside the adaptation task's distribution. We first show that the weight matrices trained with LoRA have new, high-ranking singular vectors, which we call \\emph{intruder dimensions}. Intruder dimensions do not appear during full fine-tuning. Second, we find that LoRA models with intruder dimensions, despite achieving similar performance to full fine-tuning on the target task, become worse models of the pre-training distribution and adapt less robustly to multiple tasks sequentially. Higher-rank, rank-stabilized LoRA models closely mirror full fine-tuning, even when performing on par with lower-rank LoRA models on the same tasks. These results suggest that models updated with LoRA and full fine-tuning inherently access different parts of the solution space, even when they perform equally on the fine-tuned distribution.\nWe conclude by examining why intruder dimensions appear in LoRA fine-tuned models, why they are undesirable, and how their effects can be minimized.", "title_embedding_index": 4551, "title_abs_embedding_index": 4576}, {"title": "Fast and Space-Efficient Fixed-Length Path Optimization", "link_suffix": "/forum?id=MH6yUPwVbp", "link": "https://openreview.net/forum?id=MH6yUPwVbp", "pdf_link": "https://openreview.net/pdf?id=MH6yUPwVbp", "keywords": "path optimization, fixed length constraint, space efficiency", "abstract": "Several optimization problems seek a path of predetermined length among network nodes that minimizes a cost function. Conventionally, such problems are tackled by dynamic programming (DP) applying a Bellman-type equation. A prominent example is Viterbi decoding, which returns the path in a Hidden Markov Model that best explains a series of observations, with applications from bioinformatics to communication systems and speech recognition. However, DP-based solutions (i) exhaustively explore a search space linear in both network size and path length in time quadratic in network size, without exploiting data characteristics, and (ii) require memory commensurate with that search space to reconstruct the optimal path. In this paper, we propose Isabella (Dijkstra-Bellman), a novel framework that finds optimal paths of predetermined length in time- and space-efficient fashion by a combination of best-first-search, depth-first-search, and divide-and-conquer strategies. The best-first-search component avoids the exhaustive exploration of the search space using a priority queue; the depth-first-search component keeps the size of that queue in check; and the divide-and-conquer component constructs the optimal path recursively and parsimoniously after determining its cost. We apply Isabella to Viterbi decoding, introducing algorithms that visit the most promising pathways first and control memory consumption. To emphasize the generality of Isabella, we also instantiate it with an algorithm for histogram construction. To our knowledge, no previous work addresses such problems in this manner. Our experimental evaluation shows our solutions to be highly time- and space-efficient compared to standard dynamic programming.", "title_embedding_index": 4552, "title_abs_embedding_index": 4577}, {"title": "Cognitive map formation under uncertainty via local prediction learning", "link_suffix": "/forum?id=Oq8bDXRf4F", "link": "https://openreview.net/forum?id=Oq8bDXRf4F", "pdf_link": "https://openreview.net/pdf?id=Oq8bDXRf4F", "keywords": "cognitive maps, local prediction learning, vector symbolic architectures", "abstract": "Cognitive maps are internal world models that enable adaptive behavior including spatial navigation and planning. The Cognitive Map Learner (CML) has been recently proposed as a model for cognitive map formation and planning. A CML learns high dimensional state and action representations using local prediction learning. While the CML offers a simple and elegant solution to cognitive map learning, it is limited by its simplicity, applying only to fully observable environments. To address this, we introduce the Partially Observable Cognitive Map Learner (POCML), extending the CML to handle partially observable environments.The POCML employs a superposition of states for probabilistic representation and uses binding operations for state updates. Additionally, an associative memory is incorporated to enable adaptive behavior across environments with similar structures. We derive local update rules tailored to the POCML's probabilistic state representation and associative memory. We demonstrate a POCML is capable of learning the underlying structure of an environment via local next-observation prediction learning. In addition, we show that a POCML trained on an environment is capable of generalizing to environments with the same underlying structure but with novel observations, achieving good zero-shot next-observation prediction accuracy, significantly outperforming sequence models such as LSTMs and Transformers. Finally, we present a case study of navigation in a two-tunnel maze environment with aliased observations, showing that a POCML is capable of effectively using its probabilistic state representations for disambiguation of states and spatial navigation.", "title_embedding_index": 4553, "title_abs_embedding_index": 4578}, {"title": "Revisiting Large-Scale Non-convex Distributionally Robust Optimization", "link_suffix": "/forum?id=JYwVijuNA7", "link": "https://openreview.net/forum?id=JYwVijuNA7", "pdf_link": "https://openreview.net/pdf?id=JYwVijuNA7", "keywords": "distributionally robust optimization, generalized smoothness, non-convex optimization, variance-reduced method", "abstract": "Distributionally robust optimization (DRO) is a powerful technique to train robust machine learning models that perform well under distribution shifts. Compared with empirical risk minimization (ERM), DRO optimizes the expected loss under the worst-case distribution in\nan uncertainty set of distributions. This paper revisits the important problem of DRO with non-convex smooth loss functions. For this problem, Jin et al. (2021) showed that its dual problem is generalized $(L_0, L_1)$-smooth condition and gradient noise satisfies the affine variance condition, designed an algorithm of mini-batch normalized gradient descent with momentum, and proved its convergence and complexity.   In this paper, we show that the dual problem and the gradient noise satisfy simpler yet more precise partially generalized smoothness condition and partially affine variance condition by studying the optimization variable and dual variable separately, which further yields much simpler algorithm design and convergence analysis. We develop a double stochastic gradient descent with clipping (D-SGD-C) algorithm that converges to an $\\epsilon$-stationary point with $\\mathcal O(\\epsilon^{-4})$ gradient complexity, which matches with results in Jin et al. (2021). Our algorithm does not need to use momentum, and the proof is much simpler, thanks to the more precise characterization of partially generalized smoothness and partially affine variance noise. We further design a variance-reduced method that achieves a lower gradient complexity of $\\mathcal O(\\epsilon^{-3})$. Our theoretical results and insights are further verified numerically on a number of tasks, and our algorithms outperform the existing DRO method (Jin et al., 2021).", "title_embedding_index": 4554, "title_abs_embedding_index": 4579}, {"title": "Disentangling Textual and Acoustic Features of Neural Speech Representations", "link_suffix": "/forum?id=xJc3PazBwS", "link": "https://openreview.net/forum?id=xJc3PazBwS", "pdf_link": "https://openreview.net/pdf?id=xJc3PazBwS", "keywords": "Disentangling Representations, Spoken language Processing, Speech Emotion Recognition, Interpretability", "abstract": "Neural speech models build deeply entangled internal representations, which capture a variety of features (e.g., fundamental frequency, loudness, syntactic category, or semantic content of a word) in a distributed encoding. This complexity makes it difficult to track the extent to which such representations rely on textual and acoustic information, or to suppress the encoding of acoustic features that may pose privacy risks (e.g., gender or speaker identity) in critical, real-world applications. In this paper, we build upon the Information Bottleneck principle to propose a disentanglement framework that separates complex speech representations into two distinct components: one encoding content (i.e., what can be transcribed as text) and the other encoding acoustic features relevant to a given downstream task. We apply and evaluate our framework to emotion recognition and speaker identification downstream tasks, quantifying the contribution of textual and acoustic features at each model layer. Additionally, we explore the application of our disentanglement framework as an attribution method to identify the most salient speech frame representations from both the textual and acoustic perspectives.", "title_embedding_index": 4555, "title_abs_embedding_index": 4580}, {"title": "RapidDock: Unlocking Proteome-scale Molecular Docking", "link_suffix": "/forum?id=0sU4myabw1", "link": "https://openreview.net/forum?id=0sU4myabw1", "pdf_link": "https://openreview.net/pdf?id=0sU4myabw1", "keywords": "molecular docking, protein-ligand binding, transformer, equivariance, high-throughput screening, drug discovery", "abstract": "Accelerating molecular docking -- the process of predicting how molecules bind to protein targets -- could boost small-molecule drug discovery and revolutionize medicine. Unfortunately, current molecular docking tools are too slow to screen potential drugs against all relevant proteins, which often results in missed drug candidates or unexpected side effects occurring in clinical trials.\nTo address this gap, we introduce RapidDock, an efficient transformer-based model for blind molecular docking.\nRapidDock achieves at least a $100 \\times$ speed advantage over existing methods without compromising accuracy.\nOn the Posebusters and DockGen benchmarks, our method achieves $52.1$% and $44.0$% success rates ($\\text{RMSD}<2A$), respectively. \nThe average inference time is $0.04$ seconds on a single GPU, highlighting RapidDock's potential for large-scale docking studies.\nWe examine the key features of RapidDock that enable leveraging the transformer architecture for molecular docking, including the use of relative distance embeddings of $3$D structures in attention matrices, pre-training on protein folding, and a custom loss function invariant to molecular symmetries. We make the model code and weights publicly available.", "title_embedding_index": 4556, "title_abs_embedding_index": 4581}, {"title": "Text-to-graph Generation with Conditional Diffusion Models Guided by Graph-aligned LLMs", "link_suffix": "/forum?id=ciSW6Jczvo", "link": "https://openreview.net/forum?id=ciSW6Jczvo", "pdf_link": "https://openreview.net/pdf?id=ciSW6Jczvo", "keywords": "large language model, text-to-graph, diffusion model, graph generation", "abstract": "Text-to-graph generation, aiming for controlled graph generation based on natural language instructions, holds significant application potentials in real-world scenarios such as drug discoveries. However, existing generative models fail to achieve text-to-graph generation in the following two aspects: i) language model-based generative models struggle with generating complex graph structures, and ii) graph-based generative models mainly focus on unconditional graph generation, falling short in understanding as well as following human instructions. In this paper, we tackle the text-to-graph generation problem by employing graph diffusion models with guidance from large language models (LLMs) for the first time, to the best of our knowledge.  The problem is highly non-trivial with the following challenges: 1) How to align LLMs for understanding the irregular graph structures and the graph properties hidden in human instructions, 2) How to align graph diffusion models for following natural language instructions in order to generate graphs with expected relational semantics from human. To address these challenges, we propose a novel LLM-aligned Graph Diffusion Model (LLM-GDM), which is able to generate graphs based on natural language instructions. In particular, we first propose the self-supervised text-graph alignment to empower LLMs with the ability to accurately understand graph structures and properties by finetuning LLMs with several specially designed alignment tasks involving various graph components such as nodes, edges, and subgraphs. Then, we propose a structure-aware cross-attention mechanism guiding the diffusion model to follow human instructions through inherently capturing the relational semantics among texts and structures. Extensive experiments on both synthetic and real-world molecular datasets demonstrate the effectiveness of our proposed LLM-GDM model over existing baseline methods.", "title_embedding_index": 4557, "title_abs_embedding_index": 4582}, {"title": "Beyond single neurons: population response geometry in digital twins of mouse visual cortex", "link_suffix": "/forum?id=kSISSDUYFh", "link": "https://openreview.net/forum?id=kSISSDUYFh", "pdf_link": "https://openreview.net/pdf?id=kSISSDUYFh", "keywords": "neuroscience, representation learning, population responses, cortical hierarchy, computational biology, visual perception", "abstract": "Hierarchical visual processing  is essential for cognitive functions like object recognition and spatial localization. Traditional studies of the neural basis of these computations have focused on single-neuron activity, but recent advances in large-scale neural recordings emphasize the growing need to understand computations at the population level. Digital twins-computational models trained on neural data-have successfully replicated single-neuron behavior, but their effectiveness in capturing the joint activity of neurons remains unclear. In this study, we investigate how well digital twins describe population responses in  mouse visual cortex. We show that these models fail to accurately represent the geometry of  population activity, particularly its differentiability and how this geometry evolves across the visual hierarchy. To address this, we explore how dataset, network architecture, loss function, and training method affect the ability of digital twins to recapitulate population properties. We demonstrate that improving model alignment with experiments requires training strategies that enhance robustness and generalization, reflecting principles observed in biological systems. These findings underscore the need to evaluate digital twins from multiple perspectives, identify key areas for refinement, and establish a foundation for using these models to explore neural computations at the population level.", "title_embedding_index": 4558, "title_abs_embedding_index": 4583}, {"title": "Learning Molecular Symmetry Breaking via Symmetry-adapted Neural Networks", "link_suffix": "/forum?id=fjJ5oYtBpO", "link": "https://openreview.net/forum?id=fjJ5oYtBpO", "pdf_link": "https://openreview.net/pdf?id=fjJ5oYtBpO", "keywords": "relaxed equivariance, equivariance, symmetry breaking, geometric deep learning, molecular modeling", "abstract": "E(3)-equivariant neural networks have achieved remarkable performance in molecular modeling. However, the equivariance constraint limits the model's effectiveness in tasks involving symmetry breaking, particularly those that violate the celebrated Curie principle. Relaxing this constraint is essential for addressing these challenges. In this paper, we explore the intricate symmetry relationships between an object and its spontaneously symmetry-broken outcomes. We introduce a novel loss function to measure loss in ambiguous symmetry-breaking scenarios and propose a relaxed equivariance based on the molecule's inherent symmetries. Additionally, we develop SANN -- a symmetry-adapted neural network architecture that learns symmetry breaking through equivalence classes of atoms. SANN decomposes the molecular point cloud into sets of symmetry-equivalent atoms and performs message-passing both within and across these classes. We demonstrate the advantages of our method over invariant and equivariant models through synthetic tasks and show that SANN effectively learns both equivariance and symmetry breaking in various benchmark molecular modeling tasks.", "title_embedding_index": 4559, "title_abs_embedding_index": 4584}, {"title": "Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training", "link_suffix": "/forum?id=6L8OdH5PBu", "link": "https://openreview.net/forum?id=6L8OdH5PBu", "pdf_link": "https://openreview.net/pdf?id=6L8OdH5PBu", "keywords": "LLMs, Hallucinations, Dropout, Reliability, Efficiency", "abstract": "As large language models (LLMs) become increasingly deployed across various industries, concerns regarding their reliability, particularly due to hallucinations\u2014outputs that are factually inaccurate or irrelevant to user input\u2014have grown. Our research investigates the relationship between the training process and the emergence of hallucinations  to address a key gap in existing research that focuses primarily on post hoc detection and mitigation strategies. Using models from the Pythia suite (70M\u201312B parameters) and several hallucination detection metrics, we analyze hallucination trends throughout training and explore LLM internal dynamics. We introduce SEnsitive Neuron Dropout (SeND), a novel training protocol designed to mitigate hallucinations by reducing variance during training. SeND achieves this by deterministically dropping neurons with significant variability on a dataset, referred to as Sensitive Neurons. In addition, we develop an unsupervised hallucination detection metric, Efficient EigenScore (EES), which approximates the traditional EigenScore in 2x speed. This efficient metric is integrated into our protocol, allowing SeND to be both computationally scalable and effective at reducing hallucinations. Our empirical evaluation demonstrates that our approach improves LLM reliability at test time by up to 40% compared to normal training while also providing an efficient method to improve factual accuracy when adapting LLMs to domains such as Wikipedia and Medical datasets.", "title_embedding_index": 4560, "title_abs_embedding_index": 4585}, {"title": "Sparse Rewards Can Self-Train Dialogue Agents", "link_suffix": "/forum?id=DWLlTNhig1", "link": "https://openreview.net/forum?id=DWLlTNhig1", "pdf_link": "https://openreview.net/pdf?id=DWLlTNhig1", "keywords": "Self-training, LLM, Simulation, Benchmark, Tool-calling, Dataset, Task Oriented Dialogue, Dialogue, User Simulation, Beam Search, Algorithm, Preference Tuning, Supervised Finetuning, JOSH, ToolWOZ", "abstract": "Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM) agents, especially in multi-turn dialogue tasks, have been primarily driven by supervised fine-tuning and high-quality human feedback. However, as base LLM models continue to improve, acquiring meaningful human feedback has become increasingly challenging and costly. In certain domains, base LLM agents may eventually exceed human capabilities, making traditional feedback-driven methods impractical. In this paper, we introduce a novel self-improvement paradigm that empowers LLM agents to autonomously enhance their performance without external human feedback. Our method, Juxtaposed Outcomes for Simulation Harvesting (JOSH), is a self-alignment algorithm that leverages a sparse reward simulation environment to extract ideal behaviors and further train the LLM on its own outputs. We present ToolWOZ, a sparse reward tool-calling simulation environment derived from MultiWOZ. We demonstrate that models trained with JOSH, both small and frontier, significantly improve tool-based interactions while preserving general model capabilities across diverse benchmarks. Our code and data are publicly available on GitHub.", "title_embedding_index": 4561, "title_abs_embedding_index": 4586}, {"title": "FAIRMINDSIM: ALIGNMENT OF BEHAVIOR, EMO- TION, AND BELIEF IN HUMANS AND LLM AGENTS AMID ETHICAL DILEMMAS", "link_suffix": "/forum?id=FXPsZ6cbUj", "link": "https://openreview.net/forum?id=FXPsZ6cbUj", "pdf_link": "https://openreview.net/pdf?id=FXPsZ6cbUj", "keywords": "AI alignment;  AI Security; AI Ethical; Value alignment; Simulation", "abstract": "AI alignment is a pivotal issue concerning AI control and safety. It should consider not only value-neutral human preferences but also moral and ethical considerations. In this study, we introduced FairMindSim, which simulates the moral dilemma through a series of unfair scenarios. We used LLM agents to simulate human behavior, ensuring alignment across various stages. To explore the various socioeconomic motivations, which we refer to as beliefs, that drive both humans and LLM agents as bystanders to intervene in unjust situations involving others, and how these beliefs interact to influence individual behavior, we incorporated knowledge from relevant sociological fields and proposed the Belief-Reward Alignment Behavior Evolution Model (BREM) based on the recursive reward model (RRM). Our findings indicate that, behaviorally, GPT-4o exhibits a stronger sense of social justice, while humans display a richer range of emotions. Additionally, we discussed the potential impact of emotions on behavior. This study provides a theoretical foundation for applications in aligning LLMs with altruistic values.", "title_embedding_index": 4562, "title_abs_embedding_index": 4587}, {"title": "On the ergodic convergence properties of the Peaceman-Rachford method and their applications in solving linear programming", "link_suffix": "/forum?id=IwmyQUPIP0", "link": "https://openreview.net/forum?id=IwmyQUPIP0", "pdf_link": "https://openreview.net/pdf?id=IwmyQUPIP0", "keywords": "Peaceman-Rachford method, ergodic convergence properties, linear programming, compleixty, parallel computing", "abstract": "In this paper, we study the ergodic convergence properties of the Peaceman-Rachford (PR) method with semi-proximal terms for solving convex optimization problems (COPs). By reformulating the PR method as a degenerate proximal point method, for the first time we establish the global convergence of the ergodic sequence generated by the PR method with broadly chosen semi-proximal terms under the assumption that there exists a  Karush\u2013Kuhn\u2013Tucker (KKT) solution to the COPs. This result represents a significant departure from previous studies on the non-ergodic convergence of the PR method, which typically requires strong convexity (or strong monotonicity in the reformulated operator) conditions that are hardly satisfied for COPs. Moreover, we establish an ergodic iteration complexity of $O(1/k)$ of the PR method with semi-proximal terms, measured by the objective error, the feasibility violation, and the KKT  residual using the $\\varepsilon$-subdifferential. Based on these convergence properties, we introduce the solver EPR-LP, using the ergodic sequence of the PR method with semi-proximal terms for solving linear programming (LP) problems. EPR-LP incorporates an adaptive restart strategy and dynamic penalty parameter updates for efficiency and robustness. Extensive numerical experiments on LP benchmark datasets, executed on a high-performance GPU, show that our Julia-based solver outperforms the award-winning solver PDLP at a tolerance level of $10^{-8}$.", "title_embedding_index": 4563, "title_abs_embedding_index": 4588}, {"title": "Failure-Proof Non-Contrastive Self-Supervised Learning", "link_suffix": "/forum?id=t8LzkidEuc", "link": "https://openreview.net/forum?id=t8LzkidEuc", "pdf_link": "https://openreview.net/pdf?id=t8LzkidEuc", "keywords": "Self-Supervised Learning, Representation Learning, Deep Learning", "abstract": "We identify sufficient conditions to avoid known failure modes, including representation, dimensional, cluster and intracluster collapses, occurring in non-contrastive self-supervised learning. Based on these findings, we propose a principled design for the projector and loss function. We theoretically demonstrate that this design introduces an inductive bias that promotes learning representations that are both decorrelated and clustered without explicit enforcing these properties and leading to improved generalization. To the best of our knowledge, this is the first solution that achieves robust training with respect to these failure modes while guaranteeing enhanced generalization performance in downstream tasks. We validate our theoretical findings on image datasets including SVHN, CIFAR10, CIFAR100 and ImageNet-100, and show that our solution, dubbed FALCON, outperforms existing feature decorrelation and cluster-based self-supervised learning methods in terms of generalization to clustering and linear classification tasks.", "title_embedding_index": 4564, "title_abs_embedding_index": 4589}, {"title": "Limits to scalable evaluation at the frontier: LLM as judge won\u2019t beat twice the data", "link_suffix": "/forum?id=NO6Tv6QcDs", "link": "https://openreview.net/forum?id=NO6Tv6QcDs", "pdf_link": "https://openreview.net/pdf?id=NO6Tv6QcDs", "keywords": "Evaluation, Benchmarking, Model-as-a-judge, Theory", "abstract": "High quality annotations are increasingly a bottleneck in the explosively growing machine learning ecosystem. Scalable evaluation methods that avoid costly annotation have therefore become an important research ambition. Many hope to use strong existing models in lieu of costly labels to provide cheap model evaluations. Unfortunately, this method of using models as judges introduces biases, such as self-preferencing, that can distort model comparisons. An emerging family of debiasing tools promises to fix these issues by using a few high quality labels to debias a large number of model judgments. In this paper, we study how far such debiasing methods, in principle, can go. Our main result shows that when the judge is no more accurate than the evaluated model, no debiasing method can decrease the required amount of ground truth labels by more than half. Our result speaks to the severe limitations of the LLM-as-a-judge paradigm at the evaluation frontier where the goal is to assess newly released models that are possibly better than the judge. Through an empirical evaluation, we demonstrate that the sample size savings achievable in practice are even more modest than what our theoretical limit suggests. Along the way, our work provides new observations about debiasing methods for model evaluation, and points out promising avenues for future work.", "title_embedding_index": 4565, "title_abs_embedding_index": 4590}, {"title": "Random Features Outperform Linear Models: Effect of Strong Input-Label Correlation in Spiked Covariance Data", "link_suffix": "/forum?id=OEC6zOuZG1", "link": "https://openreview.net/forum?id=OEC6zOuZG1", "pdf_link": "https://openreview.net/pdf?id=OEC6zOuZG1", "keywords": "Random feature model, Gaussian equivalence, universality", "abstract": "Random Feature Model (RFM) with a nonlinear activation function is instrumental in understanding training and generalization performance in high-dimensional learning. While existing research has established an asymptotic equivalence in performance between the RFM and noisy linear models under isotropic data assumptions, empirical observations indicate that the RFM frequently surpasses linear models in practical applications. To address this gap, we ask,\"When and how does the RFM outperform linear models?\"In practice, inputs often have additional structures that significantly influence learning. Therefore, we explore the RFM under anisotropic input data characterized by spiked covariance in the proportional asymptotic limit, where dimensions diverge jointly while maintaining finite ratios. Our analysis reveals that a high correlation between inputs and labels is a critical factor enabling the RFM to outperform linear models. Moreover, we show that the RFM performs equivalent to noisy polynomial models, where the polynomial degree depends on the strength of the correlation between inputs and labels. Our numerical simulations validate these theoretical insights, confirming the performance-wise superiority of RFM in scenarios characterized by strong input-label correlation.", "title_embedding_index": 4566, "title_abs_embedding_index": 4591}, {"title": "Controlled Denoising For Diffusion Models", "link_suffix": "/forum?id=MBDH5zyxHM", "link": "https://openreview.net/forum?id=MBDH5zyxHM", "pdf_link": "https://openreview.net/pdf?id=MBDH5zyxHM", "keywords": "Generative Models, Computer Vision, Diffusion Models, Guidance", "abstract": "Aligning diffusion models for downstream tasks often requires finetuning new models or costly inference-time solutions (e.g., gradient-based guidance) to allow sampling from the reward-tilted posterior. In this work, we explore a simple and low-cost inference-time gradient-free guidance approach, called conditional controlled denoising (C-Code), that circumvents the need for differentiable guidance functions and model finetuning. C-Code is a block-wise sampling method with adjustable conditioning on a reference image applied during intermediate denoising steps, allowing for efficient alignment with downstream rewards. Experiments demonstrate that, despite its simplicity, C-Code offers a balanced trade-off between reward alignment, prompt instruction following, and inference cost, outperforming state-of-the-art baselines. Our code is available at:https://anonymous.4open.science/r/CoDe-Repo.", "title_embedding_index": 4567, "title_abs_embedding_index": 4592}, {"title": "Post-Hoc Robustness Enhancement in Graph Neural Networks with Conditional Random Fields", "link_suffix": "/forum?id=q3Z2v2mt1R", "link": "https://openreview.net/forum?id=q3Z2v2mt1R", "pdf_link": "https://openreview.net/pdf?id=q3Z2v2mt1R", "keywords": "Robustness, Graph Neural Networks, Conditional Random Fields", "abstract": "Graph Neural Networks (GNNs), which are nowadays the benchmark approach in graph representation learning, have been shown to be vulnerable to adversarial attacks, raising concerns about their real-world applicability. While existing defense techniques primarily concentrate on the training phase of GNNs, involving adjustments to message passing architectures or pre-processing methods, there is a noticeable gap in methods focusing on increasing robustness during inference. In this context, this study introduces RobustCRF, a post-hoc approach aiming to enhance the robustness of GNNs at the inference stage. Our proposed method, founded on statistical relational learning using a Conditional Random Field, is model-agnostic and does not require prior knowledge about the underlying model architecture. We validate the efficacy of this approach across various models, leveraging benchmark node classification datasets.", "title_embedding_index": 4568, "title_abs_embedding_index": 4593}, {"title": "State Space Models are Provably Comparable to Transformers in Dynamic Token Selection", "link_suffix": "/forum?id=QFgbJOYJSE", "link": "https://openreview.net/forum?id=QFgbJOYJSE", "pdf_link": "https://openreview.net/pdf?id=QFgbJOYJSE", "keywords": "State Space Model, Transformer, Nonparametric regression", "abstract": "Deep neural networks based on state space models (SSMs) are attracting significant attention in sequence modeling since their computational cost is significantly smaller than that of Transformers. While the capabilities of SSMs have been demonstrated through experiments in various tasks, theoretical understanding of SSMs is still limited. In particular, most theoretical studies discuss the capabilities of SSM layers without nonlinear layers, and there is a lack of discussion on their combination with nonlinear layers. In this paper, we explore the capabilities of SSMs combined with fully connected neural networks, and show that they are comparable to Transformers in extracting the essential tokens depending on the input. As concrete examples, we consider two synthetic tasks, which are challenging for a single SSM layer, and demonstrate that SSMs combined with nonlinear layers can efficiently solve these tasks.  Furthermore, we study the nonparametric regression task, and prove that the ability of SSMs is equivalent to that of Transformers in estimating functions belonging to a certain class.", "title_embedding_index": 4569, "title_abs_embedding_index": 4594}, {"title": "Consistency Models Made Easy", "link_suffix": "/forum?id=xQVxo9dSID", "link": "https://openreview.net/forum?id=xQVxo9dSID", "pdf_link": "https://openreview.net/pdf?id=xQVxo9dSID", "keywords": "Consistency Models, Efficient Generative Models, Diffusion Models", "abstract": "Consistency models (CMs) offer faster sampling than traditional diffusion models, but their training is resource-intensive. For example, as of 2024, training a state-of-the-art CM on CIFAR-10 takes one week on 8 GPUs. In this work, we propose an effective scheme for training CMs that largely improves the efficiency of building such models. Specifically, by expressing CM trajectories via a particular differential equation, we argue that diffusion models can be viewed as a special case of CMs. We can thus fine-tune a consistency model starting from a pretrained diffusion model and progressively approximate the full consistency condition to stronger degrees over the training process. Our resulting method, which we term Easy Consistency Tuning (ECT), achieves vastly reduced training times while improving upon the quality of previous methods: for example, ECT achieves a 2-step FID of 2.73 on CIFAR10 within 1 hour on a single A100 GPU, matching Consistency Distillation trained for hundreds of GPU hours. Owing to this computational efficiency, we investigate the scaling laws of CMs under ECT, showing that they obey the classic power law scaling, hinting at their ability to improve efficiency and performance at larger scales. Our code will be made publicly available, making CMs more accessible to the broader community.", "title_embedding_index": 4570, "title_abs_embedding_index": 4595}, {"title": "Identify Critical Nodes in Complex Network with Large Language Models", "link_suffix": "/forum?id=rh54qNvxKO", "link": "https://openreview.net/forum?id=rh54qNvxKO", "pdf_link": "https://openreview.net/pdf?id=rh54qNvxKO", "keywords": "Complex Networks, Large Language Models", "abstract": "Identifying critical nodes in networks is a classical combinatorial optimization task, and many methods struggle to strike a balance between adaptability and utility. Therefore, we propose an approach that empowers Evolutionary Algorithm (EA) with Large Language Models (LLMs), to generate a function called \"score_nodes\" which can further be used to identify crucial nodes based on their assigned scores. Our model consists of three main components: Manual Initialization, Population Management, and LLMs-based Evolution, and it evolves from initial populations with a set of designed node scoring functions created manually. LLMs leverage their strong contextual understanding and rich programming techniques to perform crossover and mutation operations on the individuals, generating new functions. These functions are then categorized, ranked, and eliminated to ensure the stable development of the populations while preserving diversity. Extensive experiments demonstrate the excellent performance of our method compared to other state-of-the-art algorithms. It can generate diverse and efficient node scoring functions to identify critical nodes in the network.", "title_embedding_index": 4571, "title_abs_embedding_index": 4596}, {"title": "OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data", "link_suffix": "/forum?id=mTCbq2QssD", "link": "https://openreview.net/forum?id=mTCbq2QssD", "pdf_link": "https://openreview.net/pdf?id=mTCbq2QssD", "keywords": "Math Reasoning, Synthetic Data", "abstract": "Mathematical reasoning continues to be a critical challenge in large language model (LLM) development with significant interest. However, most of the cutting-edge progress in mathematical reasoning with LLMs has become closed-source due to lack of access to training data. This lack of data access limits researchers from understanding the impact of different choices for synthesizing and utilizing the data. With the goal of creating a high-quality finetuning (SFT) dataset for math reasoning, we conduct careful ablation experiments on data synthesis using the recently released Llama3.1 family of models. Our experiments show that: (a) solution format matters, with excessively verbose solutions proving detrimental to SFT performance, (b) data generated by a strong teacher outperforms on-policy data generated by a weak student model, (c) SFT is robust to low-quality solutions, allowing for imprecise data filtering, and (d) question diversity is crucial for achieving data scaling gains. Based on these insights, we create the OpenMathInstruct-2 dataset which consists of 14M question-solution pairs (\u2248 600K unique questions), making it nearly eight times larger than the previous largest open-source math reasoning dataset. Finetuning the Llama-3.1-8B-Base using OpenMathInstruct-2 outperforms Llama3.1-8B-Instruct on MATH by an absolute 15.9% (51.9% \u2192 67.8%). Finally, to accelerate the open-source efforts, we release the code, the finetuned models, and the OpenMathInstruct-2 dataset under a commercially permissive license.", "title_embedding_index": 4572, "title_abs_embedding_index": 4597}, {"title": "MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science", "link_suffix": "/forum?id=GR0y0F3Ipd", "link": "https://openreview.net/forum?id=GR0y0F3Ipd", "pdf_link": "https://openreview.net/pdf?id=GR0y0F3Ipd", "keywords": "multi-modal reasoning, scientific reasoning, physical simulation", "abstract": "Pre-trained on extensive text and image corpora, current Multi-Modal Large Language Models (MLLM) have shown strong capabilities in general visual reasoning tasks. \nHowever, their performance is still lacking in physical domains that require understanding diagrams with complex physical structures and quantitative analysis based on multi-modal information. \nTo address this, we develop a new framework, namedMulti-Modal Scientific ReAsoning withPhysics Perception andSimulation (MAPS) based on an MLLM. \nMAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator. \nThe PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions. \nAt the inference stage, MAPS integrates the simulation language description of the input diagram provided by PPM and results obtained through a Chain-of-Simulation process with MLLM to derive the underlying rationale and the final answer. \nValidated using our collected college-level circuit analysis problems, MAPS significantly improves reasoning accuracy of MLLM and outperforms all existing models. \nThe results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs. \nWe will release our code, model and dataset used for our experiments upon publishing of this paper.", "title_embedding_index": 4573, "title_abs_embedding_index": 4598}, {"title": "MAESTRO: Masked Encoding Set Transformer with Self-Distillation", "link_suffix": "/forum?id=FEZOLWexPb", "link": "https://openreview.net/forum?id=FEZOLWexPb", "pdf_link": "https://openreview.net/pdf?id=FEZOLWexPb", "keywords": "self-supervision, representation learning, immunology, biology, single-cell, cytometry, set, set representations", "abstract": "The interrogation of cellular states and interactions in immunology research is an ever-evolving task, requiring adaptation to the current levels of high dimensionality. Cytometry enables high-dimensional profiling of immune cells, but its analysis is hindered by the complexity and variability of the data. We present MAESTRO, a self-supervised set representation learning model that generates vector representations of set-structured data, which we apply to learn immune profiles from cytometry data. Unlike previous studies only learn cell-level representations, whereas MAESTRO uses all of a sample's cells to learn a set representation. MAESTRO leverages specialized attention mechanisms to handle sets of variable number of cells and ensure permutation invariance, coupled with an online tokenizer by self-distillation framework. We benchmarked our model against existing cytometry approaches and other existing machine learning methods that have never been applied in cytometry. Our model outperforms existing approaches in retrieving cell-type proportions and capturing clinically relevant features for downstream tasks such as disease diagnosis and immune cell profiling.", "title_embedding_index": 4574, "title_abs_embedding_index": 4599}]
[
    {
        "title": "Rethinking Message Passing for Algorithmic Alignment on Graphs",
        "link_suffix": "/forum?id=BZr41xSleC",
        "link": "https://openreview.net/forum?id=BZr41xSleC",
        "pdf_link": "https://openreview.net/pdf?id=BZr41xSleC",
        "keywords": "Graph Neural Networks, Algorithm Learning, Message Passing",
        "abstract": "Most Graph Neural Networks are based on the principle of message-passing, where all neighboring nodes exchange messages with each other simultaneously. We want to challenge this paradigm by introducing the Flood and Echo Net, a novel architecture that aligns neural computation with the principles of distributed algorithms. \nIn our method, nodes sparsely activate upon receiving a message, leading to a wave-like activation pattern that traverses the graph. Through these sparse but parallel activations, the Net becomes more expressive than traditional MPNNs which are limited by the 1-WL test and also is provably more efficient in terms of message complexity.\nMoreover, the mechanism's ability to generalize across graphs of varying sizes positions it as a practical architecture for the task of algorithmic learning. We test the Flood and Echo Net on a variety of synthetic tasks and find that the algorithmic alignment of the execution improves generalization to larger graph sizes. Moreover, our method significantly improves generalization and correct execution in terms of graph accuracy on the SALSA-CLRS benchmark."
    },
    {
        "title": "Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization",
        "link_suffix": "/forum?id=hXm0Wu2U9K",
        "link": "https://openreview.net/forum?id=hXm0Wu2U9K",
        "pdf_link": "https://openreview.net/pdf?id=hXm0Wu2U9K",
        "keywords": "Reinforcement Learning Theory, Offline Reinforcement Learning, single-policy concentrability, pessimism, RLHF",
        "abstract": "Language model alignment methods, such as reinforcement learning from human feedback (RLHF), have\nled to impressive advances in language model capabilities. However, existing techniques are limited by a widely observed phenomenon known asoveroptimization, where the quality of the language model degrades over the course of the alignment process. Overoptimization occurs when a language model overfits to inaccuracies in an (either explicit or implicit) offline reward model, and drifts away from preferred responses covered by the data. To discourage such distribution shift, offline alignment methods typically employ KL-regularization, but this, as we show, is too weak to prevent degradation in performance. Then, can we design an efficient algorithm that is provably robust to overoptimization?In this paper, we advance theoretical understanding of sample-efficient offline alignment and introduce a new algorithm called $\\chi^2$-Preference Optimization ($\\chi$PO). $\\chi$PO is a one-line change to Direct Preference Optimization (DPO; Rafailov et al. 2023), that modifies only the logarithmic link function in the DPO objective. Despite this minimal change, $\\chi$PO implicitly implements the principle ofpessimism in the face of uncertaintyvia regularization with the $\\chi^2$-divergence---which quantifies uncertainty more effectively than KL-regularization---and provably alleviates overoptimization, achieving sample-complexity guarantees based onsingle-policy concentrability---the gold standard in offline reinforcement learning. This guarantee makes $\\chi$PO the first simple, yet general-purpose offline alignment algorithm that is provably robust to overoptimization."
    },
    {
        "title": "Cascaded Learned Bloom filter for Optimal Model-Filter Size Balance and Fast Rejection",
        "link_suffix": "/forum?id=GOjr2Ms5ID",
        "link": "https://openreview.net/forum?id=GOjr2Ms5ID",
        "pdf_link": "https://openreview.net/pdf?id=GOjr2Ms5ID",
        "keywords": "learned Bloom filter, learned index, membership query, optimization, dynamic programming",
        "abstract": "Recent studies have demonstrated that learned Bloom filters, which combine machine learning with the classical Bloom filter, can achieve superior memory efficiency. However, existing learned Bloom filters face two critical unresolved challenges: the balance between the machine learning model size and the Bloom filter size is not optimal, and the reject time cannot be minimized effectively. We propose the Cascaded Learned Bloom Filter (CLBF) to address these issues. Our optimization approach based on dynamic programming automatically selects configurations that achieve an optimal balance between the model and filter sizes while minimizing reject time. Experiments with real-world datasets show that CLBF reduces memory usage by up to 24% and decreases reject time by up to 14 times compared to the state-of-the-art learned Bloom filter."
    },
    {
        "title": "Uncertainty Quantification in Retrieval Augmented Question Answering",
        "link_suffix": "/forum?id=8r8H4gbFXf",
        "link": "https://openreview.net/forum?id=8r8H4gbFXf",
        "pdf_link": "https://openreview.net/pdf?id=8r8H4gbFXf",
        "keywords": "uncertainty quantification, retrieval augmented question answering, large language models",
        "abstract": "Retrieval augmented Question Answering (QA) enables QA models to overcome knowledge gaps when answering questions at test time by taking as input the question together with retrieved evidence, that is usually a set of passages.  Previous studies show that this approach has numerous benefits such as improving QA performance and reducing hallucinations, without, however, qualifying whether the retrieved passages are indeed useful at answering correctly. In this work, we evaluate existing uncertainty quantification approaches and propose an approach that predicts answer correctness based on utility judgements on individual input passages. We train a small neural model that predicts passage utility for a target QA model. We find that simple information theoretic metrics can predict answer correctness up to a certain extent, more expensive sampling based approaches perform better, while our lightweight approach can efficiently approximate or improve upon sampling-based approaches."
    },
    {
        "title": "Efficient Visualization of Implicit Neural Representations via Weight Matrix Analysis",
        "link_suffix": "/forum?id=0OzDMjPHa3",
        "link": "https://openreview.net/forum?id=0OzDMjPHa3",
        "pdf_link": "https://openreview.net/pdf?id=0OzDMjPHa3",
        "keywords": "Implicit neural representation, pruning, visualization, adaptive mesh refinement",
        "abstract": "An implicit neural representation (INR) is a neural network that approximates a function over space and possibly time.  Memory-intensive visualization tasks, including modern 4D CT scanning methods, represent data natively as INRs.  While such INRs are prized for being more memory-efficient than traditional data on a lattice, discretization to a regular grid is still required for many visualization tasks.  We present an algorithm to store high-resolution voxel data only for regions with significant detail, reducing memory requirements.  To identify these high-detail areas, we use an interpolative decomposition pruning method on the weight matrices of the INR.  The information from pruning is used to guide adaptive mesh refinement, allowing automatic mesh generation, tailored to the underlying resolution of the function.  From a pre-trained INR with no access to its training data, we produce a variable resolution visualization with significant memory savings."
    },
    {
        "title": "Integrating Distributed Acoustic Sensing and PINN Frameworks for Enhanced Indoor Sound Source Localization",
        "link_suffix": "/forum?id=S2WUJUETyc",
        "link": "https://openreview.net/forum?id=S2WUJUETyc",
        "pdf_link": "https://openreview.net/pdf?id=S2WUJUETyc",
        "keywords": "distributed acoustic sensing, physics informed neural networks, room acoustics, sound source localization",
        "abstract": "Distributed Acoustic Sensing (DAS) is an emerging technology that transforms standard optical fibers into dense arrays of acoustic sensors, offering unprecedented opportunities for smart city applications, indoor monitoring of human activity, and surveillance without compromising privacy. In this paper, we integrate DAS with Physics-Informed Neural Networks (PINNs) for indoor sound source localization. By embedding the acoustic wave equation and impedance boundary conditions into the neural network architecture, we exploit physical laws to guide the learning process, improving accuracy and generalization. We propose two strategies for real-time sound source localization using DAS data. The first strategy involves training the PINN on all available data simultaneously, while the second strategy incrementally feeds data over time, simulating real-time data acquisition. Using real indoor DAS measurements, we demonstrate the effectiveness of our approach in deciphering complex room acoustics and accurately inferring sound source locations under both strategies. Our framework provides a novel solution for real-time indoor positioning and human activity surveillance, offering significant advantages over traditional camera-based systems by preserving individual privacy."
    },
    {
        "title": "High Probability Bounds for Cross-Learning Contextual Bandits with Unknown Context Distributions",
        "link_suffix": "/forum?id=zzR1Uskhj0",
        "link": "https://openreview.net/forum?id=zzR1Uskhj0",
        "pdf_link": "https://openreview.net/pdf?id=zzR1Uskhj0",
        "keywords": "contextual bandits, cross-learning, high-probability bounds",
        "abstract": "Motivated by applications in online bidding and sleeping bandits, we examine the problem of contextual bandits with cross learning, where the learner observes the loss associated with the action across all possible contexts, not just the current round’s context. Our focus is on a setting where losses are chosen adversarially, and contexts are sampled i.i.d. from a specific distribution. This problem was first studied by  Balseiro et al. (2019), who proposed an algorithm that achieves near-optimal regret under the assumption that the context distribution is known in advance. However, this assumption is often unrealistic. To address this issue, Schneider & Zimmert (2023) recently proposed a new algorithm that achieves nearly optimal expected regret. It is well-known that expected regret can be significantly weaker than high-probability bounds. In this paper, we present a novel, in-depth analysis of their algorithm and demonstrate that it actually achieves near-optimal regret with $\\textit{high probability}$. There are steps in the original analysis by Schneider & Zimmert (2023) that lead only to an expected bound by nature. In our analysis, we introduce several new insights. Specifically, we make extensive use of the weak dependency structure between different epochs, which was overlooked in previous analyses. Additionally, standard martingale inequalities are not directly applicable, so we refine martingale inequalities to complete our analysis."
    },
    {
        "title": "AutoRegressive Knowledge Base Completion",
        "link_suffix": "/forum?id=n87wrNlcJu",
        "link": "https://openreview.net/forum?id=n87wrNlcJu",
        "pdf_link": "https://openreview.net/pdf?id=n87wrNlcJu",
        "keywords": "Knowledge Graphs, Probabilistic Reasoning",
        "abstract": "Despite their large sizes, many Knowledge Graphs (KGs) remain highly incomplete. This problem has motivated numerous approaches to $\\textit{complete}$ the KGs by embedding them in a latent space to find the missing links. Although these methods show promising performance, a general limitation is that the scores given to possible links are uncalibrated and cannot be interpreted across different queries. Hence, we say they are $\\textit{local}$ as they relate to a specific context. This limitation makes it non-trivial to deduce the truth value of the links and to answer complex queries. Another limitation is that their learning depends on negative sampling, which is challenging due to the Open World Assumption (OWA).To solve this problem, we propose a novel auto-regressive generative model that learns a joint distribution of the entities and relations of the KG without resorting to negative sampling. This distribution can be used to infer the probability that a link is sampled from the KG, which allows us to return a $\\textit{global}$ score that is interpretable in different contexts. Moreover, our method has the additional advantage that it offers probabilistic semantics for complex reasoning and knowledge base completion, achieving state-of-the-art performance on link prediction with consistent scores across the entire KG."
    },
    {
        "title": "Lift Your Molecules: Molecular Graph Generation in Latent Euclidean Space",
        "link_suffix": "/forum?id=uNomADvF3s",
        "link": "https://openreview.net/forum?id=uNomADvF3s",
        "pdf_link": "https://openreview.net/pdf?id=uNomADvF3s",
        "keywords": "Drug Design, Computational Biology, Molecule Generation, Graph Generation, Latent Diffusion Models",
        "abstract": "We introduce a new framework for 2D molecular graph generation using 3D molecule generative models. Our Synthetic Coordinate Embedding (SyCo) framework maps 2D molecular graphs to 3D Euclidean point clouds via synthetic coordinates and learns the inverse map using an E($n$)-Equivariant Graph Neural Network (EGNN). The induced point cloud-structured latent space is well-suited to apply existing 3D molecule generative models. This approach simplifies the graph generation problem into a point cloud generation problem followed by node and edge classification tasks, without relying on molecular fragments nor autoregressive decoding. Further, we propose a novel similarity-constrained optimization scheme for 3D diffusion models based on inpainting and guidance. As a concrete implementation of our framework, we develop EDM-SyCo based on the E(3) Equivariant Diffusion Model (EDM). EDM-SyCo achieves state-of-the-art performance in distribution learning of molecular graphs, outperforming the best non-autoregressive methods by more than 26% on ZINC250K and 16% on the GuacaMol dataset while improving conditional generation by up to 3.9 times."
    },
    {
        "title": "Neural Sampling from Boltzmann Densities: Fisher-Rao Curves in the Wasserstein Geometry",
        "link_suffix": "/forum?id=TUvg5uwdeG",
        "link": "https://openreview.net/forum?id=TUvg5uwdeG",
        "pdf_link": "https://openreview.net/pdf?id=TUvg5uwdeG",
        "keywords": "Sampling, Boltzmann densities, Fisher-Rao Curves, Wasserstein Gradient Flows, Diffusion, Interpolations",
        "abstract": "We deal with the task of sampling from an unnormalized Boltzmann density $\\rho_D$\nby learning a Boltzmann curve given by energies $f_t$ starting in a simple density $\\rho_Z$.\nFirst, we examine conditions under which Fisher-Rao flows are absolutely continuous in the Wasserstein geometry.\nSecond, we address specific interpolations $f_t$ and  the learning of the related density/velocity pairs $(\\rho_t,v_t)$.\nIt was numerically observed that the linear interpolation, \nwhich requires only a parametrization of the velocity field $v_t$,\nsuffers from  a \"teleportation-of-mass\" issue.\nUsing tools from the Wasserstein geometry,\nwe give an analytical example,\nwhere we can precisely measure the explosion of the velocity field.\nInspired by Máté and Fleuret, who \nparametrize both $f_t$ and $v_t$, we propose an\ninterpolation which parametrizes only $f_t$ and fixes an appropriate $v_t$. \nThis corresponds to\nthe Wasserstein gradient flow of the Kullback-Leibler divergence related to Langevin dynamics. \nWe demonstrate by numerical examples that our model provides a well-behaved flow field which successfully solves the above sampling task."
    },
    {
        "title": "Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets",
        "link_suffix": "/forum?id=yYxEFC3Ep4",
        "link": "https://openreview.net/forum?id=yYxEFC3Ep4",
        "pdf_link": "https://openreview.net/pdf?id=yYxEFC3Ep4",
        "keywords": "geographical profiling, dataset auditing",
        "abstract": "Building on studies documenting gender and racial biases in vision-language models, recent works show that such models often fail to generate geographically-representative images that accurately reflect different regions around the world. A common concern is that the data used to train these models is not representative, prompting the question:which parts of the world do these training examples come from?To answer this question, we develop a system,GeoProfiler, which geographically profiles multimodal datasets by mapping image-caption pairs to countries. Using location information from captions, GeoProfiler maps examples to countries with a high precision ($0.86$). We then applyGeoProfilerto geographically profile the English captions of the LAION dataset for $10$ common entities (e.g., house, flag, etc.). We observe the geographical distribution of $8$ entities to obey the power law distribution. The United States, the United Kingdom, and India are most represented, appearing in 53.7% of samples. Problematically, African and South American countries are severely under-represented with only 2.0 % and 4.3 % of images respectively. We also observe a high correlation between a country's GDP and frequency ($\\rho=0.79$). Lastly, we analyze the diversity of images from individual countries, and find that more images does not imply higher diversity."
    },
    {
        "title": "ProtEx: A Retrieval-Augmented Approach for Protein Function Prediction",
        "link_suffix": "/forum?id=ZxZabvtLwV",
        "link": "https://openreview.net/forum?id=ZxZabvtLwV",
        "pdf_link": "https://openreview.net/pdf?id=ZxZabvtLwV",
        "keywords": "Protein function prediction, retrieval-augmented, semiparametric, protein language model, protein annotation",
        "abstract": "Mapping a protein sequence to its underlying biological function is a critical problem of increasing importance in biology. In this work, we propose ProtEx, a retrieval-augmented approach for protein function prediction that leverages exemplars from a database to improve accuracy and robustness and enable generalization to unseen classes. Our approach relies on a novel multi-sequence pretraining task, and a fine-tuning strategy that effectively conditions predictions on retrieved exemplars. Our method achieves state-of-the-art results across multiple datasets and settings for predicting Enzyme Commission (EC) numbers, Gene Ontology (GO) terms, and Pfam families. Our ablations and analysis highlight the impact of conditioning predictions on exemplar sequences, especially for classes and sequences less well represented in the training data."
    },
    {
        "title": "GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation",
        "link_suffix": "/forum?id=hPWWXpCaJ7",
        "link": "https://openreview.net/forum?id=hPWWXpCaJ7",
        "pdf_link": "https://openreview.net/pdf?id=hPWWXpCaJ7",
        "keywords": "Robot Manipulation; Vision Language Action Model",
        "abstract": "With the rapid development of embodied artificial intelligence, significant progress has been made in vision-language-action (VLA) models for general robot decision-making. However, the majority of existing VLAs fail to account for the inevitable external perturbations encountered during deployment. These perturbations introduce unforeseen state information to the VLA, resulting in inaccurate actions and consequently, a significant decline in generalization performance. The classic internal model control (IMC) principle demonstrates that a closed-loop system with an internal model that includes external input signals can accurately track the reference input and effectively offset the disturbance. We propose a novel closed-loop VLA method GEVRM that integrates the IMC principle to enhance the robustness of robot visual manipulation. The text-guided video generation model in GEVRM can generate highly expressive future visual planning goals. Simultaneously, we evaluate perturbations by simulating responses, which are called internal embeddings and optimized through prototype contrastive learning. This allows the model to implicitly infer and distinguish perturbations from the external environment. The proposed GEVRM achieves state-of-the-art performance on both standard and perturbed CALVIN benchmarks and shows significant improvements in realistic robot tasks."
    },
    {
        "title": "Revealing and Mitigating Over-Attention in Knowledge Editing",
        "link_suffix": "/forum?id=4l3AH8Bhmt",
        "link": "https://openreview.net/forum?id=4l3AH8Bhmt",
        "pdf_link": "https://openreview.net/pdf?id=4l3AH8Bhmt",
        "keywords": "model editing, mechanistic interpretability, NLP, language models",
        "abstract": "Large Language Models~(LLMs) have demonstrated superior performance across a wide range of tasks, but they still exhibit undesirable errors due to incorrect knowledge learned from the training data. To avoid this, knowledge editing methods emerged to precisely edit the specific model knowledge via efficiently modifying a very small percentage of parameters. However, those methods can lead to the problem ofSpecificity Failure, where the existing knowledge and capabilities are severely degraded due to editing.\nOur preliminary indicates that Specificity Failure primarily stems from the model's attention heads assigning excessive attention scores to entities related to the edited knowledge, thereby unduly focusing on specific snippets within the context, which we denote as theAttention Driftphenomenon.\nTo mitigate such Attention Drift issue, we introduce a simple yet effective methodSelectiveAttentionDriftRestriction(SADR), which introduces an additional regularization term during the knowledge editing process to restrict changes in the attention weight distribution, thereby preventing undue focus on the edited entity.\nExperiments on five frequently-used strong LLMs demonstrate the effectiveness of our method, where SADR can significantly mitigate Specificity Failure in the predominant knowledge editing tasks."
    },
    {
        "title": "ANYTEXT2: Visual Text Generation and Editing with Customizable Attributes",
        "link_suffix": "/forum?id=xoW1Cb4MkP",
        "link": "https://openreview.net/forum?id=xoW1Cb4MkP",
        "pdf_link": "https://openreview.net/pdf?id=xoW1Cb4MkP",
        "keywords": "Text-to-Image, Visual Text Generation, Visual Text Editing, Customizable Attributes",
        "abstract": "With the ongoing development in the text-to-image(T2I) domain, accurately generating text within images seamlessly integrating with the visual content has garnered increasing interest from the research community. In addition to controlling glyphs and positions of text, there is a rising demand for more fine-grained control over text attributes, such as font style and color, while maintaining the realism of the generated images. However, this issue has not yet been sufficiently explored. In this paper, we present AnyText2, the first known method to achieve precise control over the attributes of every line of multilingual text when generating images of natural scenes. Our method comprises two main components. First, we introduce an efficient WriteNet+AttnX architecture that encodes text features and injects these intermediate features into the U-Net decoder via learnable attention layers. This design is 19.8% faster than its predecessor, AnyText, and improves the realism of the generated images. Second, we thoroughly explore methods for extracting text fonts and colors from real images, and then develop a Text Embedding Module that employs multiple encoders to separately encode the glyph, position, font, and color of the text. This enables customizable font and color for each text line, yielding a 3.3% and 9.3% increase in text accuracy for Chinese and English, respectively, compared to AnyText. Furthermore, we validate the use of long captions, which enhances prompt-following and image realism without sacrificing text writing accuracy. Through comprehensive experiments, we demonstrate the state-of-the-art performance of our method. The code and model will be open-sourced in the future to promote the development of text generation technology."
    },
    {
        "title": "A Generalist Hanabi Agent",
        "link_suffix": "/forum?id=pCj2sLNoJq",
        "link": "https://openreview.net/forum?id=pCj2sLNoJq",
        "pdf_link": "https://openreview.net/pdf?id=pCj2sLNoJq",
        "keywords": "Multi-Agent Reinforcement Learning (MARL), Cooperative game, Multi Agent Text-based game",
        "abstract": "Traditional multi-agent reinforcement learning (MARL) systems can develop cooperative strategies through repeated interactions. However, these systems are unable to perform well on any other setting than the one they have been trained on, and struggle to successfully cooperate with unfamiliar collaborators. This is particularly visible in the Hanabi benchmark, a popular 2-to-5 player cooperative card-game which requires complex reasoning and precise assistance to other agents. Current MARL agents for Hanabi can only learn one specific game-setting (e.g., 2-player games), and play with the same algorithmic agents. This is in stark contrast to humans, who can quickly adjust their strategies to work with unfamiliar partners or situations. In this paper, we introduce a generalist agent for Hanabi, designed to overcome these limitations. We reformulate the task using text, as language has been shown to improve transfer. We then propose a distributed MARL algorithm that copes with the resulting dynamic observation- and action-space. In doing so, our agent is the first that can play all game settings concurrently, and extend strategies learned from one setting to other ones. As a consequence, our agent also demonstrates the ability to collaborate with different algorithmic agents ---agents that are themselves unable to do so."
    },
    {
        "title": "Exact Certification of (Graph) Neural Networks Against Label Poisoning",
        "link_suffix": "/forum?id=d9aWa875kj",
        "link": "https://openreview.net/forum?id=d9aWa875kj",
        "pdf_link": "https://openreview.net/pdf?id=d9aWa875kj",
        "keywords": "graph neural networks, robustness, certificates, provable robustness, neural networks, label poisoning, label flipping, poisoning, mixed-integer linear programming, neural tangent kernel, support vector machines",
        "abstract": "Machine learning models are highly vulnerable to label flipping, i.e., the adversarial modification (poisoning) of training labels to compromise performance. Thus, deriving robustness certificates is important to guarantee that test predictions remain unaffected and to understand worst-case robustness behavior. However, for Graph Neural Networks (GNNs), the problem of certifying label flipping has so far been unsolved. We change this by introducing an exact certification method, deriving both sample-wise and collective certificates. Our method leverages the Neural Tangent Kernel (NTK) to capture the training dynamics of wide networks enabling us to reformulate the bilevel optimization problem representing label flipping into a Mixed-Integer Linear Program (MILP). We apply our method to certify a broad range of GNN architectures in node classification tasks. Thereby, concerning the worst-case robustness to label flipping: $(i)$ we establish hierarchies of GNNs on different benchmark graphs; $(ii)$ quantify the effect of architectural choices such as activations, depth and skip-connections; and surprisingly, $(iii)$ uncover a novel phenomenon of the robustness plateauing for intermediate perturbation budgets across all investigated datasets and architectures. While we focus on GNNs, our certificates are applicable to any NN through its NTK. Thus, our work presents the first exact certificate to a poisoning attack ever derived for neural networks, which could be of independent interest."
    },
    {
        "title": "Learning through experience:Episodic memory representation for cognitive agents",
        "link_suffix": "/forum?id=0iXfS9Smqf",
        "link": "https://openreview.net/forum?id=0iXfS9Smqf",
        "pdf_link": "https://openreview.net/pdf?id=0iXfS9Smqf",
        "keywords": "Episodic Memory, Bio inspired Robot learning, incremental Memory structures",
        "abstract": "As the demand for intelligent robots and cognitive agents rises, the ability to retain and utilize past experiences through episodic memory has become crucial, especially for social companion robots that rely on previous interactions for task execution. To address this, we introduce Episodic Memory for Cognitive Agents (EMCA), a novel framework that advances knowledge representation by integrating real-world interactions. EMCA enables agents to adapt to complex environments by learning from tasks, interacting with humans, and processing multimodal data—such as speech, vision, and non-verbal cues—without pre-training on specific scenarios.\nEMCA models episodic memory through a graph-based structure , allowing for incremental storage and retrieval of experiences. Each interaction or event enriches the memory graph, supporting continuous learning and adaptation without extensive retraining. This human-like memory formation optimizes the agent’s ability to retrieve relevant information for tasks like localization, planning, and reasoning based on prior experiences.Unlike conventional models relying on temporal markers or recurrent patterns, EMCA encodes data like human memory, allowing reasoning across diverse scenarios regardless of temporal patterns. The framework dynamically builds a memory graph with semantic and temporal connections based on the agent’s experiences, promoting flexible temporal reasoning. It also introduces mechanisms for clustering new memories and a dynamic retrieval policy that adjusts based on context or query type, ensuring robustness even in unpredictable scenarios. Empirical tests show EMCA adapts effectively to real-world data, offering reliability and flexibility in dynamic environments."
    },
    {
        "title": "Rate/Distortion Constrained Model Quantization for Efficient Storage and Inference",
        "link_suffix": "/forum?id=LnKDcqOfgy",
        "link": "https://openreview.net/forum?id=LnKDcqOfgy",
        "pdf_link": "https://openreview.net/pdf?id=LnKDcqOfgy",
        "keywords": "quantization, model compression, rate-distortion theory, compression",
        "abstract": "The proliferation of large pre-trained neural networks has recently revived research in both quantization of network weights (for faster inference), and in their\ncompression (to reduce file sizes). However, there has so far been little idea transfer between the two lines of research. In this paper, we combine techniques from\nquantization and compression to propose an efficient and highly effective post-training compression method for large neural networks. Our method extends the\nrecently published quantization method OPTQ (Frantar et al., 2023) with a tunable\nrate/distortion trade-off by introducing a cost per bit into OPTQ's rounding\noperation. Crucially, we estimate the bit rate based on the predictive model used\nin the state-of-the-art neural network compression method NNCodec (Becking\net al., 2023). In our experiments with several standard pre-trained networks from\nthe computer vision community, our method leads to significantly (up to 2.7x)\nsmaller file sizes than NNCodec at equal model performance, generally compressing to less than half a bit per network weight and implicitly pruning insignificant weights.\nAdditionally, and in contrast to NNcodec, our method offers the same opportunities for inference speed-ups as OPTQ. By proving that file size and inference\ncost can be reduced simultaneously, we hope that our contribution shows a path\ntowards deploying large neural networks on end-user devices, alleviating privacy\nconcerns, regulatory constraints, and dependency on large service providers."
    },
    {
        "title": "Text as Any-Modality for Zero-shot Classification by Consistent Prompt Tuning",
        "link_suffix": "/forum?id=vKL1i2p5Xr",
        "link": "https://openreview.net/forum?id=vKL1i2p5Xr",
        "pdf_link": "https://openreview.net/pdf?id=vKL1i2p5Xr",
        "keywords": "Multimodal Learning ; Prompt Learning; Zero-shot Classification;",
        "abstract": "The integration of prompt tuning with multimodal learning has shown significant generalization abilities for various downstream tasks. Despite advancements, existing methods heavily depend on massive modality-specific labeled data (e.g., video, audio, and image), or are customized for a single modality. In this study, we present Text as Any-Modality by Consistent Prompt Tuning (TaAM-CPT), a scalable approach for constructing a general representation model toward unlimited modalities using solely text data. TaAM-CPT comprises modality prompt pools, text construction, and modality-aligned text encoders from pre-trained models, which allows for extending new modalities by adding prompt pools and modality-aligned text encoders. To harmonize the learning across different modalities, TaAM-CPT designs intra- and inter-modal learning objectives, which can capture category details within modalities while maintaining semantic consistency across different modalities. Benefiting from its scalable architecture and pre-trained models, TaAM-CPT can be seamlessly extended to accommodate unlimited modalities. Remarkably, without any modality-specific labeled data, TaAM-CPT achieves leading results on diverse datasets spanning various modalities, including video classification (Kinetic-400/600/700), image classification (MSCOCO, VOC2007, NUSWIDE, VOC2012, Objects365), and audio classification (ESC50, US8K). The code is available athttps://anonymous.4open.science/r/TaAM-CPT-0EA6."
    },
    {
        "title": "Dynamic Taylor Convolutional Neural Network for Few-Shot Point Cloud Semantic Segmentation",
        "link_suffix": "/forum?id=u8y7wYYs2D",
        "link": "https://openreview.net/forum?id=u8y7wYYs2D",
        "pdf_link": "https://openreview.net/pdf?id=u8y7wYYs2D",
        "keywords": "Point Cloud Semantic Segmentation; Few-Shot Learning; Taylor Series; Dynamic Convolution; Prototype Refinement",
        "abstract": "Few-shot Point cloud semantic segmentation remains a challenge in the field of computer vision due to the limitations of the pre-training learning paradigm and insufficient local geometric structure representation. To address this issue, we propose a novel pre-training-free Dynamic Taylor Convolutional Neural Network, called DyTaylorCNN ingeniously, which combines the potential of the Taylor series in local structure representation with the flexibility and adaptability of dynamic convolutions. The core of DyTaylorCNN lies in two innovative components: the Dynamic Taylor Convolution (DyTaylorConv) and the Interactive Prototype Refinement (IPR) Module. Inspired by the Taylor series and dynamic convolution, DyTaylorConv performs local structure fitting by collaborating between the Low-order Convolution (LoConv) and the Dynamic High-order Convolution (DyHiConv). LoConv is designed based on position encoding, focusing on extracting the basic geometric information of point clouds, while DyHiConv adaptively models complex local geometric features by learning spatial priors to generate dynamic weights. Moreover, the IPR Module effectively reduces the domain distribution gap by learning fine-grained prototype features, further enhancing the model's generalization capability. Experimental results on multiple benchmark datasets demonstrate that the proposed DyTaylorCNN significantly outperforms current state-of-the-art methods."
    },
    {
        "title": "Avoiding mode collapse in diffusion models fine-tuned with reinforcement learning",
        "link_suffix": "/forum?id=fXkoROek1M",
        "link": "https://openreview.net/forum?id=fXkoROek1M",
        "pdf_link": "https://openreview.net/pdf?id=fXkoROek1M",
        "keywords": "Generative Models, Diffusion Models, Reinforcement Learning, Hierarchical RL",
        "abstract": "Fine-tuning foundation models via reinforcement learning (RL) has proven promising for aligning to downstream objectives. In the case of diffusion models (DMs), though RL training improves alignment from early timesteps, critical issues such as training instability and mode collapse arise. We address these drawbacks by exploiting the hierarchical nature of DMs: we train them dynamically at each epoch with a tailored RL method, allowing for continual evaluation and step-by-step refinement of the model performance (or alignment). Furthermore, we find that not every denoising step needs to be fine-tuned to align DMs to downstream tasks. Consequently, in addition to clipping, we regularise model parameters at distinct learning phases via a sliding-window approach. Our approach, termed Hierarchical Reward Fine-tuning (HRF), is validated on the Denoising Diffusion Policy Optimisation method, where we show that models trained with HRF achieve better preservation of diversity in downstream tasks, thus enhancing the fine-tuning robustness and at uncompromising mean rewards."
    },
    {
        "title": "GridAgent: A 2D Grid-Based Game Framework And Benchmark For Multimodal Large Language Models",
        "link_suffix": "/forum?id=jpypMKAsO6",
        "link": "https://openreview.net/forum?id=jpypMKAsO6",
        "pdf_link": "https://openreview.net/pdf?id=jpypMKAsO6",
        "keywords": "MLLM; benchmark; game",
        "abstract": "Multimodal Large Language Models (MLLMs) integrate the linguistic capabilities of LLMs with the ability to process multimodal data, enabling them to address a wider array of tasks. However, a comprehensive and standardized benchmark for evaluating MLLMs' complex visual reasoning performance in multimodal tasks has yet to be established. We introduce GridAgent, a versatile 2D grid-based framework that serves as a benchmark for assessing five essential capabilities of MLLMs: execution, perception reasoning, memory, learning, and planning. The framework includes twelve unique game tasks specifically designed to avoid overlap with the model's pre-training corpus. Each task targets at least one core competency and is enriched with diverse semantic information. Additionally, the game layouts are randomly generated, ensuring a more rigorous and authentic assessment of the MLLMs' capabilities. Experimental results indicate that although certain MLLMs excel in specific capabilities, none exhibit a comprehensive skill set comparable to the human baseline. Our work can be seen at:https://iclr2025gridagent.github.io/GridAgent-website."
    },
    {
        "title": "Integrating Planning into Single-Turn Long-Form Text Generation",
        "link_suffix": "/forum?id=YONCcPQJoC",
        "link": "https://openreview.net/forum?id=YONCcPQJoC",
        "pdf_link": "https://openreview.net/pdf?id=YONCcPQJoC",
        "keywords": "LLM, planning, long-form text generation",
        "abstract": "Generating high-quality, in-depth textual documents, such as academic papers, news articles, Wikipedia entries, and books, remains a significant challenge for Large Language Models (LLMs).  In this paper, we propose to use planning to generate long form content. To achieve our goal, we generate intermediate steps via an auxiliary task that teaches the LLM to plan, reason and structure before generating the final text. Our main novelty lies in a single auxiliary task that does not require multiple rounds of prompting or planning. To overcome the scarcity of training data for these intermediate steps, we leverage LLMs to generate synthetic intermediate writing data such as outlines, key information and summaries from existing full articles. Our experiments demonstrate on two datasets from different domains, namely the scientific news dataset SciNews and Wikipedia datasets in KILT-Wiki and FreshWiki, that LLMs fine-tuned with the auxiliary task generate higher quality documents. We observed +2.5% improvement in ROUGE-Lsum, and a strong 3.60 overall win/loss ratio via human SxS evaluation, with clear wins in organization, relevance, and verifiability."
    },
    {
        "title": "SepNorm: Generalization of Lion and Normalised Gradient Methods",
        "link_suffix": "/forum?id=AM4AT2MyXQ",
        "link": "https://openreview.net/forum?id=AM4AT2MyXQ",
        "pdf_link": "https://openreview.net/pdf?id=AM4AT2MyXQ",
        "keywords": "Optimization, Lion, Deep Learning",
        "abstract": "In this paper, we investigate the novel optimizer Lion (Evolved Sign Momentum), which demonstrates superior performance compared to the well-established Adam in a wide range of tasks. Lion is a combination of Sign Gradient Descent (SignGD) and momentum, utilizing a fixed step size and adjusting the gradient direction via a sign operation. Despite its promising results, Lion currently lacks comprehensive theoretical justification. We also discuss Normalized Gradient Descent methods, characterized by a fixed step size, which predate Lion. We show that both Lion and NormGD have notable disadvantages, and to address these issues, we propose a new method SepNorm, which normalizes gradients across different parameter groups. SepNorm generalizes both Lion and NormGD, offering a more adaptable and stable optimization approach. Our theoretical analysis on quadratic functions reveals mechanisms of convergence behind the methods and allows us to formulate implicit bias criteria for them. Additionally, we introduce OrtSepNorm, an extension of SepNorm that makes update direction orthogonal to the weights, and we demonstrate that OrtSepNorm converges to a fixed weight norm, thereby making the training process more stable. Empirical evaluations reveal that SepNorm and OrtSepNorm outperform both Lion and Adam in a range of computer vision (CV) and natural language processing (NLP) tasks."
    }
]
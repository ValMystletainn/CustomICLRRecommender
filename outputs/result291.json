[
    {
        "title": "A Theory for Token-Level Harmonization in Retrieval-Augmented Generation",
        "link_suffix": "/forum?id=tbx3u2oZAu",
        "link": "https://openreview.net/forum?id=tbx3u2oZAu",
        "pdf_link": "https://openreview.net/pdf?id=tbx3u2oZAu",
        "keywords": "Retrieval-augmented generation, Duality, Large Language Models",
        "abstract": "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance large language models (LLMs). Studies show that while RAG provides valuable external information (benefit), it may also mislead LLMs (detriment) with noisy or incorrect retrieved texts. Although many existing methods attempt to preserve benefit and avoid detriment, they lack a theoretical explanation for RAG. The benefit and detriment in the next token prediction of RAG remain a 'black box' that cannot be quantified or compared in an explainable manner, so existing methods are data-driven, need additional utility evaluators or post-hoc. This paper takes the first step towards providing a theory to explain and trade off the benefit and detriment in RAG. We model RAG as the fusion between distributions of LLMs\u2019 knowledge and distributions of retrieved texts. Then, we formalize the trade-off between the value of external knowledge (benefit) and its potential risk of misleading LLMs (detriment) in next token prediction of RAG by distribution difference in this fusion. Finally, we prove that the actual effect of RAG on the token, which is the comparison between benefit and detriment, can be predicted without any training or accessing the utility of retrieval. Based on our theory, we propose a practical novel method, Tok-RAG, which achieves collaborative generation between the pure LLM and RAG at token level to preserve benefit and avoid detriment. Experiments in real-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the effectiveness of our method and support our theoretical findings. Code is in supplemental material and will be released on GitHub after acceptance."
    },
    {
        "title": "RAG-SR: Retrieval-Augmented Generation for Neural Symbolic Regression",
        "link_suffix": "/forum?id=NdHka08uWn",
        "link": "https://openreview.net/forum?id=NdHka08uWn",
        "pdf_link": "https://openreview.net/pdf?id=NdHka08uWn",
        "keywords": "Symbolic Regression, Genetic Programming, Transformers, Deep Learning",
        "abstract": "Symbolic regression is a key task in machine learning, aiming to discover mathematical expressions that best describe a dataset. While deep learning has increased interest in using neural networks for symbolic regression, many existing approaches rely on pre-trained models. These models require significant computational resources and struggle with regression tasks involving unseen functions and variables. A pre-training-free paradigm is needed to better integrate with search-based symbolic regression algorithms. To address these limitations, we propose a novel framework for symbolic regression that integrates evolutionary feature construction with a neural network, without the need for pre-training. Our approach adaptively generates symbolic trees that align with the desired semantics in real-time using a language model trained via online supervised learning, providing effective building blocks for feature construction. To mitigate hallucinations from the language model, we design a retrieval-augmented generation mechanism that explicitly leverages searched symbolic expressions. Additionally, we introduce a scale-invariant data augmentation technique that further improves the robustness and generalization of the model. Experimental results demonstrate that our framework achieves state-of-the-art accuracy across 25 regression algorithms and 120 regression tasks."
    },
    {
        "title": "Solving PDEs via learnable quadrature",
        "link_suffix": "/forum?id=tl63stKeSC",
        "link": "https://openreview.net/forum?id=tl63stKeSC",
        "pdf_link": "https://openreview.net/pdf?id=tl63stKeSC",
        "keywords": "neural network, quadrature rule, PINN",
        "abstract": "Partial differential Equations (PDEs) are an essential tool across science and engineering. Recent work has shown how contemporary developments in machine learning models can directly help in improving methods for solution discovery of PDEs. This line of work falls under the umbrella of Physics-Informed Machine Learning. A key step in solving a PDE is to determine a set of points in the domain where the current iterate of the PDE's solution will be evaluated. The most prevalent strategy here is to use Monte Carlo sampling, but it is widely known to be sub-optimal in lower dimensions. We leverage recent advances in asymptotic expansions of quadrature nodes and weights (for weight functions belonging to the modified Gauss-Jacobi family) together with suitable adjustments for parameterization towards a data-driven framework for learnable quadrature rules. A direct benefit is a performance improvement in solving PDEs via neural networks, relative to existing alternatives, on a set of problems commonly studied in the literature. Beyond finding a standard solution for an instance of a single PDE, our construction enables learning rules to predict solutions for a given family of PDEs via a simple use of hyper-networks, a broadly useful capability."
    },
    {
        "title": "Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models",
        "link_suffix": "/forum?id=wH8XXUOUZU",
        "link": "https://openreview.net/forum?id=wH8XXUOUZU",
        "pdf_link": "https://openreview.net/pdf?id=wH8XXUOUZU",
        "keywords": "efficient high-resolution diffusion models",
        "abstract": "We present Deep Compression Autoencoder (DC-AE), a new family of autoencoder models for accelerating high-resolution diffusion models. Existing autoencoder models have demonstrated impressive results at a moderate spatial compression ratio (e.g., 8x), but fail to maintain satisfactory reconstruction accuracy for high spatial compression ratios (e.g., 64x). We address this challenge by introducing two key techniques: (1) Residual Autoencoding, where we design our models to learn residuals based on the space-to-channel transformed features to alleviate the optimization difficulty of high spatial-compression autoencoders; (2) Decoupled High-Resolution Adaptation, an efficient decoupled three-phases training strategy for mitigating the generalization penalty of high spatial-compression autoencoders. With these designs, we improve the autoencoder's spatial compression ratio up to 128 while maintaining the reconstruction quality. Applying our DC-AE to latent diffusion models, we achieve significant speedup without accuracy drop. For example, on ImageNet 512x512, our DC-AE provides 19.1x inference speedup and 17.9x training speedup on H100 GPU for UViT-H while achieving a better FID, compared with the widely used SD-VAE-f8 autoencoder. Our code and models will be released upon publication."
    },
    {
        "title": "Towards Codec-LM Co-design for Neural Codec Language Models",
        "link_suffix": "/forum?id=KCVv3tICvp",
        "link": "https://openreview.net/forum?id=KCVv3tICvp",
        "pdf_link": "https://openreview.net/pdf?id=KCVv3tICvp",
        "keywords": "text-to-speech, audio generation, neural audio codecs, codec LMs, co-design",
        "abstract": "Neural codec language models (orcodec LMs) are emerging as a powerful framework for text-to-speech (TTS) and other audio generation tasks. These models leverage advancements in language modeling and high-fidelity residual vector quantization (RVQ)-based audio codecs, which compress continuous waveforms into discrete codes for LMs to process. Despite the close interdependence of codecs and LMs in these systems, research on codecs and LMs has largely remained siloed. In this work, we bridge this gap by proposing several codec-LM co-design strategies, analyzing their effects on end-to-end TTS performance and efficiency. Specifically, we introduce three complementary techniques: (i) aframe-wise codec encoderthat improves both LM log-likelihood and end-to-end TTS metrics, (ii)LM codebook level dropout, a method to efficiently navigate a portion of the codec-LM design space by training a single LM, and (iii)increased codec frame duration, which we show can accelerate inference while maintaining end-to-end performance. Our experiments demonstrate that combining all three co-design techniques results in doubled inference speed, and improvements in intelligibility, audio quality, and speaker control in TTS relative to a siloed baseline."
    },
    {
        "title": "Generalized Gaussian Temporal Difference Error for Uncertainty-aware Reinforcement Learning",
        "link_suffix": "/forum?id=7S1xDos9pH",
        "link": "https://openreview.net/forum?id=7S1xDos9pH",
        "pdf_link": "https://openreview.net/pdf?id=7S1xDos9pH",
        "keywords": "Generalized Gaussian Distribution, Reinforcement Learning, Robustness, Uncertainty",
        "abstract": "Conventional uncertainty-aware temporal difference (TD) learning methods often rely on simplistic assumptions, typically including a zero-mean Gaussian distribution for TD errors. Such oversimplification can lead to inaccurate error representations and compromised uncertainty estimation. In this paper, we introduce a novel framework for generalized Gaussian error modeling in deep reinforcement learning, applicable to both discrete and continuous control settings. Our framework enhances the flexibility of error distribution modeling by incorporating additional higher-order moment, particularly kurtosis, thereby improving the estimation and mitigation of data-dependent noise, i.e., aleatoric uncertainty. We examine the influence of the shape parameter of the generalized Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form expression that demonstrates an inverse relationship between uncertainty and the shape parameter. Additionally, we propose a theoretically grounded weighting scheme to fully leverage the GGD. To address epistemic uncertainty, we enhance the batch inverse variance weighting by incorporating bias reduction and kurtosis considerations, resulting in improved robustness. Extensive experimental evaluations using policy gradient algorithms demonstrate the consistent efficacy of our method, showcasing significant performance improvements."
    },
    {
        "title": "LCEN: A Novel Feature Selection Algorithm for Nonlinear, Interpretable Machine Learning Models",
        "link_suffix": "/forum?id=EhweLJiYi5",
        "link": "https://openreview.net/forum?id=EhweLJiYi5",
        "pdf_link": "https://openreview.net/pdf?id=EhweLJiYi5",
        "keywords": "Machine Learning, Feature Selection, Elastic Net, Interpretable Machine Learning, Interpretability, Applications of Machine Learning, Applied Machine Learning",
        "abstract": "Interpretable architectures can have advantages over black-box architectures, and interpretability is essential for the application of machine learning in critical settings, such as aviation or medicine. However, the simplest, most commonly used interpretable architectures, such as LASSO or elastic net (EN), are limited to linear predictions and have poor feature selection capabilities. In this work, we introduce the LASSO-Clip-EN (LCEN) algorithm for the creation of nonlinear, interpretable machine learning models. LCEN is tested on a wide variety of artificial and empirical datasets, frequently creating more accurate, sparser models than other architectures, including those for building sparse, nonlinear models. LCEN is robust against many issues typically present in datasets and modeling, including noise, multicollinearity, data scarcity, and hyperparameter variance. LCEN is also able to rediscover multiple physical laws from empirical data and, for processes with no known physical laws, LCEN achieves better results than many other dense and sparse methods -- including using 10.8-fold fewer features than dense methods and 8.1-fold fewer features than EN on one dataset, and is comparable to or better than ANNs on multiple datasets."
    },
    {
        "title": "PRISM: Privacy-Preserving Improved Stochastic Masking for Federated Generative Models",
        "link_suffix": "/forum?id=B9kUJuWrYC",
        "link": "https://openreview.net/forum?id=B9kUJuWrYC",
        "pdf_link": "https://openreview.net/pdf?id=B9kUJuWrYC",
        "keywords": "Generative models, Federated learning",
        "abstract": "Despite recent advancements in federated learning (FL), the integration of generative models into FL has been limited due to challenges such as high communication costs and unstable training in heterogeneous data environments. To address these issues, we propose PRISM, a FL framework tailored for generative models that ensures (i) stable performance in heterogeneous data distributions and (ii) resource efficiency in terms of communication cost and final model size. The key of our method is to search for an optimal stochastic binary mask for a random network rather than updating the model weights, identifying a sparse subnetwork with high generative performance; i.e., a ``strong lottery ticket''. By communicating binary masks in a stochastic manner, PRISM minimizes communication overhead. This approach, combined with the utilization of maximum mean discrepancy (MMD) loss and a mask-aware dynamic moving average aggregation method (MADA) on the server side, facilitates stable and strong generative capabilities by mitigating local divergence in FL scenarios. Moreover, thanks to its sparsifying characteristic, PRISM yields a lightweight model without extra pruning or quantization, making it ideal for environments such as edge devices. Experiments on MNIST, FMNIST, CelebA, and CIFAR10 demonstrate that PRISM outperforms existing methods, while maintaining privacy with minimal communication costs. PRISM is the first to successfully generate images under challenging non-IID and privacy-preserving FL environments on complex datasets, where previous methods have struggled."
    },
    {
        "title": "What Time Tells Us? Time-Aware Representation Learning from Static Images",
        "link_suffix": "/forum?id=FH4x8IqUu6",
        "link": "https://openreview.net/forum?id=FH4x8IqUu6",
        "pdf_link": "https://openreview.net/pdf?id=FH4x8IqUu6",
        "keywords": "Representation Learning, Dataset, Cross-modal, Time",
        "abstract": "Time becomes visible through changes in what we see, as daylight fades and shadows grow. Inspired by this, in this paper we explore the potential to learn time-aware representations from static images, trying to answer:what time tells us?To this end, we first introduce a Time-Oriented Collection (TOC) dataset, which contains 130,906 images with reliable timestamps. Leveraging this dataset, we propose a Time-Image Contrastive Learning (TICL) approach to jointly model timestamp and related visual representations through cross-modal contrastive learning. We found that the proposed TICL, 1) not only achieve state-of-the-art performance on the timestamp estimation task, over various benchmark metrics, 2) but also, interestingly, though only seeing static images, the representations learned by TICL show strong capability in several time-aware downstream tasks such as time-based image retrieval, video scene classification, and time-aware image editing. Our findings confirm that time-aware visual representations are learnable from static images and beneficial for various vision tasks, laying a foundation for future research on understanding time-related visual context."
    },
    {
        "title": "Bilevel Reinforcement Learning for Stock Data with A Conservative TD Ensemble",
        "link_suffix": "/forum?id=zaDU4vMAUr",
        "link": "https://openreview.net/forum?id=zaDU4vMAUr",
        "pdf_link": "https://openreview.net/pdf?id=zaDU4vMAUr",
        "keywords": "Reinforcement learning, stock markets, portfolio optimization",
        "abstract": "Reinforcement learning (RL) has shown significant promise in stock trading. A typical solution involves optimizing cumulative returns using historical offline data. However, it may produce less generalizable policies that merely \"memorize\" optimal buying and selling actions from the offline data while neglecting the non-stationary nature of the financial market. We frame stock trading as a specific type of offline RL problem. Our method, MetaTrader, presents two key contributions. First, it introduces a novel bilevel actor-critic method that spans both the original stock data and its transformations. The fundamental idea is that an effective policy should be generalizable across out-of-distribution data. Second, we propose a novel variant of conservative TD learning, utilizing an ensemble-based TD target to mitigate value overestimation, particularly in scenarios with limited offline data. Our empirical findings across two publicly available datasets demonstrate the superior performance of MetaTrader over existing methods, including both RL-based approaches and stock prediction models."
    },
    {
        "title": "Deciphering Cell Lineage Gene Regulatory Network via MTGRN",
        "link_suffix": "/forum?id=Ecb6HBoo1r",
        "link": "https://openreview.net/forum?id=Ecb6HBoo1r",
        "pdf_link": "https://openreview.net/pdf?id=Ecb6HBoo1r",
        "keywords": "Gene regulatory network, Time series, In silico perturbation",
        "abstract": "Gene regulatory network (GRN) inference is crucial for cell fate decision, as it outlines the regulations between genes, which direct cell differentiation. Although there have been some work to infer cell lineage GRN, they fail to capture the continuous nature of the differentiation process as they group cells by cell type or cluster and infer GRN in a discrete manner. In this paper, we hypothesize GRN can forecast future gene expression based on history information and transform the inference process into a multivariate time series forecasting problem, linking cells at different time to learn temporal dynamics and inferring GRN in a continuous process. We introduce MTGRN, a transformer-based model that only takes single cell data as input to infer the cell lineage GRN by forecasting gene expression. MTGRN consists of temporal blocks and spatial blocks, effectively captures the connections between cells along their developmental trajectories and leverages prior knowledge to elucidate regulatory interactions among genes. It significantly outperforms six other methods across five datasets, demonstrating superior performance even compared to multimodal approaches. Based on the inferred GRN, MTGRN pinpoints three crucial genes associated with the development of mouse embryonic stem cells and depicts the activity changes of these genes during cellular differentiation. Beyond this, MTGRN is capable of conducting perturbation experiments on key genes and accurately modeling the change of cell identity following the knockout of the Gata1 in mouse hematopoietic stem cells."
    },
    {
        "title": "Re-Aligning Language to Visual Objects with an Agentic Workflow",
        "link_suffix": "/forum?id=MPJ4SMnScw",
        "link": "https://openreview.net/forum?id=MPJ4SMnScw",
        "pdf_link": "https://openreview.net/pdf?id=MPJ4SMnScw",
        "keywords": "agentic workflow, language-based object detection",
        "abstract": "Language-based object detection (LOD) aims to align visual objects with language expressions. A large amount of paired data is utilized to improve LOD model generalizations. During the training process, recent studies leverage vision-language models (VLMs) to automatically generate human-like expressions for visual objects, facilitating training data scaling up. In this process, we observe that VLM hallucinations bring inaccurate object descriptions (e.g., object name, color, and shape) to deteriorate VL alignment quality. To reduce VLM hallucinations, we propose an agentic workflow controlled by an LLM to re-align language to visual objects via adaptively adjusting image and text prompts. We name this workflow Real-LOD, which includes planning, tool use, and reflection steps. Given an image with detected objects and VLM raw language expressions, Real-LOD reasons its state automatically and arranges action based on our neural symbolic designs (i.e., planning). The action will adaptively adjust the image and text prompts and send them to VLMs for object re-description (i.e., tool use). Then, we use another LLM to analyze these refined expressions for feedback. These steps are conducted in a cyclic form to gradually improve language descriptions for re-aligning to visual objects. We construct a dataset that contains a tiny amount of 0.18M images with re-aligned language expression and train a prevalent LOD model to surpass existing LOD methods by around 50% on the standard benchmarks. Our Real-LOD workflow, with automatic VL refinement, reveals a potential to preserve data quality along with scaling up data quantity, which further improves LOD performance from a data-alignment perspective."
    },
    {
        "title": "Step-by-Step Reasoning for Math Problems  via Twisted Sequential Monte Carlo",
        "link_suffix": "/forum?id=Ze4aPP0tIn",
        "link": "https://openreview.net/forum?id=Ze4aPP0tIn",
        "pdf_link": "https://openreview.net/pdf?id=Ze4aPP0tIn",
        "keywords": "Large Language Models, Twisted Sequential Monte Carlo, Reasoning",
        "abstract": "Augmenting the multi-step reasoning abilities of Large Language Models (LLMs) has been a persistent challenge. Recently, verification has shown promise in improving solution consistency by evaluating generated outputs. However, current verification approaches suffer from sampling inefficiencies, requiring a large number of samples to achieve satisfactory performance. Additionally, training an effective verifier often depends on extensive process supervision, which is costly to acquire. In this paper, we address these limitations by introducing a novel verification method based on Twisted Sequential Monte Carlo (TSMC). TSMC sequentially refines its sampling effort to focus exploration on promising candidates, resulting in more efficient generation of high-quality solutions. We apply TSMC to LLMs by estimating the expected future rewards at partial solutions. This approach results in a more straightforward training target that eliminates the need for step-wise human annotations. We empirically demonstrate the advantages of our method across multiple math benchmarks, and also validate our theoretical analysis of both our approach and existing verification methods."
    },
    {
        "title": "Adversarial Contrastive Decoding: Aligning Large Language Models via Exploiting Their Safety and Harm",
        "link_suffix": "/forum?id=Ys1ZbGBzHJ",
        "link": "https://openreview.net/forum?id=Ys1ZbGBzHJ",
        "pdf_link": "https://openreview.net/pdf?id=Ys1ZbGBzHJ",
        "keywords": "large language models, safety alignment, prompting",
        "abstract": "With the widespread application of Large Language Models (LLMs), it has become a significant concern to ensure their safety and prevent harmful responses. While current safe-alignment methods based on instruction fine-tuning and Reinforcement Learning from Human Feedback (RLHF) can effectively reduce harmful responses from LLMs, they often require high-quality datasets and heavy computational overhead during model training. Another way to align language models is to modify the logit of tokens in model outputs without heavy training. Recent studies have shown that contrastive decoding can enhance the performance of language models by reducing the likelihood of confused tokens. However, these methods require the manual selection of contrastive models or instruction templates, limiting the degree of contrast. To this end, we propose Adversarial Contrastive Decoding (ACD), an optimization-based framework to generate two opposite soft system prompts, the Safeguarding Prompt (SP) and the Adversarial Prompt (AP), for prompt-based contrastive decoding. The SP aims to promote safer outputs while the AP aims to exploit the harmful parts of the model, providing a strong contrast to align the model with safety. ACD only needs to apply a lightweight prompt tuning on a rather small anchor dataset without training the target model. Experiments conducted on extensive models and benchmarks demonstrate that the proposed method achieves much better safety performance than previous model training-free decoding methods without sacrificing its original generation ability."
    },
    {
        "title": "EG4D: Explicit Generation of 4D Object without Score Distillation",
        "link_suffix": "/forum?id=uq9TLFT7tF",
        "link": "https://openreview.net/forum?id=uq9TLFT7tF",
        "pdf_link": "https://openreview.net/pdf?id=uq9TLFT7tF",
        "keywords": "4D Generation",
        "abstract": "In recent years, the increasing demand for dynamic 3D assets in design and gaming applications has given rise to powerful generative pipelines capable of synthesizing high-quality 4D objects.\n  Previous methods generally rely on score distillation sampling (SDS) algorithm to infer the unseen views and motion of 4D objects, thus leading to unsatisfactory results with defects like over-saturation and Janus problem.\n  Therefore, inspired by recent progress of video diffusion models, we propose to optimize a 4D representation by explicitly generating multi-view videos from one input image.\n  However, it is far from trivial to handle practical challenges faced by such a pipeline, including dramatic temporal inconsistency, inter-frame geometry and texture diversity, and semantic defects brought by video generation results.\n  To address these issues, we propose EG4D, a novel multi-stage framework that generates high-quality and consistent 4D assets without score distillation.\n  Specifically, collaborative techniques and solutions are developed, including an attention injection strategy to synthesize temporal-consistent multi-view videos, a robust and efficient dynamic reconstruction method based on Gaussian Splatting, and a refinement stage with diffusion prior for semantic restoration.\n  The qualitative comparisons and quantitative results demonstrate that our framework outperforms the baselines in generation quality by a considerable margin."
    },
    {
        "title": "ReAcTree: Hierarchical Task Planning with Dynamic Tree Expansion using LLM Agent Nodes",
        "link_suffix": "/forum?id=KgKN7F0PyQ",
        "link": "https://openreview.net/forum?id=KgKN7F0PyQ",
        "pdf_link": "https://openreview.net/pdf?id=KgKN7F0PyQ",
        "keywords": "Task planning, large language model, decision-making, behavior tree, hierarchical planning",
        "abstract": "Recent advancements in task planning using large language models (LLMs) have made remarkable progress. However, most existing methods, such as ReAct, face limitations when handling complex, long-horizon tasks due to inefficiencies in processing entire tasks through a single sequential decision-making process. To address these challenges, we propose ReAcTree, a hierarchical task planning method that automatically decomposes complex tasks into manageable subgoals within a tree structure. This tree consists of control flow nodes, which manage the execution order of agent nodes, and agent nodes that reason, act, and expand nodes into subgoals to achieve their goals. To further enhance performance, we introduce memory systems: each agent node retrieves goal-specific, agent-level experiences from episodic memory to use as in-context examples, and all agent nodes share and recall information obtained during task execution via working memory. Experiments on the WAH-NL dataset demonstrate that ReAcTree consistently outperforms ReAct across various LLMs and model sizes. For example, when using Qwen2.5 72B, ReAcTree achieves a goal success rate of 63%, significantly surpassing ReAct's 24%."
    },
    {
        "title": "Large Language Models are Interpretable Learners",
        "link_suffix": "/forum?id=hTphfqtafO",
        "link": "https://openreview.net/forum?id=hTphfqtafO",
        "pdf_link": "https://openreview.net/pdf?id=hTphfqtafO",
        "keywords": "Interpretability, Explainable AI, LLMs, VLMs, MLLMs, Symbolic Learning, Prompting",
        "abstract": "The trade-off between expressiveness and interpretability remains a core challenge when building human-centric predictive models for classification and decision-making. While symbolic rules offer interpretability, they often lack expressiveness, whereas neural networks excel in performance but are known for being black boxes. In this paper, we show that a combination of large language models (LLMs) and symbolic programs can bridge this gap. In the proposed LLM-based Symbolic Programs (LSPs), the pretrained LLM with natural language prompts provides a massive set of interpretable modules that can transform raw input into natural language concepts. Symbolic programs then integrate these modules into an interpretable decision rule. To train LSPs, we develop a divide-and-conquer approach to incrementally build the program from scratch, where the learning process of each step is guided by LLMs. To evaluate the effectiveness of LSPs in extracting interpretable and accurate knowledge from data, we introduce IL-Bench, a collection of diverse tasks, including both synthetic and real-world scenarios across different modalities. Empirical results demonstrate LSP's superior performance compared to traditional neurosymbolic programs and vanilla automatic prompt tuning methods. Moreover, as the knowledge learned by LSP is a combination of natural language descriptions and symbolic rules, it is easily transferable to humans (interpretable), and other LLMs, and generalizes well to out-of-distribution samples."
    },
    {
        "title": "Theory on Mixture-of-Experts in Continual Learning",
        "link_suffix": "/forum?id=7XgKAabsPp",
        "link": "https://openreview.net/forum?id=7XgKAabsPp",
        "pdf_link": "https://openreview.net/pdf?id=7XgKAabsPp",
        "keywords": "continual learning, mixture-of-experts, catastrophic forgetting, generalization error",
        "abstract": "Continual learning (CL) has garnered significant attention because of its ability to adapt to new tasks that arrive over time. Catastrophic forgetting (of old tasks) has been identified as a major issue in CL, as the model adapts to new tasks. The Mixture-of-Experts (MoE) model has recently been shown to effectively mitigate catastrophic forgetting in CL, by employing a gating network to sparsify and distribute diverse tasks among multiple experts. However, there is a lack of theoretical analysis of MoE and its impact on the learning performance in CL. This paper provides the first theoretical results to characterize the impact of MoE in CL via the lens of overparameterized linear regression tasks. We establish the benefit of MoE over a single expert by proving that the MoE model can diversify its experts to specialize in different tasks, while its router learns to select the right expert for each task and balance the loads across all experts. Our study further suggests an intriguing fact that the MoE in CL needs to terminate the update of the gating network after sufficient training rounds to attain system convergence, which is not needed in the existing MoE studies that do not consider the continual task arrival. Furthermore, we provide explicit expressions for the expected forgetting and overall generalization error to characterize the benefit of MoE in the learning performance in CL. Interestingly, adding more experts requires additional rounds before convergence, which may not enhance the learning performance. Finally, we conduct experiments on both synthetic and real datasets to extend these insights from linear models to deep neural networks (DNNs), which also shed light on the practical algorithm design for MoE in CL."
    },
    {
        "title": "Decentralized Sporadic Federated Learning: A Unified Algorithmic Framework with Convergence Guarantees",
        "link_suffix": "/forum?id=cznqgb4DNv",
        "link": "https://openreview.net/forum?id=cznqgb4DNv",
        "pdf_link": "https://openreview.net/pdf?id=cznqgb4DNv",
        "keywords": "Decentralized Federated Learning, Sporadicity, Unified Algorithmic Framework, Convergence Analysis",
        "abstract": "Decentralized federated learning (DFL) captures FL settings where both (i) model updates and (ii) model aggregations are exclusively carried out by the clients without a central server. Existing DFL works have mostly focused on settings where clients conduct a fixed number of local updates between local model exchanges, overlooking heterogeneity and dynamics in communication and computation capabilities. In this work, we propose Decentralized Sporadic Federated Learning ($\\texttt{DSpodFL}$), a DFL methodology built on a generalized notion ofsporadicityin both local gradient and aggregation processes. $\\texttt{DSpodFL}$ subsumes many existing decentralized optimization methods under a unified algorithmic framework by modeling the per-iteration (i) occurrence of gradient descent at each client and (ii) exchange of models between client pairs as arbitrary indicator random variables, thus capturingheterogeneous and time-varyingcomputation/communication scenarios. We analytically characterize the convergence behavior of $\\texttt{DSpodFL}$ for both convex and non-convex models and for both constant and diminishing learning rates, under mild assumptions on the communication graph connectivity, data heterogeneity across clients, and gradient noises. We show how our bounds recover existing results from decentralized gradient descent as special cases. Experiments demonstrate that $\\texttt{DSpodFL}$ consistently achieves improved training speeds compared with baselines under various system settings."
    },
    {
        "title": "Emergence in non-neural models: grokking modular arithmetic via average gradient outer product",
        "link_suffix": "/forum?id=FrjTgprk3V",
        "link": "https://openreview.net/forum?id=FrjTgprk3V",
        "pdf_link": "https://openreview.net/pdf?id=FrjTgprk3V",
        "keywords": "Theory of deep learning, grokking, modular arithmetic, feature learning, kernel methods, average gradient outer product (AGOP), emergence",
        "abstract": "Neural networks trained to solve modular arithmetic tasks exhibit grokking, the phenomenon where the test accuracy improves only long after the model achieves 100% training accuracy in the training process. It is often taken as an example of ``emergence'', where model ability manifests sharply through a phase transition. In this work, we show that the phenomenon of grokking is not specific to neural networks nor to gradient descent-based optimization. Specifically, we show that grokking occurs when learning modular arithmetic with Recursive Feature Machines (RFM), an iterative algorithm that uses the Average Gradient Outer Product (AGOP) to enable task-specific feature learning with kernel machines. We show that RFM and, furthermore, neural networks that solve modular arithmetic learn block-circulant features transformations which implement the previously proposed Fourier multiplication algorithm."
    },
    {
        "title": "Hybrid Kernel Stein Variational Gradient Descent",
        "link_suffix": "/forum?id=x5l5PRtvul",
        "link": "https://openreview.net/forum?id=x5l5PRtvul",
        "pdf_link": "https://openreview.net/pdf?id=x5l5PRtvul",
        "keywords": "Stein Variational Gradient Descent, Approximate Inference, Particle-based Variational Inference, Gradient Flow",
        "abstract": "Stein variational gradient descent (SVGD) is a particle based approximate inference algorithm. Many variants of SVGD have been proposed in recent years, including the hybrid kernel variant (h-SVGD), which has demonstrated promising results on image classification with deep neural network ensembles. In this paper, we demonstrate the ability of h-SVGD to alleviate variance collapse, a problem that SVGD is known to suffer from. Unlike other SVGD variants that alleviate variance collapse, h-SVGD does not incur additional computational cost, nor does it require the target density to factorise. We also develop the theory of h-SVGD by demonstrating the existence of a solution to the hybrid Stein partial differential equation. We highlight a special case in which h-SVGD is a kernelised Wasserstein gradient flow on a functional other than the Kullback-Leibler divergence, which is the functional describing the SVGD gradient flow. By characterising the fixed point in this special case, we show that h-SVGD does not converge to the target distribution in the the mean field limit. Other theoretical results include a descent lemma and a large particle limit result. Despite the bias in the mean field limiting distribution, experiments demonstrate that h-SVGD remains competitive on high dimensional inference tasks whilst alleviating variance collapse."
    },
    {
        "title": "Deep Reinforcement Learning for Sequential Combinatorial Auctions",
        "link_suffix": "/forum?id=SVd9Ffcdp8",
        "link": "https://openreview.net/forum?id=SVd9Ffcdp8",
        "pdf_link": "https://openreview.net/pdf?id=SVd9Ffcdp8",
        "keywords": "Mechanism Design, Auctions, Game Theory, Differential Economics, Reinforcement Learning, Deep Learning, Market Design, AI for Economics",
        "abstract": "Revenue-optimal auction design is a challenging problem with significant theoretical and practical implications. Sequential auction mechanisms, known for their simplicity and strong strategyproofness guarantees, are often limited by theoretical results that are largely existential, except for certain restrictive settings. Although traditional reinforcement learning methods such as Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC) are applicable in this domain, they struggle with computational demands and convergence issues when dealing with large and continuous action spaces. In light of this and recognizing that we can model transitions differentiable for our settings, we propose using a new reinforcement learning framework tailored for sequential combinatorial auctions that leverages first-order gradients.  Our extensive evaluations show that our approach achieves significant improvement in revenue over both analytical baselines and standard reinforcement learning algorithms. Furthermore, we scale our approach to scenarios involving up to 50 agents and 50 items, demonstrating its applicability in complex, real-world auction settings. As such, this work advances the computational tools available for auction design and contributes to bridging the gap between theoretical results and practical implementations in sequential auction design."
    },
    {
        "title": "Privacy-Preserving of Deep Learning Queries by Domain Shifting",
        "link_suffix": "/forum?id=sruGNQHd7t",
        "link": "https://openreview.net/forum?id=sruGNQHd7t",
        "pdf_link": "https://openreview.net/pdf?id=sruGNQHd7t",
        "keywords": "Privacy-Preserving, Domain Shifting, Input Obfuscation",
        "abstract": "In the era of cloud-based deep learning (DL) services, data privacy has become a critical concern, prompting some organizations to restrict the use of online AI services. This work addresses this issue by introducing a privacy-preserving method for DL model queries through domain shifting in the input space. We develop an encoder that strategically transforms inputs into a different domain within the same space, ensuring that the original inputs remain private by presenting only the obfuscated versions to the DL model. A decoder then recovers the correct output from the model's predictions. Our method keeps the authentic input and output data secure on the local system, preventing unauthorized access by third parties who only encounter the obfuscated data. Comprehensive evaluations across various oracle models and datasets demonstrate that our approach preserves privacy with minimal impact on classification performance."
    },
    {
        "title": "Zoomer: Enhancing MLLM Performance with Adaptive Image Focus Optimization",
        "link_suffix": "/forum?id=SOVwGa0H2c",
        "link": "https://openreview.net/forum?id=SOVwGa0H2c",
        "pdf_link": "https://openreview.net/pdf?id=SOVwGa0H2c",
        "keywords": "Multimodal, MLLM, Prompt Engineering, Efficient, Token Compression",
        "abstract": "Recent advancements in multimodal large language models (MLLMs) have broadened the scope of vision-language tasks, excelling in applications like image captioning and interactive question-answering. However, these models struggle with accurately processing visual data, particularly in tasks requiring precise object recognition and fine visual details.\nStringent token limits often result in the omission of critical information, hampering performance. To address these limitations, we introduce Zoomer, a novel visual prompting mechanism designed to enhance MLLM performance while preserving essential visual details within token limits. Zoomer features three key innovations: a prompt-aware strategy that dynamically highlights relevant image regions, a spatial-preserving orchestration schema that maintains object integrity, and a budget-aware prompting method that balances global context with crucial visual details. \nComprehensive evaluations across multiple datasets demonstrate that Zoomer consistently outperforms baseline methods, achieving up to a $26.9%$ improvement in accuracy while significantly reducing token consumption."
    },
    {
        "title": "Battle of the Wordsmiths: Comparing ChatGPT, GPT-4, Claude, and Bard",
        "link_suffix": "/forum?id=LQL5CBxLrY",
        "link": "https://openreview.net/forum?id=LQL5CBxLrY",
        "pdf_link": "https://openreview.net/pdf?id=LQL5CBxLrY",
        "keywords": "Large language models, ChatGPT, GPT-4, Claude, Bard, datasets, natural language processing, language modeling",
        "abstract": "Although informal evaluations of modern LLMs\ncan be found on social media, blogs, and news\noutlets, a formal and comprehensive comparison among them has yet to be conducted. In\nresponse to this gap, we have undertaken an extensive benchmark evaluation of LLMs and conversational bots. Our evaluation involved the collection of 1002 questions encompassing 27 categories,\nwhich we refer to as the \u201cWordsmiths dataset.\u201d\nThese categories include reasoning, logic, facts,\ncoding, bias, language, humor, and more. Each\nquestion in the dataset is accompanied by an accurate and verified answer. We meticulously assessed four leading chatbots: ChatGPT, GPT-4, Bard, and Claude, using this dataset. The results\nof our evaluation revealed the following key findings: a) GPT-4 emerged as the top-performing\nchatbot across almost all categories, achieving a\nsuccess rate of 84.1%. On the other hand, Bard\nfaced challenges and achieved a success rate of\n62.4%. b) Among the four models evaluated,\none of them responded correctly approximately\n93% of the time. However, all models were correct only about 44%. c) Bard is less correlated\nwith other models while ChatGPT and GPT-4 are\nhighly correlated in terms of their responses. d)\nChatbots demonstrated proficiency in language\nunderstanding, facts, and self-awareness. However, they encountered difficulties in areas such\nas math, coding, IQ, and reasoning. e) In terms of\nbias, discrimination, and ethics categories, models\ngenerally performed well, suggesting they are relatively safe to utilize. To make future model evaluations on our dataset easier, we also provide a multiple-choice version of it (called WordsmithsMCQ)."
    }
]
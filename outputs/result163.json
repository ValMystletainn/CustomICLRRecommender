[{"title": "Agile Flight  with Optimization Embedded Networks", "link_suffix": "/forum?id=MtCcVO8Oux", "link": "https://openreview.net/forum?id=MtCcVO8Oux", "pdf_link": "https://openreview.net/pdf?id=MtCcVO8Oux", "keywords": "Robotics, Autonomous Navigation, Motion Planning and Control, Differentiable Optimization", "abstract": "To bridge the gap between perception and planning in traditional navigation systems, we address the challenge of learning optimal trajectories directly from depth information in an end-to-end fashion. Using neural networks as black-box replacements for traditional modules can compromise robustness and stability. Moreover, such methods often fail to adequately account for the robot's kinematic constraints, leading to trajectories that may not be satisfactorily executable. In this paper, we integrate the strengths of conventional methods and neural networks by introducing an optimization-embedded neural network based on a compact trajectory library. Neural networks establish spatial constraints for model-based trajectory planning, followed by robust numerical optimization to achieve feasible and optimal solutions.  By making the process differentiable, our model seamlessly approximates the optimal trajectory. Additionally, the introduction of a regularized trajectory library enables the method to efficiently capture the spatial distribution of optimal trajectories with minimal storage cost, ensuring multimodal planning characteristics. Evaluations in complex, unseen environments demonstrate our method\u2019s superior performance over state-of-the-art algorithms. Real-world flight experiments with a small onboard computer showcase the autonomous quadrotor\u2019s ability to navigate swiftly through dense forests.", "title_embedding_index": 8100, "title_abs_embedding_index": 8125}, {"title": "Training Task Experts through Retrieval Based Distillation", "link_suffix": "/forum?id=cqU91W3LnB", "link": "https://openreview.net/forum?id=cqU91W3LnB", "pdf_link": "https://openreview.net/pdf?id=cqU91W3LnB", "keywords": "Retrieval, Distillation, Task-Expert", "abstract": "One of the most reliable ways to create deployable models for specialized tasks is to obtain an adequate amount of high-quality task-specific data. However, for specialized tasks, often such datasets do not exist. Existing methods address this by creating such data from large language models (LLMs) and then distilling such knowledge into smaller models. However, these methods are limited by the quality of the LLMs output, and tend to generate repetitive or incorrect data. In this work, we present Retrieval Based Distillation (ReBase), a method that first retrieves data from rich online sources and then transforms them into domain-specific data. This method greatly enhances data diversity. Moreover, ReBase generates Chain-of-Thought reasoning and distills the reasoning capacity of LLMs. We test our method on 4 benchmarks and shows that our method significantly improves performance by up to 10.76% on SQuAD, 1.37% on MNLI, and 1.94% on BBH.", "title_embedding_index": 8101, "title_abs_embedding_index": 8126}, {"title": "Flexible Active Learning of PDE Trajectories", "link_suffix": "/forum?id=LgfaMR6Sst", "link": "https://openreview.net/forum?id=LgfaMR6Sst", "pdf_link": "https://openreview.net/pdf?id=LgfaMR6Sst", "keywords": "Active learning, Partial Differential Equation (PDE)", "abstract": "Accurately solving partial differential equations (PDEs) is critical for understanding complex scientific and engineering phenomena, yet traditional numerical solvers are computationally expensive. Surrogate models offer a more efficient alternative, but their development is hindered by the cost of generating sufficient ground-truth data from numerical simulations. In this paper, we present a novel framework for active learning (AL) in PDE surrogate modeling that reduces the data acquisition cost and improves model accuracy. Unlike the existing AL methods for PDEs that always acquire entire PDE trajectories, our approach strategically queries only a subset of the time steps from a numerical solver along a trajectory, while employing a surrogate model to approximate values for the remaining steps. This dramatically reduces the cost of data acquisition, which is proportional to the number of time steps simulated by the numerical solver, and thus allows the active learning algorithm to try out a more diverse set of trajectories given the same computational budget. To accommodate this novel framework, we develop an acquisition function that estimates the utility of a set of time steps by approximating its resulting variance reduction. We demonstrate the effectiveness of our method on several benchmark PDEs, including the Heat equation, Korteweg\u2013De Vries equation, Kuramoto\u2013Sivashinsky equation, and the incompressible Navier-Stokes equation. Extensive experiments validate that our approach outperforms existing methods, offering a cost-efficient solution to surrogate modeling for PDEs.", "title_embedding_index": 8102, "title_abs_embedding_index": 8127}, {"title": "QRazor: Reliable and Effortless 4-bit LLM Quantization by Significant Data Razoring", "link_suffix": "/forum?id=lwcnZmyojm", "link": "https://openreview.net/forum?id=lwcnZmyojm", "pdf_link": "https://openreview.net/pdf?id=lwcnZmyojm", "keywords": "Large Language Model, Post-Training Quantization, Hardware, Arithmetic Unit, Compression", "abstract": "Large-scale language models (LLMs) have demonstrated outstanding performance in language processing tasks, yet their deployment is often hindered by high memory demands and computational complexity. Although low-bit quantization techniques, such as 4-bit quantization, present a potential solution, they frequently lead to significant accuracy degradation or require substantial effort for such aggressive quantization approaches. To overcome these challenges, we introduce QRazor, a reliable and effortless quantization scheme designed to enable 4-bit quantization for weights, activations, and KV cache in transformer-based LLMs. The scheme involves two main stages: quantization and compression. During the quantization stage, weights, activations, and KV cache values are quantized with wider 8 or 16-bit integers as a basis to achieve nearly identical accuracy to the original full-precision LLM models, using the absolute max scaling. Subsequently, all data are compressed to 4-bit using our proposed significant data razoring (SDR) technique, which retains only the four most salient bits while discarding the others. Furthermore, we present an integer-based arithmetic unit dedicated to QRazor, enabling direct low-precision arithmetic operations without decompressing the SDR data. Despite the reduced quantization effort, QRazor achieves LLM accuracies better or comparable to state-of-the-art 4-bit methods. By also validating the hardware efficiency, our decompression-free arithmetic unit achieves 61.2% and 57.8% reduction in area and power consumption, respectively.", "title_embedding_index": 8103, "title_abs_embedding_index": 8128}, {"title": "BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data", "link_suffix": "/forum?id=TqwTzLjzGS", "link": "https://openreview.net/forum?id=TqwTzLjzGS", "pdf_link": "https://openreview.net/pdf?id=TqwTzLjzGS", "keywords": "Inducing Realistic Personality to LLMs, LLM Personality Evaluation", "abstract": "In this work, we tackle the challenge of embedding realistic human personality traits into LLMs. Previous approaches have primarily focused on prompt-based methods that describe the behavior associated with the desired personality traits, suffering from realism and validity issues. To address these limitations, we introduce BIG5-CHAT, a large-scale dataset containing 100,000 dialogues designed to ground models in how humans express their personality in text. Leveraging this dataset, we explore Supervised Fine-Tuning and Direct Preference Optimization as training-based methods to align LLMs more naturally with human personality patterns. Our methods outperform prompting on personality assessments such as BFI and IPIP-NEO, with trait correlations more closely matching human data. Furthermore, our experiments reveal that models trained to exhibit higher conscientiousness, higher agreeableness, lower extraversion, and lower neuroticism display better performance on reasoning tasks, aligning with psychological findings on how these traits impact human cognitive performance. To our knowledge, this work is the first comprehensive study to demonstrate how training-based methods can shape LLM personalities through learning from real human behaviors.", "title_embedding_index": 8104, "title_abs_embedding_index": 8129}, {"title": "ABNet: Attention BarrierNet for Safe and Scalable Robot Learning", "link_suffix": "/forum?id=coq1hOntgI", "link": "https://openreview.net/forum?id=coq1hOntgI", "pdf_link": "https://openreview.net/pdf?id=coq1hOntgI", "keywords": "Safe learning, Robot learning, Scalable learning", "abstract": "Safe learning is central to AI-enabled robots where a single failure may lead to catastrophic results. Barrier-based method is one of the dominant approaches for safe robot learning. However, this method is not scalable, hard to train, and tends to generate unstable signals under noisy inputs that are challenging to be deployed for robots. To address these challenges, we propose a novel Attention BarrierNet (ABNet) that is scalable to build larger foundational safe models in an incremental manner.  Each head of BarrierNet in the ABNet could learn safe robot control policies from different features and focus on specific part of the observation. In this way, we do not need to one-shotly construct a large model for complex tasks, which significantly facilitates the training of the model while ensuring its stable output. Most importantly, we can still formally prove the safety guarantees of the ABNet. We demonstrate the strength of ABNet in 2D robot obstacle avoidance, safe robot manipulation, and vision-based end-to-end autonomous driving, with results showing much better robustness and guarantees over existing models.", "title_embedding_index": 8105, "title_abs_embedding_index": 8130}, {"title": "GENERALIZATION, ROBUSTNESS AND ADAPTABILITY OF PROGRESSIVE NEURAL COLLAPSE", "link_suffix": "/forum?id=O8fUZfC4GT", "link": "https://openreview.net/forum?id=O8fUZfC4GT", "pdf_link": "https://openreview.net/pdf?id=O8fUZfC4GT", "keywords": "Neural Collapse, generalization, robustness, domain adaptability", "abstract": "Neural networks exhibit the neural collapse phenomenon in multi-class classification tasks, where last-layer features and linear classifier weights converge into a symmetric geometric structure. However, most prior studies have primarily focused on last-layer feature representations or have examined intermediate features using limited, simple architectures and datasets. The mechanisms by which deep neural networks separate data according to class membership across all layers in more complex and realistic scenarios, and how this separation evolves under distribution shifts, remain unclear. In this work, we extend the study of neural collapse to a broader range of architectures and datasets, investigating its progression throughout the network and its implications for generalization, robustness, and domain adaptability. Our findings reveal that well-trained neural networks progressively enhance neural collapse across layers, though a distinct transition phase occurs where this improvement plateaus after the initial layers and is followed by a renewed continuous improvement in the very last layers, with additional layers contributing minimal generalization benefits. Moreover, we observe that this progressive neural collapse pattern remains robust against noisy data, whether the noise occurs in inputs or labels, and that the degree of intermediate separation serves as an effective indicator of noise levels. Additionally, for the learned networks, comparing neural collapse evaluated on noisy data and clean data reveals insights into feature learning and memorization, with the latter primarily occurring in the very last layers. This finding aligns with the neural collapse pattern observed with clean training data. Finally, we show that when a shift occurs between source and target domains, intermediate neural collapse is closely related to downstream target performance.", "title_embedding_index": 8106, "title_abs_embedding_index": 8131}, {"title": "NeuGen: Amplifying the \u2018Neural\u2019 in Neural Radiance Fields for Domain Generalization", "link_suffix": "/forum?id=YxLxrWkwsX", "link": "https://openreview.net/forum?id=YxLxrWkwsX", "pdf_link": "https://openreview.net/pdf?id=YxLxrWkwsX", "keywords": "Domain Generalization, Scene Reconstruction, One-shot learning", "abstract": "Neural Radiance Fields (NeRF) have significantly advanced the field of novel view synthesis, yet their generalization across diverse scenes and conditions remains challenging. Addressing this, we propose the integration of a novel brain-inspired normalization technique Neural Generalization (NeuGen) into leading NeRF architectures which include MVSNeRF and GeoNeRF. NeuGen extracts domain-invariant features, thereby enhancing the models' generalization capabilities. It can be seamlessly integrated into NeRF architectures, capable of initiating training from scratch or fine-tuning pre-trained models, which cultivates a comprehensive feature set that significantly improves accuracy and robustness in image rendering. Through this integration, NeuGen shows benchmarking performance on diverse datasets across state-of-the-art NeRF architectures, enabling them to generalize better across varied scenes. Our comprehensive evaluations, both quantitative and qualitative, confirm that our approach not only surpasses existing models in generalizability but also markedly improves rendering quality. Our work exemplifies the potential of merging neuroscientific principles with deep learning frameworks, setting a new precedent for enhanced generalizability and efficiency in novel view synthesis. A demo of our study is available athttps://neugennerf.github.io.", "title_embedding_index": 8107, "title_abs_embedding_index": 8132}, {"title": "Hot PATE: Private Aggregation of Distributions  for Diverse Tasks", "link_suffix": "/forum?id=B6AQzaQCsl", "link": "https://openreview.net/forum?id=B6AQzaQCsl", "pdf_link": "https://openreview.net/pdf?id=B6AQzaQCsl", "keywords": "PATE, diverse tasks, privacy-preserving machine learning, coordinated sampling, in-context learning", "abstract": "The Private Aggregation of Teacher Ensembles (PATE) framework is a versatile approach to privacy-preserving machine learning. In PATE, responses made based on different parts of sensitive data are aggregated into a single response in a privacy-preserving way. Recently, multiple works applied PATE for tasks such as sequential text generation that are inherently\n diverse (or \"hot\"), with multiple valid responses. These designs, however, suffer from\n  tension between diversity and privacy -- since diversity in the responses reduces agreement which forces the aggregation to use smaller noise scales and thus incur higher privacy loss. But limiting diversity of the aggregate response is undesirable since in large models, the very knowledge we want to transfer is encapsulated in the response distribution.\n   We propose \\emph{hot PATE} that is tailored for the diverse setting where responses are distributions. We formally define \\emph{preserving diversity} and design an efficient aggregation method that provably transfers the diversity to the (randomized) aggregate response while incurring no privacy penalty. The method can be implemented using an API access to proprietary models and used as a plug-in replacement for the baseline ``cold'' PATE in existing methods. We demonstrate empirically the potential of hot PATE for an order of magnitude improvement in a task of in-context learning via prompts.", "title_embedding_index": 8108, "title_abs_embedding_index": 8133}, {"title": "Is Offline Decision Making Possible with Only Few Samples? Reliable Decisions in Data-Starved Bandits via Trust Region Enhancement", "link_suffix": "/forum?id=63pceN3fOg", "link": "https://openreview.net/forum?id=63pceN3fOg", "pdf_link": "https://openreview.net/pdf?id=63pceN3fOg", "keywords": "Multi-armed bandit, high dimensional decision making, reinforcement learning.", "abstract": "What can an agent learn in a stochastic Multi-Armed Bandit (MAB) problem from a dataset that contains just a single sample for each arm? Surprisingly, in this work, we demonstrate that even in such a data-starved setting it may still be possible to find a policy competitive with the optimal one. This paves the way to reliable decision-making in settings where critical decisions must be made by relying only on a handful of samples.Our analysis reveals that \\emph{stochastic policies can be substantially better} than deterministic ones for offline decision-making. Focusing on offline multi-armed bandits, we design an algorithm called Trust Region of Uncertainty for Stochastic policy enhancemenT (TRUST) which is quite different from the predominant value-based lower confidence bound approach. Its design is enabled by localization laws, critical radii, and relative pessimism. We prove that its sample complexity is comparable to that of LCB on minimax problems while being substantially lower on problems with very few samples.Finally, we consider an application to offline reinforcement learning in the special case where the logging policies are known.", "title_embedding_index": 8109, "title_abs_embedding_index": 8134}, {"title": "MAMBA STATE-SPACE MODELS ARE LYAPUNOV-STABLE LEARNERS", "link_suffix": "/forum?id=i9RTCC6whL", "link": "https://openreview.net/forum?id=i9RTCC6whL", "pdf_link": "https://openreview.net/pdf?id=i9RTCC6whL", "keywords": "Mamba, Mamba SSMs, SSMs, LLMs, PEFT, LoRA, Transformers", "abstract": "Mamba state-space models (SSMs) were recently shown to outperform state-of-the-art (SOTA) Transformer large language models (LLMs) across various tasks.  Despite subsequent widespread adaptation, little work has focused on Mamba LLMs' amenability for fine-tuning frameworks ubiquitously used for Transformer-based LLMs, e.g., mixed-precision fine-tuning (MPFT) and parameter-efficient fine-tuning (PEFT).  For the former, it currently remains an open question whether Mamba's recurrent dynamics are robust to small input changes, such as those encountered during MPFT.  Using dynamical systems theory (in particular, Lyapunov exponents), we answer this question in the affirmative.  We empirically validate this result through several experiments, showing that Mamba SSMs are significantly more stable to changes introduced by mixed-precision than comparable Transformers, even when both MPFT and PEFT are combined.  For PEFT, we show how targeting specific memory buffers in Mamba's customized CUDA kernels for low-rank adaptation regularizes SSM parameters, thus providing both parameter efficient learning and computational savings. Finally, with both MPFT and PEFT enabled, we explore the impact of instruction tuning Mamba SSMs for in-context learning (ICL) on natural language tasks.  While pretrained Mamba and Mamba-2 models only achieve 38% and 82% (respectively) of the ICL improvements of comparable Transformer-based LLMs, we show that instruction tuning allows Mamba models to narrow this gap to 81% and Mamba-2 models to skyrocket over this gap to 132%.", "title_embedding_index": 8110, "title_abs_embedding_index": 8135}, {"title": "Range-limited Augmentation for Few-shot Learning in Tabular Data", "link_suffix": "/forum?id=kTH3bEH6hW", "link": "https://openreview.net/forum?id=kTH3bEH6hW", "pdf_link": "https://openreview.net/pdf?id=kTH3bEH6hW", "keywords": "Tabular representation learning; Contrastive learning; Few-shot learning; Data augmentation", "abstract": "Few-shot learning is essential in many applications, particularly in tabular domains where the high cost of labeling often limits the availability of annotated data. To address this challenge, we propose range-limited augmentation for contrastive learning in tabular domains. Our augmentation method shuffles or samples values within predefined feature-specific ranges, preserving semantic consistency during contrastive learning to enhance few-shot classification performance. To evaluate the effectiveness of our approach, we introduce FeSTa (Few-Shot Tabular classification benchmark), a benchmark consisting of 42 tabular datasets and 31 algorithms. On this benchmark, contrastive learning with our augmentation method effectively preserves task-relevant information and significantly outperforms existing approaches, including supervised, unsupervised, self-supervised, semi-supervised, and foundation models. In particular, our method achieves an average rank of 2.3 out of 31 algorithms in the 1-shot learning scenario, demonstrating its robustness and effectiveness when labeled data is highly limited. The benchmark code is available in the supplementary material.", "title_embedding_index": 8111, "title_abs_embedding_index": 8136}, {"title": "Brain-to-Text Decoding with Context-Aware Neural Representations and Large Language Models", "link_suffix": "/forum?id=pEh1SXCgOc", "link": "https://openreview.net/forum?id=pEh1SXCgOc", "pdf_link": "https://openreview.net/pdf?id=pEh1SXCgOc", "keywords": "brain-computer interfaces", "abstract": "Decoding attempted speech from neural activity offers a promising avenue for restoring communication abilities in individuals with speech impairments. Previous studies have focused on mapping neural activity to text using phonemes as the intermediate target. \nWhile successful, decoding neural activity directly to phonemes ignores the context dependent nature of the neural activity-to-phoneme mapping in the brain, leading to suboptimal decoding performance.\nIn this work, we propose the use of diphone - an acoustic representation that captures the transitions between two phonemes - as the context-aware modeling target. We integrate diphones into existing phoneme decoding frameworks through a novel divide-and-conquer strategy in which we model the phoneme distribution by marginalizing over the diphone distribution. Our approach effectively leverages the enhanced context-aware representation of diphones while preserving the manageable class size of phonemes, a key factor in simplifying the subsequent phoneme-to-text conversion task. We demonstrate the effectiveness of our approach on the Brain-to-Text 2024 benchmark, where it achieves state-of-the-art Phoneme Error Rate (PER) of 15.34% compared to 16.62% PER of monophone-based decoding. When coupled with finetuned Large Language Models (LLMs), our method yields a Word Error Rate (WER) of 5.77%, significantly outperforming the 8.93% WER of the leading method in the benchmark.", "title_embedding_index": 8112, "title_abs_embedding_index": 8137}, {"title": "MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?", "link_suffix": "/forum?id=vxutwN3xQN", "link": "https://openreview.net/forum?id=vxutwN3xQN", "pdf_link": "https://openreview.net/pdf?id=vxutwN3xQN", "keywords": "Multimodal Reward Models, Foundation Models Alignment, Reinforcement Learning from Human Feedback", "abstract": "While text-to-image models like DALLE-3 and Stable Diffusion are rapidly proliferating, they often encounter challenges such as hallucination, bias, and the production of unsafe, low-quality output. To effectively address these issues, it is crucial to align these models with desired behaviors based on feedback from a multimodal judge. Despite their significance, current multimodal judges frequently undergo inadequate evaluation of their capabilities and limitations, potentially leading to misalignment and unsafe fine-tuning outcomes. To address this issue, we introduce MJ-BENCH, a novel benchmark which incorporates a comprehensive preference dataset to evaluate multimodal judges in providing feedback for image generation models across four key perspectives: alignment, safety, image quality, and bias. Specifically, we evaluate a large variety of multimodal judges including smaller-sized CLIP-based scoring models, open-source VLMs (e.g. LLaVA family), and close-source VLMs (e.g. GPT-4o, Claude 3) on each decomposed subcategory of our preference dataset. Experiments reveal that close-source VLMs generally provide better feedback, with GPT-4o outperforming other judges in average. Compared with open-source VLMs, smaller-sized scoring models can provide better feedback regarding text-image alignment and image quality, while VLMs provide more accurate feedback regarding safety and generation bias due to their stronger reasoning capabilities. Further studies in feedback scale reveal that VLM judges can generally provide more accurate and stable feedback in natural language (Likert-scale) than numerical scales. Notably, human evaluations on end-to-end fine-tuned models using separate feedback from these multimodal judges provide similar conclusions, further confirming the effectiveness of MJ-Bench.", "title_embedding_index": 8113, "title_abs_embedding_index": 8138}, {"title": "Provably Noise-Resilient Training of Parameterized Quantum Circuits", "link_suffix": "/forum?id=hqxzi4d3Ws", "link": "https://openreview.net/forum?id=hqxzi4d3Ws", "pdf_link": "https://openreview.net/pdf?id=hqxzi4d3Ws", "keywords": "robustness, quantum, Parameterized Quantum Circuits, Noise-Resilient", "abstract": "Advancements in quantum computing have spurred significant interest in harnessing its potential for speedups over classical systems. However, noise remains a major obstacle to achieving reliable quantum algorithms. In this work, we introduce a provably noise-resilient training theory and algorithm to enhance the robustness of parameterized quantum circuits. Our method, with a natural connection to Evolutionary Strategies, guarantees resilience to parameter noise with minimal adjustments to commonly used optimization algorithms, as demonstrated in phase classification and state preparation tasks. Our approach is function-agnostic, adaptable to various quantum circuits, and capable of providing explainability insights into quantum models. By developing provably guaranteed learning theory with quantum circuits, our work opens new avenues for practical, robust applications of near-term quantum computers.", "title_embedding_index": 8114, "title_abs_embedding_index": 8139}, {"title": "Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding", "link_suffix": "/forum?id=4Po8d9GAfQ", "link": "https://openreview.net/forum?id=4Po8d9GAfQ", "pdf_link": "https://openreview.net/pdf?id=4Po8d9GAfQ", "keywords": "Large language model, Optimizing LLM reasoning capabilities, Self-improvement, Reward model-free optimization, Reinforcement learning", "abstract": "Large language models (LLMs) have shown impressive capabilities, but still struggle with complex reasoning tasks requiring multiple steps. While prompt-based methods like Chain-of-Thought (CoT) can improve LLM reasoning at inference time, optimizing reasoning capabilities during training remains challenging. We introduce LaTent Reasoning Optimization (LaTRO), a principled framework that formulates reasoning as sampling from a latent distribution and optimizes it via variational approaches. LaTRO enables LLMs to concurrently improve both their reasoning process and ability to evaluate reasoning quality, without requiring external feedback or reward models. We validate LaTRO through experiments on GSM8K and ARC-Challenge datasets using multiple model architectures. On GSM8K, LaTRO improves zero-shot accuracy by an average of 12.5% over base models and 9.6% over supervised fine-tuning across Phi-3.5-mini, Mistral-7B, and Llama-3.1-8B. Our findings suggest that pre-trained LLMs possess latent reasoning capabilities that can be unlocked and enhanced through our proposed optimization approach in a self-improvement manner.", "title_embedding_index": 8115, "title_abs_embedding_index": 8140}, {"title": "Controllable Generation via Locally Constrained Resampling", "link_suffix": "/forum?id=8g4XgC8HPF", "link": "https://openreview.net/forum?id=8g4XgC8HPF", "pdf_link": "https://openreview.net/pdf?id=8g4XgC8HPF", "keywords": "Neuro-symbolic, LLMs, Controllable Generation, Constraints, Probabilistic Methods", "abstract": "Autoregressive models have demonstrated an unprecedented ability at modeling the intricacies\nof natural language. However, they continue to struggle with generating complex outputs that adhere to\nlogical constraints. Sampling from a fully-independent distribution subject to a constraint is hard. Sampling from an autoregressive distribution subject to a constraint is doubly hard: We have to contend not only with the hardness of the constraint but also the  distribution's lack of structure. We propose a tractable probabilistic approach that performs Bayesian conditioning to draw samples subject to a constraint. By factoring in information about the entire sequence, our approach offers better contextual awareness during constrained generation compared to current greedy approaches. Starting from a model sample, we induce a local, factorized distribution which we can\ntractably condition on the constraint. To generate samples that satisfy the constraint, we sample from the conditional distribution,\ncorrect for biases in the sample weights, and resample. The resulting samples closely approximate the target distribution and are guaranteed to satisfy the constraints. We evaluate our approach on several tasks, including LLM detoxification and solving Sudoku puzzles. We show that by disallowing a list of toxic expressions our approach is able to steer the model's outputs away from toxic generations, outperforming similar approaches to detoxification. We also show that our approach achieves a perfect accuracy on Sudoku, compared to less than $50%$ for GPT4-o and Gemini 1.5.", "title_embedding_index": 8116, "title_abs_embedding_index": 8141}, {"title": "GFSE: A Foundational Model For Graph Structural Encoding", "link_suffix": "/forum?id=JQT6iGrXTh", "link": "https://openreview.net/forum?id=JQT6iGrXTh", "pdf_link": "https://openreview.net/pdf?id=JQT6iGrXTh", "keywords": "foundation model, graph representation learning", "abstract": "Foundation models have recently shown remarkable promise by leveraging extensive pre-training on diverse datasets to acquire generalizable representations, which enable effective transfer to a wide range of downstream tasks. In the graph domain, however, most existing pre-training models are tailored to specific domains, primarily due to the inherent differences in semantic meanings of graph features across various contexts. Additionally, most existing models struggle to capture the rich topological complexity of graph structures, leading to inadequate exploration of the embedding space. To address these challenges, we propose a novel Graph Foundational Structural Encoder (GFSE) that identifies universal structural patterns, facilitating a unified feature embedding space suitable for diverse domains, including molecular structures, social networks, and citation networks. GFSE is the first cross-domain graph structural encoder pre-trained with multiple self-supervised learning objectives. Built on a Graph Transformer, GFSE incorporates attention mechanisms biased by graph structural information, allowing it to encode intricate multi-level and fine-grained topological features within complex graph structures. The pre-trained GFSE produces generic and theoretically expressive positional and structural encoding for graphs, which can be seamlessly integrated with various downstream graph feature encoders, including graph neural networks for graphs with vectorized features and Large Language Models for text-attributed graphs. Comprehensive experiments on synthetic and real-world datasets demonstrate GFSE's capability to significantly enhance the model's performance while requiring substantially less task-specific fine-tuning. \nNotably, GFSE boosts the performance by an average margin of 20.48% across eight real-world datasets, highlighting its potential as a powerful and adaptable foundational encoder for graph-structured data.", "title_embedding_index": 8117, "title_abs_embedding_index": 8142}, {"title": "StEVE: Adaptive Optimization in a Kronecker-Factored Eigenbasis", "link_suffix": "/forum?id=2KWZjdFwmh", "link": "https://openreview.net/forum?id=2KWZjdFwmh", "pdf_link": "https://openreview.net/pdf?id=2KWZjdFwmh", "keywords": "KFAC, EKFAC, Natural Gradient Descent, Adam, Optimization, Stochastic Optimization", "abstract": "Adaptive optimization algorithms such as Adam see widespread use in Deep Learning. However, these methods rely on diagonal approximations of the preconditioner, losing much information about the curvature of the loss surface and potentially leading to prolonged training times. We introduce StEVE (Stochastic Eigenbasis-adaptive Variance Estimation), a novel optimization algorithm that estimates lower order moments in the Kronecker-Factored Eigenbasis (KFE). By combining the advantages of Adam over other adaptive methods with the curvature-aware transformations of methods like KFAC and EKFAC, StEVE leverages second-order information while remaining computationally efficient. Our experiments demonstrate that EVE achieves faster convergence both in step-count and in wall-clock time compared to Adam, EKFAC, and KFAC for a variety of deep neural network architectures.", "title_embedding_index": 8118, "title_abs_embedding_index": 8143}, {"title": "XTransplant: A Probe into the Upper Bound Performance of Multilingual Capability in LLMs via Cross-lingual Transplantation", "link_suffix": "/forum?id=r3GxWNGpSj", "link": "https://openreview.net/forum?id=r3GxWNGpSj", "pdf_link": "https://openreview.net/pdf?id=r3GxWNGpSj", "keywords": "Large language models, Multilingual capability, Feed forward activations, Upper Bound Performance", "abstract": "Current large language models (LLMs) often display significant imbalances in their multilingual capabilities and cultural adaptability, primarily due to their unbalanced and English-centric pretraining data.\nFor these English-centric LLMs, the disparities between English and non-English languages hinder their ability to utilize their robust English-based capabilities within non-English contexts, while also limiting access to valuable multilingual knowledge derived from non-English \"language-specific neurons\" within English contexts.\nMotivated by this, our work explores the possibility for LLMs to leverage the strengths of both English and non-English languages, aiming to further unlock their multilingual potential.\nTo this end, we propose a probing method named $\\mathcal{X}$Transplant, which directly transplants feed-forward activations from English input to non-English (or from non-English to English) during inference stage, allowing the model to benefit from both English and additional multilingual knowledge.\nThrough extensive experiments on our pilotsets and representative LLMs across different tasks and languages, we empirically prove that both the multilingual capabilities and cultural adaptability of LLMs hold the potential to be significantly improved by the cross-lingual feed forward transplantation, respectively from $\\texttt{En} \\rightarrow \\texttt{non-En}$ and $\\texttt{non-En} \\rightarrow \\texttt{En}$. \nAdditionally, we also establish the upper bound performance of LLMs obtained through $\\mathcal{X}$Transplant (relative growth of +80% in multilingual capabilities, +39% in cultural adaptability), highlighting the underutilization of current LLMs' multilingual potential. \nWe do hope our further analysis and discussion could suggest promising directions for deeply unlocking the multilingual potential of current English-centric LLMs.", "title_embedding_index": 8119, "title_abs_embedding_index": 8144}, {"title": "Understanding Learning with Sliced-Wasserstein Requires Re-thinking Informative Slices", "link_suffix": "/forum?id=PqeMnyGU1B", "link": "https://openreview.net/forum?id=PqeMnyGU1B", "pdf_link": "https://openreview.net/pdf?id=PqeMnyGU1B", "keywords": "Optimal Transport, Sliced Wasserstein, Concentration of Measure", "abstract": "The practical applications of Wasserstein distances (WDs) are constrained by their sample and computational complexities. Sliced-Wasserstein distances (SWDs) provide a workaround by projecting distributions onto one-dimensional subspaces, leveraging the more efficient, closed-form WDs for one-dimensional distributions. However, in high dimensions, most random projections become uninformative due to the concentration of measure phenomenon. Although several SWD variants have been proposed to focus on \\textit{informative} slices, they often introduce additional complexity, numerical instability, and compromise desirable theoretical (metric) properties of SWD. Amidst the growing literature that focuses on directly modifying the slicing distribution, which often face challenges, we revisit the classic Sliced-Wasserstein and propose instead to rescale the 1D Wasserstein to make all slices equally informative. Importantly, we show that with an appropriate notion of \\textit{slice informativeness}, rescaling for all individual slices simplifies to \\textbf{a single global scaling factor} on the SWD. This, in turn, translates to the standard learning rate search for gradient-based learning in common ML workflows. We perform extensive experiments across various machine learning tasks showing that the classic SWD, when properly configured, can often match or surpass the performance of more complex variants. We then answer the following question: Is Sliced-Wasserstein all you need for common learning tasks?", "title_embedding_index": 8120, "title_abs_embedding_index": 8145}, {"title": "Bridging General and Personalized Federated Learning through Selective Model Integration", "link_suffix": "/forum?id=B8akWa62Da", "link": "https://openreview.net/forum?id=B8akWa62Da", "pdf_link": "https://openreview.net/pdf?id=B8akWa62Da", "keywords": "Federated Learning", "abstract": "Personalized federated learning (PFL) achieves high performance by assuming clients only meet test data locally, which does not meet many generic federated learning (GFL) scenarios. In this work, we theoretically show that PMs can be used to enhance GFL with a new learning problem named Selective FL (SFL), which involves optimizing PFL and model selection. However, storing and selecting whole models requires impractical computation and communication costs. To practically solve SFL, inspired by model components that attempt to edit a sub-model for specific purposes, we design an efficient and effective framework named Hot-Pluggable Federated Learning (HPFL). Specifically, clients individually train personalized plug-in modules based on a shared backbone, and upload them with a plug-in marker on the server modular store. In inference stage, an accurate selection algorithm allows clients to identify and retrieve suitable plug-in modules from the modular store to enhance their generalization performance on the target data distribution. Furthermore, we provide differential privacy protection during the selection with theoretical guarantee. Our comprehensive experiments and ablation studies demonstrate that HPFL significantly outperforms state-of-the-art GFL and PFL algorithms. Additionally, we empirically show HPFL's remarkable potential to resolve other practical FL problems such as continual federated learning and discuss its possible applications in one-shot FL, anarchic FL, and FL plug-in market. Our work is the first attempt towards improving GFL performance through a selecting mechanism with personalized plug-ins.", "title_embedding_index": 8121, "title_abs_embedding_index": 8146}, {"title": "RestoreGrad: Signal Restoration Using Conditional Denoising Diffusion Models with Jointly Learned Prior", "link_suffix": "/forum?id=UbMYhX60tY", "link": "https://openreview.net/forum?id=UbMYhX60tY", "pdf_link": "https://openreview.net/pdf?id=UbMYhX60tY", "keywords": "Denoising diffusion probabilistic model, prior distribution, posterior, speech enhancement, image restoration", "abstract": "Denoising diffusion probabilistic models (DDPMs) estimate the data distribution by sequentially denoising samples drawn from a prior distribution, which is typically assumed to be the standard Gaussian for simplicity. Owing to their capabilities of generating high-fidelity samples, DDPMs can be utilized for signal restoration tasks in recovering a clean signal from its degraded observation(s), by conditioning the model on the degraded signal. The degraded signals are themselves contaminated versions of the clean signals; due to this correlation, they may encompass certain useful information about the target clean data distribution. However, naively adopting the standard Gaussian as the prior distribution in turn discards such information. In this paper, we propose to improve conditional DDPMs by leveraging a more informative prior that is jointly learned with the diffusion model. The proposed framework, called RestoreGrad, exploits the correlation between the degraded and clean signals to construct a better prior, which is especially useful for signal restoration tasks. In contrast to existing DDPMs that just settle on using pre-defined or handcrafted priors, RestoreGrad learns the prior jointly with the diffusion model. To this end, we first derive a new objective function from a modified evidence lower bound (ELBO) of the data log-likelihood, to incorporate the prior learning process into conditional DDPMs. Then, we suggest a corresponding joint learning paradigm for optimizing the new ELBO. Notably, RestoreGrad requires minimum modifications to the diffusion model itself; thus, it can be flexibly implemented on top of various conditional DDPM-based signal restoration models. On speech and image restoration tasks, we show that RestoreGrad demonstrates faster convergence (5-10 times fewer training steps) to achieve on par or better perceptual quality of restored signals over existing DDPM baselines, along with improved robustness to using fewer sampling steps in inference time (2-2.5 times fewer steps), advocating the advantages of leveraging jointly learned prior for efficiency improvements in the diffusion process.", "title_embedding_index": 8122, "title_abs_embedding_index": 8147}, {"title": "Stable Hadamard Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning", "link_suffix": "/forum?id=We5z3UEnUY", "link": "https://openreview.net/forum?id=We5z3UEnUY", "pdf_link": "https://openreview.net/pdf?id=We5z3UEnUY", "keywords": "Reinforcement Learning, Memory, POMDP", "abstract": "Effective decision-making in partially observable environments demands robust memory management. Despite their success in supervised learning, current deep-learning memory models struggle in reinforcement learning environments that are partially observable and long-term. They fail to efficiently capture relevant past information, adapt flexibly to changing observations, and maintain stable updates over long episodes. We theoretically analyze the limitations of existing memory models within a unified framework and introduce the Stable Hadamard Memory, a novel memory model for reinforcement learning agents. Our model dynamically adjusts memory by erasing no longer needed experiences and reinforcing crucial ones computationally efficiently. To this end, we leverage the Hadamard product for calibrating and updating memory, specifically designed to enhance memory capacity while mitigating numerical and learning challenges. Our approach significantly outperforms state-of-the-art memory-based methods on challenging partially observable benchmarks, such as meta-reinforcement learning, long-horizon credit assignment, and POPGym, demonstrating superior performance in handling long-term and evolving contexts.", "title_embedding_index": 8123, "title_abs_embedding_index": 8148}, {"title": "MeZO-A3dam: Memory-efficient Zeroth-order Adam with Adaptivity Adjustments for Fine-tuning LLMs", "link_suffix": "/forum?id=OBIuFjZzmp", "link": "https://openreview.net/forum?id=OBIuFjZzmp", "pdf_link": "https://openreview.net/pdf?id=OBIuFjZzmp", "keywords": "Optimization, Zeroth-Order Optimization, Large Language Models, Fine-tuning", "abstract": "Recently, fine-tuning of language models (LMs) via zeroth-order (ZO) optimization have gained significant traction due to their ability of  memory-efficient deployment, significantly reducing memory cost over first-order methods. However, the existing studies on ZO optimization for LM fine-tuning often exhibit slow convergence and the reliance on the hand-crafted prompts. Towards mitigating these limitations, in this paper, we first investigate on the importance of adaptive gradient based ZO optimization method. Toward this, we revisit memory-efficient zeroth-order Adam (MeZO-Adam) and make important findings that merely considering adaptivity can enable faster convergence while improving the generalization ability compared to previous studies. Interestingly, we further observe that decreasing the level of adaptivity might be recommended in ZO optimization potentially due to the high variance of ZO gradient estimate, hypothesized as \\emph{weak adaptivity hypothesis}. Based upon our hypothesis, we propose MeZO-A$^3$dam, MeZO-Adam with Adaptivity Adjustments according to the parameter dimension. We provide the dimension-free theoretical guarantee on both the convergence and the generalization of MeZO-A$^3$dam, providing strong evidence for our hypothesis. Extensive experiments show that MeZO-A$^3$dam can achieve faster convergence and better generalization over several baselines across LMs of various sizes on diverse datasets. By adaptivity adjustments, MeZO-A$^3$dam outperforms MeZO, MeZO-SVRG, and MeZO-Adam, with up to an average of $36.6\\%$, $16.9\\%$, $6.8\\%$ improvements in performance and up to an average of $\\times 12.6$ and $\\times1.8$ faster convergence, respectively. Furthermore, by leveraging an off-the-shelf low-bit optimizer, MeZO-A$^3$dam achieves an average of $40.3\\%$ and $43.6\\%$ memory reduction from MeZO-SVRG and MeZO-Adam.", "title_embedding_index": 8124, "title_abs_embedding_index": 8149}]
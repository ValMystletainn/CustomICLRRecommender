[
    {
        "title": "LLM-Informed Semi-Supervised Learning for Text Classification",
        "link_suffix": "/forum?id=Mu2tNzS0AM",
        "link": "https://openreview.net/forum?id=Mu2tNzS0AM",
        "pdf_link": "https://openreview.net/pdf?id=Mu2tNzS0AM",
        "keywords": "semi-supervised learning, LLM",
        "abstract": "Large Language Models (LLMs) have shown impressive zero-shot and few-shot capabilities in many NLP tasks including text classification. While these models outperform others in terms of raw performance when few examples are available, they are expensive to use in practice and may lag behind traditional approaches when data (labeled or unlabeled) is plentiful. Semi-supervised learning (SSL) on the other hand can utilize large amounts of unlabeled data in combination with labeled data to improve a model's performance. In this paper, we propose to unify LLM and SSL under a common framework which effectively leverages the few-shot capabilities of LLMs in combination with SSL's ability to extract valuable information from unlabeled data to improve the model capabilities in text classification. Our approach, entitled LLM-SSL, utilizes LLMs to generate predictions on unlabeled examples and uses these predictions to guide the SSL training and improve the quality of pseudo-labels during training. We show that LLM-SSL outperforms both prior SSL approaches as well as few-shot LLMs on six text classification benchmarks."
    },
    {
        "title": "ProteinWeaver: A Divide-and-Assembly Approach for Protein Backbone Design",
        "link_suffix": "/forum?id=mPMLZv4kSL",
        "link": "https://openreview.net/forum?id=mPMLZv4kSL",
        "pdf_link": "https://openreview.net/pdf?id=mPMLZv4kSL",
        "keywords": "divide and assembly, protein backbone design, domain assembly, long-chain proteins",
        "abstract": "Nature creates diverse proteins through a 'divide and assembly' strategy. Inspired by this idea, we introduce ProteinWeaver, a two-stage framework for protein backbone design. Our method first generates individual protein domains, then employs an SE(3) diffusion model to flexibly assemble these domains. A key challenge lies in the assembling step, given the complex and rugged nature of the inter-domain interaction landscape. To address this challenge, we employ preference alignment to discern complex relationships between structure and interaction landscapes through comparative analysis of generated samples. Comprehensive experiments demonstrate that ProteinWeaver: (1) generates high-quality, novel protein backbones through versatile domain assembly; (2) outperforms RFdiffusion, the current state-of-the-art in backbone design, by 13% and 39% for long-chain proteins; (3) shows the potential for cooperative function design through illustrative case studies. To sum up, by introducing a 'divide-and-assembly' paradigm, ProteinWeaver advances protein engineering and opens new avenues for functional protein design."
    },
    {
        "title": "SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models",
        "link_suffix": "/forum?id=9chRqsPOGL",
        "link": "https://openreview.net/forum?id=9chRqsPOGL",
        "pdf_link": "https://openreview.net/pdf?id=9chRqsPOGL",
        "keywords": "large language model, instruction-following, self-improvement",
        "abstract": "Instruction-following is a fundamental capability of language models, requiring the model to recognize even the most subtle requirements in the instructions and accurately reflect them in its output.\nSuch an ability is well-suited for and often optimized by preference learning.\nHowever, existing methods often directly sample multiple independent responses from the model when creating preference pairs.\nSuch practice can introduce content variations irrelevant to whether the instruction is precisely followed (e.g., different expressions about the same semantic), interfering with the goal of teaching models to recognize the key differences that lead to improved instruction following.\nIn light of this, we introduce SPaR, a self-play framework integrating tree-search self-refinement to yield valid and comparable preference pairs free from distractions.\nBy playing against itself, an LLM employs a tree-search strategy to refine its previous responses with respect to the instruction while minimizing unnecessary variations.\nOur experiments show that a LLaMA3-8B model, trained over three iterations guided by SPaR, surpasses GPT-4-Turbo on the IFEval benchmark without losing general capabilities. \nFurthermore, SPaR demonstrates promising scalability, greatly enhancing the performance of LLaMA3-70B.\nWe also identify how inference scaling in tree search would impact model performance.\nCode and data will be publicly available."
    },
    {
        "title": "SCAR: Efficient Instruction-Tuning for Large Language Models via Style Consistency-Aware Response Ranking",
        "link_suffix": "/forum?id=5lokEzttBF",
        "link": "https://openreview.net/forum?id=5lokEzttBF",
        "pdf_link": "https://openreview.net/pdf?id=5lokEzttBF",
        "keywords": "Style Consistency, Data Efficiency, LLM Alignment, Fine-Tuning",
        "abstract": "Recent studies have shown that maintaining a consistent response style by human experts and enhancing data quality in training sets can significantly improve the performance of fine-tuned Large Language Models (LLMs) while reducing the number of training examples needed. However, the precise definition of style and the relationship between style, data quality, and LLM performance remains unclear. This research identifies two key stylistic elements in responses: linguistic form and semantic surprisal. We find that, among training data of comparable quality, higher consistency in these response elements leads to better LLM performance. Inspired by this, we introduce Style Consistency-Aware Response Ranking (SCAR), which automatically prioritizes instruction-response pairs in the training set based on their response stylistic consistency. By selecting the most style-consistent examples, sometimes as few as 0.7% of the full dataset, the fine-tuned LLMs can match or even surpass the performance of models trained on the entire dataset in coding and open-ended question-answering benchmarks. Code and data are available athttps://anonymous.4open.science/r/SCAR-0233/."
    },
    {
        "title": "EMMA: Empowering Multi-modal Mamba with Structural and Hierarchical Alignment",
        "link_suffix": "/forum?id=Ev4iw23gdI",
        "link": "https://openreview.net/forum?id=Ev4iw23gdI",
        "pdf_link": "https://openreview.net/pdf?id=Ev4iw23gdI",
        "keywords": "Multimodal models, State space models, Efficient architectures, Mamba, Computational Efficiency, Multimodal Alignment",
        "abstract": "Mamba-based architectures have shown to be a promising new direction for deep learning models owing to their competitive performance and sub-quadratic deployment speed. However, current Mamba multi-modal large language models (MLLM) are insufficient in extracting visual features, leading to imbalanced cross-modal alignment between visual and textural latents, negatively impacting performance on multi-modal tasks. In this work, we propose Empowering Multi-modal Mamba with Structural and Hierarchical Alignment (EMMA), which enables the MLLM to extract fine-grained visual information. Specifically, we propose a pixel-wise alignment module to autoregressively optimize the learning and processing of spatial image-level features along with textual tokens, enabling structural alignment at the image level. In addition, to prevent the degradation of visual information during the cross-model alignment process, we propose a multi-scale feature fusion (MFF) module to combine multi-scale visual features from intermediate layers, enabling hierarchical alignment at the feature level. Extensive experiments are conducted across a variety of multi-modal benchmarks. Our model shows lower latency than other Mamba-based MLLMs and is nearly four times faster than transformer-based MLLMs of similar scale during inference. Due to better cross-modal alignment, our model exhibits lower degrees of hallucination and enhanced sensitivity to visual details, which manifests in superior performance across diverse multi-modal benchmarks. Code will be provided."
    },
    {
        "title": "Mitigating Spurious Bias with Last-Layer Selective Activation Retraining",
        "link_suffix": "/forum?id=x9rtYetTsA",
        "link": "https://openreview.net/forum?id=x9rtYetTsA",
        "pdf_link": "https://openreview.net/pdf?id=x9rtYetTsA",
        "keywords": "spurious correlation, robustness, classification",
        "abstract": "Deep neural networks trained with standard empirical risk minimization (ERM) tend to exploit the spurious correlations between non-essential features and classes for predictions. For example, models might identify an object using its frequently co-occurring background, leading to poor performance on data lacking the correlation. Last-layer retraining approaches the problem of over-reliance on spurious correlations by adjusting the weights of the final classification layer. The success of this technique provides an appealing alternative to the problem by focusing on the improper weighting on neuron activations developed during training. However, annotations on spurious correlations are needed to guide the weight adjustment. In this paper, for the first time, we demonstrate that neuron activations, coupled with their final prediction outcomes, provide self-identifying information on whether the neurons represent spurious features. Using this information, we propose last-layer selective activation retraining, which retrains the last classification layer while selectively blocking neurons that are identified as spurious. In this way, we promote the model to discover robust decision rules beyond spurious correlations. Our method works in a classic ERM training setting where no additional annotations beyond class labels are available, making it a practical post-hoc tool for improving a model's robustness to spurious correlations. We demonstrate that our method is effective with different model architectures and can effectively mitigate spurious bias on different data modalities without requiring annotations of spurious correlations in data."
    },
    {
        "title": "Emergent Orientation Maps \u2014\u2014 Mechanisms, Coding Efficiency and Robustness",
        "link_suffix": "/forum?id=rySLejeB1k",
        "link": "https://openreview.net/forum?id=rySLejeB1k",
        "pdf_link": "https://openreview.net/pdf?id=rySLejeB1k",
        "keywords": "Vision, Energy Efficient Coding, Neural Network, Sensory Coding, Spiking Mechanism",
        "abstract": "Extensive experimental studies have established that in less visually advanced animals, the neuronal preference for input orientation in the primary visual cortex (V1) is organized in a disordered fashion (known as salt-and-pepper organizations). In contrast, in visually advanced animals, the orientation preference varies continuously across V1, forming pinwheel-like structures. However, the mechanisms underlying the emergence of these two seemingly distinctive structures are not fully understood, and their differential influences on visual encoding remain largely unexplored. To address these questions, we introduce a self-evolving spiking neural network model with plasticity that can reproduce those emergent structures in several representative animals by incorporating data on retinotopy, neuronal morphology, and connectivity for each species. We show that the salt-and-pepper organizations and pinwheel structures actually sit at the two ends of the same spectrum using a metric that involves the overlap of receptive fields and neuronal density. We also find the same mechanisms account for the formation of both structures through local recurrent connections guided by Hebbian-like learning rules. Next, we show functionally that pinwheel structures exhibit lower wiring costs and higher encoding efficiency than salt-and-pepper organizations. Finally, pinwheel structures exhibit sparse coding and greater robustness against noise in natural stimuli. These functional advantages may inspire the deep learning community to revisit the possibility of recurrent connectivity within each layer for higher coding efficiency and robustness."
    },
    {
        "title": "OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning",
        "link_suffix": "/forum?id=AEwtGiJVPi",
        "link": "https://openreview.net/forum?id=AEwtGiJVPi",
        "pdf_link": "https://openreview.net/pdf?id=AEwtGiJVPi",
        "keywords": "parameter efficient fine-tuning, large language model, low-rank, layerwise sampling",
        "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized various natural language processing tasks. However, the substantial size of LLMs presents significant challenges in training or fine-tuning. While parameter-efficient approaches such as low-rank adaptation (LoRA) have gained popularity, they often compromise performance compared to full-rank fine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled Low-Rank Projection (OwLore), a new memory-efficient fine-tuning approach, inspired by the layerwise outlier distribution of LLMs. Unlike LoRA, which adds extra adapters to all layers, OwLore strategically assigns higher sampling probabilities to layers with more outliers, selectively sampling only a few layers and fine-tuning their pre-trained weights. To further increase the number of fine-tuned layers without a proportional rise in memory costs, we incorporate gradient low-rank projection, further boosting the approach\u2019s performance. Our extensive experiments across various architectures, including LLaMa2, LLaMa3, and Mistral, demonstrate that OwLore consistently outperforms baseline approaches, including full fine-tuning. Specifically, it achieves up to a 1.1% average accuracy gain on the Commonsense Reasoning benchmark, a 3.0% improvement on MMLU, and a notable 10% boost on MT-Bench, while being more memory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of memory. Our code is submitted."
    },
    {
        "title": "packetLSTM: Dynamic LSTM Framework for Streaming Data with Varying Feature Space",
        "link_suffix": "/forum?id=VzdycorGTt",
        "link": "https://openreview.net/forum?id=VzdycorGTt",
        "pdf_link": "https://openreview.net/pdf?id=VzdycorGTt",
        "keywords": "Varying Input Dimension, Stremaing Data, Online Learning, Recurrent Neural Network, Catastrophic Forgetting",
        "abstract": "We study the online learning problem characterized by the varying input feature space of streaming data. Although LSTMs have been employed to effectively capture the temporal nature of streaming data, they cannot handle the dimension-varying streams in an online learning setting. Therefore, we propose a dynamic LSTM-based novel method, packetLSTM, to model the dimension-varying streams. The packetLSTM's dynamic framework consists of an evolving packet of LSTMs, each dedicated to processing one input feature. Each LSTM retains the local information of its corresponding feature, while a shared common memory consolidates global information. This configuration facilitates continuous learning and mitigates the issue of forgetting, even when certain features are absent for extended time periods. The idea of utilizing one LSTM per feature coupled with a dimension-invariant operator for information aggregation enhances the dynamic nature of packetLSTM. This dynamic nature is evidenced by the model's ability to activate, deactivate, and add new LSTMs as required, thus seamlessly accommodating varying input dimensions. The packetLSTM achieves state-of-the-art results on five datasets, and its underlying principle is extended to other RNN types, like GRU and vanilla RNN."
    },
    {
        "title": "From Link Prediction to Forecasting: Information Loss in Batch-based Temporal Graph Learning",
        "link_suffix": "/forum?id=5JOxazmj8b",
        "link": "https://openreview.net/forum?id=5JOxazmj8b",
        "pdf_link": "https://openreview.net/pdf?id=5JOxazmj8b",
        "keywords": "Graph Neural Network, GNN, Temporal Graph, Dynamic Link Prediction, Dynamic Graph, Temporal Graph Learning, Dynamic Graph Learning, Temporal Graph Neural Network, TGNN, DyGNN, Dynamic Graph Neural Network",
        "abstract": "Dynamic link prediction is an important problem considered by many recent works\nproposing various approaches for learning temporal edge patterns. To assess their\nefficacy, models are evaluated on publicly available benchmark datasets involving\ncontinuous-time and discrete-time temporal graphs. However, as we show in this\nwork, the suitability of common batch-oriented evaluation depends on the datasets\u2019\ncharacteristics, which can cause multiple issues: For continuous-time temporal\ngraphs, fixed-size batches create time windows with different durations, resulting in\nan inconsistent dynamic link prediction task. For discrete-time temporal graphs, the\nsequence of batches can additionally introduce temporal dependencies that are not\npresent in the data. In this work, we empirically show that this common evaluation\napproach leads to skewed model performance and hinders the fair comparison of\nmethods. We mitigate this problem by reformulating dynamic link prediction as a\nlink forecasting task that better accounts for temporal information present in the\ndata. We provide implementations of our new evaluation method for commonly\nused graph learning frameworks."
    },
    {
        "title": "Active Fine-Tuning of Generalist Policies",
        "link_suffix": "/forum?id=ARBHBA8YfW",
        "link": "https://openreview.net/forum?id=ARBHBA8YfW",
        "pdf_link": "https://openreview.net/pdf?id=ARBHBA8YfW",
        "keywords": "imitation learning, deep reinforcement learning, multi-task reinforcement learning, active learning, fine-tuning",
        "abstract": "Pre-trained generalist policies are rapidly gaining relevance in robot learning due to their promise of fast adaptation to novel, in-domain tasks.\nThis adaptation often relies on collecting new demonstrations for a specific task of interest and applying imitation learning algorithms, such as behavioral cloning.\nHowever, as soon as several tasks need to be learned, we must decidewhich tasks should be demonstrated and how often?We study this multi-task problem and explore an interactive framework in which the agentadaptivelyselects the tasks to be demonstrated.\nWe propose AMF (Active Multi-task Fine-tuning), an algorithm to maximize multi-task policy performance under a limited demonstration budget by collecting demonstrations yielding the largest information gain on the expert policy.\nWe derive performance guarantees for AMF under regularity assumptions and demonstrate its empirical effectiveness to efficiently fine-tune neural policies in complex and high-dimensional environments."
    },
    {
        "title": "RAPID: Retrieval Augmented Training of Differentially Private Diffusion Models",
        "link_suffix": "/forum?id=txZVQRc2ab",
        "link": "https://openreview.net/forum?id=txZVQRc2ab",
        "pdf_link": "https://openreview.net/pdf?id=txZVQRc2ab",
        "keywords": "Diffusion model, retrieval augmented generation, differential privacy",
        "abstract": "Differentially private diffusion models (DPDMs) harness the remarkable generative capabilities of diffusion models while enforcing differential privacy (DP) for sensitive data. However, existing DPDM training approaches often suffer from significant utility loss, large memory footprint, and expensive inference cost, impeding their practical uses.To overcome such limitations, we present RAPID: Retrieval Augmented PrIvate Diffusion model, a novel approach that integrates retrieval augmented generation (RAG) into DPDM training. Specifically, RAPID leverages available public data to build a knowledge base of sample trajectories; when training the diffusion model on private data, RAPID computes the early sampling steps as queries, retrieves similar trajectories from the knowledge base as surrogates, and focuses on training the later sampling steps in a differentially private manner. Extensive evaluation using benchmark datasets and models demonstrates that, with the same privacy guarantee, RAPID significantly outperforms state-of-the-art approaches by large margins in generative quality, memory footprint, and inference cost, suggesting that retrieval-augmented DP training represents a promising direction for developing future privacy-preserving generative models (code and data are available in the submitted supplemental materials)."
    },
    {
        "title": "Exact Computation of Any-Order Shapley Interactions for Graph Neural Networks",
        "link_suffix": "/forum?id=9tKC0YM8sX",
        "link": "https://openreview.net/forum?id=9tKC0YM8sX",
        "pdf_link": "https://openreview.net/pdf?id=9tKC0YM8sX",
        "keywords": "Graph Neural Networks (GNNs), Shapley Interactions, Game Theory, Explainable AI, Feature Interactions",
        "abstract": "Albeit the ubiquitous use of Graph Neural Networks (GNNs) in machine learning (ML) prediction tasks involving graph-structured data, their interpretability remains challenging. In explainable artificial intelligence (XAI), the Shapley Value (SV) is the predominant method to quantify contributions of individual features to a ML model\u2019s output. Addressing the limitations of SVs in complex prediction models, Shapley Interactions (SIs) extend the SV to groups of features. In this work, we explain single graph predictions of GNNs with SIs that quantify node contributions and interactions among multiple nodes. By exploiting the GNN architecture, we show that the structure of interactions in node embeddings are preserved for graph prediction. As a result, the exponential complexity of SIs depends only on the receptive fields, i.e. the message-passing ranges determined by the connectivity of the graph and the number of convolutional layers. Based on our theoretical results, we introduce GraphSHAP-IQ, an efficient approach to compute any-order SIs exactly. GraphSHAP-IQ is applicable to popular message passing techniques in conjunction with a linear global pooling and output layer. We showcase that GraphSHAP-IQ substantially reduces the exponential complexity of computing exact SIs on multiple benchmark datasets. Beyond exact computation, we evaluate GraphSHAP-IQ\u2019s approximation of SIs on popular GNN architectures and compare with existing baselines. Lastly, we visualize SIs of real-world water distribution networks and molecule structures using a SI-Graph."
    },
    {
        "title": "Privacy as a Free Lunch: Crafting Initial Distilled Datasets through the Kaleidoscope",
        "link_suffix": "/forum?id=ckabXglfiT",
        "link": "https://openreview.net/forum?id=ckabXglfiT",
        "pdf_link": "https://openreview.net/pdf?id=ckabXglfiT",
        "keywords": "Dataset Distillation",
        "abstract": "The advancement of deep learning necessitates stringent data privacy guarantees.\nDataset distillation has shown potential in preserving differential privacy while maintaining training efficiency.\nThis study first identifies that data generated by state-of-the-art dataset distillation methods strongly resembles to real data, indicating severe privacy leakage.\nWe define this phenomenon as explicit privacy leakage.\nWe theoretically analyze that although distilled datasets can ensure differential privacy to some extent, a high \\IPC can weaken both differential privacy and explicit privacy.\nFurthermore, we reveal that the primary source of privacy leakage in distilled data stems from the common approach of initializing distilled images as real data.\nTo address this, we propose a plug-and-play module, Kaleidoscopic Transformation (KT), designed to introduce enhanced strong perturbations to the selected real data during the initialization phase.\nExtensive experiments demonstrate that our method ensures both differential privacy and explicit privacy, while preserving the generalization performance of the distilled data.\nOur code will be publicly available."
    },
    {
        "title": "GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA",
        "link_suffix": "/forum?id=BKGM8fyFIo",
        "link": "https://openreview.net/forum?id=BKGM8fyFIo",
        "pdf_link": "https://openreview.net/pdf?id=BKGM8fyFIo",
        "keywords": "retrieval, LLM, graph, dynamic, summary, attention, KV cache, QA",
        "abstract": "In the past, Retrieval-Augmented Generation (RAG) methods split text into chunks to enable language models to handle long documents. Recent tree-based RAG methods are able to retrieve detailed information while preserving global context. However, with the advent of more powerful LLMs, such as Llama 3.1, which offer better comprehension and support for longer inputs, we found that even recent tree-based RAG methods perform worse than directly feeding the entire document into Llama 3.1, although RAG methods still hold an advantage in reducing computational costs. In this paper, we propose a new retrieval method, called LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph (GARLIC), which outperforms previous state-of-the-art baselines, including Llama 3.1, while retaining the computational efficiency of RAG methods. Our method introduces several improvements: (1) Rather than using a tree structure, we construct a Hierarchical Weighted Directed Acyclic Graph with many-to-many summarization, where the graph edges are derived from attention mechanisms, and each node focuses on a single event or very few events. (2) We introduce a novel retrieval method that leverages the attention weights of LLMs rather than dense embedding similarity. Our method allows for searching the graph along multiple paths and can terminate at any depth. (3) We use the LLM to control the retrieval process, enabling it to dynamically adjust the amount and depth of information retrieved for different queries. Experimental results show that our method outperforms previous state-of-the-art baselines, including Llama 3.1, on two single-document and two multi-document QA datasets, while maintaining similar computational complexity to traditional RAG methods."
    },
    {
        "title": "VisCon-100K: Leveraging Contextual Web Data for Fine-tuning Vision Language Models with Leaky Visual Conversations",
        "link_suffix": "/forum?id=kUL0QFvWim",
        "link": "https://openreview.net/forum?id=kUL0QFvWim",
        "pdf_link": "https://openreview.net/pdf?id=kUL0QFvWim",
        "keywords": "vision language models, visual question answering, image captioning, multimodality",
        "abstract": "Vision-language models (VLMs) excel in various visual benchmarks but are often constrained by the lack of high-quality visual fine-tuning data. To address this challenge, we introduce VisCon-100K, a novel dataset derived from interleaved image-text web documents. Our approach transforms 45K web documents from the OBELICS dataset into 100K image conversation samples. We utilize GPT-4V to generate image-contextual captions and OpenChat 3.5 model to convert these captions into diverse free-form and multiple-choice question-answer pairs. Integrating this dataset for fine-tuning considerably enhances VLM performance across multiple benchmarks. Unlike methods that focus solely on fine-grained visual content, our approach leverages accompanying web context, yielding superior results. We also discover that a `leaky modality mix,' where conversation samples contain questions answerable from both the image and its contextual caption, outperforms non-leaky combinations of captions and Q&A pairs. Our dataset shows strong performance with two popular VLM approaches: text-only large language model (LLM) aligned with a vision encoder using image captions data (ShareGPT4V-7b) and multimodally pretrained LLM (IDEFICS2-8b) using interleaved image-text data. In addition to releasing the VisCon-100K dataset, we provide a contextual captioner trained on this dataset, facilitating scalable fine-tuning data generation for future research and open-source applications."
    },
    {
        "title": "How Much is Unseen Depends Chiefly on Information About the Seen",
        "link_suffix": "/forum?id=uqWM9hBDAE",
        "link": "https://openreview.net/forum?id=uqWM9hBDAE",
        "pdf_link": "https://openreview.net/pdf?id=uqWM9hBDAE",
        "keywords": "Good-Turing frequency estimation, Multinomial probability estimation, Unseen events, Missing mass, Probability mass",
        "abstract": "We find thatin expectationthe missing mass, i.e., the proportion of data points in an unknown population---that belong to classes thatdo notappear in the training data---is entirely determined by the number $f_k$ of classes thatdoappear in the training data the same number of times and an exponentially decaying error.\nWhile this is the first precise characterization of the expected missing mass in terms of the sample, the induced estimator suffers from an impractically high variance. However, our theory suggests a large search space of nearly unbiased estimators that can be searched effectively and efficiently. Hence, we cast distribution-free estimation as an optimization problem to find a distribution-specific estimator with a minimized mean-squared error (MSE), given only the sample. In our experiments, our search algorithm discovers estimators that have a substantially smaller MSE than the state-of-the-art Good-Turing estimator. This holds for over 93% of runs when there are at least as many samples as classes. Our estimators' MSE is roughly 80% of the Good-Turing estimator's."
    },
    {
        "title": "Physiome-ODE: A Benchmark for Irregularly Sampled Multivariate Time-Series Forecasting Based on Biological ODEs",
        "link_suffix": "/forum?id=6ouZaBzeNO",
        "link": "https://openreview.net/forum?id=6ouZaBzeNO",
        "pdf_link": "https://openreview.net/pdf?id=6ouZaBzeNO",
        "keywords": "Irregular Time Series, ODE",
        "abstract": "State-of-the-art methods for forecasting irregularly sampled time series with missing values predominantly rely on just four datasets and a few small toy examples for evaluation. While ordinary differential equations (ODE) are the prevalent models in science and engineering, a baseline model that forecasts a constant value outperforms ODE-based models from the last five years on three of these existing datasets. This unintuitive finding hampers further research on ODE-based models, a more plausible model family.\nIn this paper, we develop a methodology to generate irregularly sampled multivariate time series (IMTS) datasets from ordinary differential\nequations and to select challenging instances via rejection sampling. Using this methodology, we create Physiome-ODE, a large and sophisticated benchmark of IMTS datasets consisting of 50 individual datasets, derived from real-world ordinary differential equations from research in biology. Physiome-ODE is the first benchmark for IMTS forecasting that we are aware of and an order of magnitude larger than the current evaluation setting of four datasets. Using our benchmark Physiome-ODE, we show qualitatively completely different results than those derived from the current four datasets: on Physiome-ODE ODE-based models can play to their strength and our benchmark can differentiate in a meaningful way between different IMTS forecasting models. This way, we expect to give a new impulse to research on ODE-based time series modeling."
    },
    {
        "title": "How much can we Forget about Data Contamination?",
        "link_suffix": "/forum?id=Nsms7NeU2x",
        "link": "https://openreview.net/forum?id=Nsms7NeU2x",
        "pdf_link": "https://openreview.net/pdf?id=Nsms7NeU2x",
        "keywords": "Large Language Models, Contamination, Forgetting, Scaling, Optimization",
        "abstract": "The leakage of benchmark data into the training data has emerged as a significant challenge for evaluating the capabilities of large language models (LLMs). In this work, we use experimental evidence and theoretical estimates to challenge the common assumption that small-scale contamination renders benchmark evaluations invalid. First, we experimentally quantify the magnitude of benchmark overfitting based on scaling along three dimensions: The number of model parameters (up to 1.6B), the number of times an example is seen (up to 144), and the number of training tokens (up to 40B). We find that if model and data follow the Chinchilla scaling laws, minor contamination indeed leads to overfitting. At the same time, even 144 times of contamination can be forgotten if the training data is scaled beyond five times Chinchilla, a regime characteristic of many modern LLMs. We then derive a simple theory of example forgetting via cumulative weight decay. It allows us to bound the number of gradient steps required to forget past data for any training run where we know the hyperparameters of AdamW. This indicates that many LLMs, including Llama 3, have forgotten the data seen at the beginning of training. Experimentally, we demonstrate that forgetting occurs faster than what is predicted by our bounds. Taken together, our results suggest that moderate amounts of contamination can be forgotten at the end of realistically scaled training runs."
    },
    {
        "title": "SPACT18: Spiking Human Action Recognition Benchmark Dataset with Complementary RGB and Thermal Modalities",
        "link_suffix": "/forum?id=MJip0YjQkp",
        "link": "https://openreview.net/forum?id=MJip0YjQkp",
        "pdf_link": "https://openreview.net/pdf?id=MJip0YjQkp",
        "keywords": "Spiking Camera, Spiking Neural Network, Video Understanding, Video Action Recognition",
        "abstract": "Spike cameras, bio-inspired vision sensors, asynchronously fire spikes by accumulating light intensities at each pixel, offering ultra-high energy efficiency and exceptional temporal resolution. Unlike event cameras, which record changes in light intensity to capture motion, spike cameras provide even finer spatiotemporal resolution and a more precise representation of continuous changes. In this paper, we introduce the first video action recognition (VAR) dataset using spike camera, alongside synchronized RGB and thermal modalities, to enable comprehensive benchmarking for Spiking Neural Networks (SNNs). By preserving the inherent sparsity and temporal precision of spiking data, our three datasets offer a unique platform for exploring multimodal video understanding and serve as a valuable resource for directly comparing spiking, thermal, and RGB modalities. This work contributes a novel dataset that will drive research in energy-efficient, ultra-low-power video understanding, specifically for action recognition tasks using spike-based data."
    },
    {
        "title": "Cross-Cultural Recipe Transformation via Neural Network and Encoder-Based Models",
        "link_suffix": "/forum?id=ZxQD6oYIOm",
        "link": "https://openreview.net/forum?id=ZxQD6oYIOm",
        "pdf_link": "https://openreview.net/pdf?id=ZxQD6oYIOm",
        "keywords": "recipe transformation, ingredient embeddings, ingredient replacement, cuisine embeddings, Word2Vec, BERT, SBERT, Doc2Vec, computational gastronomy",
        "abstract": "Every cuisine has a culinary fingerprint characterized by its idiosyncratic ingredient composition. Transforming the culinary signature of a recipe is a creative endeavor. Traditionally, such fusion recipes have arisen from creative human interventions as a product of trial and error. Herein, we present a framework to transform the culinary signature of a recipe from one regional cuisine to another. A clustering-based computational strategy was developed, which replaces the ingredients of a recipe, one at a time, to achieve the transformation of the cuisine. We used a neural network-based Word2Vec-Doc2Vec model and three encoder-based BERT models to capture the context of an ingredient within the culinary landscape. The performance of recipe transformation strategies was evaluated by scoring their success at \u2018Recipe Transformation\u2019 and manually assessing the most frequent ingredient replacements for every fusion experiment. We observe that the encoder-based models perform better at transforming recipes with fewer ingredient replacements needed, suggesting that BERT-based models are better at providing more meaningful ingredient replacements to transform the culinary signature of recipes. The percentage of successful recipe transformations in the case of Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 99.95%, 43.1%, 41.65%, and 41.45% respectively, indicating that the neural network-based model can better cluster the cuisine-wise ingredient embeddings. On the other hand, for a successful recipe transformation, the average percentage of ingredients replaced for Word2Vec-Doc2Vec, BERT-Mean Pooling, BERT-CLS Pooling, and BERT-SBERT model are 77%, 52.3%, 51.6% and 51.5%, respectively. Our study shows a way forward for implementing cross-cultural fusion of recipes."
    },
    {
        "title": "Neuron-based Multifractal Analysis of Neuron Interaction Dynamics in Large Models",
        "link_suffix": "/forum?id=nt8gBX58Kh",
        "link": "https://openreview.net/forum?id=nt8gBX58Kh",
        "pdf_link": "https://openreview.net/pdf?id=nt8gBX58Kh",
        "keywords": "Emergent ability; Large language model",
        "abstract": "In recent years, there has been increasing attention on the capabilities of large models, particularly in handling complex tasks that small-scale models are unable to perform. Notably, large language models (LLMs) have demonstrated ``intelligent'' abilities such as complex reasoning and abstract language comprehension, reflecting cognitive-like behaviors. However, current research  on emergent abilities in large models predominantly focuses on the relationship between model performance and size, leaving a significant gap in the systematic quantitative analysis of the internal structures and mechanisms driving these emergent abilities. Drawing inspiration from neuroscience research on brain network structure and self-organization, we propose (i) a general network representation of large models, (ii) a new analytical framework \u2014Neuron-based Multifractal Analysis (NeuroMFA)- for structural analysis, and (iii) a novel structure-based metric for evaluating the degree of emergence in large models. By linking structural features to the capabilities of large models, NeuroMFA provides a quantitative framework for analyzing emergent phenomena in large models. Our experiments show that the proposed method yields a comprehensive measure of network's evolving heterogeneity and organization, offering theoretical foundations and new perspective for investigating emergence in large models."
    },
    {
        "title": "Emergence of Hierarchical Emotion Representations in Large Language Models",
        "link_suffix": "/forum?id=wTm4W39GdD",
        "link": "https://openreview.net/forum?id=wTm4W39GdD",
        "pdf_link": "https://openreview.net/pdf?id=wTm4W39GdD",
        "keywords": "LLM, emotion",
        "abstract": "As large language models (LLMs) increasingly power emotionally engaging conversational agents, understanding how they represent, predict, and potentially influence human emotions is critical for their ethical deployment in sensitive contexts. In this work, we reveal emergent hierarchical structures in LLMs' emotion representations, drawing inspiration from psychological theories of emotion. By analyzing probabilistic dependencies between emotional states in LLM outputs, we propose a method for extracting these hierarchies. Our results show that larger models, such as LLaMA 3.1 (405B parameters), develop more intricate emotion hierarchies, resembling human emotional differentiation from broad categories to finer states. Moreover, we find that stronger emotional modeling enhances persuasive abilities in synthetic negotiation tasks, with LLMs that more accurately predict counterparts' emotions achieving better outcomes. Additionally, we explore the effects of persona biases\u2014such as gender and socioeconomic status\u2014on emotion recognition, revealing that LLMs can misclassify emotions when processing minority personas, thus exposing underlying biases. This study contributes to both the scientific understanding of how LLMs represent emotions and the ethical challenges they pose, proposing a novel interdisciplinary perspective on the issue."
    },
    {
        "title": "Collaborative Theorem Proving with Large Language Models: Enhancing Formal Proofs with ProofRefiner",
        "link_suffix": "/forum?id=y9xNQZjUJM",
        "link": "https://openreview.net/forum?id=y9xNQZjUJM",
        "pdf_link": "https://openreview.net/pdf?id=y9xNQZjUJM",
        "keywords": "Agent-base System, Reasoning",
        "abstract": "Abstract\uff1a Theorem proving presents a significant challenge for large language models (LLMs) because formal proofs can be rigorously verified by proof assistants like Lean, leaving no room for errors. Existing LLM-based provers typically operate autonomously, but they often struggle with complex and novel theorems where human insights are crucial. We propose a new framework that positions LLMs as collaborative assistants in theorem proving to address this. This framework enables the seamless integration of LLM inference into the Lean environment, allowing developers to build various proof automation tools. These tools offer features such as suggesting proof steps, completing intermediate goals, and selecting relevant premises, thereby enhancing the theorem-proving process. Users can leverage our pretrained models or integrate their own, supporting local and cloud-based execution. Experimental results demonstrate that our approach is more effective in aiding humans and automating the theorem-proving process than existing rule-based systems. Additionally, we introduce a system called ProofRefiner, which refines questions and answers through dynamic dialogue adjustments to ensure relevance and precision."
    },
    {
        "title": "TLXML: Task-Level Explanation of Meta-Learning via Influence Functions",
        "link_suffix": "/forum?id=NYf2XIXUi3",
        "link": "https://openreview.net/forum?id=NYf2XIXUi3",
        "pdf_link": "https://openreview.net/pdf?id=NYf2XIXUi3",
        "keywords": "meta-learning, XAI, explainability, influence function, hessian approximation",
        "abstract": "The scheme of adaptation via meta-learning is seen as an ingredient for solving the problem of data shortage or distribution shift in real-world applications, but it also brings the new risk of inappropriate updates of the model in the user environment, which increases the demand for explainability. Among the various types of XAI methods, establishing a method of explanation based on past experience in meta-learning requires special consideration due to its bi-level structure of training, which has been left unexplored. In this work, we propose influence functions for explaining meta-learning that measure the sensitivities of training tasks to adaptation and inference. We also argue that the approximation of the Hessian using the Gauss-Newton matrix resolves computational barriers peculiar to meta-learning. We demonstrate the adequacy of the method through experiments on task distinction and task distribution distinction using image classification tasks with MAML and Prototypical Network."
    }
]
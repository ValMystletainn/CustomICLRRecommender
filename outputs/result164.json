[{"title": "Towards Understanding Token Selection in Self-Attention: Successes and Pitfalls in Learning Random Walks", "link_suffix": "/forum?id=9ngFxN83j2", "link": "https://openreview.net/forum?id=9ngFxN83j2", "pdf_link": "https://openreview.net/pdf?id=9ngFxN83j2", "keywords": "self-attention, token selection", "abstract": "As a key component of the transformer architecture, the self-attention mechanism is known for its capability to perform token selection, which can often significantly enhance model performance. However, when and how self-attention can be trained to perform effective token selection remains poorly understood in theory. In this paper, we study the problem of using a single self-attention layer to learn random walks on circles. We theoretically demonstrate that, after training with gradient descent, the self-attention layer can successfully learn the Markov property of the random walk, and achieve optimal next-token prediction accuracy by focusing on the correct parent token. In addition, we also study the performance of a single self-attention layer in learning relatively simpler \"deterministic walks\" \non circles. Surprisingly, in this case, our findings indicate that the self-attention model trained with gradient descent consistently yields next-token prediction accuracy no better than a random guess. This counter-intuitive observation that self-attention can learn random walks but struggles with deterministic walks reveals a potential issue in self-attention: when there are multiple highly informative tokens, self-attention may fail to properly utilize any of them.", "title_embedding_index": 8150, "title_abs_embedding_index": 8175}, {"title": "Looks Great, Functions Better: Physics Compliance Text-to-3D Shape Generation", "link_suffix": "/forum?id=6SMeOas0JX", "link": "https://openreview.net/forum?id=6SMeOas0JX", "pdf_link": "https://openreview.net/pdf?id=6SMeOas0JX", "keywords": "3D shape generation, Functional 3D model, Physics perception, Differentiable physics layer, Solid mechanics", "abstract": "Text-to-3D shape generation has shown great promise in generating novel 3D content based on given text prompts. However, existing generative methods mostly focus on geometric or visual plausibility while ignoring function for the generated 3D shapes. This greatly hinders the practicality of generated 3D shapes in real-world applications. In this work, we propose Fun3D, a physics driven functional text-to-3D shape generation method. By analyzing the solid mechanics of generated 3D shapes, we reveal that the 3D shapes generated by existing text-to-3D generation methods are impractical for real-world applications as the generated 3D shapes do not conform to the laws of physics. To this end, we leverage 3D diffusion models to provide 3D shape priors and design a data-driven differentiable physics layer to optimize 3D shape priors with solid mechanics. This allows us to optimize geometry efficiently and learn physics information about 3D shapes at the same time. Experimental results demonstrate that our method can consider both geometric plausibility and functional requirement, further bridging 3D virtual modeling and physical worlds.", "title_embedding_index": 8151, "title_abs_embedding_index": 8176}, {"title": "A Unified Framework for Speculative Decoding with Multiple Drafters as a Bandit", "link_suffix": "/forum?id=5haYLrlyGj", "link": "https://openreview.net/forum?id=5haYLrlyGj", "pdf_link": "https://openreview.net/pdf?id=5haYLrlyGj", "keywords": "Speculative decoding, multi-armed bandit, large language model", "abstract": "Speculative decoding (SD) has emerged as a promising approach to accelerate inference in large language models (LLMs). This method drafts potential future tokens by leveraging a smaller model, while these tokens are concurrently verified by the target LLM, ensuring only outputs aligned with the target LLM\u2019s predictions are accepted. However, the inherent limitations of individual drafters, especially when trained on specific tasks or domains, can hinder their effectiveness across diverse applications. In this paper, we introduce a simple yet efficient unified framework, termed MetaSD, that incorporates multiple drafters into the speculative decoding process to address this limitation. Our approach employs multi-armed bandit sampling to dynamically allocate computational resources across various drafters, thereby improving overall generation performance. Through extensive experiments, we demonstrate that our unified framework achieves superior results compared to traditional single-drafter approaches.", "title_embedding_index": 8152, "title_abs_embedding_index": 8177}, {"title": "Lipschitz Bandits in Optimal Space", "link_suffix": "/forum?id=i7k2sXSW1b", "link": "https://openreview.net/forum?id=i7k2sXSW1b", "pdf_link": "https://openreview.net/pdf?id=i7k2sXSW1b", "keywords": "Space complexity, Lipschitz bandits", "abstract": "This paper considers the Lipschitz bandit problem, where the set of arms is continuous and the expected reward is a Lipschitz function over the arm space. This problem has been extensively studied. Prior algorithms need to store the reward information of all visited arms, leading to significant memory consumption. We address this issue by introducing an algorithm named Log-space Lipschitz bandits (Log-Li), which achieves an optimal (up to logarithmic factors) regret of $\\widetilde{O}\\left(T^{\\frac{d_z+1}{d_z+2}}\\right)$ while only uses $O\\left(\\log T\\right)$ bits of memory. Additionally, we provide a complexity analysis for this problem, demonstrating that $\\Omega\\left(\\log T\\right)$ bits of space are necessary for any algorithm to achieve the optimal regret. We also conduct numerical simulations, and the results show that our new algorithm achieves regret comparable to the state-of-the-art while reducing memory usage by orders of magnitude.", "title_embedding_index": 8153, "title_abs_embedding_index": 8178}, {"title": "Fast and Slow Streams for Online Time Series Forecasting Without Information Leakage", "link_suffix": "/forum?id=I0n3EyogMi", "link": "https://openreview.net/forum?id=I0n3EyogMi", "pdf_link": "https://openreview.net/pdf?id=I0n3EyogMi", "keywords": "online time series forecasting, concept drift, online learning", "abstract": "Current research in online time series forecasting suffers from information leakage: models predict and then evaluate on historical time steps that have been backpropagated for parameter updates. This setting also misaligns with the real-world conception of forecasting, which typically emphasizes looking ahead and anticipating future uncertainties. This paper redefines online time series forecasting to focus on predicting unknown future steps and evaluates performance solely based on these predictions. Following this new setting, challenges arise in leveraging incomplete pairs of ground truth and prediction for backpropagation, as well as generalizing accurate information without overfitting to noises from recent data streams. To address these challenges, we propose a novel dual-stream framework for online forecasting (DSOF): a slow stream that updates with complete data using experience replay, and a fast stream that adapts to recent data through temporal difference learning. This dual-stream approach updates a teacher-student model learned through a residual learning strategy, generating predictions in a coarse-to-fine manner. Extensive experiments demonstrate its improvement in forecasting performance in changing environments.", "title_embedding_index": 8154, "title_abs_embedding_index": 8179}, {"title": "Jogging the Memory of Unlearned LLMs Through Targeted Relearning Attacks", "link_suffix": "/forum?id=fMNRYBvcQN", "link": "https://openreview.net/forum?id=fMNRYBvcQN", "pdf_link": "https://openreview.net/pdf?id=fMNRYBvcQN", "keywords": "Machine Unlearning, Large Language Model", "abstract": "Machine unlearning is a promising approach to mitigate undesirable memorization of training data in ML models. However, in this work we show that existing approaches for unlearning in LLMs are surprisingly susceptible to a simple set oftargeted relearning attacks. With access to only a small and potentially loosely related set of data, we find that we can \u2018jog\u2019 the memory of unlearned models to reverse the effects of unlearning. For example, we show that relearning on public medical articles can lead an unlearned LLM to output harmful knowledge about bioweapons, and relearning general wiki information about the book series Harry Potter can force the model to output verbatim memorized text. We formalize this unlearning-relearning pipeline, explore the attack across three popular unlearning benchmarks, and discuss future directions and guidelines that result from our study.", "title_embedding_index": 8155, "title_abs_embedding_index": 8180}, {"title": "SCHEME: Scalable Channel Mixer for Vision Transformers", "link_suffix": "/forum?id=U4ekUAOLsM", "link": "https://openreview.net/forum?id=U4ekUAOLsM", "pdf_link": "https://openreview.net/pdf?id=U4ekUAOLsM", "keywords": "Vision Transformers, Channel Mixer, Efficient, Scalable, Attention", "abstract": "Vision Transformers have received significant attention due to their impressive performance in many vision tasks. While the token mixer or attention block has been studied in great detail, the channel mixer or feature mixing block (FFN or MLP) has not been explored in depth albeit it accounts for a bulk of the parameters and computation in a model. In this work, we study whether sparse feature mixing can replace the dense connections and confirm this with a block diagonal MLP structure that improves the accuracy by supporting larger expansion ratios. To improve the feature clusters formed by this structure and thereby further improve the accuracy, a lightweight, parameter-free, channel covariance attention (CCA) mechanism is introduced as a parallel branch during training. This design of CCA enables gradual feature mixing across channel groups during training whose contribution decays to zero as the training progresses to convergence. This allows the CCA block to be discarded during inference, thus enabling enhanced performance with no additional computational cost. The resulting $\\textit{Scalable CHannEl MixEr}$ (SCHEME) can be plugged into any ViT architecture to obtain a gamut of models with different trade-offs between complexity and performance by controlling the block diagonal structure size in the MLP. This is shown by the introduction of a new family of SCHEMEformer models. Experiments on image classification, object detection, and semantic segmentation, with different ViT backbones, consistently demonstrate substantial accuracy gains over existing designs, especially under lower FLOPs regimes. The SCHEMEformer family is shown to establish new Pareto frontiers for accuracy vs FLOPS, accuracy vs model size, and accuracy vs throughput, especially for fast transformers of small model size.", "title_embedding_index": 8156, "title_abs_embedding_index": 8181}, {"title": "Differentiation and Specialization of Attention Heads via the Refined Local Learning Coefficient", "link_suffix": "/forum?id=SUc1UOWndp", "link": "https://openreview.net/forum?id=SUc1UOWndp", "pdf_link": "https://openreview.net/pdf?id=SUc1UOWndp", "keywords": "Developmental Interpretability, Mechanistic Interpretability, Singular Learning Theory, Learning Dynamics, Stagewise development, Model complexity", "abstract": "We introduce refined variants of the Local Learning Coefficient (LLC), a measure of model complexity grounded in singular learning theory, to study the development of internal structure in transformer language models during training. By applying these refined LLCs (rLLCs) to individual components of a two-layer attention-only transformer, we gain novel insights into the progressive differentiation and specialization of attention heads. Our methodology reveals how attention heads differentiate into distinct functional roles over the course of training, analyzes the types of data these heads specialize to process, and discovers a previously unidentified multigram circuit. These findings demonstrate that rLLCs provide a principled, quantitative toolkit for developmental interpretability, which aims to understand models through their evolution across the learning process. This work advances the field of developmental interpretability by providing a mathematically rigorous approach to understanding neural networks through the lens of their learning process. More broadly, this work takes a step towards establishing the correspondence between data distributional structure, geometric properties of the loss landscape, learning dynamics, and emergent computational structures in neural networks.", "title_embedding_index": 8157, "title_abs_embedding_index": 8182}, {"title": "Federated Learning for Time-Series Healthcare Sensing with Incomplete Modalities", "link_suffix": "/forum?id=qezVbskHmi", "link": "https://openreview.net/forum?id=qezVbskHmi", "pdf_link": "https://openreview.net/pdf?id=qezVbskHmi", "keywords": "federated learning, incomplete modalities, time-series healthcare sensing", "abstract": "Many healthcare sensing applications utilize multimodal time-series data from sensors embedded in mobile and wearable devices. Federated Learning (FL), with its privacy-preserving advantages, is particularly well-suited to such applications. However, most multimodal FL methods assume the availability of complete modality data for local training, which is often unrealistic. Moreover, recent approaches for tackling incomplete modalities scale poorly and become inefficient as the number of modalities increases. To address these limitations, we propose FLISM, an innovative algorithm that enables efficient FL training with incomplete sensing modalities while maintaining high accuracy. FLISM employs three key techniques: (1) modality-invariant representation learning to extract effective features from clients with a diverse set of modalities, (2) modality quality-aware aggregation to prioritize contributions from clients with higher-quality data, and (3) global-aligned knowledge distillation to mitigate local update shifts caused by modality differences. Extensive experiments on real-world datasets show that FLISM not only achieves high accuracy but is also faster and more efficient compared to state-of-the-art methods designed to handle incomplete modality problems in FL.", "title_embedding_index": 8158, "title_abs_embedding_index": 8183}, {"title": "ToVE: Efficient Vision-Language Learning via Knowledge Transfer from Vision Experts", "link_suffix": "/forum?id=EMMnAd3apQ", "link": "https://openreview.net/forum?id=EMMnAd3apQ", "pdf_link": "https://openreview.net/pdf?id=EMMnAd3apQ", "keywords": "Vision-language Modeling, Knowledge Transfer, Vision Experts", "abstract": "Vision-language (VL) learning requires extensive visual perception capabilities, such as fine-grained object recognition and spatial perception. Recent works typically rely on training huge models on massive datasets to develop these capabilities. As a more efficient alternative, this paper proposes a new framework that Transfers the knowledge from a hub of Vision Experts (ToVE) for efficient VL learning, leveraging pre-trained vision expert models to promote visual perception capability. Specifically, building on a frozen CLIP image encoder that provides vision tokens for image-conditioned language generation, ToVE introduces a hub of multiple vision experts and a token-aware gating network that dynamically routes expert knowledge to vision tokens. In the transfer phase, we propose a \"residual knowledge transfer\" strategy, which not only preserves the generalizability of the vision tokens but also allows selective detachment of low-contributing experts to improve inference efficiency. Further, we explore to merge these expert knowledge to a single CLIP encoder, creating a knowledge-merged CLIP that produces more informative vision tokens without expert inference during deployment. Experiment results across various VL tasks demonstrate that the proposed ToVE achieves competitive performance with two orders of magnitude fewer training data.", "title_embedding_index": 8159, "title_abs_embedding_index": 8184}, {"title": "SaMer: A Scenario-aware Multi-dimensional Evaluator for Large Language Models", "link_suffix": "/forum?id=aBnVU5DL3I", "link": "https://openreview.net/forum?id=aBnVU5DL3I", "pdf_link": "https://openreview.net/pdf?id=aBnVU5DL3I", "keywords": "Fine-grained Evaluation, Adaptive Multi-dimensional Evaluator, Large Language Models", "abstract": "Evaluating the response quality of large language models (LLMs) for open-ended questions poses a significant challenge, especially given the subjectivity and multi-dimensionality of \"quality\" in natural language generation. Existing LLM evaluators often neglect that different scenarios require distinct evaluation criteria. In this work, we proposeSaMer, a scenario-aware multi-dimensional evaluator designed to provide both overall and fine-grained assessments of LLM-generated responses. Unlike fixed-dimension evaluation approaches, SaMer adapts to different scenarios by automatically identifying and prioritizing relevant evaluation dimensions tailored to the given query. To achieve this, we construct a large-scale fine-grained preference dataset spanning multiple real-world scenarios, each with distinct evaluation dimensions. We then leverage a text embedding model combined with three specialized heads to predict the appropriate evaluation dimensions and corresponding scores, as well as the respective weights that contribute to the overall score. The resulting model offers fine-grained and interpretable evaluations and shows robust adaptability across diverse scenarios. Extensive experiments on eight single rating and pairwise comparison datasets demonstrate that SaMer outperforms existing baselines in a variety of evaluation tasks, showcasing its robustness, versatility, and generalizability.", "title_embedding_index": 8160, "title_abs_embedding_index": 8185}, {"title": "Putnam-AXIOM: A Functional & Static Benchmark for Measuring Higher Level Mathematical Reasoning in LLMs", "link_suffix": "/forum?id=WrBqgoseGL", "link": "https://openreview.net/forum?id=WrBqgoseGL", "pdf_link": "https://openreview.net/pdf?id=WrBqgoseGL", "keywords": "Benchmarks, Large Language Models, Mathematical Reasoning, Mathematics, Reasoning, Machine Learning", "abstract": "As large language models (LLMs) continue to advance, many existing benchmarks designed to evaluate their reasoning capabilities are becoming saturated. Therefore, we present the Putnam-AXIOM Original benchmark consisting of 236 mathematical problems from the William Lowell Putnam Mathematical Competition, along with detailed step-by-step solutions. To preserve the Putnam-AXIOM benchmark's validity and mitigate potential data contamination, we created the Putnam-AXIOM Variation benchmark with functional variations of 52 problems. By programmatically altering problem elements like variables and constants, we can generate unlimited novel, equally challenging problems not found online. We see that almost all models have significantly lower accuracy in the variations than the original problems. Our results reveal that OpenAI's o1-preview, the best performing model, achieves merely 41.95% accuracy on the Putnam-AXIOM Original but experiences around a 30% reduction in accuracy on the variations' dataset when compared to corresponding original problems. Moreover, we explore metrics beyond boxed accuracy to assess models on complex tasks like natural language theorem proving, crucial for evaluating reasoning capabilities  in depth, opening the possibility for open-ended evaluation of reasoning strings.", "title_embedding_index": 8161, "title_abs_embedding_index": 8186}, {"title": "Towards Hierarchical Rectified Flow", "link_suffix": "/forum?id=6F6qwdycgJ", "link": "https://openreview.net/forum?id=6F6qwdycgJ", "pdf_link": "https://openreview.net/pdf?id=6F6qwdycgJ", "keywords": "Generative Model, Flow Matching, Rectified Flow", "abstract": "We formulate a hierarchical rectified flow to model data distributions. It hierarchically couples multiple ordinary differential equations (ODEs) and defines a time-differentiable stochastic process that generates a data distribution from a known source distribution. Each ODE resembles the ODE that is solved in a classic rectified flow, but differs in its domain, i.e., location, velocity, acceleration, etc. Unlike the classic rectified flow formulation, which formulates a single ODE in the location domain and only captures the expected velocity field (sufficient to capture a multi-modal data distribution), the hierarchical rectified flow formulation models the multi-modal random velocity field, acceleration field, etc., in their entirety. This more faithful modeling of the random velocity field enables integration paths to intersect when the underlying ODE is solved during data generation. Intersecting paths in turn lead to integration trajectories that are more straight than those obtained in the classic rectified flow formulation, where integration paths cannot intersect. This leads to modeling of data distributions with fewer neural function evaluations. We empirically verify this on synthetic 1D and 2D data as well as MNIST and CIFAR10 data. We will release our code.", "title_embedding_index": 8162, "title_abs_embedding_index": 8187}, {"title": "FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources", "link_suffix": "/forum?id=FbQLFsBbTe", "link": "https://openreview.net/forum?id=FbQLFsBbTe", "pdf_link": "https://openreview.net/pdf?id=FbQLFsBbTe", "keywords": "Multimodal Learning, Contrastive Learning", "abstract": "Existing studies of training state-of-the-art Contrastive Language-Image Pretraining (CLIP) models on large-scale data involve hundreds of or even thousands of GPUs due to the requirement of a large batch size. However, such a large amount of resources is not accessible to most people. While advanced compositional optimization techniques for optimizing global contrastive losses have been demonstrated effective for removing the requirement of a large batch size, their performance on large-scale data remains underexplored and not optimized. To bridge the gap, this paper explores several aspects of CLIP training with \\textit{limited resources} (e.g., up to tens of GPUs). First, we introduce FastCLIP, a general CLIP training framework built on advanced compositional optimization techniques while designed and optimized for the {\\bf distributed setting}. Our framework is equipped with an efficient gradient reduction strategy to reduce communication overhead. Second, to further boost training efficiency, we investigate three components of the framework from an optimization perspective: the schedule of the inner learning rate, the update rules of the temperature parameter and the model parameters, respectively. Experiments on different strategies for each component shed light on how to conduct CLIP training more efficiently. Finally, we evaluate the performance of FastCLIP and the state-of-the-art training baseline (OpenCLIP) on different compute scales up to 32 GPUs on 8 nodes, and three data scales ranging from 2.7 million, 9.1 million to 315 million image-text pairs to demonstrate the significant improvement of FastCLIP in the resource-limited setting.", "title_embedding_index": 8163, "title_abs_embedding_index": 8188}, {"title": "Relaxing Representation Alignment with Knowledge Preservation for Multi-Modal Continual Learning", "link_suffix": "/forum?id=CagdoUkvvl", "link": "https://openreview.net/forum?id=CagdoUkvvl", "pdf_link": "https://openreview.net/pdf?id=CagdoUkvvl", "keywords": "Continual learning, Multi-modal", "abstract": "In continual learning, developing robust representations that adapt to new distributions or classes while retaining prior knowledge is crucial. While most traditional approaches focus on single-modality data, multi-modal learning offers significant advantages by leveraging diverse sensory inputs, akin to human perception. However, transitioning to multi-modal continual learning introduces additional challenges as the model needs to effectively combine new information from different modalities while avoiding catastrophic forgetting. In this work, we propose a relaxed cross-modality representation alignment loss and utilize a dual-learner framework to preserve the relation between previously learned representations. We validate our framework using several multi-modal datasets that  encompass various types of input modalities. Results show that we consistently outperform baseline continual learning methods in both class incremental and domain incremental learning scenarios. Further analysis highlights the effectiveness of our solution in preserving prior knowledge while incorporating new information.", "title_embedding_index": 8164, "title_abs_embedding_index": 8189}, {"title": "Representing Part-Whole Hierarchy with Nested Neuronal Coherence", "link_suffix": "/forum?id=AFVofardeb", "link": "https://openreview.net/forum?id=AFVofardeb", "pdf_link": "https://openreview.net/pdf?id=AFVofardeb", "keywords": "Part-Whole Relationship, Neural Syntax, Cell Assembly, Nested Oscillation, Neuronal Coherence, Object-Centric Representation, Binding Problem, Hierarchical Grouping, Structured Representation Learning, Spiking Neural Network, Visual Perception, Cortical Computation, Cortical Column, Attractor Network, NeuroAI, Hybrid Approach", "abstract": "Human vision flexibly extracts part-whole hierarchy from visual scenes. However, representing such hierarchical structure is a key challenge for neural networks. Most machine learning efforts addressing this issue have focused on slot-based methods, which may be limiting due to their discrete nature and difficulty to express uncertainty. Inspired by how neural syntax is organized in the brain, this paper presents a framework to represent the hierarchical part-whole relationship through hierarchically nested neuronal coherence, which has a continuous and distributed nature. At implementation level, we further developed a cortical-inspired hybrid model, the Composer, which dynamically achieves the emergent nestedness given images. To evaluate the emergent hierarchical structure, 4 synthetic datasets and 3 quantitative metrics are invented, which showed its ability to parse a range of scenes of different complexities. We believe this work, from representation, implementation to evaluation, advances a new paradigm for developing human-like vision in neural network models.", "title_embedding_index": 8165, "title_abs_embedding_index": 8190}, {"title": "A Theoretical Framework for Partially-Observed Reward States in RLHF", "link_suffix": "/forum?id=OjAU0LLDbe", "link": "https://openreview.net/forum?id=OjAU0LLDbe", "pdf_link": "https://openreview.net/pdf?id=OjAU0LLDbe", "keywords": "reinforcement learning, learning theory, reinforcement learning theory, reinforcement learning from human feedback, eluder dimension, partial observability", "abstract": "The growing deployment of reinforcement learning from human feedback (RLHF) calls for a deeper theoretical investigation of its underlying models. The prevalent models of RLHF do not account for neuroscience-backed, partially-observed \"internal states'' that can affect human feedback, nor do they accommodate intermediate feedback during an interaction. Both of these can be instrumental in speeding up learning and improving alignment. To address these limitations, we model RLHF as reinforcement learning with partially observed reward-states (PORRL). We accommodate two kinds of feedback \u2014 cardinal and dueling feedback. We first demonstrate that PORRL subsumes a wide class of RL problems, including traditional RL, RLHF, and reward machines. For cardinal feedback, we present two model-based methods (POR-UCRL, POR-UCBVI). We give both cardinal regret and sample complexity guarantees for the methods, showing that they improve over naive history-summarization. We then discuss the benefits of a model-free method like GOLF with naive history-summarization in settings with recursive internal states and dense intermediate feedback. For this purpose, we define a new history aware version of the Bellman-eluder dimension and give a new guarantee for GOLF in our setting, which can be exponentially sharper in illustrative examples. For dueling feedback, we show that a naive reduction to cardinal feedback fails to achieve sublinear dueling regret. We then present the first explicit reduction that converts guarantees for cardinal regret to dueling regret. In both feedback settings, we show that our models and guarantees generalize and extend existing ones.", "title_embedding_index": 8166, "title_abs_embedding_index": 8191}, {"title": "A Novel Kernel Sparse Coding Method with A Two-stage Acceleration Strategy", "link_suffix": "/forum?id=U2s5hBE1I9", "link": "https://openreview.net/forum?id=U2s5hBE1I9", "pdf_link": "https://openreview.net/pdf?id=U2s5hBE1I9", "keywords": "Sparse Coding, Kernel Trick, Acceleration Strategy", "abstract": "Sparse coding aims to exploit the latent linear structure of the input data, transforming dense data into sparse data, thereby improving data processing efficiency. However, many real-word signals cannot be expressed linearly, rendering the traditional sparse coding algorithms ineffective. One potential solution is to expand the dimensions of data. In this paper, we verify that the feature mapping of Radial Basis Function (RBF) kernel contains infinite dimensional information, and it does not significantly increase the computational complexity. Based on this, we propose to explore the $l_1$-norm regularization sparse coding method with RBF kernel, and provides a solution with convergence guarantees by leveraging the principle of coordinate descent. Additionally, to accelerate the optimization process, we introduce a novel two-stage acceleration strategy, based on theoretical analysis and empirical observations. Experimental results demonstrate that the two-stage acceleration strategy can reduce processing time by up to 90%. Furthermore, when the data size is compressed to about 2% of its original scale, the NMAE metric of the proposed method reaches as low as 0.0824 to 0.2195, achieving a significant improvement of up to 47% compared to traditional linear sparse coding methods and 36% compared to other kernel sparse coding techniques.", "title_embedding_index": 8167, "title_abs_embedding_index": 8192}, {"title": "BeST - A Novel Source Selection Metric for Transfer Learning", "link_suffix": "/forum?id=rkc79rOJu8", "link": "https://openreview.net/forum?id=rkc79rOJu8", "pdf_link": "https://openreview.net/pdf?id=rkc79rOJu8", "keywords": "Transfer Learning, Pretrained Model Selection, Task-Similarity Metric", "abstract": "One of the most fundamental, and yet relatively less explored, goals in transfer learning is the efficient means of selecting top candidates from a large number of previously trained models (optimized for various \"source\" tasks) that would perform the best for a new \"target\" task with a limited amount of data. In this paper, we undertake this goal by developing a novel task-similarity metric (BeST) and an associated method that consistently performs well in identifying the most transferrable source(s) for a given task. In particular, our design employs an innovative quantization-level optimization procedure in the context of classification tasks that yields a measure of similarity between a source model and the given target data. The procedure uses a concept similar to early stopping (usually implemented to train deep neural networks (DNNs) to ensure generalization) to derive a function that approximates the transfer learning mapping without training. The advantage of our metric is that it can be quickly computed to identify the top candidate(s) for a given target task before a computationally intensive transfer operation (typically using DNNs) can be implemented between the selected source and the target task. As such, our metric can provide significant computational savings for transfer learning from a selection of a large number of possible source models. Through extensive experimental evaluations, we establish that our metric performs well over different datasets and varying numbers of data samples.", "title_embedding_index": 8168, "title_abs_embedding_index": 8193}, {"title": "KEYPOINT-GUIDED 4D GAUSSIAN SPLATTING WITH DECOUPLED SPATIO-TEMPORAL FLOW REFINEMENT", "link_suffix": "/forum?id=wKOoWTBMZe", "link": "https://openreview.net/forum?id=wKOoWTBMZe", "pdf_link": "https://openreview.net/pdf?id=wKOoWTBMZe", "keywords": "Keypoint, 4D Gaussian Splatting", "abstract": "We propose KG4D, a novel method for generating time-aware 4D representations\nfrom a single static image or video. Previous methods largely rely on weak su-\npervision signals, failing to introduce fine-grained supervision necessary for cap-\nturing detailed spatio-temporal dynamics. In contrast, our approach employs Har-\nmonic Spatio-temporal Encoding (HSE) to achieve efficient spatio-temporal sep-\naration during training, allowing the model to represent dynamic scene changes\nmore accurately. Furthermore, Keypoint Feature Calibration (KFC) ensures pre-\ncise pose consistency, and Wasserstein Gradient Flow (WGF) enhances motion\ncoherence, effectively reducing artifacts. Comprehensive evaluation and ablations\ndemonstrate that our proposed KG4D outperforms existing state-of-the-art meth-\nods on various benchmarks in dynamic 4D generation and novel viewpoint syn-\nthesis, validating its effectiveness and superior generation capability.", "title_embedding_index": 8169, "title_abs_embedding_index": 8194}, {"title": "CONTRA: Conformal Prediction Region via Normalizing Flow Transformation", "link_suffix": "/forum?id=pOO9cqLq7Q", "link": "https://openreview.net/forum?id=pOO9cqLq7Q", "pdf_link": "https://openreview.net/pdf?id=pOO9cqLq7Q", "keywords": "Uncertainty Quantification, Conditional Density Estimation, Conformalized Quantile Regression, Coverage Probability, Multi-dimensional Prediction", "abstract": "Density estimation and reliable prediction regions for outputs are crucial in supervised and unsupervised learning. While conformal prediction effectively generates coverage-guaranteed regions, it struggles with multi-dimensional outputs due to reliance on one-dimensional nonconformity scores. To address this, we introduce CONTRA: CONformal prediction region via normalizing flow TRAnsformation. CONTRA utilizes the latent spaces of normalizing flows to define nonconformity scores based on distances from the center. This allows for the mapping of high-density regions in latent space to sharp prediction regions in the output space, surpassing traditional hyperrectangular or elliptical conformal regions. Further, for scenarios where other predictive models are favored over flow-based models, we extend CONTRA to enhance any such model with a reliable prediction region by training a simple normalizing flow on the residuals. We demonstrate that both CONTRA and its extension maintain guaranteed coverage probability and outperform existing methods in generating accurate prediction regions across various datasets. We conclude that CONTRA is an effective tool for (conditional) density estimation, addressing the under-explored challenge of delivering multi-dimensional prediction regions.", "title_embedding_index": 8170, "title_abs_embedding_index": 8195}, {"title": "LASP-2: Rethinking Sequence Parallelism for Linear Attention and its Hybrid", "link_suffix": "/forum?id=c6TDOPEQ0e", "link": "https://openreview.net/forum?id=c6TDOPEQ0e", "pdf_link": "https://openreview.net/pdf?id=c6TDOPEQ0e", "keywords": "Sequence parallelism, Distributed Training", "abstract": "Linear sequence modeling approaches, such as linear attention, provide advantages like linear-time training and constant-memory inference over sequence lengths. However, existing sequence parallelism (SP) methods are either not optimized for their right-product-first feature or use ring-style communication as in LASP, which results in lower computation parallelism, limits their scalability for longer sequences in distributed systems. In this paper, we introduce LASP-2, a new SP approach designed to enhance both communication and computation efficiency in linear (attention) transformer models with very-long input sequences. Compared to LASP, LASP-2 rethinks the minimal communication requirement for SP on linear attention, reorganizes the whole communication-computation order of LASP. In this way, only one single all-gather collective communication is needed on intermediate memory states, whose sizes are independent of the sequence length, leading to significant improvements of both communication and computation parallelism, as well as their overlap. Additionally, we extend LASP-2 to LASP-2H by applying similar communication redesign to standard attention modules, offering an efficient SP solution for hybrid models that combine linear and standard attention layers. Our evaluation on a Linear-Llama3 model, a variant of Llama3 with linear attention replacing standard attention, demonstrates the effectiveness of LASP-2 and LASP-2H. Specifically, LASP-2 achieves throughput improvements of 15.2% over LASP and 36.6% over Ring Attention, with a sequence length of 2048K across 64 GPUs.", "title_embedding_index": 8171, "title_abs_embedding_index": 8196}, {"title": "Positional Attention: Out-of-Distribution Generalization and Expressivity for Neural Algorithmic Reasoning", "link_suffix": "/forum?id=NmFt9dIrSi", "link": "https://openreview.net/forum?id=NmFt9dIrSi", "pdf_link": "https://openreview.net/pdf?id=NmFt9dIrSi", "keywords": "Transformers; neural algorithmic reasoning; attention", "abstract": "There has been a growing interest in the ability of neural networks to solve algorithmic tasks, such as arithmetic, summary statistics, and sorting. While state-of-the-art models like Transformers have demonstrated good generalization performance on in-distribution tasks, their out-of-distribution (OOD) performance is poor when trained end-to-end. In this paper, we focus on value generalization, a common instance of OOD generalization where the test distribution has the same input sequence length as the training distribution, but the value ranges in the training and test distributions do not necessarily overlap. To address this issue, we propose that using fixed positional encodings to determine attention weights\u2014referred to as positional attention\u2014enhances empirical OOD performance while maintaining expressivity. We support our claim about expressivity by proving that Transformers with positional attention can effectively simulate parallel algorithms.", "title_embedding_index": 8172, "title_abs_embedding_index": 8197}, {"title": "Learn from the Past: Dynamic Data Pruning with Historically Weighted Bernoulli Sampling", "link_suffix": "/forum?id=ZQ9SF5eUHZ", "link": "https://openreview.net/forum?id=ZQ9SF5eUHZ", "pdf_link": "https://openreview.net/pdf?id=ZQ9SF5eUHZ", "keywords": "data selection, dynamic data pruning, importance sampling", "abstract": "Dynamic data pruning, which also known as data importance sampling, has been proposed to improve training efficiency. For the case of sampling with replacement, the optimal sampling distribution to minimize the variance is to sample proportional to the gradient norm, which can be approximated by the gradient norm of the logits from an extra forward pass. However, this could result in repeated samples, which can be an undesirable property. Noticing that most dynamic data pruning methods that avoids repeated samples can be seen as weighted Bernoulli sampling, in this work we study the optimal distribution to reduce its variance. Furthermore, to avoid an extra forward pass, we study the use of historic statistics. We propose the use of exponential moving average and probability smoothing to improve the performance.", "title_embedding_index": 8173, "title_abs_embedding_index": 8198}, {"title": "Noise Balance and Stationary Distribution of Stochastic Gradient Descent", "link_suffix": "/forum?id=eev4PHiMir", "link": "https://openreview.net/forum?id=eev4PHiMir", "pdf_link": "https://openreview.net/pdf?id=eev4PHiMir", "keywords": "stochastic gradient descent, stationary distribution, stochastic differential equation, phase transition", "abstract": "How the stochastic gradient descent (SGD) navigates the loss landscape of a neural network remains poorly understood. This work shows that the minibatch noise of SGD regularizes the solution towards a noise-balanced solution whenever the loss function contains a rescaling symmetry. We prove that when the rescaling symmetry exists, the SGD dynamics is limited to only a low-dimensional subspace and prefers a special set of solutions in an infinitely large degenerate manifold, which offers a partial explanation of the effectiveness of SGD in training neural networks. We then apply this result to derive the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width, which is the first analytical expression of the stationary distribution of SGD in a high-dimensional non-quadratic potential. The stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, loss of ergodicity, memory effects, and fluctuation inversion. These phenomena are shown to exist uniquely in deep networks, highlighting a fundamental difference between deep and shallow models. Lastly, we discuss the implication of the proposed theory for the practical problem of variational Bayesian inference.", "title_embedding_index": 8174, "title_abs_embedding_index": 8199}]
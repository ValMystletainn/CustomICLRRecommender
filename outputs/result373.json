[
    {
        "title": "GlobalMamba: Global Image Serialization for Vision Mamba",
        "link_suffix": "/forum?id=XKQ2qzajbU",
        "link": "https://openreview.net/forum?id=XKQ2qzajbU",
        "pdf_link": "https://openreview.net/pdf?id=XKQ2qzajbU",
        "keywords": "GlobalMamba, Representation Learning, Frequency Domain",
        "abstract": "Vision mambas have demonstrated strong performance with linear complexity to the number of vision tokens. Their efficiency results from processing image tokens sequentially. However, most existing methods employ patch-based image tokenization and then flatten them into 1D sequences for causal processing, which ignore the intrinsic 2D structural correlations of images. It is also difficult to extract global information by sequential processing of local patches. In this paper, we propose a global image serialization method to transform the image into a sequence of causal tokens, which contain global information of the 2D image. We first convert the image from the spatial domain to the frequency domain using Discrete Cosine Transform (DCT) and then arrange the pixels with corresponding frequency ranges. We further transform each set within the same frequency band back to the spatial domain to obtain a series of images before tokenization. We construct a vision mamba model with causal input format, GlobalMamba, based on the proposed global image serialization, which can better exploit the causal relations among image sequences. Extensive experiments demonstrate the effectiveness of our GlobalMamba, including image classification on ImageNet-1K, object detection on COCO, and semantic segmentation on ADE20K."
    },
    {
        "title": "PoI: Pixel of Interest for Novel View Synthesis Assisted Scene Coordinate Regression",
        "link_suffix": "/forum?id=j0YOeUZkjD",
        "link": "https://openreview.net/forum?id=j0YOeUZkjD",
        "pdf_link": "https://openreview.net/pdf?id=j0YOeUZkjD",
        "keywords": "visual localization, scene coordinate regresion, novel view synthesis",
        "abstract": "The task of estimating camera poses can be enhanced through novel view synthesis techniques such as NeRF and Gaussian Splatting to increase the diversity and extension of training data. However, these techniques often produce rendered images with issues like blurring and ghosting, which compromise their reliability. These issues become particularly pronounced for Scene Coordinate Regression (SCR) methods, which estimate 3D coordinates at the pixel level. To mitigate the problems associated with unreliable rendered images, we introduce a novel filtering approach, which selectively extracts well-rendered pixels while discarding the inferior ones. The threshold of this filter is adaptively determined by the real-time reprojection loss recorded by the SCR models during training. Building on this filtering technique, we also develop a new strategy to improve scene coordinate regression using sparse inputs, drawing on successful applications of sparse input techniques in novel view synthesis. Our experimental results validate the effectiveness of our method, demonstrating the state-of-the-art performance on both indoor and outdoor datasets."
    },
    {
        "title": "PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction",
        "link_suffix": "/forum?id=w3rbBVJ9Jg",
        "link": "https://openreview.net/forum?id=w3rbBVJ9Jg",
        "pdf_link": "https://openreview.net/pdf?id=w3rbBVJ9Jg",
        "keywords": "PDEs, physics encoding, data-driven modeling",
        "abstract": "Simulating spatiotemporal systems governed by partial differential equations is widely applied in biology, chemistry, aerospace dynamics and meteorology. The classical numerical methods require small time stepping to generate predictions, leading to high computational costs. Although machine learning has reduced computational costs, they are limited in terms of stability and accuracy for long-term predictions, especially in cases of insufficient data or varying time scales. They often overlook how to effectively utilize multi-scale data, leading to poor robustness of prediction. To this end, we propose a novel multi-scale framework, termed the Physics-Informed Multi-Scale Recurrent Learning (PIMRL) framework to proficiently harness temporal multi-scale data for spatiotemporal dynamics prediction. This framework consists of two modules: the micro-scale module embeds physical knowledge into neural networks through pretraining, while the macro-scale module employs a data-driven approach to learn the temporal evolution of physics in the latent space. The PIMRL framework consistently achieves state-of-the-art performance across five benchmark datasets ranging from one to three dimensions, demonstrating improvements of over 9% in both RMSE and MAE evaluation metrics, with maximum enhancements reaching up to 80%."
    },
    {
        "title": "CreDes: Causal Reasoning Enhancement and Dual-End Searching for Solving Long-Range Reasoning Problems using LLMs",
        "link_suffix": "/forum?id=W9uY7is3Ey",
        "link": "https://openreview.net/forum?id=W9uY7is3Ey",
        "pdf_link": "https://openreview.net/pdf?id=W9uY7is3Ey",
        "keywords": "Causal Reasoning Enhancement, Dual-End Searching, Long-Range Reasoning, LLM",
        "abstract": "Large language models (LLMs) have demonstrated limitations in handling combinatorial optimization problems involving long-range reasoning, partially due to causal hallucinations and huge search space. As for causal hallucinations, i.e., the inconsistency between reasoning and corresponding state transition, this paper introduces the Causal Relationship Enhancement (CRE) mechanism combining cause-effect interventions and the Individual Treatment Effect (ITE) to guarantee the solid causal rightness between each step of reasoning and state transition. As for the long causal range and huge search space limiting the performances of existing models featuring single-direction search, a Dual-End Searching (DES) approach is proposed to seek solutions by simultaneously starting from both the initial and goal states on the causal probability tree. By integrating CRE and DES (CreDes), our model has realized simultaneous multi-step reasoning, circumventing the inefficiencies from cascading multiple one-step reasoning like the Chain-of-Thought (CoT). Experiments demonstrate that CreDes significantly outperforms existing State-Of-The-Art (SOTA) solutions in long-range reasoning tasks in terms of both accuracy and time efficiency."
    },
    {
        "title": "RealTracker: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos",
        "link_suffix": "/forum?id=0Wl6h2CZeJ",
        "link": "https://openreview.net/forum?id=0Wl6h2CZeJ",
        "pdf_link": "https://openreview.net/pdf?id=0Wl6h2CZeJ",
        "keywords": "Point tracking, Optical flow, Motion estimation, Pseudo labelling",
        "abstract": "Most state-of-the-art point trackers are trained on synthetic data due to the difficulty of annotating real videos for this task.\nHowever, this can result in suboptimal performance due to the statistical gap between synthetic and real videos. In order to understand these issues better, we introduce RealTracker, comprising a new tracking model and a new semi-supervised training recipe. This allows real videos without annotations to be used during training by generating pseudo-labels using off-the-shelf teachers.\nThe new model eliminates or simplifies components from previous trackers, resulting in a simpler and smaller architecture.\nThis training scheme is much simpler than prior work and achieves better results using 1,000 times less data.\nWe further study the scaling behaviour to understand the impact of using more real unsupervised data in point tracking.\nThe model is available in online and offline variants and reliably tracks visible and occluded points."
    },
    {
        "title": "Abstracting and Refining Provably Sufficient Explanations of Neural Network Predictions",
        "link_suffix": "/forum?id=1IeCqgULIM",
        "link": "https://openreview.net/forum?id=1IeCqgULIM",
        "pdf_link": "https://openreview.net/pdf?id=1IeCqgULIM",
        "keywords": "explainability, XAI, explainable AI",
        "abstract": "Despite significant advancements in post-hoc explainability techniques for neural networks, many current methods rely on approximations and heuristics and do not provide formally provable guarantees over the explanations provided.  Recent work has shown that it is possible to obtain explanations with formal guarantees by identifying subsets of input features that are sufficient to determine that predictions remain unchanged by incorporating neural network verification techniques. Despite the appeal of these explanations, their computation faces significant scalability challenges. In this work, we address this gap by proposing a novel abstraction-refinement technique for efficiently computing provably sufficient explanations of neural network predictions. Our methodabstractsthe original large neural network by constructing a substantially reduced network, where a sufficient explanation of the reduced network is alsoprovably sufficientfor the original network, hence significantly speeding up the verification process. If the explanation is insufficient on the reduced network, we iterativelyrefinethe network size (by gradually increasing it) until convergence. Our experimental results demonstrate that our approach substantially enhances the efficiency of obtaining provably sufficient explanations for neural network predictions while additionally providing a fine-grained interpretation of the network's decisions across different abstraction levels. We thus regard this work as a substantial step forward in improving the feasibility of computing explanations with formal guarantees for neural networks."
    },
    {
        "title": "InstantSwap: Fast Customized Concept Swapping across Sharp Shape Differences",
        "link_suffix": "/forum?id=UFrHWzZENz",
        "link": "https://openreview.net/forum?id=UFrHWzZENz",
        "pdf_link": "https://openreview.net/pdf?id=UFrHWzZENz",
        "keywords": "Text-to-image generation, Image editing, Customized concept swapping",
        "abstract": "Recent advances in Customized Concept Swapping (CCS) enable a text-to-image model to swap a concept in the source image with a customized target concept. However, the existing methods still face the challenges of $\\textit{\\textbf{inconsistency}}$ and $\\textit{\\textbf{inefficiency}}$. They struggle to maintain consistency in both the foreground and background during concept swapping, especially when the shape difference is large between objects. Additionally, they either require time-consuming training processes or involve redundant calculations during inference. To tackle these issues, we introduce InstantSwap, a new CCS method that aims to handle sharp shape disparity at speed. Specifically, we first extract the bbox of the object in the source image $\\textit{automatically}$ based on attention map analysis and leverage the bbox to achieve both foreground and background consistency. For background consistency, we remove the gradient outside the bbox during the swapping process so that the background is free from being modified. For foreground consistency, we employ a cross-attention mechanism to inject semantic information into both source and target concepts inside the box. This helps learn semantic-enhanced representations that encourage the swapping process to focus on the foreground objects. To improve swapping speed, we avoid computing gradients at each timestep but instead calculate them periodically to reduce the number of forward passes, which improves efficiency a lot with a little sacrifice on performance. Finally, we establish a benchmark dataset to facilitate comprehensive evaluation. Extensive evaluations demonstrate the superiority and versatility of InstantSwap."
    },
    {
        "title": "Double Descent Meets Out-of-Distribution Detection: Theoretical Insights and Empirical Analysis of the role of model complexity",
        "link_suffix": "/forum?id=eN0RyRVbSm",
        "link": "https://openreview.net/forum?id=eN0RyRVbSm",
        "pdf_link": "https://openreview.net/pdf?id=eN0RyRVbSm",
        "keywords": "Out-Of-Distribution, double descent.",
        "abstract": "While overparameterization is known to benefit generalization, its impact on Out-Of-Distribution (OOD) detection is less understood. This paper investigates the influence of model complexity in OOD detection. We propose an expected OOD risk metric to evaluate classifiers confidence on both training and OOD samples. Leveraging Random Matrix Theory, we derive bounds for the expected OOD risk of binary least-squares classifiers applied to Gaussian data. We show that the OOD risk depicts an infinite peak, when the number of parameters is equal to the number of samples, which we associate with the double descent phenomenon. Our experimental study on different OOD detection methods across multiple neural architectures extends our theoretical insights and highlights a double descent curve. Our observations suggest that overparameterization does not necessarily lead to better OOD detection. Using the Neural Collapse framework, we provide insights to better understand this behavior. To facilitate reproducibility, our code will be made publicly available upon publication."
    },
    {
        "title": "HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models",
        "link_suffix": "/forum?id=QM2WoPu1It",
        "link": "https://openreview.net/forum?id=QM2WoPu1It",
        "pdf_link": "https://openreview.net/pdf?id=QM2WoPu1It",
        "keywords": "Large Language Models, Long Text Generation, Benchmark",
        "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks (e.g., long-context understanding), and many benchmarks have been proposed. However, we observe that long text generation capabilities are not well investigated. Therefore, we introduce the Hierarchical Long Text Generation Benchmark (HelloBench), a comprehensive, in-the-wild, and open-ended benchmark to evaluate LLMs' performance in generating long text. Based on Bloom's Taxonomy, HelloBench categorizes long text generation tasks into five subtasks: open-ended QA, summarization, chat, text completion, and heuristic text generation. Besides, we propose Hierarchical Long Text Evaluation (HelloEval), a human-aligned evaluation method that significantly reduces the time and effort required for human evaluation while maintaining a high correlation with human evaluation. We have conducted extensive experiments across around 30 mainstream LLMs and observed that the current LLMs lack long text generation capabilities. Specifically, first, regardless of whether the instructions include explicit or implicit length constraints, we observe that most LLMs cannot generate text that is longer than 4000 words. Second, we observe that while some LLMs can generate longer text, many issues exist (e.g., severe repetition and quality degradation). Third, to demonstrate the effectiveness of HelloEval, we compare HelloEval with traditional metrics (e.g., ROUGE, BLEU, etc.) and LLM-as-a-Judge methods, which show that HelloEval has the highest correlation with human evaluation."
    },
    {
        "title": "On Joint Noise Scaling in Differentially Private Federated Learning with Multiple Local Steps",
        "link_suffix": "/forum?id=natXOadi7j",
        "link": "https://openreview.net/forum?id=natXOadi7j",
        "pdf_link": "https://openreview.net/pdf?id=natXOadi7j",
        "keywords": "federated learning, cross-silo, differential privacy, secure aggregation, privacy-preserving federated learning",
        "abstract": "Federated learning is a distributed learning setting where the main aim is to train machine learning models without having to share raw data but only what is required for learning. To guarantee training data privacy and high-utility models, differential privacy and secure aggregation techniques are often combined with federated learning. However, with fine-grained protection granularities the currently existing techniques require the parties to communicate for each local optimisation step, if they want to fully benefit from the secure aggregation in terms of the resulting formal privacy guarantees. In this paper, we show how a simple new analysis allows the parties to perform multiple local optimisation steps while still benefiting from joint noise scaling when using secure aggregation. We show that our analysis enables higher utility models with guaranteed privacy protection under limited number of communication rounds."
    },
    {
        "title": "Benchmarking XAI Explanations with Human-Aligned Evaluations",
        "link_suffix": "/forum?id=6KZ80APcxf",
        "link": "https://openreview.net/forum?id=6KZ80APcxf",
        "pdf_link": "https://openreview.net/pdf?id=6KZ80APcxf",
        "keywords": "Explainable artificial intelligence (XAI), Dataset, Benchmark",
        "abstract": "In this paper, we introduce PASTA (Perceptual Assessment System for explanaTion of Artificial intelligence), a novel framework for a human-centric evaluation of XAI techniques in computer vision.\nOur first key contribution is a human evaluation of XAI explanations on four diverse datasets\u2014COCO, Pascal Parts, Cats Dogs Cars, and MonumAI\u2014which constitutes the first large-scale benchmark dataset for XAI, with annotations at both the image and concept levels. This dataset allows for robust evaluation and comparison across various XAI methods. Our second major contribution is a data-based metric for assessing the interpretability of explanations. It mimics human preferences, based on a database of human evaluations of explanations in the PASTA-dataset. With its dataset and metric, the PASTA framework provides consistent and reliable comparisons between XAI techniques, in a way that is scalable but still aligned with human evaluations. Additionally, our benchmark allows for comparisons between explanations across different modalities, an aspect previously unaddressed. Our findings indicate that humans tend to prefer saliency maps over other explanation types. Moreover, we provide evidence that human assessments show a low correlation with existing XAI metrics that are numerically simulated by probing the model."
    },
    {
        "title": "FreeRide: Harvesting Bubbles in Pipeline Parallelism",
        "link_suffix": "/forum?id=cJn9HXPEpc",
        "link": "https://openreview.net/forum?id=cJn9HXPEpc",
        "pdf_link": "https://openreview.net/pdf?id=cJn9HXPEpc",
        "keywords": "Pipeline parallelism, bubbles",
        "abstract": "The occurrence of bubbles in pipeline parallelism is an inherent limitation that can account for more than 40% of the large language model (LLM) training time and is one of the main reasons for the underutilization of GPU resources in LLM training. Harvesting these bubbles for GPU side tasks can increase resource utilization and reduce training costs but comes with challenges. First, because bubbles are discontinuous with various shapes, programming side tasks becomes difficult while requiring excessive engineering effort. Second, a side task can compete with pipeline training for GPU resources and incur significant overhead. To address these challenges, we propose FreeRide, a system designed to harvest bubbles in pipeline parallelism for side tasks. FreeRide provides programmers with interfaces to implement side tasks easily, manages bubbles and side tasks during pipeline training, and controls access to GPU resources by side tasks to reduce overhead. We demonstrate that FreeRide achieves about 8% average cost savings with a negligible overhead of about 1% for typical long training times of LLMs while serving model training, graph analytics, and image processing side tasks."
    },
    {
        "title": "Concise, Efficient, and Faithful Sufficient Reasons using Self-Explaining Neural Networks",
        "link_suffix": "/forum?id=8nuzsfiQfS",
        "link": "https://openreview.net/forum?id=8nuzsfiQfS",
        "pdf_link": "https://openreview.net/pdf?id=8nuzsfiQfS",
        "keywords": "XAI, explainability, explainable AI",
        "abstract": "Minimal sufficient reasonsrepresent a prevalent form of explanation - the smallest subset of input features which, when held constant at their corresponding values, ensure that the prediction remains unchanged. Previouspost-hocmethods attempt to obtain such explanations but face two main limitations: (1) Obtaining these subsets poses a computational challenge, leading most scalable methods to converge towards suboptimal, less meaningful subsets; (2) These methods heavily rely on sampling out-of-distribution input assignments, potentially resulting in counterintuitive behaviors. To tackle these limitations, we propose in this work a self-supervised training approach, which we termsufficient subset training(SST). Using SST, we train models to generate concise sufficient reasons for their predictions as an integral part of their output. Our results indicate that our framework produces succinct and faithful subsets substantially more efficiently than competing post-hoc methods while maintaining comparable predictive performance."
    },
    {
        "title": "MIND SCRAMBLE: UNVEILING LARGE LANGUAGE MODEL PSYCHOLOGY VIA TYPOGLYCEMIA",
        "link_suffix": "/forum?id=KBixkDNE8p",
        "link": "https://openreview.net/forum?id=KBixkDNE8p",
        "pdf_link": "https://openreview.net/pdf?id=KBixkDNE8p",
        "keywords": "Large Language Model, Typoglycemia, Scrambled Text Understanding",
        "abstract": "Although still in its infancy, research into the external behaviors and internal mechanisms of large language models (LLMs) has shown significant promise in addressing complex tasks in the physical world. These studies suggest that powerful LLMs, such as GPT-4, are beginning to exhibit human-like cognitive abilities, including planning, reasoning, and reflection, among others. In this paper, we introduce an innovative research line and methodology named LLM Psychology, which leverages or extends human psychology experiments and theories to investigate cognitive behaviors and mechanisms of LLMs. Practically, we migrate the Typoglycemia phenomenon from psychology to explore the \u201cmind\u201d of LLMs. To comprehend scrambled text in Typoglycemia, human brains rely on context and word patterns, which reveals a fundamental difference from LLMs\u2019 encoding and decoding processes. Through various Typoglycemia experiments at the character, word, and sentence levels, we observe the following: (I) LLMs demonstrate human-like behaviors on a macro scale, such as slightly lower task accuracy with consuming more tokens and time; (II) Different LLMs show varying degrees of robustness to scrambled input, making it a democratized benchmark for model evaluation without crafting new datasets; (III) The impact of different task types varies, with complex logical tasks (e.g., math) in scrambled format being more challenging. Going beyond these, some misleadingly optimistic results suggest that LLMs are still primarily data-driven, and their human-like cognitive abilities may differ from what we perceive; (IV) Interestingly, each LLM exhibit its unique and consistent \u201ccognitive pattern\u201d across various tasks, unveiling a general mechanism in its psychology process. To conclude, we provide an in-depth analysis of hidden layers on a micro scale to explain these phenomena, paving the way for LLMs\u2019 deeper interpretability and future research in LLM Psychology."
    },
    {
        "title": "Leveraging Submodule Linearity Enhances Task Arithmetic Performance in LLMs",
        "link_suffix": "/forum?id=irPcM6X5FV",
        "link": "https://openreview.net/forum?id=irPcM6X5FV",
        "pdf_link": "https://openreview.net/pdf?id=irPcM6X5FV",
        "keywords": "Large Language model, Task Arithmetic",
        "abstract": "Task arithmetic is a straightforward yet highly effective strategy for model merging, enabling the resultant model to exhibit multi-task capabilities. Recent research indicates that models demonstrating linearity enhance the performance of task arithmetic. In contrast to existing methods that rely on the global linearization of the model, we argue that this linearity already exists within the model's submodules. In particular, we present a statistical analysis and show that submodules (e.g., layers, self-attentions, and MLPs) exhibit significantly higher linearity than the overall model. Based on these findings, we propose an innovative model merging strategy that independently merges these submodules. Especially, we derive a closed-form solution for optimal merging weights grounded in the linear properties of these submodules. Experimental results demonstrate that our method consistently outperforms the standard task arithmetic approach and other established baselines across different model scales and various tasks. This result highlights the benefits of leveraging the linearity of submodules and provides a new perspective for exploring solutions for effective and practical multi-task model merging."
    },
    {
        "title": "CPT: Consistent Proxy Tuning for Black-box Optimization",
        "link_suffix": "/forum?id=o7alDZDJWB",
        "link": "https://openreview.net/forum?id=o7alDZDJWB",
        "pdf_link": "https://openreview.net/pdf?id=o7alDZDJWB",
        "keywords": "black-box models, large language models, vision-language models, black-box tuning",
        "abstract": "Black-box tuning has attracted recent attention due to that the structure or inner parameters of advanced proprietary models are not accessible. Recently, Proxy-tuning provides a test-time output adjustment for tuning black-box language models.It applies the difference of the output logits before and after tuning a smaller white-box \"proxy\" model to improve the black-box model. However, this technique serves only as a decoding-time algorithm, leading to an inconsistency between training and testing which potentially limits overall performance. To address this problem, we introduce Consistent Proxy Tuning (CPT), a simple yet effective black-box tuning method. Different from Proxy-tuning, CPT additionally exploits the frozen large black-box model and another frozen small white-box model, ensuring consistency between training-stage optimization objective and test-time proxies. This consistency benefits Proxy-tuning and enhances model performance. Note that our method focuses solely on logit-level computation, which makes it model-agnostic and applicable to any task involving logit classification. Extensive experimental results demonstrate the superiority of our CPT in both black-box tuning of Large-Language Models (LLMs) and Vision-Language Models (VLMs) across various datasets."
    },
    {
        "title": "HexGen-2: Disaggregated Generative Inference of LLMs in Heterogeneous Environment",
        "link_suffix": "/forum?id=Cs6MrbFuMq",
        "link": "https://openreview.net/forum?id=Cs6MrbFuMq",
        "pdf_link": "https://openreview.net/pdf?id=Cs6MrbFuMq",
        "keywords": "Distributed Machine Learning System; Generative Inference of LLM.",
        "abstract": "Disaggregating the prefill and decoding phases represents an effective new paradigm for generative inference of large language models (LLM). This approach offers some significant system advantages, such as eliminating prefill-decoding interference and optimizing resource allocation. However, it is still an challenging open problem about how to deploy the disaggregated inference paradigm across a group of heterogeneous GPUs, which can be an economic alternative of the deployment over the homogeneous high performance GPUs.\nTowards this end, we introduce HexGen-2, a distributed system for high throughput and cost-efficient LLM serving on heterogeneous GPUs following the disaggragated paradigm. Built on top of HexGen, the core component of HexGen-2 is a sophisticated scheduling algorithm that formalizes the allocation of disaggregated LLM inference computations and communications over heterogeneous GPUs and network connections as a constraint optimization problem. We leverage the graph partitioning and max-flow algorithm to co-optimize resource allocation, parallel strategies for distinct inference phases, and the efficiency of inter-phase key-value (KV) cache communications. We conduct extensive experiments to evaluate HexGen-2, i.e., on OPT (30B) and Llama-2 (70B) models in various real-world settings, the results reveal that HexGen-2 delivers up to a 2.0$\\times$ and on average a 1.3$\\times$ improvement in serving throughput, reduces the average inference latency by 1.5$\\times$ compared with state-of-the-art systems given the same price budget, and achieves comparable inference performance with a 30% lower price budget."
    },
    {
        "title": "Neural Regenerative Stochastic Differential Equation: Dropout Scheme for Neural Differential Equations",
        "link_suffix": "/forum?id=Mq23uJ6sIm",
        "link": "https://openreview.net/forum?id=Mq23uJ6sIm",
        "pdf_link": "https://openreview.net/pdf?id=Mq23uJ6sIm",
        "keywords": "neural differential equations, neural stochastic differential equations, dropout, regularization, renewal process",
        "abstract": "Neural Differential Equations (NDEs) are an excellent tool for modeling continuous-time (stochastic) dynamics, effectively handling challenges such as irregular observations, missing values, and noise. Despite their advantages, there is a lack of regularization techniques in the NDE framework, particularly those like dropout, which have been successfully implemented in other discrete neural networks, making them susceptible to overfitting. To address this research gap, we introduce Neural Regenerative Stochastic Differential Equation (NRSDE), based on alternating renewal processes, as a universally applicable regularization technique for NDEs. Our study reveals that NRSDE can effectively represent a continuous approximation of neural networks that randomly deactivate some neurons during training, similar to dropout, thereby enhancing the robustness and generalization capabilities of NDEs. Through extensive experiments, we demonstrate that NRSDE outperforms existing regularization methods for NDEs and can be applied to all existing NDE models, significantly improving their performance across various deep learning tasks, including time series classification and image classification."
    },
    {
        "title": "FreqPrior: Improving Diffusion Models with Frequency Filtering Gaussian Noise as Prior",
        "link_suffix": "/forum?id=8x0SGbCpzs",
        "link": "https://openreview.net/forum?id=8x0SGbCpzs",
        "pdf_link": "https://openreview.net/pdf?id=8x0SGbCpzs",
        "keywords": "video diffusion models; Fourier transform; noise prior; frequency filtering",
        "abstract": "Text-driven video generation has advanced significantly due to developments in diffusion models. Beyond the training and sampling phases, recent studies have investigated noise priors of diffusion models, as improved noise priors yield better generation results. One recent approach employs Fourier transform to manipulate noise, marking the initial exploration of frequency operations in this context. However, it often generates videos that lack motion dynamics and imaging details. In this work, we provide a comprehensive theoretical analysis of the variance decay issue present in existing methods, contributing to the loss of details and motion dynamics. Recognizing the critical impact of noise distribution on generation quality, we introduce FreqPrior, a novel noise initialization strategy that refines noise in the frequency domain.  Our method features a novel filtering technique designed to address different frequency signals while maintaining the noise prior distribution that closely approximates a standard Gaussian distribution. Additionally, we propose a partial sampling process by perturbing the latent at an intermediate timestep during finding the noise prior, significantly reducing inference time without compromising quality. Extensive experiments on VBench demonstrate that our method achieves the highest scores in both quality and semantic assessments, resulting in the best overall total score. These results highlight the superiority of our proposed noise prior."
    },
    {
        "title": "Progressively Refined Differentiable Physics",
        "link_suffix": "/forum?id=9Fh0z1JmPU",
        "link": "https://openreview.net/forum?id=9Fh0z1JmPU",
        "pdf_link": "https://openreview.net/pdf?id=9Fh0z1JmPU",
        "keywords": "differentiable physics, iterative PDE solvers, neural surrogate",
        "abstract": "The physics solvers employed for neural network training are primarily iterative, and hence, differentiating through them introduces a severe computational burden as iterations grow large. Inspired by works in bilevel optimization, we show that full accuracy of the network is achievable through physics significantly coarser than fully converged solvers. We proposeprogressively refined differentiable physics(PRDP), an approach that identifies the level of physics refinement sufficient for full training accuracy. By beginning with coarse physics, adaptively refining it during training, and stopping refinement at the level adequate for training, it enables significant compute savings without sacrificing network accuracy. Our focus is on differentiating iterative linear solvers for sparsely discretized differential operators, which are fundamental to scientific computing. PRDP is applicable to both unrolled and implicit differentiation. We validate its performance on a variety of learning scenarios involving differentiable physics solvers such as inverse problems, autoregressive neural emulators, and correction-based neural-hybrid solvers. In the challenging example of emulating the Navier-Stokes equations, we reduce training time by 62%."
    },
    {
        "title": "Stochastic Layer-Wise Shuffle: A Good Practice to Improve Vision Mamba Training",
        "link_suffix": "/forum?id=EispKqtw5B",
        "link": "https://openreview.net/forum?id=EispKqtw5B",
        "pdf_link": "https://openreview.net/pdf?id=EispKqtw5B",
        "keywords": "Vision Mamba, Supervised Learning, Training Regularization, Computer Vision",
        "abstract": "Recent Vision Mamba models not only have much lower complexity for processing higher resolution images and longer videos but also the competitive performance with Vision Transformers (ViTs). However, they are stuck into overfitting and thus only present up to base size (about 80M). It is still unclear how vanilla Vision Mamba (Vim) can be efficiently scaled up to larger sizes, which is essentially for further exploitation. In this paper, we propose a stochastic layer-wise shuffle regularization, which empowers successfully scaling non-hierarchical Vision Mamba to a large size (about 300M) in a supervised setting. Specifically, our base and large-scale ShuffleMamba models can outperform the supervised ViTs of similar size by 0.8% and 1.0% classification accuracy on ImageNet1k, respectively, without auxiliary data. When evaluated on the ADE20K semantic segmentation and COCO detection tasks, our ShuffleMamba models also show significant improvements. Without bells and whistles, the stochastic layer-wise shuffle has the following highlights: (1) Plug and play: it does not change model architectures and will be omitted in inference. (2) Simple but effective: it can improve the overfitting in Vim training and only introduce random token permutation operations. (3) Intuitive: the token sequences in deeper layers are more likely to be shuffled as they are expected to be more semantic and less sensitive to patch positions."
    },
    {
        "title": "Dual Variance Reduction with Momentum for Imbalanced Black-Box Discrete Prompt Learning",
        "link_suffix": "/forum?id=LtHy5y4Ep0",
        "link": "https://openreview.net/forum?id=LtHy5y4Ep0",
        "pdf_link": "https://openreview.net/pdf?id=LtHy5y4Ep0",
        "keywords": "prompt learning; black-box optimization; imbalanced data",
        "abstract": "Black-box prompt learning has proven to be an effective approach for customizing large language models (LLMs) offered as services to address various downstream tasks. \nWithin this domain, policy gradient-based methods have garnered substantial attention as a prominent approach for learning discrete prompts.\nHowever, the highly imbalanced data distribution in the real world limits the applicability of such approaches by influencing LLMs' tendency to favor certain categories.\nTo tackle the challenge posed by imbalanced data, this paper pioneers the integration of pairwise AUC loss into the policy gradient optimization of discrete text prompts and proposes learning discrete prompts with doubly policy gradient.\nUnfortunately, the doubly policy gradient estimation suffers from two variance components, resulting in unstable optimization.\nAs a further improvement, we propose (1) a novel unbiased variance-reduced doubly policy gradient estimator and (2) incorporating the STORM variance reduction technique. \nUltimately, we introduce a novel momentum-based discrete prompt learning method with doubly policy gradient (mDP-DPG).\nCrucially, we provide theoretical convergence guarantees for mDP-DPG within standard frameworks.\nThe experimental results show that mDP-DPG surpasses baseline approaches across diverse imbalanced text classification datasets, emphasizing the advantages of our proposed approach for tackling data imbalance.\nOur code is available at the following URL:https://anonymous.4open.science/r/DPDPG-1ECB."
    },
    {
        "title": "Generalizing to any diverse distribution: uniformity, gentle finetuning & rebalancing",
        "link_suffix": "/forum?id=sRb9sddBy2",
        "link": "https://openreview.net/forum?id=sRb9sddBy2",
        "pdf_link": "https://openreview.net/pdf?id=sRb9sddBy2",
        "keywords": "out-of-distribution generalization, ood generalization, diversity, rebalancing, finetuning",
        "abstract": "As training datasets grow larger, we aspire to develop models that generalize well to any diverse test distribution, even if the latter deviates significantly from the training data. Various approaches like domain adaptation, domain generalization, and robust optimization attempt to address the out-of-distribution challenge by posing assumptions about the relation between training and test distribution. Differently, we adopt a more conservative perspective by accounting for the worst-case error across all sufficiently diverse test distributions within a known domain. Our first finding is that training on a uniform distribution over this domain is optimal. We also interrogate practical remedies when uniform samples are unavailable by considering methods for mitigating non-uniformity through finetuning and rebalancing. Our theory provides a mathematical grounding for previous observations on the role of entropy and rebalancing for o.o.d. generalization and foundation model training. We also provide new empirical evidence across tasks involving o.o.d. shifts which illustrate the broad applicability of our perspective."
    },
    {
        "title": "PABBO: Preferential Amortized Black-Box Optimization",
        "link_suffix": "/forum?id=YhfrKB3Ah7",
        "link": "https://openreview.net/forum?id=YhfrKB3Ah7",
        "pdf_link": "https://openreview.net/pdf?id=YhfrKB3Ah7",
        "keywords": "Bayesian optimization, preference learning, amortized inference, neural processes",
        "abstract": "Preferential Bayesian Optimization (PBO) is a sample-efficient method to learn latent user utilities from preferential feedback over a pair of designs. It relies on a statistical surrogate model for the latent function, usually a Gaussian process, and an acquisition strategy to select the next candidate pair to get user feedback on. Due to the non-conjugacy of the associated likelihood, every PBO step requires a significant amount of computations with various approximate inference techniques. This computational overhead is incompatible with the way humans interact with computers, hindering the use of PBO in real-world cases. Building on the recent advances of amortized BO, we propose to circumvent this issue by fully amortizing PBO, meta-learning both the surrogate and the acquisition function. Our method comprises a novel transformer neural process architecture, trained using reinforcement learning and tailored auxiliary losses.\nOn a benchmark composed of synthetic and real-world datasets, our method is several orders of magnitude faster than the usual Gaussian process-based strategies and often outperforms them in accuracy."
    },
    {
        "title": "Evaluating Perceptual Distances Models by Fitting Binomial Distributions to Two-Alternative Forced Choice Data",
        "link_suffix": "/forum?id=fRaK0cG9L8",
        "link": "https://openreview.net/forum?id=fRaK0cG9L8",
        "pdf_link": "https://openreview.net/pdf?id=fRaK0cG9L8",
        "keywords": "visual perception, perceptual distances, two-alternative forced choice",
        "abstract": "The two-alternative forced choice (2AFC) experimental method is popular in the visual perception literature, where practitioners aim to understand how human observers perceive distances within triplets made of a reference image and two distorted versions. In the past, this had been conducted in controlled environments, with triplets sharing images, so it was possible to rank the perceived quality. This ranking would then be used to evaluate perceptual distance models against the experimental data. Recently, crowd-sourced perceptual datasets have emerged, with no images shared between triplets, making ranking infeasible. Evaluating perceptual distance models using this data reduces the judgements on a triplet to a binary decision, namely, whether the distance model agrees with the human decision - which is suboptimal and prone to misleading conclusions. Instead, we statistically model the underlying decision-making process during 2AFC experiments using a binomial distribution. Having enough empirical data, we estimate a smooth and consistent distribution of the judgements on the reference-distorted distance plane, according to each distance model. By applying maximum likelihood, we estimate the parameter of the local binomial distribution, and a global measurement of the expected log-likelihood of the measured responses. We calculate meaningful and well-founded metrics for the distance model, beyond the mere prediction accuracy as percentage agreement, even with variable numbers of judgements per triplet -- key advantages over both classical and neural network methods."
    }
]
[{"title": "LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch", "link_suffix": "/forum?id=9OMvtboTJg", "link": "https://openreview.net/forum?id=9OMvtboTJg", "pdf_link": "https://openreview.net/pdf?id=9OMvtboTJg", "keywords": "Optimization, Optimization Problem Formulation, Problem Definition, Foundation Model", "abstract": "Optimization problems are prevalent across various scenarios. Formulating and then solving optimization problems described by natural language often requires highly specialized human expertise, which could block the widespread application of optimization-based decision making. To make problem formulating and solving automated, leveraging large language models (LLMs) has emerged as a potential way. However, this kind of way suffers from the issue of optimization generalization. Namely, the accuracy of most current LLM-based methods and the generality of optimization problem types that they can model are still limited. In this paper, we propose a unified learning-based framework called LLMOPT to boost optimization generalization. Starting from the natural language descriptions of optimization problems and a pre-trained LLM, LLMOPT constructs the introduced five-element formulation as a universal model for learning to define diverse optimization problem types. Then, LLMOPT employs the multi-instruction tuning to enhance both problem formalization and solver code generation accuracy and generality. After that, to prevent hallucinations in LLMs, such as sacrificing solving accuracy to avoid execution errors, model alignment and self-correction mechanism are adopted in LLMOPT. We evaluate the optimization generalization ability of LLMOPT and compared methods across six real-world datasets covering roughly 20 fields such as health, environment, energy and manufacturing, etc. Extensive experiment results show that LLMOPT is able to model various optimization problem types such as linear/nonlinear programming, mixed integer programming and combinatorial optimization, and achieves a notable 11.08% average solving accuracy improvement compared with the state-of-the-art methods. The code is available athttps://anonymous.4open.science/r/LLMOPT.", "title_embedding_index": 7400, "title_abs_embedding_index": 7425}, {"title": "T2V2: A Unified Non-Autoregressive Model for Speech Recognition and Synthesis via Multitask Learning", "link_suffix": "/forum?id=TtKN1TpvUu", "link": "https://openreview.net/forum?id=TtKN1TpvUu", "pdf_link": "https://openreview.net/pdf?id=TtKN1TpvUu", "keywords": "ASR, TTS, Non-Autoregressive, Conformer, Multitask Learning", "abstract": "We introduce T2V2 (Text toVoice andVoice toText), a unified non-autoregressive model capable of performing both automatic speech recognition (ASR) and text-to-speech (TTS) synthesis within the same framework. T2V2 uses a shared Conformer backbone with rotary positional embeddings to efficiently handle these core tasks, with ASR trained using Connectionist Temporal Classification (CTC) loss and TTS using masked language modeling (MLM) loss. The model operates on discrete tokens, where speech tokens are generated by clustering features from a self-supervised learning model. To further enhance performance, we introduce auxiliary tasks: CTC error correction to refine raw ASR outputs using contextual information from speech embeddings, and unconditional speech MLM, enabling classifier free guidance to improve TTS. Our method is self-contained, leveraging intermediate CTC outputs to align text and speech using Monotonic Alignment Search, without relying on external aligners. We perform extensive experimental evaluation to verify the efficacy of the T2V2 framework, achieving state-of-the-art performance on TTS task and competitive performance in discrete ASR.", "title_embedding_index": 7401, "title_abs_embedding_index": 7426}, {"title": "How To Be A Good Teacher? Process Strong Pretrained Models For Effective Knowledge Distillation", "link_suffix": "/forum?id=UAzVXdgheU", "link": "https://openreview.net/forum?id=UAzVXdgheU", "pdf_link": "https://openreview.net/pdf?id=UAzVXdgheU", "keywords": "Knowledge distillation, Pretrained models, Mutual information, Sharpness Aware Minimization, Mixture-of-Experts", "abstract": "Transferring the world knowledge encoded in pretrained models through knowledge distillation is an effective approach to improve the performance of small, task-specific production models. However, the effectiveness of such knowledge transfer drops greatly for strong models that are pretrained in a large scale. In this paper, we explore methods to preprocess strong pretrained models to improve the effectiveness of its knowledge transfer. From a mutual information perspective of distillation effectiveness, we propose to incorporate mutual information-aware optimization into the fine-tuning of strong pretrained models. For small or highly-imbalanced downstream datasets where such optimization is less effective, we further propose to heuristically reweight the MLP blocks, which is inspired by our observation that top MLP blocks often cause the loss of mutual information. Our method enables small student models to benefit from those pretrained models among the strongest.", "title_embedding_index": 7402, "title_abs_embedding_index": 7427}, {"title": "Enhancing Perception Capabilities of Multimodal LLMs with Training-Free Fusions", "link_suffix": "/forum?id=2jEiFTLRwX", "link": "https://openreview.net/forum?id=2jEiFTLRwX", "pdf_link": "https://openreview.net/pdf?id=2jEiFTLRwX", "keywords": "Multimodal Large Language Model, Model Integration", "abstract": "Multimodal LLMs (MLLMs) equip language models with visual capabilities by aligning vision encoders with language models. \nExisting methods to enhance the visual perception of MLLMs often involve designing more powerful vision encoders, which requires re-aligning these vision modules with the language model, leading to expensive and time-consuming training processes.\nIn this paper, we introduce VisionFuse, a novel integration framework that efficiently utilizes multiple vision encoders from off-the-shelf MLLMs to enhance visual perception without requiring additional training.\nOur approach is motivated by the observation that different MLLMs tend to focus on distinct regions of the same query and image. Moreover, we find that the feature distributions of vision encoders within an MLLM family, a group of MLLMs sharing the same pretrained LLM, are highly aligned.\nBuilding on these insights, VisionFuse enriches the visual context by concatenating the tokens generated by the vision encoders of selected MLLMs within a family. By merging the parameters of language models from different MLLMs, VisionFuse allows a single language model to align with various vision encoders, significantly reducing deployment overhead.\nWe conduct comprehensive evaluations across multiple multimodal benchmarks using various MLLM combinations, \ndemonstrating substantial improvements \nin multimodal tasks. Notably, when integrating MiniGemini-8B and SLIME-8B, VisionFuse achieves an average performance increase of over 4%.", "title_embedding_index": 7403, "title_abs_embedding_index": 7428}, {"title": "Optimistic Gradient Learning with Hessian Corrections for High-Dimensional Black-Box Optimization", "link_suffix": "/forum?id=nKlcmBJpiH", "link": "https://openreview.net/forum?id=nKlcmBJpiH", "pdf_link": "https://openreview.net/pdf?id=nKlcmBJpiH", "keywords": "Black box optimization, Derivative free optimization, Gradient free optimization, Large language model code geneation, Adversarial training", "abstract": "Black-box algorithms are designed to optimize functions without relying on their underlying analytical structure or gradient information, making them essential when gradients are inaccessible or difficult to compute. Traditional methods for solving black-box optimization (BBO) problems predominantly rely on non-parametric models and struggle to scale to large input spaces. Conversely, parametric methods that model the function with neural estimators and obtain gradient signals via backpropagation may suffer from significant gradient errors. A recent alternative, Explicit Gradient Learning (EGL), which directly learns the gradient using a first-order Taylor approximation, has demonstrated superior performance over both parametric and non-parametric methods. In this paper, we extend EGL by incorporating second-order Taylor corrections via the function's Hessian, improving robustness in complex, highly non-linear problems. Additionally, we refine EGL\u2019s sampling strategy and loss function, enhancing its capability to efficiently address high-dimensional optimization problems. We term our approach as Optimistic Higher-Order Gradient Learning (OHGL) and validate it on the synthetic COCO suite. We also demonstrate its applicability in two high-dimensional real-world machine learning (ML) tasks: adversarial training and code generation. The results show that OHGL produces stronger candidates and serves as a valuable tool for ML researchers and practitioners tackling high-dimensional, non-linear contemporary optimization challenges.", "title_embedding_index": 7404, "title_abs_embedding_index": 7429}, {"title": "IF-MODGS : INITIAL FREE MONOCULAR DYNAMIC GAUSSIAN SPLATTING", "link_suffix": "/forum?id=ylgg2RE7ub", "link": "https://openreview.net/forum?id=ylgg2RE7ub", "pdf_link": "https://openreview.net/pdf?id=ylgg2RE7ub", "keywords": "novel view synthesis, 4D rendering, camera pose estimation, 3D reconstruction", "abstract": "In the field of scene reconstruction with moving objects, recent studies have utilized 3D Gaussian Splatting (3DGS) for spatial representation. This method typically relies on camera poses and point clouds obtained through the Structure-from-Motion (SfM) algorithm. However, in scenes captured with monocular viewpoints and containing moving objects in each frame, the SfM algorithm struggles to obtain accurate camera poses and points clouds. As a result, it often either removes point clouds of dynamic objects or fails to find camera poses for each frame, thereby leading to sub-optimal rendering of dynamic scenes. We propose a novel approach, Initial-Free Monocular Dynamic Gaussian Splatting (IF-MoDGS) which does not require precomputed camera poses and point clouds in dynamic scenes with moving objects. Our approach estimates camera poses using the static background, separated from dynamic objects by a motion mask, and generates point clouds specifically for the dynamic objects. To handle dynamic objects, we define a canonical space and apply deformation to link it with each viewpoint and timestamp. Then, to improve quality in complex spatio-temporal scenes, we utilize a high-dimensional feature loss and an annealing frequency loss. Extensive experimental results demonstrate that our method can effectively render dynamic scenes without relying on precomputed camera poses and point clouds, achieving the state-of-the-art performance in dynamic scene rendering tasks using a monocular camera. Our project will be available at:https://anonymous.4open.science/w/IF-MODGS-67F5/", "title_embedding_index": 7405, "title_abs_embedding_index": 7430}, {"title": "Conditionally Adaptive Graph Attention Networks for Credit Card Fraud Detection", "link_suffix": "/forum?id=fh9OwKKb8D", "link": "https://openreview.net/forum?id=fh9OwKKb8D", "pdf_link": "https://openreview.net/pdf?id=fh9OwKKb8D", "keywords": "Semi-supervised Learning, Graph Neural Networks, Fraud Detection", "abstract": "Fraudulent transactions have been on the rise, leading to significant financial losses annually. In credit card fraud detection (CCFD), various predictive models aim to mitigate these losses by assessing transaction risk. While GNN-based methods have been employed to capture spatio-temporal transaction features, they often suffer from oversmoothing as graph layers increase, causing fraudulent and legitimate transactions to become indistinguishable. Existing semi-supervised methods that mask some labels have not fully resolved this issue. To address this, we propose the Multi-head Attention Conditional Variational Autoencoder (Ma-CVAE), which leverages weight distributions from imbalanced datasets and the Gumbel softmax distribution to construct more diverse reconstructed features, reducing feature homogenization. Then, We utilize Temporal Graph Attention Networks (TGAT) with a Multi-Attention mechanism to model risk propagation among transactions. Finally, classification probabilities are mapped to risk scores via a Multi-Layer Perceptron (MLP). Our approach achieves state-of-the-art performance, improving AUC scores by 1.45%, 3.05%, and 0.83% on three semi-supervised datasets: FFSD, YelpChi, and Amazon, respectively.", "title_embedding_index": 7406, "title_abs_embedding_index": 7431}, {"title": "Certified PEFTSmoothing: Parameter-Efficient Fine-Tuning with Randomized Smoothing", "link_suffix": "/forum?id=9KatbAXLAq", "link": "https://openreview.net/forum?id=9KatbAXLAq", "pdf_link": "https://openreview.net/pdf?id=9KatbAXLAq", "keywords": "Certified Robustness, Parameter-Efficient Fine Tuning, Adversarial Example", "abstract": "Randomized smoothing is the primary certified robustness method for accessing the robustness of deep learning models to adversarial perturbations in the $l_2$-norm, by taking a majority vote over the multiple predictions of a random Gaussian perturbed input of the base classifier. To fulfill the certified bound and empirical accuracy of randomized smoothing, the base model either needs to be retrained from scratch to learn Gaussian noise or adds an auxiliary denoiser to eliminate it. In this work, we propose \\textit{PEFTSmoothing}, which teach the base model to learn the Gaussian noise-augmented data with Parameter-Efficient Fine-Tuning (PEFT) methods in both white-box and black-box settings. This design is based on the intuition that large-scale models have the potential to learn diverse data patterns, including the noise data distributions. In addition, we explore the possibility of combining \\textit{PEFTSmoothing} with the fine-tuning for downstream task adaptation, which allows us to simultaneously obtain a robust version of the large vision model and its adaptation tailored to downstream datasets. Extensive results demonstrate the effectiveness and efficiency of \\textit{PEFTSmoothing}, which allow us to certify over 98% accuracy for ViT on CIFAR-10, 20% higher than SoTA denoised smoothing, and over 61% accuracy on ImageNet which is 30% higher than CNN-based denoiser and comparable to the Diffusion-based denoiser.", "title_embedding_index": 7407, "title_abs_embedding_index": 7432}, {"title": "Cognitive Overload Attack: Prompt Injection for Long Context", "link_suffix": "/forum?id=L5fZHoaUCF", "link": "https://openreview.net/forum?id=L5fZHoaUCF", "pdf_link": "https://openreview.net/pdf?id=L5fZHoaUCF", "keywords": "In Context Learning, Cognitive Overload, LLMs Safety, Prompt Injection Attack", "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in performing tasks across various domains without needing explicit retraining. This capability, known as In-Context Learning (ICL), while impressive, exposes LLMs to a variety of adversarial prompts and jailbreaks that manipulate safety-trained LLMs into generating undesired or harmful output. In this paper, we propose a novel interpretation of ICL in LLMs through the lens of cognitive neuroscience, by drawing parallels between learning in human cognition with ICL. We applied the principles of Cognitive Load Theory in LLMs and empirically validate that similar to human cognition, LLMs also suffer from \\emph{cognitive overload}\u2014a state where the demand on cognitive processing exceeds the available capacity of the model, leading to potential errors. Furthermore, we demonstrated how an attacker can exploit ICL to jailbreak LLMs through deliberately designed prompts that induce cognitive overload on LLMs, thereby compromising the safety mechanisms of LLMs. We empirically validate this threat model by crafting various cognitive overload prompts and show that advanced models such as GPT-4, Claude-3.5 Sonnet, Claude-3 OPUS, LLAMA-3-70B-Instruct, Gemini-1.0-Pro, and Gemini-1.5-Pro can be successfully jailbroken, with attack success rates of up to 99.99%. Our findings highlight critical vulnerabilities in LLMs and underscore the urgency of developing robust safeguards. We propose integrating insights from cognitive load theory into the design and evaluation of LLMs to better anticipate and mitigate the risks of adversarial attacks. By expanding our experiments to encompass a broader range of models and by highlighting vulnerabilities in LLMs' ICL, we aim to ensure the development of safer and more reliable AI systems.", "title_embedding_index": 7408, "title_abs_embedding_index": 7433}, {"title": "Improving Reasoning Ability of Large Language Models via Iterative Uncertainty-based Preference Optimization", "link_suffix": "/forum?id=bGGMLWAGMc", "link": "https://openreview.net/forum?id=bGGMLWAGMc", "pdf_link": "https://openreview.net/pdf?id=bGGMLWAGMc", "keywords": "Preference Optimization, Large Language Model, Iterative Optimization, Uncertainty", "abstract": "Direct Preference Optimization (DPO) has recently emerged as an efficient and effective method for aligning large language models with human preferences.\nHowever, constructing high-quality preference datasets remains challenging, often necessitating expensive manual or powerful LM annotations. Additionally, standard DPO exhibits suboptimal performance in complex reasoning tasks, such as mathematical and code reasoning.\nIn this paper, we introduce an approach to collect preference pairs through iterative sampling and execution feedback, tailored to the current learning state (e.g. well-learned, mis-learned, and unlearned) of the policy model.\nTo alleviate the failures of DPO and improve its applicability in reasoning tasks, we propose IUPO, an iterative uncertainty-based preference optimization method that achieves fine-grained preference control by assessing model confidence.\nWe validate our approach across three reasoning tasks, incorporating five established reasoning datasets and one self-curated dataset. Our experimental results demonstrate an overall improvement of 3.6% over the standard DPO method. \nFurthermore, our approach exhibits promising generalizability involving weak-to-strong (8B to 70B) and cross-model (Llama to Mistral) generalizations.", "title_embedding_index": 7409, "title_abs_embedding_index": 7434}, {"title": "A Second-Order Perspective on Model Compositionality and Incremental Learning", "link_suffix": "/forum?id=OZVTqoli2N", "link": "https://openreview.net/forum?id=OZVTqoli2N", "pdf_link": "https://openreview.net/pdf?id=OZVTqoli2N", "keywords": "Continual Learning, Model Compositionality, Ensemble Learning, Task Arithmetic", "abstract": "The fine-tuning of deep pre-trained models has revealed compositional properties, with multiple specialized modules that can be arbitrarily composed into a single, multi-task model. However, identifying the conditions that promote compositionality remains an open issue, with recent efforts concentrating mainly on linearized networks. We conduct a theoretical study that attempts to demystify compositionality in standard non-linear networks through the second-order Taylor approximation of the loss function. The proposed formulation highlights the importance of staying within the pre-training basin to achieve composable modules. Moreover, it provides the basis for two dual incremental training algorithms: the one from the perspective of multiple models trained individually, while the other aims to optimize the composed model as a whole. We probe their application in incremental classification tasks and highlight some valuable skills. In fact, the pool of incrementally learned modules not only supports the creation of an effective multi-task model but also enables unlearning and specialization in certain tasks.", "title_embedding_index": 7410, "title_abs_embedding_index": 7435}, {"title": "Towards Understanding Robustness and Generalization in World Models", "link_suffix": "/forum?id=k7nYm2yU5i", "link": "https://openreview.net/forum?id=k7nYm2yU5i", "pdf_link": "https://openreview.net/pdf?id=k7nYm2yU5i", "keywords": "World models, robustness, generalization, model-based reinforcement learning", "abstract": "World model has recently emerged as a promising approach to reinforcement learning (RL), as evidenced by the recent successes that world model based agents achieve state-of-the-art performance on a wide range of visual control tasks. This work aims to obtain a deep understanding of the robustness and generalization capabilities of world models. Thus motivated, we develop a stochastic differential\nequation formulation by treating the world model learning as a stochastic dynamical system in the latent state space, and characterize the impact of latent representation errors on robustness and generalization, for both cases with zero-drift representation errors and with non-zero-drift representation errors. Our somewhat surprising findings, based on both theoretic and experimental studies, reveal that for the case with zero drift, modest latent representation errors can in fact function as implicit regularization and hence result in improved robustness. We further propose a Jacobian regularization scheme to mitigate the compounding error propagation effects of non-zero drift, thereby enhancing training stability and robustness. Our extensive experimental studies corroborate that this regularization approach not only stabilizes training but also accelerates convergence and improves accuracy of long-horizon prediction.", "title_embedding_index": 7411, "title_abs_embedding_index": 7436}, {"title": "Physics-Informed Diffusion Models", "link_suffix": "/forum?id=tpYeermigp", "link": "https://openreview.net/forum?id=tpYeermigp", "pdf_link": "https://openreview.net/pdf?id=tpYeermigp", "keywords": "physics-informed, scientific machine learning, denoising diffusion, inverse problems, generative modeling", "abstract": "Generative models such as denoising diffusion models are quickly advancing their ability to approximate highly complex data distributions. They are also increasingly leveraged in scientific machine learning, where samples from the implied data distribution are expected to adhere to specific governing equations. We present a framework that unifies generative modeling and PDE fulfillment and meaningfully informs denoising diffusion models of such underlying constraints on generated samples during training. Our approach improves the alignment of the generated samples with the imposed constraints and significantly outperforms existing methods without affecting inference speed. Additionally, incorporating these constraints during training acts as a natural regularization mechanism against overfitting. Our framework is easy to implement and versatile in its applicability for imposing equality and inequality constraints as well as auxiliary optimization objectives.", "title_embedding_index": 7412, "title_abs_embedding_index": 7437}, {"title": "Turn-by-Turn Driving Navigation: Leveraging Sequence Model for Real-time Audio Instructions", "link_suffix": "/forum?id=2JXe3RprGS", "link": "https://openreview.net/forum?id=2JXe3RprGS", "pdf_link": "https://openreview.net/pdf?id=2JXe3RprGS", "keywords": "Turn-by-Turn Navigation; Deep Learning; Sequence Models", "abstract": "Turn-by-turn (TBT) navigation systems are integral to modern driving experiences, providing real-time audio instructions to guide drivers safely to destinations. However, existing audio instruction policy often rely on rule-based approaches that struggle to balance informational content with cognitive load, potentially leading to driver confusion or missed turns in complex environments. To overcome these difficulties, we first model the generation of audio instructions as a multi-task learning problem by decomposing the audio content into combinations of modular elements. Then, we propose a novel deep learning framework that leverages the powerful spatiotemporal information processing capabilities of Transformers and the strong multi-task learning abilities of Mixture of Experts (MoE) to generate real-time, context-aware audio instructions for TBT driving navigation. A cloud-edge collaborative architecture is implemented to handle the computational demands of the model, ensuring scalability and real-time performance for practical applications. Experimental results in the real world demonstrate that the proposed method significantly reduces the yaw rate compared to traditional methods, delivering clearer and more effective audio instructions. This is the first large-scale application of deep learning in driving audio navigation, marking a substantial advancement in intelligent transportation and driving assistance technologies.", "title_embedding_index": 7413, "title_abs_embedding_index": 7438}, {"title": "Multi-view Consistent Image Generation through Self-calibrated Latent Refinement", "link_suffix": "/forum?id=Ns84n4NWh6", "link": "https://openreview.net/forum?id=Ns84n4NWh6", "pdf_link": "https://openreview.net/pdf?id=Ns84n4NWh6", "keywords": "3D aware image synthesis, 3D generation, GAN, Diffusion.", "abstract": "In this paper, we introduce a novel 3D-aware image generation framework that ensures high-quality and view-consistent image generation. Our core idea is to leverage the semantic latent space of a pre-trained 2D GAN for 3D view-consistent image generation, eliminating need for large-scale dataset use and prior knowledge of camera poses. To achieve this, we propose a latent refiner with multi-view and geometry-preserving capabilities, enabled by self-calibrated depth and pose estimation. Thanks to the advances of diffusion models, our refiner allows for view-consistent latent manipulation in GANs and can be trained using a self-supervised fashion. Our method optimizes the latent codes of a pre-trained 2D GAN across a wide range of pose angles. We demonstrate the effectiveness of our method through evaluations and comparisons with existing baselines on benchmark datasets. Experimental results show the superiority of our method over existing works in both the quality and view consistency of generated images.", "title_embedding_index": 7414, "title_abs_embedding_index": 7439}, {"title": "Investigating Memorization in Video Diffusion Models", "link_suffix": "/forum?id=RFZV2tOWYN", "link": "https://openreview.net/forum?id=RFZV2tOWYN", "pdf_link": "https://openreview.net/pdf?id=RFZV2tOWYN", "keywords": "Video Diffusion Models, Memorization", "abstract": "Diffusion models, widely used for image and video generation, face a significant limitation: the risk of memorizing and reproducing training data during inference, potentially generating unauthorized copyrighted content. While prior research has focused on image diffusion models (IDMs), video diffusion models (VDMs) remain underexplored. To address this, we introduce new metrics specifically designed to separately assess content and motion memorization in VDMs. By applying these metrics, we systematically analyze memorization in various pretrained VDMs, including text-conditional and unconditional models on various datasets, revealing that memorization is widespread across both video and image datasets. Finally, we propose effective detection strategies for both content and motion memorization, offering a foundational approach for improving privacy in VDMs.", "title_embedding_index": 7415, "title_abs_embedding_index": 7440}, {"title": "G2D2: Gradient-guided Discrete Diffusion for image inverse problem solving", "link_suffix": "/forum?id=mZfBRjMWq0", "link": "https://openreview.net/forum?id=mZfBRjMWq0", "pdf_link": "https://openreview.net/pdf?id=mZfBRjMWq0", "keywords": "diffusion model, discrete diffusion model, inverse problems, categorical data", "abstract": "Recent literature has effectively utilized diffusion models trained on continuous variables as priors for solving inverse problems. Notably, discrete diffusion models with discrete latent codes have shown strong performance, particularly in modalities suited for discrete compressed representations, such as image and motion generation. However, their discrete and non-differentiable nature has limited their application to inverse problems formulated in continuous spaces. This paper presents a novel method for addressing linear inverse problems by leveraging image-generation models based on discrete diffusion as priors. We overcome these limitations by approximating the true posterior distribution with a variational distribution constructed from categorical distributions and continuous relaxation techniques. Furthermore, we employ a star-shaped noise process to mitigate the drawbacks of traditional discrete diffusion models with absorbing states, demonstrating that our method performs comparably to continuous diffusion techniques. To the best of our knowledge, this is the first approach to use discrete diffusion model-based priors for solving image inverse problems.", "title_embedding_index": 7416, "title_abs_embedding_index": 7441}, {"title": "Causal Graph Learning via Distributional Invariance of Cause-Effect Relationship", "link_suffix": "/forum?id=Lxst78Rrwj", "link": "https://openreview.net/forum?id=Lxst78Rrwj", "pdf_link": "https://openreview.net/pdf?id=Lxst78Rrwj", "keywords": "Causal Graph Learning, Invariance", "abstract": "This paper introduces a new framework for recovering causal graphs from observational data, leveraging the fact that the distribution of an effect, conditioned on its causes, remains invariant to changes in the prior distribution of those causes. This insight enables a direct test for potential causal relationships by checking the variance of their corresponding effect-cause conditional distributions across multiple downsampled subsets of the data. These subsets are selected to reflect different prior cause distributions, while preserving the effect-cause conditional relationships. Using this invariance test and exploiting an (empirical) sparsity of most causal graphs, we develop an algorithm that efficiently uncovers causal relationships with quadratic complexity in the number of observational features/variables, reducing the processing time by up to 25x compared to state-of-the-art methods. Our empirical studies on a diverse benchmark of large-scale datasets demonstrate that the developed algorithm consistently performs better or comparable to existing works while generally achieving better scalability.", "title_embedding_index": 7417, "title_abs_embedding_index": 7442}, {"title": "Preference Discerning in Generative Sequential Recommendation", "link_suffix": "/forum?id=3ZDMQGQgkE", "link": "https://openreview.net/forum?id=3ZDMQGQgkE", "pdf_link": "https://openreview.net/pdf?id=3ZDMQGQgkE", "keywords": "Generative Retrieval, Sequential Recommendation, Preference Discerning, LLM", "abstract": "Sequential recommendation systems aim to provide personalized recommendations for users based on their interaction history. To achieve this, they often incorporate auxiliary information, such as textual descriptions of items and auxiliary tasks, like predicting user preferences and intent. Despite numerous efforts to enhance these models, they still suffer from limited personalization. To address this issue, we propose a new paradigm, which we termpreference discerning. Inpreference discerning, we explicitly condition a generative sequential recommendation system on user preferences within its context. The user preferences are generated by large language models (LLMs) based on user reviews. To evaluatepreference discerningcapabilities of sequential recommendation systems, we introduce a novel benchmark that provides a holistic evaluation across various scenarios, including preference steering and sentiment following. We assess current state-of-the-art methods using our benchmark and show that they struggle to accurately discern user preferences. Therefore, we propose a new method named Mender (Multimodal preferencediscerner), which improves upon existing methods and achieves state-of-the-art performance on our benchmark. Our results show that Mender can be effectively guided by human preferences, paving the way toward more personalized sequential recommendation systems. We will open-source the code and benchmarks upon publication.", "title_embedding_index": 7418, "title_abs_embedding_index": 7443}, {"title": "A Simple yet Effective\u0394\u0394GPredictor is An Unsupervised Antibody Optimizer and Explainer", "link_suffix": "/forum?id=IxmWIkcKs5", "link": "https://openreview.net/forum?id=IxmWIkcKs5", "pdf_link": "https://openreview.net/pdf?id=IxmWIkcKs5", "keywords": "Mutation Effect Prediction, Mutation Preference Explanation, Unsupervised Protein Evolution", "abstract": "The proteins that exist today have been optimized over billions of years of natural evolution, during which nature creates random mutations and selects them. The discovery of functionally promising mutations is challenged by the limited evolutionary accessible regions, i.e., only a small region on the fitness landscape is beneficial. There have been numerous priors used to constrain protein evolution to regions of landscapes with high-fitness variants, among which the change in binding free energy ($\\Delta\\Delta G$) of protein complexes upon mutations is one of the most commonly used priors. However, the huge mutation space poses two challenges: (1) how to improve the efficiency of $\\Delta\\Delta G$ prediction for fast mutation screening; and (2) how to explain mutation preferences and efficiently explore accessible evolutionary regions. To address these challenges, we propose a lightweight $\\Delta\\Delta G$ predictor (Light-DDG), which adopts a structure-aware Transformer as the backbone and enhances it by knowledge distilled from existing powerful but computationally heavy $\\Delta\\Delta G$ predictors. Additionally, we augmented, annotated, and released a large-scale dataset containing millions of mutation data for pre-training Light-DDG. We find that such a simple yet effective Light-DDG can serve as a good unsupervised antibody optimizer and explainer. For the target antibody, we propose a novel Mutation Explainer to learn mutation preferences, which accounts for the marginal benefit of each mutation per residue. To further explore accessible evolutionary regions, we conduct preference-guided antibody optimization and evaluate antibody candidates quickly using Light-DDG to identify desirable mutations. Extensive experiments have demonstrated the effectiveness of Light-DDG in terms of test generalizability, noise robustness, and inference practicality, e.g., 89.7$\\times$ inference acceleration and 15.45% performance gains over previous state-of-the-art baselines. A case study of SARS-CoV-2 further demonstrates the crucial role of Light-DDG for mutation explanation and antibody optimization.", "title_embedding_index": 7419, "title_abs_embedding_index": 7444}, {"title": "Identifying latent state transitions in non-linear dynamical systems", "link_suffix": "/forum?id=d16mJDyQN6", "link": "https://openreview.net/forum?id=d16mJDyQN6", "pdf_link": "https://openreview.net/pdf?id=d16mJDyQN6", "keywords": "nonlinear ica, identifiability, disentanglement, dynamical systems", "abstract": "This work improves generalization and interpretability of dynamical systems by recovering the underlying lower-dimensional latent states and their time evolution. Previous work on disentangled representation learning within the realm of dynamical systems focused on the latent states, possibly with linear transition approximations. As such, they cannot identify nonlinear transition dynamics, and hence fail to reliably predict complex future behavior. Inspired by the advances in nonlinear ICA, we propose a state-space modeling framework in which we can identify not just the latent states but also the unknown transition function that maps the past states to the present. Our identifiability theory relies on two key assumptions: (i) sufficient variability in the latent noise, and (ii) the bijectivity of the augmented transition function. Drawing from this theory, we introduce a practical algorithm based on variational auto-encoders. We empirically demonstrate that it can (i) recover latent state dynamics with high accuracy, (ii) correspondingly achieve high future prediction accuracy, and (iii) adapt fast to new environments. Additionally, for complex real-world dynamics, (iv) it produces state-of-the-art future prediction results for long horizons, highlighting its usefulness for practical scenarios.", "title_embedding_index": 7420, "title_abs_embedding_index": 7445}, {"title": "TSTTC: A Large-Scale Dataset for Time-to-Contact Estimation in Driving Scenarios", "link_suffix": "/forum?id=ubuGgIPVD0", "link": "https://openreview.net/forum?id=ubuGgIPVD0", "pdf_link": "https://openreview.net/pdf?id=ubuGgIPVD0", "keywords": "Time-to-Contact Estimation, Dataset", "abstract": "Time-to-Contact (TTC) estimation is a critical task for assessing collision risk and is widely used in various driver assistance and autonomous driving systems. The past few decades have witnessed development of related theories and algorithms. The prevalent learning-based methods call for a large-scale TTC dataset in real-world scenarios. In this work, we present a large-scale object oriented TTC dataset in the driving scene for promoting the TTC estimation by a monocular camera. To collect valuable samples and make data with different TTC values relatively balanced, we go through thousands of hours of driving data and select over 200K sequences with a preset data distribution. To augment the quantity of small TTC cases, we also generate clips using the latest Neural rendering methods. Additionally, we provide several simple yet effective TTC estimation baselines and evaluate them extensively on the proposed dataset to demonstrate their effectiveness.", "title_embedding_index": 7421, "title_abs_embedding_index": 7446}, {"title": "Splitting & Integrating: Out-of-Distribution Detection via Adversarial Gradient Attribution", "link_suffix": "/forum?id=D0hd7YA0fP", "link": "https://openreview.net/forum?id=D0hd7YA0fP", "pdf_link": "https://openreview.net/pdf?id=D0hd7YA0fP", "keywords": "Out-of-Distribution Detection, Adversarial Gradient Attribution, Safety", "abstract": "Out-of-distribution (OOD) detection is essential for enhancing the robustness and security of deep learning models in unknown and dynamic data environments. Gradient-based OOD detection methods, such as GAIA, analyse the explanation pattern representations of in-distribution (ID) and OOD samples by examining the sensitivity of model outputs w.r.t. model inputs, resulting in superior performance compared to traditional OOD detection methods. However, we argue that the non-zero gradient behaviors of OOD samples do not exhibit significant distinguishability, especially when ID samples are perturbed by random noise in high-dimensional spaces, which negatively impacts the accuracy of OOD detection. In this paper, we propose a novel OOD detection method calledS & Ibased on layerSplitting and gradientIntegration via Adversarial Gradient Attribution. Specifically, our approach involves splitting the model's intermediate layers and iteratively updating adversarial examples layer-by-layer. We then integrate the attribution gradients from each intermediate layer along the attribution path from adversarial examples to the actual input, yielding true explanation pattern representations for both ID and OOD samples. Experiments demonstrate that our S & I algorithm achieves state-of-the-art results, with the average FPR95 of 29.05% (38.61%) and 37.31% on the CIFAR100 and ImageNet benchmarks, respectively. Our code is available at:https://anonymous.4open.science/r/S-I-F6F7/.", "title_embedding_index": 7422, "title_abs_embedding_index": 7447}, {"title": "Lyapunov Stability Learning with Nonlinear Control via Inductive Biases", "link_suffix": "/forum?id=gvk3XEjxIc", "link": "https://openreview.net/forum?id=gvk3XEjxIc", "pdf_link": "https://openreview.net/pdf?id=gvk3XEjxIc", "keywords": "Lyapunov Stability, Self-supervised Learning, Region of Attraction, Nonlinear Dynamics", "abstract": "Finding a control Lyapunov function (CLF) in a dynamical system with a controller is an effective way to guarantee stability, which is a crucial issue in safety-concerned applications. Recently, deep learning models representing CLFs have been applied into a learner-verifier framework to identify satisfiable candidates. However, the learner treats Lyapunov conditions as complex constraints for optimisation, which is hard to achieve global convergence. It is also too complicated to implement these Lyapunov conditions for verification. To improve this framework, we treat Lyapunov conditions as inductive biases and design a neural CLF and a CLF-based controller guided by this knowledge. This design enables a stable optimisation process with limited constraints, and allows end-to-end learning of both the CLF and the controller. Our approach achieves higher convergence rate and larger region of attraction (ROA) in learning the CLF compared to existing methods among abundant experiment cases. We also thoroughly reveal why the success rate decreases with previous methods during learning.", "title_embedding_index": 7423, "title_abs_embedding_index": 7448}, {"title": "On the Mode-Seeking Properties of Langevin Dynamics", "link_suffix": "/forum?id=VvHVLVUD6m", "link": "https://openreview.net/forum?id=VvHVLVUD6m", "pdf_link": "https://openreview.net/pdf?id=VvHVLVUD6m", "keywords": "Langevin dynamics, convergence analysis, mixture distribution, mode-seeking", "abstract": "The Langevin Dynamics framework, which aims to generate samples from the score function of a probability distribution, is widely used for analyzing and interpreting score-based generative modeling. While the convergence behavior of Langevin Dynamics under unimodal distributions has been extensively studied in the literature, in practice the data distribution could consist of multiple distinct modes. In this work, we investigate Langevin Dynamics in producing samples from multimodal distributions and theoretically study its mode-seeking properties. We prove that under a variety of sub-Gaussian mixtures, Langevin Dynamics is unlikely to find all mixture components within a sub-exponential number of steps in the data dimension. To reduce the mode-seeking tendencies of Langevin Dynamics, we propose Chained Langevin Dynamics, which divides the data vector into patches of constant size and generates every patch sequentially conditioned on the previous patches. We perform a theoretical analysis of Chained Langevin Dynamics by reducing it to sampling from a constant-dimensional distribution. We present the results of several numerical experiments on synthetic and real image datasets, supporting our theoretical results on the iteration complexities of sample generation from mixture distributions using the chained and vanilla Langevin Dynamics.", "title_embedding_index": 7424, "title_abs_embedding_index": 7449}]
[
    {
        "title": "RetrievalAttention: Accelerating Long-Context LLM Inference via Vector Retrieval",
        "link_suffix": "/forum?id=qBpYqQUFPx",
        "link": "https://openreview.net/forum?id=qBpYqQUFPx",
        "pdf_link": "https://openreview.net/pdf?id=qBpYqQUFPx",
        "keywords": "Large Language Model; Efficient Inference; Long Context; Vector Retrieval",
        "abstract": "Transformer-based Large Language Models (LLMs) have become increasingly important. However, due to the quadratic time complexity of attention computation, scaling LLMs to longer contexts incurs extremely slow inference speed and high GPU memory consumption for caching key-value (KV) vectors. This paper proposes RetrievalAttention, a training-free approach to both accelerate attention computation and reduce GPU memory consumption. By leveraging the dynamic sparsity of attention mechanism, RetrievalAttention proposes to build approximate nearest neighbour search (ANNS) indexes for KV vectors in CPU memory and retrieve the most relevant ones through vector search during generation. Unfortunately, we observe that the off-the-shelf ANNS indexes are often ineffective for such retrieval tasks due to the out-of-distribution (OOD) between query vectors and key vectors in the attention mechanism. RetrievalAttention addresses the OOD challenge by designing an attention-aware vector search algorithm that can adapt to the distribution of query vectors. Our evaluation demonstrates that RetrievalAttention achieves near full attention accuracy while only requiring access to 1\u20133% of the data. This leads to a significant reduction in the inference cost of long-context LLMs, with a much lower GPU memory footprint. In particular, RetrievalAttention only needs a single NVIDIA RTX4090 (24GB) to serve 128K tokens for LLMs with 8B parameters, which is capable of generating one token in 0.188 seconds."
    },
    {
        "title": "CoVT-CXR: Building Chain of Visual Thought for Interpretable Chest X-Ray Diagnosis",
        "link_suffix": "/forum?id=myZNJSpiK1",
        "link": "https://openreview.net/forum?id=myZNJSpiK1",
        "pdf_link": "https://openreview.net/pdf?id=myZNJSpiK1",
        "keywords": "chain of visual thought, multimodal understanding, fine-grained dataset, medical report generation, interpretable LLM.",
        "abstract": "Though clinical report generation demonstrates the potential to improve the efficiency of radiologist workflow and benefits the under-served regions, automated analysis of radiographs suffers from un-interpretable progress and inaccurate results. To this end, we propose a novel Chain-of-Visual-Thought (CoVT) to emulate doctors' multi-modal reasoning, enabling more interpretable and accurate CXR diagnostic predictions with explicit multi-step intermediate guidance. Specifically, we mimic the multi-modal multi-step reasoning procedure of the doctors by breaking down clinical reports into individual descriptions and connecting each rationale to corresponding visual prompts\u2014like masks, landmarks, linestrips, and bounding boxes\u2014to illuminate the visual reasoning behind radiographs. By further dividing this association into cross-modal sub-tasks, CoVT is able to exploit a multi-stage fine-tuning protocol to gradually develop the chain-of-reasoning capability. To support this approach, we introduce CoVT-CXR, the first detailed-aligned, multi-step cross-modal dataset for diagnostic tasks, featuring about 3M instruction-following data points for pretraining and around 30K reasoning sequences for fine-tuning, sourced from 6K patient cases and annotated by 32 medical trainees using our tailored tool. Our CoVT-CXR covers more than 20 diseases, requiring 1 to 12 reasoning steps for diagnoses. Through a series of experiments on our CoVT-CXR, we demonstrate the advantages of the CoVT method over baseline approaches, validate the quality of our annotated data, and highlight the positive impacts of CoVT-CXR on various clinical-related tasks. Our CoVT model, annotation tool, and CoVT-CXR dataset will be fully available upon acceptance."
    },
    {
        "title": "Neural Context Flows for Meta-Learning of Dynamical Systems",
        "link_suffix": "/forum?id=8vzMLo8LDN",
        "link": "https://openreview.net/forum?id=8vzMLo8LDN",
        "pdf_link": "https://openreview.net/pdf?id=8vzMLo8LDN",
        "keywords": "meta-learning, OOD generalisation, physical sciences, neural ODEs",
        "abstract": "Neural Ordinary Differential Equations (NODEs) often struggle to adapt to new dynamic behaviors caused by parameter changes in the underlying system, even when these dynamics are similar to previously observed behaviors. This problem becomes more challenging when the changing parameters are unobserved, meaning their value or influence cannot be directly measured when collecting data. To address this issue, we introduce Neural Context Flow (NCF), a robust and interpretable Meta-Learning framework that includes uncertainty estimation. NCF uses $k$-th order Taylor expansion to enable contextual self-modulation, allowing context vectors to influence dynamics from other domains while also modulating themselves. After establishing convergence guarantees, we empirically test NCF and compare it to related adaptation methods. Our results show that NCF achieves state-of-the-art Out-of-Distribution performance on 5 out of 6 linear and non-linear benchmark problems. Through extensive experiments, we explore the flexible model architecture of NCF and the encoded representations within the learned context vectors. Our findings highlight the potential implications of NCF for foundational models in the physical sciences, offering a promising approach to improving the adaptability and generalization of NODEs in various scientific applications. Our code is openly available at \\url{AnonymousGithubRepo}."
    },
    {
        "title": "Weak-to-Strong Preference Optimization: Stealing Reward from Weak Aligned Model",
        "link_suffix": "/forum?id=f7KxfUrRSb",
        "link": "https://openreview.net/forum?id=f7KxfUrRSb",
        "pdf_link": "https://openreview.net/pdf?id=f7KxfUrRSb",
        "keywords": "weak-to-strong, model alignment",
        "abstract": "Aligning language models (LMs) with human preferences has become a key area of research, enabling these models to meet diverse user needs better. Inspired by weak-to-strong generalization, where a strong LM fine-tuned on labels generated by a weaker model can consistently outperform its weak supervisor, we extend this idea to model alignment. In this work, we observe that the alignment behavior in weaker models can be effectively transferred to stronger models and even exhibit an amplification effect. Based on this insight, we propose a method called Weak-to-Strong Preference Optimization (WSPO), which achieves strong model alignment by learning the distribution differences before and after the alignment of the weak model. Experiments demonstrate that WSPO delivers outstanding performance, improving the win rate of Qwen2-7B-Instruct on Arena-Hard from 39.70 to 49.60, achieving a remarkable 47.04 length-controlled win rate on AlpacaEval 2, and scoring 7.33 on MT-bench. Our results suggest that using the weak model to elicit a strong model with a high alignment ability is feasible."
    },
    {
        "title": "LATABLE: TOWARDS LARGE TABULAR MODELS",
        "link_suffix": "/forum?id=oFIU5CBY9p",
        "link": "https://openreview.net/forum?id=oFIU5CBY9p",
        "pdf_link": "https://openreview.net/pdf?id=oFIU5CBY9p",
        "keywords": "Tabular data, generative models",
        "abstract": "Tabular data is one of the most ubiquitous data modalities, yet the literature on tabular generative foundation models is lagging behind its text and vision counterparts. Large Tabular Models (LTMs) could revolutionize the way tabular data is used: not as any single dataset analyzed in a vacuum, but contextualized using their metadata and with respect to related datasets. Creating an LTM is difficult, due to the heterogeneous feature spaces of different tabular datasets, metadata, and prior knowledge. In this work, we propose LaTable: a novel tabular diffusion model that addresses these challenges. We show LaTable can be trained across tabular datasets. Through extensive experiments, we find that LaTable displays early signs of scaling laws previously encountered in foundation model regimes. Moreover, LaTable outperform baselines in out-of-distribution few-shot data generation."
    },
    {
        "title": "Efficiently Deploying LLMs with Controlled Risk",
        "link_suffix": "/forum?id=BjZP3fTlVg",
        "link": "https://openreview.net/forum?id=BjZP3fTlVg",
        "pdf_link": "https://openreview.net/pdf?id=BjZP3fTlVg",
        "keywords": "natural language processing, selective prediction, uncertainty quantification, large language models, compound AI systems",
        "abstract": "Deploying large language models in production requires simultaneous attention to efficiency and risk control. Prior work has shown the possibility to cut costs while maintaining similar accuracy, but has neglected to focus on risk control. By contrast, here we present hierarchical chains with multi-level abstention (HCMA), which use model-intrinsic uncertainty to delegate queries along the LLM intelligence hierarchy, enabling training-free model switching based solely on black-box API calls. Our framework presents novel trade-offs between efficiency and risk. For example, deploying HCMA on MMLU cuts the error rate of Llama3 405B by 30% when the model is allowed to abstain on 20% of the queries. To calibrate HCMA for optimal performance, our approach uses data-efficient logistic regressions (based on a simple nonlinear feature transformation), which require only 50 or 100 labeled examples to achieve excellent calibration error (ECE), cutting ECE by 50% compared to naive Platt scaling. On free-form generation tasks, we find that chain-of-thought is ineffectual for selective prediction, whereas zero-shot prompting yields drives error to 0% on TruthfulQA at high abstention rates. As LLMs are increasingly deployed across computing environments with different capabilities (such as mobile, laptop, and cloud), our framework paves the way towards maintaining deployment efficiency while putting in place sharp risk controls."
    },
    {
        "title": "Concept forgetting via label annealing",
        "link_suffix": "/forum?id=2L7KQ4qbHi",
        "link": "https://openreview.net/forum?id=2L7KQ4qbHi",
        "pdf_link": "https://openreview.net/pdf?id=2L7KQ4qbHi",
        "keywords": "Concept forgetting, Privacy, Bias, Computer Vision (CV)",
        "abstract": "The effectiveness of current machine learning models relies on their ability to grasp diverse concepts present in datasets. However, biased and noisy data can inadvertently cause these models to be biased toward certain concepts, undermining their ability to generalize and provide utility. Consequently, modifying a trained model to forget these concepts becomes imperative for their responsible deployment. We refer to this problem asconcept forgetting. Our goal is to develop techniques for forgetting specific undesired concepts from a pre-trained classification model's prediction. To achieve this goal, we present an algorithm calledLabelANnealing (LAN). This iterative algorithm employs a two-stage method for each iteration. In the first stage, pseudo-labels are assigned to the samples by annealing or redistributing the original labels based on the current iteration's model predictions of all samples in the dataset. During the second stage, the model is fine-tuned on the dataset with pseudo-labels. We illustrate the effectiveness of the proposed algorithms across various models and datasets. Our method reducesconcept violation, a metric that measures how much the model forgets specific concepts, by about 85.35% on the MNIST dataset, 73.25% on the CIFAR-10 dataset, and 69.46% on the CelebA dataset while maintaining high model accuracy. Our  implementation can be found at this following link: \\url{https://anonymous.4open.science/r/LAN-141B/}"
    },
    {
        "title": "UNIFYING LONG AND SHORT SPATIO-TEMPORAL FORECASTING WITH SPECTRAL GRAPH NEURAL NETWORKS",
        "link_suffix": "/forum?id=uiyljVIP0k",
        "link": "https://openreview.net/forum?id=uiyljVIP0k",
        "pdf_link": "https://openreview.net/pdf?id=uiyljVIP0k",
        "keywords": "multivariate time series forecasting, spatio-temporal graph neural network, spectral graph neural network",
        "abstract": "Multivariate Time Series (MTS) forecasting plays a vital role in various practical applications. Current research in this area is categorized into Spatial-Temporal Forecasting (STF) and Long-term Time Series Forecasting (LTSF). While these tasks share similarities, the methods and benchmarks used differ significantly. Spatio-Temporal Graph Neural Networks (STGNNs) excel at modeling interrelationships in STF tasks but face difficulties with long sequence inputs due to inefficient training. In contrast, LTSF models handle long sequences well but struggle with capturing complex variable interrelationships. This paper proposes the Spectral Spatio-Temporal Graph Neural Network (S2GNN) to address these challenges, unifying short- and long-sequence spatio-temporal forecasting within a single framework. S2GNN leverages spectral GNNs for global feature extraction incorporates an adaptive graph structure to manage varying sequence lengths and adopts a decoupled framework to improve scalability. Additionally, we introduce scale-adaptive node embeddings and cross-correlation embeddings for better differentiation between similar temporal patterns. Extensive experiments on eight public datasets, including both STF and LTSF datasets, demonstrate that S2GNN consistently outperforms state-of-the-art models across diverse prediction tasks. Code is available at \\url{https://anonymous.4open.science/r/S2GNN-B21D}."
    },
    {
        "title": "Decoding Reading Goals from Eye Movements",
        "link_suffix": "/forum?id=ZjuEPZJsa3",
        "link": "https://openreview.net/forum?id=ZjuEPZJsa3",
        "pdf_link": "https://openreview.net/pdf?id=ZjuEPZJsa3",
        "keywords": "application of language models to cognitive science and psycholinguistic, eye movements in reading, reading goals, cognitive state decoding, multimodal models (eye movements and text)",
        "abstract": "Readers can have different goals with respect to the text they are reading. Can these goals be decoded from the pattern of their eye movements over the text? In this work, we examine for the first time whether it is possible to decode two types of reading goals that are common in daily life: information seeking and ordinary reading. Using large scale eye-tracking data, we apply to this task a wide range of state-of-the-art models for eye movements and text that cover different architectural and data representation strategies, and further introduce a new model ensemble. We systematically evaluate these models at three levels of generalization: new textual item, new participant, and the combination of both. We find that eye movements contain highly valuable signals for this task. We further perform an error analysis which builds on prior empirical findings on differences between ordinary reading and information seeking and leverages rich textual annotations. This analysis reveals key properties of textual items and participant eye movements that contribute to the difficulty of the task."
    },
    {
        "title": "Density estimation with LLMs: a geometric investigation of in-context learning trajectories",
        "link_suffix": "/forum?id=semTHoVGsJ",
        "link": "https://openreview.net/forum?id=semTHoVGsJ",
        "pdf_link": "https://openreview.net/pdf?id=semTHoVGsJ",
        "keywords": "Large language models, in-context learning, Intensive Principal Component Analysis, density estimation, Mechanistic  interpretations, High-dimensional learning dynamics, dimensionality reduction",
        "abstract": "Large language models (LLMs) demonstrate remarkable emergent abilities to perform in-context learning across various tasks, including time series forecasting. \nThis work investigates LLMs' ability to estimate probability density functions (PDFs) from data observed in-context; \nsuch density estimation (DE) is a fundamental task underlying many probabilistic modeling problems. \nWe leverage the Intensive Principal Component Analysis (InPCA) to visualize and analyze the in-context learning dynamics of LLaMA-2 models. \nOur main finding is that these LLMs all follow similar learning trajectories in a low-dimensional InPCA space, which are distinct from those of traditional density estimation methods like histograms and Gaussian kernel density estimation (KDE). \nWe interpret the LLaMA in-context DE process as a KDE with an adaptive kernel width and shape. \nThis custom kernel model captures a significant portion of LLaMA's behavior despite having only two parameters. \nWe further speculate on why LLaMA's kernel width and shape differs from classical algorithms, providing insights into the mechanism of in-context probabilistic reasoning in LLMs."
    },
    {
        "title": "Inverted Activations: Reducing Memory Footprint in Neural Network Training",
        "link_suffix": "/forum?id=Ng1r9kTep4",
        "link": "https://openreview.net/forum?id=Ng1r9kTep4",
        "pdf_link": "https://openreview.net/pdf?id=Ng1r9kTep4",
        "keywords": "deep learning, large language models",
        "abstract": "The scaling of neural networks with increasing data and model sizes necessitates the development of more efficient deep learning algorithms. \n    A significant challenge in neural network training is the memory footprint associated with activation tensors, particularly in pointwise nonlinearity layers that traditionally save the entire input tensor for the backward pass, leading to substantial memory consumption.In this paper, we propose a modification to the handling of activation tensors in pointwise nonlinearity layers. \nOur method involves saving the output tensor instead of the input tensor during the forward pass. Since the subsequent layer typically also saves its input tensor, this approach reduces the total memory required by storing only one tensor between layers instead of two. This optimization is especially beneficial for transformer-based architectures like GPT, BERT, Mistral, and Llama.\n\nTo enable this approach, we utilize the inverse function of the nonlinearity during the backward pass. As the inverse cannot be computed analytically for most nonlinearities, we construct accurate approximations using simpler functions. \nExperimental results demonstrate that our method significantly reduces memory usage without affecting training accuracy or computational performance.\n\nOur implementation is provided as a drop-in replacement for standard nonlinearity layers in the PyTorch framework, facilitating easy adoption without requiring architectural modifications. The code is available at \\url{https://github.com/removed/for/anonimity}."
    },
    {
        "title": "Multimodal Quantitative Language for Generative Recommendation",
        "link_suffix": "/forum?id=v7YrIjpkTF",
        "link": "https://openreview.net/forum?id=v7YrIjpkTF",
        "pdf_link": "https://openreview.net/pdf?id=v7YrIjpkTF",
        "keywords": "Recommendation System, Generative Recommendation",
        "abstract": "Generative recommendation has emerged as a promising paradigm aiming at directly generating the identifiers of the target candidates.\nMost existing methods attempt to leverage prior knowledge embedded in Pre-trained Language Models (PLMs) to improve the recommendation performance. However, they often fail to accommodate the differences between the general linguistic knowledge of PLMs and the specific needs of recommendation systems. Moreover, they rarely consider the complementary knowledge between the multimodal information of items, which represents the multi-faceted preferences of users.  To facilitate efficient recommendation knowledge transfer, we propose a novel approach called Multimodal Quantitative Language for Generative Recommendation (MQL4GRec). Our key idea is to transform items from different domains and modalities into a unified language, which can serve as a bridge for transferring recommendation knowledge. Specifically, we first introduce quantitative translators to convert the text and image content of items from various domains into a new and concise language, known as quantitative language, with all items sharing the same vocabulary. Then, we design a series of quantitative language generation tasks to enrich quantitative language with semantic information and prior knowledge.  Finally, we achieve the transfer of recommendation knowledge from different domains and modalities to the recommendation task through pre-training and fine-tuning. We evaluate the effectiveness of MQL4GRec through extensive experiments and comparisons with existing methods, achieving improvements over the baseline by 11.18%, 14.82%, and 7.95% on the NDCG metric across three different datasets, respectively. Our implementation is available at: \\href{https://anonymous.4open.science/r/QL4GRec-ED65/}{\\textcolor{blue}{https://anonymous.4open.science/r/MQL4GRec-ED65/}.}"
    },
    {
        "title": "Fixed Strength Optimization Enhances Adversarial Attacks",
        "link_suffix": "/forum?id=llFXOrEbG5",
        "link": "https://openreview.net/forum?id=llFXOrEbG5",
        "pdf_link": "https://openreview.net/pdf?id=llFXOrEbG5",
        "keywords": "Adversarial examples, Attack efficiency\uff0c Transferability\uff0cPerturbation imperceptibility\uff0cDistance metric, Multi-step optimization",
        "abstract": "Gradient-based multi-step iteration has been widely used to enhance attack efficiency of adversarial examples. In this work, we propose a $\\textit{Fixed Strength Optimization}$ (FSO) method to accelerate the convergence of adversarial examples with a fixed preset attack strength. FSO can be easily combined with existing attack techniques to achieve fast convergence and well-controlled attack strength. We further introduce a combined norm based on $L_{2}$ and $L_{\\infty}$ norms to modulate the attacking direction. This combined norm can help to balance the attack strength in the directions of semantic information and noise components in the model gradients on sample data. By incorporating the combined norm into FSO, our numerical experiments show improved attack transferability and high imperceptibility of perturbations."
    },
    {
        "title": "Coreset Spectral Clustering",
        "link_suffix": "/forum?id=1qgZXeMTTU",
        "link": "https://openreview.net/forum?id=1qgZXeMTTU",
        "pdf_link": "https://openreview.net/pdf?id=1qgZXeMTTU",
        "keywords": "spectral clustering, kernel k-means, coresets",
        "abstract": "Coresets have become an invaluable tool for solving $k$-means and kernel $k$-means clustering problems on large datasets with small numbers of clusters. On the other hand, spectral clustering works well on sparse graphs and has recently been extended to scale efficiently to large numbers of clusters. We exploit the connection between kernel $k$-means and the normalised cut problem to combine the benefits of both. Our main result is a coreset spectral clustering algorithm for graphs that clusters a coreset graph to infer a good labelling of the original graph. We prove that an $\\alpha$-approximation for the normalised cut problem on the coreset graph is an $O(\\alpha)$-approximation on the original. We also improve the running time of the state-of-the-art coreset algorithm for kernel $k$-means on sparse kernels, from $\\tilde{O}(nk)$ to $\\tilde{O}(n d_{avg})$, where $d_{avg}$ is the average number of non-zero entries in each row of the $n\\times n$ kernel matrix. Our experiments confirm our coreset algorithm is asymptotically faster on large real-world graphs with many clusters, and show that our clustering algorithm overcomes the main challenge faced by coreset kernel $k$-means on sparse kernels which is getting stuck in local optima."
    },
    {
        "title": "Seg-LaneDet: 3D Lane Detection from Monocular Images with 2D Segmentation",
        "link_suffix": "/forum?id=CH7Ba4RFa2",
        "link": "https://openreview.net/forum?id=CH7Ba4RFa2",
        "pdf_link": "https://openreview.net/pdf?id=CH7Ba4RFa2",
        "keywords": "3D Lane Detection, Autonomous Driving, Computer Vision",
        "abstract": "Monocular 3D lane detection is a fundamental yet challenging task in autonomous driving. Recent advancements primarily rely on constructing 3D surrogates from monocular images and camera parameters. However, misalignment is introduced in current methods due to the lack of dense depth information in datasets, coupled with the inherent depth ambiguity of monocular images. To address this issue, we propose Seg-LaneDet, a simple but effective end-to-end 3D lane detector. We frame the task of 3D lane detection as an elevation from 2D to 3D detection. Specifically, we leverage a pre-trained 2D lane detector to obtain instance segmentation of lanes, of which the segmentation maps serve as the sole prior for the 2D-to-3D module. This allows us to achieve a straightforward 3D lane representation based on front-view segmentation maps. Our method demonstrates comparable performance to state-of-the-art (SOTA) F1 scores on the OpenLane and the Apollo datasets."
    },
    {
        "title": "Write More at Once: Stylized Chinese Handwriting Generation via Two-stage Diffusion",
        "link_suffix": "/forum?id=VdDtRu7RTf",
        "link": "https://openreview.net/forum?id=VdDtRu7RTf",
        "pdf_link": "https://openreview.net/pdf?id=VdDtRu7RTf",
        "keywords": "Handwritten Text Generation; Conditional Diffusion;",
        "abstract": "Handwritten data generation is an intriguing research area with broad applications in human interaction with digital documents. In Chinese handwritten text generation, practical applications necessitate the ability to produce sentence-level handwritten data to convey complex information effectively. However, existing methods mainly focus on generating single-font outputs. To tackle this challenge, we model handwritten text generation as a \\textit{style transfer problem}, aiming to convert a standard text line template into a target handwriting style. Recognizing the highly structured nature of handwritten data, we view complex text lines as compositions of individual characters and their positions. We propose a two-stage text line generation method based on generative diffusion model. In the first stage, character positions are generated using a Character-Position-Diffusion (CharPos-Diff), which, combined with standard character templates from a digital library, creates text line-level templates. In the second stage, a font style transfer diffusion model (Imitating-Diff) generates handwritten text lines directly from these templates. Our extensive experiments show that our method effectively mimics handwriting styles, generates structurally accurate text lines, and facilitates the simultaneous generation of paragraph-level handwritten text."
    },
    {
        "title": "Disentangled Representation Learning with the Gromov-Monge Gap",
        "link_suffix": "/forum?id=ehr4oTe6XI",
        "link": "https://openreview.net/forum?id=ehr4oTe6XI",
        "pdf_link": "https://openreview.net/pdf?id=ehr4oTe6XI",
        "keywords": "Disentangled Representational Learning, Optimal Transport, Geometric Learning",
        "abstract": "Learning disentangled representations from unlabelled data is a fundamental challenge in machine learning. Solving it may unlock other problems, such as generalization, interpretability, or fairness. Although remarkably challenging to solve in theory, disentanglement is often achieved in practice through prior matching. Furthermore, recent works have shown that prior matching approaches can be enhanced by leveraging geometrical considerations, e.g., by learning representations that preserve geometric features of the data, such as distances or angles between points. However, matching the prior while preserving geometric features is challenging, as a mapping thatfullypreserves these features while aligning the data distribution with the prior does not exist in general. To address these challenges, we introduce a novel approach to disentangled representation learning based on quadratic optimal transport. We formulate the problem using Gromov-Monge maps that transport one distribution onto another with minimal distortion of predefined geometric features, preserving themas much as can be achieved. To compute such maps, we propose the Gromov-Monge-Gap (GMG), a regularizer quantifying whether a map moves a reference distribution with minimal geometry distortion. We demonstrate the effectiveness of our approach for disentanglement across four standard benchmarks, outperforming other methods leveraging geometric considerations."
    },
    {
        "title": "HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks",
        "link_suffix": "/forum?id=KRdiRGSNc9",
        "link": "https://openreview.net/forum?id=KRdiRGSNc9",
        "pdf_link": "https://openreview.net/pdf?id=KRdiRGSNc9",
        "keywords": "Large Multimodal Models, Vision Language Models, Code Generation, Visual Reasoning, Visual Understanding",
        "abstract": "Coding tasks have been valuable for evaluating Large Language Models (LLMs), as they demand the comprehension of high-level instructions, complex reasoning, and the implementation of functional programs $-$ core capabilities for advancing Artificial General Intelligence. Despite the progress in Large Multimodal Models (LMMs), which extend  LLMs with visual understanding and reasoning capabilities, there remains a notable lack of coding benchmarks that rigorously assess these models, particularly in tasks that emphasize visual reasoning. To address this gap, we introduce HumanEval-V, a novel and lightweight benchmark specifically designed to evaluate LMMs' visual understanding and reasoning capabilities through code generation tasks. HumanEval-V includes 108 carefully crafted, entry-level Python coding tasks derived from platforms like CodeForces and Stack Overflow. Each task is created by modifying the context and algorithmic patterns of the original problems and redrawing the visual elements to ensure they are distinct from the source. LMMs are required to generate code solutions using the provided visual context and a predefined Python function signature that outlines the task requirements. Every coding task is equipped with meticulously crafted human-generated test cases to ensure a thorough and reliable evaluation of the model-generated code solutions. We evaluate 19 state-of-the-art LMMs using HumanEval-V, uncovering significant challenges. Proprietary models like GPT-4o achieve only 13% pass@1 and 36.4% pass@10, while open-weight models with 70B parameters score below 4% pass@1. Ablation studies further demonstrate the limitations of current LMMs in vision understanding and reasoning as well as coding abilities. These results highlight key areas for future research to improve LMMs' capabilities."
    },
    {
        "title": "Backpropagation-Free Learning through Gradient Aligned Feedbacks",
        "link_suffix": "/forum?id=oRPXPoTXYz",
        "link": "https://openreview.net/forum?id=oRPXPoTXYz",
        "pdf_link": "https://openreview.net/pdf?id=oRPXPoTXYz",
        "keywords": "backpropagation-free, direct feedback alignment, optimization, forward gradient",
        "abstract": "Deep neural networks heavily rely on the back-propagation algorithm for optimiza-\ntion. Nevertheless, the global sequential transmission of gradients in the backward\npass inhibits its scalability. The Direct Feedback Alignment algorithm has been\nproposed as a promising approach for parallel learning of deep neural networks,\nrelying on fixed random feedback weights to project the error on every layer in\na parallel manner. However, it notoriously fails to train networks that are really\ndeep and that include compulsory layers like convolutions and transformers. In this\npaper, we show that alternatives to back-propagation may greatly benefit from local\nand forward approximation of the gradient to better cope with the inherent and\nconstrained structure of such layers.This directional approximation allows us to design a novel algorithm that updates the feedback weights called GrAPE (GRadient\nAligned Projected Error). A first set of experiments are carried out on image classi-\nfication tasks with feedforward and convolutional architectures. The results show\nimportant improvement in performance over other backpropagation-free algorithms,\nnarrowing the gap with backpropagation. More importantly, the method scales\nto modern and deep architectures like AlexNet, VGG-16 and Transformer-based\nlanguage models where the performance gains are even more notable."
    },
    {
        "title": "Divergence-enhanced Knowledge-guided Context Optimization for Visual-Language Prompt Tuning",
        "link_suffix": "/forum?id=6wOmHdwCC4",
        "link": "https://openreview.net/forum?id=6wOmHdwCC4",
        "pdf_link": "https://openreview.net/pdf?id=6wOmHdwCC4",
        "keywords": "visual-language prompt tuning;few-shot learning;zero-shot learning",
        "abstract": "Prompt tuning vision-language models like CLIP has shown great potential in learning transferable representations for various downstream tasks. The main issue is how to mitigate the over-fitting problem on downstream tasks with limited training samples. While knowledge-guided context optimization (Yao et al.,2023; 2024) has been proposed by constructing consistency constraints to handle catastrophic forgetting in the pre-trained backbone, it also introduces a potential bias toward pre-training. This paper proposes a novel and simple Divergence-enhanced Knowledge-guided Prompt Tuning (DeKg) method to address this issue. The key insight is that the bias toward pre-training can be alleviated by encouraging the independence between the learnable and the crafted prompt. Specifically, DeKg employs the Hilbert-Schmidt Independence Criterion (HSIC) to regularize the learnable prompts, thereby reducing their dependence on prior general knowledge, and enabling divergence induced by target knowledge. Comprehensive evaluations demonstrate that DeKg serves as a plug-and-play module can seamlessly integrate with existing knowledge-guided methods and achieves superior performance in three challenging benchmarks."
    },
    {
        "title": "SATCH: Specialized Assistant Teacher Distillation to Reduce Catastrophic Forgetting",
        "link_suffix": "/forum?id=CSAfU7J8Gw",
        "link": "https://openreview.net/forum?id=CSAfU7J8Gw",
        "pdf_link": "https://openreview.net/pdf?id=CSAfU7J8Gw",
        "keywords": "Continual Learning, Catastrophic Forgetting, Knowledge Distillation, Class Incremental Learning",
        "abstract": "Continual learning enables models to learn new tasks sequentially without forgetting previously learned knowledge. Knowledge distillation reduces forgetting by using a single teacher model to transfer previous knowledge to the student model. However, existing methods face challenges, specifically loss of task-specific knowledge, limited diversity in the transferred knowledge, and delays in teacher availability. These issues stem from self-distillation, where the teacher is a mere snapshot of the student after learning a new task, inheriting the student\u2019s biases and becoming available only after learning a task. We propose Specialized Assistant TeaCHer distillation (SATCH), a novel method that uses a smaller assistant teacher trained exclusively on the current task. By incorporating the assistant teacher early in the learning process, SATCH provides task-specific guidance, improves the diversity of transferred knowledge, and preserves critical task-specific insights. Our method integrates seamlessly with existing knowledge distillation techniques, and experiments on three standard continual learning benchmarks show that SATCH improves accuracy by up to 12% when combined with four state-of-the-art methods. Code is available in supplementary materials."
    },
    {
        "title": "Reassessing Number-Detector Units in Convolutional Neural Networks",
        "link_suffix": "/forum?id=cYB7GvpGj9",
        "link": "https://openreview.net/forum?id=cYB7GvpGj9",
        "pdf_link": "https://openreview.net/pdf?id=cYB7GvpGj9",
        "keywords": "Feature Selection, Pruning, RSA, CNN, Numerosity",
        "abstract": "Convolutional neural networks (CNNs), including CORnet, have become essential models for predicting neural activity and behavior in visual tasks. However, their ability to capture complex cognitive functions, such as numerosity discrimination, remains a topic of debate. Numerosity\u2014the ability to perceive and estimate the number of items in a visual scene\u2014is believed to be represented by specialized 'number-detector' units within CNNs. In this study, we utilize CORnet, a specialized type of CNN inspired by brain anatomy, which also effectively captures the variance in human behavioral data, to address the limitations of classical representational similarity analysis (RSA), which assumes equal importance for all features. We apply pruning, a feature selection technique that identifies and retains the most behaviorally relevant units. Our results demonstrate that number-detector units are not critical for population-level representations of numerosity, challenging their proposed significance in previous studies. These results can have implications for both machine learning and neuroscience."
    },
    {
        "title": "Predicting Time-Varying Flux and Balance in Metabolic Systems using Structured Neural ODE Processes",
        "link_suffix": "/forum?id=FmoInsWCkp",
        "link": "https://openreview.net/forum?id=FmoInsWCkp",
        "pdf_link": "https://openreview.net/pdf?id=FmoInsWCkp",
        "keywords": "Neural ODEs, Metabolic Networks",
        "abstract": "We develop a novel data-driven framework as an alternative to dynamic flux balance analysis, bypassing the demand for deep domain knowledge and manual efforts to formulate the optimization problem. The proposed framework is end-to-end, which trains a structured neural ODE process (SNODEP) model to estimate flux and balance samples using gene-expression time-series data. SNODEP is designed to circumvent the limitations of the standard neural ODE process model, including restricting the latent and decoder sampling distributions to be normal and lacking structure between context points for calculating the latent, thus more suitable for modeling the underlying dynamics of a metabolic system. Through comprehensive experiments ($156$ in total), we demonstrate that SNODEP not only predicts the unseen time points of real-world gene-expression data and the flux and balance estimates well but can even generalize to more challenging unseen knockout configurations and irregular data sampling scenarios, all essential for metabolic pathway analysis. We hope our work can serve as a catalyst for building more scalable and powerful models for genome-scale metabolic analysis."
    },
    {
        "title": "Unsupervised Prior Learning: Discovering Categorical Pose Priors from Videos",
        "link_suffix": "/forum?id=mPyPm9mmc6",
        "link": "https://openreview.net/forum?id=mPyPm9mmc6",
        "pdf_link": "https://openreview.net/pdf?id=mPyPm9mmc6",
        "keywords": "unsupervised prior learning, unsupervised pose estimation, memory",
        "abstract": "A prior represents a set of beliefs or assumptions about a system, aiding inference and decision-making. In this work, we introduce the challenge of unsupervised prior learning in pose estimation, where AI models learn pose priors of animate objects from videos in a self-supervised manner. These videos present objects performing various actions, providing crucial information about their keypoints and connectivity.\nWhile priors are effective in pose estimation, acquiring them can be difficult. We propose a novel method, named Pose Prior Learner (PPL), to learn general pose priors applicable to any object category. PPL uses a hierarchical memory to store compositional parts of prototypical poses, from which we distill a general pose prior. This prior enhances pose estimation accuracy through template transformation and image reconstruction. PPL learns meaningful pose priors without any additional human annotations or interventions, outperforming competitive baselines on both human and animal pose estimation datasets. Notably, our experimental results reveal the effectiveness of PPL using learnt priors for pose estimation on occluded images. Through iterative inference, PPL leverages priors to refine estimated poses, regressing them to any prototypical poses stored in memory. Our code, model, and data will be publicly available."
    },
    {
        "title": "Language Model for Large-Text Transmission in Noisy Quantum Communications",
        "link_suffix": "/forum?id=TgTxJALwDz",
        "link": "https://openreview.net/forum?id=TgTxJALwDz",
        "pdf_link": "https://openreview.net/pdf?id=TgTxJALwDz",
        "keywords": "Language Model; Noisy Superdense Coding; Text Transmission",
        "abstract": "Quantum communication has the potential to revolutionise information processing, providing unparalleled security and increased capacity compared to its classical counterpart by using the principles of quantum mechanics. However, the presence of errors poses a significant challenge to realising these advantages. While strategies like quantum error correction and quantum error mitigation have been developed to address these errors, they often come with substantial overhead, hindering the practical transmission of large texts. Here, we introduce an application of machine learning frameworks for natural language processing to enhence the performance of noisy quantum communications, particularly superdense coding. Using BERT, a model known for its capabilities in natural language processing, we demonstrate that language-model-assisted quantum communication protocols can substantially improve the efficiency of large-scale information transmission. This brings us closer to the practical realisation of a quantum internet."
    }
]
[
    {
        "title": "Hypergraph-Based Machine Learning for Robust Handling of Missing Data",
        "link_suffix": "/forum?id=jBpEsliki9",
        "link": "https://openreview.net/forum?id=jBpEsliki9",
        "pdf_link": "https://openreview.net/pdf?id=jBpEsliki9",
        "keywords": "Hypergraph, Machine Learning, Missing Data",
        "abstract": "Handling missing data is a major challenge in machine learning where missing values are common in datasets. This work introduces a hypergraph representation constructed from datasets containing missing values. The method does not rely on traditional techniques like deletion or data imputations. The approach constructs hypergraphs directly from the dataset, preserving the relationships between variables and modeling multi-variable interactions. This enables the model to capture the dataset structure in ways other methods may overlook. The proposed hypergraph learning method can be applied to classification and regression tasks. For real-world evaluation, we use the MIMIC-III and Adult datasets focusing on classification performance. Additionally, synthetic datasets with controlled missingness are used to evaluate the method's effectiveness across varying degrees of missingness. When compared with imputation and prediction techniques, the hypergraph approach achieves competitive or superior performance. Specifically, our method maintains high performance in scenarios with significant levels of missing data. We demonstrate that the hypergraph representation not only offers a more resilient framework for learning from datasets with missing data. But also scales effectively across diverse datasets and prediction tasks. The method maintains stable performance under various degrees of missingness, demonstrating its potential as a valuable machine learning tool with high data reliability and prediction quality."
    },
    {
        "title": "CAB-KGC: Context-Aware BERT for Knowledge Graph Completion",
        "link_suffix": "/forum?id=lBrLDC7qXF",
        "link": "https://openreview.net/forum?id=lBrLDC7qXF",
        "pdf_link": "https://openreview.net/pdf?id=lBrLDC7qXF",
        "keywords": "Knowledge Graph Completion (KGC), Tail Prediction, Context-Aware BERT (CAB-KGC), Large Language Models (LLMs), BERT",
        "abstract": "Knowledge graph completion (KGC) addresses the challenge of predicting missing entities (i.e., heads, tails) or relationships in knowledge graphs (KGs), which often suffer from incomplete data. While traditional embedding-based methods, like TransE and ComplEx, have improved tail entity prediction, these techniques struggle with unseen entities at test. Textual-based models leverage additional context and semantics about entities and relationships to address the issue, but their dependence on negative triplet sampling incurs high computational cost, semantic inconsistency, and data imbalance. Recent LLM-based models, such as KG-BERT, offer improvements but depend on entity descriptions, which are often unavailable in KGs. Furthermore, most approaches ignore crucial contextual information from related nodes and relationships. In this study, we introduce Context-Aware BERT for Knowledge Graph Completion (CAB-KGC) model that overcomes these limitations by leveraging the contextual information from neighbouring entities and relationships to predict tail entities. CAB-KGC eliminates the need for entity descriptions and negative triplet sampling, reducing computation while improving performance. Additionally, we introduce, for the first time, the use of the Evaluation based on Distance from Average Solution (EDAS) criterion in KG domain, offering a more comprehensive assessment across various performance metrics. Experiments on various standard datasets, including FB15k-237 and WN18RR, show that CAB-KGC outperforms state-of-the-art methods. Specifically, CAB-KGC improves Hit@1 by 5.3% and 4.88% on FB15k-237 and WN18RR respectively.  The EDAS criterion further ranks CAB-KGC as the top-performing model on both datasets."
    },
    {
        "title": "Multi-Fidelity Fine-Tuning of Pre-Trained Language Models",
        "link_suffix": "/forum?id=KGhkIySg3h",
        "link": "https://openreview.net/forum?id=KGhkIySg3h",
        "pdf_link": "https://openreview.net/pdf?id=KGhkIySg3h",
        "keywords": "language models, foundation models, multi-fidelity, learning with noisy labels, fine-tuning",
        "abstract": "We consider the problem of fine-tuning pre-trained language models with a small amount of trusted data (high-fidelity) and a larger amount of data with noisy labels (low-fidelity). We propose Multi-Fidelity Fine-Tuning (MFFT), a novel approach which implicitly determines for new inputs when we can rely on information from high-fidelity data and when instead we need to fall back on knowledge from low-fidelity data. MFFT does not require any architecture changes to the base model and simply provides its fine-tuned version that can be easily deployed for inference. We extensively benchmark MFFT on various classification tasks against several baselines, with both simulated label noise, and in realistic scenarios with LLM generated data. MFFT consistently improves performance compared to using trusted data alone and outperforms all baselines across experiments with macro F1-score improvements of 2-4%. Finally, it provides substantial improvements in uncertainty calibration with expected calibration error (ECE) reductions of 40-60% compared to the best baselines."
    },
    {
        "title": "Learning 3D Medical Image Models From Brain Functional Connectivity Network Supervision For Mental Disorder Diagnosis",
        "link_suffix": "/forum?id=v5bK7cQch3",
        "link": "https://openreview.net/forum?id=v5bK7cQch3",
        "pdf_link": "https://openreview.net/pdf?id=v5bK7cQch3",
        "keywords": "3D medical image, functional connectivity network, contrastive learning, mental disease diagnosis",
        "abstract": "For mental disorder diagnosis, most previous works are task-specific and focus primarily on functional connectivity network (FCN) derived from functional MRI (fMRI) data. However, the high cost of fMRI acquisition limits its practicality in real-world clinical settings. Meanwhile, the more easily obtainable 3D T1-weighted (T1w) MRI, which captures brain anatomy, is ofen overlooked in standard diagnostic processes of mental disorders.\nTo address these two issues, we propose CINP (Contrastive Image-Network Pre-training), a framework that employs contrastive learning between 3D T1w MRI and FCNs. CINP aims to learn a joint latent semantic space that integrates complementary information from both functional and structural perspective. During pre-training, we incorporate masked image modeling loss and network-image matching loss to enhance visual representation learning and modality alignment.\nFurthermore, thanks to contrastive pre-training which facilitates knowledge transfer from FCN to T1w MRI, we introduce network prompting. This protocol leverages 3D T1w MRI from suspected patients and FCNs from confirmed patients for differential diagnosis of mental disorders.Extensive experiments across three mental disorder diagnosis tasks demonstrate the competitive performance of CINP, using both linear probing and network prompting, compared with FCN-based methods and self-supervised pre-training methods.\nThese results highlight the potential of CINP to enhance diagnostic processes with the aid of 3D T1w MRI in real-world clinical scenario."
    },
    {
        "title": "Bayesian Persuasion Is a Bargaining Game",
        "link_suffix": "/forum?id=RWiqprM18N",
        "link": "https://openreview.net/forum?id=RWiqprM18N",
        "pdf_link": "https://openreview.net/pdf?id=RWiqprM18N",
        "keywords": "Bayesian persuasion, bargaining game, anti-exploitation, large language models",
        "abstract": "Bayesian persuasion studies how a sender with an informational advantage can persuade a receiver with a different motive to take actions that benefit the sender. This problem is previously formulated from an equilibrium perspective, where the sender is to choose a Bayes correlated equilibrium and the receiver is willing to respect the signaling scheme based on posterior beliefs. However, evidence in real-world scenarios and studies in farsighted receivers suggest otherwise: senders tend to be much more honest than the equilibrium. In this work, we show that Bayesian persuasion is reducible to a bargaining game. This reduction suggests that the receiver in Bayesian persuasion can be aware of the game structure and can develop an anti-exploitation strategy. This equalizes the power of commitment of the two parties and prevents the sender from taking the maximum possible payoff. Through experiments on large language models, we demonstrate the receiver's retaliatory strategies and the sender's compromise to that. More findings on the impact of the context and alignments further suggest that bargaining behavior emerges in persuasion tasks. The insights given by our results have potential implications on various scenarios to reduce exploitation, improve equality, and improve social welfare."
    },
    {
        "title": "VoiceNoNG: High-Quality Speech Editing Model without Hallucinations",
        "link_suffix": "/forum?id=BVsFp5rQxd",
        "link": "https://openreview.net/forum?id=BVsFp5rQxd",
        "pdf_link": "https://openreview.net/pdf?id=BVsFp5rQxd",
        "keywords": "speech generative model, speech editing, neural codec, vector quantizer, deepfake detection",
        "abstract": "Currently, most advanced speech editing models are based on either neural codec\nlanguage models (NCLM) (e.g., VoiceCraft) or diffusion models (e.g., Voicebox).\nAlthough NCLM can generate higher quality speech compared to diffusion models,\nit suffers from a higher word error rate (WER) (Peng et al., 2024), calculated by\ncomparing the transcribed text to the input text. We identify that this higher WER\nis due to attention errors (hallucinations), which make it difficult for NCLM to\naccurately follow the target transcription. To maintain speech quality and address\nthe hallucination issue, we introduce VoiceNoNG, which combines the strengths of\nboth model frameworks. VoiceNoNG utilizes a latent flow-matching framework to\nmodel the pre-quantization features of a neural codec. The vector quantizer in the\nneural codec implicitly converts the regression problem into a token classification\ntask similar to NCLM. We empirically verified that this transformation is crucial\nfor enhancing the performance and robustness of the speech generative model. This\nsimple modification enables VoiceNoNG to achieve state-of-the-art performance\nin both objective and subjective evaluations. Lastly, to mitigate the potential\nrisks posed by the speech editing model, we examine the performance of the\nDeepfake detector in a new and challenging practical scenario. Audio examples\ncan be found on the demo page:https://anonymous.4open.science/w/NoNG-8004/"
    },
    {
        "title": "Don’t Say No: Jailbreaking LLM by Suppressing Refusal",
        "link_suffix": "/forum?id=frZVMBbqQJ",
        "link": "https://openreview.net/forum?id=frZVMBbqQJ",
        "pdf_link": "https://openreview.net/pdf?id=frZVMBbqQJ",
        "keywords": "prompting, security and privacy, red teaming, applications, robustness",
        "abstract": "Ensuring the safety alignment of Large Language Models (LLMs) is crucial to generating responses consistent with human values. Despite their ability to recognize and avoid harmful queries, LLMs are vulnerable to jailbreaking attacks, where carefully crafted prompts seduce them to produce toxic content. One category of jailbreak attacks is reformulating the task as an optimization by eliciting the LLM to generate affirmative responses. However, such optimization objective has its own limitations, such as the restriction on the predefined objectionable behaviors, leading to suboptimal attack performance. In this study, we first uncover the reason why vanilla target loss is not optimal, then we explore and enhance the loss objective and introduce the $\\textit{DSN}$ (Don't Say No) attack, which achieves successful attack by suppressing refusal. Another challenge in studying jailbreak attacks is the evaluation, as it is difficult to directly and accurately assess the harmfulness of the responses. The existing evaluation such as refusal keyword matching reveals numerous false positive and false negative instances. To overcome this challenge, we propose an Ensemble Evaluation pipeline that novelly incorporates Natural Language Inference (NLI) contradiction assessment and two external LLM evaluators. Extensive experiments demonstrate the potential of the $\\textit{DSN}$ and effectiveness of Ensemble Evaluation compared to baseline methods."
    },
    {
        "title": "ReCogLab: a framework testing relational reasoning, cognitive hypotheses on LLMs",
        "link_suffix": "/forum?id=yORSk4Ycsa",
        "link": "https://openreview.net/forum?id=yORSk4Ycsa",
        "pdf_link": "https://openreview.net/pdf?id=yORSk4Ycsa",
        "keywords": "Congitive Science, Large Language Models, Datasets, Evaluation, Relational Reasoning",
        "abstract": "A fundamental part of human cognition is the ability to not only recall memories, but to reason and manipulate information from them. In cognitive science and psychology, this is termed relational reasoning or relational memory and a number of cognitive effects and biases have been observed and proposed. Some of these effects include \\textit{congruence}, \\textit{the symbolic distance effect} and \\textit{transitive inference}. In addition, many other phenomenon of large language model performance have been observed or proposed. While some of these have been studied individually in prior work and datasets for general long-context inputs have been proposed, none of these has the flexibility to study all or even most of these hypotheses or phenomenon. In this work, we create a fully customizable, automatically generated dataset which allows us to study these effects in detail. We introduce four settings with multiple cognitive-reasoning-inspired tasks targeting different skills and difficulties with parameters of each of these being configurable to run probes on different abilities. With our framework, we test and find many of these human cognitive effects are repeated in LLMs and provide a number of interesting analyses."
    },
    {
        "title": "Swift-FedGNN: Federated Graph Learning with Low Communication and Sample Complexities",
        "link_suffix": "/forum?id=QXwtkVI8Yr",
        "link": "https://openreview.net/forum?id=QXwtkVI8Yr",
        "pdf_link": "https://openreview.net/pdf?id=QXwtkVI8Yr",
        "keywords": "federated learning, graph neural network, optimization",
        "abstract": "Graph neural networks (GNNs) have achieved great success in a wide variety of graph-based learning applications.\nTo expedite training for large-scale graphs,\ndistributed GNN training has been proposed using sampling-based mini-batch training.\nHowever, such a traditional distributed GNN training approach is not applicable to emerging GNN learning applications with geo-distributed input graphs, which require the data to be kept within the site where it is generated to protect privacy.\nOn the other hand, federated learning (FL) has been widely used to enable privacy-preserving training under data parallelism.\nHowever, because of cross-client links in the aforementioned geo-distributed graph data, applying federated learning directly to GNNs incurs expensive cross-client neighbor sampling and communication costs due to the large graph size and the dependencies between nodes among different clients. \nTo overcome these challenges, we propose a new mini-batch and sampling-based federated GNN algorithmic framework called Swift-FedGNN that primarily performs efficient parallel local training and periodically conducts time-consuming cross-client training.\nSpecifically, in Swift-FedGNN, each clientprimarilytrains a local GNN model using only its local graph data, and some randomly sampled clientsperiodicallylearn the local GNN models based on their local graph data and the dependent nodes across clients.\nWe theoretically establish the convergence performance of Swift-FedGNN and show that it enjoys a convergence rate of $\\mathcal{O}\\left( T^{-1/2} \\right)$, matching the state-of-the-art (SOTA) rate of sampling-based GNN methods, despite operating in the challenging FL setting.\nExtensive experiments on real-world datasets show that Swift-FedGNN significantly outperforms the SOTA federated GNN approaches with comparable accuracy in terms of efficiency."
    },
    {
        "title": "MGCFNN: A Neural MultiGrid Solver with Novel Fourier Neural Network for High Wave Number Helmholtz Equations",
        "link_suffix": "/forum?id=ThhQyIruEs",
        "link": "https://openreview.net/forum?id=ThhQyIruEs",
        "pdf_link": "https://openreview.net/pdf?id=ThhQyIruEs",
        "keywords": "neural multigrid solver, Fourier transform, Helmholtz equations, high wave number, heterogeneous medium",
        "abstract": "Solving high wavenumber Helmholtz equations is notoriously challenging. Traditional solvers have yet to yield satisfactory results, and most neural network methods struggle to accurately solve cases with extremely high wavenumbers within heterogeneous media. This paper presents an advanced multigrid-hierarchical AI solver, tailored specifically for high wavenumber Helmholtz equations. We adapt the MGCNN architecture to align with the problem setting and incorporate a novel Fourier neural network (FNN) to match the characteristics of Helmholtz equations. FNN, mathematically akin to the convolutional neural network (CNN), enables faster propagation of source influence during the solve phase, making it particularly suitable for handling large size, high wavenumber problems. We conduct supervised learning tests against numerous neural operator learning methods to demonstrate the superior learning capabilities of our solvers. Additionally, we perform scalability tests using an unsupervised strategy to highlight our solvers' significant speedup over the most recent specialized AI solver and AI-enhanced traditional solver for high wavenumber Helmholtz equations. We also carry out an ablation study to underscore the effectiveness of the multigrid hierarchy and the benefits of introducing FNN. Notably, our solvers exhibit optimal convergence of $\\mathcal{O}(k)$ up to $k \\approx 2000$."
    },
    {
        "title": "Vision-Language Models Meet Meteorology: Developing Models for Anomalies Analysis with Heatmaps",
        "link_suffix": "/forum?id=kWELXBKl54",
        "link": "https://openreview.net/forum?id=kWELXBKl54",
        "pdf_link": "https://openreview.net/pdf?id=kWELXBKl54",
        "keywords": "AI for Science, VLMs, Dataset, Meteorology",
        "abstract": "Real-time analysis and prediction of meteorological anomalies protect human lives and infrastructure. Traditional methods rely on numerical threshold setting and manual interpretation of weather heatmaps with Geographic Information Systems (GIS), which can be slow and error-prone. Our research redefines Meteorological Anomalies Analysis(MAA) by framing it as a Visual Question Answering (VQA) problem, thereby introducing a more precise and automated solution. Leveraging Vision-Language Models (VLM) to simultaneously process visual and textual data, we offer an effective aid to enhance the analysis process of weather heatmaps. Our initial assessment of general-purpose VLMs (e.g., GPT-4-Vision) on MAA revealed poor performance, characterized by low accuracy and frequent hallucinations due to inadequate color differentiation and insufficient meteorological knowledge. To address these challenges, we introduce ClimateIQA, the first meteorological VQA dataset, which includes 8,760 wind gust heatmaps and 254,040 question-answer pairs covering four question types, both generated from the latest climate reanalysis data. We also propose Sparse Position and Outline Tracking (SPOT), an innovative technique that leverages OpenCV and K-Means clustering to capture and depict color contours in heatmaps, providing ClimateIQA with more accurate color spatial location information. Finally, we present Climate-Zoo, the first meteorological VLM collection, which adapts VLMs to meteorological applications using the ClimateIQA dataset. Experiment results demonstrate that models from Climate-Zoo substantially outperform state-of-the-art general VLMs, achieving an accuracy increase from 0% to over 90% in MAA verification."
    },
    {
        "title": "SimSiam Naming Game: A Unified Approach for Representation Learning and Emergent Communication",
        "link_suffix": "/forum?id=VoVVDaVXdf",
        "link": "https://openreview.net/forum?id=VoVVDaVXdf",
        "pdf_link": "https://openreview.net/pdf?id=VoVVDaVXdf",
        "keywords": "emergent communication, representation learning, SimSiam, contrastive learning, self-supervised learning",
        "abstract": "Emergent communication, driven by generative models, enables agents to develop a shared language for describing their individual views of the same objects through interactions. Meanwhile, self-supervised learning (SSL), particularly SimSiam, uses discriminative representation learning to make representations of augmented views of the same data point closer in the representation space. Building on the prior work of VI-SimSiam, which incorporates a generative and Bayesian perspective into the SimSiam framework via variational inference (VI) interpretation, we propose SimSiam+VAE, a unified approach for both representation learning and emergent communication. SimSiam+VAE integrates a variational autoencoder (VAE) into the predictor of the SimSiam network to enhance representation learning and capture uncertainty. Experimental results show that SimSiam+VAE outperforms both SimSiam and VI-SimSiam. We further extend this model into a communication framework called the SimSiam Naming Game (SSNG), which applies the generative and Bayesian approach based on VI to develop internal representations and emergent language while utilizing the discriminative process of SimSiam to facilitate mutual understanding between agents. In experiments with established models, despite the dynamic alternation of agent roles during interactions, SSNG demonstrates comparable performance to the referential game and slightly outperforms the Metropolis-Hastings naming game."
    },
    {
        "title": "Evaluating the Goal-Directedness of Large Language Models",
        "link_suffix": "/forum?id=BECkhjcofz",
        "link": "https://openreview.net/forum?id=BECkhjcofz",
        "pdf_link": "https://openreview.net/pdf?id=BECkhjcofz",
        "keywords": "LLMs, agents, goal-directedness, safety",
        "abstract": "LLM-based agents may transform AI and society in the near future. Along with opportunities for automation and increased productivity come novel safety and ethics concerns. This means both researchers and regulators need good ways to keep track of progress and properties of LLM-based agents. A key feature of agentic behaviour is goal-directedness, which has so far received limited attention in the context of AI agents. In this work we define the concept of goal-directedness for LLM agents, and develop a framework for evaluating it empirically on tasks involving information gathering, information processing, and execution. Results on state-of-the-art LLM agents indicate a lack of goal-directedness, meaning models often fail to fully deploy capabilities that they evidently have. This raises the question of how we can elicit the full capabilities of LLM-based agents, as well as what policies should be in place for future more goal-directed systems."
    },
    {
        "title": "CirT: Global Subseasonal-to-Seasonal Forecasting with Geometry-inspired Transformer",
        "link_suffix": "/forum?id=YslOW2SO6S",
        "link": "https://openreview.net/forum?id=YslOW2SO6S",
        "pdf_link": "https://openreview.net/pdf?id=YslOW2SO6S",
        "keywords": "Weather and climate forecasting",
        "abstract": "Accurate Subseasonal-to-Seasonal (S2S) climate forecasting is pivotal for decision-making including agriculture planning and disaster preparedness but is known to be challenging due to its chaotic nature. Although recent data-driven models have shown promising results, their performance is limited by inadequate consideration of geometric inductive biases. Usually, they treat the spherical weather data as planar images, resulting in an inaccurate representation of locations and spatial relations. In this work, we propose the geometric-inspired Circular Transformer (CirT) to model the cyclic characteristic of the graticule, consisting of two key designs: (1) Decomposing the weather data by latitude into circular patches that serve as input tokens to the Transformer; (2) Leveraging Fourier transform in self-attention to capture the global information and model the spatial periodicity. Extensive experiments on the Earth Reanalysis 5 (ERA5) reanalysis dataset demonstrate our model yields a significant improvement over the advanced data-driven models, including PanguWeather and GraphCast, as well as skillful ECMWF systems. Additionally, we empirically show the effectiveness of our model designs and high-quality prediction over spatial and temporal dimensions."
    },
    {
        "title": "What Does it Mean for a Neural Network  to Learn a \"World Model\"?",
        "link_suffix": "/forum?id=89nUKXMt8E",
        "link": "https://openreview.net/forum?id=89nUKXMt8E",
        "pdf_link": "https://openreview.net/pdf?id=89nUKXMt8E",
        "keywords": "Large Language Model, World model",
        "abstract": "We propose an abstract but precise definition of what it means for a neural net to learn and use a \"world model.\" The goal is to give an operational meaning to terms that are often used informally, in order to provide a common language for experimental investigation. Our definition is based on ideas from the linear probing literature, and formalizes the notion of a computation that factors through a representation of the data generation process. We also describe a set of conditions to check that such a \"world model\" is not a trivial consequence of the neural net's data or task."
    },
    {
        "title": "Predicting and analyzing memorization within fine-tuned Large Language Models",
        "link_suffix": "/forum?id=XcSJ6hoc1O",
        "link": "https://openreview.net/forum?id=XcSJ6hoc1O",
        "pdf_link": "https://openreview.net/pdf?id=XcSJ6hoc1O",
        "keywords": "Memorization, Large Language Model, Privacy",
        "abstract": "Large Language Models have received significant attention due to their abilities to solve a wide range of complex tasks. However these models memorize a significant proportion of their training data, posing a serious threat when disclosed at inference time. To mitigate this unintended memorization, it is crucial to understand what elements are memorized and why. Most existing works provide a posteriori explanations, which has a limited interest in practice. To address this gap, we propose a new approach based on sliced mutual information to detect memorized samples a priori, in a classification setting. It is efficient from the early stages of training, and is readily adaptable to practical scenarios. Our method is supported by new theoretical results that we demonstrate, and requires a low computational budget. We obtain strong empirical results, paving the way for systematic inspection and protection of these vulnerable samples before memorization happens."
    },
    {
        "title": "In-context learning in presence of spurious correlations",
        "link_suffix": "/forum?id=pudmhZdV78",
        "link": "https://openreview.net/forum?id=pudmhZdV78",
        "pdf_link": "https://openreview.net/pdf?id=pudmhZdV78",
        "keywords": "in-context learning, spurious features, out-of-distribution, meta learning",
        "abstract": "Large language models exhibit a remarkable capacity for in-context learning, where they learn to solve tasks given a few examples.\nRecent work has shown that transformers can be trained to perform simple regression tasks in-context.\nThis work explores the possibility of training an in-context learner for classification tasks involving spurious features.\nWe find that the conventional approach of training in-context learners is susceptible to spurious features.\nMoreover, when the meta-training dataset includes instances of only one task, the conventional approach leads to task memorization and fails to produce a model that leverages context for predictions.\nBased on these observations, we propose a novel technique to train such a learner for a given classification task.\nRemarkably, this in-context learner matches and sometimes outperforms strong methods like ERM and GroupDRO.\nHowever, unlike these algorithms, it does not generalize well to other tasks.\nWe show that it is possible to obtain an in-context learner that generalizes to unseen tasks by training on a diverse dataset of synthetic in-context learning instances."
    },
    {
        "title": "Accelerating neural network training: An analysis of the AlgoPerf competition",
        "link_suffix": "/forum?id=CtM5xjRSfm",
        "link": "https://openreview.net/forum?id=CtM5xjRSfm",
        "pdf_link": "https://openreview.net/pdf?id=CtM5xjRSfm",
        "keywords": "Training algorithms, optimizers, benchmark, competition, neural network, training",
        "abstract": "The goal of the AlgoPerf: Training Algorithms competition is to evaluate practical speed-ups in neural network training achieved solely by improving the underlying training algorithms. In the external tuning ruleset, submissions must provide workload-agnostic hyperparameter search spaces, while in the self-tuning ruleset they must be completely hyperparameter-free. In both rulesets, submissions are compared on time-to-result across multiple deep learning workloads, training on fixed hardware. This paper presents the inaugural AlgoPerf competition's results, which drew 18 diverse submissions from 10 teams. Our investigation reveals several key findings: (1) The winning submission in the external tuning ruleset, using Distributed Shampoo, demonstrates the effectiveness of non-diagonal preconditioning over popular methods like Adam, even when compared on wall-clock runtime. (2) The winning submission in the self-tuning ruleset, based on the Schedule Free AdamW algorithm, demonstrates a new level of effectiveness for completely hyperparameter-free training algorithms. (3) The top-scoring submissions were surprisingly robust to workload changes. We also discuss the engineering challenges encountered in ensuring a fair comparison between different training algorithms. These results highlight both the significant progress so far, and the considerable room for further improvements."
    },
    {
        "title": "EReLELA: Exploration in Reinforcement Learning via Emergent Language Abstractions",
        "link_suffix": "/forum?id=7ienVkNf83",
        "link": "https://openreview.net/forum?id=7ienVkNf83",
        "pdf_link": "https://openreview.net/pdf?id=7ienVkNf83",
        "keywords": "Emergent Communication, Exploration, Reinforcement Learning, Abstraction, Emergent Languages, Natural Languages",
        "abstract": "The ability of AI agents to follow natural language (NL) instructions is important for Human-AI collaboration. \nTraining Embodied AI agents for instruction-following can be done with Reinforcement Learning (RL), yet it poses many challenges.\nAmong which is the exploitation versus exploration trade-off in RL. \nPrevious works have shown that NL-based state abstractions can help address this challenge. \nHowever, NLs descriptions have limitations in that they are not always readily available and are expensive to collect. \nIn order to address these limitations, we propose to use the Emergent Communication paradigm, where artificial agents learn an emergent language (EL) in an unsupervised fashion, via referential games. \nThus, ELs constitute cheap and readily-available abstractions. \nIn this paper, we investigate (i) how EL-based state abstractions compare to NL-based ones for RL in hard-exploration, procedurally-generated environments, and (ii) how properties of the referential games used to learn ELs impact the quality of the RL exploration and learning.\nWe provide insights about the kind of state abstractions performed by NLs and ELs over RL state spaces, using our proposed Compactness Ambiguity Metric.\nOur results indicate that our proposed EL-guided agent, entitled EReLELA, achieves similar performance as its NL-based counterparts without its limitations. \nOur work shows that RL agents can leverage unsupervised EL abstractions to greatly improve their exploration skills in sparse reward settings, thus opening new research avenues between Embodied AI and Emergent Communication."
    },
    {
        "title": "Counterfactual Outcome Estimation in Time Series via Sub-treatment Group Alignment and Random Temporal Masking",
        "link_suffix": "/forum?id=uSV07DapJx",
        "link": "https://openreview.net/forum?id=uSV07DapJx",
        "pdf_link": "https://openreview.net/pdf?id=uSV07DapJx",
        "keywords": "Counterfactual treatment effect estimation, Time series observational data, Confounding in time series, Sub-treatment Group Alignment, Random Temporal Masking",
        "abstract": "Estimating counterfactual outcomes in time series from observational data is important for effective decision-making in many fields, such as determining the optimal timing for a medical intervention. However, this task is challenging, primarily because of the unobservability of counterfactual outcomes and the complexity of confounding in time series. To this end, we introduce a representation learning-based framework for counterfactual estimation in time series with two novel techniques:Sub-treatment Group Alignment (SGA)andRandom Temporal Masking (RTM). The first technique focuses on reducing confounding at each time point. While the common approach is to align the distributions of different treatment groups in the latent space, our proposed approach, SGA, first identifiessub-treatment groupsthrough Gaussian Mixture Models (GMMs) and subsequently aligns the corresponding sub-groups. We demonstrate that, both theoretically and empirically, SGA achieves improved alignment, thus leading to more effective deconfounding. The second technique, RTM, masks covariates at random time steps with Gaussian noises. This approach promotes the time series models to select information not only important for the outcome estimation at current time point but also crucial for the time points in the future where the covariates are masked out, thus preserving thecausal informationand reducing the risk of overfitting to factual outcomes. We observe in experiments on synthetic and semi-synthetic datasets that applying SGA and RTM individually improves counterfactual outcome estimation, and when combined, they achieve state-of-the-art performance."
    },
    {
        "title": "OptionZero: Planning with Learned Options",
        "link_suffix": "/forum?id=3IFRygQKGL",
        "link": "https://openreview.net/forum?id=3IFRygQKGL",
        "pdf_link": "https://openreview.net/pdf?id=3IFRygQKGL",
        "keywords": "Option, Semi-MDP, MuZero, MCTS, Planning, Reinforcement Learning",
        "abstract": "Planning with options -- a sequence of primitive actions -- has been shown effective in reinforcement learning within complex environments. Previous studies have focused on planning with predefined options or learned options through expert demonstration data. Inspired by MuZero, which learns superhuman heuristics without any human knowledge, we propose a novel approach, named OptionZero. OptionZero incorporates an option network into MuZero, providing autonomous discovery of options through self-play games. Furthermore, we modify the dynamics network in MuZero to provide environment transitions when using options, allowing searching deeper under the same simulation constraints. Empirical experiments conducted in 26 Atari games demonstrate that OptionZero outperforms MuZero, achieving a 131.58% improvement in mean human-normalized score. Our behavior analysis shows that OptionZero not only learns options but also acquires strategic skills tailored to different game characteristics. Our findings show promising directions for discovering and using options in planning."
    },
    {
        "title": "Structure and Behavior in Weight Space Representation Learning",
        "link_suffix": "/forum?id=GOwNImvCWf",
        "link": "https://openreview.net/forum?id=GOwNImvCWf",
        "pdf_link": "https://openreview.net/pdf?id=GOwNImvCWf",
        "keywords": "weight space learning, hyper-representations, deep weight spaces, representation learning, model reconstruction, model weights generation",
        "abstract": "The weights of neural networks (NNs) have recently gained prominence as a new data modality in machine learning, with applications ranging from accuracy and hyperparameter prediction to representation learning or weight generation. One approach to leverage NN weights involves training autoencoders (AEs) with contrastive and reconstruction losses. Indeed, such models can be applied to a wide variety of downstream tasks, and they demonstrate strong predictive performance and low reconstruction error. However, despite the low reconstruction error, these AEs reconconstruct NN models that fail to match the performance of the original ones. In this paper, we identify a limitation of weight-space AEs, specifically highlighting that structural weight reconstruction alone fails to capture some features critical for reconstructing high-performing models. To address this issue, we propose a behavioral loss for training AEs in weight space. This behavioral loss focuses on the features essential for reconstructing performant models, which are not adequately captured by structural reconstruction. We evaluate the capabilities of AE trained using this novel loss on three different model zoos: we demonstrate that when combining structural and behavioral losses, we can reconstruct and generate models that match the performance of the original models. With our exploration of representation learning in deep weight spaces, we show that a strong synergy exists between structural and behavioral features, and that combining them results in increased performance across all evaluated downstream tasks."
    },
    {
        "title": "Leopard: A Vision Language Model For Text-Rich Multi-Image Tasks",
        "link_suffix": "/forum?id=oSJqRF0Tkg",
        "link": "https://openreview.net/forum?id=oSJqRF0Tkg",
        "pdf_link": "https://openreview.net/pdf?id=oSJqRF0Tkg",
        "keywords": "Multimodal Large Language Models, Text-rich Image, Multi-image",
        "abstract": "Text-rich images, where text serves as the central visual element guiding the overall understanding, are prevalent in real-world applications, such as presentation slides, scanned documents, and webpage snapshots. Tasks involving multiple text-rich images are especially challenging, as they require not only understanding the content of individual images but reasoning about inter-relationships and logical flows across multiple visual inputs.\nDespite the importance of these scenarios, current multimodal large language models (MLLMs) struggle to handle such tasks due to two key challenges: (1) the scarcity of high-quality instruction tuning datasets for text-rich multi-image scenarios, and (2) the difficulty in balancing image resolution with visual feature sequence length. Low-resolution encoding impairs the recognition of embedded text, while high-resolution encoding quickly exceeds the model’s maximum sequence length under multi-image settings.\nTo address these challenges, we propose Leopard, a MLLM designed specifically for handling vision-language tasks involving multiple text-rich images. \nFirst, we curated about one million high-quality multimodal instruction-tuning data, tailored to text-rich, multi-image scenarios.\nSecond, we developed an adaptive high-resolution multi-image encoding module to dynamically optimize the allocation of visual sequence length based on the original aspect ratios\nand resolutions of the input images.\nExperiments across a wide range of benchmarks demonstrate our model's superior capabilities in text-rich, multi-image evaluations and competitive performance in general domain evaluations.\nWe are committed to open-source models and will release all collected data, code, and checkpoints to the community."
    },
    {
        "title": "From Skills to Plans: Automatic Skill Discovery and Symbolic Interpretation for Compositional Tasks",
        "link_suffix": "/forum?id=q1Cv7Hp52y",
        "link": "https://openreview.net/forum?id=q1Cv7Hp52y",
        "pdf_link": "https://openreview.net/pdf?id=q1Cv7Hp52y",
        "keywords": "automatic skill discovery, symbolic interpretation, pixel-based controlling",
        "abstract": "Deep Reinforcement Learning (DRL) has struggled with pixel-based controlling tasks that have numerous entities, long sequences, and logical dependencies. Methods using structured representations have shown promise in generalizing to different object entities in manipulation tasks. However, they lack the ability to segment and reuse basic skills. Neuro-symbolic RL excels in handling long sequential decomposable tasks yet heavily relies on expert-designed predicates. To address these challenges, we introduce a novel pixel-based framework that combines entity-centric decision transformers with symbolic planning. Our approach first automatically discovers and learns basic skills through experiences in simple environments without human intervention. Then, we employ a genetic algorithm to enhance these basic skills with symbolic interpretations. Therefore, we convert the complex controlling problem into a planning problem. Taking advantage of symbolic planning and entity-centric skills, our model is inherently interpretable and provides compositional generalizability. The results of the experiments show that our method demonstrates superior performance in long-horizon sequential tasks and real-world object manipulation."
    },
    {
        "title": "AIME: AI System Optimization via Multiple LLM Evaluators",
        "link_suffix": "/forum?id=Z6kVjQAPNq",
        "link": "https://openreview.net/forum?id=Z6kVjQAPNq",
        "pdf_link": "https://openreview.net/pdf?id=Z6kVjQAPNq",
        "keywords": "AI System Optimization, Agentic AI, Large Language Models, LLM-based Evaluation",
        "abstract": "Text-based AI system optimization typically involves a feedback loop scheme where a \\textit{single} LLM generates an evaluation in natural language of the current output to improve the next iteration's output. However, in this work, we empirically demonstrate that for a practical and complex task (code generation) with multiple criteria to evaluate, utilizing only one LLM evaluator tends to let errors in generated code go undetected, thus leading to incorrect evaluations and ultimately suboptimal test case performance. Motivated by this failure case, we assume there exists an optimal evaluation policy that samples an evaluation between response and ground truth. We then theoretically prove that a linear combination of multiple evaluators can approximate this optimal policy. From this insight, we propose AI system optimization via Multiple LLM Evaluators (AIME). AIME is an evaluation protocol that utilizes multiple LLMs that each independently generate an evaluation on separate criteria and then combine them via concatenation. We provide an extensive empirical study showing AIME outperforming baseline methods in code generation tasks, with up to 62% higher error detection rate and up to 16% higher success rate than a single LLM evaluation protocol on LeetCodeHard and HumanEval datasets. We also show that the selection of the number of evaluators and which criteria to utilize is non-trivial as it can impact pact success rate by up to 12%."
    }
]
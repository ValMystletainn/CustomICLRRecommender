[
    {
        "title": "Learning Identifiable Concepts for Compositional Image Generation",
        "link_suffix": "/forum?id=0BBzwpLVpm",
        "link": "https://openreview.net/forum?id=0BBzwpLVpm",
        "pdf_link": "https://openreview.net/pdf?id=0BBzwpLVpm",
        "keywords": "concept; composition; image generation",
        "abstract": "Humans have the ability to decompose objects into parts and relationships and\ncreate new objects by properly combining existing concepts. However, enabling\nmachines to achieve this in real-world tasks remains a challenge. In this paper,\nwe investigate how to teach machines compositional image generation through\nlearning identifiable concepts. To derive concepts from attribute labels, we formulate the minimal change principle and propose a method to limit the information introduced by each label. Additionally, to address dependent attribute labels\n(with causal influences in between or common causes behind them), we present\na causal conditioning approach to disentangle concepts from these correlations.\nOur framework enhances data efficiency, interpretability, and control, while enabling sampling from unseen combinations. We validate our method on various\ncompositional image generation and editing tasks, demonstrating its effectiveness\nthrough superior performance."
    },
    {
        "title": "On Unsupervised Prompt Learning for Classification with Black-box Language Models",
        "link_suffix": "/forum?id=xRi8sKo4XI",
        "link": "https://openreview.net/forum?id=xRi8sKo4XI",
        "pdf_link": "https://openreview.net/pdf?id=xRi8sKo4XI",
        "keywords": "Prompt Learning, Black-box Language Models, In-context Learning",
        "abstract": "Large language models (LLMs) have achieved impressive success in text-formatted learning problems, and most popular LLMs have been deployed in a black-box fashion. Meanwhile, fine-tuning is usually necessary for a specific downstream task to obtain better performance, and this functionality is provided by the owners of the black-box LLMs. To fine-tune a black-box LLM, labeled data are always required to adjust the model parameters. However, in many real-world applications, LLMs can label textual datasets with even better quality than skilled human annotators, motivating us to explore the possibility of fine-tuning black-box LLMs with unlabeled data. In this paper, we propose unsupervised prompt learning for classification with black-box LLMs, where the learning parameters are the prompt itself and the pseudo labels of unlabeled data. Specifically, the prompt is modeled as a sequence of discrete tokens, and every token has its own to-be-learned categorical distribution. On the other hand, for learning the pseudo labels, we are the first to consider the in-context learning (ICL) capabilities of LLMs: we first identify reliable pseudo-labeled data using the LLM, and then assign pseudo labels to other unlabeled data based on the prompt, allowing the pseudo-labeled data to serve as in-context demonstrations alongside the prompt. Those in-context demonstrations matter: previously, they are involved when the prompt is used for prediction while they are not involved when the prompt is trained; thus, taking them into account during training makes the prompt-learning and prompt-using stages more consistent. Experiments on benchmark datasets show the effectiveness of our proposed algorithm. After unsupervised prompt learning, we can use the pseudo-labeled dataset for further fine-tuning by the owners of the black-box LLMs."
    },
    {
        "title": "SynHING: Synthetic Heterogeneous Information Network Generation for Graph Learning and Explanation",
        "link_suffix": "/forum?id=ZbHIDgDFN0",
        "link": "https://openreview.net/forum?id=ZbHIDgDFN0",
        "pdf_link": "https://openreview.net/pdf?id=ZbHIDgDFN0",
        "keywords": "synthetic graph generation, heterogeneous information networks, graph neural networks, explainable artificial intelligence",
        "abstract": "Graph Neural Networks (GNNs) excel in modeling graph structures across diverse domains, such as community analysis and recommendation systems. As the need for GNN interpretability grows, there is an increasing demand for robust baselines and comprehensive graph datasets, especially within the realm of Heterogeneous Information Networks (HIN). To address this, we introduce SynHING, a framework for Synthetic Heterogeneous Information Network Generation designed to advance graph learning and explanation.\nAfter identifying key motifs in a target HIN, SynHING systematically employs a bottom-up generation process with intra-cluster and inter-cluster merge modules. This process, along with post-pruning techniques, ensures that the synthetic HIN accurately mirrors the structural and statistical properties of the original graph. The effectiveness of SynHING is validated using four datasets - IMDB, Recipe, ACM, and DBLP - spanning three distinct application categories, demonstrating both its generality and practicality.\nFurthermore, SynHING provides ground-truth motifs for evaluating GNN explainer models, establishing a new benchmark for explainable, synthetic HIN generation. This contributes significantly to advancing interpretable machine learning in complex network environments."
    },
    {
        "title": "Fast Crystal Tensor Property Prediction: A General O(3)-Equivariant Framework Based on Polar Decomposition",
        "link_suffix": "/forum?id=0k7pbSxNOG",
        "link": "https://openreview.net/forum?id=0k7pbSxNOG",
        "pdf_link": "https://openreview.net/pdf?id=0k7pbSxNOG",
        "keywords": "$O(3)$ group tensor equivariance, polar decomposition, tensor properties",
        "abstract": "Predicting tensor properties of the crystalline materials is a fundamental task in materials science. Unlike single-value property prediction, which is inherently invariant, tensor property prediction requires maintaining $O(3)$ group tensor equivariance. This equivariance constraint often introduces tremendous computational costs, necessitating specialized designs for effective and efficient predictions. \nTo address this limitation, we propose a general $O(3)$-equivariant framework for fast crystal tensor prediction, called {\\em GoeCTP}. \nOur framework is efficient as it does not need to impose equivalence constraints onto the network architecture. Instead, {\\em GoeCTP} captures the tensor equivariance with a simple external rotation and reflection (R&R) module based on the polar decomposition. The crafted external R&R module can rotate and reflect the crystal into an invariant standardized crystal position in space without introducing extra computational cost. We show that {\\em GoeCTP} is general as it is a plug-and-play module that can be smoothly integrated with any existing single-value property prediction network for predicting tensor properties. Experimental results indicate that the {\\em GoeCTP} method achieves higher prediction performance and runs 13$\\times$ faster compared to existing state-of-the-art models in elastic benchmarking datasets, underscoring its effectiveness and efficiency."
    },
    {
        "title": "FLARE: Faithful Logic-Aided Reasoning and Exploration",
        "link_suffix": "/forum?id=awtd0XhzKQ",
        "link": "https://openreview.net/forum?id=awtd0XhzKQ",
        "pdf_link": "https://openreview.net/pdf?id=awtd0XhzKQ",
        "keywords": "Reasoning, LLM, multi-hop, complex, prompting, faithfulness, logic, symbolic, search",
        "abstract": "Modern Question Answering (QA) and Reasoning approaches based on Large Language Models (LLMs) commonly use prompting techniques, such as Chain-of-Thought (CoT), assuming the resulting generation will have a more granular exploration and reasoning over the question space and scope. However, such methods struggle with generating outputs that are faithful to the intermediate chain of reasoning produced by the model. On the other end of the spectrum, neuro-symbolic methods such as Faithful CoT (F-CoT) propose to combine LLMs with external symbolic solvers. While such approaches boast a high degree of faithfulness, they usually require a model trained for code generation and struggle with tasks that are ambiguous or hard to formalise strictly. We introduceFaithfulLogic-AidedReasoning andExploration (FLARE), a novel interpretable approach for traversing the problem space using task decompositions. We use the LLM to plan a solution, soft-formalise the query into facts and predicates using a logic programming code and simulate that code execution using an exhaustive multi-hop search over the defined space. Our method allows us to compute the faithfulness of the reasoning process w.r.t. the generated code and analyse the steps of the multi-hop search without relying on external solvers. Our methods achieve SOTA results on7out of9diverse reasoning benchmarks. We also show that model faithfulness positively correlates with overall performance and further demonstrate thatFLAREallows pinpointing the decisive factors sufficient for and leading to the correct answer with optimal reasoning during the multi-hop search."
    },
    {
        "title": "Understanding and Mitigating Distribution Shifts for Machine Learning Force Fields",
        "link_suffix": "/forum?id=Xk9Q0CrJQc",
        "link": "https://openreview.net/forum?id=Xk9Q0CrJQc",
        "pdf_link": "https://openreview.net/pdf?id=Xk9Q0CrJQc",
        "keywords": "machine learning force fields, test-time training, distribution shifts",
        "abstract": "Machine Learning Force Fields (MLFFs) are  a promising alternative to expensive ab initio quantum mechanical molecular simulations. Given the diversity of chemical spaces that are of interest and the cost of generating new data, it is important to understand how MLFFs generalize beyond their training distributions. Our diagnostic experiments on real-world datasets reveal common distribution shifts that pose significant challenges, including for large foundation models trained on extensive datasets. Based on these observations, we hypothesize that current supervised training methods inadequately regularize MLFFs, resulting in overfitting and learning poor representations of out-of-distribution systems. Based on our observations, we propose two new methods as initial steps for mitigating distribution shifts for MLFFs. Our methods focus on test-time refinement strategies that incur minimal computational cost. The first strategy, based on spectral graph theory, modifies the edges of test graphs to align with graph structures seen during training. It can be applied to any existing pre-trained model to mitigate connectivity distribution shifts. Our second strategy improves representations for out-of-distribution systems at test-time by taking gradient steps using an auxiliary objective. We demonstrate that our test-time refinement strategies can reduce force errors by an order of magnitude on out-of-distribution systems, suggesting that MLFFs are capable of modeling diverse chemical spaces, but are not being effectively trained to do so. Our experiments establish clear benchmarks for evaluating the generalization capabilities of the next generation of MLFFs."
    },
    {
        "title": "Reducing Complexity of Force-Directed Graph Embedding",
        "link_suffix": "/forum?id=1MjOlHwCE6",
        "link": "https://openreview.net/forum?id=1MjOlHwCE6",
        "pdf_link": "https://openreview.net/pdf?id=1MjOlHwCE6",
        "keywords": "Graph embedding, Force-directed, representation learning, Spring model, Reduced complexity",
        "abstract": "Graph embedding is a critical pre-processing step that maps elements of a graph network, such as its nodes or edges, to coordinates in a $d$-dimensional space. The primary goal of the embedding process is to capture and preserve various features of the graph network, including its topology and node attributes, in the generated embedding. Maintaining these graph features in the embedding can significantly enhance the performance of the downstream machine learning tasks. In this work, we introduce a novel family of graph embedding methods that leverage kinematics principles within a spring model and $n$-body simulation framework to generate the graph embedding. The proposed method differs substantially from state-of-the-art (SOTA) methods, as it does not attempt to fit a model (such as neural networks) and eliminates the need for functions such as message passing or back-propagation. Instead, it aims to position the nodes in the embedding space such that the total net force of the system is reduced to a minimal threshold, resulting in the system reaching an equilibrium state. The spring model is designed as a linear summation of non-linear force functions, with the shortest-path distance serving as the adjusting parameter for the force factor between each node pair, and therefore, inducing the graph topology in the force functions. In this work, we attempted to reduce the complexity of the original algorithm from $\\log(n^2)$ to $n\\log(n)$, while maintaining the performance metrics at a competitive level.\nThe proposed method is intuitive, parallelizable, and highly scalable. While the primary focus of this work is on the feasibility of the Force-Directed approach, the results in unsupervised graph embeddings are comparable to or better than SOTA methods, demonstrating its potential for practical applications."
    },
    {
        "title": "HATFormer: Historic Handwritten Arabic Text Recognition with Transformers",
        "link_suffix": "/forum?id=ITi9Zwkge2",
        "link": "https://openreview.net/forum?id=ITi9Zwkge2",
        "pdf_link": "https://openreview.net/pdf?id=ITi9Zwkge2",
        "keywords": "OCR, computer vision, transformer, handwritten text recognition, HTR, Arabic, historical handwritten Arabic, handwritten Arabic",
        "abstract": "Arabic handwritten text recognition (HTR) is challenging, especially for historical texts, due to diverse writing styles and the intrinsic features of Arabic script. Additionally, Arabic handwriting datasets are smaller compared to English ones, making it difficult to train generalizable Arabic HTR models. To address these challenges, we propose HATFormer, a transformer-based encoder-decoder architecture that builds on a state-of-the-art English HTR model.  By leveraging the transformer's attention mechanism, HATFormer captures spatial contextual information to address the intrinsic challenges of Arabic script through differentiating cursive characters, decomposing visual representations, and identifying diacritics. Our customization to historical handwritten Arabic includes an image processor for effective ViT information preprocessing, a text tokenizer for compact Arabic text representation, and a training pipeline that accounts for a limited amount of historic Arabic handwriting data. HATFormer achieves a character error rate~(CER) of 8.6% on the largest public historical handwritten Arabic dataset, with a 51% improvement over the best baseline in the literature. HATFormer also attains a comparable CER of 4.2% on the largest private non-historical dataset. Our work demonstrates the feasibility of adapting an English HTR method to a low-resource language with complex, language-specific challenges, contributing to advancements in document digitization, information retrieval, and cultural preservation. The source code will be available as a link on the discussion forum once it is open."
    },
    {
        "title": "Labits: Layered Bidirectional Time Surfaces Representation for Event Camera-based Continuous Dense Trajectory Estimation",
        "link_suffix": "/forum?id=f5kwV2rdce",
        "link": "https://openreview.net/forum?id=f5kwV2rdce",
        "pdf_link": "https://openreview.net/pdf?id=f5kwV2rdce",
        "keywords": "event camera, trajectory estimation, computer vision, event-based vision, dynamic vision sensor, feature tracking",
        "abstract": "Event cameras provide a compelling alternative to traditional frame-based sensors, capturing dynamic scenes with high temporal resolution and low latency. Moving objects trigger events with precise timestamps along their trajectory, enabling smooth continuous-time estimation. However, few works have attempted to optimize the information loss during event representation construction, imposing a ceiling on this task. Fully exploiting event cameras requires representations that simultaneously preserve fine-grained temporal information, stable and characteristic 2D visual features, and temporally consistent information density\u2014an unmet challenge in existing representations. We introduce Labits: Layered Bidirectional Time Surfaces, a simple yet elegant representation designed to retain all these features. Additionally, we propose a dedicated module for extracting active pixel local optical flow (APLOF), significantly boosting the performance. Our approach achieves an impressive 49% reduction in trajectory end-point error (TEPE) compared to the previous state-of-the-art on the MultiFlow dataset. Labits offers a potential out-of-the-box performance boost for other event-based local motion-sensitive tasks, with code to be released upon acceptance."
    },
    {
        "title": "Generative Editing via Convolutional Obscuring (GECO): A Generative Adversarial Network for MRI de-artifacting",
        "link_suffix": "/forum?id=pPWAPiFf3z",
        "link": "https://openreview.net/forum?id=pPWAPiFf3z",
        "pdf_link": "https://openreview.net/pdf?id=pPWAPiFf3z",
        "keywords": "Deep convolutional neural networks, computer vision, medical machine learning, image analysis, generative adversarial networks, artifact removal, machine learning model generalization",
        "abstract": "Magnetic resonance imaging (MRI) is the dominant diagnostic technique to non-invasively image the brain, and deep learning has proven a powerful tool for analyzing these images. However, machine learning models trained on such MRI data have empirically shown an ability to detect complex and invisible artifacts, such as which type of machine a scan was taken from to a high degree of accuracy. Such artifacts are potentially invisible to the human eye, but can be identified by machine learning systems, leading them to focus on irrelevant features rather than scientifically and/or medically useful ones. For example, machine learning systems can often \u201cshortcut\u201d past the actual features researchers would like to detect and utilize separate spurious correlations to make predictions. Several such undesired features have been reported to interfere with cross-institutional medical imaging deep learning research, and more are likely to be identified as time goes on. Here, we develop a method capable of removing these spurious correlations in an unsupervised manner, leveraging generative techniques to produce images which maintain image quality while learning how to remove technical artifacts. Generative Adversarial Networks are a class of deep learning architectures which have shown impressive efficacy in image generation and editing tasks, and our work builds upon this success. Here, we propose Generative Editing via Convolutional Obscuring (GECO), a Generative Adverserial Network for MRI deartifacting. GECO is based on a CycleGAN, a GAN architecture designed for image-to-image translation that is transforming an input image into a new image with one or more desirable properties. By formulating the CycleGAN loss as a two-player game with a regularization term and incentivizing the generator to erase spurious correlations the original image quality can be better preserved. Beginning with classifiers trained on original images to identify images based on artifacts of interest, GECO reduced the classifiers\u2019 ability to detect these spurious correlations from 97% down to a difference which is nearly equal to a classifier making purely random guesses. We also observe over 98% structural similarity between the original and deartifacted images, indicating the preservation of the vast majority of non-spurious information contained in the original images. In addition to solving the known problem of avoiding artifacts from scanner type, this method opens the door to potentially removing many other types of spurious correlations from medical images and other data modalities across many fields."
    },
    {
        "title": "Fast Diversity-Preserving Reward Finetuning of Diffusion Models via Nabla-GFlowNets",
        "link_suffix": "/forum?id=Aye5wL6TCn",
        "link": "https://openreview.net/forum?id=Aye5wL6TCn",
        "pdf_link": "https://openreview.net/pdf?id=Aye5wL6TCn",
        "keywords": "Generative Models, GFlowNet, Reward Finetuning, Diffusion Models",
        "abstract": "While one commonly trains large diffusion models by collecting datasets on target downstream tasks, it is often desired to finetune pretrained diffusion models on some reward functions that are either designed by experts or learned from small-scale datasets. Existing methods for finetuning diffusion models typically suffer either 1) lack of diversity in generated samples, or 2) costly finetuning and slow convergence. Inspired by recent successes in generative flow networks (GFlowNets), a class of probabilistic models that sample with the unnormalized density of a reward function, we propose a novel GFlowNet method dubbed Nabla-GFlowNet (abbreviated as \\nabla-GFlowNet), together with an objective called \\nabla-DB, plus its variant residual \\nabla-DB for finetuning pretrained diffusion models. These objectives leverage the rich signal in reward gradients for diversity-aware finetuning. We empirically show that our proposed residual \\nabla-DB achieves fast yet diversity- & prior-preserving finetuning of StableDiffusion, a large-scale text-conditioned image diffusion model, on different realistic reward functions."
    },
    {
        "title": "Block Verification Accelerates Speculative Decoding",
        "link_suffix": "/forum?id=frsg32u0rO",
        "link": "https://openreview.net/forum?id=frsg32u0rO",
        "pdf_link": "https://openreview.net/pdf?id=frsg32u0rO",
        "keywords": "llm efficiency, speculative decoding, distribution coupling",
        "abstract": "Speculative decoding is an  effective method for lossless acceleration of large language models during inference. It uses a fast model to draft a block of tokens which are then verified in parallel by the target model, and provides a guarantee that the output is distributed identically to a sample from the target model. In prior works, draft verification is performed independently token-by-token. Surprisingly, we show that this approach is not optimal. We proposeBlock Verification, a simple draft verification algorithm that verifies the entire block jointly and provides additional wall-clock speedup. We prove that the proposed mechanism is optimal in the expected number of tokens produced each iteration and specifically is never worse than the standard token-level verification.\nEmpirically, block verification provides modest but consistent wall-clock speedups over the standard token verification algorithm of 5%-8% in a range of tasks and datasets.\nGiven that block verification does not increase code complexity, maintains the strong lossless guarantee of the standard speculative decoding verification algorithm, cannot deteriorate performance, and, in fact, consistently improves it, it can be used as a good default in speculative decoding implementations."
    },
    {
        "title": "Combinatorial Reinforcement Learning with Preference Feedback",
        "link_suffix": "/forum?id=MdidZNQxqK",
        "link": "https://openreview.net/forum?id=MdidZNQxqK",
        "pdf_link": "https://openreview.net/pdf?id=MdidZNQxqK",
        "keywords": "combinatorial reinforcement learning, preference feedback, contextual MNL bandits, nonlinear function approximation",
        "abstract": "In this paper, we consider combinatorial reinforcement learning with preference feedback, where a learning agent sequentially offers an action\u2014an assortment of multiple items\u2014to a user, whose preference feedback follows a multinomial logit (MNL) model. This framework allows us to model real-world scenarios, particularly those involving long-term user engagement, such as in recommender systems and online advertising. However, this framework faces two main challenges: (1) the unknown value of each item, unlike traditional MNL bandits (which only account for single-step preference feedback), and (2) computational complexity due to the combinatorial action space. In this paper, we assume a contextual MNL preference model, where mean utilities are linear, and the value of each item is approximated using general function approximation. We propose an algorithm, MNL-V$Q$L, that addresses these challenges, making it both computationally and statistically efficient. As a special case, for linear MDPs (with the MNL preference model), we establish a regret lower bound and show that MNL-V$Q$L achieves near-optimal regret. To the best of our knowledge, this is the first work to provide statistical guarantees in combinatorial RL with preference feedback."
    },
    {
        "title": "NetFormer: An interpretable model for recovering dynamical connectivity in neuronal population dynamics",
        "link_suffix": "/forum?id=bcTjW5kS4W",
        "link": "https://openreview.net/forum?id=bcTjW5kS4W",
        "pdf_link": "https://openreview.net/pdf?id=bcTjW5kS4W",
        "keywords": "neuronal dynamics, nonstationary, dynamical connectivity, interpretability, transformer, attention",
        "abstract": "Neuronal dynamics are highly nonlinear and nonstationary. Traditional methods for extracting the underlying network structure from neuronal activity recordings mainly concentrate on modeling static connectivity, without accounting for key nonstationary aspects of biological neural systems, such as ongoing synaptic plasticity and neuronal modulation. To bridge this gap, we introduce the NetFormer model, an interpretable approach applicable to such systems. In NetFormer, the activity of each neuron across a series of historical time steps is defined as a token. These tokens are then linearly mapped through a query and key mechanism to generate a state- (and hence time-) dependent attention matrix that directly encodes nonstationary connectivity structures.\nWe analyzed our formulation from the perspective of nonstationary and nonlinear networked dynamical systems, and show both via an analytical expansion and targeted simulations how it can approximate the underlying  ground truth.  Next, we demonstrate NetFormer's ability to model a key feature of biological and bio-informed networks, spike-timing-dependent plasticity, whereby connection strengths continually change in response to local activity patterns.\nThus informed, we apply NetFormer to a large-scale database of real neural recordings, which contains neural activity, cell type, and behavioral state information.  We show that the NetFormer effectively predicts neural dynamics and identifies cell-type specific, state-dependent dynamic connectivity that matches patterns measured in separate ground-truth physiology experiments, demonstrating its ability to help decode complex neural interactions based on large-scale activity observations alone."
    },
    {
        "title": "NTK-DFL: Enhancing Decentralized Federated Learning in Heterogeneous Settings via Neural Tangent Kernel",
        "link_suffix": "/forum?id=TwZBQKgwdW",
        "link": "https://openreview.net/forum?id=TwZBQKgwdW",
        "pdf_link": "https://openreview.net/pdf?id=TwZBQKgwdW",
        "keywords": "Federated Learning, Decentralized Federated Learning",
        "abstract": "Decentralized federated learning (DFL) is a collaborative machine learning framework for training a model across participants without a central server or raw data exchange. DFL faces challenges due to statistical heterogeneity, as participants often possess different data distributions reflecting local environments and user behaviors. Recent work has shown that the neural tangent kernel (NTK) approach, when applied to federated learning in a centralized framework, can lead to improved performance. The NTK-based update mechanism is more expressive than typical gradient descent methods, enabling more efficient convergence and better handling of data heterogeneity. We propose an approach leveraging the NTK to train client models in the decentralized setting, while introducing a synergy between NTK-based evolution and model averaging. This synergy exploits inter-model variance and improves both accuracy and convergence in heterogeneous settings. Our model averaging technique significantly enhances performance, boosting accuracy by at least 10% compared to the mean local model accuracy. Empirical results demonstrate that our approach consistently achieves higher accuracy than baselines in highly heterogeneous settings, where other approaches often underperform. Additionally, it reaches target performance in 4.6 times fewer communication rounds. We validate our approach across multiple datasets, network topologies, and heterogeneity settings to ensure robustness and generalizability. The source code will be available as a link on the discussion forum once it is open."
    },
    {
        "title": "Bayes Adaptive Monte Carlo Tree Search for Offline Model-based Reinforcement Learning",
        "link_suffix": "/forum?id=S1OAqOtN5U",
        "link": "https://openreview.net/forum?id=S1OAqOtN5U",
        "pdf_link": "https://openreview.net/pdf?id=S1OAqOtN5U",
        "keywords": "Bayes Adaptive Markov Decision Process, Monte Carlo Tree Search, Offline Reinforcement Learning",
        "abstract": "Offline reinforcement learning (RL) is a powerful approach for data-driven decision-making and control. Compared to model-free methods, offline model-based reinforcement learning (MBRL) explicitly learns world models from a static dataset and uses them as surrogate simulators, improving the data efficiency and enabling the learned policy to potentially generalize beyond the dataset support. However, there could be various MDPs that behave identically on the offline dataset and so dealing with the uncertainty about the true MDP can be challenging.  In this paper, we propose modeling offline MBRL as a Bayes Adaptive Markov Decision Process (BAMDP), which is a principled framework for addressing model uncertainty. We further introduce a novel Bayes Adaptive Monte-Carlo planning algorithm capable of solving BAMDPs in continuous state and action spaces with stochastic transitions. This planning process is based on Monte Carlo Tree Search and can be integrated into offline MBRL as a policy improvement operator in policy iteration. Our \"RL + Search\" framework follows in the footsteps of superhuman AIs like AlphaZero, improving on current offline MBRL methods by incorporating more computation input. The proposed algorithm significantly outperforms state-of-the-art model-based and model-free offline RL methods on twelve D4RL MuJoCo benchmark tasks and three target tracking tasks in a challenging, stochastic tokamak control simulator."
    },
    {
        "title": "Evaluating and Improving Subspace Inference in Bayesian Deep Learning",
        "link_suffix": "/forum?id=1wRXUROlzY",
        "link": "https://openreview.net/forum?id=1wRXUROlzY",
        "pdf_link": "https://openreview.net/pdf?id=1wRXUROlzY",
        "keywords": "Subspace inference, Bayesian neural networks, Uncertainty quantification",
        "abstract": "Bayesian neural networks incorporate Bayesian inference over model weights to account for uncertainty in weight estimation and predictions. Since full Bayesian inference methods are computationally expensive and suffer from high dimensionality, subspace inference has emerged as an appealing class of methods for approximate inference, where inference is restricted to a lower-dimensional weight subspace. Despite their benefits, existing subspace inference methods have notable pitfalls in terms of subspace construction, subspace evaluation, and inference efficiency. \nIn this work, we conduct a comprehensive analysis of current subspace inference techniques and address all the aforementioned issues. \nFirst, we propose a block-averaging construction strategy that improves subspace quality by better resembling subspaces built from the full stochastic gradient descent trajectory. Second, to directly evaluate subspace quality, we propose novel metrics based on the Bayes factor and prior predictive, focusing on both goodness-of-fit and generalization abilities. Finally, we enhance inference within the subspace by leveraging importance sampling and quasi-Monte Carlo methods, significantly reducing computational overhead. Our experimental results demonstrate that the proposed methods not only improve computational efficiency but also achieve better accuracy and uncertainty quantification compared to existing subspace inference methods on CIFAR and UCI datasets."
    },
    {
        "title": "Revisiting Source-Free Domain Adaptation: a New Perspective via Uncertainty Control",
        "link_suffix": "/forum?id=nx9Z5Kva96",
        "link": "https://openreview.net/forum?id=nx9Z5Kva96",
        "pdf_link": "https://openreview.net/pdf?id=nx9Z5Kva96",
        "keywords": "Source-Free Domain Adaptation, Unsupervised Domain Adaptation",
        "abstract": "Source-Free Domain Adaptation (SFDA) seeks to adapt a pre-trained source model to the target domain using only unlabeled target data, without access to the original source data. While current state-of-the-art (SOTA) methods rely on leveraging weak supervision from the source model to extract reliable information for self-supervised adaptation, they often overlook the uncertainty that arises during the transfer process.  In this paper, we conduct a systematic and theoretical analysis of the uncertainty inherent in existing SFDA methods and demonstrate its impact on transfer performance through the lens of Distributionally Robust Optimization (DRO). Building upon the theoretical results, we propose a novel instance-dependent uncertainty control algorithm for SFDA.  Our method is designed to quantify and exploit the uncertainty during the adaptation process, significantly improving the model performance.  Extensive experiments on benchmark datasets and empirical analyses confirm the validity of our theoretical findings and the effectiveness of the proposed method. \nThis work offers new insights into understanding and advancing SFDA performance."
    },
    {
        "title": "Generalizable Motion Planning via Operator Learning",
        "link_suffix": "/forum?id=UYcUpiULmT",
        "link": "https://openreview.net/forum?id=UYcUpiULmT",
        "pdf_link": "https://openreview.net/pdf?id=UYcUpiULmT",
        "keywords": "Motion planning, operator learning, value function approximation, Eikonal PDE",
        "abstract": "In this work, we introduce a planning neural operator (PNO) for predicting the value function of a motion planning problem. We recast value function approximation as learning a single operator from the cost function space to the value function\nspace, which is defined by an Eikonal partial differential equation (PDE). Therefore, our PNO model, despite being trained with a finite number of samples at coarse resolution, inherits the zero-shot super-resolution property of neural operators. We demonstrate accurate value function approximation at 16\u00d7 the training resolution on the MovingAI lab\u2019s 2D city dataset and compare with state-of-the-art neural\nvalue function predictors on 3D scenes from the iGibson building dataset. Lastly, we investigate employing the value function output of PNO as a heuristic function to accelerate motion planning. We show theoretically that the PNO heuristic is $\\epsilon$-consistent by introducing an inductive bias layer that guarantees our value functions satisfy the triangle inequality. With our heuristic, we achieve a $30$% decrease in\nnodes visited while obtaining near optimal path lengths on the MovingAI lab 2D city dataset, compared to classical planning methods (A$^\\ast$, RRT$^\\ast$)."
    },
    {
        "title": "Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning",
        "link_suffix": "/forum?id=XMgpnZ2ET7",
        "link": "https://openreview.net/forum?id=XMgpnZ2ET7",
        "pdf_link": "https://openreview.net/pdf?id=XMgpnZ2ET7",
        "keywords": "Model-based Reinforcement Learning, World Model, Causal Representation Learning, Generalization in Reinforcement Learning",
        "abstract": "Generalization in reinforcement learning (RL) remains a significant challenge, especially when agents encounter novel environments with unseen dynamics. Drawing inspiration from human compositional reasoning\u2014where known components are reconfigured to handle new situations\u2014we introduce World Modeling with Compositional Causal Components (WM3C). This novel framework enhances RL generalization by learning and leveraging compositional causal components. Unlike previous approaches focusing on invariant representation learning or meta-learning, WM3C identifies and utilizes causal dynamics among composable elements, facilitating robust adaptation to new tasks. Our approach integrates language as a compositional modality to decompose the latent space into meaningful components and provides theoretical guarantees for their unique identification under mild assumptions. Our practical implementation uses a masked autoencoder with mutual information constraints and adaptive sparsity regularization to capture high-level semantic information and effectively disentangle transition dynamics. Experiments on numerical simulations and real-world robotic manipulation tasks demonstrate that WM3C significantly outperforms existing methods in identifying latent processes, improving policy learning, and generalizing to unseen tasks."
    },
    {
        "title": "Revisiting Random Walks for Learning on Graphs",
        "link_suffix": "/forum?id=SG1R2H3fa1",
        "link": "https://openreview.net/forum?id=SG1R2H3fa1",
        "pdf_link": "https://openreview.net/pdf?id=SG1R2H3fa1",
        "keywords": "Graph machine learning, random walk, invariance, universal approximation, markov chain",
        "abstract": "We revisit a recent model class for machine learning on graphs, where a random walk on a graph produces a machine-readable record, and this record is processed by a deep neural network to directly make vertex-level or graph-level predictions. We refer to these stochastic machines as random walk neural networks (RWNNs), and through principled analysis, show that we can design them to be isomorphism invariant while capable of universal approximation of graph functions in probability. A useful finding is that almost any kind of record of random walk guarantees probabilistic invariance as long as the vertices are anonymized. This enables us, for example, to record random walks in plain text and adopt a language model to read these text records to solve graph tasks. We further establish a parallelism to message passing neural networks using tools from Markov chain theory, and show that over-smoothing in message passing is alleviated by construction in RWNNs, while over-squashing manifests as probabilistic under-reaching. We empirically demonstrate RWNNs on a range of problems, verifying our theoretical analysis and demonstrating the use of language models for separating strongly regular graphs where the 3-WL test fails, and transductive classification on arXiv citation network."
    },
    {
        "title": "Provably Learning Concepts by Comparison",
        "link_suffix": "/forum?id=QwrnH32tJV",
        "link": "https://openreview.net/forum?id=QwrnH32tJV",
        "pdf_link": "https://openreview.net/pdf?id=QwrnH32tJV",
        "keywords": "Concept Learning, Compositional Learning, Interpretability",
        "abstract": "We are born with the ability to learn concepts by comparing diverse observations. This helps us to understand the new world in a compositional manner and facilitates extrapolation, as objects naturally consist of multiple concepts. In this work, we argue that the cognitive mechanism of comparison, fundamental to human learning, is also vital for machines to recover true concepts underlying the data. This offers correctness guarantees for the field of concept learning, which, despite its impressive empirical successes, still lacks general theoretical support. Specifically, we aim to develop a theoretical framework for the identifiability of concepts with multiple classes of observations. We show that with sufficient diversity across classes, hidden concepts can be identified without assuming specific concept types, functional relations, or parametric generative models. Interestingly, even when conditions are not globally satisfied, we can still provide alternative guarantees for as many concepts as possible based on local comparisons, thereby extending the applicability of our theory to more flexible scenarios. Moreover, the hidden structure between classes and concepts can also be identified nonparametrically. We validate our theoretical results in both synthetic and real-world settings."
    },
    {
        "title": "On Choice of Loss Functions For Neural Control Barrier Certificates",
        "link_suffix": "/forum?id=GFaplOjE7E",
        "link": "https://openreview.net/forum?id=GFaplOjE7E",
        "pdf_link": "https://openreview.net/pdf?id=GFaplOjE7E",
        "keywords": "Safe Learning for Control; Control Systems; Neural Control Barrier Certificates",
        "abstract": "The design of controllers with correctness guarantees is a primary concern for safety-critical control systems. \nA Control Barrier Certificate (CBC) is a real-valued function over the state space of the system that provides an inductive proof of the existence of a safe controller. \nRecently, neural networks have been successfully deployed for data-driven learning of control barrier certificates. \nThese approaches encode the conditions for the existence of a CBC using a rectified linear unit (ReLU) loss function. \nThe resulting encoding, while sound, tends to be conservative, which results in slower training and limits scalability to large, complex systems. \nCan altering the loss function alleviate some of the problems associated with ReLU loss and lead to faster learning?This paper proposes a novel encoding with a Mean Squared Error (MSE) loss function, which allows for more scalable and efficient training, while addressing some of the theoretical limitations of previous methods. \nThe proposed approach derives a validity condition based on Lipschitz continuity to formally characterize safety guarantees, eliminating the need for a post-hoc verification. \nThe effectiveness of the proposed loss functions is demonstrated through six case studies curated from the existing state of the art.\nOur results provide a compelling argument for exploring alternative loss function choices as a novel approach to optimizing the design of control barrier certificates."
    },
    {
        "title": "Doubly robust identification of treatment effects from multiple environments",
        "link_suffix": "/forum?id=9vTAkJ9Tik",
        "link": "https://openreview.net/forum?id=9vTAkJ9Tik",
        "pdf_link": "https://openreview.net/pdf?id=9vTAkJ9Tik",
        "keywords": "treatment effect, confounding, heterogenous data, causality, causal inference, unobserved variables, post-treatment variables, collider bias",
        "abstract": "Practical and ethical constraints often dictate the use of observational data for causal inference, particularly in medicine and social sciences. Yet, observational datasets are prone to confounding, potentially compromising the validity of conclusions. While adjusting for all available covariates is a common corrective strategy, this approach can introduce bias, especially when post-treatment variables are present or some variables remain unobserved\u2014a frequent scenario in practice. Avoiding this bias often requires detailed knowledge of the underlying causal graph, a challenging and often impractical prerequisite. In this work, we propose RAMEN, an algorithm that tackles this challenge by leveraging the heterogeneity of multiple data sources without the need to know the complete causal graph. Notably, RAMEN achievesdoubly robust identification: we identify the treatment effect if either the causal parents of the treatment or those of the outcome are observed. Empirical evaluations across synthetic, semi-synthetic, and real-world datasets show that our approach significantly outperforms existing methods."
    },
    {
        "title": "Convergence Towards Stable Intrinsic Self-correction of Large Language Models",
        "link_suffix": "/forum?id=bEbQBiMpUI",
        "link": "https://openreview.net/forum?id=bEbQBiMpUI",
        "pdf_link": "https://openreview.net/pdf?id=bEbQBiMpUI",
        "keywords": "self-correction, large language models, morality, toxicity, social bias",
        "abstract": "Large Language Models (LLMs) are able to improve their responses when instructed to do so, a capability known as self-correction. \nWhen instructions provide only the task's goal without specific details about potential issues in the response, LLMs must rely on their internal knowledge to improve response quality, a process referred to as intrinsic self-correction. \nThe empirical success of intrinsic self-correction is evident in various applications, but how and why it is effective remains unknown.\nIn this paper, we unveil that intrinsic self-correction can be progressively improved, allowing it to approach a converged state. Our findings are verified in: (1) the scenario of multi-round question answering, by comprehensively demonstrating that intrinsic self-correction can progressively introduce performance gains through iterative interactions, ultimately converging to stable performance; and (2) the context of intrinsic self-correction for enhanced morality, in which we provide empirical evidence that iteratively applying instructions reduces model uncertainty towards convergence, which then leads to convergence of both the calibration error and self-correction performance, ultimately resulting in a stable state of intrinsic self-correction. Furthermore, we introduce a mathematical formulation and a simulation task indicating that the latent concepts activated by self-correction instructions drive the reduction of model uncertainty.\nBased on our experimental results and analysis of the convergence of intrinsic self-correction, we reveal its underlying mechanism: consistent injected instructions reduce model uncertainty which yields converged, improved performance."
    }
]
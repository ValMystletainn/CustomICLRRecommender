[{"title": "Convergence of Distributed Adaptive Optimization with Local Updates", "link_suffix": "/forum?id=VNg7srnvD9", "link": "https://openreview.net/forum?id=VNg7srnvD9", "pdf_link": "https://openreview.net/pdf?id=VNg7srnvD9", "keywords": "distributed optimization; Adam; theoretical benefits of local updates", "abstract": "We study distributed adaptive algorithms with local updates (intermittent communication).  Despite the great empirical success of adaptive methods in distributed training of modern machine learning models, the theoretical benefits of local updates within adaptive methods, particularly in terms of reducing communication complexity, have not been fully understood yet. In this paper, we prove that \\em Local SGD \\em with momentum (\\em Local \\em  SGDM) and \\em Local \\em  Adam can outperform their minibatch counterparts in convex and weakly convex settings, respectively. Our analysis relies on a novel technique to prove contraction during local iterations, which is a crucial yet challenging step to show the advantages of local updates, under generalized smoothness assumption and gradient clipping strategy.", "title_embedding_index": 15500, "title_abs_embedding_index": 15525}, {"title": "LightSAM: Parameter-Agnostic Sharpness-Aware Minimization", "link_suffix": "/forum?id=pmYpa7GpFH", "link": "https://openreview.net/forum?id=pmYpa7GpFH", "pdf_link": "https://openreview.net/pdf?id=pmYpa7GpFH", "keywords": "optimization, parameter-agnostic, sharpness-aware", "abstract": "Sharpness-Aware Minimization (SAM) optimizer enhances the generalization ability of the machine learning model by exploring the flat minima landscape through weight perturbations. Despite its empirical success, SAM introduces an additional hyper-parameter, the perturbation radius, which causes the sensitivity of SAM to it. Moreover, it has been proved that the perturbation radius and learning rate of SAM are constrained by problem-dependent parameters to guarantee convergence. These limitations indicate the requirement of parameter-tuning in practical applications. In this paper, we propose the algorithm LightSAM which sets the perturbation radius and learning rate of SAM adaptively, thus extending the application scope of SAM. LightSAM employs three popular adaptive optimizers, including AdaGrad-Norm, AdaGrad and Adam, to replace the SGD optimizer for weight perturbation and model updating, reducing sensitivity to parameters. Theoretical results show that under weak assumptions, LightSAM could converge ideally with any choices of perturbation radius and learning rate, thus achieving parameter-agnostic. We conduct preliminary experiments on several deep learning tasks, which together with the theoretical findings validate the the effectiveness of LightSAM.", "title_embedding_index": 15501, "title_abs_embedding_index": 15526}, {"title": "Learning a Neural Solver for Parametric PDE to Enhance Physics-Informed Methods", "link_suffix": "/forum?id=jqVj8vCQsT", "link": "https://openreview.net/forum?id=jqVj8vCQsT", "pdf_link": "https://openreview.net/pdf?id=jqVj8vCQsT", "keywords": "Physics-informed Deep Learning, PDE Solver, Parametric PDE, PINNs", "abstract": "Physics-informed deep learning often faces optimization challenges due to the complexity of solving partial differential equations (PDEs), which involve exploring large solution spaces, require numerous iterations, and can lead to unstable training. These challenges arise particularly from the ill-conditioning of the optimization problem, caused by the differential terms in the loss function. To address these issues, we propose learning a solver, i.e., solving PDEs using a physics-informed iterative algorithm trained on data. Our method learns to condition a gradient descent algorithm that automatically adapts to each PDE instance, significantly accelerating and stabilizing the optimization process and enabling faster convergence of physics-aware models. Furthermore, while traditional physics-informed methods solve for a single PDE instance, our approach addresses parametric PDEs. Specifically, our method integrates the physical loss gradient with the PDE parameters to solve over a distribution of PDE parameters, including coefficients, initial conditions, or boundary conditions. We demonstrate the effectiveness of our method through empirical experiments on multiple datasets, comparing training and test-time optimization performance.", "title_embedding_index": 15502, "title_abs_embedding_index": 15527}, {"title": "USDC: A Dataset ofU\u2015serS\u2015tance andD\u2015ogmatism in LongC\u2015onversations", "link_suffix": "/forum?id=Eaw1ZrsNUN", "link": "https://openreview.net/forum?id=Eaw1ZrsNUN", "pdf_link": "https://openreview.net/pdf?id=Eaw1ZrsNUN", "keywords": "large language models, annotators, user opinions, stance, dogmatism, human-llm alignment, open-source llms, closed-source llms", "abstract": "Although prior studies have explored Stance and Dogmatism in user conversations, their datasets are constructed at the post level, treating each post as independent and randomly sampling posts from conversation threads. Thus, Stance and Dogmatism labels in these datasets cannot capture the user's opinion fluctuations expressed throughout the entire conversation context. However, identifying user's opinion fluctuations in long conversation threads on various topics can be extremely critical for enhanced personalization, market research, political campaigns, customer service, conflict resolution, targeted advertising, and content moderation. Hence, training language models to automate this task is critical. However, to train such models, gathering manual annotations has multiple challenges: 1) It is time-consuming and costly; 2) Conversation threads could be very long, increasing chances of noisy annotations; and 3) Interpreting instances where a user changes their opinion within a conversation is difficult because often such transitions are subtle and not expressed explicitly. Inspired by the recent success of large language models (LLMs) for complex natural language processing tasks, we leverage Mistral Large and GPT-4 to automate the human annotation process on the following two tasks while also providing reasoning: i) User Stance classification, which involves labeling a user's stance of a post in a conversation on a five-point scale; ii) User Dogmatism classification, which deals with labeling a user's overall opinion in the conversation on a four-point scale. The majority voting on zero-shot, one-shot, and few-shot annotations from these two LLMs on 764 multi-user Reddit conversations helps us curate the USDC dataset. USDC is then used to finetune and instruction-tune multiple deployable small language models for the 5-class stance and 4-class dogmatism classification tasks. Additionally, human annotations on 200 test conversations achieved inter-annotator agreement scores of 0.49 for stance and 0.50 for dogmatism, indicating a reasonable level of consistency between human and LLM annotations. We make the code and dataset publicly available [https://anonymous.4open.science/r/USDC-0F7F].", "title_embedding_index": 15503, "title_abs_embedding_index": 15528}, {"title": "Theory on Score-Mismatched Diffusion Models and Zero-Shot Conditional Samplers", "link_suffix": "/forum?id=nWT6LxbuGi", "link": "https://openreview.net/forum?id=nWT6LxbuGi", "pdf_link": "https://openreview.net/pdf?id=nWT6LxbuGi", "keywords": "generative models, denoising diffusion probabilistic model (DDPM), convergence analysis, zero-shot conditional sampling, model mismatch", "abstract": "The denoising diffusion model has recently emerged as a powerful generative technique, capable of transforming noise into meaningful data. While theoretical convergence guarantees for diffusion models are well established when the target distribution aligns with the training distribution, practical scenarios often present mismatches. One common case is in zero-shot conditional diffusion sampling, where the target conditional distribution is different from the (unconditional) training distribution. These score-mismatched diffusion models remain largely unexplored from a theoretical perspective. In this paper, we present the first performance guarantee with explicit dimensional dependencies for general score-mismatched diffusion samplers, focusing on target distributions with finite second moments. We show that score mismatches result in an asymptotic distributional bias between the target and sampling distributions, proportional to the accumulated mismatch between the target and training distributions. This result can be directly applied to zero-shot conditional samplers for any conditional model, irrespective of measurement noise. Interestingly, the derived convergence upper bound offers useful guidance for designing a novel bias-optimal zero-shot sampler in linear conditional models that minimizes the asymptotic bias. For such bias-optimal samplers, we further establish convergence guarantees with explicit dependencies on dimension and conditioning, applied to several interesting target distributions, including those with bounded support and Gaussian mixtures. Our findings are supported by numerical studies.", "title_embedding_index": 15504, "title_abs_embedding_index": 15529}, {"title": "Towards Interpreting Visual Information Processing in Vision-Language Models", "link_suffix": "/forum?id=chanJGoa7f", "link": "https://openreview.net/forum?id=chanJGoa7f", "pdf_link": "https://openreview.net/pdf?id=chanJGoa7f", "keywords": "Interpretability, Vision-Language Model, Mechanistic Interpretability, Multimodal", "abstract": "Vision-Language Models (VLMs) are powerful tools for processing and understanding text and images. We study the processing of visual tokens in the language model component of LLaVA, a prominent VLM. Our approach focuses on analyzing the localization of object information, the evolution of visual token representations across layers, and the mechanism of integrating visual information for predictions. Through ablation studies, we demonstrated that object identification accuracy drops by over 70% when object-specific tokens are removed. We observed that visual token representations become increasingly interpretable in the vocabulary space across layers, suggesting an alignment with textual tokens corresponding to image content. Finally, we found that the model extracts object information from these refined representations at the last token position for prediction, mirroring the process in text-only language models for factual association tasks. These findings provide crucial insights into how VLMs process and integrate visual information, bridging the gap between our understanding of language and vision models, and paving the way for more interpretable and controllable multimodal systems.", "title_embedding_index": 15505, "title_abs_embedding_index": 15530}, {"title": "Mitigating Compositional Issues in Text-to-Image Generative Models via Enhanced Text Embeddings", "link_suffix": "/forum?id=QVBeBPsmy0", "link": "https://openreview.net/forum?id=QVBeBPsmy0", "pdf_link": "https://openreview.net/pdf?id=QVBeBPsmy0", "keywords": "Diffusion Models, Stable Diffusion, Compositionality, Generative Models, Explainability", "abstract": "Text-to-image diffusion-based generative models have the stunning ability to generate photo-realistic images and achieve state-of-the-art low FID scores on challenging image generation benchmarks. However, one of the primary failure modes of these text-to-image generative models is in composing attributes, objects, and their associated relationships accurately into an image. In our paper, we investigate this compositionality-based failure mode and highlight that imperfect text conditioning with CLIP text-encoder is one of the primary reasons behind the inability of these models to generate high-fidelity compositional scenes. In particular, we show that (i) there exists an optimal text-embedding space that can generate highly coherent compositional scenes showing that the output space of the CLIP text-encoder is sub-optimal, and (ii) the final token embeddings in CLIP are erroneous as they often include attention contributions from unrelated tokens in compositional prompts.  Our main finding shows that the best compositional improvements can be achieved (without harming the model's FID score) by fine-tuning only a simple and parameter-efficient linear projection on CLIP's representation space in Stable-Diffusion variants using a small set of compositional image-text pairs. This result demonstrates that the sub-optimality of the CLIP's output space is a major error source.  We also show that re-weighting the erroneous attention contributions in CLIP can lead to slightly improved compositional performances.", "title_embedding_index": 15506, "title_abs_embedding_index": 15531}, {"title": "Optimization on Manifolds with Riemannian Jacobian Regularization", "link_suffix": "/forum?id=aEJ5ilIuwg", "link": "https://openreview.net/forum?id=aEJ5ilIuwg", "pdf_link": "https://openreview.net/pdf?id=aEJ5ilIuwg", "keywords": "Riemannian manifolds, Flat minimizer, Sharpness-aware Minimization", "abstract": "Understanding the effectiveness of intrinsic geometry in enhancing a model's generalization ability, we draw upon prior works that apply geometric principles to optimization and present a novel approach to improve robustness and generalization for constrained optimization problems. This work aims to strengthen the sharpness-aware optimizers and proposes a novel Riemannian optimizer. We first present a theoretical analysis that characterizes the relationship between the general loss and the perturbation of the empirical loss in the context of Riemannian manifolds. Motivated by the result obtained from this analysis, we introduce our algorithm named Riemannian Jacobian Regularization (RJR), which explicitly regularizes the Riemannian gradient norm and the projected Hessian. To demonstrate RJR's ability to enhance generalization, we evaluate and contrast our algorithm on a broad set of problems, such as image classification and contrastive learning across different datasets with various architectures.", "title_embedding_index": 15507, "title_abs_embedding_index": 15532}, {"title": "AdaptiveQ-Network: On-the-fly Target Selection for Deep Reinforcement Learning", "link_suffix": "/forum?id=leACdxBEgv", "link": "https://openreview.net/forum?id=leACdxBEgv", "pdf_link": "https://openreview.net/pdf?id=leACdxBEgv", "keywords": "automated reinforcement learning, deep reinforcement learning, hyperparameter selection", "abstract": "Deep Reinforcement Learning (RL) is well known for being highly sensitive to hyperparameters, requiring practitioners substantial efforts to optimize them for the problem at hand. This also limits the applicability of RL in real-world scenarios. In recent years, the field of automated Reinforcement Learning (AutoRL) has grown in popularity by trying to address this issue. However, these approaches typically hinge on additional samples to select well-performing hyperparameters, hindering sample-efficiency and practicality. Furthermore, most AutoRL methods are heavily based on already existing AutoML methods, which were originally developed neglecting the additional challenges inherent to RL due to its non-stationarities. In this work, we propose a new approach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to RL to take into account the non-stationarity of the optimization procedure without requiring additional samples. AdaQN learns several $Q$-functions, each one trained with different hyperparameters, which are updated online using the $Q$-function with the smallest approximation error as a shared target. Our selection scheme simultaneously handles different hyperparameters while coping with the non-stationarity induced by the RL optimization procedure and being orthogonal to any critic-based RL algorithm. We demonstrate that AdaQN is theoretically sound and empirically validate it in MuJoCo control problems and Atari $2600$ games, showing benefits in sample-efficiency, overall performance, robustness to stochasticity and training stability.", "title_embedding_index": 15508, "title_abs_embedding_index": 15533}, {"title": "Exponential-Wrapped Mechanisms for Differential Privacy on Hadamard Manifolds", "link_suffix": "/forum?id=H4k6Yn5kSt", "link": "https://openreview.net/forum?id=H4k6Yn5kSt", "pdf_link": "https://openreview.net/pdf?id=H4k6Yn5kSt", "keywords": "Differential Privacy, Riemannian Manifold, Gaussian Differential Privacy, Renyi Differential Privacy, Hadamard Manifold, Frechet Mean, Symmetric Positive Definite Matrices", "abstract": "We extend the Differential Privacy (DP) framework to Hadamard manifolds, the class of complete and simply connected Riemannian manifolds with non-positive sectional curvature. Inspired by the Cartan\u2013Hadamard theorem, we introduce Exponential-Wrapped Laplace and Gaussian mechanisms to achieve $\\varepsilon$-DP, $(\\varepsilon, \\delta)$-DP, Gaussian DP (GDP), and R'enyi DP (RDP) on these manifolds. Our approach employs efficient, straightforward algorithms that circumvent the computationally intensity Monte Carlo Markov Chain (MCMC) methods.  This work is the first to extend $(\\varepsilon, \\delta)$-DP, GDP, and RDP to Hadamard manifolds. We further demonstrate the effectiveness of our methodology through simulations on the space of Symmetric Positive Definite Matrices, a frequently used Hadamard manifold in statistics. Our findings reveal that our Exponential-Wrapped mechanisms surpass traditional MCMC-based approaches, which require careful tuning and extensive diagnostics, in both performance and ease of use. Additionally, our methods achieve comparable utility to the Riemannian Laplace mechanism with enhanced utility for smaller privacy budgets ($\\varepsilon$) and operate orders of magnitude faster computationally.", "title_embedding_index": 15509, "title_abs_embedding_index": 15534}, {"title": "Replacing Implicit Regression with Classification in Policy Gradient Reinforcement Learning", "link_suffix": "/forum?id=xrWOR5wSOz", "link": "https://openreview.net/forum?id=xrWOR5wSOz", "pdf_link": "https://openreview.net/pdf?id=xrWOR5wSOz", "keywords": "reinforcement learning; policy gradient RL; actor-critic", "abstract": "Stochastic policy gradient methods are a fundamental class of reinforcement learning algorithms. When using these algorithms for continuous control it is common to parameterize the policy using a Gaussian distribution. In this paper, we show that the policy gradient with Gaussian policies can be viewed as the gradient of a weighted least-squares objective function. That is, policy gradient algorithms are implicitly implementing a form of regression. A number of recent works have shown that reformulating regression problems as classification problems can improve learning. Inspired by these works, we investigate whether replacing this implicit regression with classification can improve the data efficiency and stability of policy learning. Toward this end, we introduce a novel policy gradient surrogate objective for softmax policies over a discretized action space. This surrogate objective uses a form of cross-entropy loss as a replacement for the implicit least-squares loss found in the surrogate loss for Gaussian policies. We extend prior theoretical analysis of this loss to our policy gradient surrogate objective and then provide experiments showing that this novel loss improves the data efficiency of stochastic policy gradient learning.", "title_embedding_index": 15510, "title_abs_embedding_index": 15535}, {"title": "Enabling Weak LLMs to Judge Response Reliability via Meta Ranking", "link_suffix": "/forum?id=dRdjTNb5eN", "link": "https://openreview.net/forum?id=dRdjTNb5eN", "pdf_link": "https://openreview.net/pdf?id=dRdjTNb5eN", "keywords": "LLM Response Judgement, LLM Reliability, Weak Language Model, Model Cascading, Data Selection", "abstract": "Despite the strong performance of large language models (LLMs) across a wide range of tasks, they still have reliability issues. Previous studies indicate that strong LLMs like GPT-4-turbo excel in evaluating the reliability of responses from LLMs, but face efficiency and local deployment issues. Thus, to enable weak LLMs to effectively assess the reliability of LLM responses, we propose a novel cross-query-comparison-based method called $\\textit{Meta Ranking}$ (MR). Unlike previous few-shot methods that solely based on in-context learning capabilities in LLMs, MR assesses reliability by pairwise ranking the target query-response pair with multiple reference query-response pairs. We found that MR is highly effective in error detection for LLM responses, that MR with weaker LLMs, which have lower task performance, results in higher judgement precision against baselines with the same or even stronger models. Moreover, the method requires as few as five reference samples and significantly improving efficiency. \nWe further demonstrate that MR can enhance strong LLMs' performance in two practical applications: model cascading and instruction tuning. In model cascading, we combine open- and closed-source LLMs to achieve performance comparable to GPT-4-turbo with lower costs. In instruction tuning, we use MR for iterative training data filtering, significantly reducing data processing time and enabling LLaMA-7B and Phi-2 to surpass 13B models with fewer training tokens. These results underscore the high potential of MR in both efficiency and effectiveness.", "title_embedding_index": 15511, "title_abs_embedding_index": 15536}, {"title": "Enhancing Decision-Making of Large Language Models via Actor-Critic", "link_suffix": "/forum?id=0tXmtd0vZG", "link": "https://openreview.net/forum?id=0tXmtd0vZG", "pdf_link": "https://openreview.net/pdf?id=0tXmtd0vZG", "keywords": "Large Language Models, Decision-Making, Actor-Critic", "abstract": "Large Language Models (LLMs) have achieved significant advancements in natural language processing tasks, yet they encounter challenges in complex decision-making scenarios that require long-term reasoning and alignment with high-level objectives. This paper introduces a novel gradient-free LLM-based Actor-Critic framework, termed LAC, which addresses these limitations by integrating both action generation and action evaluation mechanisms. Our approach employs two distinct critics: a language-based critic that provides context-sensitive feedback and a value-based critic that offers quantitative assessments of expected long-term rewards. This dual-critic architecture enhances decision-making by leveraging the complementary strengths of both critics, enabling contextually appropriate and more robust action selection. Additionally, we propose a gradient-free policy improvement method that reduces computational overhead, facilitating efficient updates to the actor\u2019s policy without the complexities of gradient backpropagation. We validate the effectiveness of LAC across diverse environments that cover both high-level action space (ALFWorld) and low-level action space (BabyAI-Text), demonstrating its superior performance compared to existing state-of-the-art methods. Our method outperforms other state-of-the-art baselines using the same 7B/8B open-source LLMs and even exceeds a strong baseline ReAct using GPT-4 in most settings. Our findings highlight the efficacy and generality of the dual-critic Actor-Critic framework in enhancing LLM-based decision-making.", "title_embedding_index": 15512, "title_abs_embedding_index": 15537}, {"title": "TGTOD: A Global Temporal Graph Transformer for Outlier Detection at Scale", "link_suffix": "/forum?id=2o7wxbKEQY", "link": "https://openreview.net/forum?id=2o7wxbKEQY", "pdf_link": "https://openreview.net/pdf?id=2o7wxbKEQY", "keywords": "Graph Outlier Detection, Temporal Graph Learning, Graph Transformers", "abstract": "Graph outlier detection aims to identify anomalous substructures in graphs that deviate significantly from normal patterns. Traditional methods primarily focus on static graphs, overlooking the dynamic nature of real-world networks and ignoring valuable temporal signals crucial for outlier detection. While Transformers have revolutionized machine learning on time-series data, existing Transformers for temporal graphs face limitations in (1) restricted receptive fields, (2) overhead of subgraph extraction, and (3) suboptimal generalization capability beyond link prediction. In this paper, we propose TGTOD, a novel end-to-end Temporal Graph Transformer for Outlier Detection. TGTOD employs global attention to model both structural and temporal dependencies within temporal graphs. To tackle scalability, our approach divides large temporal graphs into spatiotemporal patches, which are then processed by a hierarchical Transformer architecture comprising Patch Transformer, Cluster Transformer, and Temporal Transformer. We evaluate TGTOD on three public datasets under two settings, comparing with a wide range of baselines. Our experimental results demonstrate the effectiveness of TGTOD, achieving AP improvement of 61% on Elliptic dataset. Furthermore, our efficiency evaluation shows that TGTOD reduces training time by 44\u00d7compared to existing Transformers for temporal graphs. To foster reproducibility, we make our implementation publicly available athttps://anonymous.4open.science/r/tgtod.", "title_embedding_index": 15513, "title_abs_embedding_index": 15538}, {"title": "Adversarial Attacks on Data Attribution", "link_suffix": "/forum?id=oJgIRwkIUB", "link": "https://openreview.net/forum?id=oJgIRwkIUB", "pdf_link": "https://openreview.net/pdf?id=oJgIRwkIUB", "keywords": "data attribution, adversarial attack, data-centric AI", "abstract": "Data attribution aims to quantify the contribution of individual training data points to the outputs of an AI model, which has been used to measure the value of training data and compensate data providers. Given the impact on financial decisions and compensation mechanisms, a critical question arises concerning the adversarial robustness of data attribution methods. However, there has been little to no systematic research addressing this issue. In this work, we aim to bridge this gap by detailing a threat model with clear assumptions about the adversary's goal and capabilities and proposing principled adversarial attack methods on data attribution. We present two methods,Shadow AttackandOutlier Attack, which generate manipulated datasets to inflate the compensation adversarially. The Shadow Attack leverages knowledge about the data distribution in the AI applications, and derives adversarial perturbations through \"shadow training\", a technique commonly used in membership inference attacks. In contrast, the Outlier Attack does not assume any knowledge about the data distribution and relies solely on black-box queries to the target model's predictions. It exploits an inductive bias present in many data attribution methods - outlier data points are more likely to be influential - and employs adversarial examples to generate manipulated datasets. Empirically, in image classification and text generation tasks, the Shadow Attack can inflate the data-attribution-based compensation by at least 200%, while the Outlier Attack achieves compensation inflation ranging from 185% to as much as 643%.", "title_embedding_index": 15514, "title_abs_embedding_index": 15539}, {"title": "Not All Prompts Are Made Equal: Prompt-based Pruning of Text-to-Image Diffusion Models", "link_suffix": "/forum?id=3BhZCfJ73Y", "link": "https://openreview.net/forum?id=3BhZCfJ73Y", "pdf_link": "https://openreview.net/pdf?id=3BhZCfJ73Y", "keywords": "Model Pruning, Diffusion Models, Inference Efficiency", "abstract": "Text-to-image (T2I) diffusion models have demonstrated impressive image generation capabilities. Still, their computational intensity prohibits resource-constrained organizations from deploying T2I models after fine-tuning them on their internaltargetdata. While pruning techniques offer a potential solution to reduce the computational burden of T2I models, static pruning methods use the same pruned model for all input prompts, overlooking the varying capacity requirements of different prompts. Dynamic pruning addresses this issue by utilizing a separate sub-network for each prompt, but it prevents batch parallelism on GPUs. To overcome these limitations, we introduce Adaptive Prompt-Tailored Pruning (APTP), a novel prompt-based pruning method designed for T2I diffusion models. Central to our approach is aprompt routermodel, which learns to determine the required capacity for an input text prompt and routes it to an architecture code, given a total desired compute budget for prompts. Each architecture code represents a specialized model tailored to the prompts assigned to it, and the number of codes is a hyperparameter. We train the prompt router and architecture codes using contrastive learning, ensuring that similar prompts are mapped to nearby codes. Further, we employ optimal transport to prevent the codes from collapsing into a single one. We demonstrate APTP's effectiveness by pruning Stable Diffusion (SD) V2.1 using CC3M and COCO astargetdatasets. APTP outperforms the single-model pruning baselines in terms of FID, CLIP, and CMMD scores. Our analysis of the clusters learned by APTP reveals they are semantically meaningful. We also show that APTP can automatically discover previously empirically found challenging prompts for SD,e.g.,prompts for generating text images, assigning them to higher capacity codes.", "title_embedding_index": 15515, "title_abs_embedding_index": 15540}, {"title": "Efficient Diffusion Models for Symmetric Manifolds", "link_suffix": "/forum?id=GLKig15TWJ", "link": "https://openreview.net/forum?id=GLKig15TWJ", "pdf_link": "https://openreview.net/pdf?id=GLKig15TWJ", "keywords": "Diffusion model, symmetric manifolds", "abstract": "We present a  framework for designing  efficient diffusion models on symmetric Riemannian manifolds, which include the  torus, sphere, special orthogonal group, and unitary group. While diffusion models on symmetric manifolds have gained significant attention, existing approaches often rely on the manifolds' heat kernels, which lack closed-form expressions and result in exponential-in-dimension per-iteration runtimes during training. We introduce a new diffusion model for symmetric-space manifolds, leveraging a projection of Euclidean Brownian motion to bypass explicit heat kernel computations. Our training algorithm minimizes a novel objective function derived via Ito's Lemma, with efficiently computable gradients, allowing each iteration to run in polynomial time for symmetric manifolds. Additionally, the symmetries of the manifold ensure the diffusion satisfies an \"average-case\" Lipschitz condition, enabling accurate and efficient sample generation. These improvements enhance both the training runtime and sample accuracy for key cases of symmetric manifolds, helping to bridge the gap between diffusion models on symmetric manifolds and Euclidean space.", "title_embedding_index": 15516, "title_abs_embedding_index": 15541}, {"title": "Graph Neural Network Is A Mean Field Game", "link_suffix": "/forum?id=mxkm1Pr2PM", "link": "https://openreview.net/forum?id=mxkm1Pr2PM", "pdf_link": "https://openreview.net/pdf?id=mxkm1Pr2PM", "keywords": "graph neural network, mean field game, reaction-diffusion equations, Hamiltonian flows", "abstract": "In current graph neural networks (GNNs), it is a common practice to apply a pre-defined message passing heuristics to all graph data, even though the stereotypical relational inductive bias (e.g., graph heat diffusion) might not fit the unseen graph topology. Such gross simplification might be responsible for the lack of an in-depth understanding of graph learning principles, which challenges us to push the boundary from crafting application-specific GNNs to embracing a \"meta-learning\" paradigm. In this work, we ratchet the gear of GNN another notch forward by formulating GNN as amean field game, that is, the best learning outcome occurs at theNash-equilibrium when the learned graph inference rationale allows each graph node to find what is the best feature representations for not only the individual node but also the entire graph. Following this spirit, we formulate the search for novel GNN mechanism into a variational framework ofmean-field control(MFC) problem, where the optimal relational inductive bias is essentially the critical point of mean-field information dynamics. Specifically, we seek for the best characteristic MFC functions of transportation mobility (controlling information exchange throughout the graph) and reaction mobility (controlling feature representation learning on each node), on the fly, that uncover the most suitable learning mechanism for a GNN instance by solving an MFC variational problem through the lens ofHamiltonian flows(formed in partial differential equations). In this context, our variational framework brings together existing GNN models into various mean-field games with distinct equilibrium states, each characterized by a unique MFC functional. Furthermore, we present an agnostic end-to-end deep model, coinedNash-GNN(in honor of Nobel laureate Dr. John Nash), to jointly carve the nature of the inductive bias and fine-tune the GNN hyper-parameters on top of the elucidated learning mechanism.Nash-GNNhas achieved SOTA performance on diverse graph data including popular benchmark datasets and human connectomes. More importantly, the mathematical insight of mean-field games provides a new window to understand the foundational principles of graph learning as an interactive dynamical system, which allows us to reshape the idea of designing next-generation GNN models.", "title_embedding_index": 15517, "title_abs_embedding_index": 15542}, {"title": "F-Fidelity: A Robust Framework for Faithfulness Evaluation of Explainable AI", "link_suffix": "/forum?id=X0r4BN50Dv", "link": "https://openreview.net/forum?id=X0r4BN50Dv", "pdf_link": "https://openreview.net/pdf?id=X0r4BN50Dv", "keywords": "Explainable AI, Evaluation Metric, Computer Vision", "abstract": "With the rapid development of eXplainable AI, various methods are proposed to explain attributions, such as Integral Gradient, and SmoothGrad. However, how to measure the faithfulness of explanations maintains an open question. The most popular removal strategy suffers from the Out-of-Distribution(OOD) problem. The RemOve And Retrain and Importance Measure try to solve the OOD problem by retraining while suffering information leakage and convergence problems. To address these problems and provide a robust evaluation method for faithfulness measurement, we propose a new method, Fine-tuned Fidelity(F-Fidelity).  It alleviates the OOD problem by using consistent augmentation operations in fine-tuning and evaluation stages to reduce the gap between the training set and evaluation inputs. To verify the effectiveness of F-Fidelity, we proposed a fair comparison strategy employing various degraded explanations. We have conducted experiments on Image and Natural Language Processing classification tasks with two datasets and two architectures for each task. The results demonstrate the generality, and robustness of F-Fidelity.", "title_embedding_index": 15518, "title_abs_embedding_index": 15543}, {"title": "Machine Reinforced Perturbation on Drifted Human Logical Reasoning", "link_suffix": "/forum?id=DjEyXTbEpa", "link": "https://openreview.net/forum?id=DjEyXTbEpa", "pdf_link": "https://openreview.net/pdf?id=DjEyXTbEpa", "keywords": "Human Logical Reasoning, Deep Reinforcement Learning, Cognitive Model", "abstract": "Using deep neural networks as computational models to simulate cognitive process can provide key insights into human behavioral dynamics. This enables synthetic data generation to test hypotheses for neuroscience and guides adaptive interventions for cognitive regulation. Challenges arise when environments are highly dynamic, obscuring stimulus-behavior relationships. However, the majority of current research focuses on simulating human cognitive behaviors under ideal conditions, neglecting the influence of environmental disturbances. We propose ReactiveAgent, integrating drift-diffusion with deep reinforcement learning to simulate granular effects of dynamic environmental stimuli on human logical reasoning process. This framework is built and evaluated upon our contributed large dataset of 21,157 logical responses of humans under various dynamic stimuli. Quantitatively, the framework improves cognition modelling by considering temporal effect of environmental stimuli on logical reasoning and captures both subject-specific and stimuli-specific behavioural differences. Qualitatively, it captures general trends in human logical reasoning under stress, better than baselines. Our approach is extensible to examining diverse environmental influences on cognitive behaviors. Overall, it demonstrates a powerful, data-driven methodology to simulate, align with, and understand the vagaries of human logical reasoning in dynamic contexts.", "title_embedding_index": 15519, "title_abs_embedding_index": 15544}, {"title": "Build Roadmap for Automated Feature Transformation: A Graph-based Reinforcement Learning Approach", "link_suffix": "/forum?id=3EeyQNgKTP", "link": "https://openreview.net/forum?id=3EeyQNgKTP", "pdf_link": "https://openreview.net/pdf?id=3EeyQNgKTP", "keywords": "Automated Feature Transformation, Tabular Data, Multi-Agent Reinforcement Learning", "abstract": "Feature transformation task aims to generate high-value features and improve the performance of downstream machine learning tasks using the mathematical feature-feature crossing. \nCurrent frameworks rely on iterative sequence generation with exploration optimization through performance feedback from downstream tasks.\nHowever, these approaches fail to effectively utilize historical decision-making experiences and overlook potential relationships among generated features, thus limiting the flexibility of the whole process.\nMoreover, the decision-making process lacks dynamic backtracking capabilities for each feature, leading to insufficient adaptability when encountering inefficient pathways, adversely affecting overall robustness and exploration stability.To overcome these challenges, we present an innovative framework that employs a feature-state transformation graph to maintain the roadmap of feature transformation, with each node symbolizing a transformation state. \nDuring exploration, three cascading agents sequentially select nodes and mathematical operations to generate new transformation states.\nThis strategy leverages the graph structure's inherent properties, allowing for the preservation and reuse of sight-seen and valuable transformations. \nIt also enables back-tracking capabilities through graph pruning techniques, which can rectify inefficient transformation paths.\nTo validate the efficacy and flexibility of our approach, we conducted comprehensive experiments and detailed case studies, demonstrating superior performance in diverse datasets.", "title_embedding_index": 15520, "title_abs_embedding_index": 15545}, {"title": "Diffusion Preference Alignment via Relative Text-Image Contrast", "link_suffix": "/forum?id=rH6IZIXqZG", "link": "https://openreview.net/forum?id=rH6IZIXqZG", "pdf_link": "https://openreview.net/pdf?id=rH6IZIXqZG", "keywords": "Diffusion Models, Human Preference Alignment, Fine-tuning", "abstract": "Aligning Large Language Models (LLMs) to human preferences has become a prominent area of research within language modeling. However, the application of preference learning to image generation in Text-to-Image (T2I) models remains relatively unexplored. One approach, Diffusion-DPO, initially experimented with pairwise preference learning in diffusion models for individual text prompts. We propose Diff-contrast, a novel method designed to align diffusion-based T2I models with human preferences. This method utilizes both prompt-image pairs with identical prompts and those that are semantically related across different modalities. Additionally, we introduced a new evaluation task, style alignment, to address the issues of high cost, low reproducibility, and poor interpretability associated with current evaluations of human preference alignment. Our results show that Diff-contrast surpasses existing techniques, e.g. Diffusion-DPO, in tuning Stable Diffusion versions 1.5 and XL-1.0 across both automated evaluations of human preference and style alignment.", "title_embedding_index": 15521, "title_abs_embedding_index": 15546}, {"title": "Online Gradient Boosting Decision Tree: In-Place Updates for Adding/Deleting Data", "link_suffix": "/forum?id=8G2CvYlfjw", "link": "https://openreview.net/forum?id=8G2CvYlfjw", "pdf_link": "https://openreview.net/pdf?id=8G2CvYlfjw", "keywords": "Machine Unlearning, Decremental Learning, Incremental Learning, Online Learning, Gradient Boosting Decision Trees", "abstract": "Gradient Boosting Decision Tree (GBDT) is one of the most popular machine learning models in various applications. But in the traditional settings, all data should be simultaneously accessed in the training procedure: it does not allow to add or delete any data instances after training. In this paper, we propose a novel online learning framework for GBDT supporting both incremental and decremental learning. To the best of our knowledge, this is the first work that considers an in-place unified incremental and decremental learning on GBDT. To reduce the learning cost, we present a collection of optimizations for our framework, so that it can add or delete a small fraction of data on the fly. We theoretically show the relationship between the hyper-parameters of the proposed optimizations, which enables trading off accuracy and cost on incremental and decremental learning. The backdoor attack results show that our framework can successfully inject and remove backdoor in a well-trained model using incremental and decremental learning, and the empirical results on public datasets confirm the effectiveness and efficiency of our proposed online learning framework and optimizations.", "title_embedding_index": 15522, "title_abs_embedding_index": 15547}, {"title": "Beyond Single Concept Vector: Modeling Concept Subspace in LLMs with Gaussian Distribution", "link_suffix": "/forum?id=CvttyK4XzV", "link": "https://openreview.net/forum?id=CvttyK4XzV", "pdf_link": "https://openreview.net/pdf?id=CvttyK4XzV", "keywords": "Large language model, Explainability, Probing, Gaussian distribution", "abstract": "Probing learned concepts in large language models (LLMs) is crucial for understanding how semantic knowledge is encoded internally. Training linear classifiers on probing tasks is a principle approach to denote the vector of a certain concept in the representation space. However, the single vector identified for a concept varies with both data and training, making it less robust and weakening its effectiveness in real-world applications. To address this challenge, we propose an approach to approximate the subspace representing a specific concept. Built on linear probing classifiers, we extend the concept vectors into Gaussian Concept Subspace (GCS). We demonstrate GCS's effectiveness through measuring its faithfulness and plausibility across multiple LLMs with different sizes and architectures. Additionally, we use representation intervention tasks to showcase its efficacy in real-world applications such as emotion steering. Experimental results indicate that GCS concept vectors have the potential to balance steering performance and maintaining the fluency in natural language generation tasks.", "title_embedding_index": 15523, "title_abs_embedding_index": 15548}, {"title": "ART: Actor-Related Tubelet for Detecting Complex-shaped Action Tubes", "link_suffix": "/forum?id=ICr9KMxa1K", "link": "https://openreview.net/forum?id=ICr9KMxa1K", "pdf_link": "https://openreview.net/pdf?id=ICr9KMxa1K", "keywords": "human action recognition, action tube localization", "abstract": "This paper focuses on detecting complex-shaped action tubes in videos. Existing methods are based on the assumption that actor's position changes slightly in short video clips. These methods either oversimplify the shape of action tubes by representing them as cuboids or conjecture that action tubes can be summarized into a set of learnable positional patterns. However, these solutions may be insufficient when actor trajectories become more complex. This limitation arises because these methods rely solely on position information to determine action tubes, lacking the ability to trace the same actor when their movement patterns are intricate. To address this issue, we propose Actor-related Tubelet (ART), which incorporates actor-specific information when generating action tubes. Regardless of the complexity of an actor's trajectory, ART ensures that an action tube consistently tracks the same actor, relying on actor-specific cues rather than solely on positional information. To evaluate the effectiveness of ART in handling complex-shaped action tubes, we introduce a dedicated metric that quantifies tube shape complexity. We conduct experiments on three commonly used tube detection datasets: MultiSports, UCF101-24 and JHMDB51-21. ART presents remarkable improvements on all the datasets.", "title_embedding_index": 15524, "title_abs_embedding_index": 15549}]
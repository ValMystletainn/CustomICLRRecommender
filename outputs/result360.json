[
    {
        "title": "Simple Policy Optimization",
        "link_suffix": "/forum?id=MOEqbKoozj",
        "link": "https://openreview.net/forum?id=MOEqbKoozj",
        "pdf_link": "https://openreview.net/pdf?id=MOEqbKoozj",
        "keywords": "Reinforcement Learning, Policy Optimization",
        "abstract": "Model-free reinforcement learning algorithms have seen remarkable progress, but key challenges remain. Trust Region Policy Optimization (TRPO) is known for ensuring monotonic policy improvement through conservative updates within a trust region, backed by strong theoretical guarantees. However, its reliance on complex second-order optimization limits its practical efficiency. Proximal Policy Optimization (PPO) addresses this by simplifying TRPO's approach using ratio clipping, improving efficiency but sacrificing some theoretical robustness. This raises a natural question: Can we combine the strengths of both methods? In this paper, we introduce Simple Policy Optimization (SPO), a novel unconstrained first-order algorithm. SPO integrates the surrogate objective with Total Variation (TV) divergence instead of Kullback-Leibler (KL) divergence, achieving a balance between the theoretical rigor of TRPO and the efficiency of PPO. Our new objective improves upon ratio clipping, offering stronger theoretical properties and better constraining the probability ratio within the trust region. Empirical results demonstrate that SPO achieves state-of-the-art performance, with a simple implementation and improves sample efficiency, particularly for training large, complex network architectures end-to-end."
    },
    {
        "title": "LazyLLM: DYNAMIC TOKEN PRUNING FOR EFFICIENT LONG CONTEXT LLM INFERENCE",
        "link_suffix": "/forum?id=am5Z8dXoaV",
        "link": "https://openreview.net/forum?id=am5Z8dXoaV",
        "pdf_link": "https://openreview.net/pdf?id=am5Z8dXoaV",
        "keywords": "Efficient LLM Inference, Optimization",
        "abstract": "The inference of transformer-based large language models consists of two sequential stages: 1) a prefilling stage to compute the KV cache of prompts and generate the first token, and 2) a decoding stage to generate subsequent tokens. For long prompts, the KV cache must be computed for all tokens during the prefilling stage, which can significantly increase the time needed to generate the first token. Consequently, the prefilling stage may become a bottleneck in the generation process. An open question remains whether all prompt tokens are essential for generating the first token. To answer this, we introduce a novel method, LazyLLM, that selectively computes the KV for tokens important for the next token prediction in both the prefilling and decoding stages. Contrary to static pruning approaches that prune the prompt at once, LazyLLM allows language models to dynamically select different subsets of tokens from the context in different generation steps, even though they might be pruned in previous steps. Extensive experiments on standard datasets across various tasks demonstrate that LazyLLM is a generic method that can be seamlessly integrated with existing language models to significantly accelerate the generation without fine-tuning. For instance, in the multi-document question-answering task, LazyLLM accelerates the prefilling stage of the LLama 2 7B model by 2.34\u00d7 while maintaining accuracy."
    },
    {
        "title": "Longhorn: State Space Models are Amortized Online Learners",
        "link_suffix": "/forum?id=8jOqCcLzeO",
        "link": "https://openreview.net/forum?id=8jOqCcLzeO",
        "pdf_link": "https://openreview.net/pdf?id=8jOqCcLzeO",
        "keywords": "Deep State Space Models, Linear Attention Models, Online Learning, Language Modeling",
        "abstract": "The most fundamental capability of modern AI methods such as Large Language Models (LLMs) is the ability to predict the next token in a long sequence of tokens, known as \u201csequence modeling.\u201d  Although the Transformers model is the current dominant approach to sequence modeling, its quadratic computational cost with respect to sequence length is a significant drawback. State-space models (SSMs) offer a promising alternative due to their linear decoding efficiency and high parallelizability during training. However, existing SSMs often rely on seemingly ad hoc linear recurrence designs.\nIn this work, we explore SSM design through the lens of online learning, conceptualizing SSMs as meta-modules for specific online learning problems. This approach links SSM design to formulating precise online learning objectives, with state transition rules derived from optimizing these objectives.\nBased on this insight, we introduce a novel deep SSM architecture based on the implicit update for optimizing an online regression objective. Our experimental results show that our models outperform state-of-the-art SSMs, including the Mamba model, on standard sequence modeling benchmarks and language modeling tasks."
    },
    {
        "title": "Complementary Coding of Space with Coupled Place Cells and Grid Cells",
        "link_suffix": "/forum?id=905dpz8K73",
        "link": "https://openreview.net/forum?id=905dpz8K73",
        "pdf_link": "https://openreview.net/pdf?id=905dpz8K73",
        "keywords": "Place cells, Grid cells, Complementary Coding of Space, Coupled Attractor Networks",
        "abstract": "Spatial coding is a fundamental function of the brain. Place cells in the hippocampus (HPC) and grid cells in the medial entorhinal cortex (MEC) are two primary types of neurons accounting for spatial representation in the brain. These two types of neurons employ different spatial coding strategies and process environmental and motion cues, respectively. \nIn this work, we develop a computational model to elucidate how place and grid cells can complement each other to integrate information optimally and overcome their respective shortcomings. Specifically, we build a model with reciprocally coupled continuous attractor neural networks (CANNs), in which a CANN with location coordinate models the place cell ensemble in HPC, and multiple CANNs with phase coordinate model grid cell modules with different spacings in MEC, and the coupling between place and grid cells conveys the correlation prior between sensory cues. We theoretically derive that the dynamics of our model effectively implements the gradient-based optimization of the posterior. Using simulations, we demonstrate that our model achieves Bayesian optimal integration of the environmental and motion cues, and avoids the non-local error problem in phase coding of grid cells. We hope that this study gives us insights into understanding how place and grid cells complement each other to improve spatial representation in the brain."
    },
    {
        "title": "SteerDiff: Steering towards Safe Text-To-Image Diffusion Models",
        "link_suffix": "/forum?id=Jlhq0zb76Q",
        "link": "https://openreview.net/forum?id=Jlhq0zb76Q",
        "pdf_link": "https://openreview.net/pdf?id=Jlhq0zb76Q",
        "keywords": "Diffusion Model, Text-to-image, concept unlearning",
        "abstract": "Text-to-image (T2I) diffusion models have drawn attention for their ability to generate high-quality images with precise text alignment. However, these models can also be misused to produce inappropriate content. Existing safety measures, which typically rely on text classifiers or ControlNet-like approaches, are often insufficient.\nTraditional text classifiers rely on large-scale labeled datasets and can be easily bypassed by rephrasing.\nAs diffusion models continue to scale, fine-tuning these safeguards becomes increasingly challenging and lacks flexibility. Recent red-teaming attack researches further underscore the need for a new paradigm to prevent the generation of inappropriate content.\nIn this paper, we introduce SteerDiff, a lightweight adaptor module designed to act as an intermediary between user input and the diffusion model, ensuring that generated images adhere to ethical and safety standards with little to no impact on usability. SteerDiff identifies and manipulates inappropriate concepts within the text embedding space to guide the model away from harmful outputs. We conduct extensive experiments across various concept unlearning tasks to evaluate the effectiveness of our approach. Furthermore, we benchmark SteerDiff against multiple red-teaming strategies to assess its robustness. Finally, we explore the potential of SteerDiff for concept forgetting tasks, demonstrating its versatility in text-conditioned image generation."
    },
    {
        "title": "CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation",
        "link_suffix": "/forum?id=KRv9NubipP",
        "link": "https://openreview.net/forum?id=KRv9NubipP",
        "pdf_link": "https://openreview.net/pdf?id=KRv9NubipP",
        "keywords": "Embodied AI, multi-agent cooperation, LLM",
        "abstract": "In this work, we address the cooperation problem among large language model (LLM) based embodied agents, where agents must cooperate to achieve a common goal. Previous methods often execute actions extemporaneously and incoherently, without long-term  strategic and cooperative planning, leading to redundant steps, failures, and even serious repercussions in complex tasks like search-and-rescue missions where discussion and cooperative plan are crucial.  To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance the cooperation efficiency of LLM-based embodied agents. Inspired by human cooperation schemes, CaPo improves cooperation efficiency with two  phases: 1) meta plan generation, and 2) progress-adaptive meta plan and execution. In the first phase, all agents analyze the task, discuss, and cooperatively create a meta-plan that decomposes the task into subtasks with detailed steps, ensuring a long-term strategic and coherent plan for efficient coordination.  In the second phase, agents execute tasks according to the meta-plan and dynamically adjust it based on their latest progress (e.g., discovering a target object) through multi-turn discussions.  This progress-based adaptation eliminates redundant actions, improving the overall cooperation efficiency of agents. Experimental results on the ThreeDworld Multi-Agent Transport and Communicative Watch-And-Help tasks demonstrate CaPo's much higher task completion rate and efficiency compared with  state-of-the-arts."
    },
    {
        "title": "SMITE: Segment Me In TimE",
        "link_suffix": "/forum?id=KW6B6s1X82",
        "link": "https://openreview.net/forum?id=KW6B6s1X82",
        "pdf_link": "https://openreview.net/pdf?id=KW6B6s1X82",
        "keywords": "video segmentation, diffusion models, video diffusion, part segmentation",
        "abstract": "Segmenting an object in a video presents significant challenges. Each pixel must be accurately labeled, and these labels must remain consistent across frames. The difficulty increases when the segmentation is with arbitrary granularity, meaning the number of segments can vary arbitrarily, and masks are defined based on only one or a few sample images. In this paper, we address this issue by employing a pre-trained text to image diffusion model supplemented with an additional tracking mechanism. We demonstrate that our approach can effectively manage various segmentation scenarios and outperforms state-of-the-art alternatives."
    },
    {
        "title": "TILDE-Q: a Transformation Invariant Loss Function for Time-Series Forecasting",
        "link_suffix": "/forum?id=7egJb0X9m2",
        "link": "https://openreview.net/forum?id=7egJb0X9m2",
        "pdf_link": "https://openreview.net/pdf?id=7egJb0X9m2",
        "keywords": "Time Series Forecasting, Deep Learning, Loss Function",
        "abstract": "Time-series forecasting has gained increasing attention in the field of artificial intelligence due to its potential to address real-world problems across various domains, including energy, weather, traffic, and economy. While time-series forecasting is a well-researched field, predicting complex temporal patterns such as sudden changes in sequential data still poses a challenge with current models. This difficulty stems from minimizing $L_p$ norm distances as loss functions, such as mean absolute error (MAE) or mean square error (MSE), which are susceptible to both intricate temporal dynamics modeling and signal shape capturing. Furthermore, these functions often cause models to behave aberrantly and generate uncorrelated results with the original time-series. Consequently, the development of a shape-aware loss function that goes beyond mere point-wise comparison is essential. In this paper, we examine the definition of shape and distortions, which are crucial for shape-awareness in time-series forecasting, and provide a design rationale for the shape-aware loss function. Based on our design rationale, we propose a novel, compact loss function called TILDE-Q (Transformation Invariant Loss function with Distance EQuilibrium) that considers not only amplitude and phase distortions but also allows models to capture the shape of time-series sequences. Furthermore, TILDE-Q supports the simultaneous modeling of periodic and nonperiodic temporal dynamics. We evaluate the efficacy of TILDE-Q by conducting extensive experiments under both periodic and nonperiodic conditions with various models ranging from naive to state-of-the-art. The experimental results show that the models trained with TILDE-Q surpass those trained with other metrics, such as MSE and DILATE, in various real-world applications, including electricity, traffic, illness, economics, weather, and electricity transformer temperature (ETT)."
    },
    {
        "title": "War and Peace (WarAgent): LLM-based Multi-Agent Simulation of World Wars",
        "link_suffix": "/forum?id=RBaDiInDRg",
        "link": "https://openreview.net/forum?id=RBaDiInDRg",
        "pdf_link": "https://openreview.net/pdf?id=RBaDiInDRg",
        "keywords": "large language model, multi-agent system, social simulation",
        "abstract": "This research explores the potential of Artificial Intelligence and Large Language Models in understanding and simulating complex human behaviors, specifically in the context of historical international conflicts. We introduce WarAgent, an LLM-powered multi-agent AI system, to simulate the decisions and consequences of participating countries in three specific historical conflicts. In addition, we propose standard evaluation protocols for LLM-based Multi-agent Systems simulation. Our study provides a nuanced analysis of the strengths and limitations of current MAS systems in simulating complex collective human behaviors under diverse settings of international conflicts. The emergent interactions among agents in our simulations offer fresh perspectives on the triggers and conditions leading to war. Our findings offer data-driven and AI-augmented insights that can help redefine how we approach conflict resolution and peacekeeping strategies. While we acknowledge the potential of AI in providing data-driven insights, we caution against over-reliance and emphasize the need for careful interpretation in conflict resolution and peacekeeping strategies. The implications of this work extend beyond computer simulation, offering a potential avenue for using AI to better understand human history. Code and data are available at \\url{https://anonymous.4open.science/r/WarAgent-0FF0}"
    },
    {
        "title": "WISE-GNN: Enhancing GNNs with Wise Embedding and Topological Encoding",
        "link_suffix": "/forum?id=7pIxS9m283",
        "link": "https://openreview.net/forum?id=7pIxS9m283",
        "pdf_link": "https://openreview.net/pdf?id=7pIxS9m283",
        "keywords": "graph representation learning, graph neural networks, node classification",
        "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful framework for graph representation learning. However, they often struggle to capture long-range dependencies between distant nodes, leading to suboptimal performance in tasks such as node classification, particularly in heterophilic graphs. Challenges like oversmoothing, oversquashing, and underreaching intensify the problem, limiting GNN effectiveness in such settings.In this paper, we introduceWISE-GNN, a novel framework designed to address these limitations. Our approach enhances any GNN model by incorporatingWise-embeddings, which capture attribute proximity and similarities among distant nodes, thereby improving the representation of nodes in both homophilic and heterophilic graphs. Additionally, we propose a topological module that can be smoothly integrated into any GNN model, further enriching node representations by incorporating the topological signatures of node neighborhoods. Comprehensive experiments across various GNN architectures show that WISE-GNN delivers significant improvements in node classification tasks, achieving mean accuracy gains of up to 14% and 23% on benchmark datasets in homophilic and heterophilic settings, respectively. Moreover, WISE-GNN enhances the performance of various GNN architectures, allowing even standard GNNs to outperform SOTA baselines on benchmark datasets."
    },
    {
        "title": "MLLM Is a Strong Reranker: Advancing Multimodal Retrieval-augmented Generation via Knowledge-enhanced Reranking and Noise-injected Training",
        "link_suffix": "/forum?id=TPtzZQyiFm",
        "link": "https://openreview.net/forum?id=TPtzZQyiFm",
        "pdf_link": "https://openreview.net/pdf?id=TPtzZQyiFm",
        "keywords": "Multimodal Retrieval-augmented Generation, Multimodal Large Language Model",
        "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in processing and generating content across multiple data modalities. However, a significant drawback of MLLMs is their reliance on static training data, leading to outdated information and limited contextual awareness. This static nature hampers their ability to provide accurate and up-to-date responses, particularly in dynamic or rapidly evolving contexts. Though integrating Multimodal Retrieval-augmented Generation (Multimodal RAG) offers a promising solution, the system would inevitably encounter the multi-granularity noisy correspondence (MNC) problem, which hinders accurate retrieval and generation. In this work, we propose RagVL, a novel framework with knowledge-enhanced reranking and noise-injected training, to address these limitations. We instruction-tune the MLLM with a simple yet effective instruction template to induce its ranking ability and serve it as a reranker to precisely filter the top-k retrieved images. For generation, we inject visual noise during training at the data and token levels to enhance the generator's robustness. Extensive experiments on four datasets verify the effectiveness of our method. Code and models are available athttps://anonymous.4open.science/r/RagVL-F694."
    },
    {
        "title": "Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface",
        "link_suffix": "/forum?id=BwR8t91yqh",
        "link": "https://openreview.net/forum?id=BwR8t91yqh",
        "pdf_link": "https://openreview.net/pdf?id=BwR8t91yqh",
        "keywords": "large language model, agent, efficiency, human-computer interaction",
        "abstract": "Agents, as user-centric tools, are increasingly deployed for human task delegation, assisting with a broad spectrum of requests by generating thoughts, engaging with user proxies, and producing action plans. However, agents based on large language models often face substantial planning latency due to two primary factors: the efficiency limitations of the underlying LLMs due to their large size and high demand, and the structural complexity of the agents due to the extensive generation of intermediate steps to produce the final output. Given that inefficiency in service provision can undermine the value of automation for users, this paper presents a human-centered efficient agent planning method \u2013 Interactive Speculative Planning \u2013 aiming at enhancing the efficiency of agent planning through both system design and user interaction. Our approach advocates for the co-design of the agent system and user interface, underscoring the importance of an agent system that can fluidly manage user interactions and interruptions. By integrating human interruptions as a fundamental component of the system, we not only make it more user-centric but also expedite the entire process by leveraging human-in-the-loop interactions to provide accurate intermediate steps."
    },
    {
        "title": "Generalizable autoregressive modeling of time series through functional narratives",
        "link_suffix": "/forum?id=t5FD4QTDTu",
        "link": "https://openreview.net/forum?id=t5FD4QTDTu",
        "pdf_link": "https://openreview.net/pdf?id=t5FD4QTDTu",
        "keywords": "autoregressive modeling, transformers, time series",
        "abstract": "Time series data are inherently functions of time, yet current transformers often learn time series by modeling them as mere concatenations of time periods, overlooking their functional properties. In this work, we propose a novel objective for transformers that learn time series by re-interpreting them as temporal functions. We build an alternative sequence of time series by constructing degradation operators of different intensity in the functional space, creating augmented variants of the original sample that are abstracted or simplified to different degrees. Based on the new set of generated sequence, we train an autoregressive transformer that progressively recovers the original sample from the most simplified variant. Analogous to the next word prediction task in languages that learns narratives by connecting different words, our autoregressive transformer aims to learn the Narratives of Time Series (NoTS) by connecting different functions in time. Theoretically, we justify the construction of the alternative sequence through its advantages in approximating functions. When learning time series data with transformers, constructing sequences of temporal functions allows for a broader class of approximable functions (e.g., differentiation) compared to sequences of time periods, leading to a 26$%$ performance improvement in synthetic feature regression experiments. Experimentally, we validate NoTS in 3 different tasks across 22 real-world datasets, where we show that NoTS significantly outperforms other pre-training methods by up to 6%. Additionally, combining NoTS on top of existing transformer architectures can consistently boost the performance. Our results demonstrate the potential of NoTS as a general-purpose dynamic learner, offering a viable alternative for developing foundation models for time series analysis."
    },
    {
        "title": "DMQR-RAG: Diverse Multi-Query Rewriting in Retrieval-Augmented Generation",
        "link_suffix": "/forum?id=lz936bYmb3",
        "link": "https://openreview.net/forum?id=lz936bYmb3",
        "pdf_link": "https://openreview.net/pdf?id=lz936bYmb3",
        "keywords": "LLM, RAG, Query Rewrite",
        "abstract": "Large language models often encounter challenges with static knowledge and hallucinations, which undermine their reliability. Retrieval-augmented generation (RAG) mitigates these issues by incorporating external information. However, user queries frequently contain noise and intent deviations, necessitating query rewriting to improve the relevance of retrieved documents. In this paper, we introduce DMQR-RAG, a Diverse Multi-Query Rewriting framework designed to improve the performance of both document retrieval and final responses in RAG. Specifically, we investigate how queries with varying information quantities can retrieve a diverse array of documents, presenting four rewriting strategies that operate at different levels of information to enhance the performance of baseline approaches. Additionally, we propose an adaptive strategy selection method that minimizes the number of rewrites while optimizing overall performance. Our methods have been rigorously validated through extensive experiments conducted in both academic and industry settings."
    },
    {
        "title": "SCFormer: Spatial Coordination for Efficient and Robust Vision Transformers",
        "link_suffix": "/forum?id=QRmpkVsvqS",
        "link": "https://openreview.net/forum?id=QRmpkVsvqS",
        "pdf_link": "https://openreview.net/pdf?id=QRmpkVsvqS",
        "keywords": "Vision backbone, Transformer, Efficiency, Robustness, Spatial coordinating Attention.",
        "abstract": "We investigate the design of visual backbones with a focus on optimizing both efficiency and robustness. While recent advancements in hybrid Vision Transformers (ViTs) have significantly enhanced efficiency, achieving state-of-the-art performance with fewer parameters, their robustness against domain-shifted and corrupted inputs remains a critical challenge. This trade-off is particularly difficult to balance in lightweight models, where robustness often relies on wider channels to capture diverse spatial features. In this paper, we present SCFormer, a novel hybrid ViT architecture designed to address these limitations. SCFormer introduces Spatial Coordination Attention (SCA), a mechanism that coordinates cross-spatial pixel interactions by deconstructing and reassembling spatial conditions with diverse connectivity patterns. This approach broadens the representation boundary, allowing SCFormer to efficiently capture more diverse spatial dependencies even with fewer channels, thereby improving robustness without sacrificing efficiency. Additionally, we incorporate an Inceptional Local Representation (ILR) block to flexibly enrich local token representations before self-attention, enhancing both locality and feature diversity. Through extensive experiments, SCFormer demonstrates superior performance across multiple benchmarks. On ImageNet-1K, SCFormer-XS achieves 2.5% higher top-1 accuracy and 10% faster GPU inference speed compared to FastViT-T8. On ImageNet-A, SCFormer-L (30.1M) surpasses RVT-B (91.8M) in robustness accuracy by 5.6% while using 3$\\times$ fewer parameters. These results underscore the effectiveness of our design in achieving a new state-of-the-art balance between efficiency and robustness."
    },
    {
        "title": "Addition is All You Need for Energy-efficient Language Models",
        "link_suffix": "/forum?id=nXV3C8aKxZ",
        "link": "https://openreview.net/forum?id=nXV3C8aKxZ",
        "pdf_link": "https://openreview.net/pdf?id=nXV3C8aKxZ",
        "keywords": "energy saving, tensor multiplication, transformer",
        "abstract": "Large neural networks spend most computation on floating point tensor multiplications. In this work, we find that a floating point multiplier can be approximated by one integer adder with high precision. We propose the linear-complexity multiplication L-Mul algorithm that approximates floating point number multiplication with integer addition operations. The new algorithm costs significantly less computation resource than 8-bit floating point multiplication but achieves higher precision. Compared to 8-bit floating point multiplications, the proposed method achieves higher precision but consumes significantly less bit-level computation. Since multiplying floating point numbers requires substantially higher energy compared to integer addition operations, applying the L-Mul operation in tensor processing hardware can potentially reduce 95% energy cost by element-wise floating point tensor multiplications and 80% energy cost of dot products. We calculated the theoretical error expectation of L-Mul, and evaluated the algorithm on a wide range of textual, visual, and symbolic tasks, including natural language understanding, structural reasoning, mathematics, and commonsense question answering. Our numerical analysis experiments agree with the theoretical error estimation, which indicates that L-Mul with 4-bit mantissa achieves comparable precision as float8_e4m3 multiplications, and L-Mul with 3-bit mantissa outperforms float8_e5m2. Evaluation results on popular benchmarks show that directly applying L-Mul to the attention mechanism is almost lossless. We further show that replacing all floating point multiplications with 3-bit mantissa L-Mul in a transformer model achieves equivalent precision as using float8_e4m3 as accumulation precision in both fine-tuning and inference."
    },
    {
        "title": "On Expressive Power of Looped Transformers: Theoretical Analysis and Enhancement via Timestep Encoding",
        "link_suffix": "/forum?id=j87C29mAZl",
        "link": "https://openreview.net/forum?id=j87C29mAZl",
        "pdf_link": "https://openreview.net/pdf?id=j87C29mAZl",
        "keywords": "Transformers, Looped Transformers, Expressive power, Approximation Rate",
        "abstract": "Looped Transformers offer advantages in parameter efficiency and Turing completeness. However, their expressive power for function approximation and approximation rate remains underexplored. In this paper, we establish approximation rates of Looped Transformers by defining the concept of the modulus of continuity for sequence-to-sequence functions. This reveals a limitation specific to\nthe looped architecture. That is, the analysis prompts us to incorporate scaling parameters for each loop, conditioned on timestep encoding. Experimental results demonstrate that increasing the number of loops enhances performance, with further gains achieved through the timestep encoding architecture."
    },
    {
        "title": "MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models",
        "link_suffix": "/forum?id=s5epFPdIW6",
        "link": "https://openreview.net/forum?id=s5epFPdIW6",
        "pdf_link": "https://openreview.net/pdf?id=s5epFPdIW6",
        "keywords": "medical vision-language model, retrieval-augmented generation",
        "abstract": "Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new possibilities for interactive diagnostic tools. However, these models often suffer from factual hallucination, which can lead to incorrect diagnoses. Fine-tuning and retrieval-augmented generation (RAG) have emerged as methods to address these issues. However, the amount of high-quality data and distribution shifts between training data and deployment data limit the application of fine-tuning methods. Although RAG is lightweight and effective, existing RAG-based approaches are not sufficiently general to different medical domains and can potentially cause misalignment issues, both between modalities and between the model and the ground truth. In this paper, we propose a versatile multimodal RAG system, MMed-RAG, designed to enhance the factuality of Med-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an adaptive retrieved contexts selection, and a provable RAG-based preference fine-tuning strategy. These innovations make the RAG process sufficiently general and reliable, significantly improving alignment when introducing retrieved contexts. Experimental results across five medical datasets (involving radiology, ophthalmology, pathology) on medical VQA and report generation demonstrate that MMed-RAG can achieve an average improvement of 43.8% in factual accuracy in the factual accuracy of Med-LVLMs."
    },
    {
        "title": "YESNO-PRO: A HIGH-PERFORMANCE POINTWISE RERANKING ALGORITHM BRIDGING ENCODERDECODER AND DECODER-ONLY LLMS",
        "link_suffix": "/forum?id=z1pydjd4XQ",
        "link": "https://openreview.net/forum?id=z1pydjd4XQ",
        "pdf_link": "https://openreview.net/pdf?id=z1pydjd4XQ",
        "keywords": "zero-shot text reranking, Large Language Models",
        "abstract": "Recent research has shown significant progress in the field of zero-shot text reranking for large language models (LLMs). Traditional pointwise approaches prompt the LLM to output relevance labels such as \"yes/no\" or fine-grained labels, but they have several drawbacks. Firstly, these prompts struggle to capture complex correlations between queries and passages and lack robustness for outputs not covered by predefined labels. Secondly, ranking scores rely solely on the likelihood of relevance labels, leading to potential noise and bias. Lastly, existing pointwise approaches are not supported by decoder-only LLMs, as ranking requires LLMs to output prediction probabilities. In response to these challenges, a novel pointwise approach called yesno-pro has been designed, which redefines both prompt design and score computation mechanisms to better align with the intrinsic nature of text reranking. Additionally, a comprehensive reranking framework based on LLM services has been proposed to support concurrent ranking calls and quickly adapt to any open-source decoder-only large models. Experimental results have demonstrated that this method outperforms existing pointwise and some pairwise/listwise methods on TREC19/20 and BEIR datasets, achieving the state-of-the-art performance. Due to its concurrency features, this work is applicable to practical applications with high real-time requirements."
    },
    {
        "title": "Controllable Satellite-to-Street-View Synthesis with Precise Pose Alignment and Zero-Shot Environmental Control",
        "link_suffix": "/forum?id=f92M45YRfh",
        "link": "https://openreview.net/forum?id=f92M45YRfh",
        "pdf_link": "https://openreview.net/pdf?id=f92M45YRfh",
        "keywords": "Satellite to street-view synthesis, diffusion model, controllable, precise pose Alignment",
        "abstract": "Generating street-view images from satellite imagery is a challenging task, particularly in maintaining accurate pose alignment and incorporating diverse environmental conditions. While diffusion models have shown promise in generative tasks, their ability to maintain strict pose alignment throughout the diffusion process is limited. In this paper, we propose a novel Iterative Homography Adjustment (IHA) scheme applied during the denoising process, which effectively addresses pose misalignment and ensures spatial consistency in the generated street-view images. Additionally, currently, available datasets for satellite-to-street-view generation are limited in their diversity of illumination and weather conditions, thereby restricting the generalizability of the generated outputs. To mitigate this, we introduce a text-guided illumination and weather-controlled sampling strategy that enables fine-grained control over the environmental factors. Extensive quantitative and qualitative evaluations demonstrate that our approach significantly improves pose accuracy and enhances the diversity and realism of generated street-view images, setting a new benchmark for satellite-to-street-view generation tasks."
    },
    {
        "title": "Generating GFlowNets as You Wish with Diffusion Process",
        "link_suffix": "/forum?id=8ljEGpXuqB",
        "link": "https://openreview.net/forum?id=8ljEGpXuqB",
        "pdf_link": "https://openreview.net/pdf?id=8ljEGpXuqB",
        "keywords": "GFlowNet, Parameter generation",
        "abstract": "Generative Flow Networks (GFlowNets) are probabilistic samplers that learn stochastic policies to generate diverse sets of high-reward objects, which is essential in scientific discovery tasks. However, most existing GFlowNets necessitate training, becoming costly as the diversity of GFlowNets expands and trajectory lengths increase. To alleviate this problem,  we propose a method to Generate high-performing GFlowNet parameters based on a given model structure, called GenFlowNet. Specifically, we first prepare an autoencoder to extract latent representations of GeFlowNet parameters and reconstruct them. Then, a structure encoder is trained alongside a conditional latent diffusion model to generate the target GFlowNet parameters based on the given structure information. To the best of our knowledge, it is the first exploration to generate parameters of a probabilistic sampler using the diffusion process. It enables us to obtain a new GFlowNet without training, effectively reducing the trial-and-error cost during GFlowNet development. Extensive experiments on diverse structures and tasks validate the superiority and generalizability of our method."
    },
    {
        "title": "Seeing the Unseen: How EMoE Unveils Bias in Text-to-Image Diffusion Models",
        "link_suffix": "/forum?id=LlZ929lua7",
        "link": "https://openreview.net/forum?id=LlZ929lua7",
        "pdf_link": "https://openreview.net/pdf?id=LlZ929lua7",
        "keywords": "Uncertainty Quantification, Text-to-Image Modeling, Ensembles",
        "abstract": "Estimating uncertainty in text-to-image diffusion models is challenging due to their large parameter counts (often exceeding 100 million) and operation in complex, high-dimensional spaces with virtually infinite input possibilities. In this paper, we propose EMoE, a novel framework for efficiently estimating epistemic uncertainty in diffusion models. EMoE leverages pre-trained networks without requiring additional training, enabling direct uncertainty estimation from a prompt. We introduce a novel latent space within the diffusion process that captures model uncertainty better during the first denoising step than existing methods. Experimental results on the COCO dataset demonstrate EMoE's effectiveness, showing a strong correlation between uncertainty and image quality. Additionally, EMoE identifies under-sampled languages and regions with higher uncertainty, revealing hidden biases related to linguistic representation. This capability demonstrates the relevance of EMoE as a tool for addressing fairness and accountability in AI-generated content."
    },
    {
        "title": "FAMMA: A Benchmark for Financial Multilingual Multimodal Question Answering",
        "link_suffix": "/forum?id=gNOW7ch3Ye",
        "link": "https://openreview.net/forum?id=gNOW7ch3Ye",
        "pdf_link": "https://openreview.net/pdf?id=gNOW7ch3Ye",
        "keywords": "benchmark, multimodal large language model, financial question answering",
        "abstract": "In this paper, we introduce FAMMA, an open-source benchmark for financial multilingual multimodal question answering (QA).\nOur benchmark aims to evaluate the abilities of multimodal large language models (MLLMs) in answering questions that require advanced financial knowledge and sophisticated reasoning. It includes 1,758 meticulously collected question-answer pairs from university textbooks and exams, spanning 8 major subfields in finance including corporate finance, asset management, and financial engineering. Some of the QA pairs are written in Chinese or French, while a majority of them are in English. These questions are presented in a mixed format combining text and heterogeneous image types, such as charts, tables, and diagrams. \nWe evaluate a range of state-of-the-art MLLMs on our benchmark, and our analysis shows that FAMMA poses a significant challenge for these models. Even advanced systems like GPT-4o and Claude-35-Sonnet achieve only 42% accuracy. Additionally, the open-source Qwen2-VL lags notably behind its proprietary counterparts. Lastly, we explore GPT o1-style reasoning chains to enhance the models' reasoning capabilities, which significantly improve error correction.\nOur FAMMA benchmark will facilitate future research to develop expert systems in financial QA. The code and data have been anonymously released at \\small \\url{https://github.com/random2024GO/bench-script}."
    },
    {
        "title": "Bayesian Nonparametric Survival Analysis via Deep Dirichlet Process",
        "link_suffix": "/forum?id=dWi2c9auRm",
        "link": "https://openreview.net/forum?id=dWi2c9auRm",
        "pdf_link": "https://openreview.net/pdf?id=dWi2c9auRm",
        "keywords": "Bayesian nonparametric methods, Survival Analysis, Variational Inference",
        "abstract": "The analysis of time-to-event data has received increasing attention in many application fields. The key challenge is that the data are mostly incomplete, with the right censoring mechanism being the most popular form. While Cox's proportional hazards assumption has shown adaptivity to traditional time-to-event datasets, challenges are observed when generalizing this assumption to modern survival analysis --- the proportional hazards assumption is often violated when covariates are high-dimensional. Moreover, traditional parametric assumptions on the survival distribution mostly belong to the exponential family and thus the assumption is strong and their exponential decay rate leads to poor long-tail approximations. To overcome these challenges, we propose a novel deep learning framework for survival analysis, namedDDPSurv, which adopts a deeply parameterized Dirichlet process (DP) mixture model on survival distribution. Different from previous deep parametric approaches which rely on strong statistical assumptions, our framework can model the survival distribution with greater flexibility by adopting a DP mixture model. With the DP mixture model, we can improve the flexibility in modelling the survival distributions and achieve better tail behaviour by including the heavy-tail distributions in the mixture. We theoretically show that the proposed model can approximate the true survival distribution at a tight concentration rate. Empirical evaluations on standard survival benchmarks validate the satisfactory performance of the proposed method. Extensive experiments on large-scale clinical datasets --- MIMIC-III and MIMIC-IV --- highlight the scalability and clinical significance of our method. Codes are anonymously available athttps://anonymous.4open.science/r/DeepSurv-net-2215"
    },
    {
        "title": "A Dual-branch Multi-Band Neural Vocoder with Harmonic Discriminator for High-Fidelity Speech Synthesis",
        "link_suffix": "/forum?id=YTxx02MnTS",
        "link": "https://openreview.net/forum?id=YTxx02MnTS",
        "pdf_link": "https://openreview.net/pdf?id=YTxx02MnTS",
        "keywords": "Dual-branch, multi-band, CondNet, harmonic discriminator",
        "abstract": "Recent developments in vocoders are primarily dominated by GAN-based networks targeting to high-quality waveform generation from mel-spectrogram representations. However, these methods are typically computationally expensive and operate in the time-domain which neglect the time-frequency structures. In this paper, we propose the DMNet, a Dual-branch Multi-band Network to address these limitations. First, a reconstruction network of complex-valued spectrogram called CondNet is used as a condition and thus integrated into the GAN-based branch. Second, we use multi-band processing in the dual-branch: the CondNet produces Fourier spectral coefficients in one sub-band signal and GAN-based branch generates sub-band representations which are subsequently transformed to full-band speech. Finally, to further improve fidelity, we propose a novel harmonic discriminator which utilizes learnable harmonic filters at multiple scales for a better modeling ability in harmonic structures. In our experiments, DMNet validates the effectiveness and achieves superior performance for high quality waveform generation, both on subjective and objective metrics."
    }
]
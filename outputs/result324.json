[{"title": "R\u00e9nyi Neural Processes", "link_suffix": "/forum?id=b9w9b6naQG", "link": "https://openreview.net/forum?id=b9w9b6naQG", "pdf_link": "https://openreview.net/pdf?id=b9w9b6naQG", "keywords": "Neural processes, variational inference, meta learning, robust divergence", "abstract": "Neural Processes (NPs) are deep probabilistic models that represent stochastic processes by conditioning their prior distributions on a set of context points. Despite their obvious advantages in uncertainty estimation for complex distributions,  NPs enforce parameterization coupling between the conditional prior model and the posterior model, thereby risking introducing a misspecified prior distribution. We hereby revisit the NP objectives and propose R\u00e9nyi Neural Processes (RNP) to ameliorate the impacts of prior misspecification by optimizing an alternative posterior that achieves better marginal likelihood. More specifically, by replacing the standard KL divergence with the R\u00e9nyi divergence between the model posterior and the true posterior, we scale the density ratio $\\frac{p}{q}$ by the power of (1-$\\alpha$) in the divergence gradients with respect to the posterior. This hyper parameter $\\alpha$ allows us to dampen the effects of the misspecified prior for the posterior update, which has been shown to effectively avoid oversmoothed predictions and improve the expressiveness of the posterior model.\nOur extensive experiments show consistent log-likelihood improvements over state-of-the-art NP family models which adopt both the variational inference or maximum likelihood estimation objectives. We validate the effectiveness of our approach across multiple benchmarks including regression and image inpainting tasks, and show significant performance improvements of RNPs in real-world regression problems where the underlying prior model is misspecifed.", "title_embedding_index": 16150, "title_abs_embedding_index": 16175}, {"title": "3DIS: Depth-Driven Decoupled Instance Synthesis for Text-to-Image Generation", "link_suffix": "/forum?id=MagmwodCAB", "link": "https://openreview.net/forum?id=MagmwodCAB", "pdf_link": "https://openreview.net/pdf?id=MagmwodCAB", "keywords": "Image Generation; Diffusion Models", "abstract": "The increasing demand for controllable outputs in text-to-image generation has spurred advancements in multi-instance generation (MIG), allowing users to define both instance layouts and attributes. However, unlike image-conditional generation methods such as ControlNet, MIG techniques have not been widely adopted in state-of-the-art models like SD2 and SDXL, primarily due to the challenge of building robust renderers that simultaneously handle instance positioning and attribute rendering. In this paper, we introduce Depth-Driven Decoupled Instance Synthesis (3DIS), a novel framework that decouples the MIG process into two stages: (i) generating a coarse scene depth map for accurate instance positioning and scene composition, and (ii) rendering fine-grained attributes using pre-trained ControlNet on any foundational model, without additional training. Our 3DIS framework integrates a custom adapter into LDM3D for precise depth-based layouts and employs a finetuning-free method for enhanced instance-level attribute rendering. Extensive experiments on COCO-Position and COCO-MIG benchmarks demonstrate that 3DIS significantly outperforms existing methods in both layout precision and attribute rendering. Notably, 3DIS offers seamless compatibility with diverse foundational models, providing a robust, adaptable solution for advanced multi-instance generation.", "title_embedding_index": 16151, "title_abs_embedding_index": 16176}, {"title": "No-Regret and Incentive-Compatible Combinatorial Online Prediction", "link_suffix": "/forum?id=liSixK3eY4", "link": "https://openreview.net/forum?id=liSixK3eY4", "pdf_link": "https://openreview.net/pdf?id=liSixK3eY4", "keywords": "online learning", "abstract": "We study the combinatorial online learning prediction problem with bandit feedback in a strategic setting, where the experts can strategically influence the learning algorithm\u2019s predictions by manipulating their beliefs about a sequence of binary events. There are two learning objectives for the algorithm. The first is maximizing its cumulative utility over a fixed time horizon, equivalent to minimizing regret. The second objective is to ensure incentive compatibility, guaranteeing that each expert's optimal strategy is to report their true beliefs about the outcomes of each event. In real applications, the learning algorithm only receives the utility corresponding to their chosen experts, which is referred to as the full-bandit setting. In this work, we present an algorithm based on mirror descent, which achieves a regret of $O(T^{3/4})$ under both the full-bandit or semi-bandit feedback model, while ensuring incentive compatibility. To our best knowledge, this is the first algorithm that can simultaneously achieve sublinear regret and incentive compatibility. To demonstrate the effectiveness of our algorithm, we conduct extensive empirical evaluation with the algorithm on a synthetic dataset.", "title_embedding_index": 16152, "title_abs_embedding_index": 16177}, {"title": "Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs): learning neural networks for designing neutral inclusions", "link_suffix": "/forum?id=XxxKHiy9Gw", "link": "https://openreview.net/forum?id=XxxKHiy9Gw", "pdf_link": "https://openreview.net/pdf?id=XxxKHiy9Gw", "keywords": "Inverse problems, PINNs, Complex analysis, Neutral inclusions", "abstract": "We focus on designing and solving the neutral inclusion problem via neural networks. The neutral inclusion problem has a long history in the theory of composite materials, and it is exceedingly challenging to identify the precise condition that precipitates a general-shaped inclusion into a neutral inclusion. Physics-informed neural networks (PINNs) have recently become a highly successful approach to addressing both forward and inverse problems associated with partial differential equations. We found that traditional PINNs perform inadequately when applied to the inverse problem of designing neutral inclusions with arbitrary shapes. In this study, we introduce a novel approach, Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs), which integrates complex analysis techniques into PINNs. This method exhibits strong performance in solving forward-inverse problems to construct neutral inclusions of arbitrary shapes in two dimensions, where the imperfect interface condition on the inclusion's boundary is modeled by training neural networks. Notably, we mathematically prove that training with a single linear field is sufficient to achieve neutrality for untrained linear fields in arbitrary directions, given a minor assumption. We demonstrate that CoCo-PINNs offer enhanced performances in terms of credibility, consistency, and stability.", "title_embedding_index": 16153, "title_abs_embedding_index": 16178}, {"title": "OpsEval: A Comprehensive Benchmark Suite for Evaluating Large Language Models\u2019 Capability in IT Operations Domain", "link_suffix": "/forum?id=a2tU4ykVA9", "link": "https://openreview.net/forum?id=a2tU4ykVA9", "pdf_link": "https://openreview.net/pdf?id=a2tU4ykVA9", "keywords": "Large language models, Ops, Benchmark, Dataset, Evaluation, Prompt engineering", "abstract": "The past decades have witnessed the rapid development of Information Technology (IT) systems, such as cloud computing, 5G networks, and financial information systems. Ensuring the stability of these IT systems has become an important issue. Large language models (LLMs) that have exhibited remarkable capabilities in NLP-related tasks are showing great potential in AIOps, such as root cause analysis of failures, generation of operations and maintenance scripts, and summarizing of alert information. Unlike knowledge in general corpora, knowledge of Ops varies with the different IT systems, encompassing various private sub-domain knowledge, sensitive to prompt engineering due to various sub-domains, and containing numerous terminologies. Existing NLP-related benchmarks (e.g., C-Eval, MMLU) can not guide the selection of suitable LLMs for Ops (OpsLLM), and current metrics (e.g., BLEU, ROUGE) can not adequately reflect the question-answering (QA) effectiveness in the Ops domain. We propose a comprehensive benchmark suite, OpsEval, including an Ops-oriented evaluation dataset, an Ops evaluation benchmark, and a specially designed Ops QA evaluation method. Our dataset contains 7,334 multiple-choice questions and 1,736 QA questions. We have carefully selected and released 20% of the dataset written by domain experts in various sub-domains to assist current researchers in preliminary evaluations of OpsLLMs. We test over 24 latest LLMs under various settings such as self-consistency, chain-of-thought, and in-context learning, revealing findings when applying LLMs to Ops. We also propose an evaluation method for QA in Ops, which has a coefficient of 0.9185 with human experts and is improved by 0.4471 and 1.366 compared to BLEU and ROUGE, respectively. Over the past one year, our dataset and leaderboard have been continuously updated.", "title_embedding_index": 16154, "title_abs_embedding_index": 16179}, {"title": "Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing", "link_suffix": "/forum?id=87DtYFaH2d", "link": "https://openreview.net/forum?id=87DtYFaH2d", "pdf_link": "https://openreview.net/pdf?id=87DtYFaH2d", "keywords": "Role-play Agents, Refusal Capabilities, Representation Editing, Representation Analyze", "abstract": "Role-Playing Agents (RPAs) have shown remarkable performance in various applications, yet they often struggle to recognize and appropriately respond to hard queries that conflict with their role-play knowledge. To investigate RPAs' performance when faced with different types of conflicting requests, we develop an evaluation benchmark that includes contextual knowledge conflicting requests, parametric knowledge conflicting requests, and non-conflicting requests to assess RPAs' ability to identify conflicts and refuse to answer appropriately without over-refusing. Through extensive evaluation, we find that most RPAs behave significant performance gaps toward different conflict requests. To elucidate the reasons, we conduct an in-depth representation-level analysis of RPAs under various conflict scenarios. Our findings reveal the existence of rejection regions and direct response regions within the model's forwarding representation, and thus influence the RPA's final response behavior. Therefore, we introduce a lightweight representation editing approach that conveniently shifts conflicting requests to the rejection region, thereby enhancing the model's refusal accuracy. The experimental results validate the effectiveness of our editing method, improving RPAs' refusal ability of conflicting requests while maintaining their general role-playing capabilities.", "title_embedding_index": 16155, "title_abs_embedding_index": 16180}, {"title": "Adversarial Training for Defense Against Label Poisoning Attacks", "link_suffix": "/forum?id=UlpkHciYQP", "link": "https://openreview.net/forum?id=UlpkHciYQP", "pdf_link": "https://openreview.net/pdf?id=UlpkHciYQP", "keywords": "adversarial machine learning, label poisoning attacks, support vector machines, adversarial training, robust classification, bilevel optimization, projected gradient descent, data poisoning, Stackelberg game", "abstract": "As machine learning models advance in complexity and increasingly depend on large volumes of publicly sourced data, such as the human-annotated labels used in training large language models, they become more vulnerable to label poisoning attacks. These attacks, in which adversaries subtly alter the labels within a training dataset, can severely degrade model performance, posing significant risks in critical applications. In this paper, we propose $\\textbf{Floral}$, an adversarial training defense strategy based on support vector machines (SVMs) to counter label poisoning attacks. Utilizing a bilevel optimization framework, we cast the adversarial training process as a non-zero-sum Stackelberg game between an $\\textit{attacker}$, who strategically poisons critical training labels, and the $\\textit{model}$, which seeks to recover from such attacks. Our approach introduces a projected gradient descent algorithm with kernel SVMs for adversarial training. We provide a theoretical analysis of our algorithm\u2019s convergence properties and empirically evaluate its effectiveness across diverse classification tasks including sentiment analysis on the IMDB dataset. Compared to baseline robust models and robust foundation models such as RoBERTa, our method consistently achieves higher robust accuracy as the attacker\u2019s budget increases. These results underscore the potential of $\\textbf{Floral}$ to enhance the resilience of machine learning models against label poisoning threats, thereby ensuring robust classification in adversarial environments.", "title_embedding_index": 16156, "title_abs_embedding_index": 16181}, {"title": "PersonalLLM: Tailoring LLMs to Individual Preferences", "link_suffix": "/forum?id=2R7498e2Tx", "link": "https://openreview.net/forum?id=2R7498e2Tx", "pdf_link": "https://openreview.net/pdf?id=2R7498e2Tx", "keywords": "Personalization, LLM, Alignment, benchmark, dataset, reinforcement learning from human feedback, language models, RLHF, preferences", "abstract": "As LLMs become capable of complex tasks, there is growing potential for personalized interactions tailored to the subtle and idiosyncratic preferences of the user. We present a public benchmark, PersonalLLM, focusing on adapting LLMs to provide maximal benefits for a particular user. Departing from existing alignment benchmarks that implicitly assume uniform preferences, we curate open-ended prompts paired with many high-quality answers over which users would be expected to display heterogeneous latent preferences. Instead of persona prompting LLMs based on high-level attributes (e.g., user race or response length), which yields homogeneous preferences relative to humans, we develop a method that can simulate a large user base with diverse preferences from a set of pre-trained reward models. Our dataset and generated personalities offer an innovative testbed for developing personalization algorithms that grapple with continual data sparsity---few relevant feedback from the particular user---by leveraging historical data from other (similar) users. We explore basic in-context learning and meta-learning baselines to illustrate the utility of PersonalLLM and highlight the need for future methodological development.", "title_embedding_index": 16157, "title_abs_embedding_index": 16182}, {"title": "Streamlining Bayesian Deep Learning", "link_suffix": "/forum?id=pW387D5OUN", "link": "https://openreview.net/forum?id=pW387D5OUN", "pdf_link": "https://openreview.net/pdf?id=pW387D5OUN", "keywords": "Bayesian deep learning, uncertainty quantification", "abstract": "The rising interest in Bayesian deep learning (BDL) has led to a plethora of methods for estimating the posterior distribution. However, efficient computation of inferences, such as predictions, has been largely overlooked with Monte Carlo integration remaining the standard. In this work we examine streamlining prediction in BDL through a single forward pass without sampling. For this we use local linearisation on activation functions and local Gaussian approximations at linear layers. Thus allowing us to analytically compute an approximation to the posterior predictive distribution. We showcase our approach for both MLP and transformers, such as ViT and GPT-2, and assess its performance on regression and classification tasks.", "title_embedding_index": 16158, "title_abs_embedding_index": 16183}, {"title": "Unified Neural Solvers for General TSP and Multiple Combinatorial Optimization Tasks via Problem Reduction and Matrix Encoding", "link_suffix": "/forum?id=yEwakMNIex", "link": "https://openreview.net/forum?id=yEwakMNIex", "pdf_link": "https://openreview.net/pdf?id=yEwakMNIex", "keywords": "Travelling Salesman Problem, Neural Combinatorial Optimization", "abstract": "Various neural solvers have been devised for combinatorial optimization (CO), which are often tailored for specific problem types, ranging from TSP, CVRP to SAT, etc. Yet, it remains an open question how to achieve universality regarding problem representing and learning with a general  framework. This paper first proposes RedCO, to unify a set of CO problems by reducing them into the general TSP form featured by distance matrices. The applicability of this strategy is dependent on the efficiency of the problem reduction and solution transition procedures, which we show that at least ATSP, HCP, and SAT are readily feasible. The hope is to allow for the effective and even simultaneous use of as many types of CO instances as possible to train a neural TSP solver, and optionally finetune it for specific problem types. In particular, unlike the prevalent TSP benchmarks based on Euclidean instances with 2-D coordinates, our focused domain of general TSP could involve non-metric, asymmetric or discrete distances without explicit node coordinates, which is much less explored in TSP literature while poses new intellectual challenges. Along this direction, we devise two neural TSP solvers with and without supervision to conquer such matrix-formulated input, respectively: 1) MatPOENet and 2) MatDIFFNet. The former is a reinforcement learning-based sequential model with pseudo one-hot embedding (POE) scheme; and the latter is a Diffusion-based generative model with the mix-noised reference mapping scheme. Extensive experiments on ATSP, 2DTSP, HCP- and SAT-distributed general TSPs demonstrate the strong ability of our approaches towards arbitrary matrix-encoded TSP with structure and size variation. Source code and data will be made public.", "title_embedding_index": 16159, "title_abs_embedding_index": 16184}, {"title": "From Complex to Atomic: Enhancing Augmented Generation via Knowledge-Aware Dual Rewriting and Reasoning", "link_suffix": "/forum?id=kpLMN5fok1", "link": "https://openreview.net/forum?id=kpLMN5fok1", "pdf_link": "https://openreview.net/pdf?id=kpLMN5fok1", "keywords": "RAG, Knowledge atomizing, Knowledge-aware task decomposition, Multihop QA", "abstract": "Recent advancements in Retrieval-Augmented Generation (RAG) systems have significantly enhanced the capabilities of large language models (LLMs) by incorporating external knowledge retrieval. However, the sole reliance on retrieval is often inadequate for mining deep, domain-specific knowledge and for performing logical reasoning from specialized datasets. To tackle these challenges, we present an approach, which is designed to extract, comprehend, and utilize domain knowledge while constructing a coherent rationale. At the heart of our approach lie four pivotal components: a knowledge atomizer that extracts atomic questions from raw data, a query proposer that generates subsequent questions to facilitate the original inquiry, an atomic retriever that locates knowledge based on atomic knowledge alignments, and an atomic selector that determines which follow-up questions to pose guided by the retrieved information. Through this approach, we implement a knowledge-aware task decomposition strategy that adeptly extracts multifaceted knowledge from segmented data and iteratively builds the rationale in alignment with the initial query and the acquired knowledge. We conduct comprehensive experiments to demonstrate the efficacy of our approach across various benchmarks, particularly those requiring multihop reasoning steps. The results indicate a significant enhancement in performance, up to 12.6% over the second-best method, underscoring the potential of the approach in complex, knowledge-intensive applications.", "title_embedding_index": 16160, "title_abs_embedding_index": 16185}, {"title": "Learning to Construct Implicit Communication Channel", "link_suffix": "/forum?id=wm5wwAdiEt", "link": "https://openreview.net/forum?id=wm5wwAdiEt", "pdf_link": "https://openreview.net/pdf?id=wm5wwAdiEt", "keywords": "implicit communication, multi-agent reinforcement learning, the Hanabi challenge", "abstract": "Effective communication is an essential component in collaborative multi-agent systems. Situations where explicit messaging is not feasible have been common in human society throughout history, which motivate the study of implicit communication. Previous works on learning implicit communication mostly rely on theory of mind (ToM), where agents infer the mental states and intentions of others by interpreting their actions. However, ToM-based methods become less effective in making accurate inferences in complex tasks. In this work, we propose the Implicit Channel Protocol (ICP) framework, which allows agents to construct implicit communication channels similar to the explicit ones. ICP leverages a subset of actions, denoted as the scouting actions, and a mapping between information and these scouting actions that encodes and decodes the messages. We propose training algorithms for agents to message and act, including learning with a randomly initialized information map and with a delayed information map. The efficacy of ICP has been tested on the tasks of Guessing Number, Revealing Goals, and Hanabi, where ICP significantly outperforms baseline methods through more efficient information transmission.", "title_embedding_index": 16161, "title_abs_embedding_index": 16186}, {"title": "Accelerating Block Coordinate Descent for LLM Finetuning via Landscape Correction", "link_suffix": "/forum?id=zs6bRl05g8", "link": "https://openreview.net/forum?id=zs6bRl05g8", "pdf_link": "https://openreview.net/pdf?id=zs6bRl05g8", "keywords": "Block coordinate descent, large language model finetuning", "abstract": "Training and finetuning large language models (LLMs) are resource-intensive tasks, with memory limitations being a key bottleneck. A classic optimization method, block coordinate descent (BCD), offers solutions by segmenting the trainable parameters into multiple blocks and optimizing one active block at a time while freezing the others, thereby significantly reducing memory cost. However, we identify that blindly applying BCD to train LLMs can be inefficient for two reasons. First, optimizing only the active block requires backpropagating through multiple deeper yet inactive blocks, resulting in wasteful computations. Second, the frozen blocks, when they are not quite close to optimality, can narrow the optimization landscape, potentially misguiding the training of the active block. To address these issues simultaneously, we propose integrating BCD withlandscape correction, which unfreezes the inactive blocks and updates them in a cost-efficient manner during the same backpropagation as the update to the active block. We show that our method empirically improves vanilla BCD with minimal additional computation and memory. Experiments on 8B and 70B models demonstrate that our proposed method surpasses memory efficient baselines and matches Adam's downstream performance while reducing memory cost by 80% compared to Adam.", "title_embedding_index": 16162, "title_abs_embedding_index": 16187}, {"title": "Reformulating Strict Monotonic Probabilities with a Generative Cost Model", "link_suffix": "/forum?id=Qohoh5x1Jm", "link": "https://openreview.net/forum?id=Qohoh5x1Jm", "pdf_link": "https://openreview.net/pdf?id=Qohoh5x1Jm", "keywords": "monotonic model, variational inference, generative model", "abstract": "In numerous machine learning contexts, the relationship between input variables and predicted outputs is not only statistically significant but also strictly monotonic. Conventional approaches to ensuring monotonicity primarily focus on construction or regularization methods. This paper establishes that the problem of strict monotonic probability can be interpreted as a comparison between an observable revenue variable and a latent cost variable. This insight allows us to reformulate the original monotonicity challenge into modeling the latent cost variable and estimating its distribution. To address this issue, we introduce a generative model for the latent cost variable, referred to as the Generative Cost Model (\\textbf{GCM}), and derive a corresponding loss function. We further enhance the estimation of latent variables using variational inference and importance sampling, which reformulate our loss function accordingly. Lastly, we validate our approach through experiments on an artificial gamble simulation and two public datasets, demonstrating that our method significantly outperforms traditional techniques.", "title_embedding_index": 16163, "title_abs_embedding_index": 16188}, {"title": "Towards Holistic Multimodal Interaction: An Information-Theoretic Perspective", "link_suffix": "/forum?id=BZWssJoYEv", "link": "https://openreview.net/forum?id=BZWssJoYEv", "pdf_link": "https://openreview.net/pdf?id=BZWssJoYEv", "keywords": "Multimodal learning, Information theory, Multimodal interaction", "abstract": "Multimodal interaction, which assesses whether information originates from individual modalities or their integration, is a critical property of multimodal data. The type of interaction varies across different tasks and subtly influences the effectiveness of multimodal learning, but it remains an underexplored topic.\nIn this paper, we present an information-theoretic analysis to examine how interactions affect multimodal learning. We formulate specific types of information-theoretical interactions and provide theoretical evidence that an effective multimodal model necessity comprehensive learning across all interaction types. Moreover, we analyze two typical multimodal learning paradigms\u2014joint learning and modality ensemble\u2014and demonstrate that they both exhibit generalization gaps when faced with certain types of interactions. This observation underscores the need for a new paradigm that can isolate and enhance each type of interaction.\nTo address this challenge, we propose the Decomposition-based Multimodal Interaction learning (DMI) paradigm. Our approach utilizes variation-based decomposition modules to segregate multimodal information into distinct types of disentangled interactions. Then, a new training strategy is developed to holistically enhance learning efficacy across various interaction types. \nComprehensive empirical results indicate our DMI paradigm enhances multimodal learning by effectively decomposing and targeted improving the learning of interactions.", "title_embedding_index": 16164, "title_abs_embedding_index": 16189}, {"title": "Mask in the Mirror: Implicit Sparsification", "link_suffix": "/forum?id=U47ymTS3ut", "link": "https://openreview.net/forum?id=U47ymTS3ut", "pdf_link": "https://openreview.net/pdf?id=U47ymTS3ut", "keywords": "Continuous sparsification, Implicit bias, Mirror flow, Time-dependent Bregman potential, Regularization, Rich regime", "abstract": "Continuous sparsification strategies are among the most effective methods for reducing the inference costs and memory demands of large-scale neural networks. A key factor in their success is the implicit $L_1$ regularization induced by jointly learning both mask and weight variables, which has been shown experimentally to outperform explicit $L_1$ regularization. We provide a theoretical explanation for this observation by analyzing the learning dynamics, revealing that early continuous sparsification is governed by an implicit $L_2$ regularization that gradually transitions to an $L_1$ penalty over time. Leveraging this insight, we propose a method to dynamically control the strength of this implicit bias. Through an extension of the mirror flow framework, we establish convergence and optimality guarantees in the context of underdetermined linear regression. Our theoretical findings may be of independent interest, as we demonstrate how to enter the rich regime and show that the implicit bias can be controlled via a time-dependent Bregman potential. To validate these insights, we introduce PILoT, a continuous sparsification approach with novel initialization and dynamic regularization, which consistently outperforms baselines in standard experiments.", "title_embedding_index": 16165, "title_abs_embedding_index": 16190}, {"title": "A Comprehensive Library for Benchmarking Multi-class Visual Anomaly Detection", "link_suffix": "/forum?id=R03zKO9T9S", "link": "https://openreview.net/forum?id=R03zKO9T9S", "pdf_link": "https://openreview.net/pdf?id=R03zKO9T9S", "keywords": "Visual Anomaly Detection, Unsupervised Learning, benchmark", "abstract": "Visual anomaly detection aims to identify anomalous regions in images through unsupervised learning paradigms, with increasing application demand and value in fields such as industrial inspection and medical lesion detection. Despite significant progress in recent years, there is a lack of comprehensive benchmarks to adequately evaluate the performance of various mainstream methods across different datasets under the practical multi-class setting. The absence of standardized experimental setups can lead to potential biases in training epochs, resolution, and metric results, resulting in erroneous conclusions. This paper addresses this issue by proposing a comprehensive visual anomaly detection benchmark,ADer, which is a modular framework that is highly extensible for new methods. The benchmark includes multiple datasets from industrial and medical domains, implementing fifteen state-of-the-art methods and nine comprehensive metrics. Additionally, we have proposed the GPU-assistedADEvalpackage to address the slow evaluation problem of metrics like time-consuming mAU-PRO on large-scale data, significantly reducing evaluation time by more than \\textit{1000-fold}. Through extensive experimental results, we objectively reveal the strengths and weaknesses of different methods and provide insights into the challenges and future directions of multi-class visual anomaly detection. We hope thatADerwill become a valuable resource for researchers and practitioners in the field, promoting the development of more robust and generalizable anomaly detection systems. Full codes have been attached in Appendix and will be open-sourced.", "title_embedding_index": 16166, "title_abs_embedding_index": 16191}, {"title": "Highlight: Learning Visual Prompts for Vision-Language Models", "link_suffix": "/forum?id=3xxxoh92Mo", "link": "https://openreview.net/forum?id=3xxxoh92Mo", "pdf_link": "https://openreview.net/pdf?id=3xxxoh92Mo", "keywords": "VLMs, prompting, visual prompting, self-supervision", "abstract": "Large-scale Vision-Language Models, such as CLIP, demonstrate impressive capabilities and have multiple applications, from text-to-image generation to zero-shot classification. Recent work has suggested that visual prompts, such as a red circle, can steer the vision encoder to the circled region. While such vision prompts have now been used in various applications, they might be model-specific and depend on the model learning these behaviours from its training data. Discovering and evaluating various prompts might not be feasible given different models, tasks, and datasets. In this paper, we propose Highlight, a method to learn a visual prompt that highlights a region in an image or refines a manually engineered visual prompt. Using our framework, we can learn to highlight in a supervised way using a dataset of text-image region pairs or in an unsupervised way using synthetic captions or images only. Highlight outperforms other visual prompts, prompt learning approaches, and compute-intensive methods that use ensembles of multiple models and visual prompts.", "title_embedding_index": 16167, "title_abs_embedding_index": 16192}, {"title": "Shh, don't say that! Domain Certification in LLMs", "link_suffix": "/forum?id=F64wTvQBum", "link": "https://openreview.net/forum?id=F64wTvQBum", "pdf_link": "https://openreview.net/pdf?id=F64wTvQBum", "keywords": "large language model, natural language processing, adversarial robustness, adversary, natural text generation, certification, verification", "abstract": "Large language models (LLMs) are often deployed to do constrained tasks, with narrow domains. For example, customer support bots can be built on top of LLMs, relying on their broad language understanding and capabilities to enhance performance. However, these LLMs are adversarially susceptible, potentially generating outputs outside the intended domain. To formalize, assess and mitigate this risk, we introduce \\emph{domain certification}; a guarantee that accurately characterizes the out-of-domain behavior of language models. We then propose a simple yet effective approach dubbed VALID that provides adversarial bounds as a certificate. Finally, we evaluate our method across a diverse set of datasets, demonstrating that it yields meaningful certificates.", "title_embedding_index": 16168, "title_abs_embedding_index": 16193}, {"title": "QFree-Det: Query-Free Detector with Transformer and Sequential Matching", "link_suffix": "/forum?id=vyF5aim4US", "link": "https://openreview.net/forum?id=vyF5aim4US", "pdf_link": "https://openreview.net/pdf?id=vyF5aim4US", "keywords": "free-object prediction, query-free, detecting ambiguity, location-deduplication decoder", "abstract": "Transformer-based detectors, such as DETR and DINO, often struggle with a specific limitation: they can detect only a fixed number of objects based on the predefined number of queries set. This limitation leads to missed detections when the scene exceeds the model\u2019s capacity and increases false positives when the scene contains fewer objects. In addition, existing approaches often combine one-to-one and one-to-many matching label assignment methods in the decoder for accelerating the model training and convergence. However, this operation can introduce a new detecting ambiguity issue, which is often overlooked by those methods. To address these challenges, we propose QFree-Det, a novel query-free detector capable of dynamically detecting a variable number of objects across different input images. In particular, we present an Adaptive Free Query Selection (AFQS) algorithm to dynamically select queries from the encoder tokens, which resolves the issue of fixed capacity. Then, we propose a sequential matching method that decouples the one-to-one and one-to-many processes into separating sequential steps, effectively addressing the issue of detecting ambiguity. To achieve the sequential matching, we design a new Location-Deduplication Decoder (LDD) by rethinking the role of cross-attention (CA) and self-attention (SA) within the decoder. LDD first regresses the location of multiple boxes with CA in a one-to-many manner and then performs object classification to recognize and eliminate duplicate boxes with SA in a one-to-one manner. Finally, to improve the detection ability on small objects, we design a unified PoCoo loss that leverages prior knowledge of box size to encourage the model to pay more attention to small objects. Extensive experiments on COCO2017 and WiderPerson datasets demonstrate the effectiveness of our QFreeDet. For instance, QFree-Det achieves consistent and remarkable improvements over DINO across five different backbones. Notably, QFree-Det obtains a new state-of-the-art of 54.4% AP and 38.8% APs on val2017 of COCO with the backbone of VMamba-T under 1\u00d7 training schedule (12 epochs), higher than DINO-VMamba-T by +0.9% AP and +2.2% APs. The source codes will be released upon acceptance.", "title_embedding_index": 16169, "title_abs_embedding_index": 16194}, {"title": "Scaling Value Iteration Networks to 5000 Layers for Extreme Long-Term Planning", "link_suffix": "/forum?id=USE9akheEY", "link": "https://openreview.net/forum?id=USE9akheEY", "pdf_link": "https://openreview.net/pdf?id=USE9akheEY", "keywords": "Value Iteration Networks, Long-term Planning, Reinforcement Learning, Deep Neural Network", "abstract": "The Value Iteration Network (VIN) is an end-to-end differentiable architecture that performs value iteration on a latent Markov Decision Process (MDP) for planning in reinforcement learning (RL). However, VINs struggle to scale to long-term and large-scale planning tasks, such as navigating a $100\\times 100$ maze---a task that typically requires thousands of planning steps to solve. We observe that this deficiency is due to two issues: the representation capacity of the latent MDP and the planning module's depth. We address these by augmenting the latent MDP with a dynamic transition kernel, dramatically improving its representational capacity, and, to mitigate the vanishing gradient problem, introduce an \"adaptive highway loss\" that constructs skip connections to improve gradient flow. We evaluate our method on 2D maze navigation environments, the ViZDoom 3D navigation benchmark, and the real-world Lunar rover navigation task. We find that our new method, named \\textit{Dynamic Transition VIN (DT-VIN)}, scales to 5000 layers and solves challenging versions of the above tasks. Altogether, we believe that DT-VIN represents a concrete step forward in performing long-term large-scale planning in RL environments.", "title_embedding_index": 16170, "title_abs_embedding_index": 16195}, {"title": "Dice-GAN: Generative Adversarial Network  with Diversity Injection and Consistency Enhancement", "link_suffix": "/forum?id=5187wrocJq", "link": "https://openreview.net/forum?id=5187wrocJq", "pdf_link": "https://openreview.net/pdf?id=5187wrocJq", "keywords": "text-to-image, generative adversarial networks, self-attention, semantic consistency", "abstract": "In the field of natural language description tasks, one challenge for text-to-image modeling is to generate images that are both of high quality and diversity and maintain a high degree of semantic consistency with the textual description. Although significant progress has been made in existing research, there is still potential for improving image quality and diversity. In this study, we propose an efficient attention-based text-to-image synthesis model based on generative adversarial networks named Dice-GAN. To enhance the diversity of image generation, we design a diversity injection module, which injects noise multiple times during image generation and incorporates a self-attention mechanism to assist the generator in maintaining global structural consistency while enhancing the diversity of images. To improve the semantic consistency, we designed a consistency enhancement module, which enhances the semantic consistency of image generation by combining word vectors and a hybrid attention mechanism to achieve dynamic weight adjustment for different image regions. We conducted experiments on two widely accepted benchmark datasets, CUB and COCO. Dice-GAN demonstrated significant superiority in improving the fidelity and diversity of image generation compared to the existing approaches.", "title_embedding_index": 16171, "title_abs_embedding_index": 16196}, {"title": "On The Representation Properties Of The Perturb-Softmax And The Perturb-Argmax Probability Distributions", "link_suffix": "/forum?id=BLg4PeBqsV", "link": "https://openreview.net/forum?id=BLg4PeBqsV", "pdf_link": "https://openreview.net/pdf?id=BLg4PeBqsV", "keywords": "representation properties, Gumbel-Softmax, Gumbel-Argmax, minimality, completeness, discrete probabilistic models", "abstract": "The Gumbel-Softmax probability distribution allows learning discrete tokens in generative learning, whereas the Gumbel-Argmax probability distribution is useful in learning discrete structures in discriminative learning. Despite the efforts invested in optimizing these models, their properties are underexplored. In this work, we investigate their representation properties and determine for which families of parameters these probability distributions are complete, that is, can represent any probability distribution, and minimal, i.e., can represent a probability distribution uniquely. We rely on convexity and differentiability to determine these conditions and extend this framework to general probability models, denoted Perturb-Softmax and Perturb-Argmax. We conclude the analysis by identifying two sets of parameters that satisfy these assumptions and thus admit a complete and minimal representation. A faster convergence rate of Gaussian-Softmax in comparison to Gumbel-Softmax further motivates our study, as the experimental evaluation validates.", "title_embedding_index": 16172, "title_abs_embedding_index": 16197}, {"title": "FairDD: Fair Dataset Distillation via Adversarial Matching", "link_suffix": "/forum?id=8fYvPCB0Ja", "link": "https://openreview.net/forum?id=8fYvPCB0Ja", "pdf_link": "https://openreview.net/pdf?id=8fYvPCB0Ja", "keywords": "Fair Dataset Distillation, Fair Dataset Condensation", "abstract": "Condensing large datasets into smaller synthetic counterparts has demonstrated its promise for image classification. However, previous research has overlooked a crucial concern in image recognition: ensuring that models trained on condensed datasets are unbiased towards protected attributes (PA), such as gender and race. Our investigation reveals that dataset distillation (DD) fails to alleviate the unfairness towards minority groups within original datasets. Moreover, this bias typically worsens in the condensed datasets due to their smaller size. To bridge the research gap, we propose a novel fair dataset distillation (FDD) framework, namely FairDD, which can be seamlessly applied to diverse matching-based DD approaches, requiring no modifications to their original architectures. The key innovation of FairDD lies in adversarially matching synthetic datasets to PA-wise groups of original datasets simultaneously, rather than indiscriminate alignment to the whole distributions in vanilla DDs, dominated by majority groups. This adversarial matching allows synthetic datasets to avoid collapsing into majority groups and bootstrap their balanced generation to all PA groups. Consequently, FairDD could effectively regularize vanilla DDs to favor biased generation toward minority groups while maintaining the accuracy of target attributes. Theoretical analyses and extensive experimental evaluations demonstrate that FairDD significantly improves fairness compared to vanilla DD methods, without sacrificing classification accuracy. Its consistent superiority across diverse DDs, spanning Distribution and Gradient Matching, establishes it as a versatile FDD approach.", "title_embedding_index": 16173, "title_abs_embedding_index": 16198}, {"title": "Systematic Outliers in Large Language Models", "link_suffix": "/forum?id=rLX7Vyyzus", "link": "https://openreview.net/forum?id=rLX7Vyyzus", "pdf_link": "https://openreview.net/pdf?id=rLX7Vyyzus", "keywords": "Model Interpretability, Large Language Models, Outliers, Attention Mechanism", "abstract": "Outliers have been widely observed in Large Language Models (LLMs), significantly impacting model performance and posing challenges for model compression. Therefore, understanding the mechanisms by which these outliers affect the models is important. However, existing works either highlight outliers to guide specific algorithmic design or analyze isolated instances without providing a comprehensive understanding. In this work, we present the first systematic analysis of outliers in LLMs. We identify and categorize three types of outliers\u2014activation outliers, weight outliers, and attention outliers\u2014and discover inherent connections between their occurrences. By employing numerical computation and gradient optimization methods, we analyze the causes of these outliers. We summarize their roles within the models, demonstrating through experiments that they function as implicit context-aware scaling factors in the attention mechanism. As these outliers arise from systematic influences, we call them as \\textit{systematic outliers}. Our study not only deepens our understanding of Transformer-based LLMs but also shows that structurally eliminating outliers can accelerate convergence and improve model compression, offering fresh insights for future model design. The code has been submitted as supplementary material and will be released upon acceptance to facilitate further research.", "title_embedding_index": 16174, "title_abs_embedding_index": 16199}]
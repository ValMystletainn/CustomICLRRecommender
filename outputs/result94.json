[
    {
        "title": "Improving Multimodal Protein Function Prediction Using Bidirectional Interaction and Dynamic Selection Mechanisms",
        "link_suffix": "/forum?id=nbia2X0urs",
        "link": "https://openreview.net/forum?id=nbia2X0urs",
        "pdf_link": "https://openreview.net/pdf?id=nbia2X0urs",
        "keywords": "Multimodal, protein function prediction, multi-label classification",
        "abstract": "Protein function prediction is pivotal for uncovering the mechanisms of life processes. Protein function prediction is a multi-label classification task with numerous functional labels that exhibit hierarchical relationships. Relying solely on unimodal protein features is insufficient for computational models to capture complex protein functions adequately. Recently, several methods for protein function prediction have enhanced the performance by integrating multimodal protein features. However, since multimodal protein features describe protein functions from different perspectives, it is challenging to capture the intricate relationships among these multimodal features with different meanings and heterogeneity. Therefore, we propose a multimodal method for protein function prediction that can effectively utilize the intricate internal relationships between spatial features (i.e., protein-protein interaction network, subcellular location, and protein domains) and sequence features (i.e., amino acid sequence). In this work, we introduce the Bidirectional Interaction Module (BInM) to facilitate interactive learning between multimodal features by mapping spatial and sequence features of proteins to each other. Moreover, to deal with the difficulty of hierarchical multi-label classification in this task, a multi-branch Dynamic Selection Module (DSM) is designed to select the feature representation that is most favorable for current protein function prediction. Comprehensive experiments on human datasets demonstrate that our model outperforms state-of-the-art multimodal-based methods such as Graph2GO, DeepGraphGO, and CFAGO. Furthermore, we assess the efficacy of the features through Davies-Bouldin scores and t-SNE visualization experiments. The experimental results show that our method constructs more useful protein representations through bidirectional interaction and dynamic selection mechanisms, leading to improved accuracy in protein function prediction. The code in this work will be made public after its acceptance."
    },
    {
        "title": "Learning to engineer protein flexibility",
        "link_suffix": "/forum?id=L238BAx0wP",
        "link": "https://openreview.net/forum?id=L238BAx0wP",
        "pdf_link": "https://openreview.net/pdf?id=L238BAx0wP",
        "keywords": "protein flexibility, protein flexibility prediction, protein design, protein sequence design, inverse folding",
        "abstract": "Generative machine learning models are increasingly being used to design novel proteins. However, their major limitation is the inability to account for protein flexibility, a property crucial for protein function. Learning to engineer flexibility is difficult because the relevant data is scarce, heterogeneous, and costly to obtain using computational and experimental methods. Our contributions are three-fold. First, we perform a comprehensive comparison of methods for evaluating protein flexibility and identify relevant data for learning. Second, we overcome the data scarcity issue by leveraging a pre-trained protein language model. We design and train flexibility predictors utilizing either only sequential or both sequential and structural information on the input. Third, we introduce a method for fine-tuning a protein inverse folding model to make it steerable toward desired flexibility at specified regions. We demonstrate that our method Flexpert enables guidance of inverse folding models toward increased flexibility. This opens up a transformative possibility of engineering protein flexibility."
    },
    {
        "title": "Jet Expansions of Residual Computation",
        "link_suffix": "/forum?id=JCCPtPDido",
        "link": "https://openreview.net/forum?id=JCCPtPDido",
        "pdf_link": "https://openreview.net/pdf?id=JCCPtPDido",
        "keywords": "Interpretability, residual networks, transformers, LLMs, expansions, Taylor series, logit lens",
        "abstract": "We introduce a framework for expanding residual networks using \\textit{jets}, operators that generalize truncated Taylor series.\nOur method provides a systematic approach to disentangle contributions of different computational paths to model predictions.\nIn contrast to existing techniques such as distillation, probing, or early decoding, our expansions rely solely on the model itself and requires no data, training, or sampling from the model.\nWe demonstrate how our framework grounds and subsumes the logit lens,\nreveals a (super-)exponential path structure in the network depth and opens up several applications. \nThese include the extraction of $n$-gram statistics from a transformer large language model, and the definition of data-free toxicity scores.\nOur approach enables data-free analysis of residual networks for model interpretation, development, and evaluation."
    },
    {
        "title": "ElasticTok: Adaptive Tokenization for Image and Video",
        "link_suffix": "/forum?id=tFV5GrWOGm",
        "link": "https://openreview.net/forum?id=tFV5GrWOGm",
        "pdf_link": "https://openreview.net/pdf?id=tFV5GrWOGm",
        "keywords": "adaptive representation, adaptive tokenization, autoencoder",
        "abstract": "Efficient video tokenization remains a key bottleneck in learning general purpose vision models that are capable of processing long video sequences. Prevailing approaches are restricted to encoding videos to a fixed number of tokens, where too few tokens will result in overly lossy encodings, and too many tokens will result in prohibitively long sequence lengths. In this work, we introduce ElasticTok, a method that conditions on prior frames to adaptively encode a frame into a variable number of tokens. To enable this in a computationally scalable way, we propose a masking technique that drops a random number of tokens at the end of each frames's token encoding. During inference, ElasticTok can dynamically allocate tokens when needed -- more complex data can leverage more tokens, while simpler data only needs a few tokens. Our empirical evaluations on images and video demonstrate the effectiveness of our approach in efficient token usage, paving the way for future development of more powerful multimodal models, world models, and agents. Video examples of using ElasticTok can be found on our website:https://elastic-tokenizer.github.io"
    },
    {
        "title": "Toward Efficient Kernel-Based Solvers for Nonlinear PDEs",
        "link_suffix": "/forum?id=86hNGGo1CU",
        "link": "https://openreview.net/forum?id=86hNGGo1CU",
        "pdf_link": "https://openreview.net/pdf?id=86hNGGo1CU",
        "keywords": "Kernel methods, Non-Linear PDE",
        "abstract": "This paper introduces a novel kernel learning  framework toward efficiently solving nonlinear partial differential equations (PDEs). In contrast to the state-of-the-art kernel solver that embeds differential operators within kernels, posing challenges with a large number of collocation points, our approach eliminates these operators from the kernel. We model the solution using a standard kernel interpolation form and differentiate the interpolant to compute the derivatives. Our framework obviates the need for complex Gram matrix construction between solutions and their derivatives, allowing for a straightforward implementation and scalable computation. As an instance, we allocate the collocation points on a grid and adopt a product kernel, which yields a Kronecker product structure in the interpolation. This structure enables us to avoid computing the full Gram matrix, reducing costs and scaling efficiently to a large number of collocation points. We provide a proof of the convergence and rate analysis of our method under appropriate regularity assumptions. In numerical experiments, we demonstrate the advantages of our method in solving several benchmark PDEs."
    },
    {
        "title": "Trajectory-Class-Aware Multi-Agent Reinforcement Learning",
        "link_suffix": "/forum?id=uqe5HkjbT9",
        "link": "https://openreview.net/forum?id=uqe5HkjbT9",
        "pdf_link": "https://openreview.net/pdf?id=uqe5HkjbT9",
        "keywords": "trajectory clustering, multi-agent reinforcement learning, trajectory-class-aware policy",
        "abstract": "In the context of multi-agent reinforcement learning,generalizationis a challenge to solve various tasks that may require different joint policies or coordination without relying on policies specialized for each task. We refer to this type of problem as amulti-goal task, and we train agents to be versatile in this multi-goal task through a single training process. To address this challenge, we introduce TRajectory-class-Aware Multi-Agent reinforcement learning (TRAMA). In TRAMA, agents recognize a task type by identifying the class of trajectories they are experiencing through partial observations, and the agents use this trajectory awareness or prediction as additional information for action policy. To this end, we introduce three primary objectives in TRAMA: (a) constructing a quantized latent space to generate trajectory embeddings that reflect key similarities among them; (b) conducting trajectory clustering using these trajectory embeddings; and (c) building a trajectory-class-aware policy. Specifically for (c), we introduce a trajectory-class predictor that performs agent-wise predictions on the trajectory class; and we design a trajectory-class representation model for each trajectory class. Each agent takes actions based on this trajectory-class representation along with its partial observation for task-aware execution. The proposed method is evaluated on various tasks including multi-goal tasks built upon StarCraft II. Empirical results show further performance improvements over state-of-the-art baselines."
    },
    {
        "title": "Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning",
        "link_suffix": "/forum?id=2Ey2hkFicp",
        "link": "https://openreview.net/forum?id=2Ey2hkFicp",
        "pdf_link": "https://openreview.net/pdf?id=2Ey2hkFicp",
        "keywords": "Large Language Model, Reasoning, Biology, Biological System, Pathway, Agent",
        "abstract": "Large language models (LLMs) have demonstrated remarkable performance across various domains of biology, but their ability to reason about biological pathways remains underexplored. This includes reasoning about how perturbations in biological systems lead to various downstream effects through complex intermediate processes. Such reasoning is crucial for explaining and predicting biological phenomena, as well as for formulating hypotheses and designing experiments.In this study, we investigate whether LLMs can effectively understand and reason about biological pathways by introducing BioMaze, a comprehensive benchmark focusing on reasoning about the effects and mechanisms of natural and synthetic interventions—such as mutations, infections, or treatments—on various downstream targets under different conditions through complex intermediate pathway processes. BioMaze spans multiple biological domains and is categorized along three reasoning dimensions, capturing various aspects of pathway reasoning.We evaluate LLMs using the BioMaze benchmark with reasoning methods like Chain-of-Thought (CoT) and pathway graph-augmented approaches. Results show that while LLMs can understand mechanisms in natural organisms, they struggle with predicting phenomena after perturbations, highlighting their limitations in reasoning about biological pathways. To address these challenges, we propose PathSeeker, a novel LLM agent that interactively reasons through subgraph-based navigation within the pathway graph. This approach enhances LLMs' reasoning in biological pathways by leveraging pathway graph augmentation, particularly in cases involving perturbations, potentially bridging the gap between LLMs' current capabilities and the complexities of biological systems."
    },
    {
        "title": "Modeling Focal Synaptic Degeneration and Neural Plasticity in Ventral Visual Cortex",
        "link_suffix": "/forum?id=hyYP9MZeYn",
        "link": "https://openreview.net/forum?id=hyYP9MZeYn",
        "pdf_link": "https://openreview.net/pdf?id=hyYP9MZeYn",
        "keywords": "reorganization, recurrent connections, self-supervision, vision, stroke, deep artificial neural networks",
        "abstract": "Strokes affect a significant portion of the population and often result in secondary damage in the form of focal synaptic degeneration. When this occurs in the ventral visual cortex (VVC), it can lead to neurological deficits, including visual function loss. In this paper, we use the VVC as a framework in which to model focal synaptic degeneration and post-injury plasticity. We do so by progressively ``injuring'' synaptic connections in primate visual areas V1, V2, V4, and the inferior temporal cortex (IT), followed by continual retraining of the spared connections on real-world visual stimuli. We demonstrate that the functional signatures of carefully designed differential tasks can localize synaptic decay in the VVC. Initially, categorization performance deteriorates gradually, up to a critical threshold, beyond which there is a sharp drop. This slow decline in performance is marked by a reorganization in nearby neurons, where both visual function and the structure of receptive fields adapt to compensate for the damage. Spared recurrent connections significantly contribute to recovery. Furthermore, we find that performing contrastive learning over a stimulus-to-category matching task as a re-learning protocol leads to improved categorization performance recovery."
    },
    {
        "title": "Universally Applicable And Tunable Graph-Based Coarse-Graining For Machine Learning Force Fields",
        "link_suffix": "/forum?id=McNPMnPVrz",
        "link": "https://openreview.net/forum?id=McNPMnPVrz",
        "pdf_link": "https://openreview.net/pdf?id=McNPMnPVrz",
        "keywords": "Molecular Dynamics, Coarse-graining, Quantum Chemistry, EGNN, Geometric Deep Learning, JAX, Dataset generation",
        "abstract": "Coarse-grained (CG) force field methods for molecular systems are a crucial tool to simulate large biological macromolecules and are therefore essential for characterisations of biomolecular systems. While state-of-the-art deep learning (DL)-based models for all-atom force fields have improved immensely over recent years, we observe and analyse significant limitations of the currently available approaches for DL-based CG simulations. In this work, we present a transferable DL-based CG force field approach applicable to a wide range of biosystems. To achieve this, our CG algorithm does not rely on hard-coded rules and is tuned to output coarse-grained systems optimised for minimal statistical noise in the ground truth CG forces, which results in significant improvement of model training. The force field model is based on the MACE architecture and is trained on a custom dataset created by a new approach based on the fragmentation of large biosystems covering protein, RNA and lipid chemistry. We demonstrate that our model can be applied in molecular dynamics simulations to obtain stable and qualitatively accurate trajectories for a variety of systems, while also discussing cases for which we observe limited reliability."
    },
    {
        "title": "Long-context Extrapolation via Periodic Extension",
        "link_suffix": "/forum?id=jp4pxKqCRW",
        "link": "https://openreview.net/forum?id=jp4pxKqCRW",
        "pdf_link": "https://openreview.net/pdf?id=jp4pxKqCRW",
        "keywords": "Long-context Extrapolation, Positional encoding, Extra-PE, Extra-MPE, LLM",
        "abstract": "Long-context extrapolation aims to extend the contextual window of large language models to process more contextual information, which is widely adopted in industrial applications. \nCurrent mainstream solutions involve increasing the rotation base of RoPE to varying degrees or introducing optimization strategies such as ``low-frequency extrapolation and high-frequency interpolation'', in order to enhance the model's extrapolation capabilities for long context. Actually, these methods alter the representation distribution of positional information by adjusting the rotation frequency of positional encoding, resulting in inevitably disrupt the attention distribution within the original training length range. \nIn this paper, we analyze this phenomenon from a theoretical perspective and propose a long-context extrapolation strategy that preserves the known distribution via periodic extension of high-dimensional positional encoding. Based on this strategy, we design two methods, namely Extra-PE and Extra-MPE, to significantly enhance the models' long-context extrapolation capabilities without disrupting the positional encoding distribution within the original training length. \nThrough extensive experimental results, it is found that the long-context extrapolation method based on periodic extension can enhance the model's capability in extrapolating long-contexts. Specifically, a model fine-tuned on 32k tokens can extrapolate beyond 80k tokens, surpassing the performance of the NTK-32k model and approaching that of the YaRN-64k model. Furthermore, this method demonstrates significantly superior performance in extrapolating extremely long-contexts compared to other methods. Notably, a model fine-tuned on 8k tokens still does not exhibit perplexity explosion when extrapolating to 80k tokens. Additionally, during the fine-tuning process, our approach achieves optimal performance using only one-fourth of the fine-tuning steps (100 steps) compared to the YaRNmethod. Secondly, in our comparative experiments, we found that the period in which the model learns a sufficient number of positional encoding has a significant impact on long-context extrapolation capability. Finally, through attention analysis, we discovered that our method can still maintain a stable level of attention at ultra-long distances, with the mean attention value exceeding 0 at these distances."
    },
    {
        "title": "Understanding Depth and Height Perception in Large Visual-Language Models",
        "link_suffix": "/forum?id=t1LfiWCYux",
        "link": "https://openreview.net/forum?id=t1LfiWCYux",
        "pdf_link": "https://openreview.net/pdf?id=t1LfiWCYux",
        "keywords": "large vision language models, frontier models, visual reasoning, visual question answering",
        "abstract": "Geometric understanding—including depth and height perception—is fundamental to intelligence and crucial for navigating our environment. Despite the impressive capabilities of large Vision Language Models (VLMs), it remains unclear how well they possess the geometric understanding required for practical applications in visual perception. In this work, we focus on evaluating the geometric understanding of these models, specifically targeting their ability to perceive the depth and height of objects in an image. To address this, we introduce GeoMeter, a suite of benchmark datasets—encompassing 2D and 3D scenarios—to rigorously evaluate these aspects. By benchmarking 18 state-of-the-art VLMs, we found that although they excel in perceiving basic geometric properties like shape and size, they consistently struggle with depth and height perception. Our analysis reveal that these challenges stem from shortcomings in their depth and height reasoning capabilities and inherent biases. This study aims to pave the way for developing VLMs with enhanced geometric understanding by emphasizing depth and height perception as critical components necessary for real-world applications."
    },
    {
        "title": "Symbolic Autoencoding with Straight-Through Gradient Approximations",
        "link_suffix": "/forum?id=RMBwNzs57N",
        "link": "https://openreview.net/forum?id=RMBwNzs57N",
        "pdf_link": "https://openreview.net/pdf?id=RMBwNzs57N",
        "keywords": "straight-through gradient approximation, Autoencoders, discrete representation learning",
        "abstract": "Self-supervised auto-regressive models have achieved notable success in diverse domains such as text, audio, and biological sequences.\nHowever, current models generally require large samples of aligned (parallel) data.To alleviate this limitation,\nwe propose Symbolic Autoencoding ($\\Sigma$AE):\na latent variable model in which the latent space consists of sequences of categorical random variables, resembling sentences in an emergent symbolic language. \nOur approach enables unsupervised alignment of the learned latent variables with the target system when parallel data is scarce.Leveraging supervised and unsupervised objectives, $\\Sigma$AE improves latent random variables' interpretability and structure by grounding them in a weakly supervised setting. \nWe use the reparameterization trick alongside three quantization variants of a straight-through gradient estimator, to enable end-to-end optimization with discrete latent variables,\nOur experiments on four text sequence transduction tasks empirically show significant performance improvements of our approach over baselines, particularly in low-resource scenarios where only a small amount of parallel data is available."
    },
    {
        "title": "Language Fusion for Parameter-Efficient Cross-lingual Transfer",
        "link_suffix": "/forum?id=eLBKQSpsVd",
        "link": "https://openreview.net/forum?id=eLBKQSpsVd",
        "pdf_link": "https://openreview.net/pdf?id=eLBKQSpsVd",
        "keywords": "cross-lingual transfer, multilingual representation learning, parameter-efficient fine-tuning",
        "abstract": "Limited availability of multilingual text corpora for training language models often leads to poor performance on downstream tasks due to undertrained representation spaces for languages other than English. This 'under-representation' has motivated recent cross-lingual transfer methods to leverage the English representation space by e.g. mixing English and 'non-English' tokens at input or extending model parameters to accommodate new languages, which in turn increases computational complexity. To address this, we introduceFusion forLanguageRepresentations (FLARE) in adapters, a method designed to improve both the representation quality and downstream performance for languages other than English. FLARE integrates source and target language representations within the bottlenecks of low-rank LoRA adapters using lightweight linear transformations. This maintains parameter efficiency as the method does not require additional parameters, while improving transfer performance, further narrowing the performance gap to English.\nFurthermore, the proposed latent representation fusion does not increase the number of input tokens, this way maintaining computational efficiency. Moreover, FLARE provides flexibility to integrate various types of representations, e.g., we show that it is possible to fuse latent translations extracted from machine translation models. A series of experiments across representative cross-lingual natural language understanding tasks, including natural language inference, question-answering and sentiment analysis, demonstrate FLARE's effectiveness, reducing the average performance gap to English to 8.39% for XLM-R Large and 12.41% for Llama 3 across our benchmarks."
    },
    {
        "title": "Revisit the open nature of open vocabulary segmentation",
        "link_suffix": "/forum?id=2vHIHrJAcI",
        "link": "https://openreview.net/forum?id=2vHIHrJAcI",
        "pdf_link": "https://openreview.net/pdf?id=2vHIHrJAcI",
        "keywords": "Open vocabulary segmentation, Evaluation",
        "abstract": "In Open-Vocabulary Segmentation (OVS), we observe a consistent drop in model\nperformance as the query vocabulary set expands, especially when it includes se-\nmantically similar and ambiguous vocabularies, such as ‘sofa’ and ‘couch’. The\nprevious OVS evaluation protocol, however, does not account for such ambiguity,\nas any mismatch between predicted and human-annotated pairs is simply treated\nas incorrect on a pixel-wise basis. This contradicts the open nature of OVS, where\nambiguous categories can both be correct from an open-world perspective. To\naddress this, in this work, we further study the open nature of OVS and pro-\npose a mask-wise evaluation protocol thatis based on matched and mismatched\nmask pairs between prediction and annotation respectively. Extensive experimen-\ntal evaluations show that OVS models consistently perform better under the pro-\nposed mask-wise protocol compared to the previous pixel-wise one. Moreover,\nanalysis of mismatched mask pair reveals that large amount of ambiguous cate-\ngories exist in commonly used OVS datasets. Interestingly, we find that reducing\nthese ambiguities during both training and inference enhances zero-shot inference\ncapabilities. These findings and the new evaluation protocol encourage further\nexploration of the open nature of OVS and broader open-world challenges."
    },
    {
        "title": "Robust Barycenter Estimation using Semi-Unbalanced Neural Optimal Transport",
        "link_suffix": "/forum?id=CI5Cj0vktS",
        "link": "https://openreview.net/forum?id=CI5Cj0vktS",
        "pdf_link": "https://openreview.net/pdf?id=CI5Cj0vktS",
        "keywords": "unbalanced optimal transport, barycenter, generative modeling",
        "abstract": "A common challenge in aggregating data from multiple sources can be formalized as anOptimal Transport(OT) barycenter problem, which seeks to compute the average of probability distributions with respect to OT discrepancies. However, the presence of outliers and noise in the data measures can significantly hinder the performance of traditional statistical methods for estimating OT barycenters. To address this issue, we propose a novel, scalable approach for estimating therobustcontinuous barycenter, leveraging the dual formulation of the(semi-)unbalancedOT problem. To the best of our knowledge, this paper is the first attempt to develop an algorithm for robust barycenters under the continuous distribution setup. \nOur method is framed as a $\\min$-$\\max$ optimization problem and is adaptable togeneralcost function. \nWe rigorously establish the theoretical underpinnings of the proposed method and demonstrate its robustness to outliers and class imbalance through a number of illustrative experiments."
    },
    {
        "title": "Asynchronous stochastic gradient descent with decoupled backpropagation and layer-wise updates",
        "link_suffix": "/forum?id=hFB7XGcBeB",
        "link": "https://openreview.net/forum?id=hFB7XGcBeB",
        "pdf_link": "https://openreview.net/pdf?id=hFB7XGcBeB",
        "keywords": "asynchronous sgd, layer-wise updates, distributed training",
        "abstract": "The increasing size of deep learning models has created the need for more efficient alternatives to the standard error backpropagation algorithm, that make better use of asynchronous, parallel and distributed computing. One major shortcoming of backpropagation is the interlocking between the forward phase of the algorithm, which computes a global loss, and the backward phase where the loss is backpropagated through all layers to compute the gradients, which are used to update the network parameters. To address this problem, we propose a method that parallelises SGD updates across the layers of a model by asynchronously updating them from multiple threads. Furthermore, since we observe that the forward pass is often much faster than the backward pass, we use separate threads for the forward and backward pass calculations, which allows us to use a higher ratio of forward to backward threads than the usual 1:1 ratio, reducing the overall staleness of the parameters. Thus, our approach performs asynchronous stochastic gradient descent using separate threads for the loss (forward) and gradient (backward) computations and performs layer-wise partial updates to parameters in a distributed way. We show that this approach yields close to state-of-the-art results while running up to 2.97× faster than Hogwild! scaled on multiple devices (Locally- Partitioned-Asynchronous-Parallel SGD).We theoretically prove the convergence of the algorithm using a novel theoretical framework based on stochastic differential equations and the drift diffusion process, by modeling the asynchronous parameter updates as a stochastic process."
    },
    {
        "title": "Inverse decision-making using neural amortized Bayesian actors",
        "link_suffix": "/forum?id=zxO4WuVGns",
        "link": "https://openreview.net/forum?id=zxO4WuVGns",
        "pdf_link": "https://openreview.net/pdf?id=zxO4WuVGns",
        "keywords": "Bayesian actor models, perception and action, cognitive science, Bayesian inference, inverse modeling",
        "abstract": "Bayesian observer and actor models have provided normative explanations for many behavioral phenomena in perception, sensorimotor control, and other areas of cognitive science and neuroscience. They attribute behavioral variability and biases to interpretable entities such as perceptual and motor uncertainty, prior beliefs, and behavioral costs. However, when extending these models to more naturalistic tasks with continuous actions, solving the Bayesian decision-making problem is often analytically intractable. Inverse decision-making, i.e. performing inference over the parameters of such models given behavioral data, is computationally even more difficult. Therefore, researchers typically constrain their models to easily tractable components, such as Gaussian distributions or quadratic cost functions, or resort to numerical approximations. To overcome these limitations, we amortize the Bayesian actor using a neural network trained on a wide range of parameter settings in an unsupervised fashion. Using the pre-trained neural network enables performing efficient gradient-based Bayesian inference of the Bayesian actor model's parameters. We show on synthetic data that the inferred posterior distributions are in close alignment with those obtained using analytical solutions where they exist. Where no analytical solution is available, we recover posterior distributions close to the ground truth. We then show how our method allows for principled model comparison and how it can be used to disentangle factors that may lead to unidentifiabilities between priors and costs. Finally, we apply our method to empirical data from three sensorimotor tasks and compare model fits with different cost functions to show that it can explain individuals' behavioral patterns."
    },
    {
        "title": "Textbook Consistency Weighted Internet Improves Efficiency Twofold",
        "link_suffix": "/forum?id=a6bnpOInjs",
        "link": "https://openreview.net/forum?id=a6bnpOInjs",
        "pdf_link": "https://openreview.net/pdf?id=a6bnpOInjs",
        "keywords": "training efficiency, large language model, adaptive data weighting",
        "abstract": "We propose a novel method, Textbook Consistency, to improve the training efficiency of large language models by leveraging textbooks as a guiding signal for learning from internet-scale data. Rather than relying on hard filtering of data based on quality thresholds before training, our approach adaptively adjusts the weight of data during training based on its consistency with textbooks during training. We compute the cosine similarity between internet data and textbooks in a latent space, using this metric to modulate the cross-entropy loss. Our method significantly enhances training efficiency, achieving twice the effectiveness by reducing training time or the number of tokens required. Empirical results show superior performance on language models trained on large datasets like FineWeb and The Pile, with extensions to other domains such as robotics. Our method is simple to implement, incurs no additional overhead, and is compatible with existing data curation techniques."
    },
    {
        "title": "The GECo algorithm for Graph Neural Networks Explanation",
        "link_suffix": "/forum?id=sTQC4TeYo1",
        "link": "https://openreview.net/forum?id=sTQC4TeYo1",
        "pdf_link": "https://openreview.net/pdf?id=sTQC4TeYo1",
        "keywords": "Graph Neural Networks, Interpretability, Explainability",
        "abstract": "Graph Neural Networks (GNNs) are powerful models that manage complex data sources and their interconnection links. One of GNNs' main drawbacks is their lack of interpretability, which limits their applicability in sensitive cases. In this paper, we introduce a new methodology involving graph communities to address the interpretability of graph classification problems. The proposal, called GECo (Graph Explanation by COmmunities), exploits the idea that a community, i.e., a subset of graph nodes densely connected, should play a crucial role in graph classification. This assumption is reasonable considering the message-passing mechanism, the core of GNNs. GECo analyzes the contribution to the classification result of the community graphs, building a mask that highlights graph-relevant structures. It first uses the trained GNN one wants to explain to classify the entire graph. Then, it detects the different communities; for each community, a smaller subgraph, including the community nodes’ is created, and the trained GNN is run to see how likely the subgraph alone supports the predicted class. After evaluating all the subgraph communities, an average probability is calculated and set as a threshold. Finally, any subgraph community with a probability value higher than the threshold is assessed as necessary for the model's decision. The collection of these key communities is the basis for the final explanation since they allow the highlighting of the most relevant parts of the graph leading to the classification. GECo has been tested on GNN employing Graph Convolutional Networks layers, using six artificial and four real-world graph datasets. The six synthetic datasets were generated by adding some artificial motifs (e.g., house, cycle, etc.) to Erdos-Renyi and Barabasi-Albert graphs.  The real-world datasets contain molecule structures. Both categories of datasets are adopted in the experimental part of the state-of-the-art proposals for graph explainability. GECo has been compared with a random baseline explainer and four state-of-the-art approaches: PGExplainer, PGMExplainer, GNNExplainer, and SubgraphX. We chose these methods for their different strengths, specifically PGExplainer for its efficiency and generalization capability through a learned explanation model, PGMExplainer for its probabilistic approach based on causal graphs, GNNExplainer for its detailed subgraph and feature-level explanations, and SubgraphX for its theoretically grounded subgraph selection by Shapley values. These choices ensure a comprehensive evaluation of our approach against a wide range of robust techniques. We assessed GECo's performance using four evaluation criteria that leverage predicted and ground-truth explanations and use user-controlled parameters, such as the probability distribution obtained by the GNN. The results obtained by GECo consistently outperform state-of-the-art techniques across multiple metrics for synthetic and most real-world datasets. In addition, GECo is significantly faster than its competitors in terms of computational efficiency, making it an ideal solution for large-scale data analysis and practical applications. These strengths solidify GECo’s role in generating accurate, efficient, and interpretable explanations in graph-based classification tasks."
    },
    {
        "title": "Reframing Structure-Based Drug Design Model Evaluation via Metrics Correlated to Practical Needs",
        "link_suffix": "/forum?id=RyWypcIMiE",
        "link": "https://openreview.net/forum?id=RyWypcIMiE",
        "pdf_link": "https://openreview.net/pdf?id=RyWypcIMiE",
        "keywords": "Stucture-Based Drug Design, Model Evaluation, Benchmark",
        "abstract": "Recent advances in structure-based drug design (SBDD) have produced surprising results, with models often generating molecules that achieve better Vina docking scores than actual ligands. However, these overly optimistic results are questionable due to the known inaccuracies of docking scores and the difficulty of evaluating these molecules in wet-lab settings. Despite showing good QED (drug-likeness) and SA (synthetic ability) scores, these molecules are often poorly drug-like or not synthesizable. To address these issues, rather than relying solely on those heuristic-based theoretical estimation metrics that has poor correlation with actual wet lab success, we evaluate SBDD models from a practical perspective aligned with real-world needs. Inspired by recent research demonstrating the value of generated molecules through ligand-based virtual screening, our evaluation metrics simulate the success rate of wet-lab assessments without requiring time-consuming, costly, and expertise-dependent processes. These metrics assess the ability of generated molecules to effectively retrieve active compounds from a chemical library via similarity-based searches, offering a more direct indication of therapeutic potential. Our experiments reveal that while SBDD models may excel on theoretical metrics like Vina scores, they often fall short in practical applications, highlighting a gap between theoretical performance and real-world utility. By introducing these new metrics, we aim to make SBDD models more relevant and impactful for pharmaceutical research and development."
    },
    {
        "title": "Valid Conformal Prediction for Dynamic GNNs",
        "link_suffix": "/forum?id=i3T0wvQDKg",
        "link": "https://openreview.net/forum?id=i3T0wvQDKg",
        "pdf_link": "https://openreview.net/pdf?id=i3T0wvQDKg",
        "keywords": "Graph neural networks, Graph machine learning, conformal prediction",
        "abstract": "Dynamic graphs provide a flexible data abstraction for modelling many sorts of real-world systems, such as transport, trade, and social networks. Graph neural networks (GNNs) are powerful tools allowing for different kinds of prediction and inference on these systems, but getting a handle on uncertainty, especially in dynamic settings, is a challenging problem.In this work we propose to use a dynamic graph representation known in the tensor literature as the unfolding, to achieve valid prediction sets via conformal prediction. This representation, a simple graph, can be input to any standard GNN and does not require any modification to existing GNN architectures or conformal prediction routines.One of our key contributions is a careful mathematical consideration of the different inference scenarios which can arise in a dynamic graph modelling context. For a range of practically relevant cases, we obtain valid prediction sets with almost no assumptions, even dispensing with exchangeability. In a more challenging scenario, which we call the semi-inductive regime, we achieve valid prediction under stronger assumptions, akin to stationarity.We provide real data examples demonstrating validity, showing improved accuracy over baselines, and sign-posting different failure modes which can occur when those assumptions are violated."
    },
    {
        "title": "ContextGNN: Beyond Two-Tower Recommendation Systems",
        "link_suffix": "/forum?id=nzOD1we8Z4",
        "link": "https://openreview.net/forum?id=nzOD1we8Z4",
        "pdf_link": "https://openreview.net/pdf?id=nzOD1we8Z4",
        "keywords": "graph neural networks, recommendation, relational deep learning",
        "abstract": "Recommendation systems predominantly utilize two-tower architectures, which evaluate user-item rankings through the inner product of their respective embeddings. However, one key limitation of two-tower models is that they learn a pair-agnostic representation of users and items. In contrast, pair-wise representations either scale poorly due to their quadratic complexity or are too restrictive on the candidate pairs to rank. To address these issues, we introduce Context-based Graph Neural Networks (ContextGNNs), a novel deep learning architecture for link prediction in recommendation systems. The method employs a pair-wise representation technique for familiar items situated within a user's local subgraph, while leveraging two-tower representations to facilitate the recommendation of exploratory items. A final network then predicts how to fuse both pair-wise and two-tower recommendations into a single ranking of items. We demonstrate that ContextGNN is able to adapt to different data characteristics and outperforms existing methods, both traditional and GNN-based, on a diverse set of practical recommendation tasks, improving performance by 20% on average."
    },
    {
        "title": "Leveraging Knowledge Distillation to Mitigate Model Collapse",
        "link_suffix": "/forum?id=8TbqoP3Rjg",
        "link": "https://openreview.net/forum?id=8TbqoP3Rjg",
        "pdf_link": "https://openreview.net/pdf?id=8TbqoP3Rjg",
        "keywords": "computer vision, natural language processing, generative models, diffusion, vae, text summarization, model collapse, synthetic data, distillation",
        "abstract": "Since the amount of data generated by neural networks on the Internet is growing rapidly due to widespread access to corresponding models, it is logical to inquire about the impact of this surge in synthetic data on the training of subsequent models that will utilize it during training.  Previous work has demonstrated a concerning trend: models trained predominantly on synthetic data often experience a decline in performance, which can escalate to a complete loss of the ability to reproduce the initial distribution of real-world data. This phenomenon, now referred to as model collapse, highlights the potential pitfalls of over-reliance on synthetic datasets, which may lack the diversity and complexity inherent in genuine data. To address this issue, we propose a novel method that leverages the well-established technique of knowledge distillation. Our approach aims to mitigate the adverse effects of synthetic data by facilitating a more effective transfer of knowledge from high-performing teacher models to student model. By doing so, we seek to enhance not only the qualitative aspects—such as the richness and variability of the generated outputs—but also the quantitative metrics that gauge model performance. Through extensive experimentation, we demonstrate that our method improves the robustness and generalization capabilities of models trained on synthetic data, for instance, for DDPM enhancement is 68.8%, in terms of the FID metric, contributing to a more sustainable and effective use of synthetic datasets in machine learning applications."
    },
    {
        "title": "Partition First, Embed Later: Laplacian-Based Feature Partitioning for Refined Embedding and Visualization of High-Dimensional Data",
        "link_suffix": "/forum?id=LzuyCHvdVo",
        "link": "https://openreview.net/forum?id=LzuyCHvdVo",
        "pdf_link": "https://openreview.net/pdf?id=LzuyCHvdVo",
        "keywords": "data visualization, dimensionality reduction, manifold learning, data embedding, feature partitioning",
        "abstract": "The utility of embedding and visualization techniques for high-dimensional data in exploratory analysis is well-established. However, when the data embody intricate structures governed by multiple latent variables, standard techniques may distort or even mask part of the phenomenon under study. This paper explores scenarios where the observed features can be partitioned into mutually exclusive subsets, each capturing a different smooth substructure. In such cases, visualizing the data based on each feature partition can better characterize the underlying processes and structures in the data, leading to improved interpretability. To partition the features, we propose solving an optimization problem that promotes a graph Laplacian-based smoothness in each partition, thus prioritizing partitions with simpler geometric structures. Our approach generalizes traditional embedding and visualization techniques such as t-distributed Stochastic Neighbor Embedding and Diffusion Maps, allowing them to learn multiple embeddings simultaneously. We establish that if several independent or partially dependent manifolds are embedded in distinct feature subsets in high-dimensional space, then our framework can reliably identify the correct subsets with theoretical guarantees. Finally, we demonstrate the effectiveness of our approach in extracting multiple low-dimensional structures and partially independent processes from both simulated and real data."
    },
    {
        "title": "KOR-Bench: Benchmarking Language Models on Knowledge-Orthogonal Reasoning Tasks",
        "link_suffix": "/forum?id=SVRRQ8goQo",
        "link": "https://openreview.net/forum?id=SVRRQ8goQo",
        "pdf_link": "https://openreview.net/pdf?id=SVRRQ8goQo",
        "keywords": "Reasoning; Knowledge-Orthogonal; Rule-Based",
        "abstract": "In this paper, we introduce the concept of Knowledge-Orthogonal Reasoning(KOR),\nwhere knowledge orthogonality refers to the independence from existing pretrained knowledge. \nBy introducing new rules that are orthogonal to the pretrained knowledge, we minimize its interference to achieve a more accurate evaluation of the model's intrinsic reasoning and planning abilities. \nBased on this concept, we propose the Knowledge-Orthogonal Reasoning Benchmark (KOR-Bench), which includes five task categories: Operation, Logic, Cipher, Puzzle, and Counterfactual.\nKOR-Bench focuses on assessing how well models apply new rule descriptions to solve new rule-driven questions. \nThis challenging benchmark shows that leading models like Claude-3.5-Sonnet and GPT-4o achieve only 58.96% and 58.00%, respectively. \nWe conduct thorough analyses using Stepwise Prompting to identify bottlenecks in Cipher task. Self-correction experiments indicate that two rounds of correction usually result in the best performance. Complex Task Processing evaluates the model's performance across three integrated task settings. Additionally, we analyze the impact of Tricks on puzzle task and visualize rule-focused attention. Our goal is for \\our{} to serve as a valuable tool for evaluating and enhancing the reasoning abilities of models, while also fostering further research and development in this field. All data, inference, evaluation code, and experimental results are available here\\footnote{\\url{https://anonymous.4open.science/r/kor-bench-rebuttal-repo-44F6}}."
    }
]
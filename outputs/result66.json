[{"title": "Universal Multimodal Retrieval with Multimodal LLMs", "link_suffix": "/forum?id=i45NQb2iKO", "link": "https://openreview.net/forum?id=i45NQb2iKO", "pdf_link": "https://openreview.net/pdf?id=i45NQb2iKO", "keywords": "multimodal, embedding model, retriever, LLM", "abstract": "State-of-the-art retrieval models typically address a straightforward search scenario, where retrieval tasks are fixed (e.g., finding a passage to answer a specific question) and only a single modality is supported for both queries and retrieved results. \nThis paper introduces techniques for advancing information retrieval with multimodal large language models (MLLMs), enabling a broader search scenario, termed universal multimodal retrieval, where multiple modalities and diverse retrieval tasks are accommodated. \nTo this end, we first study fine-tuning an MLLM as a bi-encoder retriever on 10 datasets with 16 retrieval tasks. \nOur empirical results show that the fine-tuned MLLM retriever is capable of understanding challenging queries, composed of both text and image, but underperforms a smaller CLIP retriever in cross-modal retrieval tasks due to modality bias from MLLMs. \nTo address the issue, we propose modality-aware hard negative mining to mitigate the modality bias exhibited by MLLM retrievers. \nSecond, we propose to continually fine-tune the universal multimodal retriever to enhance its text retrieval capability while maintaining multimodal retrieval capability. \nAs a result, our model, UniEmb, achieves state-of-the-art performance on the multimodal retrieval benchmark M-BEIR, which spans multiple domains and tasks, while also surpassing the state-of-the-art text retrieval model, NV-Embed-v1, on MTEB retrieval benchmark.\nFinally, we explore to prompt the off-the-shelf MLLMs as the zero-shot reranker to refine the ranking of the candidates from the multimodal retriever. \nWe find that through prompt-and-reranking, MLLMs can further improve multimodal retrieval when the user queries (e.g., text-image composed queries) are more complex and challenging to understand. \nThese findings also pave the way to advance universal multimodal retrieval in the future.", "title_embedding_index": 3250, "title_abs_embedding_index": 3275}, {"title": "Spark Transformer: How Many FLOPs is a Token Worth?", "link_suffix": "/forum?id=iOy2pITOoH", "link": "https://openreview.net/forum?id=iOy2pITOoH", "pdf_link": "https://openreview.net/pdf?id=iOy2pITOoH", "keywords": "LLM, activation sparsity, inference efficiency", "abstract": "This work introduces Spark Transformer, an architectural variant of the Transformer model that drastically reduces the FLOPs count while maintaining comparable quality and an identical parameter count. This reduction is achieved by introducing sparse activations in both the feedforward network (FFN) and the Attention mechanism. In the FFN, this sparsity engages only a subset of parameters for each input. In the Attention mechanism, it limits the number of tokens that each token attends to.  We achieve this sparsity through statistical top-$k$, a lightweight approximate algorithm that is well-suited for accelerator hardware and minimizes training slowdown. Furthermore, Spark Transformer incorporates dedicated predictors to identify the activated entries. These predictors are formed by allocating a portion of the model's parameters and are trained jointly with the rest of the model. This approach distinguishes Spark Transformer from existing methods that introduce sparsity and predictors post-training, which often leads to increased training costs, additional model parameters, and complex modifications to the model architecture. Our Spark Transformer, pretrained using the Gemma 2 recipe, achieves competitive performance on standard benchmarks while exhibiting significant sparsity. Specifically, it utilizes only 8% nonzeros in the FFN activation and attends to a maximum of 256 tokens. This results in a 3.1$\\times$ reduction in FLOPs, yielding a 1.70$\\times$ speedup for prefill and a 1.79$\\times$ speedup for decoding on a 16-core CPU VM.", "title_embedding_index": 3251, "title_abs_embedding_index": 3276}, {"title": "QuantRad: Advancing Quantitative Reliability in Radiology Report Generation with Cascaded Decoders", "link_suffix": "/forum?id=JIEHSyLhG7", "link": "https://openreview.net/forum?id=JIEHSyLhG7", "pdf_link": "https://openreview.net/pdf?id=JIEHSyLhG7", "keywords": "Radiology Report Generation, Image Captioning, Medical Imaging", "abstract": "Radiology report generation using artificial intelligence has shown promise in enhancing clinical workflows. However, due to limitations of language modeling loss, existing approaches struggle with quantitative accuracy (e.g., measuring the size of nodules), and lack the ability to produce confidence scores for medical findings, which is crucial for quantitative metrics required by regulatory approval. This paper introduces QuantRad, a novel approach utilizing cascaded decoders to address these challenges in radiology report generation. QuantRad pairs a vision encoder with three decoders that operate sequentially: the first conducts sentence-level topic planning by generating a series of questions, the second recognizes abnormal targets and their quantitative and categorical attributes, and the third generates the final report by answering each question based on the recognized targets. With the dedicated target recognition step, our method integrates the quantitative strength of a perception model to text generation. Specifically, QuantRad recognizes abnormal targets without being biased by language priors, and produces probability scores along with each finding, allowing adjustments of sensitivity for clinical adoption and producing ROC curves for regulatory compliance. Besides, the disentangled topic planning captures the uncertainties in the omission of medical findings and their presentation order, allowing the report generation decoder to be trained with less ambiguity. Our method advances the accuracy and reliability of radiology report generation, offering a promising path for clinical applications and regulatory validation.", "title_embedding_index": 3252, "title_abs_embedding_index": 3277}, {"title": "On more accurate alignment modeling methods for automatic speech recognition", "link_suffix": "/forum?id=7NlGsjrEd8", "link": "https://openreview.net/forum?id=7NlGsjrEd8", "pdf_link": "https://openreview.net/pdf?id=7NlGsjrEd8", "keywords": "speech recognition, CTC, HMM, AED, alignment accuracy, full sum, peaky behavior, separated blank, alignment by input gradient", "abstract": "The connectionist temporal classification (CTC) training criterion\noptimizes the conditional log probability of the label sequence given the input,\nwhich involves a sum over all possible alignment labels including blank over the time frames.\nIt is well known that CTC training leads to peaky behavior\nwhere blank is predicted in most frames and the labels are focused mostly on single frames.\nThus, CTC is suboptimal to obtain accurate word boundaries.\nHidden Markov models (HMMs) can be seen as a generalization of CTC\nand trained in the same way with\na generalized training criterion,\nand may lead to similar problems.\nLabel units such as subword units and its vocabulary size or phoneme-based units\nalso significantly impact the alignment quality.\nHere we study different variations of the training criterion, procedure and modeling\nwith the goals\nto improve alignment accuracy in terms of time-stamp-error (TSE) of word boundaries or word center positions,\nto improve convergence rate and training robustness,\nthe recognition performance,\nand to gain better understanding of the training dynamics.\nWe introduce\n(1) a synthetic framework to study alignment behavior,\nand compare various models, noise and training conditions,\n(2) a new training variant with renormalizing the gradients to counteract the class imbalance of blank,\n(3) a novel CTC model variation to use a hierarchical softmax and separating the blank label in CTC,\nas another alternative to counteract class imbalance,\nleading to improved alignment quality,\n(4) a novel way to get alignments via the gradients\nof the label log probabilities w.r.t.~the input features.\nThis method can be used for all kinds of models,\nand we evaluate it for CTC and Attention-based encoder-decoder (AED) subword based models\nwhere it performs competitive and more robustly,\nalthough phoneme-based HMMs still provide the best alignments.", "title_embedding_index": 3253, "title_abs_embedding_index": 3278}, {"title": "In Praise of Stubbornness: The Case for Cognitive-Dissonance Aware Continual Update of Knowledge in LLMs", "link_suffix": "/forum?id=cHyQT6Y1jY", "link": "https://openreview.net/forum?id=cHyQT6Y1jY", "pdf_link": "https://openreview.net/pdf?id=cHyQT6Y1jY", "keywords": "LLM, knowledge editing, continual learning, Cognitive Science-Inspired AI, Human-inspired AI, Episodic Memory, Incremental Learning, Targeted Network Updates", "abstract": "Despite remarkable capabilities, large language models (LLMs) struggle to continually update their knowledge without catastrophic forgetting. In contrast, humans effortlessly integrate new information, detect conflicts with existing beliefs, and selectively update their mental models. This paper introduces a novel incremental update paradigm inspired by human cognition. We implement and evaluate two key components within existing LLM architectures: (1) Dissonance and Familiarity Awareness, enabling LLMs to classify new information as novel, familiar, or dissonant; and (2) Targeted Network Updates, which involve continuously tracking past gradient usage to distinguish between frequently used (stubborn) and rarely used (plastic) neurons.Through a series of carefully designed experiments, we uncover a number of empirical findings and demonstrate the potential of this approach. First, dissonance awareness is feasible even using simple features like activations and gradients. Second, unlike non-dissonant updates which largely preserve prior knowledge even with naive fine-tuning, dissonant updates prove catastrophically destructive to the model's knowledge base, indiscriminately affecting even information unrelated to the current updates. Finally, our history-aware targeted updates, which continuously monitor and leverage past gradient information, alleviate the negative impact of dissonant updates significantly better than state-of-the-art editing methods. We plan to develop dedicated conflict resolution methods in future work.", "title_embedding_index": 3254, "title_abs_embedding_index": 3279}, {"title": "RNNs are not Transformers (Yet):  The Key Bottleneck on In-Context Retrieval", "link_suffix": "/forum?id=h3wbI8Uk1Z", "link": "https://openreview.net/forum?id=h3wbI8Uk1Z", "pdf_link": "https://openreview.net/pdf?id=h3wbI8Uk1Z", "keywords": "rnn, cot, representation theory", "abstract": "This paper investigates the gap in representation powers of Transformers and Recurrent Neural Networks (RNNs), which are more memory efficient than Transformers. We aim to understand whether RNNs can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: \nfor several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease.\nConversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, including Retrieval-Augmented Generation (RAG) and adding a single Transformer layer, can elevate RNNs to be capable of solving all polynomial-time solvable problems with CoT, hence closing the representation gap with Transformers. We validate our theory on synthetic and natural language experiments.", "title_embedding_index": 3255, "title_abs_embedding_index": 3280}, {"title": "DC-Spin: A Speaker-invariant Speech Tokenizer For Spoken Language Models", "link_suffix": "/forum?id=OW332Wh9S5", "link": "https://openreview.net/forum?id=OW332Wh9S5", "pdf_link": "https://openreview.net/pdf?id=OW332Wh9S5", "keywords": "speech tokenizer, self-supervised learning, spoken language model, speech language model, speech resynthesis, audio codec", "abstract": "Spoken language models (SLMs) have gained increasing attention with advancements in text-based, decoder-only language models.\nThese models process text and speech, enabling simultaneous speech understanding and generation. This paper presents Double-Codebook Speaker-invariant Clustering (DC-Spin), which aims to improve speech tokenization by bridging audio signals and SLM input-output tokens. DC-Spin extracts speaker-invariant tokens rich in phonetic information and resilient to input variations, enhancing zero-shot SLM tasks and speech resynthesis. Comparisons of tokenization methods (self-supervised and neural audio codecs), model scalability, and downstream task proxies show that tokens easily modeled by an n-gram LM or aligned with phonemes offer strong performance, providing insights for designing speech tokenizers for SLMs.", "title_embedding_index": 3256, "title_abs_embedding_index": 3281}, {"title": "Interactive Dialogue Agents via Reinforcement Learning with Hindsight Regenerations", "link_suffix": "/forum?id=hrGOMrfc2z", "link": "https://openreview.net/forum?id=hrGOMrfc2z", "pdf_link": "https://openreview.net/pdf?id=hrGOMrfc2z", "keywords": "offline reinforcement learning, language models, self-reflection", "abstract": "Recent progress on large language models (LLMs) has enabled dialogue agents to generate highly naturalistic and plausible text. However, current LLM language generation focuses on responding accurately to questions and requests with a single effective response.\nIn reality, many real dialogues are interactive, meaning an agent's utterances will influence their conversational partner, elicit information, or change their opinion. Accounting for how an agent can effectively steer a conversation is a crucial ability in many dialogue tasks, from healthcare to preference elicitation. Existing methods for fine-tuning dialogue agents to accomplish such tasks would rely on curating some amount of expert data. However, doing so often requires understanding the underlying cognitive processes of the conversational partner, which is a skill neither humans nor LLMs trained on human data can reliably do. Our key insight is that while LLMs may not be adept at identifying effective strategies for steering conversations a priori, or in the middle of an ongoing conversation, they can do so post-hoc, or in hindsight, after seeing how their conversational partner responds. We use this fact to rewrite and augment existing suboptimal data, and train via offline reinforcement learning (RL) an agent that outperforms both prompting and learning from unaltered human demonstrations. We apply our approach to two domains that require understanding human mental state, intelligent interaction, and persuasion: mental health support, and soliciting charitable donations. Our results in a user study with real humans show that our approach greatly outperforms existing state-of-the-art dialogue agents.", "title_embedding_index": 3257, "title_abs_embedding_index": 3282}, {"title": "Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF", "link_suffix": "/forum?id=cVyELMpMRS", "link": "https://openreview.net/forum?id=cVyELMpMRS", "pdf_link": "https://openreview.net/pdf?id=cVyELMpMRS", "keywords": "Reinforcement Learning, Reinforcement Learning from Human Feedback", "abstract": "Large Language Models (LLMs) have achieved remarkable success at tasks like summarization that involve asingle turnof interaction. However, they can still struggle withmulti-turntasks like dialogue that require long-term planning. Previous works on multi-turn dialogue extend single-turn reinforcement learning from human feedback (RLHF) methods to the multi-turn setting by treating all prior dialogue turns as a long context. Such approaches suffer fromcovariate shift: the conversations in the training set have previous turns generated by some reference policy, which means that low training error may not necessarily correspond to good performance when the learner is actually in the conversation loop. In response, we introduce REgressing the RELative FUture (REFUEL), an efficient policy optimization approach designed to address multi-turn RLHF in LLMs. REFUEL employs a single model to estimate Q-values and trains on self-generated data, addressing the covariate shift issue. REFUEL frames the multi-turn RLHF problem as a sequence of regression tasks on iteratively collected datasets, enabling ease of implementation. Theoretically, we prove that REFUEL can match the performance of any policy covered by the training set. Empirically, we evaluate our algorithm by using Llama-3.1-70B-it to simulate a user in conversation with our model. REFUEL consistently outperforms state-of-the-art methods such as DPO and REBEL across various settings. Furthermore, despite having only 8 billion parameters, Llama-3-8B-it fine-tuned with REFUEL, outperforms Llama-3.1-70B-it on long multi-turn dialogues.", "title_embedding_index": 3258, "title_abs_embedding_index": 3283}, {"title": "Efficiently Identifying Watermarked Segments in Mixed-Source Texts", "link_suffix": "/forum?id=dmDEhEHxix", "link": "https://openreview.net/forum?id=dmDEhEHxix", "pdf_link": "https://openreview.net/pdf?id=dmDEhEHxix", "keywords": "Watermark, Online learning, LLM", "abstract": "Text watermarks in large language models (LLMs) are increasingly used to detect synthetic text, mitigating misuse cases like fake news and academic dishonesty. While existing watermarking detection techniques primarily focus on classifying entire documents as watermarked or not, they often neglect the common scenario of identifying individual watermark segments within longer, mixed-source documents. Drawing inspiration from plagiarism detection systems, we propose two novel methods for partial watermark detection. First, we develop a geometry cover detection framework aimed at determining whether there is a watermark segment in long text. Second, we introduce an adaptive online learning algorithm to pinpoint the precise location of watermark segments within the text. Evaluated on three popular watermarking techniques (KGW-Watermark, Unigram-Watermark, and Gumbel-Watermark), our approach achieves high accuracy, significantly outperforming baseline methods. Moreover, our framework is adaptable to other watermarking techniques, offering new insights for precise watermark detection.", "title_embedding_index": 3259, "title_abs_embedding_index": 3284}, {"title": "Foundation Vision Models are Unsupervised Image Canonicalizers", "link_suffix": "/forum?id=Il5DjZmLzp", "link": "https://openreview.net/forum?id=Il5DjZmLzp", "pdf_link": "https://openreview.net/pdf?id=Il5DjZmLzp", "keywords": "Invariance, Canonicalization, Foundation Models, CLIP, SD, Augmentation, Vision, Robustness", "abstract": "One of the most significant and longstanding problems in computer vision is invariance - the ability to robustly handle changes in real-world transformations such as rotation, viewpoint, and lighting. Unfortunately, popular foundation models remain brittle under such transformations. While existing solutions towards invariance have shown promise, they all fundamentally require some model training, limiting their ability to adapt broadly to new tasks, transformations, and datasets. Our key insight is that foundation model priors can be used to reason about transformations. We thus propose Foundation Model Canonicalization (FMC), an approach that can undo nuisance transformations in images without any model training. With a single core approach, FMC can make models like CLIP and SAM invariant to different transformations without any training or fine-tuning. Our approach FMC flexibly adapts to new foundation models and tasks, making it significantly easier for newer and larger models to achieve invariance.", "title_embedding_index": 3260, "title_abs_embedding_index": 3285}, {"title": "Diffusing States and Matching Scores: A New Framework for Imitation Learning", "link_suffix": "/forum?id=kWRKNDU6uN", "link": "https://openreview.net/forum?id=kWRKNDU6uN", "pdf_link": "https://openreview.net/pdf?id=kWRKNDU6uN", "keywords": "imitation learning, diffusion model, score matching", "abstract": "Adversarial Imitation Learning is traditionally framed as a two-player zero-sum game between a learner and an adversarially chosen cost function, and can therefore be thought of as the sequential generalization of a Generative Adversarial Network (GAN). A prominent example of this framework is Generative Adversarial Imitation Learning (GAIL). However, in recent years, diffusion models have emerged as a non-adversarial alternative to GANs that merely require training a score function via regression, yet produce generations of a higher quality. In response, we investigate how to lift insights from diffusion modeling to the sequential setting. We propose diffusing states and performing \\textit{score-matching} along diffused states to measure the discrepancy between the expert's and learner's states. Thus, our approach only requires training score functions to predict noises via standard regression, making it significantly easier and more stable to train than adversarial methods. Theoretically, we prove first- and second-order instance-dependent bounds with linear scaling in the horizon, proving that our approach avoids the compounding errors that stymie offline approaches to imitation learning. Empirically, we show our approach outperforms GAN-style imitation learning baselines across various continuous control problems, including complex tasks like controlling humanoids to walk, sit, and crawl.", "title_embedding_index": 3261, "title_abs_embedding_index": 3286}, {"title": "Linear Representations of Political Perspective Emerge in Large Language Models", "link_suffix": "/forum?id=rwqShzb9li", "link": "https://openreview.net/forum?id=rwqShzb9li", "pdf_link": "https://openreview.net/pdf?id=rwqShzb9li", "keywords": "large language model, political perspective, ideology, representation learning", "abstract": "Large language models (LLMs) have demonstrated the ability to simulate responses aligned with human subjective perspectives, such as liberal or conservative ideologies in American politics. Our study reveals that LLMs achieve this by learning a ``geometry of perspective'' that linearly represents subjective perspectives in the activation space, where similar simulated perspectives are represented closer to each other. Specifically, we probe the hidden layers of open, transformer-based LLMs (\\texttt{Llama-2-7b-chat, Mistral-7b-instruct, Vicuna-7b}) when prompted to generate texts under the ideological perspective of distinct politicians. We find a set of attention heads that represent U.S. ideological slant, which is primarily located in the middle layers known to encode high-level concepts and tasks. The activation of these attention heads, when prompted about U.S.~politicians and media outlets, linearly correlates with existing measures of their ideological slant. We use this activation to detect the ideological slant implicitly adopted by an LLM as it is generating each token. We further show that by intervening on these attention heads, we can tune LLM output to any position along the linear dimension from a liberal to conservative ideological perspective. Our research shows that political ideology serves as a fundamental dimension of LLM representations, and present an interpretability method to identify, monitor, and control the subjective perspective used to generate text. Code:https://osf.io/us9yx/?view_only=cf0fdcdb123e4d6bb7d10a64be5c1a09", "title_embedding_index": 3262, "title_abs_embedding_index": 3287}, {"title": "Understanding the Interplay between Parametric and Contextual Knowledge for Large Language Models", "link_suffix": "/forum?id=t21RmVmJrT", "link": "https://openreview.net/forum?id=t21RmVmJrT", "pdf_link": "https://openreview.net/pdf?id=t21RmVmJrT", "keywords": "Large Language Models, Parametric Knowledge, Contextual Knowledge, Reasoning", "abstract": "Large language models (LLMs) encode vast amounts of knowledge during pre-training (parametric knowledge or PK) and can further be enhanced by incorporating contextual knowledge (CK). Can LLMs effectively integrate their internal PK with external CK to solve complex problems? In this paper, we investigate the dynamic interaction between PK and CK, categorizing their relationships into Supportive, Complementary, Conflicting, and Irrelevant types. To support this investigation, we introduce EchoQA, a benchmark spanning scientific, factual, and commonsense knowledge. Our results show that LLMs tend to suppress their PK when contextual information is available, even when it is complementary or irrelevant. While tailored instructions can encourage LLMs to rely more on their PK, they still struggle to fully leverage it. These findings reveal a key vulnerability in LLMs, raising concerns about their reliability in knowledge-intensive tasks.", "title_embedding_index": 3263, "title_abs_embedding_index": 3288}, {"title": "Towards continuous machine learning on periodic crystals by ultra-fast invariants", "link_suffix": "/forum?id=rcdR97P2Mp", "link": "https://openreview.net/forum?id=rcdR97P2Mp", "pdf_link": "https://openreview.net/pdf?id=rcdR97P2Mp", "keywords": "scientific integrity, periodic crystal, isometry invariant, continuous metric", "abstract": "Periodic point sets model all solid crystalline materials (crystals) whose atoms can be considered zero-sized points with or without atomic types.This paper addresses the fundamental problem of checking whether claimed crystals are novel, not noisy perturbations of known materials obtained by unrealistic atomic replacements. Such near-duplicates have already skewed ground truth because past comparisons relied on discontinuous cells and symmetries.The proposed Lipschitz continuity under noise is a new essential requirement for machine learning on any data objects that have ambiguous representations and live in continuous spaces.For periodic point sets under isometry (any distance-preserving transformation), we designed the invariants that distinguish all known counter-examples to the completeness of past descriptors and detect thousands of (near-)duplicates in the world's five largest databases in a few minutes on a modest desktop computer.", "title_embedding_index": 3264, "title_abs_embedding_index": 3289}, {"title": "Behavioral Entropy-Guided Dataset Generation for Offline Reinforcement Learning", "link_suffix": "/forum?id=LuT2CVrlpU", "link": "https://openreview.net/forum?id=LuT2CVrlpU", "pdf_link": "https://openreview.net/pdf?id=LuT2CVrlpU", "keywords": "reinforcement learning, offline reinforcement learning, exploration, entropy", "abstract": "Entropy-based objectives are widely used to perform state space exploration in reinforcement learning (RL) and dataset generation for offline RL. Behavioral entropy (BE), a rigorous generalization of classical entropies that incorporates cognitive and perceptual biases of agents, was recently proposed for discrete settings and shown to be a promising metric for robotic exploration problems. In this work, we propose using BE as a principled exploration objective for systematically generating datasets that provide diverse state space coverage in complex, continuous, potentially high-dimensional domains. To achieve this, we extend the notion of BE to continuous settings, derive tractable $k$-nearest neighbor estimators, provide theoretical guarantees for these estimators, and develop practical reward functions that can be used with standard RL methods to learn BE-maximizing policies. Using standard MuJoCo environments, we experimentally compare the performance of offline RL algorithms for a variety of downstream tasks on datasets generated using BE, R'{e}nyi, and Shannon entropy-maximizing policies. We find that offline RL algorithms trained on datasets collected using BE outperform those trained on datasets collected using Shannon entropy on all tasks considered, and on 80% of the tasks compared to datasets collected using R'{e}nyi entropy.", "title_embedding_index": 3265, "title_abs_embedding_index": 3290}, {"title": "Resolving Domain Shift For Representations Of Speech In Non-Invasive Brain Recordings", "link_suffix": "/forum?id=HJp1g4w1Or", "link": "https://openreview.net/forum?id=HJp1g4w1Or", "pdf_link": "https://openreview.net/pdf?id=HJp1g4w1Or", "keywords": "Domain Adaptation, MEG, Magnetoencephalography, Speech Decoding, Brain-Computer Interfaces, Non-invasive Neuroimaging, Domain Shift", "abstract": "Machine learning techniques have enabled researchers to leverage neuroimaging data to decode speech from brain activity, with some amazing recent successes achieved by applications built using invasive devices. However, research requiring surgical implants has a number of practical limitations. Non-invasive neuroimaging techniques provide an alternative but come with their own set of challenges, the limited scale of individual studies being among them. Without the ability to pool the recordings from different non-invasive studies, data on the order of magnitude needed to leverage deep learning techniques to their full potential remains out of reach. In this work, we focus on non-invasive data collected using magnetoencephalography (MEG). We leverage two different, leading speech decoding models to investigate how an adversarial domain adaptation framework augments their ability to generalize across datasets. We successfully improve the performance of both models when training across multiple datasets. To the best of our knowledge, this study is the first ever application of feature-level, deep learning based harmonization for MEG neuroimaging data. Our analysis additionally offers further evidence of the impact of demographic features on neuroimaging data, demonstrating that participant age strongly affects how machine learning models solve speech decoding tasks using MEG data. Lastly, in the course of this study we produce a new open-source implementation of one of these models to the benefit of the broader scientific community.", "title_embedding_index": 3266, "title_abs_embedding_index": 3291}, {"title": "Small features matter: Robust representation for world models", "link_suffix": "/forum?id=Qr9TjKYzjl", "link": "https://openreview.net/forum?id=Qr9TjKYzjl", "pdf_link": "https://openreview.net/pdf?id=Qr9TjKYzjl", "keywords": "Representation learning, model based reinforcement learning, world models", "abstract": "In Model-Based Reinforcement Learning (MBRL), an agent learns to make decisions by building a world model that predicts the environment's dynamics. The accuracy of this world model is crucial for generalizability and sample efficiency. Many works rely on pixel-level reconstruction, which may focus on irrelevant, exogenous features over minor, but key information. In this work, to encourage the world model to focus on important task related information, we propose an augmentation to the world model training using a temporal prediction loss in the embedding space as an auxiliary loss. Building our method on the DreamerV3 architecture, we improve sample efficiency and stability by learning better representation for world model and policy training. We evaluate our method on the Atari100k and Distracting Control Suite benchmarks, demonstrating significant improvements in world model quality and overall MBRL performance.", "title_embedding_index": 3267, "title_abs_embedding_index": 3292}, {"title": "Rational Metareasoning for Large Language Models", "link_suffix": "/forum?id=jRZ1ZeenZ6", "link": "https://openreview.net/forum?id=jRZ1ZeenZ6", "pdf_link": "https://openreview.net/pdf?id=jRZ1ZeenZ6", "keywords": "LLM, Metareasoning, Problem solving, Chain of Thought, Inference Optimization, Value of Computation", "abstract": "Being prompted to engage in reasoning has emerged as a core technique for using large language models (LLMs), deploying additional inference-time compute to improve task performance. However, as LLMs increase in both size and adoption, inference costs are correspondingly becoming increasingly burdensome. How, then, might we optimize reasoning's cost-performance tradeoff?  This work introduces a novel approach based on computational models of metareasoning used in cognitive science, training LLMs to selectively use intermediate reasoning steps only when necessary. We first develop a reward function that incorporates the Value of Computation by penalizing unnecessary reasoning, then use this reward function with Expert Iteration to train the LLM. Compared to few-shot chain-of-thought prompting and STaR, our method significantly reduces inference costs (20-37% fewer tokens generated across three models) while maintaining task performance across diverse datasets.", "title_embedding_index": 3268, "title_abs_embedding_index": 3293}, {"title": "Context-aware Dynamic Pruning for Speech Foundation Models", "link_suffix": "/forum?id=u2QdCiOgwA", "link": "https://openreview.net/forum?id=u2QdCiOgwA", "pdf_link": "https://openreview.net/pdf?id=u2QdCiOgwA", "keywords": "Pruning, Speech Foundation Model, Automatic Speech Recognition, Speech Translation", "abstract": "Foundation models, such as large language models, have achieved remarkable success in natural language processing and are evolving into models capable of handling multiple modalities.\nListening ability, in particular, is crucial for many applications, leading to research on building speech foundation models. However, the high computational cost of these large models presents a significant challenge for real-world applications. Although substantial efforts have been made to reduce computational costs, such as through pruning techniques, the majority of these approaches are applied primarily during the training phase for specific downstream tasks. In this study, we hypothesize that optimal pruned networks may vary based on contextual factors such as speaker characteristics, languages, and tasks. To address this, we propose a dynamic pruning technique that adapts to these contexts during inference without altering the underlying model. We demonstrated that we could successfully reduce inference time by approximately 30% while maintaining accuracy in multilingual/multi-task scenarios. We also found that the obtained pruned structure offers meaningful interpretations based on the context, e.g., task-related information emerging as the dominant factor for efficient pruning.", "title_embedding_index": 3269, "title_abs_embedding_index": 3294}, {"title": "Consistency-based Black-box Uncertainty Quantification for Text-to-SQL by Similarity Aggregation", "link_suffix": "/forum?id=ofiZbAmrZh", "link": "https://openreview.net/forum?id=ofiZbAmrZh", "pdf_link": "https://openreview.net/pdf?id=ofiZbAmrZh", "keywords": "text-to-sql, uncertainty quantification, black-box, similarity, large language model, generative model", "abstract": "When does a large language model (LLM) know what it does not know? Uncertainty quantification (UQ) provides an estimate of the confidence in an LLM's generated output and is therefore increasingly recognized as a crucial component of trusted AI systems. UQ is particularly important for complex generative tasks such as \\emph{text-to-SQL}, where an LLM helps users gain insights about data stored in noisy and large databases by translating their natural language queries to structured query language (SQL). \\emph{Black-box} UQ methods do not require access to internal model information from the generating LLM, and therefore have numerous real-world advantages, such as robustness to system changes, adaptability to choice of LLM (including those with commercialized APIs), reduced costs, and substantial computational tractability. In this paper, we investigate the effectiveness of black-box UQ techniques for text-to-SQL, where the consistency between a generated output and other sampled generations is used as a proxy for estimating its confidence. We propose a high-level non-verbalized \\emph{similarity aggregation} approach that is suitable for complex generative tasks, including specific techniques that train confidence estimation models using small training sets. Through an extensive empirical study over various text-to-SQL datasets and models, we provide recommendations for the choice of sampling technique and similarity metric. The experiments demonstrate that our proposed similarity aggregation techniques result in better calibrated confidence estimates as compared to the closest baselines, but also highlight how there is room for improvement on downstream tasks such as selective generation.", "title_embedding_index": 3270, "title_abs_embedding_index": 3295}, {"title": "From Pixels to Prose: A Large Dataset of Dense Image Captions", "link_suffix": "/forum?id=UwbX8KOZgK", "link": "https://openreview.net/forum?id=UwbX8KOZgK", "pdf_link": "https://openreview.net/pdf?id=UwbX8KOZgK", "keywords": "multimodal datasets, image-text pairs, large scale datasets", "abstract": "Training large vision-language models requires extensive, high-quality image-text pairs. Existing web-scraped datasets, however, are noisy and lack detailed image descriptions. To bridge this gap, we introduce PixelProse, a comprehensive dataset of over 16M (million) synthetically generated captions, leveraging cutting-edge vision-language models for detailed and accurate descriptions. To ensure data integrity, we rigorously analyze our dataset for problematic content, including child sexual abuse material (CSAM), personally identifiable information (PII), and toxicity. We also provide valuable metadata such as watermark presence and aesthetic scores, aiding in further dataset filtering. We hope PixelProse to serve as a valuable resource for future research involving vision-language modalities.", "title_embedding_index": 3271, "title_abs_embedding_index": 3296}, {"title": "Infinite-Resolution Integral Noise Warping for Diffusion Models", "link_suffix": "/forum?id=Y6LPWBo2HP", "link": "https://openreview.net/forum?id=Y6LPWBo2HP", "pdf_link": "https://openreview.net/pdf?id=Y6LPWBo2HP", "keywords": "diffusion models; video generation; temporal consistency; noise warping; white Gaussian noise", "abstract": "Adapting pretrained image-based diffusion models to generate temporally consistent videos has become an impactful generative modeling research direction. Training-free noise-space manipulation has proven to be an effective technique, where the challenge is to preserve the Gaussian white noise distribution while adding in temporal consistency. Recently, Chang et al. (2024) formulated this problem using an integral noise representation with distribution-preserving guarantees, and proposed an upsampling-based algorithm to compute it. However, while their mathematical formulation is advantageous, the algorithm incurs a high computational cost. Through analyzing the limiting-case behavior of their algorithm as the upsampling resolution goes to infinity, we develop an alternative algorithm that, by gathering increments of multiple Brownian bridges, achieves their infinite-resolution accuracy while simultaneously reducing the computational cost by orders of magnitude. We prove and experimentally validate our theoretical claims, and demonstrate our method's effectiveness in real-world applications. We further show that our method can readily extend to the 3-dimensional space.", "title_embedding_index": 3272, "title_abs_embedding_index": 3297}, {"title": "Data-Centric Graph Condensation via Diffusion Trajectory Matching", "link_suffix": "/forum?id=XWK2o2cJ3W", "link": "https://openreview.net/forum?id=XWK2o2cJ3W", "pdf_link": "https://openreview.net/pdf?id=XWK2o2cJ3W", "keywords": "Graph Condensation, Distribution Matching", "abstract": "This paper introduces Data Centric Graph Condensation (named DCGC), a data-centric and model-agnostic method for condensing a large graph into a smaller one by matching the distribution between two graphs. DCGC defines the distribution of a graph as the trajectories of its node signals (such as node features and node labels) induced by a diffusion process over the geometric structure, which accommodates multi-order structural information. Built upon this, DCGC compresses the topological knowledge of the original graph into the orders-of-magnitude smaller synthetic one by aligning their distributions in input space. Compared with existing methods that stick to particular GNN architectures and require solving complicated optimization, DCGC can be flexibly applied for arbitrary off-the-shelf GNNs and achieve graph condensation with a much faster speed. Apart from the cross-architecture generalization ability and training efficiency, experiments demonstrate that DCGC yields consistently superior performance than existing methods on datasets with varying scales and condensation ratios.", "title_embedding_index": 3273, "title_abs_embedding_index": 3298}, {"title": "Smooth Real-time Rendering via Implicit Nested Neighborhoods", "link_suffix": "/forum?id=mMjSc5fspq", "link": "https://openreview.net/forum?id=mMjSc5fspq", "pdf_link": "https://openreview.net/pdf?id=mMjSc5fspq", "keywords": "Implicit Neural Representations, Neural Signed Distance Functions, Neural Rendering, Real-time Rendering, Surfaces and Attributes", "abstract": "Implicit neural representations (INRs) for surfaces have been mostly used as intermediary representations before triangle mesh extraction. Extracting meshes is not a real-time task and introduces unnecessary discretization to rendering, making it difficult to fully use the smoothness of INRs in applications. Smooth INRs are broadly used for approximating surface \\textit{signed distance functions} (SDFs) through an implicit regularization (Eikonal equation) using their available high-order derivatives. Such property also makes it easier to integrate those INRs in pipelines that explore differentiable properties of the underlying surface. The current real-time state-of-the-art approach uses grid-based data-structures that introduce discretization, resulting in a non-smooth representation.We propose an end-to-end smooth ($C^{\\infty}$) INR framework to represent and render surfaces in real-time using neural SDFs endowed with smooth attributes such as normals and textures. Our approach leverages from a novel localized SDF training based on nested neighborhoods, a multiscale surface representation, and residual training. The framework does not depend on spatial data-structures, nor surface extraction. We show that our representation renders detailed smooth surfaces in real-time while the previous works can only render coarse non-smooth surfaces. We also present applications of our representation, including integration with a pipeline for dynamic surfaces and a way to improve performance of surface extraction via marching cubes.", "title_embedding_index": 3274, "title_abs_embedding_index": 3299}]
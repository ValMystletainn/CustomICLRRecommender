[
    {
        "title": "SigDiffusions: Score-Based Diffusion Models for Time Series via Log-Signature Embeddings",
        "link_suffix": "/forum?id=Y8KK9kjgIK",
        "link": "https://openreview.net/forum?id=Y8KK9kjgIK",
        "pdf_link": "https://openreview.net/pdf?id=Y8KK9kjgIK",
        "keywords": "diffusion models, path signatures, time series",
        "abstract": "Score-based diffusion models have recently emerged as state-of-the-art generative models for a variety of data modalities. Nonetheless, it remains unclear how to adapt these models to generate long multivariate time series. Viewing a time series as the discretization of an underlying continuous process, we introduce SigDiffusion, a novel diffusion model operating on log-signature embeddings of the data. The forward and backward processes gradually perturb and denoise log-signatures preserving their algebraic structure. To recover a signal from its log-signature, we provide new closed-form inversion formulae expressing the coefficients obtained by expanding the signal in a given basis (e.g. Fourier or orthogonal polynomials) as explicit polynomial functions of the log-signature. Finally, we show that combining \\texttt{SigDiffusion} with these inversion formulae results in highly realistic time series generation, competitive with the current state-of-the-art on various datasets of synthetic and real-world examples."
    },
    {
        "title": "Causal Bayesian Optimization with Unknown Causal Graphs",
        "link_suffix": "/forum?id=MVpvyeVeyI",
        "link": "https://openreview.net/forum?id=MVpvyeVeyI",
        "pdf_link": "https://openreview.net/pdf?id=MVpvyeVeyI",
        "keywords": "causality; bayesian optimization; causal graph discovery; optimal intervention design",
        "abstract": "Causal Bayesian Optimization (CBO) is a methodology designed to optimize an outcome variable by leveraging known causal relationships through targeted interventions. Traditional CBO methods require a fully and accurately specified causal graph, which is a limitation in many real-world scenarios where such graphs are unknown. To address this, we propose a new method for the CBO framework that operates without prior knowledge of the causal graph. We demonstrate through theoretical analysis and empirical validation that focusing on the direct causal parents of the target variable is sufficient for optimization. Our method learns a Bayesian posterior over the direct parents of the target variable.  This allows us to optimize the outcome variable while simultaneously learning the causal structure. Our contributions include a derivation of a closed-form posterior distribution for the linear case. In the nonlinear case, we present a Gaussian Process (GP) approximation that still enables CBO in cases where the posterior is not tractable. The proposed method performs competitively with existing benchmarks and scales well to larger graphs, making it a practical tool for real-world applications where causal information is incomplete."
    },
    {
        "title": "Graph Neural Ricci Flow: Evolving Feature from a Curvature Perspective",
        "link_suffix": "/forum?id=7b2JrzdLhA",
        "link": "https://openreview.net/forum?id=7b2JrzdLhA",
        "pdf_link": "https://openreview.net/pdf?id=7b2JrzdLhA",
        "keywords": "Graph neural network, Differential equation, Curvature, Ricci flow",
        "abstract": "Differential equations provide a dynamical perspective for understanding and designing graph neural networks (GNNs). By generalizing the discrete Ricci flow (DRF) to attributed graphs, we can leverage a new paradigm for the evolution of node features with the help of curvature. We show that in the attributed graphs, DRF guarantees a vital property: The curvature of each edge concentrates toward zero over time. This property leads to two interesting consequences: 1) graph Dirichlet energy with bilateral bounds and 2) data-independent curvature decay rate. Based on these theoretical results, we propose the Graph Neural Ricci Flow (GNRF), a novel curvature-aware continuous-depth GNN. Compared to traditional curvature-based graph learning methods, GNRF is not limited to a specific curvature definition. It computes and adjusts time-varying curvature efficiently in linear time. We also empirically illustrate the operating mechanism of GNRF and verify that it performs excellently on diverse datasets."
    },
    {
        "title": "StableSemantics: A Synthetic Language-Vision Dataset of Semantic Representations in Naturalistic Images",
        "link_suffix": "/forum?id=fSB95BWiBQ",
        "link": "https://openreview.net/forum?id=fSB95BWiBQ",
        "pdf_link": "https://openreview.net/pdf?id=fSB95BWiBQ",
        "keywords": "diffusion, interpretation, attention, attribution, semantics, synthetic data, dataset",
        "abstract": "Understanding dense visual semantics remains a fundamental challenge in computer vision, as semantically similar objects can exhibit drastically different visual appearances. Recent advancements in generative text-to-image frameworks have led to models that implicitly capture natural scene statistics. These models learn to model complex relationships between objects, lighting, and other visual factors, enabling the generation of detailed and contextually rich images from text captions. To advance visual semantic understanding and develop more robust and interpretable vision models, we present StableSemantics, a large-scale dataset composed of 224 thousand human-curated prompts, processed natural language captions, over 2 million synthetic images, and 10 million attention maps. The dataset provides fine-grained semantic attributions at the noun-chunk level, leverages human-generated prompts that correspond to visually interesting stable diffusion generations, and provides 10 generations per phrase, with cross-attention maps corresponding to noun chunks for each image. We explore the semantic distribution of generated images, examine the distribution of objects within images, and benchmark captioning and open vocabulary segmentation methods on our data. As the first diffusion dataset to include dense attention attributions, we expect StableSemantics to catalyze advances in visual semantic understanding and provide a foundation for developing more sophisticated and effective visual models."
    },
    {
        "title": "I4VGen: Image as Free Stepping Stone for Text-to-Video Generation",
        "link_suffix": "/forum?id=PKAZzhcIrP",
        "link": "https://openreview.net/forum?id=PKAZzhcIrP",
        "pdf_link": "https://openreview.net/pdf?id=PKAZzhcIrP",
        "keywords": "Text-to-Video, Video Diffusion Models, Video Synthesis",
        "abstract": "Text-to-video generation has trailed behind text-to-image generation in terms of quality and diversity, primarily due to the inherent complexities of spatio-temporal modeling and the limited availability of video-text datasets. Recent text-to-video diffusion models employ the image as an intermediate step, significantly enhancing overall performance but incurring high training costs. In this paper, we present I4VGen, a novel video diffusion inference pipeline to leverage advanced image techniques to enhance pre-trained text-to-video diffusion models, which requires no additional training. Instead of the vanilla text-to-video inference pipeline, I4VGen consists of two stages: anchor image synthesis and anchor image-augmented text-to-video synthesis. Correspondingly, a simple yet effective generation-selection strategy is employed to achieve visually-realistic and semantically-faithful anchor image, and an innovative noise-invariant video score distillation sampling (NI-VSDS) is developed to animate the image to a dynamic video by distilling motion knowledge from video diffusion models, followed by a video regeneration process to refine the video. Extensive experiments show that the proposed method produces videos with higher visual realism and textual fidelity. Furthermore, I4VGen also supports being seamlessly integrated into existing image-to-video diffusion models, thereby improving overall video quality."
    },
    {
        "title": "Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents",
        "link_suffix": "/forum?id=V4y0CpX4hK",
        "link": "https://openreview.net/forum?id=V4y0CpX4hK",
        "pdf_link": "https://openreview.net/pdf?id=V4y0CpX4hK",
        "keywords": "AI agents; Large Language Model; Benchmark; Prompt Injection Attacks; Backdoor Attack; Defenses",
        "abstract": "Although LLM-based agents, powered by Large Language Models (LLMs), can use external tools and memory mechanisms to solve complex real-world tasks, they may also introduce critical security vulnerabilities. However, the existing literature does not comprehensively evaluate attacks and defenses against LLM-based agents. To address this, we introduce Agent Security Bench (ASB), a comprehensive framework designed to formalize, benchmark, and evaluate the attacks and defenses of LLM-based agents, including 10 scenarios (e.g., e-commerce, autonomous driving, finance), 10 agents targeting the scenarios, over 400 tools, 23 different types of attack/defense methods, and 8 evaluation metrics. Based on ASB, we benchmark 10 prompt injection attacks, a memory poisoning attack, a novel Plan-of-Thought backdoor attack, a mixed attack, and 10 corresponding defenses across 13 LLM backbones with nearly 90,000 testing cases in total. Our benchmark results reveal critical vulnerabilities in different stages of agent operation, including system prompt, user prompt handling, tool usage, and memory retrieval, with the highest average attack success rate of 84.30%, but limited effectiveness shown in current defenses, unveiling important works to be done in terms of agent security for the community. Our code can be found athttps://anonymous.4open.science/r/AgentSecurityBench-A757."
    },
    {
        "title": "TabGraphs: A Benchmark and Strong Baselines for Learning on Graphs with Tabular Node Features",
        "link_suffix": "/forum?id=a6XE2GJHjk",
        "link": "https://openreview.net/forum?id=a6XE2GJHjk",
        "pdf_link": "https://openreview.net/pdf?id=a6XE2GJHjk",
        "keywords": "graph machine learning, tabular machine learning, graph neural network, gradient boosting, benchmark",
        "abstract": "Tabular machine learning is an important field for industry and science. In this field, table rows are typically treated as independent data samples, but additional information about the relations between these samples is sometimes available and can be used to improve predictive performance. Such information can be naturally modeled with a graph, hence tabular machine learning may benefit from graph machine learning methods. However, graph machine learning models are typically evaluated on datasets with homogeneous, most often text-based node features, which are very different from heterogeneous mixtures of numerical and categorical features present in tabular datasets. Thus, there is a critical difference between the data used in tabular and graph machine learning studies, which does not allow one to understand how successfully graph models can be transferred to tabular data. To bridge this gap, we propose a new benchmark of diverse graphs with heterogeneous tabular node features and realistic prediction tasks. We use this benchmark to evaluate a vast set of models, including simple methods previously overlooked in the literature. Our experiments show that graph neural networks indeed can often bring gains in predictive performance for tabular data, but standard tabular models can also be adapted to work with graph data by using simple graph-based feature augmentation, which sometimes enables them to compete with and even outperform graph neural models. Based on our empirical study, we provide insights for researchers and practitioners in both tabular and graph machine learning fields."
    },
    {
        "title": "IVCR-200K: A Large-Scale Benchmark for Interactive Video Corpus Retrieval",
        "link_suffix": "/forum?id=Dojny642Dy",
        "link": "https://openreview.net/forum?id=Dojny642Dy",
        "pdf_link": "https://openreview.net/pdf?id=Dojny642Dy",
        "keywords": "Interactive Video Corpus Retrieval Dataset; Cross-Modal Video Retrieval; Multi-Modal Large Language Model",
        "abstract": "In recent years, significant developments have been made in both video retrieval and video moment retrieval tasks, which respectively retrieve complete videos or moments for a given text query. These advancements have greatly improved user satisfaction during the search process. However, previous work has failed to establish meaningful \"interaction\" between the retrieval system and the user, and its one-way retrieval paradigm can no longer fully meet the personalization and dynamics needs of at least 80.8% of users.In this paper, we introduce a more realistic setting, the Interactive Video Corpus Retrieval task (IVCR) that enables multi-turn, conversational, realistic interactions between the user and the retrieval system. To facilitate research on this challenging task, we introduce IVCR-200K, a bilingual, multi-turn, conversational, abstract semantic high-quality dataset that supports video retrieval and even moment retrieval. Furthermore, we propose a comprehensive framework based on multi-modal large language models (MLLMs) to support users' several interaction modes with more explainable solutions. Our extensive experiments demonstrate the effectiveness of our dataset and framework."
    },
    {
        "title": "Calibrating Video Watch-time Predictions with Credible Prototype Alignment",
        "link_suffix": "/forum?id=b7ROBvgNkE",
        "link": "https://openreview.net/forum?id=b7ROBvgNkE",
        "pdf_link": "https://openreview.net/pdf?id=b7ROBvgNkE",
        "keywords": "Prototype learning, optimal transport, recommendation",
        "abstract": "Accurately predicting user watch-time is crucial for enhancing user stickiness and retention in video recommendation systems. Existing watch-time prediction approaches typically involve transformations of watch-time labels for prediction and subsequent reversal, ignoring both the natural distribution properties of label and the \\textit{instance representation confusion} that results in inaccurate predictions. \nIn this paper, we propose ProWTP, a two-stage method combining prototype learning and optimal transport for watch-time regression prediction, suitable for any deep recommendation model. The core idea of ProWTP is to align label distribution with instance representation distribution to calibrate the instance space, thereby improving prediction accuracy. Specifically, we observe that the watch-ratio (the ratio of watch-time to video duration) within the same duration bucket exhibits a multimodal distribution. To facilitate incorporation into models, we use a hierarchical vector quantised variational autoencoder (HVQ-VAE) to convert the continuous label distribution into a high-dimensional discrete distribution, serving as credible prototypes for calibrations. Based on this, ProWTP views the alignment between prototypes and instance representations as a Semi-relaxed Unbalanced Optimal Transport (SUOT) problem, where the marginal constraints of prototypes are relaxed. And the corresponding optimization problem is reformulated as a weighted Lasso problem for solution. Moreover, ProWTP introduces the assignment and compactness losses to encourage instances to cluster closely around their respective prototypes, thereby enhancing the prototype-level distinguishability. Finally, we conducted extensive offline experiments on two industrial datasets, demonstrating our consistent superiority in real-world application."
    },
    {
        "title": "CofCA: A STEP-WISE Counterfactual Multi-hop QA benchmark",
        "link_suffix": "/forum?id=q2DmkZ1wVe",
        "link": "https://openreview.net/forum?id=q2DmkZ1wVe",
        "pdf_link": "https://openreview.net/pdf?id=q2DmkZ1wVe",
        "keywords": "LLM evaluation, Multi-hop QA evaluation",
        "abstract": "While Large Language Models (LLMs) excel in question-answering (QA) tasks, their real reasoning abilities on multiple evidence retrieval and integration on Multi-hop QA tasks remain less explored. Firstly, LLMs sometimes generate answers that rely on internal memory rather than retrieving evidence and reasoning in the given context, which brings concerns about the evaluation quality of real reasoning abilities. Although previous counterfactual QA benchmarks can separate the internal memory of LLMs, they focus solely on final QA performance, which is insufficient for reporting LLMs' real reasoning abilities. Because LLMs are expected to engage in intricate reasoning processes that involve evidence retrieval and answering a series of sub-questions from given passages. Moreover, current factual Multi-hop QA (MHQA) benchmarks are annotated on open-source corpora such as Wikipedia, although useful for multi-step reasoning evaluation, they show limitations due to the potential data contamination in LLMs' pre-training stage. To address these issues, we introduce the Step-wise and Counterfactual benchmark (CofCA), a novel evaluation benchmark consisting of factual data and counterfactual data that reveals LLMs' real reasoning abilities on multi-step reasoning and reasoning chain evaluation. Our experimental results reveal a significant performance gap of several LLMs between Wikipedia-based factual data and counterfactual data, deeming data contamination issues in existing benchmarks. Moreover, we observe that LLMs usually bypass the correct reasoning chain, showing an inflated multi-step reasoning performance. We believe that our CofCA benchmark will enhance and facilitate the evaluations of trustworthy LLMs."
    },
    {
        "title": "Differentiable and Learnable Wireless Simulation with Geometric Transformers",
        "link_suffix": "/forum?id=9TClCDZXeh",
        "link": "https://openreview.net/forum?id=9TClCDZXeh",
        "pdf_link": "https://openreview.net/pdf?id=9TClCDZXeh",
        "keywords": "inverse problems, learning to simulate, wireless channel modeling, geometric deep learning, equivariance, inverse problems, electromagnetic signals, diffusion models",
        "abstract": "Modelling the propagation of electromagnetic wireless signals is critical for designing modern communication systems. Wireless ray tracing simulators model signal propagation based on the 3D geometry and other scene parameters, but their accuracy is fundamentally limited by underlying modelling assumptions and correctness of parameters. In this work, we introduce Wi-GATr, a fully-learnable neural simulation surrogate designed to predict the channel observations based on scene primitives (e. g., surface mesh, antenna position and orientation). Recognizing the inherently geometric nature of these primitives, Wi-GATr leverages an equivariant Geometric Algebra Transformer that operates on a tokenizer specifically tailored for wireless simulation. We evaluate our approach on a range of tasks (i. e., signal strength and delay spread prediction, receiver localization, and geometry reconstruction) and find that Wi-GATr is accurate, fast, sample-efficient, and robust to symmetry-induced transformations. Remarkably, we find our results also translate well to the real world: Wi-GATr demonstrates more than 35% lower error than hybrid techniques, and 70% lower error than a calibrated wireless tracer."
    },
    {
        "title": "ASROB: Measuring Automatic Speech Recognition from One Book",
        "link_suffix": "/forum?id=sjvz40tazX",
        "link": "https://openreview.net/forum?id=sjvz40tazX",
        "pdf_link": "https://openreview.net/pdf?id=sjvz40tazX",
        "keywords": "large language models, benchmarks, translation, speech recognition, in-context learning, long context, Kalamang, multilinguality",
        "abstract": "The MTOB (Machine Translation from One Book) benchmark measures the ability of large language models (LLMs) to \"learn to translate between English and Kalamang\u2014a language with less than 200 speakers and therefore virtually no presence on the web\u2014using several hundred pages of field linguistics reference materials,\" predominantly with long in-context learning. However, many endangered languages like Kalamang are primarily oral, so supporting only text is insufficient: speech must be a first-class citizen for applications to be useful to actual communities. In this paper, we present ASROB (Automatic Speech Recognition from One Book), an extension of MTOB to speech tasks\u2014Kalamang speech-to-text recognition (ASR) and Kalamang speech to English text translation (S2TT)\u2014using an additional 15 hours of transcribed and translated Kalamang speech recordings. Our baselines measure the long mixed-modal (text+audio) in-context learning abilities of the Gemini 1.5 family. 1.5 Pro reaches 24.6% CER on ASR and 6.53 BLEU on S2TT, already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources, but there is still substantial headroom for models to improve beyond this. We hope that ASROB will help evaluate extreme mixed-modal capabilities in LLMs and increase focus on supporting endangered languages in their spoken form."
    },
    {
        "title": "Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning",
        "link_suffix": "/forum?id=QOfWubPhdS",
        "link": "https://openreview.net/forum?id=QOfWubPhdS",
        "pdf_link": "https://openreview.net/pdf?id=QOfWubPhdS",
        "keywords": "Reinforcement Learning, Reward Shaping, Thompson Sampling, Beta Distribution, Self-Adaptive Exploration-Exploitation Trade-off, Success Rate",
        "abstract": "Reward shaping is a technique in reinforcement learning that addresses the sparse-reward problem by providing more frequent and informative rewards. We introduce a self-adaptive and highly efficient reward shaping mechanism that incorporates success rates derived from historical experiences as shaped rewards. The success rates are sampled from Beta distributions, which dynamically evolve from uncertain to reliable values as data accumulates. Initially, the shaped rewards exhibit more randomness to encourage exploration, while over time, the increasing certainty enhances exploitation, naturally balancing exploration and exploitation. Our approach employs Kernel Density Estimation (KDE) combined with Random Fourier Features (RFF) to derive the Beta distributions, providing a computationally efficient, non-parametric, and learning-free solution for high-dimensional continuous state spaces. Our method is validated on various tasks with extremely sparse rewards, demonstrating notable improvements in sample efficiency and convergence stability over relevant baselines."
    },
    {
        "title": "Your Agent Can Defend Itself against Backdoor Attacks",
        "link_suffix": "/forum?id=pBugl1EIkm",
        "link": "https://openreview.net/forum?id=pBugl1EIkm",
        "pdf_link": "https://openreview.net/pdf?id=pBugl1EIkm",
        "keywords": "LLM Agent, Backdoor Attack, Backdoor Defense",
        "abstract": "Intelligent agents powered by large language models (LLMs) have gained surging popularity due to their versatile and customizable capabilities across diverse environments. However, recent studies also reveal their critical vulnerability: LLM agents are highly susceptible to backdoor attacks during training or fine-tuning. Such compromised agents can subsequently be manipulated to execute malicious operations when presented with specific triggers in their inputs or environments. To address this pressing risk, we present ReAgent, a novel defense against a range of backdoor attacks on LLM-based agents. Intuitively, backdoor attacks often result in inconsistencies among the user's instruction, the agent's planning, and its execution. Drawing on this insight, ReAgent employs a two-level approach to detect potential backdoors. At the execution level, ReAgent verifies consistency between the agent's thoughts and actions; at the planning level, ReAgent leverages the agent's capability to reconstruct the instruction based on\nits thought trajectory, checking for consistency between the reconstructed instruction and the user's instruction. Extensive evaluation demonstrates ReAgent's effectiveness against various backdoor attacks across diverse tasks. For instance, ReAgent reduces the attack success rate by up to 90% in database operation tasks, outperforming existing defenses by large margins. This work reveals the potential of utilizing compromised agents themselves to mitigate backdoor risks."
    },
    {
        "title": "Few-shot In-context Preference Learning using Large Language Models",
        "link_suffix": "/forum?id=w9tS6NRmxX",
        "link": "https://openreview.net/forum?id=w9tS6NRmxX",
        "pdf_link": "https://openreview.net/pdf?id=w9tS6NRmxX",
        "keywords": "Large Language Models, Preference-based RL, Reinforcement Learning from Human Feedback, Reward Design",
        "abstract": "Designing reward functions is a core component of reinforcement learning but can be challenging for truly complex behavior. Reinforcement Learning from Human Feedback (RLHF) has been used to alleviate this challenge by replacing a hand-coded reward function with a reward function learned from preferences. However, it can be exceedingly inefficient to learn these rewards as they are often learned tabula rasa. We investigate whether Large Language Models (LLMs) can reduce this query inefficiency by converting an iterative series of human preferences into code representing the rewards. We propose In-Context Preference Learning (ICPL), a method that uses the grounding of an LLM to accelerate learning reward functions from preferences. ICPL takes the environment context and task description, synthesizes a set of reward functions, and then repeatedly updates the reward functions using human feedback over videos of the resultant policies over a small number of trials. Using synthetic preferences, we demonstrate that ICPL is orders of magnitude more efficient than RLHF and is even competitive with methods that use ground-truth reward functions instead of preferences. Finally, we perform a series of human preference-learning trials and observe that ICPL extends beyond synthetic settings and can work effectively with humans-in-the-loop."
    },
    {
        "title": "Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements",
        "link_suffix": "/forum?id=ERce2rgMQC",
        "link": "https://openreview.net/forum?id=ERce2rgMQC",
        "pdf_link": "https://openreview.net/pdf?id=ERce2rgMQC",
        "keywords": "large language models, safety alignment, pluralistic alignment",
        "abstract": "The current paradigm for safety alignment of large language models (LLMs) follows aone-size-fits-allapproach: the model refuses to interact with any content deemed unsafe by the model provider. This approach lacks flexibility in the face of varying social norms across cultures and regions. In addition, users may have diverse safety needs, making a model withstaticsafety standards too restrictive to be useful, as well as too costly to be re-aligned.We proposeControllable Safety Alignment(CoSA), a framework designed to adapt models to diverse safety requirements without re-training. Instead of aligning a fixed model, we align models to followsafety configs\u2014free-form natural language descriptions of the desired safety behaviors\u2014that are provided as part of the system prompt. To adjust model safety behavior, authorized users only need to modify such safety configs at inference time. To enable that, we propose CoSAlign, a data-centric method for aligning LLMs to easily adapt to diverse safety configs. Furthermore, we devise a novel controllability evaluation protocol that considers both helpfulness and configured safety, summarizing them into CoSA-Score, and construct CoSApien, ahuman-authoredbenchmark that consists of real-world LLM use cases with diverse safety requirements and corresponding evaluation prompts.We show that CoSAlign leads to substantial gains of controllability over strong baselines including in-context alignment. Our framework encourages better representation and adaptation to pluralistic human values in LLMs, and thereby increasing their practicality."
    },
    {
        "title": "YouTube-SL-25: A Large-Scale, Open-Domain Multilingual Sign Language Parallel Corpus",
        "link_suffix": "/forum?id=nFVsK3QLgs",
        "link": "https://openreview.net/forum?id=nFVsK3QLgs",
        "pdf_link": "https://openreview.net/pdf?id=nFVsK3QLgs",
        "keywords": "sign language translation, sign language, multilinguality, data curation, data auditing",
        "abstract": "Even for better-studied sign languages like American Sign Language (ASL), data is the bottleneck for machine learning research. The situation is worse yet for the many other sign languages used by Deaf/Hard of Hearing communities around the world. In this paper, we present YouTube-SL-25, a large-scale, open-domain multilingual corpus of sign language videos with seemingly well-aligned captions drawn from YouTube. With >3000 hours of videos across >25 sign languages, YouTube-SL-25 is a) >3x the size of YouTube-ASL, b) the largest parallel sign language dataset to date, and c) the first or largest parallel dataset for many of its component languages. We provide baselines for sign-to-text tasks using a unified multilingual multitask model based on T5 and report scores on benchmarks across 4 sign languages. The results demonstrate that multilingual transfer benefits both higher- and lower-resource sign languages within YouTube-SL-25."
    },
    {
        "title": "A Proxy Matrix-based Framework for Contextual Stochastic Optimization under Confounding Effect",
        "link_suffix": "/forum?id=AWegTKIJs9",
        "link": "https://openreview.net/forum?id=AWegTKIJs9",
        "pdf_link": "https://openreview.net/pdf?id=AWegTKIJs9",
        "keywords": "Contextual optimization, confounding effect, confounders, proxy matrix, semi-parametric decision framework",
        "abstract": "Data-driven decision-making in real-world scenarios often faces the challenge of endogeneity between decisions and outcomes, introducing confounding effects. While existing literature typically assumes unconfoundedness, this is often unrealistic. In practice, decision-making relies on high-dimensional, heterogeneous-type proxy features of confounders, leading to suboptimal decisions due to limited predictive power for uncertainty. We propose a novel semi-parametric decision framework to mitigate confounding effects.\nOur approach combines exponential family matrix completion to infer the confounders matrix from proxy features, with non-parametric prescriptive methods for decision-making based on the estimated confounders. We derive a non-convergent regret bound for data-driven decisions under confounding effects and demonstrate how our framework improves this bound. Experiments on both synthetic and real datasets validate our method's efficacy in reducing confounding effects across various proxy dimensions.  We also show that our approach consistently outperforms benchmarks in practical applications."
    },
    {
        "title": "Training-free Guidance in Multi-modal Generative Flow for Inverse Molecular Design",
        "link_suffix": "/forum?id=GK5ni7tIHp",
        "link": "https://openreview.net/forum?id=GK5ni7tIHp",
        "pdf_link": "https://openreview.net/pdf?id=GK5ni7tIHp",
        "keywords": "flow matching, molecular design, training-free guidance",
        "abstract": "Given an unconditional generative model and a predictor for a target property (e.g., a classifier), the goal of training-free guidance is to generate samples with desirable target properties without additional training. As a highly efficient technique for steering generative models toward flexible outcomes, training-free guidance has gained increasing attention in diffusion models. However, existing methods only handle data in continuous spaces, while many scientific applications involve both continuous and discrete data (referred to as multimodality). Another emerging trend is the growing use of the simple and general flow matching framework in building generative foundation models, where guided generation remains under-explored. To address this, we introduce TFG-Flow, a novel training-free guidance method for multimodal generative flow. TFG-Flow addresses the curse-of-dimensionality while maintaining the property of unbiased sampling in guiding discrete variables. We validate TFG-Flow on four molecular design tasks and show that \\method has great potential in drug design by generating molecules with desired properties."
    },
    {
        "title": "PhiNets: Brain-inspired Non-contrastive Learning Based on Temporal Prediction Hypothesis",
        "link_suffix": "/forum?id=5tjdRyqnSn",
        "link": "https://openreview.net/forum?id=5tjdRyqnSn",
        "pdf_link": "https://openreview.net/pdf?id=5tjdRyqnSn",
        "keywords": "Non contrastive learning, Predictive coding, Eigenvalue dynamics, Temporal prediction hypothesis",
        "abstract": "Predictive coding has been established as a promising neuroscientific theory to describe the mechanism of long-term memory residing in the retina.\n  This theory hypothesises that cortex predicts sensory inputs at various levels of abstraction to minimise prediction errors and forms long-term memory.\n  Inspired by predictive coding, Chen et al. (2024) proposed another theory, temporal prediction hypothesis, to claim that sequence memory residing in hippocampus has emerged through predicting input signals from the past sensory inputs.\n  Specifically, they supposed that the CA3 predictor in hippocampus creates synaptic delay between input signals, which is compensated by the following CA1 predictor.\n  Though recorded neural activities were replicated based on the temporal prediction hypothesis, its validity has not been fully explored.\n  In this work, we aim to explore the temporal prediction hypothesis from the perspective of self-supervised learning (SSL).\n  Specifically, we focus on non-contrastive learning, which generates two augmented views of an input image and predicts one from another.\n  Non-contrastive learning is intimately related to the temporal prediction hypothesis because the synaptic delay is implicitly created by StopGradient.\n  Building upon a popular non-contrastive learner, SimSiam, we propose PhiNet, an extension of SimSiam to have two predictors explicitly corresponding to the CA3 and CA1, respectively.\n  Through studying the PhiNet model, we discover two findings.\n  First, meaningful data representations emerge in PhiNet more stably than in SimSiam.\n  This is initially supported by our learning dynamics analysis: PhiNet is more robust to the representational collapse.\n  Second, PhiNet adapts more quickly to newly incoming patterns in online and continual learning scenarios.\n  For practitioners, we additionally propose an extension called X-PhiNet integrated with a momentum encoder, excelling in continual learning.\n  All in all, our work reveals that the temporal prediction hypothesis is a reasonable model in terms of the robustness and adaptivity."
    },
    {
        "title": "FedCVD: The First Real-World Federated Learning Benchmark on Cardiovascular Disease Data",
        "link_suffix": "/forum?id=g0Doz4IRHU",
        "link": "https://openreview.net/forum?id=g0Doz4IRHU",
        "pdf_link": "https://openreview.net/pdf?id=g0Doz4IRHU",
        "keywords": "Federated Learning, Healthcare Data, Cardiovascular Diseases, Real-world Datasets, Data Heterogeneity",
        "abstract": "Cardiovascular diseases (CVDs) are currently the leading cause of death worldwide, highlighting the critical need for early diagnosis and treatment. Machine learning (ML) methods can help diagnose CVDs early, but their performance relies on access to substantial data with high quality. However, the sensitive nature of healthcare data often restricts individual clinical institutions from sharing data to train sufficiently generalized and unbiased ML models. Federated Learning (FL) is an emerging approach, which offers a promising solution by enabling collaborative model training across multiple participants without compromising the privacy of the individual data owners. However, to the best of our knowledge, there has been limited prior research applying FL to the cardiovascular disease domain. Moreover, existing FL benchmarks and datasets are typically simulated and may fall short of replicating the complexity of natural heterogeneity found in realistic datasets that challenges current FL algorithms. To address these gaps, this paper presents the first real-world FL benchmark for cardiovascular disease detection, named FedCVD. This benchmark comprises two major tasks: electrocardiogram (ECG) classification and echocardiogram (ECHO) segmentation,  based on naturally scattered datasets constructed from the CVD data of seven institutions. Our extensive experiments on these datasets reveal that FL faces new challenges with real-world non-IID and long-tail data."
    },
    {
        "title": "UniCon: Unidirectional Information Flow for Effective Control of Large-Scale Diffusion Models",
        "link_suffix": "/forum?id=uJqKf24HGN",
        "link": "https://openreview.net/forum?id=uJqKf24HGN",
        "pdf_link": "https://openreview.net/pdf?id=uJqKf24HGN",
        "keywords": "Diffusion Models, Lowlevel Vision, Conditional Generation",
        "abstract": "We introduce UniCon, a novel architecture designed to enhance control and efficiency in training adapters for large-scale diffusion models like the Diffusion transformer. Unlike existing methods that rely on bidirectional interaction between the diffusion model and control adapter, UniCon implements a unidirectional flow from the diffusion network to the adapter, allowing the adapter alone to generate the final output. UniCon reduces computational demands by eliminating the need for the diffusion model to compute and store gradients during adapter training. UniCon is free from the constrains of encoder-focused designs and is able to utilize all parameters of the diffusion model, making it highly effective for transformer-based architectures. Our results indicate that UniCon reduces GPU memory usage by one-third and increases training speed by 2.3 times, while all maintaining the same adapter parameter size. Additionally, without requiring extra computational resources, UniCon enables the training of adapters with double the parameter volume of existing ControlNets. In a series of image condition generation tasks, UniCon has demonstrated precise response to control information and excellent generation capabilities. UniCon makes the control of large-scale diffusion models feasible and provides a basis for further scaling up of diffusion models."
    },
    {
        "title": "Revamping Diffusion Guidance for Conditional and Unconditional Generation",
        "link_suffix": "/forum?id=b3CzCCCILJ",
        "link": "https://openreview.net/forum?id=b3CzCCCILJ",
        "pdf_link": "https://openreview.net/pdf?id=b3CzCCCILJ",
        "keywords": "diffusion models, classifier-free guidance",
        "abstract": "Classifier-free guidance (CFG) has become the standard method for enhancing the quality of conditional diffusion models. However, employing CFG requires either training an unconditional model alongside the main diffusion model or modifying the training procedure by periodically inserting a null condition.  There is also no clear extension of CFG to unconditional models. In this paper, we revisit the core principles of CFG and introduce a new method, independent condition guidance (ICG), which provides the benefits of CFG without the need for any special training procedures. Our approach streamlines the training process of conditional diffusion models and can also be applied during inference on any pre-trained conditional model. Additionally, by leveraging the time-step information encoded in all diffusion networks, we propose an extension of CFG, called time-step guidance (TSG), which can be applied toanydiffusion model, including unconditional ones. Our guidance techniques are easy to implement and have the same sampling cost as CFG. Through extensive experiments, we demonstrate that ICG matches the performance of standard CFG across various conditional diffusion models. Moreover, we show that TSG improves generation quality in a manner similar to CFG, without relying on any conditional information."
    },
    {
        "title": "CarbonSense: A Multimodal Dataset and Baseline for Carbon Flux Modelling",
        "link_suffix": "/forum?id=l8zRnvD95l",
        "link": "https://openreview.net/forum?id=l8zRnvD95l",
        "pdf_link": "https://openreview.net/pdf?id=l8zRnvD95l",
        "keywords": "dataset, machine learning, deep learning, multimodal models, climate chage, carbon dynamics, benchmark",
        "abstract": "Terrestrial carbon fluxes provide vital information about our biosphere's health and its capacity to absorb anthropogenic CO$_2$\n emissions. The importance of predicting carbon fluxes has led to the emerging field of data-driven carbon flux modelling (DDCFM), which uses statistical techniques to predict carbon fluxes from biophysical data. However, the field lacks a standardized dataset to promote comparisons between models. To address this gap, we present CarbonSense, the first machine learning-ready dataset for DDCFM. CarbonSense integrates measured carbon fluxes, meteorological predictors, and satellite imagery from 385 locations across the globe, offering comprehensive coverage and facilitating robust model training. Additionally, we provide a baseline model using a current state-of-the-art DDCFM approach and a novel transformer based model. Our experiments illustrate the potential gains that multimodal deep learning techniques can bring to this domain. By providing these resources, we aim to lower the barrier to entry for other deep learning researchers to develop new models and drive new advances in carbon flux modelling."
    },
    {
        "title": "MuHBoost: A Multi-Label Boosting Method For Practical Longitudinal Human Behavior Modeling",
        "link_suffix": "/forum?id=BAelAyADqn",
        "link": "https://openreview.net/forum?id=BAelAyADqn",
        "pdf_link": "https://openreview.net/pdf?id=BAelAyADqn",
        "keywords": "AI for Public Health, large language models, heterogeneous time-series classification, multi-label classification",
        "abstract": "Longitudinal human behavior modeling has received increasing attention over the years due to its widespread applications to patient monitoring, dietary and lifestyle recommendations, and just-in-time intervention for at-risk individuals (e.g., problematic drug users and struggling students), to name a few. Using in-the-moment health data collected via ubiquitous devices (e.g., smartphones and smartwatches), this multidisciplinary field focuses on developing predictive models for certain health or well-being outcomes (e.g., depression and stress) in the short future given the time series of individual behaviors (e.g., resting heart rate, sleep quality, and current feelings). Yet, most existing models on these data, which we refer to as ubiquitous health data, do not achieve adequate accuracy. The latest works that yielded promising results have yet to consider realistic aspects of ubiquitous health data (e.g., containing features of different types and high rate of missing values) and the consumption of various resources (e.g., computing power, time, and cost). Given these two shortcomings, it is dubious whether these studies could translate to realistic settings. In this paper, we propose MuHBoost, a multi-label boosting method for addressing these shortcomings, by leveraging advanced methods in large language model (LLM) prompting and multi-label classification (MLC) to jointly predict multiple health or well-being outcomes. Because LLMs can hallucinate when tasked with answering multiple questions simultaneously, we also develop two variants of MuHBoost that alleviate this issue and thereby enhance its predictive performance. We conduct extensive experiments to evaluate MuHBoost and its variants on 13 health and well-being prediction tasks defined from four realistic ubiquitous health datasets. Our results show that our three developed methods outperform all considered baselines across three standard MLC metrics, demonstrating their effectiveness while ensuring resource efficiency."
    }
]
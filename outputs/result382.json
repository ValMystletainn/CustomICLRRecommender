[{"title": "Neighborhood and Global Perturbations Supported SAM in Federated Learning:  From Local Tweaks To Global Awareness", "link_suffix": "/forum?id=9Q9KXUTjmd", "link": "https://openreview.net/forum?id=9Q9KXUTjmd", "pdf_link": "https://openreview.net/pdf?id=9Q9KXUTjmd", "keywords": "Federatd Learning; Heterogeneous  Data", "abstract": "Federated Learning (FL) can be coordinated under the orchestration of a central server to build a privacy-preserving model without collaborative data exchange.\nHowever, participant data heterogeneity leads to local optima divergence, affecting convergence outcomes. Recent research focused on global sharpness-aware minimization (SAM) and dynamic regularization to enhance consistency between global and local generalization and optimization objectives. Nonetheless, the estimation of global SAM introduces additional computational and memory overhead. At the same time, the local dynamic regularizer cannot capture the global update state due to training isolation.\nThis paper proposes a novel FL algorithm, FedTOGA, designed to consider optimization and generalization objectives while maintaining minimal uplink communication overhead. By linking local perturbations to global updates, global generalization consistency is improved. Additionally, linking the local dynamic regularizer to global updates increases the perception of the global gradient and enhances optimization consistency. Global updates are passively received by clients, reducing overhead.\nWe also propose neighborhood perturbation to approximate local perturbation, analyzing its strengths and working principle. Theoretical analysis shows FedTOGA achieves faster convergence $O(1/T)$ under non-convex functions. Empirical studies demonstrate that FedTOGA outperforms state-of-the-art algorithms, with a 1% accuracy increase and 30% faster convergence, achieving state-of-the-art.", "title_embedding_index": 19050, "title_abs_embedding_index": 19075}, {"title": "A Hypothesis on Black Swan in Unchanging Environments", "link_suffix": "/forum?id=7k4HVhUS9k", "link": "https://openreview.net/forum?id=7k4HVhUS9k", "pdf_link": "https://openreview.net/pdf?id=7k4HVhUS9k", "keywords": "AI Safety, Risk, Reinforcement Learning", "abstract": "Black swan events are statistically rare occurrences that carry extremely high risks. A typical view of defining black swan events is heavily assumed to originate from an unpredictable time-varying environments; however, the community lacks a comprehensive definition of black swan events. To this end, this paper challenges that the standard view is incomplete and claims that high-risk, statistically rare events can also occur in unchanging environments due to human misperception of their value and likelihood, which we call as spatial black swan event. We first carefully categorize black swan events, focusing on spatial black swan events, and mathematically formalize the definition of black swan events. We hope these definitions can pave the way for the development of algorithms to prevent such events by rationally correcting human perception.", "title_embedding_index": 19051, "title_abs_embedding_index": 19076}, {"title": "A Benchmark Study For Limit Order Book (LOB) Models and Time Series Forecasting Models on LOB Data", "link_suffix": "/forum?id=MhD9rLeU31", "link": "https://openreview.net/forum?id=MhD9rLeU31", "pdf_link": "https://openreview.net/pdf?id=MhD9rLeU31", "keywords": "benchmark, time series forecasting, convolution, deep learning, limit order book, mid-price trend prediction, mid-price return forecasting", "abstract": "We present a comprehensive benchmark to evaluate the performance of deep learning models on limit order book (LOB) data. Our work makes four significant contributions: (i) We evaluate existing LOB models on a proprietary futures LOB dataset to examine the transferability of LOB model performance between various assets; (ii) We are the first to benchmark existing LOB models on the mid-price return forecasting (MPRF) task. (iii) We present the first benchmark study to evaluate SOTA time series forecasting models on the MPRF task to bridge the two fields of general-purpose time series forecasting and LOB time series forecasting; and (iv) we propose an architecture of convolutional cross-variate mixing layers (CVML) as an add-on to any deep learning multivariate time series model to significantly enhance MPRF performance on LOB data. Our empirical results highlight the value of our benchmark results on our proprietary futures LOB dataset, demonstrating a performance gap between the commonly used open-source stock LOB dataset and our futures dataset. Furthermore, the results demonstrate that LOB-aware model design is essential for achieving optimal prediction performance on LOB datasets. Most importantly, our results show that our proposed CVML architecture brings about an average improvement of 244.9% to various time series models\u2019 mid-price return forecasting performance.", "title_embedding_index": 19052, "title_abs_embedding_index": 19077}, {"title": "Convex Potential Mirror Langevin Algorithm for Efficient Sampling of Energy-Based Models", "link_suffix": "/forum?id=oiDvwOhvjq", "link": "https://openreview.net/forum?id=oiDvwOhvjq", "pdf_link": "https://openreview.net/pdf?id=oiDvwOhvjq", "keywords": "mirror Langevin dynamics, efficient sampling, energy based models", "abstract": "This paper introduces the Convex Potential Mirror Langevin Algorithm (CPMLA), a novel method designed to optimize sampling efficiency within Energy-Based Models (EBMs). CPMLA employs mirror Langevin dynamics in conjunction with convex potential flow as a dynamic mirror map for sampling in EBMs. By leveraging this dynamic mirror map, CPMLA enables targeted geometric exploration on the data manifold, enhancing the convergence process towards the target distribution. Theoretical analysis proves that CPMLA achieves exponential convergence with vanishing bias under relaxed log-concave conditions, supporting its efficiency and effectiveness in adapting to complex data distributions. Experimental results on established benchmarks like CIFAR-10, SVHN, and CelebA showcase CPMLA's enhanced sampling quality and inference efficiency compared to existing techniques.", "title_embedding_index": 19053, "title_abs_embedding_index": 19078}, {"title": "AR-1-to-3: Single Image to Consistent 3D Object Generation via Next-View Prediction", "link_suffix": "/forum?id=pOcGFvfgjS", "link": "https://openreview.net/forum?id=pOcGFvfgjS", "pdf_link": "https://openreview.net/pdf?id=pOcGFvfgjS", "keywords": "Multi-View Synthesis; Image-to-3D; Autoregressive Generation;", "abstract": "Represented by Zero123 series of works, recent advancements in single-view 3D generation research have shown prominent progress by utilizing pre-trained 2D diffusion generation models. These approaches either generate multiple discrete views of a 3D object from a single-view image and a set of camera poses or produce multiple views simultaneously under specified camera conditions. However,\nit is hard to maintain consistency across different views and camera angles, especially for poses with large differences. In this paper, we introduce AR-1-to-3, a novel paradigm to generate multi-view images according to the input single image with significantly improved consistency in details. We achieve this by designing a novel auto-regressive scheme where novel views are generated based on previous views. The core of our method is first to generate views closer to the input view, which is utilized as contextual information to prompt the generation of farther views. To this end, we propose two image conditioning strategies, termed as Stacked-LE and LSTM-GE, to encode the sequence views. Particularly, Stacked-LE encodes the previously generated views into a stack embedding, which is employed as a local condition to modify the key and value matrices of the self-attention layers for denoising the target views of the current step. Meanwhile, LSTM-GE divides the previously generated views into two groups based on their elevations, whose feature vectors are encoded by two LSTM modules into high-level semantic information for global conditioning. Extensive experiments on the Objaverse dataset show that our method can synthesize more consistent 3D views and produce high-quality 3D assets that closely mirror the given image. Code and pre-trained weights will be made publicly available.", "title_embedding_index": 19054, "title_abs_embedding_index": 19079}, {"title": "CogMath: Evaluating LLMs' Authentic Mathematical Ability from a Cognitive Perspective", "link_suffix": "/forum?id=x1nlO1d1iG", "link": "https://openreview.net/forum?id=x1nlO1d1iG", "pdf_link": "https://openreview.net/pdf?id=x1nlO1d1iG", "keywords": "Mathematical Reasoning, Large Language Models", "abstract": "As large language models (LLMs) exhibit potential in solving complex mathematical tasks, increasing attention has been directed toward constructing benchmarks to evaluate their mathematical capabilities. However, existing benchmarks are either limited to specific task types (e.g., long-text problem understanding) or rely solely on a coarse measure of answer accuracy, making them insufficient for assessing a model's authentic mathematical proficiency. In this paper, we propose CogMath, which provides a comprehensive assessment of LLMs' mathematical abilities based on human cognitive processes. Specifically, inspired by cognitive theories, CogMath formalizes the reasoning process into 3 stages that align with human cognition: problem comprehension, problem solving, and solution summarization, and encompasses 9 fine-grained evaluation dimensions from perspectives such as numerical calculation, knowledge, and counterfactuals. In each dimension, to carry out a scientific evaluation, we develop an ``Inquiry-Judge-Reference'' multi-agent system, where the Inquiry agent generates inquiries that assess LLMs' mastery from this dimension, the Judge agent ensures the inquiry quality, and the Reference agent provides correct responses for comparison with the LLMs' actual performances. A LLM is considered to truly master a problem only when excelling in all inquiries from the 9 dimensions. In experiments, we evaluate 7 mainstream LLMs by applying CogMath to three benchmarks, which cover the full K-12 mathematical curriculum. The results reveal that the authentic mathematical capabilities of current LLMs are overestimated by 30-40%. Moreover, we locate their strengths and weaknesses across different stages/dimensions, offering constructive insights to further enhance their reasoning abilities.", "title_embedding_index": 19055, "title_abs_embedding_index": 19080}, {"title": "Local Patterns Generalize Better for Novel Anomalies", "link_suffix": "/forum?id=4ua4wyAQLm", "link": "https://openreview.net/forum?id=4ua4wyAQLm", "pdf_link": "https://openreview.net/pdf?id=4ua4wyAQLm", "keywords": "Global Patterns; Local Patterns; Image-Text Alignment Module; Cross-Modality Attention; Temporal Sentence Generation; State Machine Module", "abstract": "Video anomaly detection (VAD) aims at identifying novel actions or events which are unseen during training. Existing mainstream VAD techniques typically focus on the global patterns of events but struggle to generalize to novel samples. In this paper, we propose a framework that identifies the local patterns which generalize to novel samples and models the dynamics of local patterns. The capability of extracting spatial local patterns is achieved through a two-stage process involving  image-text alignment and cross-modality attention. Generalizable representations are built by focusing on text-informative features that filter out unnecessary visual data variances. To enhance spatial local patterns with temporal clues, we introduce a State Machine Module (SMM) that combines tokens from different moments to improve sentence generation within cross-modality attention. Furthermore, temporal motion estimation complements spatial local patterns to detect anomalies characterized by novel spatial distributions or distinctive dynamics. Extensive experiments on popular benchmark datasets demonstrate the achievement of state-of-the-art performance. Code is available athttps://anonymous.4open.science/r/Local-Patterns-Generalize-Better-1E30/.", "title_embedding_index": 19056, "title_abs_embedding_index": 19081}, {"title": "Lexical Diversity-aware Relevance Assessment for Retrieval-Augmented Generation", "link_suffix": "/forum?id=omv3VfVIQt", "link": "https://openreview.net/forum?id=omv3VfVIQt", "pdf_link": "https://openreview.net/pdf?id=omv3VfVIQt", "keywords": "language model, Retrieval-Augmented Generation, Lexical Diversity, Relevance Assessment", "abstract": "Despite their extensive applications, large language models trained on vast historical datasets still struggle with hallucination issues, particularly when addressing open-ended, factual, and commonsense questions. In contrast, Retrieval-Augmented Generation (RAG) methods have proven effective in enhancing large language models' responses to such inquiries, making them a focal point of research.\nHowever, previous RAG approaches overlook the lexical diversity of queries, hindering their ability to achieve a granular relevance assessment between queries and retrieved documents, resulting in suboptimal performance.  In this paper, we introduce a Lexical Diversity-aware RAG (DRAG) model, comprising a Diversity-sensitive Relevance Analyzer (DRA) and a Contrastive Relevance Calibration Module (CRC). Specifically, DRA decouples and assesses the relevance of different query components (words, phrases) based on their levels of lexical diversity, ensuring precise and comprehensive document retrieval. According to the DRA assessment, CRC further emphasizes the pertinent knowledge of the retrieved relevant documents through contrastively eliminating the adverse effects of irrelevant contents. By integrating DRA and CRC, the proposed method effectively retrieves relevant documents and leverages their pertinent knowledge to refine the original results and generate meaningful outcomes. Extensive experiments on widely-used benchmarks demonstrate the efficacy of our approach, yielding a 12.5% accuracy improvement on HotpotQA.", "title_embedding_index": 19057, "title_abs_embedding_index": 19082}, {"title": "Learning to Plan Before Answering: Self-Teaching LLMs to Learn Abstract Plans for Problem Solving", "link_suffix": "/forum?id=KmmNb7631I", "link": "https://openreview.net/forum?id=KmmNb7631I", "pdf_link": "https://openreview.net/pdf?id=KmmNb7631I", "keywords": "LLM, self-training, high-level abstraction, self-reflection, meta learning, anticipatory plans", "abstract": "In the field of large language model (LLM) post-training, the effectiveness of utilizing synthetic data generated by the LLM itself has been well-presented. However, a key question remains unaddressed: what essential information should such self-generated data encapsulate? Existing approaches only produce step-by-step problem solutions, and fail to capture the abstract meta-knowledge necessary for generalization across similar problems. Drawing insights from cognitive science, where humans employ high-level abstraction to simplify complex problems before delving into specifics, we introduce a novel self-training algorithm: LEarning to Plan before Answering (LEPA). LEPA trains the LLM to formulate anticipatory plans, which serve as abstract meta-knowledge for problem-solving, before engaging with the intricacies of problems. This approach not only outlines the solution generation path but also shields the LLM from the distraction of irrelevant details. During data generation, LEPA first crafts an anticipatory plan based on the problem, and then generates a solution that aligns with both the plan and the problem. LEPA refines the plan through self-reflection, aiming to acquire plans that are instrumental in yielding correct solutions. During model optimization, the LLM is trained to predict both the refined plans and the corresponding solutions. By efficiently extracting and utilizing the anticipatory plans, LEPA demonstrates remarkable superiority over conventional algorithms on various challenging natural language reasoning benchmarks.", "title_embedding_index": 19058, "title_abs_embedding_index": 19083}, {"title": "VaQuitA: Enhancing Alignment in LLM-Assisted Zero-Shot Video Understanding", "link_suffix": "/forum?id=LSq9ef8ANs", "link": "https://openreview.net/forum?id=LSq9ef8ANs", "pdf_link": "https://openreview.net/pdf?id=LSq9ef8ANs", "keywords": "Video Understanding, Large Language Model, Alignment", "abstract": "Recent advancements in language-model-based video understanding have been progressing at a remarkable pace, spurred by the introduction of Large Language Models (LLMs). However, the focus of prior research has been predominantly on devising a projection layer that maps video features to tokens, an approach that is both rudimentary and inefficient. In our study, we introduce a cutting-edge framework, VaQuitA, designed to refine the synergy between video and textual information. At the data level, instead of sampling frames uniformly, we implement a sampling method guided by CLIP-score rankings, which enables a more aligned selection of frames with the given question. At the feature level, we integrate a trainable Video Perceiver alongside a Visual-Query Transformer (abbreviated as VQ-Former), which bolsters the interplay between the input question and the video features. We also discover that incorporating a simple prompt, ``Please be critical.'', into the LLM input can substantially enhance its video comprehension capabilities. Our experimental results indicate that VaQuitA consistently sets a new benchmark for zero-shot video question-answering tasks and is adept at producing high-quality, multi-turn video dialogues with users. The code will be released.", "title_embedding_index": 19059, "title_abs_embedding_index": 19084}, {"title": "Minixax Optimal Two-Stage Algorithm For Moment Estimation Under Covariate Shift", "link_suffix": "/forum?id=oc4yw7zX9T", "link": "https://openreview.net/forum?id=oc4yw7zX9T", "pdf_link": "https://openreview.net/pdf?id=oc4yw7zX9T", "keywords": "covariate shift, minimax optimal, two-stage algorithm, double robustness", "abstract": "Covariate shift occurs when the distribution of input features differs between the training and testing phases.  In covariate shift, estimating an unknown function's moment is a classical problem that remains under-explored, despite its common occurrence in real-world scenarios. In this paper, we investigate the minimax lower bound of the problem when the source and target distributions are known. To achieve the minimax optimal bound (up to a logarithmic factor), we propose a two-stage algorithm. Specifically, it first trains an optimal estimator for the function under the source distribution, and then uses a likelihood ratio reweighting procedure to calibrate the moment estimator. In practice, the source and target distributions are typically unknown, and estimating the likelihood ratio may be unstable. To solve this problem, we propose a truncated version of the estimator that ensures double robustness and provide the corresponding upper bound. Extensive numerical studies on synthetic examples confirm our theoretical findings and further illustrate the effectiveness of our proposed method.", "title_embedding_index": 19060, "title_abs_embedding_index": 19085}, {"title": "The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs", "link_suffix": "/forum?id=vJ0axKTh7t", "link": "https://openreview.net/forum?id=vJ0axKTh7t", "pdf_link": "https://openreview.net/pdf?id=vJ0axKTh7t", "keywords": "Multi-modal LLM, Visual Reasoning, Association", "abstract": "Multi-modal Large Language Models (MLLMs) have exhibited impressive capability. However, recently many deficiencies of MLLMs have been found compared to human intelligence, $\\textit{e.g.}$, hallucination. To drive the MLLMs study, the community dedicated efforts to building larger benchmarks with complex tasks. In this paper, we propose benchmarking an essential but usually overlooked intelligence: $\\textbf{association}$, a human's basic capability to link observation and prior practice memory. To comprehensively investigate MLLM's performance on the association, we formulate the association task and devise a standard benchmark based on adjective and verb semantic concepts. Instead of costly data annotation and curation, we propose a convenient $\\textbf{annotation-free}$ construction method transforming the general dataset for our association tasks. Simultaneously, we devise a rigorous data refinement process to eliminate confusion in the raw dataset. Building on this database, we establish three levels of association tasks: single-step, synchronous, and asynchronous associations. Moreover, we conduct a comprehensive investigation into the MLLMs' zero-shot association capabilities, addressing multiple dimensions, including three distinct memory strategies, both open-source and closed-source MLLMs, cutting-edge Mixture-of-Experts (MoE) models, and the involvement of human experts. Our systematic investigation shows that current open-source MLLMs consistently exhibit poor capability in our association tasks, even the currently state-of-the-art GPT-4V(vision) also has a significant gap compared to humans. We believe our benchmark would pave the way for future MLLM studies.  $\\textit{Our data and code will be made publicly available.}$", "title_embedding_index": 19061, "title_abs_embedding_index": 19086}, {"title": "SolidMark: Evaluating Image Memorization in Generative Models", "link_suffix": "/forum?id=F61IzZl5jw", "link": "https://openreview.net/forum?id=F61IzZl5jw", "pdf_link": "https://openreview.net/pdf?id=F61IzZl5jw", "keywords": "Memorization, Diffusion Models, Metrics", "abstract": "Recent works have shown that diffusion models are able to memorize training images and emit them at generation time. However, the metrics used to evaluate memorization and its mitigation techniques suffer from dataset-dependent biases and struggle to detect whether a given specific image has been memorized or not.This paper begins with a comprehensive exploration of issues surrounding memorization metrics in diffusion models. Then, to mitigate these issues, we introduce SolidMark, a novel evaluation method that provides a per-image memorization score. We then re-evaluate existing memorization mitigation techniques and show that SolidMark is capable of evaluating fine-grained pixel-level memorization. Finally, we release a text-to-image model pretrained from scratch based on SolidMark to facilitate further research for understanding memorization phenomena in generative models.", "title_embedding_index": 19062, "title_abs_embedding_index": 19087}, {"title": "Poly-Autoregressive Modeling for Interacting Entities", "link_suffix": "/forum?id=MI0UiWeqOl", "link": "https://openreview.net/forum?id=MI0UiWeqOl", "pdf_link": "https://openreview.net/pdf?id=MI0UiWeqOl", "keywords": "autoregressive prediction; multi-agent interaction", "abstract": "We present a simple framework that predicts an agent's future behavior by considering the effects that other interacting agents and entities have on them. We propose to model behavior as a sequence of tokens, each representing the state of an agent at a specific timestep. The core of our approach centers around Poly-Autoregressive models, which predict the future behavior of an agent during interaction by considering the agent's past state history and the state of other agents in the scene. In this paper, we develop the mechanics of Poly-Autoregressive (PAR) modeling and show that this framework applies without any modification to an extensive range of prediction problems that, on the surface, appear as entirely different scenarios, such as human action prediction in social situations, trajectory prediction for autonomous vehicles, and object pose prediction during hand-object interaction.", "title_embedding_index": 19063, "title_abs_embedding_index": 19088}, {"title": "A new perspective on applying mesoscience to explore the model generalizability", "link_suffix": "/forum?id=lZRRfupxYn", "link": "https://openreview.net/forum?id=lZRRfupxYn", "pdf_link": "https://openreview.net/pdf?id=lZRRfupxYn", "keywords": "Mesoscience, Compromise in competition, Machine learning, Generalizability", "abstract": "The black-box nature is one of bottlenecks constraining machine learning (ML) models, especially, neural networks, from playing a more important role in the field of engineering. The decision-making process of the model often lacks transparency and is difficult to interpret, which limits its use in the high-risk domain. Thus, explaining the generalizability of ML models is a crucial topic in the field of AI. However, there has been no unified understanding of this issue. This work attempts to introduce the concept of compromise in competition (CIC) in mesoscience into the explanation of the generalizability of ML models. In this work, a scale decomposition method is proposed from the perspective of training samples, and the CIC between memorizing and forgetting, refined as dominant mechanisms, is studied. Empirical studies on computer vision (CV) and natural language processing (NLP) datasets demonstrate that the CIC between memorizing and forgetting significantly influences model generalizability. Additionally, dropout, L2 regularization, etc., aimed at mitigating overfitting, can be uniformly reinterpreted through the CIC between memorizing and forgetting. Collectively, this work proposes a new perspective to explain the generalizability of ML models, in order to provide inherent support for further applications of ML in the field of engineering.", "title_embedding_index": 19064, "title_abs_embedding_index": 19089}, {"title": "Boosting Semi-Supervised 2D Human Pose Estimation by Revisiting Data Augmentation and Consistency Training", "link_suffix": "/forum?id=5zGuFj0y9V", "link": "https://openreview.net/forum?id=5zGuFj0y9V", "pdf_link": "https://openreview.net/pdf?id=5zGuFj0y9V", "keywords": "semi-supervised learning, human pose estimation, data augmentation, consistency training", "abstract": "The 2D human pose estimation (HPE) is a basic visual problem. However, its supervised learning requires massive keypoint labels, which is labor-intensive to collect. Thus, we aim at boosting a pose estimator by excavating extra unlabeled data with semi-supervised learning (SSL). Most previous SSHPE methods are consistency-based and strive to maintain consistent outputs for differently augmented inputs. Under this genre, we find that SSHPE can be boosted from two cores: advanced data augmentations and concise consistency training ways. Specifically, for the first core, we discover the synergistic effects of existing augmentations, and reveal novel paradigms for conveniently producing new superior HPE-oriented augmentations which can more effectively add noise on unlabeled samples. We can therefore establish paired easy-hard augmentations with larger difficulty gaps. For the second core, we propose to repeatedly augment unlabeled images with diverse hard augmentations, and generate multi-path predictions sequentially for optimizing multi-losses in a single network. This simple and compact design is interpretable, and easily benefits from newly found augmentations. Comparing to state-of-the-art SSL approaches, our method brings substantial improvements on public datasets. Code will be released for academic use.", "title_embedding_index": 19065, "title_abs_embedding_index": 19090}, {"title": "Failures to Find Transferable Image Jailbreaks Between Vision-Language Models", "link_suffix": "/forum?id=wvFnqVVUhN", "link": "https://openreview.net/forum?id=wvFnqVVUhN", "pdf_link": "https://openreview.net/pdf?id=wvFnqVVUhN", "keywords": "adversarial robustness, jailbreaks, vision-language model, multimodal, adversarial attack, image jailbreak, safety, trustworthy, robustness", "abstract": "The integration of new modalities into frontier AI systems increases the possibility such systems can be adversarially manipulated in undesirable ways. In this work, we focus on a popular class of vision-language models (VLMs) that generate text conditioned on visual and textual inputs. We conducted a large-scale empirical study to assess the transferability of gradient-based universal image \"jailbreaks\" using a diverse set of over 40 open-parameter VLMs, including 18 new VLMs that we publicly release. We find that transferable gradient-based image jailbreaks are extremely difficult to obtain. When an image jailbreak is optimized against a single VLM or against an ensemble of VLMs, the image successfully jailbreaks the attacked VLM(s), but exhibits little-to-no transfer to any other VLMs; transfer is not affected by whether the attacked and target VLMs possess matching vision backbones or language models, whether the language model underwent instruction-following and/or safety-alignment training, or other factors. Only two settings display partial transfer: between identically-pretrained and identically-initialized VLMs with slightly different VLM training data, and between different training checkpoints of a single VLM. Leveraging these results, we demonstrate that transfer can be significantly improved against a specific target VLM by attacking larger ensembles of ``highly-similar\" VLMs. These results stand in stark contrast to existing evidence of universal and transferable text jailbreaks against language models and transferable adversarial attacks against image classifiers, suggesting that VLMs may be more robust to gradient-based transfer attacks.", "title_embedding_index": 19066, "title_abs_embedding_index": 19091}, {"title": "A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language", "link_suffix": "/forum?id=0pLCDJVVRD", "link": "https://openreview.net/forum?id=0pLCDJVVRD", "pdf_link": "https://openreview.net/pdf?id=0pLCDJVVRD", "keywords": "Emergence, Percolation, Formal languages", "abstract": "Increase in data, size, or compute can lead to sudden learning of specific capabilities by a neural network---a phenomenon often called \"emergence\". Beyond scientific understanding, establishing the causal factors underlying such emergent capabilities is crucial to enable risk regulation frameworks for AI. In this work, we seek inspiration from study of emergent properties in other fields and propose a phenomenological definition for the concept in the context of neural networks. Our definition implicates the acquisition of general structures underlying the data-generating process as a cause of sudden performance growth for specific, narrower tasks. We empirically investigate this definition by proposing an experimental system grounded in a context-sensitive formal language and find that Transformers trained to perform tasks on top of strings from this language indeed exhibit emergent capabilities. Specifically, we show that once the language's underlying grammar and context-sensitivity inducing structures are learned by the model, performance on narrower tasks suddenly begins to improve. We then analogize our network's learning dynamics with the process of percolation on a bipartite graph, establishing a formal phase transition model that predicts the shift in the point of emergence observed in our experiments when changing the data structure. Overall, our experimental and theoretical frameworks yield a step towards better defining, characterizing, and predicting emergence in neural networks.", "title_embedding_index": 19067, "title_abs_embedding_index": 19092}, {"title": "Sequential Stochastic Combinatorial Optimization Using Hierarchal Reinforcement Learning", "link_suffix": "/forum?id=AloCXPpq54", "link": "https://openreview.net/forum?id=AloCXPpq54", "pdf_link": "https://openreview.net/pdf?id=AloCXPpq54", "keywords": "Sequential Stochastic Combinatorial Optimization, Hierarchal Reinforcement Learning, Graph", "abstract": "Reinforcement learning (RL) has emerged as a promising tool for combinatorial optimization (CO) problems due to its ability to learn fast, effective, and generalizable solutions. \nNonetheless, existing works mostly focus on one-shot deterministic CO, while sequential stochastic CO (SSCO) has rarely been studied despite its broad applications such as adaptive influence maximization (IM) and infectious disease intervention. \nIn this paper, we study the SSCO problem where we first decide the budget (e.g., number of seed nodes in adaptive IM) allocation for all time steps, and then select a set of nodes for each time step. The few existing studies on SSCO simplify the problems by assuming a uniformly distributed budget allocation over the time horizon, yielding suboptimal solutions. We propose a generic hierarchical RL (HRL) framework called wake-sleep option (WS-option), a two-layer option-based framework that simultaneously decides adaptive budget allocation on the higher layer and node selection on the lower layer. \nWS-option starts with a coherent formulation of the two-layer Markov decision processes (MDPs), capturing the interdependencies between the two layers of decisions. Building on this, WS-option employs several innovative designs to balance the model's training stability and computational efficiency, preventing the vicious cyclic interference issue between the two layers. Empirical results show that WS-option exhibits significantly improved effectiveness and generalizability compared to traditional methods. Moreover, the learned model can be generalized to larger graphs, which significantly reduces the overhead of computational resources.", "title_embedding_index": 19068, "title_abs_embedding_index": 19093}, {"title": "CR2PQ: Continuous Relative Rotary Positional Query for Dense Visual Representation Learning", "link_suffix": "/forum?id=3l6PwssLNY", "link": "https://openreview.net/forum?id=3l6PwssLNY", "pdf_link": "https://openreview.net/pdf?id=3l6PwssLNY", "keywords": "Self-supervised learning, Distillation", "abstract": "Dense visual contrastive learning (DRL) shows promise for learning localized information in dense prediction tasks, but struggles with establishing pixel/patch correspondence across different views (cross-contrasting). Existing methods primarily rely on self-contrasting the same view with variations, limiting input variance and hindering downstream performance. This paper delves into the mechanisms of self-contrasting and cross-contrasting, identifying the crux of the issue: transforming discrete positional embeddings to continuous representations. To address the correspondence problem, we propose a Continuous Relative Rotary Positional Query ({\\mname}), enabling patch-level representation learning. Our extensive experiments on standard datasets demonstrate state-of-the-art (SOTA) results. Compared to the previous SOTA method (PQCL), our approach achieves significant improvements on COCO: with 300 epochs of pretraining, {\\mname} obtains \\textbf{3.4%} mAP$^{bb}$ and \\textbf{2.1%} mAP$^{mk}$ improvements for detection and segmentation tasks, respectively. Furthermore, {\\mname} exhibits faster convergence, achieving \\textbf{10.4%} mAP$^{bb}$ and \\textbf{7.9%} mAP$^{mk}$ improvements over SOTA with just 40 epochs of pretraining.", "title_embedding_index": 19069, "title_abs_embedding_index": 19094}, {"title": "Towards zero shot multivariate time series anomaly detection - A Realistic Evaluation", "link_suffix": "/forum?id=rCaA79Obsj", "link": "https://openreview.net/forum?id=rCaA79Obsj", "pdf_link": "https://openreview.net/pdf?id=rCaA79Obsj", "keywords": "multidimensional time series anomaly detection, zero shot, model recovery, model conformance", "abstract": "A long line of multivariate timeseries anomaly detection (MTAD) approaches use performance enhancement techniques that are not feasible in practical scenarios. In specific, a) point adjustment technique is employed which uses ground truth to forcefully convert false negatives to true positives and inflates precision to unrealistic proportions, and b) significant data leakage is introduced where anomaly score threshold is determined using the test data and test labels. In this paper, we show the real world performance of existing MTAD techniques when point adjustment and threshold learning on test data is disabled. Moreover, we show that anomalies introduced in real world benchmark datasets result in significant distribution shift between normal and anomalous data, and when point adjustment and threshold learning are used even untrained deterministic methods can perform on par or even beat baseline techniques. We then introduce six synthetic benchmark examples derived from real world systems, where anomalous data and normal data have statistically insignificant distribution shift. We propose, sparse model identification enhanced anomaly detection (SPIE-AD), a model recovery and conformance based zero shot MTAD approach that outperforms state of art MTAD techniques on three real world benchmark datasets without using point adjustment and threshold learning on test data. We evaluate state-of-art MTAD and SPIE-AD on the novel synthetic benchmarks. SPIE-AD outperforms state-of-art MTAD techniques on both standard and novel benchmarks.", "title_embedding_index": 19070, "title_abs_embedding_index": 19095}, {"title": "Rethinking Visual Counterfactual Explanations Through Region Constraint", "link_suffix": "/forum?id=gqeXXrIMr0", "link": "https://openreview.net/forum?id=gqeXXrIMr0", "pdf_link": "https://openreview.net/pdf?id=gqeXXrIMr0", "keywords": "visual, counterfactual, explanations, diffusion, generative, explainable", "abstract": "Visual counterfactual explanations (VCEs) have recently gained immense popularity as a tool for clarifying the decision-making process of image classifiers. This trend is largely motivated by what these explanations promise to deliver -- indicate semantically meaningful factors that change the classifier's decision. However, we argue that current state-of-the-art approaches lack a crucial component -- the region constraint -- whose absence prevents from drawing explicit conclusions, and may even lead to faulty reasoning due to phenomenons like confirmation bias. To address the issue of previous methods, which modify images in a very entangled and widely dispersed manner, we propose region-constrained VCEs (RVCEs), which assume that only a predefined image region can be modified to influence the model's prediction. To effectively sample from this subclass of VCEs, we propose Region-Constrained Counterfactual Schr\u00f6dinger Bridge (RCSB), an adaptation of a tractable subclass of Schr\u00f6dinger Bridges to the problem of conditional inpainting, where the conditioning signal originates from the classifier of interest. In addition to setting a new state-of-the-art by a large margin, we extend RCSB to allow for exact counterfactual reasoning, where the predefined region contains only the factor of interest, and incorporating the user to actively interact with the RVCE by predefining the regions manually.", "title_embedding_index": 19071, "title_abs_embedding_index": 19096}, {"title": "Binary Hyperbolic Embeddings", "link_suffix": "/forum?id=KmdwGYbMv0", "link": "https://openreview.net/forum?id=KmdwGYbMv0", "pdf_link": "https://openreview.net/pdf?id=KmdwGYbMv0", "keywords": "Hyperbolic, Binary", "abstract": "As datasets grow in size, vector-based search becomes increasingly challenging in terms of both storage and computational efficiency. Traditional solutions such as quantization techniques involve trade-offs between retrieval speed and accuracy, while hashing methods often require further optimization for binarization. In this work, we propose leveraging the compact nature of hyperbolic space for efficient search. Specifically, we introduce Binary Hyperbolic Embeddings, which transform complex hyperbolic similarity calculations into binary operations. We prove that these binary hyperbolic embeddings are retrieval equivalent to their real-valued counterparts, ensuring no loss in retrieval quality. This approach improves the memory efficiency and running speed of the FAISS library while maintaining performance comparable to full-precision Euclidean embeddings. Furthermore, our method is orthogonal to product quantization, allowing seamless integration with it to further enhance retrieval systems. We achieve significant improvements in storage efficiency, with the potential for scaling to larger datasets. The code is provided in the supplementary materials.", "title_embedding_index": 19072, "title_abs_embedding_index": 19097}, {"title": "Multi-Concept Editing Using Task Arithmetic", "link_suffix": "/forum?id=UHDSE86qiG", "link": "https://openreview.net/forum?id=UHDSE86qiG", "pdf_link": "https://openreview.net/pdf?id=UHDSE86qiG", "keywords": "Task Vectors", "abstract": "Model owners often wish to introduce new capabilities into their trained models or remove undesired ones. Task Vectors (TVs) present a promising new approach to editing models after training, allowing simple and controllable addition of new capabilities to the model and the removal of undesired ones. But what happens when the model owner wants to change multiple capabilities?In this work, we study the interactions of task vectors in a multi-edit setting for image classifiers and diffusion models. We start by quantifying the overall model degradation induced by applying many specific TVs simultaneously. \nWe show that the overall model performance degrades rapidly as the quantity of TV edits increases.\nFinally, we explore different ways to mitigate this degradation and present an adaptive method to select the most relevant TVs to apply to a diffusion model during inference. Our technique achieves a 94.6% ROC AUC in identifying the correct TV, enabling the effective integration of multiple TV edits while significantly mitigating quality degradation.", "title_embedding_index": 19073, "title_abs_embedding_index": 19098}, {"title": "Hidden in the Noise: Two-Stage Robust Watermarking for Images", "link_suffix": "/forum?id=ll2nz6qwRG", "link": "https://openreview.net/forum?id=ll2nz6qwRG", "pdf_link": "https://openreview.net/pdf?id=ll2nz6qwRG", "keywords": "Watermarking", "abstract": "As the quality of image generators continues to improve, deepfakes become a topic of considerable societal debate. Image watermarking allows responsible model owners to detect and label their AI-generated content, which can mitigate the harm. Yet, current state-of-the-art methods in image watermarking remain vulnerable to forgery and removal attacks.In this work, we first demonstrate that the initial noise used in the diffusion process can itself be a distortion-free watermarking method for images.\nHowever, detecting the watermark requires comparing the latent noise of an image to all previously used initial noises. Additionally, the initial noise may still be susceptible to some removal attacks.\nTo mitigate these issues, we propose a two-stage watermarking framework for efficient detection. During generation, we augment the initial noise with generated Fourier patterns to embed information about the group of initial noises we used. For detection, we (i) retrieve the relevant group of noises, and (ii) search within the given group for an initial noise that might match our image. This watermarking approach achieves state-of-the-art robustness to forgery and removal against a large battery of attacks.\nThe project code is anonymously available athttps://github.com/anonymousiclr2025submission/Hidden-in-the-Noise.", "title_embedding_index": 19074, "title_abs_embedding_index": 19099}]
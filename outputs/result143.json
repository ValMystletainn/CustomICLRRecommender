[{"title": "Can Watermarked LLMs be Identified by Users via Crafted Prompts?", "link_suffix": "/forum?id=ujpAYpFDEA", "link": "https://openreview.net/forum?id=ujpAYpFDEA", "pdf_link": "https://openreview.net/pdf?id=ujpAYpFDEA", "keywords": "Large Language Models, Watermark, Identification", "abstract": "Text watermarking for Large Language Models (LLMs) has made significant progress in detecting LLM outputs and preventing misuse. Current watermarking techniques offer high detectability, minimal impact on text quality, and robustness to text editing. \n    However, current researches lack investigation into the imperceptibility of watermarking techniques in LLM services.\n    This is crucial as LLM providers may not want to disclose the presence of watermarks in real-world scenarios, as it could reduce user willingness to use the service and make watermarks more vulnerable to attacks. This work is the first to investigate the imperceptibility of watermarked LLMs. We design an identification algorithm called Water-Probe that detects watermarks through well-designed prompts to the LLM. Our key motivation is that current watermarked LLMs expose consistent biases under the same watermark key, resulting in similar differences across prompts under different watermark keys. Experiments show that almost all mainstream watermarking algorithms are easily identified with our well-designed prompts, \n    while Water-Probe demonstrates a minimal false positive rate for non-watermarked LLMs. \n    Finally, we propose that the key to enhancing the imperceptibility of watermarked LLMs is to increase the randomness of watermark key selection. Based on this, we introduce the Water-Bag strategy, which significantly improves watermark imperceptibility by merging multiple watermark keys.", "title_embedding_index": 7100, "title_abs_embedding_index": 7125}, {"title": "Bayesian WeakS-to-Strong from Text Classification to Generation", "link_suffix": "/forum?id=pHe4P1IVnb", "link": "https://openreview.net/forum?id=pHe4P1IVnb", "pdf_link": "https://openreview.net/pdf?id=pHe4P1IVnb", "keywords": "weaks-to-strong, bayesian, generation, per token", "abstract": "Advances in large language models raise the question of how alignment techniques will adapt as models become increasingly complex and humans will only be able to supervise them weakly. Weak-to-Strong mimics such a scenario where weak model supervision attempts to harness the full capabilities of a much stronger model. This work extends Weak-to-Strong to WeakS-to-Strong by exploring an ensemble of weak models which simulate the variability in human opinions. Confidence scores are estimated using a Bayesian approach to guide the WeakS-to-Strong generalization. Furthermore, we extend the application of WeakS-to-Strong from text classification tasks to text generation tasks where more advanced strategies are investigated for supervision. Moreover, direct preference optimization is applied to advance the student model's preference learning, beyond the basic learning framework of teacher forcing. Results demonstrate the effectiveness of the proposed approach for the reliability of a strong student model, showing potential for superalignment.", "title_embedding_index": 7101, "title_abs_embedding_index": 7126}, {"title": "FacLens: Transferable Probe for Foreseeing Non-Factuality in Large Language Models", "link_suffix": "/forum?id=0QkVAxJ5iZ", "link": "https://openreview.net/forum?id=0QkVAxJ5iZ", "pdf_link": "https://openreview.net/pdf?id=0QkVAxJ5iZ", "keywords": "Large language models, hidden question representation, non-factuality predictor, transferability", "abstract": "Despite advancements in large language models (LLMs), non-factual responses remain prevalent. Unlike extensive studies on post-hoc detection of such responses, this work studies non-factuality prediction (NFP), aiming to predict whether an LLM will generate a non-factual response to a question before the generation process. Previous efforts on NFP have demonstrated LLMs' awareness of their internal knowledge, but they still face challenges in efficiency and transferability. In this work, we propose a lightweight NFP model named Factuality Lens (FacLens), which effectively probes hidden representations of questions for the NFP task. Besides, we discover that hidden question representations sourced from different LLMs exhibit similar NFP patterns, which enables the transferability of FacLens across LLMs to reduce development costs. Extensive experiments highlight FacLens\u2019s superiority in both effectiveness and efficiency.", "title_embedding_index": 7102, "title_abs_embedding_index": 7127}, {"title": "Automated Knowledge Concept Annotation and Question Representation Learning for Knowledge Tracing", "link_suffix": "/forum?id=M4fhjfGAsZ", "link": "https://openreview.net/forum?id=M4fhjfGAsZ", "pdf_link": "https://openreview.net/pdf?id=M4fhjfGAsZ", "keywords": "knowledge tracing, time series prediction, knowledge concept, KC annotation, representation learning, contrastive learning, large language models", "abstract": "Knowledge tracing (KT) is a popular approach for modeling students' learning progress over time, which can enable more personalized and adaptive learning. However, existing KT approaches face two major limitations: (1) they rely heavily on expert-defined knowledge concepts (KCs) in questions, which is time-consuming and prone to errors; and (2) KT methods tend to overlook the semantics of both questions and the given KCs. In this work, we address these challenges and present KCQRL, a framework for automated knowledge concept annotation and question representation learning that  can improve the effectiveness of any existing KT model. First, we propose an automated KC annotation process using large language models (LLMs), which generates question solutions and then annotates KCs in each solution step of the questions. Second, we introduce a contrastive learning approach to generate semantically rich embeddings for questions and solution steps, aligning them with their associated KCs via a tailored false negative elimination approach. These embeddings can be readily integrated into existing KT models, replacing their randomly initialized embeddings. We demonstrate the effectiveness of KCQRL across 15 KT algorithms on two large real-world Math learning datasets, where we achieve consistent performance improvements.", "title_embedding_index": 7103, "title_abs_embedding_index": 7128}, {"title": "YouCLIP: Advancing Multilingual Cross-Modal Learning with Efficient Training.", "link_suffix": "/forum?id=P7s4WYF1rf", "link": "https://openreview.net/forum?id=P7s4WYF1rf", "pdf_link": "https://openreview.net/pdf?id=P7s4WYF1rf", "keywords": "CLIP; Vision-Language Pre-training; Non-English CLIP", "abstract": "Since the advent of vision-language pretraining, the CLIP model has become a foundational model for many downstream tasks. However, most of the advanced CLIP models available today are trained primarily on English, making them poorly suited for other languages. This limits accessibility for countries where other languages are dominant. Given that training CLIP models requires vast amounts of GPU resources and data, which most countries lack due to the absence of companies on the scale of Google or OpenAI, this paper proposes an efficient and straightforward three-stage fine-tuning method, which allows for the conversion of the most powerful English CLIP model into models for other languages. \nIn these three stages of training, the first stage focuses on aligning the embedding layer, followed by token fusion in the second stage, and finally contrastive learning fine-tuning in the third stage.\nMeanwhile, to improve data quality, we propose a translation filtering model to filter the data.\nIn this work, we target Chinese as the language of interest and name the resulting model YouCLIP, which is currently the most powerful Chinese CLIP model, significantly outperforming previous models across all Chinese benchmarks. For example, YouCLIP improves the text-to-image Recall@1 score on the COCO-CN dataset from 63.4 to 73.1. Additionally, YouCLIP retains strong English capabilities, achieving a Top-1 accuracy of 76.9 on ImageNet. Despite these impressive results, YouCLIP requires the least amount of training resources compared to other Chinese CLIP models. All models and code for YouCLIP will be open-sourced.", "title_embedding_index": 7104, "title_abs_embedding_index": 7129}, {"title": "Efficient Newton-type Federated Learning with Non-IID Data", "link_suffix": "/forum?id=uaGNerHa1J", "link": "https://openreview.net/forum?id=uaGNerHa1J", "pdf_link": "https://openreview.net/pdf?id=uaGNerHa1J", "keywords": "Federated learning, Newton-type optimization, Generalization analysis, Integral operator theory", "abstract": "The mainstream federated learning algorithms only communicate the first-order information across the local devices, i.e., FedAvg and FedProx. However, only using first-order information, these methods are often inefficient and the impact of heterogeneous data is yet not precisely understood. This paper proposes an efficient federated Newton method (FedNewton), by sharing both first-order and second-order knowledge over heterogeneous data. In general kernel ridge regression setting, we derive the generalization bounds for FedNewton and obtain the minimax-optimal learning rates. For the first time, our results analytically quantify the impact of the number of local examples, the data heterogeneity and the model heterogeneity. Moreover, as long as the local sample size is not too small and data heterogeneity is moderate, the federated error in FedNewton decreases exponentially in terms of iterations. Extensive experimental results further validate our theoretical findings and illustrate the advantages of FedNewton over the first-order methods.", "title_embedding_index": 7105, "title_abs_embedding_index": 7130}, {"title": "Variational Learned Priors for Intrinsically Motivated Reinforcement Learning", "link_suffix": "/forum?id=fMRq7sPP1y", "link": "https://openreview.net/forum?id=fMRq7sPP1y", "pdf_link": "https://openreview.net/pdf?id=fMRq7sPP1y", "keywords": "reinforcement, learning, intrinsic, motivation, exploration, curiosity", "abstract": "Efficient exploration is a fundamental challenge in reinforcement learning, especially in environments with sparse rewards. Intrinsic motivation can improve exploration efficiency by rewarding agents for encountering novel states. In this work, we propose a method called Variation Learned Priors for intrinsic motivation that estimates state novelty through variational state encoding. Specifically, novelty is measured using the Kullback-Leibler divergence between a Variational Autoencoder's learned prior and posterior distributions. When tested across various domains, our approach improves the latent space quality of the Variational Autoencoder, leading to increased exploration efficiency and better task performance for the reinforcement learning agent.", "title_embedding_index": 7106, "title_abs_embedding_index": 7131}, {"title": "Interaction Based Gaussian Weighting Clustering for Federated Learning", "link_suffix": "/forum?id=JF8ovQyueq", "link": "https://openreview.net/forum?id=JF8ovQyueq", "pdf_link": "https://openreview.net/pdf?id=JF8ovQyueq", "keywords": "Federated Learning, Clustered Federated Learning, Personalized Federated Learning", "abstract": "Federated learning emerged as a decentralized paradigm to train models while securing privacy. However, conventional FL faces data heterogeneity and class imbalance challenges, affecting model performance. In response to these issues, Personalized FL has been developed as an innovative methodology that relies on fine-tuning the distinct local models based on individual training datasets. In this work, we propose a novel PFL method, FedGW (Federated Gaussian Weighting), which groups clients based on their data distribution, allowing training of a more robust and personalized model on the identified clusters. FedGW identifies homogeneous clusters by transforming individual empirical losses to model client interactions with a Gaussian reward mechanism. Additionally, we introduce a new clustering metric for FL to evaluate cluster cohesion with respect to the individual class distribution. Our experiments on benchmark datasets show that FedGW outperforms existing FL algorithms in cluster quality and classification accuracy, validating the efficacy of our approach.", "title_embedding_index": 7107, "title_abs_embedding_index": 7132}, {"title": "Polyrating: A Cost-Effective and Bias-Aware Rating System for LLM Evaluation", "link_suffix": "/forum?id=URPwT55i6O", "link": "https://openreview.net/forum?id=URPwT55i6O", "pdf_link": "https://openreview.net/pdf?id=URPwT55i6O", "keywords": "large language models, model evaluation, rating", "abstract": "Rating-based human evaluation has become an essential tool to accurately evaluate the impressive performance of large language models (LLMs). However, current rating systems suffer from several important limitations: first, they fail to account for biases that significantly influence evaluation results, second, they require large and expensive preference datasets to obtain accurate ratings, and third, they do not facilitate meaningful comparisons of model ratings across different tasks. To address these issues, we introduce Polyrating, an expressive and flexible rating system based on maximum a posteriori estimation that enables a more nuanced and thorough analysis of model performance at lower costs. Polyrating can detect and quantify biases affecting human preferences, ensuring fairer model comparisons. Further, Polyrating can reduce the cost of human evaluations by up to $41$% for new models and up to $77$% for new tasks by leveraging existing benchmark scores. Lastly, Polyrating enables direct comparisons of ratings across different tasks, providing a comprehensive understanding of an LLMs' strengths, weaknesses, and relative performance across different applications.", "title_embedding_index": 7108, "title_abs_embedding_index": 7133}, {"title": "A Semantic Data Augmentation driven Nested Adapter for Video Moment Retrieval", "link_suffix": "/forum?id=8Ds99sdp3U", "link": "https://openreview.net/forum?id=8Ds99sdp3U", "pdf_link": "https://openreview.net/pdf?id=8Ds99sdp3U", "keywords": "Moment Retrieval, Highlight Detection, Adapter, Data Augmentation", "abstract": "Existing transformer-based video-moment retrieval models achieve sub-optimal\nperformance when using the pretrain-finetuning learning paradigm \u2013 a pretrained\nmultimodal encoder is finetuned using the target training data. While current work\nhas explored different model architectures and training paradigms to explore this\nproblem, the problem of data dilemma has been under addressed. Specifically,\nthere exists high diversity of how semantic is captured in textual query and the\ntraining dataset only consist of limited moment-query pairs for the highly diverse moments. This work addresses this problem with a novel nested adaptor\nand a LLM-driven semantic data generation pipeline. First, a LLM-driven data\naugmentation generates queries that are semantically similar to the ground truth,\nwhich enrich the semantic boundary captured by textual query. We empirically\nanalyze the effectiveness of data augmentation, and proposed a simple yet effective quality measure to retain high quality samples. Second, we propose a novel\nnested adapter that utilises both augmented queries and human annotated queries\nfor model coarse-tuning and fine-tuning, respectively. By combining semantic\nperturbation with domain adaptation, our approach addresses the variability in\nvideo content while capturing nuanced features more effectively. Experimental\nresults on various baseline models show the efficacy of our proposed approach.", "title_embedding_index": 7109, "title_abs_embedding_index": 7134}, {"title": "The impact of allocation strategies in subset learning on the expressive power of neural networks", "link_suffix": "/forum?id=upoxXRRTQ2", "link": "https://openreview.net/forum?id=upoxXRRTQ2", "pdf_link": "https://openreview.net/pdf?id=upoxXRRTQ2", "keywords": "subset learning, theoretical neuroscience, expressive power, neural networks, recurrent neural network", "abstract": "In traditional machine learning, models are defined by a set of parameters, which are optimized to perform specific tasks. In neural networks, these parameters correspond to the synaptic weights. However, in reality, it is often infeasible to control or update all weights, particularly in biological systems like the brain, where evidence suggests that only a subset of synaptic weights are modified during learning. Motivated by these insights, we theoretically investigate how different allocations of a fixed number of learnable weights influence the capacity of neural networks. Using a teacher-student setup, we introduce a benchmark to quantify the expressivity associated with each allocation. We establish conditions under which allocations havemaximal' orminimal' expressive power in linear recurrent neural networks and linear multi-layer feedforward networks. For suboptimal allocations, we propose heuristic principles to estimate their expressivity. These principles extend to shallow ReLU networks as well. Finally, we validate our theoretical findings with empirical experiments. Our results emphasize the critical role of strategically distributing learnable weights across the network, showing that a more widespread allocation generally enhances the network\u2019s expressive power.", "title_embedding_index": 7110, "title_abs_embedding_index": 7135}, {"title": "Escaping the Big Data Paradigm in Self-Supervised Representation Learning", "link_suffix": "/forum?id=6cHUucnYOk", "link": "https://openreview.net/forum?id=6cHUucnYOk", "pdf_link": "https://openreview.net/pdf?id=6cHUucnYOk", "keywords": "Representation Learning, self-supervised learning, data efficiency, computer vision, SCOTT, MIM-JEPA, Joint-Embedding Predictive Architecture, Masked Image Modeling", "abstract": "The reliance on large-scale datasets and extensive computational resources has become a significant barrier to advancing representation learning from images, particularly in domains where data is scarce or expensive to obtain. In this paper, we address the critical question: Can we escape the big data paradigm in self-supervised representation learning from images? We introduce SCOTT (Sparse Convolutional Tokenizer for Transformers), a simple tokenization architecture that injects convolutional inductive biases into Vision Transformers (ViTs), enhancing their efficacy in small-scale data regimens while remaining compatible with Masked Image Modeling (MIM) tasks. Alongside, we propose MIM-JEPA, a Joint-Embedding Predictive Architecture within a MIM framework, operating in latent representation space to capture more semantic features. Our approach enables ViTs to be trained from scratch on datasets orders of magnitude smaller than traditionally required --without relying on massive external datasets for pretraining. We validate our method on three small-size, high-resoultion, fine-grained datasets: Oxford Flowers-102, Oxford IIIT Pets-37, and ImageNet-100. Despite the challenges of limited data and high intra-class similarity, our frozen SCOTT models pretrained with MIM-JEPA significantly outperform fully supervised methods and achieve competitive results with state-of-the-art approaches that rely on large-scale pretraining, complex image augmentations and bigger model sizes. By demonstrating that robust off-the-shelf representations can be learned with limited data, compute, and model sizes, our work paves the way for computer applications in resource constrained environments such as medical imaging or robotics. Our findings challenge the prevailing notion that vast amounts of data are indispensable for effective representation learning, offering a new pathway toward more accessible and inclusive advancements in the field.", "title_embedding_index": 7111, "title_abs_embedding_index": 7136}, {"title": "ROMA: Regularization for Out-of-distribution Detection with Masked Autoencoders", "link_suffix": "/forum?id=kBVPD2kJMy", "link": "https://openreview.net/forum?id=kBVPD2kJMy", "pdf_link": "https://openreview.net/pdf?id=kBVPD2kJMy", "keywords": "out-of-distribution detection, masked autoencoders, regularization, masked image modeling", "abstract": "Existing out-of-distribution (OOD) detection methods without outlier exposure learn effective in-distribution (ID) representations distinguishable for OOD samples, which have shown promising performance on many OOD detection tasks. However, we find a performance degradation in some challenging OOD detection, where pre-trained networks tend to perform worse during the fine-tuning process, exhibiting the over-fitting of ID representations. Motivated by this observation, we propose a critical task of hidden OOD detection, wherein ID representations provide limited or even counterproductive assistance in identifying hidden OOD data. To address this issue, we introduce a novel Regularization framework for OOD detection with Masked Autoencoders (ROMA), which utilizes the masked image modeling task to regularize the network. With distribution-agnostic auxiliary data exposure, ROMA notably surpasses previous OOD detection methods in hidden OOD detection. Moreover, the robustness of ROMA is further evidenced by its state-of-the-art performance on benchmarks for other challenging OOD detection tasks.", "title_embedding_index": 7112, "title_abs_embedding_index": 7137}, {"title": "Perceived speech decoding and neurophysiological knowledge mining with explainable AI and non-invasive  brain activity recordings", "link_suffix": "/forum?id=hfRb6yC0W0", "link": "https://openreview.net/forum?id=hfRb6yC0W0", "pdf_link": "https://openreview.net/pdf?id=hfRb6yC0W0", "keywords": "MEG, Speech decoding, explainable AI, cortical mechanisms of speech processing", "abstract": "Explainable artificial intelligence (XAI) is a branch of AI directed at the development of machine learning (ML) solutions that can be comprehended by the human users. Here we use an interpretable and domain-grounded machine learning architecture applied to non-invasive magnetoencephalographic (MEG) data of subjects performing a speech listening task and discover neurophsyologically plausible spatial-temporal neuronal representations  of latent sources identified through self-supervised network training process. Achieving high decoding accuracy in the downstream task our solution bridges the gap between high performance and big data-based AI and the classical neuroimaging research and represents a novel knowledge mining platform where the decoding rule can be interpreted  using the accepted in electrophysiology terms and concepts which is likely to advance neuroscientific research.", "title_embedding_index": 7113, "title_abs_embedding_index": 7138}, {"title": "Temporal Heterogeneous Graph Generation with Privacy, Utility, and Efficiency", "link_suffix": "/forum?id=tj5xJInWty", "link": "https://openreview.net/forum?id=tj5xJInWty", "pdf_link": "https://openreview.net/pdf?id=tj5xJInWty", "keywords": "Temporal Graph, Heterogeneous Graph, Graph Generation", "abstract": "Nowadays, Temporal Heterogeneous Graphs attract much research and industrial attention for building the next-generation Relational Deep Learning Models and Applications, due to their informative structures and features. While providing timely and precise services like personalized recommendations and question answering, this rich information also introduces extra exposure risk for each node in the graph, because the distinctive local topology, the abundant heterogeneous features, and the time dimension of the graph data are more prone to exposing sensitive information and narrow down the scope of victim candidates, which calls for well-defined protection techniques on graphs. To this end, we propose aTemporalHeterogeneous Graph Generator balancingPrivacy,Utility, and Efficiency, namedTHePUff. More specifically, we first propose a differential privacy algorithm to perturb the input temporal heterogeneous graph for protecting privacy, and then utilize both the perturbed graph and the original one in a generative adversarial setting for THePUff to learn and generate privacy-guaranteed and utility-preserved graph data in an efficient manner. We further propose 6 new metrics in the temporal setting to measure heterogeneous graph utility and privacy. Finally, based on temporal heterogeneous graph datasets with up to 1 million nodes and 20 million edges, the experiments show that THePUff generates utilizable temporal heterogeneous graphs with privacy protected, compared with state-of-the-art baselines.", "title_embedding_index": 7114, "title_abs_embedding_index": 7139}, {"title": "WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning", "link_suffix": "/forum?id=oVKEAFjEqv", "link": "https://openreview.net/forum?id=oVKEAFjEqv", "pdf_link": "https://openreview.net/pdf?id=oVKEAFjEqv", "keywords": "Web Agent, LLM Agent, Curriculum RL Learning, Online Learning", "abstract": "Large language models (LLMs) have shown remarkable potential as autonomous agents, particularly in web-based tasks. \nHowever, existing LLM web agents face significant limitations: high-performing agents rely on expensive proprietary LLM APIs, while open LLMs lack the necessary decision-making capabilities. \nThis paper introduces WebRL, a novel self-evolving online curriculum reinforcement learning framework designed to train high-performance web agents using open LLMs. \nOur approach addresses key challenges in this domain, including the scarcity of training tasks, sparse feedback signals, and policy distribution drift in online learning. \nWebRL incorporates a self-evolving curriculum that generates new tasks from unsuccessful attempts, a robust outcome-supervised reward model (ORM), and adaptive reinforcement learning strategies to ensure consistent improvement. \nWe apply WebRL to transform Llama-3.1 models into proficient web agents, achieving remarkable results on the WebArena-Lite benchmark. \nOur Llama-3.1-8B agent improves from an initial 4.8% success rate to 42.4%, while the Llama-3.1-70B agent achieves a 47.3% success rate across five diverse websites. \nThese results surpass the performance of GPT-4-Turbo (17.6%) by over 160% relatively and significantly outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM, 18.2%). \nOur findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents, paving the way for more accessible and powerful autonomous web interaction systems.", "title_embedding_index": 7115, "title_abs_embedding_index": 7140}, {"title": "Survival Analysis via Density Estimation", "link_suffix": "/forum?id=XgYPzNtz0s", "link": "https://openreview.net/forum?id=XgYPzNtz0s", "pdf_link": "https://openreview.net/pdf?id=XgYPzNtz0s", "keywords": "survival analysis, censored regression, competing risks, dependent censoring", "abstract": "This paper introduces an algorithm that reinterprets survival analysis through the lens of density estimation, addressing the challenge of censored inputs inherent to survival data. Recognizing that many survival analysis methodologies are extensions of foundational density estimation models, our approach leverages this intrinsic relationship. By conceptualizing survival analysis as a form of density estimation, our algorithm postprocesses the density estimation outputs to derive survival functions. This framework allows for the application of any density estimation model to effectively estimate survival functions, thereby broadening the toolkit available for survival analysis and enhancing the flexibility and applicability of existing density estimation techniques in this domain. The proposed algorithm not only bridges the methodological gap between density estimation and survival analysis but also offers a versatile and robust approach for handling censored survival data.", "title_embedding_index": 7116, "title_abs_embedding_index": 7141}, {"title": "Surgical, Cheap, and Flexible: Mitigating False Refusal in Language Models via Single Vector Ablation", "link_suffix": "/forum?id=SCBn8MCLwc", "link": "https://openreview.net/forum?id=SCBn8MCLwc", "pdf_link": "https://openreview.net/pdf?id=SCBn8MCLwc", "keywords": "LLM Safety, Exaggerated Safety, Representation Editing", "abstract": "Training a language model to be both helpful and harmless requires careful calibration of refusal behaviours: Models should refuse to follow malicious instructions or give harmful advice (e.g. \u201chow do I kill someone?\u201d), but they should not refuse safe requests, even if they superficially resemble unsafe ones (e.g. \u201chow do I kill a Python process?\u201d). Avoiding such false refusal, as prior work has shown, is challenging even for highly-capable language models. In this paper, we propose a simple and surgical method for mitigating false refusal in language models via single vector ablation. For a given model, we extract a false refusal vector and show that ablating this vector reduces false refusal rate without negatively impacting model safety and general model capabilities. We also show that our approach can be used for fine-grained calibration of model safety. Our approach is training-free and model-agnostic, making it useful for mitigating the problem of false refusal in current and future language models.", "title_embedding_index": 7117, "title_abs_embedding_index": 7142}, {"title": "Adaptive Methods through the Lens of SDEs: Theoretical Insights on the Role of Noise", "link_suffix": "/forum?id=ww3CLRhF1v", "link": "https://openreview.net/forum?id=ww3CLRhF1v", "pdf_link": "https://openreview.net/pdf?id=ww3CLRhF1v", "keywords": "Stochastic Differential Equations, Stochastic Optimization, Adaptive Methods", "abstract": "Despite the vast empirical evidence supporting the efficacy of adaptive optimization methods in deep learning, their theoretical understanding is far from complete. This work introduces novel SDEs for commonly used adaptive optimizers: SignSGD, RMSprop(W), and Adam(W). These SDEs offer a quantitatively accurate description of these optimizers and help illuminate an intricate relationship between adaptivity, gradient noise, and curvature. Our novel analysis of SignSGD highlights a noteworthy and precise contrast to SGD in terms of convergence speed, stationary distribution, and robustness to heavy-tail noise. We extend this analysis to AdamW and RMSpropW, for which we observe that the role of noise is much more complex. Crucially, we support our theoretical analysis with experimental evidence by verifying our insights: this includes numerically integrating our SDEs using Euler-Maruyama discretization on various neural network architectures such as MLPs, CNNs, ResNets, and Transformers. Our SDEs accurately track the behavior of the respective optimizers, especially when compared to previous SDEs derived for Adam and RMSprop. We believe our approach can provide valuable insights into best training practices and novel scaling rules.", "title_embedding_index": 7118, "title_abs_embedding_index": 7143}, {"title": "Glauber Generative Model: Discrete Diffusion Models via Binary Classification", "link_suffix": "/forum?id=HyjIEf90Tn", "link": "https://openreview.net/forum?id=HyjIEf90Tn", "pdf_link": "https://openreview.net/pdf?id=HyjIEf90Tn", "keywords": "Discrete Diffusion Models, Diffusion Models, Non-Autoregressive Models, Generative Models, Markov Chains, MCMC", "abstract": "We introduce the Glauber Generative Model (GGM), a new class of discrete diffusion models, to obtain new samples from a distribution given samples from a discrete space. GGM deploys a discrete Markov chain called the heat bath dynamics (or the Glauber dynamics) to denoise a sequence of noisy tokens to a sample from a joint distribution of discrete tokens. Our novel conceptual framework provides an exact reduction of the task of learning the denoising Markov chain to solving a class of binary classification tasks. More specifically, the model learns to classify a given token in a noisy sequence as signal or noise. In contrast, prior works on discrete diffusion models either solve regression problems to learn importance ratios, or minimize loss functions given by variational approximations.  We apply GGM to language modeling and image generation, where images are discretized using image tokenizers like VQGANs. We show that it outperforms existing discrete diffusion models in language generation, and demonstrates strong performance for image generation without using dataset-specific image tokenizers. We also show that our model is capable of performing well in zero-shot control settings like text and image infilling.", "title_embedding_index": 7119, "title_abs_embedding_index": 7144}, {"title": "Faster Adaptive Momentum-Based Federated Methods for Distributed Composition Optimization", "link_suffix": "/forum?id=Og7ZZd7hDm", "link": "https://openreview.net/forum?id=Og7ZZd7hDm", "pdf_link": "https://openreview.net/pdf?id=Og7ZZd7hDm", "keywords": "Federated Learning, Composition Optimization, Adaptive Learning Rate", "abstract": "Federated learning is a popular distributed learning paradigm in machine learning. Meanwhile, composition optimization is an effective hierarchical learning model, which appears in many machine learning applications such as meta learning and robust learning. More recently, although a few federated composition optimization algorithms have been proposed, they still suffer from high sample and communication complexities. In the paper, thus, we propose a class of faster adaptive federated compositional optimization algorithms (i.e., MFCGD and AdaMFCGD) to solve the nonconvex distributed composition problems, which builds on the momentum-based variance reduced and local-SGD techniques. In particular, our adaptive algorithm (i.e., AdaMFCGD) uses a unified adaptive matrix to flexibly incorporate various adaptive learning rates. Moreover, we provide a solid theoretical analysis for our algorithms under non-i.i.d. setting, and prove our algorithms obtain a lower sample and communication complexities simultaneously than the existing federated composition optimization  algorithms. Specifically, our algorithms obtain lower sample complexity of $\\tilde{O}(\\epsilon^{-3})$ with lower communication complexity of $\\tilde{O}(\\epsilon^{-2})$ in finding an $\\epsilon$-stationary solution. We conduct numerical experiments on robust federated learning and distributed meta learning tasks to demonstrate the efficiency of our algorithms.", "title_embedding_index": 7120, "title_abs_embedding_index": 7145}, {"title": "AutoBencher: Towards Declarative Benchmark Construction", "link_suffix": "/forum?id=ymt4crbbXh", "link": "https://openreview.net/forum?id=ymt4crbbXh", "pdf_link": "https://openreview.net/pdf?id=ymt4crbbXh", "keywords": "automatic evaluation, language models", "abstract": "We present AutoBencher, a declarative framework for automatic benchmark construction, and use it to scalably discover novel insights and vulnerabilities of existing language models. Concretely, given a few desiderata of benchmarks (e.g., question difficulty, topic salience), we operationalize each desideratum and cast benchmark creation as an optimization problem. Specifically, we experiment with two settings with different optimization objectives: (i) for capability evaluation, we declare the goal of finding a salient, difficult dataset that induces novel performance patterns; (ii) for safety evaluation, we declare the goal of finding a dataset of unsafe prompts that existing LMs fail to decline. To tackle this type of optimization problem, we propose to use a language model to automatically construct datasets and iteratively revise the dataset to optimize for the declared desiderata. We use AutoBencher (powered by GPT-4) to create datasets for math, multilinguality, knowledge, and safety. The scalability of AutoBencher allows it to test fine-grained categories and tail knowledge, creating datasets that are on average 27% more novel and 22% more difficult than existing benchmarks. AutoBencher also helps identify specific gaps not captured by existing benchmarks: e.g., Gemini-Pro has knowledge gaps on Permian Extinction and Fordism while GPT-4o fails to decline harmful requests about cryptocurrency scams.", "title_embedding_index": 7121, "title_abs_embedding_index": 7146}, {"title": "Evading Data Contamination Detection for Language Models is (too) Easy", "link_suffix": "/forum?id=Nk1MegaPuG", "link": "https://openreview.net/forum?id=Nk1MegaPuG", "pdf_link": "https://openreview.net/pdf?id=Nk1MegaPuG", "keywords": "large language models, model evaluation, malicious actors", "abstract": "The benchmark performance of large language models (LLMs) has a high impact on their popularity and is thus of great importance to many model providers. However, the reliability of such benchmark scores as a measure of model quality gets compromised if the model is contaminated with benchmark data. While recent contamination detection methods try to address this issue, they overlook the possibility of deliberate contamination by malicious model providers aiming to evade detection. We propose a categorization of model providers based on their (de)contamination practices and argue that malicious contamination is of crucial importance as it casts doubt on the reliability of public benchmarks. To study this issue more rigorously, we analyze current contamination detection methods based on their assumptions. This analysis reveals a significant vulnerability in existing approaches: they do not account for rephrased benchmark data used during training by malicious actors. We demonstrate how exploiting this gap can result in significantly inflated benchmark scores while completely evading current detection methods.", "title_embedding_index": 7122, "title_abs_embedding_index": 7147}, {"title": "Defects4C: Benchmarking C/C++ Faults to Assess LLM-Based Program Repair", "link_suffix": "/forum?id=gXK3Y6WNVv", "link": "https://openreview.net/forum?id=gXK3Y6WNVv", "pdf_link": "https://openreview.net/pdf?id=gXK3Y6WNVv", "keywords": "Defects4C; Large Language Model; Program Repair", "abstract": "Automated Program Repair (APR) plays a pivotal role in ensuring the quality and reliability of software. However, most existing APR research focuses on Java programs, primarily due to the well-established benchmark such as Defects4J. Despite the significant prevalence of C/C++ vulnerabilities, the field lacks extensive research on the automated repair of such vulnerabilities, primarily attributed to the absence of high-quality open-source benchmarks in this domain.To address the critical gap in available datasets for C/C++ program repair, this paper introduces Defects4C, a comprehensive and high-quality executable benchmark designed to improve defect detection and repair. The dataset includes a vast collection of bug-relevant commits (e.g.,9Min total),248high-quality buggy functions and102vulnerable functions paired with test cases for reproduction. These datasets can be used to evaluate repair techniques and to retrain learning-based methods for improved performance. Using this expanded dataset, we evaluate the performance of state-of-the-art LLM-based automated program repair techniques in addressing C/C++ faults. Specifically, we conduct an extensive empirical study with24leading LLMs. Our findings provide valuable insights into the capabilities and limitations of existing APR approaches for C/C++ programs, underscoring the necessity for novel APR techniques and the significance of Defects4C. This dataset marks a significant advancement in the field, offering a robust and comprehensive C/C++ dataset that is instrumental for future research on program repair.", "title_embedding_index": 7123, "title_abs_embedding_index": 7148}, {"title": "Training-free Editioning of Text-to-Image Models", "link_suffix": "/forum?id=myYKk4Qz3l", "link": "https://openreview.net/forum?id=myYKk4Qz3l", "pdf_link": "https://openreview.net/pdf?id=myYKk4Qz3l", "keywords": "text-to-image synthesis, software edition, concept subspace", "abstract": "Inspired by the software industry's practice of offering different editions or versions of a product tailored to specific user groups or use cases, we propose a novel task, namely, training-free editioning, for text-to-image models. Specifically, we aim to create variations of a base text-to-image model without retraining, enabling the model to cater to the diverse needs of different user groups or to offer distinct features and functionalities. To achieve this, we propose that different editions of a given text-to-image model can be formulated as concept subspaces in the latent space of its text encoder (e.g., CLIP). In such a concept subspace, all points satisfy a specific user need (e.g., generating images of a cat lying on the grass/ground/falling leaves). Technically, we apply Principal Component Analysis (PCA) to obtain the desired concept subspaces from representative text embedding that correspond to a specific user need or requirement. Projecting the text embedding of a given prompt into these low-dimensional subspaces enables efficient model editioning without retraining. Intuitively, our proposed editioning paradigm enables a service provider to customize the base model into its \"cat edition\" that restricts image generation to cats, regardless of the user's prompt (e.g., dogs, people, etc.). This introduces a new dimension for product differentiation, targeted functionality, and pricing strategies, unlocking novel business models for text-to-image generators. Extensive experimental results demonstrate the validity of our approach and its potential to enable a wide range of customized text-to-image model editions across various domains and applications.", "title_embedding_index": 7124, "title_abs_embedding_index": 7149}]
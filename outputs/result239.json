[
    {
        "title": "Revisiting PCA for Time Series Reduction in Temporal Dimension",
        "link_suffix": "/forum?id=0CvJYiOo2b",
        "link": "https://openreview.net/forum?id=0CvJYiOo2b",
        "pdf_link": "https://openreview.net/pdf?id=0CvJYiOo2b",
        "keywords": "principal component analysis (PCA), time series classification, time series forecasting, time series extrinsic regression",
        "abstract": "Deep learning has significantly advanced time series analysis (TSA), enabling the extraction of complex patterns for tasks like classification, forecasting, and regression. While dimensionality reduction has traditionally focused on the variable space\u2014achieving notable success in minimizing data redundancy and computational complexity\u2014less attention has been paid to reducing the temporal dimension. In this study, we revisit Principal Component Analysis (PCA), a classical dimensionality reduction technique, to explore its utility in temporal dimension reduction for time series data. It is generally thought that applying PCA to the temporal dimension would disrupt temporal dependencies, leading to limited exploration in this area. However, our theoretical analysis and extensive experiments demonstrate that applying PCA to sliding series windows not only maintains model performance but also enhances computational efficiency. In auto-regressive forecasting, the temporal structure is partially preserved through windowing, and PCA is applied within these windows to denoise the time series while retaining their statistical information. By preprocessing time series data with PCA, we reduce the temporal dimensionality before feeding it into TSA models such as Linear, Transformer, CNN, and RNN architectures. This approach accelerates training and inference and reduces resource consumption. Notably, PCA improves Informer training and inference speed by up to 40% and decreases GPU memory usage of TimesNet by 30%, without sacrificing model accuracy. Comparative analysis against other reduction methods further highlights the effectiveness of PCA in enhancing the efficiency of TSA models. Code is provided in the supplementary materials."
    },
    {
        "title": "Safe Multi-task Pretraining with Constraint Prioritized Decision Transformer",
        "link_suffix": "/forum?id=CbPifku2Un",
        "link": "https://openreview.net/forum?id=CbPifku2Un",
        "pdf_link": "https://openreview.net/pdf?id=CbPifku2Un",
        "keywords": "Reinforcement Learning, Offline Learning, Safe Reinforcement Learning, Multi-task Pretrain",
        "abstract": "Learning a safe policy from offline data without interacting with the environment is crucial for deploying reinforcement learning (RL) policies. Recent approaches leverage transformers to address tasks under various goals, demonstrating a strong generalizability for broad applications. However, these methods either completely overlook safety concerns during policy deployment or simplify safe RL as a dual-objective problem, disregarding the differing priorities between costs and rewards, as well as the additional challenge of multi-task identification caused by cost sparsity. To address these issues, we propose \\textbf{S}afe \\textbf{M}ulti-t\\textbf{a}sk Pretraining with \\textbf{Co}nstraint Prioritized Decision \\textbf{T}ransformer (SMACOT), which utilizes the Decision Transformer (DT) to accommodate varying safety threshold objectives during policy deployment while ensuring scalability. It introduces a Constraint Prioritized Return-To-Go (CPRTG) token to emphasize cost priorities in the Transformer\u2019s inference process, effectively balancing reward maximization with safety constraints. Additionally, a Constraint Prioritized Prompt Encoder is designed to leverage the sparsity of cost information for task identification. Extensive experiments on the public OSRL dataset demonstrate that SMACOT achieves exceptional safety performance in both single-task and multi-task scenarios, satisfying different safety constraints in over 2x as many environments compared with strong baselines, showcasing its superior safety capability."
    },
    {
        "title": "Biologically Plausible Brain Graph Transformer",
        "link_suffix": "/forum?id=rQyg6MnsDb",
        "link": "https://openreview.net/forum?id=rQyg6MnsDb",
        "pdf_link": "https://openreview.net/pdf?id=rQyg6MnsDb",
        "keywords": "brain, graph learning, transformer, graph representation, brain networks",
        "abstract": "State-of-the-art brain graph analysis methods generally lack biological plausibility, primarily because they fail to fully encode the small-world architecture of brain graphs (accompanied by the presence of hubs and functional modules). This limitation hinders their ability to accurately represent the brain's structural and functional properties, thereby restricting the effectiveness of machine learning models in tasks such as brain disorder detection. In this work, we propose a novel Biologically Plausible Brain Graph Transformer (BioBGT) that encodes the small-world architecture inherent in brain graphs. Specifically, we present a network entanglement-based node importance encoding technique that captures the structural importance of nodes in global information propagation during brain graph communication, highlighting the biological properties of the brain structure. Furthermore, we introduce a functional module-aware self-attention to preserve the functional segregation and integration characteristics of brain graphs in the learned representations. Experimental results on three benchmark datasets demonstrate that BioBGT outperforms state-of-the-art models, providing biologically plausible brain graph representations for various brain graph analytical tasks"
    },
    {
        "title": "GLANCE: Global Actions in a Nutshell for Counterfactual Explainability",
        "link_suffix": "/forum?id=j6GIg0peoS",
        "link": "https://openreview.net/forum?id=j6GIg0peoS",
        "pdf_link": "https://openreview.net/pdf?id=j6GIg0peoS",
        "keywords": "Global Counterfactual Explainability, Recourse, Actions, Clustering",
        "abstract": "The widespread deployment of machine learning systems in critical real-world decision-making applications has highlighted the urgent need for counterfactual explainability methods that operate effectively. Global counterfactual explanations, expressed as actions to offer recourse, aim to provide succinct explanations and insights applicable to large population subgroups. Effectiveness is measured by the fraction of the population that is provided recourse, ensuring that the actions benefit as many individuals as possible. Keeping the cost of actions low ensures the proposed recourse actions remain practical and actionable. Limiting the number of actions that provide global counterfactuals is essential to maximize interpretability. The primary challenge, therefore, is balancing these trade-offs\u2014maximizing effectiveness, minimizing cost, while maintaining a small number of actions. We introduce GLANCE, a versatile and adaptive framework, comprising two algorithms, that allows the careful balancing of the trade-offs among the three key objectives, with the size objective functioning as a tunable parameter to keep the actions few and easy to interpret. C-GLANCE employs a clustering approach that considers both the feature space and the space of counterfactual actions, thereby accounting for the distribution of points in a way that aligns with the structure of the model. T-GLANCE provides additional features to enhance flexibility. It employs a tree-based approach, that allows users to specify split features, to build a decision tree with a single counterfactual action at each node that can be used as a subgroup policy. Our extensive experimental evaluation demonstrates that our method consistently shows greater robustness and performance compared to existing methods across various datasets and models."
    },
    {
        "title": "Learning High-dimensional Gaussian Mixture Models via a Fourier Approach",
        "link_suffix": "/forum?id=x4jPW4p55i",
        "link": "https://openreview.net/forum?id=x4jPW4p55i",
        "pdf_link": "https://openreview.net/pdf?id=x4jPW4p55i",
        "keywords": "Gaussian Mixture Models(GMM), Parameter Estimation, Model Order Selection, Super-resolution, Line Spectral Estimation",
        "abstract": "In this paper, we address the challenge of learning high-dimensional Gaussian mixture models (GMMs), with a specific focus on estimating both the model order and the mixing distribution from i.i.d. samples. We propose a novel algorithm that achieves linear complexity relative to the sample size $n$, significantly improving computational efficiency. Unlike traditional methods, such as the method of moments or maximum likelihood estimation, our algorithm leverages Fourier measurements from the samples, facilitating simultaneous estimation of both the model order and the mixing distribution. The difficulty of the learning problem can be quantified by the minimum separation distance $\\Delta$ and minimal mixing weight $w_{\\min}$. For stable estimation, a sample size of $\\Omega\\left(\\frac{1}{w_{\\min}^2 \\Delta^{4K-4}}\\right)$ is required for the model order,  while $\\Omega\\left(\\frac{1}{w_{\\min}^2 \\Delta^{4K-2}}\\right)$ is necessary for the mixing distribution. This highlights the distinct sample complexities for the two tasks. For $D$-dimensional mixture models, we propose a PCA-based approach to reduce the dimension, reducing the algorithm\u2019s complexity to $O(nD^2)$, with potential further reductions through random projections. Numerical experiments demonstrate the efficiency and accuracy compared with the EM algorithm. In particular, we observe a clear phase transition in determining the model order, as our method outperforms traditional information criteria. Additionally, our framework is flexible and can be extended to learning mixtures of other distributions, such as Cauchy or exponential distributions."
    },
    {
        "title": "Building, Reusing, and Generalizing Abstract Representations from Concrete Sequences",
        "link_suffix": "/forum?id=xIUUnzrUtD",
        "link": "https://openreview.net/forum?id=xIUUnzrUtD",
        "pdf_link": "https://openreview.net/pdf?id=xIUUnzrUtD",
        "keywords": "Abstraction, Chunking, Cognitive Science, LLMs",
        "abstract": "Humans excel at learning abstract patterns across different sequences, filtering out irrelevant details, and transferring these generalized concepts to new sequences.\nIn contrast, many sequence learning\nmodels lack the ability to abstract, which leads to memory\ninefficiency and poor transfer. We introduce a non-parametric hierarchical variable learning model (HVM) that learns chunks from sequences and abstracts contextually similar chunks as variables. HVM efficiently organizes memory while uncovering abstractions, leading to compact sequence representations.  When learning on language datasets such as babyLM, HVM learns a more efficient dictionary than standard compression algorithms such as Lempel-Ziv. In a sequence recall task requiring the acquisition and transfer of variables embedded in sequences, we demonstrate HVM's sequence likelihood correlates with human recall times. In contrast, large language models (LLMs) struggle to transfer abstract variables as effectively as humans. From HVM's adjustable layer of abstraction, we demonstrate that the model realizes a precise trade-off between compression and generalization. Our work offers a cognitive model that captures the learning and transfer of abstract representations in human cognition and differentiates itself from the behavior of large language models."
    },
    {
        "title": "Unsupervised Meta-Learning via Dynamic Head and Heterogeneous Task Construction for Few-Shot Classification",
        "link_suffix": "/forum?id=iotwQLLatn",
        "link": "https://openreview.net/forum?id=iotwQLLatn",
        "pdf_link": "https://openreview.net/pdf?id=iotwQLLatn",
        "keywords": "Meta-Learning; Unsupervised Learning; Few-shot Learning; Data Noise; Heterogeneous Task",
        "abstract": "Meta-learning has been widely used in recent years in areas such as few-shot learning and reinforcement learning. However, the questions of why and when it's better than other algorithms in few-shot classification remain to be explored. In this paper, we answer the above questions from the perspective of data noise and heterogeneous tasks. Specifically, we perform pre-experiments by adjusting the proportion of data noise and the degree of heterogeneity of the task in the dataset. We use the metric of Singular Vector Canonical Correlation Analysis to quantified the representation stability of the neural network and thus to compare the behavior of meta-learning algorithms and other algorithms. We find that benefits from the bi-level optimization strategy, the meta-learning algorithm has better robustness to label noise and heterogeneous tasks. Based on the above conclusion, we argue a promising future for meta-learning in the unsupervised area, and thus propose DHM-UHT, a dynamic head meta-learning algorithm with unsupervised heterogeneous task construction. The core idea of DHM-UHT is to use DBSCAN and dynamic head to achieve heterogeneous task construction and meta-learn the whole process of unsupervised heterogeneous task construction. On several unsupervised zero-shot and few-shot datasets, DHM-UHT obtains state-of-the-art performance. The code is released athttps://github.com/tuantuange/DHM-UHT."
    },
    {
        "title": "Bellman Diffusion: Generative Modeling as Learning a Linear Operator in the Distribution Space",
        "link_suffix": "/forum?id=kIqA447T5c",
        "link": "https://openreview.net/forum?id=kIqA447T5c",
        "pdf_link": "https://openreview.net/pdf?id=kIqA447T5c",
        "keywords": "Deep Generative Models; Markov Decision Processes; Foundation of Distributional Reinforcement Learning",
        "abstract": "Deep Generative Models (DGMs), including Energy-Based Models (EBMs) and Score-based Generative Models (SGMs), have advanced high-fidelity data generation and complex continuous distribution approximation. However, their application in Markov Decision Processes (MDPs), particularly in distributional Reinforcement Learning (RL), remains underexplored, with conventional histogram-based methods dominating the field. This paper rigorously highlights that this application gap is caused by the nonlinearity of modern DGMs, which conflicts with the linearity required by the Bellman equation in MDPs. For instance, EBMs involve nonlinear operations such as exponentiating energy functions and normalizing constants. To address this, we introduce Bellman Diffusion, a novel DGM framework that maintains linearity in MDPs through gradient and scalar field modeling. With divergence-based training techniques to optimize neural network proxies and a new type of  stochastic differential equation (SDE) for sampling, Bellman Diffusion is guaranteed to converge to the target distribution. Our empirical results show that Bellman Diffusion achieves accurate field estimations and is a capable image generator, converging 1.5x faster than the traditional histogram-based baseline in distributional RL tasks. This work enables the effective integration of DGMs into MDP applications, unlocking new avenues for advanced decision-making frameworks."
    },
    {
        "title": "No MCMC Teaching For me: Learning Energy-Based Models via Diffusion Synergy",
        "link_suffix": "/forum?id=46tjvA75h6",
        "link": "https://openreview.net/forum?id=46tjvA75h6",
        "pdf_link": "https://openreview.net/pdf?id=46tjvA75h6",
        "keywords": "energy-based models, generative modeling, sampling, diffusion models",
        "abstract": "Markov chain Monte Carlo (MCMC) sampling-based maximum likelihood estimation is a standard approach for training Energy-Based Models (EBMs). However, its effectiveness and training stability in high-dimensional settings remain thorny issues due to challenges like mode collapse and slow mixing of MCMC.\nTo address these limitations, we introduce a novel MCMC teaching-free learning framework that jointly trains an EBM and a diffusion-based generative model, leveraging the variational formulation of divergence between time-reversed diffusion paths. In each iteration, the generator model is trained to align with both the empirical data distribution and the current EBM, bypassing the need for biased MCMC sampling. The EBM is then updated by maximizing the likelihood of the synthesized examples generated through a diffusion generative process that more accurately reflects the EBM\u2019s distribution. Moreover, we propose a novel objective function that further improves EBM learning by minimizing the discrepancy between the EBM and the generative model. Our proposed approach enhances training efficiency and overcomes key challenges associated with traditional MCMC-based methods. Experimental results on generative modeling and likelihood estimation demonstrate the superior performance of our method."
    },
    {
        "title": "Accelerate Quantization Aware Training for Diffusion Models with Difficulty-aware Time Allocation",
        "link_suffix": "/forum?id=XQQMKhGBoY",
        "link": "https://openreview.net/forum?id=XQQMKhGBoY",
        "pdf_link": "https://openreview.net/pdf?id=XQQMKhGBoY",
        "keywords": "Diffusion Models, Model Quantization, Text-to-image Generation",
        "abstract": "Diffusion models have demonstrated remarkable power in various generation tasks. Nevertheless, the large computational cost during inference is a troublesome issue for diffusion models, especially for large pretrained models such as Stable Diffusion. Quantization-aware training (QAT) is an effective method to reduce both memory and time costs for diffusion models while maintaining good performance. However, QAT methods usually suffer from the high cost of retraining the large pretrained model, which restricts the efficient deployment of diffusion models. To alleviate this problem, we propose a framework DFastQ (Diffusion Fast QAT) to accelerate the training of QAT from a difficulty-aware perspective in the timestep dimension. Specifically, we first propose to adaptively identify the difficulties of different timesteps according to the oscillation of their training loss curves. Then we propose a difficulty-aware time allocation module, which aims to dynamically allocate more training time to difficult timesteps to speed up the convergence of QAT. The key component of this is a timestep drop mechanism consisting of a drop probability predictor and a pair of adversarial losses. We conduct a series of experiments on different Stable Diffusion models, quantization settings, and sampling strategies, demonstrating that our method can effectively accelerate QAT by at least 24% while achieving comparable or even better performance."
    },
    {
        "title": "Agents Help Agents: Exploring Training-Free Knowledge Distillation for Small Language Models in Data Science Code Generation",
        "link_suffix": "/forum?id=hREMYJ5ZmD",
        "link": "https://openreview.net/forum?id=hREMYJ5ZmD",
        "pdf_link": "https://openreview.net/pdf?id=hREMYJ5ZmD",
        "keywords": "Knowledge Distillation, Large Language Models, Small Language Models, Data Science Code Generation, In-Context Learning, Agent Orchestration",
        "abstract": "Knowledge distillation from Large Language Models (LLMs) to locally hosted Small Language Models (SLMs) provides advantages for Data Science Code Generation (DSCG) such as enhanced data privacy and reduced response times. However, achieving effective distillation without resource-intensive training is challenging. This paper investigates whether LLMs can distill knowledge to SLMs through In-Context Learning (ICL), a training-free method for rapid task adaptation. We present theAgents Help Agents (AHA)framework, which facilitates automatic knowledge distillation from LLMs to SLMs via agent orchestration. AHA consists of three phases: exploration through anAgent Orchestration Interface (AOI), memory collection of successful examples, and inference augmented with distilled knowledge. The AOI orchestrates interactions between a LLM as a teacher agent and a SLM as a student agent. And we propose two distillation strategies: a static approach that aggregates an offline instruction set and a dynamic RAG-based approach that distills knowledge dynamically during inference.  We evaluate AHA on three challenging code generation tasks for tabular data analysis: TabMWP, BirD-SQL, and WikiTQ. Experimental results demonstrate the effectiveness of AHA, leading to an average 27.5% relative improvement in the performance of the Student Agent Phi-3-mini. Additionally, relative gains of 14.3% and 30.9% are observed inLlama-3.1-8BandGPT-35-Turbo, respectively, even though those models were not calibrated as part of the orchestration, highlighting the model-agnostic nature of the distilled knowledge in AHA. Further analysis compares distillation and demonstration techniques across different data input settings, providing insights into optimal configurations for DSCG."
    },
    {
        "title": "A Foundation Model for Patient Behavior Monitoring and Suicide Detection",
        "link_suffix": "/forum?id=h24XT5DOb2",
        "link": "https://openreview.net/forum?id=h24XT5DOb2",
        "pdf_link": "https://openreview.net/pdf?id=h24XT5DOb2",
        "keywords": "Foundation models for patient monitoring, Suicide detection via deep learning",
        "abstract": "Foundation models have achieved remarkable success across various domains, yet their adoption in healthcare remains limited, particularly in areas requiring the analysis of smaller and more complex datasets. While foundation models have made significant advances in medical imaging, genetic biomarkers, and time series from electronic health records, the potential for patient behavior monitoring through wearable devices remains underexplored. Wearable device datasets are inherently heterogeneous and multisource and often exhibit high rates of missing data, presenting unique challenges. Notably, missing patterns in these datasets are frequently not-at-random, and when adequately modeled, these patterns can reveal crucial insights into patient behavior. \nThis paper introduces a novel foundation model based on a modified vector quantized variational autoencoder (VQ-VAE), specifically designed to process real-world data from wearable devices. Our model excels at reconstructing heterogeneous multisource time-series data and effectively models missing data patterns. We demonstrate that our pretrained model, trained on a broad cohort of psychiatric patients with diverse mental health issues, can perform downstream tasks without fine-tuning on a held-out cohort of suicidal patients. This is illustrated through the use of a change-point detection algorithm that identifies suicide attempts with high accuracy, matching or surpassing patient-specific methods, thereby highlighting the potential of VQ-VAE as a versatile tool for behavioral analysis in healthcare."
    },
    {
        "title": "ECD: A Machine Learning Benchmark for Predicting Enhanced-Precision Electronic Charge Density in Crystalline Inorganic Materials",
        "link_suffix": "/forum?id=SBCMNc3Mq3",
        "link": "https://openreview.net/forum?id=SBCMNc3Mq3",
        "pdf_link": "https://openreview.net/pdf?id=SBCMNc3Mq3",
        "keywords": "Electronic Charge Density, Crystalline Inorganic Materials, Graph Neural Network, Dataset",
        "abstract": "Supervised machine learning techniques are increasingly being adopted to speed up electronic structure predictions, serving as alternatives to first-principles methods like Density Functional Theory (DFT). Although current DFT datasets mainly emphasize chemical properties and atomic forces, the precise prediction of electronic charge density is essential for accurately determining a system's total energy and ground state properties. In this study, we introduce a novel electronic charge density dataset named ECD, which encompasses 140,646 stable crystal geometries with medium-precision Perdew\u2013Burke\u2013Ernzerhof (PBE) functional data. Within this dataset, a subset of 7,147 geometries includes high-precision electronic charge density data calculated using the Heyd\u2013Scuseria\u2013Ernzerhof (HSE) functional in DFT. By designing various benchmark tasks for crystalline materials and emphasizing training with large-scale PBE data while fine-tuning with a smaller subset of high-precision HSE data, we demonstrate the efficacy of current machine learning models in predicting electronic charge densities.\nThe ECD dataset and baseline models are open-sourced to support community efforts in developing new methodologies and accelerating materials design and applications."
    },
    {
        "title": "ProFI-Painter: Text-Guided Prompt-Faithful Image Inpainting with Diffusion Models",
        "link_suffix": "/forum?id=6lB5qtdYAg",
        "link": "https://openreview.net/forum?id=6lB5qtdYAg",
        "pdf_link": "https://openreview.net/pdf?id=6lB5qtdYAg",
        "keywords": "text-guided image inpainting, diffusion models, high-resolution image inpainting",
        "abstract": "Recent progress in text-guided image inpainting, based on the unprecedented success of text-to-image diffusion models, has led to exceptionally realistic and visually plausible results.\nHowever, there is still significant potential for improvement in current text-to-image inpainting models, particularly in better aligning the inpainted area with user prompts.\nTherefore, we introduce $\\textit{ProFI-Painter}$, a $\\textbf{training-free}$ approach that $\\textbf{accurately follows prompts}$.\nTo this end, we design the $\\textit{Prompt-Aware Introverted Attention (PAIntA)}$ layer enhancing self-attention scores by prompt information resulting in better text aligned generations.\nTo further improve the prompt coherence we introduce the $\\textit{Reweighting Attention Score Guidance (RASG)}$ mechanism seamlessly integrating a post-hoc sampling strategy into the general form of DDIM to prevent out-of-distribution latent shifts.\nOur experiments demonstrate that ProFI-Painter surpasses existing state-of-the-art approaches quantitatively and qualitatively across multiple metrics and a user study. \nCode will be made public."
    },
    {
        "title": "ViBiDSampler: Enhancing Video Interpolation Using Bidirectional Diffusion Sampler",
        "link_suffix": "/forum?id=nNYA7tcJSE",
        "link": "https://openreview.net/forum?id=nNYA7tcJSE",
        "pdf_link": "https://openreview.net/pdf?id=nNYA7tcJSE",
        "keywords": "Keyframe interpolation, Stable video diffusion, Bidirectional diffusion sampling",
        "abstract": "Recent progress in large-scale text-to-video (T2V) and image-to-video (I2V) diffusion models has greatly enhanced video generation, especially in terms of keyframe interpolation. However, current image-to-video diffusion models, while powerful in generating videos from a single conditioning frame, need adaptation for two-frame (start & end) conditioned generation, which is essential for effective bounded interpolation. Unfortunately, existing approaches that fuse temporally forward and backward paths in parallel often suffer from off-manifold issues, leading to artifacts or requiring multiple iterative re-noising steps. In this work, we introduce a novel, bidirectional sampling strategy to address these off-manifold issues without requiring extensive re-noising or fine-tuning. Our method employs sequential sampling along both forward and backward paths, conditioned on the start and end frames, respectively, ensuring more coherent and on-manifold generation of intermediate frames. Additionally, we incorporate advanced guidance techniques, CFG++ and DDS, to further enhance the interpolation process. By integrating these, our method achieves state-of-the-art performance, efficiently generating high-quality, smooth videos between keyframes. On a single 3090 GPU, our method can interpolate 25 frames at 1024$\\times$576 resolution in just 195 seconds, establishing it as a leading solution for keyframe interpolation.\nProject page:https://vibid.github.io"
    },
    {
        "title": "Stochastic Bandits Robust to Adversarial Attacks",
        "link_suffix": "/forum?id=vOFx8HDcvF",
        "link": "https://openreview.net/forum?id=vOFx8HDcvF",
        "pdf_link": "https://openreview.net/pdf?id=vOFx8HDcvF",
        "keywords": "Robust Algorithms, Multi-armed Bandits, Adversarial Attacks",
        "abstract": "This paper investigates stochastic multi-armed bandit algorithms that are robust to adversarial attacks, where an attacker can first observe the learner's action andthenalter their reward observation.\nWe study two cases of this model, with or without the knowledge of an attack budget $C$, defined as an upper bound of the summation of the difference between the actual and altered rewards. For both cases, we devise two types of algorithms with regret bounds having additive or multiplicative $C$ dependence terms.\nFor the known attack budget case, we prove our algorithms achieve the regret bound of ${O}((K/\\Delta)\\log T + KC)$ and $\\tilde{O}(\\sqrt{KTC})$ for the additive and multiplicative $C$ terms, respectively, where $K$ is the number of arms, $T$ is the time horizon, $\\Delta$ is the gap between the expected rewards of the optimal arm and the second-best arm, and $\\tilde{O}$ hides the logarithmic factors.\nFor the unknown case, we prove our algorithms achieve the regret bound of $\\tilde{O}(\\sqrt{KT} + KC^2)$ and $\\tilde{O}(KC\\sqrt{T})$ for the additive and multiplicative $C$ terms, respectively.\nIn addition to these upper bound results, we provide several lower bounds showing the tightness of our bounds and the optimality of our algorithms.\nThese results delineate an intrinsic separation between the bandits with attacks and corruption models."
    },
    {
        "title": "Theoretical Insights into Fine-Tuning Attention Mechanism: Generalization and Optimization",
        "link_suffix": "/forum?id=P98KMCf60l",
        "link": "https://openreview.net/forum?id=P98KMCf60l",
        "pdf_link": "https://openreview.net/pdf?id=P98KMCf60l",
        "keywords": "Large Language Models, Attention mechanism, Fine-tuning, Generalization and Optimization",
        "abstract": "Large Language Models (LLMs), built on Transformer architectures, exhibit remarkable generalization across a wide range of tasks. However, fine-tuning these models for specific tasks remains resource-intensive due to their extensive parameterization. In this paper, we investigate two remarkable phenomena observed during the fine-tuning of LLMs, particularly focusing on the attention mechanism: (1) Different Impact, optimizing the $\\mathbf{W}_v$ matrix significantly improves performance over optimizing the $\\mathbf{W}_k$ matrix. Fine-tuning only the $\\mathbf{W}_q$ and $\\mathbf{W}_v$ matrices is computationally efficient, delivering results that are comparable to, or even better than, fine-tuning all three matrices $\\mathbf{W}_q$, $\\mathbf{W}_k$, and $\\mathbf{W}_v$. (2) Efficient Convergence, employing distinct learning rates for these matrices is crucial for optimal performance, with a higher learning rate for the $\\mathbf{W}_v$ matrix expediting convergence. However, theoretical analyses of these phenomena are still relatively limited. We present a theoretical analysis of these phenomena from two perspectives: (i) Generalization, where we demonstrate that fine-tuning only $\\mathbf{W}_q$ and $\\mathbf{W}_v$ improves generalization bounds, enhances memory efficiency, and (ii) Optimization, where we emphasize that the feature learning of the attention mechanism is efficient, particularly when using distinct learning rates for the matrices, which leads to more effective fine-tuning. Building on these insights, we propose a new strategy that improves fine-tuning efficiency in terms of both storage and time. Experimental results on benchmark datasets validate the effectiveness of this approach, supporting our theoretical findings. Our analysis lays the theoretical groundwork for configuring and improving lightweight algorithms in LLMs fine-tuning."
    },
    {
        "title": "MinorityPrompt: Text to Minority Image Generation via Prompt Optimization",
        "link_suffix": "/forum?id=98dyxUoI3q",
        "link": "https://openreview.net/forum?id=98dyxUoI3q",
        "pdf_link": "https://openreview.net/pdf?id=98dyxUoI3q",
        "keywords": "text-to-image generation, diffusion models, minority generation",
        "abstract": "We investigate the generation of minority samples using pretrained text-to-image (T2I) latent diffusion models. Minority instances, in the context of T2I generation, can be defined as ones living on low-density regions oftext-conditionaldata distributions. They are valuable for various applications of modern T2I generators, such as data augmentation and creative AI. Unfortunately, existing pretrained T2I diffusion models primarily focus on high-density regions, largely due to the influence of guided samplers (like CFG) that are essential for producing high-quality generations. To address this, we present a novel framework to counter the high-density-focus of T2I diffusion models. Specifically, we first develop an online prompt optimization framework that can encourage the emergence of desired properties during inference while preserving semantic contents of user-provided prompts. We subsequently tailor this generic prompt optimizer into a specialized solver that promotes the generation of minority features by incorporating a carefully-crafted likelihood objective. Our comprehensive experiments, conducted across various types of T2I models, demonstrate that our approach significantly enhances the capability to produce high-quality minority instances compared to existing samplers."
    },
    {
        "title": "Delving into Weakly Supervised Learning with Pre-Trained Models",
        "link_suffix": "/forum?id=RgWATMmWmz",
        "link": "https://openreview.net/forum?id=RgWATMmWmz",
        "pdf_link": "https://openreview.net/pdf?id=RgWATMmWmz",
        "keywords": "Weakly supervised learning, positive-unlabeled learning, unlabeled-unlabeled learning, pre-trained models.",
        "abstract": "Weakly supervised learning (WSL) is a popular machine learning paradigm in recent years that aims to learn a classifier with incomplete, imprecise, or inaccurate supervision. Existing WSL approaches have mainly focused on designing different loss functions or training strategies and then training models from scratch. In this paper, we first empirically show that a zero-shot baseline based on the Contrastive Language-Image Pre-Training (CLIP) model with class descriptions empowered by GPT-4o can outperform previous state-of-the-art methods trained from scratch on various WSL problems. Therefore, this motivates us to fine-tune pre-trained models to further improve the performance. However, our additional experiments show that naive use of existing WSL losses degrades performance due to severe overfitting exacerbation and feature degeneration problems. To address these problems, we propose a novel weakly supervised fine-tuning approach using dual classification heads that are trained synergistically by alternately distilling reliable supervision and performing efficient model fine-tuning. Theoretically, we prove the consistency and convergence rate of the proposed risk estimator. Empirically, extensive experiments on benchmark datasets of different WSL problems validate the effectiveness of the proposed approach against state-of-the-art competitors. The code is provided athttps://github.com/ICLR2025-6897/WSFT_code."
    },
    {
        "title": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping",
        "link_suffix": "/forum?id=pqeWzZTrZY",
        "link": "https://openreview.net/forum?id=pqeWzZTrZY",
        "pdf_link": "https://openreview.net/pdf?id=pqeWzZTrZY",
        "keywords": "Adversarial Attack; Person Detection; NeRF; UV-Mapping",
        "abstract": "Recent works have attacked person detectors using adversarial patches or static-3D-model-based texture modifications. However, these methods suffer from low attack success rates when faced with significant human movements. The primary challenge stems from the highly non-rigid nature of the human body and clothing. Current attacks fail to model these 3D non-rigid deformations caused by varied actions.\nFortunately, recent research has shown significant progress in using NeRF for dynamic human modeling. \nIn this paper, we introduce \\texttt{UV-Attack}, a novel physical adversarial attack achieving high attack success rates in scenarios involving extensive and unseen actions. We address the challenges above by leveraging dynamic-NeRF-based UV mapping. Our method can generate human images across diverse actions and viewpoints and even create novel unseen actions by sampling from the SMPL parameter space. While dynamic NeRF models are capable of modeling human bodies, modifying their clothing textures is challenging due to the texture being embedded within neural network parameters.\nTo overcome this, \\texttt{UV-Attack} generates UV maps instead of RGB images and modifies the texture stacks. This approach enables real-time texture edits and makes attacks more practical. Finally, we propose a novel Expectation over Pose Transformation loss (EoPT) to improve the evasion success rate on unseen poses and views.\nOur experiments show that \\texttt{UV-Attack} achieves a 92.75% attack success rate against the FastRCNN model across varied poses in dynamic video settings, significantly outperforming the state-of-the-art AdvCaT attack, which only had a 28.50% ASR. Moreover, we achieve 49.5% ASR on the latest YOLOv8 detector in black-box settings."
    },
    {
        "title": "Optimizer-Dependent Generalization Bound for Quantum Neural Networks",
        "link_suffix": "/forum?id=lirR6Wfkd6",
        "link": "https://openreview.net/forum?id=lirR6Wfkd6",
        "pdf_link": "https://openreview.net/pdf?id=lirR6Wfkd6",
        "keywords": "Quantum Machine Learning, Quantum Neural Networks, Stability, Generalization",
        "abstract": "Quantum neural networks (QNNs) play a pivotal role in addressing complex tasks within quantum machine learning, analogous to classical neural networks in deep learning. Ensuring consistent performance across diverse datasets is crucial for understanding and optimizing QNNs in both classical and quantum machine learning tasks, but remains a challenge as QNN's generalization properties have not been fully explored. In this paper, we investigate the generalization properties of QNNs through the lens of learning algorithm stability, circumventing the need to explore the entire hypothesis space and providing insights into how classical optimizers influence QNN performance. By establishing a connection between QNNs and quantum combs, we examine the general behaviors of QNN models from a quantum information theory perspective. Leveraging the uniform stability of the stochastic gradient descent algorithm, we propose a generalization error bound determined by the number of trainable parameters, data uploading times, dataset dimension, and classical optimizer hyperparameters. Numerical experiments validate this comprehensive understanding of QNNs and align with our theoretical conclusions. As the first investigation into QNN stability, this work provides valuable guidelines for designing and training powerful QNNs in quantum machine learning applications."
    },
    {
        "title": "MambaMatch: Learning Two-View Correspondences with Selective State Spaces",
        "link_suffix": "/forum?id=YuJdtpPV4n",
        "link": "https://openreview.net/forum?id=YuJdtpPV4n",
        "pdf_link": "https://openreview.net/pdf?id=YuJdtpPV4n",
        "keywords": "Correspondence learning, image matching, feature matching",
        "abstract": "Two-view correspondence learning aims to discern true and false correspondences between image pairs by recognizing their underlying different information. Previous methods either treat the information equally or fail to discard the superfluous information of false correspondences, tending to be invalid in practical scenarios. Therefore, inspired by Mamba's inherent competence of selectivity, we propose MambaMatch as a Mamba-based correspondence filter to selectively mine information from true correspondences and to dispose of the potentially interfering information of false correspondences. Specifically, the selection is achieved by adaptively adjusting model parameters in a high-dimensional latent space, which also avoids attention leakage and implements context compression, ensuring the precise and efficient exploitation of pertinent information. Meanwhile, channel awareness is tailored to serve as a complementary aspect of comprehensive information acquisition. Moreover, we design a novel local-context enhancement module to capture reasonable local context that is crucial for correspondence pruning. Extensive experiments demonstrate that our approach outperforms existing state-of-the-art methods on several visual tasks while saving time and space costs."
    },
    {
        "title": "TestGenEval: A Real World Unit Test Generation and Test Completion Benchmark",
        "link_suffix": "/forum?id=7o6SG5gVev",
        "link": "https://openreview.net/forum?id=7o6SG5gVev",
        "pdf_link": "https://openreview.net/pdf?id=7o6SG5gVev",
        "keywords": "test generation, software engineering, language models",
        "abstract": "Code generation models can help improve many common software tasks ranging from  code completion to defect prediction. Most of the existing benchmarks for code generation LLMs focus on code authoring or code completion. Surprisingly, there has been far less effort dedicated to benchmarking software testing, despite the strong correlation between well-tested software and effective bug detection. To address this gap, we create and release TestGenEval, a large-scale benchmark to measure test generation performance. Based on SWEBench, TestGenEval comprises 68,647 tests from 1,210 code and test file pairs across 11 well-maintained Python repositories. It covers initial tests authoring, test suite completion, and code coverage improvements. Test authoring simulates the process of a developer writing a test suite from scratch, while test completion mimics the scenario where a developer aims to improve the coverage of an existing test suite. We evaluate several popular models, with sizes ranging from 7B to 405B parameters. Our detailed analysis highlights TestGenEval's contribution to a comprehensive evaluation of test generation performance. In particular, models struggle to generate high-coverage test suites, with the best model, GPT-4o, achieving an average coverage of only 35.2%. This is primarily due to models struggling to reason about execution, and their frequent assertion errors when addressing complex code paths."
    },
    {
        "title": "Efficient Distribution Matching of Representations via Noise-Injected Deep InfoMax",
        "link_suffix": "/forum?id=mAmCdASmJ5",
        "link": "https://openreview.net/forum?id=mAmCdASmJ5",
        "pdf_link": "https://openreview.net/pdf?id=mAmCdASmJ5",
        "keywords": "information theory, deep infomax, self-supervised learning, representation learning, distribution matching, Gaussian embeddings",
        "abstract": "Deep InfoMax (DIM) is a well-established method for self-supervised representation learning (SSRL) based on maximization of the mutual information between the input and the output of a deep neural network encoder. Despite the DIM and contrastive SSRL in general being well-explored, the task of learning representations conforming to a specific distribution (i.e., distribution matching, DM) is still under-addressed. Motivated by the importance of DM to several downstream tasks (including generative modeling, disentanglement, outliers detection and other), we enhance DIM to enable automatic matching of learned representations to a selected prior distribution. To achieve this, we propose injecting an independent noise into the normalized outputs of the encoder, while keeping the same InfoMax training objective. We show that such modification allows for learning uniformly and normally distributed representations, as well as representations of other absolutely continuous distributions. Our approach is tested on various downstream tasks. The results indicate a moderate trade-off between the performance on the downstream tasks and quality of DM."
    },
    {
        "title": "ProtMamba: a homology-aware but alignment-free protein state space model",
        "link_suffix": "/forum?id=BMfHO2lXGe",
        "link": "https://openreview.net/forum?id=BMfHO2lXGe",
        "pdf_link": "https://openreview.net/pdf?id=BMfHO2lXGe",
        "keywords": "proteins, protein sequence, protein language model, computational biology, generative model, protein engineering, protein fitness prediction, protein design",
        "abstract": "Protein design has important implications for drug discovery, personalized medicine, and biotechnology. Models based on multiple sequence alignments efficiently capture the evolutionary information in homologous protein sequences, but multiple sequence alignment construction is imperfect. We present ProtMamba, a homology-aware but alignment-free protein language model based on the Mamba architecture. In contrast with attention-based models, ProtMamba efficiently handles very long context, comprising hundreds of protein sequences. We train ProtMamba on a large dataset of concatenated homologous sequences, using two GPUs. We combine autoregressive modeling and masked language modeling through a fill-in-the-middle training objective. This makes the model adapted to various protein design applications. We demonstrate ProtMamba's usefulness for the generation of novel sequences and for fitness prediction. ProtMamba reaches competitive performance with other protein language models despite its smaller size, which sheds light on the importance of long-context conditioning."
    }
]
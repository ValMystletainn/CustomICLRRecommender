[{"title": "An Efficient Algorithm For Computing Optimal Wasserstein Ball Center", "link_suffix": "/forum?id=TLmibuPMyi", "link": "https://openreview.net/forum?id=TLmibuPMyi", "pdf_link": "https://openreview.net/pdf?id=TLmibuPMyi", "keywords": "Wasserstein barycenter, model ensembling, fairness", "abstract": "Wasserstein Barycenter (WB) is a fundamental problem in machine learning, whose objective is to find a representative probability measure that minimizes the sum of its Wasserstein distance to given distributions. WB has a number of applications in various areas.  However, in some applications like model ensembling, where it aggregates predictions of different models on the label space, WB may lead to unfair outcome towards underrepresented groups (e.g., a \"minority'' distribution may be far away from the obtained WB under Wasserstein distance). To address this issue, we propose an alternative objective called  ``Wasserstein Ball Center (WBC)''. Specifically, WBC is a distribution that encompasses all input distributions within the minimum Wasserstein distance, which can be formulated as a minmax optimization problem. We show that the WBC problem with fixed support is equivalent to solving a large-scale linear programming (LP) instance, which is quite different from the previous LP model for WB. By incorporating some novel observations on the induced normal equation, we propose an efficient algorithm that accelerates the interior point method by $O(Nm)$ times ($N$ is the number of distributions and $m$ is the support size).  Finally, we conduct a set of experiments on  both synthetic and real-world datasets. We demonstrate the computational efficiency of our algorithm, and showcase its better accuracy on model ensembling under heterogeneous data distributions.", "title_embedding_index": 7550, "title_abs_embedding_index": 7575}, {"title": "One to All: Individual Reweighting for User-Oriented Fairness in Recommender Systems", "link_suffix": "/forum?id=ArW410lq8C", "link": "https://openreview.net/forum?id=ArW410lq8C", "pdf_link": "https://openreview.net/pdf?id=ArW410lq8C", "keywords": "Recommender Systems, Fairness, Reweighting", "abstract": "Recommender systems often manifest biases toward a small user group, resulting in pronounced disparities in recommendation performance, i.e., the User-Oriented Fairness (UOF) issue. Existing research on UOF faces three major limitations, and no single approach effectively addresses all of them. Limitation 1: Post-processing methods fail to address the root cause of the UOF issue. Limitation 2: Some in-processing methods rely heavily on unstable user similarity calculations under severe data sparsity problems. Limitation 3: Other in-processing methods overlook the disparate treatment of individual users within user groups. In this paper, we propose a novel Individual Reweighting for User-Oriented Fairness framework, namely IR-UOF, to address all the aforementioned limitations. IR-UOF serves as a versatile solution applicable across various backbone recommendation models to achieve UOF. The motivation behind IR-UOF is to introduce an in-processing strategy that addresses the UOF issue at the individual level without the need to explore user similarities. We conduct extensive experiments on three real-world datasets using four backbone recommendation models to demonstrate the effectiveness of IR-UOF in mitigating UOF and improving recommendation fairness.", "title_embedding_index": 7551, "title_abs_embedding_index": 7576}, {"title": "Problem-dependent Quantum Circuit Design Based on Entropy Matching", "link_suffix": "/forum?id=YHUOaIbFby", "link": "https://openreview.net/forum?id=YHUOaIbFby", "pdf_link": "https://openreview.net/pdf?id=YHUOaIbFby", "keywords": "Quantum computing, Expressibility, Ansatz design, Linear entropy.", "abstract": "Variational quantum machine learning (QML) have shown great promise for harnessing quantum advantage in machine learning tasks. However, architecture design of quantum circuits employed in these QML algorithms has been poorly explored for practical problems. Specifically, quantum circuits should have sufficient expressibility for modeling complex functions considering the inherent structures of real-world data. Naively increasing the circuit depth could enhance the expressibility of quantum circuits, which also induce the barren plateau problem as a by-product. In this work, we develop an architecture design framework to solve this problem. We use a simple yet effective metric of quantum entanglement, i.e. the linear entropy, to guide the circuit design from the perspective of the input data. First, we quantify the entanglement of input data by calculating the 1-qubit linear entropy of their amplitude encoding states. Then we implement an entropy matching approach to identify the optimal circuit depth that lead to the linear entropy being close the entropy of input data. The effectiveness of circuit designs based on entropy is verified by extensive experimental results. Specifically, we demonstrate that real-world datasets like MNIST images has limited quantum entanglement. Therefore, circuits designed with entropy matching exhibit relatively small depths being free from the barren plateau issue while maintaining benign performances in binary classification tasks. This work not only advances the efficiency of quantum circuit design but also sets the stage for further refinement of QML performance, with broad implications for practical quantum computing applications.", "title_embedding_index": 7552, "title_abs_embedding_index": 7577}, {"title": "How Transformers Implement Induction Heads: Approximation and Optimization Analysis", "link_suffix": "/forum?id=1lFZusYFHq", "link": "https://openreview.net/forum?id=1lFZusYFHq", "pdf_link": "https://openreview.net/pdf?id=1lFZusYFHq", "keywords": "Transformer, mechanisms, approximiation, training dynamics, abrupt transition", "abstract": "Transformers exhibit exceptional in-context learning capabilities, yet the theoretical understanding of the underlying mechanisms remain limited.\nA recent work (Elhage et al., 2021) identified a \"rich\" in-context mechanism known as induction head, contrasting with \"lazy\" $n$-gram models that overlook long-range dependencies.\nIn this work, we provide both approximation and optimization analyses of how transformers implement induction heads.\nIn the approximation analysis, we formalize both standard and generalized induction head mechanisms, and examine whether two-layer single- or multi-head transformers can efficiently implement them, with an emphasis on the distinct role of each transformer submodule.\nFor the optimization analysis, we study the training dynamics on a synthetic mixed target, composed of a 4-gram and an in-context 2-gram component. This setting enables us to precisely characterize the entire training process and uncover anabrupt transitionfrom lazy (4-gram) to rich (induction head) mechanisms as training progresses.", "title_embedding_index": 7553, "title_abs_embedding_index": 7578}, {"title": "MF-LAL: Drug Compound Generation Using Multi-Fidelity Latent Space Active Learning", "link_suffix": "/forum?id=bKAqK7Bh7n", "link": "https://openreview.net/forum?id=bKAqK7Bh7n", "pdf_link": "https://openreview.net/pdf?id=bKAqK7Bh7n", "keywords": "drug discovery, multi-fidelity learning, generative models", "abstract": "Current generative models for drug discovery primarily use molecular docking as an oracle to guide the generation of active compounds. However, such models are often not useful in practice because even compounds with high docking scores do not consistently show experimental activity. More accurate methods for activity prediction exist, such as molecular dynamics based binding free energy calculations, but they are too computationally expensive to use in a generative model. To address this challenge, we propose Multi-Fidelity Latent space Active Learning (MF-LAL), a generative modeling framework that integrates a set of oracles with varying cost-accuracy tradeoffs. Unlike previous approaches that separately learn the surrogate model and generative model, MF-LAL combines the generative and multi-fidelity surrogate models into a single framework, allowing for more accurate activity prediction and higher quality samples. We train MF-LAL with a novel active learning algorithm to further reduce computational cost. Our experiments on two disease-relevant proteins show that MF-LAL produces compounds with significantly better binding free energy scores than other single and multi-fidelity approaches.", "title_embedding_index": 7554, "title_abs_embedding_index": 7579}, {"title": "Do We Need Domain-Specific Embedding Models? An Empirical Investigation", "link_suffix": "/forum?id=powufeT93G", "link": "https://openreview.net/forum?id=powufeT93G", "pdf_link": "https://openreview.net/pdf?id=powufeT93G", "keywords": "Domain Adaptation; Embedding Benchmark; Empirical Analysis", "abstract": "Embedding models play a crucial role in representing and retrieving information across various NLP applications. Recent advancements in Large Language Models (LLMs) have further enhanced the performance of embedding models, which are trained on massive amounts of text covering almost every domain. These models are often benchmarked on general-purpose datasets like Massive Text Embedding Benchmark (MTEB), where they demonstrate superior performance. However, a critical question arises: Is the development of domain-specific embedding models necessary when general-purpose models are trained on vast corpora that already include specialized domain texts? In this paper, we empirically investigate this question, choosing the finance domain as an example. We introduce the Finance Massive Text Embedding Benchmark (FinMTEB), a counterpart to MTEB that consists of financial domain-specific text datasets. We evaluate the performance of seven state-of-the-art embedding models on FinMTEB and observe a significant performance drop compared to their performance on MTEB. To account for the possibility that this drop is driven by FinMTEB's higher complexity, we propose four measures to quantify dataset complexity and control for this factor in our analysis. Our analysis provides compelling evidence that state-of-the-art embedding models struggle to capture domain-specific linguistic and semantic patterns. Moreover, we find that the performance of general-purpose embedding models on MTEB is not correlated with their performance on FinMTEB, indicating the need for domain-specific embedding benchmarks for domain-specific embedding models. This study sheds light on developing domain-specific embedding models in the LLM era.", "title_embedding_index": 7555, "title_abs_embedding_index": 7580}, {"title": "Looking Backward: Retrospective Backward Synthesis for Goal-Conditioned GFlowNets", "link_suffix": "/forum?id=fNMKqyvuZT", "link": "https://openreview.net/forum?id=fNMKqyvuZT", "pdf_link": "https://openreview.net/pdf?id=fNMKqyvuZT", "keywords": "Backward Sampling, Goal-Conditioned Learning, Generative Flow Networks", "abstract": "Generative Flow Networks (GFlowNets), a new family of probabilistic samplers, have demonstrated remarkable capabilities to generate diverse sets of high-reward candidates, in contrast to standard return maximization approaches (e.g., reinforcement learning) which often converge to a single optimal solution. Recent works have focused on developing goal-conditioned GFlowNets, which aim to train a single GFlowNet capable of achieving different outcomes as the task specifies. However, training such models is challenging due to extremely sparse rewards, particularly in high-dimensional problems. Moreover, previous methods suffer from the limited coverage of explored trajectories during training, which presents more pronounced challenges when only offline data is available. In this work, we propose a novel method called \\textbf{R}etrospective \\textbf{B}ackward \\textbf{S}ynthesis (\\textbf{RBS}) to address these critical problems. Specifically, RBS synthesizes new backward trajectories in goal-conditioned GFlowNets to enrich training trajectories with enhanced quality and diversity, thereby introducing copious learnable signals for effectively tackling the sparse reward problem. Extensive empirical results show that our method improves sample efficiency by a large margin and outperforms strong baselines on various standard evaluation benchmarks.", "title_embedding_index": 7556, "title_abs_embedding_index": 7581}, {"title": "Steering Protein Family Design through Profile Bayesian Flow", "link_suffix": "/forum?id=PSiijdQjNU", "link": "https://openreview.net/forum?id=PSiijdQjNU", "pdf_link": "https://openreview.net/pdf?id=PSiijdQjNU", "keywords": "protein family generation, homologous protein generation, protein design, bayesian flow", "abstract": "Protein family design emerges as a promising alternative by combining the advantages of de novo protein design and mutation-based directed evolution. In this paper, we propose ProfileBFN, the Profile Bayesian Flow Networks, for specifically generative modeling of protein families. ProfileBFN extends the discrete Bayesian Flow Network from an MSA profile perspective, which can be trained on single protein sequences by regarding it as a degenerate profile, thereby achieving efficient protein family design by avoiding large-scale MSA data construction and training. Empirical results show that ProfileBFN has a profound understanding of proteins. When generating diverse and novel family proteins, it can accurately capture the structural characteristics of the family. The enzyme produced by it has a significantly higher probability (30 times that of the previous method) to have the corresponding function.", "title_embedding_index": 7557, "title_abs_embedding_index": 7582}, {"title": "Tree-Wasserstein Distance for High Dimensional Data with a Latent Feature Hierarchy", "link_suffix": "/forum?id=nYjAzwor9R", "link": "https://openreview.net/forum?id=nYjAzwor9R", "pdf_link": "https://openreview.net/pdf?id=nYjAzwor9R", "keywords": "diffusion geometry, hyperbolic geometry, tree-Wasserstein distance, high-dimensional hyperbolic tree decoding", "abstract": "Finding meaningful distances between high-dimensional data samples is an important scientific task. To this end, we propose a new tree-Wasserstein distance (TWD) for high-dimensional data with two key aspects. First, our TWD is specifically designed for data with a latent feature hierarchy, i.e., the features lie in a hierarchical space, in contrast to the usual focus on embedding samples in hyperbolic space. Second, while the conventional use of TWD is to speed up the computation of the Wasserstein distance, we use its inherent tree as a means to learn the latent feature hierarchy. The key idea of our method is to embed the features into a multi-scale hyperbolic space using diffusion geometry and then present a new tree decoding method by establishing analogies between the hyperbolic embedding and trees. We show that our TWD computed based on data observations provably recovers the TWD defined with the latent feature hierarchy and that its computation is efficient and scalable. We showcase the usefulness of the proposed TWD in applications to word-document and single-cell RNA-sequencing datasets, demonstrating its advantages over existing TWDs and methods based on pre-trained models.", "title_embedding_index": 7558, "title_abs_embedding_index": 7583}, {"title": "Diff-BBO:  Diffusion-Based Inverse Modeling for Black-Box Optimization", "link_suffix": "/forum?id=Vlo3Gad3YP", "link": "https://openreview.net/forum?id=Vlo3Gad3YP", "pdf_link": "https://openreview.net/pdf?id=Vlo3Gad3YP", "keywords": "Diffusion models, Black-box Optimization, Uncertainty Quantification", "abstract": "Black-box optimization (BBO) aims to optimize an objective function by iteratively querying a black-box oracle in a sample-efficient way.\nWhile prior studies focus on forward approaches to learn surrogates for the unknown objective function, they struggle with steering clear of out-of-distribution and invalid inputs. Recently, inverse modeling approaches that map objective space to the design space with conditional diffusion models have demonstrated impressive capability in learning the data manifold. They have shown promising performance in offline BBO tasks. However, these approaches require a pre-collected dataset. How to design the acquisition function for inverse modeling to actively query new data remains an open question. In this work, we propose diffusion-based inverse modeling for black-box optimization (Diff-BBO), an inverse approach leveraging diffusion models for online BBO problem. Instead of proposing candidates in the design space, Diff-BBO employs a novel acquisition function Uncertainty-aware Exploration (UaE) to propose objective function values. Subsequently, we employ a conditional diffusion model to generate samples based on these proposed values within the design space. We demonstrate that using UaE results in optimal optimization outcomes, supported by both theoretical and empirical evidence.", "title_embedding_index": 7559, "title_abs_embedding_index": 7584}, {"title": "Spectral Compressive Imaging via Unmixing-driven Subspace Diffusion Refinement", "link_suffix": "/forum?id=Q150eWkQ4I", "link": "https://openreview.net/forum?id=Q150eWkQ4I", "pdf_link": "https://openreview.net/pdf?id=Q150eWkQ4I", "keywords": "Spectral compressive imaging, subspace, diffusion, fine-tune", "abstract": "Spectral Compressive Imaging (SCI) reconstruction is inherently ill-posed, offering multiple plausible solutions from a single observation. Traditional deterministic methods typically struggle to effectively recover high-frequency details. Although diffusion models offer promising solutions to this challenge, their application is constrained by the limited training data and high computational demands associated with multispectral images (MSIs), complicating direct training. To address these issues, we propose a novel Predict-and-unmixing-driven-Subspace-Refine framework (PSR-SCI). This framework begins with a cost-effective predictor that produces an initial, rough estimate of the MSI. Subsequently, we introduce a unmixing-driven reversible spectral embedding module that decomposes the MSI into subspace images and spectral coefficients. This decomposition facilitates the adaptation of pre-trained RGB diffusion models and focuses refinement processes on high-frequency details, thereby enabling efficient diffusion generation with minimal MSI data. Additionally, we design a high-dimensional guidance mechanism with imaging consistency to enhance the model's efficacy. The refined subspace image is then reconstructed back into an MSI using the reversible embedding, yielding the final MSI with full spectral resolution. Experimental results on the standard KAIST and zero-shot datasets NTIRE, ICVL, and Harvard show that PSR-SCI enhances visual quality and delivers PSNR and SSIM metrics comparable to existing diffusion, transformer, and deep unfolding techniques. This framework provides a robust alternative to traditional deterministic SCI reconstruction methods.", "title_embedding_index": 7560, "title_abs_embedding_index": 7585}, {"title": "Rethinking Data Selection at Scale: Random Selection is Almost All You Need", "link_suffix": "/forum?id=qUJsX3XMBH", "link": "https://openreview.net/forum?id=qUJsX3XMBH", "pdf_link": "https://openreview.net/pdf?id=qUJsX3XMBH", "keywords": "large language model, supervised fine-tuning, data selection", "abstract": "Supervised fine-tuning (SFT) is crucial for aligning Large Language Models (LLMs) with human instructions. The primary goal during SFT is to select a small yet representative subset of training data from the larger pool, such that fine-tuning with this subset achieves results comparable to or even exceeding those obtained using the entire dataset. However, most existing data selection techniques are designed for small-scale data pools, which fail to meet the demands of real-world SFT scenarios. In this paper, we replicated several self-scoring methods\u2014those that do not rely on external model assistance\u2014on two million-scale datasets, and found that nearly all methods struggled to significantly outperform random selection when dealing with such large-scale data pools. Moreover, our comparisons suggest that, during SFT, diversity in data selection is more critical than simply focusing on high-quality data. We also analyzed the limitations of several current approaches, explaining why they perform poorly on large-scale datasets and why they are unsuitable for such contexts. Finally, we found that filtering data by token length offers a stable and efficient method for improving results. This approach, particularly when training on long-text data, proves highly beneficial for relatively weaker base models, such as Llama3.", "title_embedding_index": 7561, "title_abs_embedding_index": 7586}, {"title": "AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents", "link_suffix": "/forum?id=x9gCQC3rVA", "link": "https://openreview.net/forum?id=x9gCQC3rVA", "pdf_link": "https://openreview.net/pdf?id=x9gCQC3rVA", "keywords": "Large Language Models, Web Agent, Multimodal, Attack", "abstract": "Vision Language Models (VLMs) have revolutionized the creation of generalist web agents, empowering them to autonomously complete diverse tasks on real-world websites, thereby boosting human efficiency and productivity. However, despite their remarkable capabilities, the safety and security of these agents against malicious attacks remain critically underexplored, raising significant concerns about their safe deployment. To uncover and exploit such vulnerabilities in web agents, we provide AdvWeb, a novel black-box attack framework designed against web agents. AdvWeb trains an adversarial prompter model that generates and injects adversarial prompts into web pages, misleading web agents into executing targeted adversarial actions such as inappropriate stock purchases or erroneous bank transactions\u2014actions that could lead to severe consequences. With only black-box access to the web agent, we train and optimize the adversarial prompter model using Direct Policy Optimization (DPO), leveraging both successful and failed attack strings against the target agent. Unlike prior approaches, our adversarial string injection maintains stealth and control: (1) the appearance of the website remains unchanged before and after the attack, making it nearly impossible for users to detect tampering, and (2) attackers can modify specific substrings within the generated adversarial string to seamlessly change the attack objective (e.g., purchasing stocks from a different company), greatly enhancing attack flexibility and efficiency. We conduct extensive evaluations, demonstrating that AdvWeb achieves high success rates in attacking state-of-the-art GPT-4V-based VLM agents across various web tasks in black-box settings. Our findings expose critical vulnerabilities in current LLM/VLM-based agents, emphasizing the urgent need for developing more reliable web agents and implementing effective defenses against such adversarial threats.", "title_embedding_index": 7562, "title_abs_embedding_index": 7587}, {"title": "InstantIR: Blind Image Restoration with Instant Generative Reference", "link_suffix": "/forum?id=ONWLxkNkGN", "link": "https://openreview.net/forum?id=ONWLxkNkGN", "pdf_link": "https://openreview.net/pdf?id=ONWLxkNkGN", "keywords": "blind image restoration; diffusion model; text-to-image model; generative model", "abstract": "Handling test-time unknown degradation is the major challenge in Blind Image Restoration (BIR), necessitating high model generalization. An effective strategy is to incorporate prior knowledge, either from human input or generative model. In this paper, we introduce Instant-reference Image Restoration (InstantIR), a novel diffusion-based BIR method which dynamically adjusts generation condition during inference. We first extract a compact representation of the input via a pre-trained vision encoder. At each generation step, this representation is used to decode current diffusion latent and instantiate it in the generative prior. The degraded image is then encoded with this reference, providing robust generation condition. We observe the variance of generative references fluctuate with degradation intensity, which we further leverage as an indicator for developing a sampling algorithm adaptive to input quality. Extensive experiments demonstrate InstantIR achieves state-of-the-art performance and offering outstanding visual quality. Through modulating generative references with textual description, InstantIR can restore extreme degradation and additionally feature creative restoration.", "title_embedding_index": 7563, "title_abs_embedding_index": 7588}, {"title": "AutoRedTeamer: An Autonomous Red Teaming Agent Against Language Models", "link_suffix": "/forum?id=DVmn8GyjeD", "link": "https://openreview.net/forum?id=DVmn8GyjeD", "pdf_link": "https://openreview.net/pdf?id=DVmn8GyjeD", "keywords": "adversarial robustness, large language models, jailbreaking, ai agents", "abstract": "As large language models (LLMs) become increasingly capable, robust and scalable security evaluation is crucial. While current red teaming approaches have made strides in assessing LLM vulnerabilities, they often rely heavily on human input and fail to provide comprehensive coverage of potential risks. This paper introduces AutoRedTeamer, a unified framework for fully automated, end-to-end red teaming against LLMs. AutoRedTeamer is an LLM-based agent architecture comprising five specialized modules and a novel memory-based attack selection mechanism, enabling deliberate exploration of new attack vectors. AutoRedTeamer supports both seed prompt and risk category inputs, demonstrating flexibility across red teaming scenarios. We demonstrate AutoRedTeamer\u2019s superior performance in identifying potential vulnerabilities compared to existing manual and optimization-based approaches, achieving higher attack success rates by 20% on HarmBench against Llama-3.1-70B while reducing computational costs by 46%. Notably, AutoRedTeamer can break jailbreaking defenses and generate test cases with comparable diversity to human-curated benchmarks. AutoRedTeamer establishes the state of the art for automating the entire red teaming pipeline, a critical step towards comprehensive and scalable security evaluations of AI systems.", "title_embedding_index": 7564, "title_abs_embedding_index": 7589}, {"title": "StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization", "link_suffix": "/forum?id=GhexuBLxbO", "link": "https://openreview.net/forum?id=GhexuBLxbO", "pdf_link": "https://openreview.net/pdf?id=GhexuBLxbO", "keywords": "RAG, Structured Knowledge", "abstract": "Retrieval-augmented generation (RAG) is a key means to effectively enhance large language models (LLMs) in many knowledge-based tasks. \nHowever, existing RAG methods struggle with knowledge-intensive reasoning tasks, because useful information required to these tasks are badly scattered. \nThis characteristic makes it difficult for existing RAG methods to accurately identify key information and perform global reasoning with such noisy augmentation.\nIn this paper, motivated by the cognitive theories that humans convert raw information into various structured knowledge when tackling knowledge-intensive reasoning, we proposes a new framework, StructRAG, which can identify the optimal structure type for the task at hand, reconstruct original documents into this structured format, and infer answers based on the resulting structure. \nExtensive experiments across various knowledge-intensive tasks show that StructRAG achieves state-of-the-art performance, particularly excelling in challenging scenarios, demonstrating its potential as an effective solution for enhancing LLMs in complex real-world applications.", "title_embedding_index": 7565, "title_abs_embedding_index": 7590}, {"title": "Infilling Score: A Pretraining Data Detection Algorithm for Large Language Models", "link_suffix": "/forum?id=9QPH1YQCMn", "link": "https://openreview.net/forum?id=9QPH1YQCMn", "pdf_link": "https://openreview.net/pdf?id=9QPH1YQCMn", "keywords": "Pretraining data detection, Large language models", "abstract": "In pretraining data detection, the goal is to detect whether a given sentence is in the dataset used for training a Large Language Model LLM). Recent methods (such as Min-K % and Min-K%++) reveal that most training corpora are likely contaminated with both sensitive content and evaluation benchmarks, leading to inflated test set performance. These methods sometimes fail to detect samples from the pretraining data, primarily because they depend on statistics composed of causal token likelihoods. We introduce Infilling Score, a new test-statistic based on non-causal token likelihoods. Infilling Score can be computed for autoregressive models without re-training using Bayes rule. A naive application of Bayes rule scales linearly with the vocabulary size. However, we propose a ratio test-statistic whose computation is invariant to vocabulary size. Empirically, our method achieves a significant accuracy gain over state-of-the-art methods including Min-K%, and Min-K%++ on the WikiMIA benchmark across seven models with different parameter sizes. Further, we achieve higher AUC compared to reference-free methods on the challenging MIMIR benchmark. Finally, we create a benchmark dataset consisting of recent data sources published after the release of Llama-3; this benchmark provides a statistical baseline to indicate potential corpora used for Llama-3 training.", "title_embedding_index": 7566, "title_abs_embedding_index": 7591}, {"title": "Solving Token Gradient Conflict in Mixture-of-Experts for Large Vision-Language Model", "link_suffix": "/forum?id=VxvnV6slP0", "link": "https://openreview.net/forum?id=VxvnV6slP0", "pdf_link": "https://openreview.net/pdf?id=VxvnV6slP0", "keywords": "Large Vision-Language Model (LVLM), Mixture-of-Expert (MoE), token-level gradient, conflicting token", "abstract": "The Mixture-of-Experts (MoE) has gained increasing attention in studying Large Vision-Language Models (LVLMs). It uses a sparse model to replace the dense model, achieving comparable performance while activating fewer parameters during inference, thus significantly reducing the inference cost. Existing MoE methods in LVLM encourage different experts to specialize in different tokens, and they usually employ a router to predict the routing of each token. However, the router is not optimized concerning distinct parameter optimization directions generated from tokens within an expert. This may lead to severe interference between tokens within an expert. To address this problem, we propose to use the token-level gradient analysis to Solving Token Gradient Conflict (STGC) in this paper. Specifically, we first use token-level gradients to identify conflicting tokens in experts. After that, we add a regularization loss tailored to encourage conflicting tokens routing from their current experts to other experts, for reducing interference between tokens within an expert. Our method can serve as a plug-in for diverse LVLM methods, and extensive experimental results demonstrate its effectiveness. The code will be publicly available.", "title_embedding_index": 7567, "title_abs_embedding_index": 7592}, {"title": "Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection", "link_suffix": "/forum?id=t15cWqydys", "link": "https://openreview.net/forum?id=t15cWqydys", "pdf_link": "https://openreview.net/pdf?id=t15cWqydys", "keywords": "Decoding, Benchmark, Large Language Models, Autoregressive Decoding", "abstract": "Generative Language Models rely on autoregressive decoding to produce the output sequence token by token. Some tasks, such as preference optimization, require the model to produce task-level output consisting of multiple tokens directly by selecting candidates from a pool as predictions. Determining a task-level prediction from candidates using the ordinary token-level decoding mechanism is constrained by time-consuming decoding and interrupted gradients by discrete token selection. Existing works have been using decoding-free candidate selection methods to obtain candidate probability from initial output logits over vocabulary. Though these estimation methods are widely used, they are not systematically evaluated, especially on end tasks. We introduce an evaluation of a comprehensive collection of decoding-free candidate selection approaches on a comprehensive set of tasks, including five multiple-choice QA tasks with a small candidate pool and four clinical decision tasks with a massive amount of candidates, some with 10k+ options. We evaluate the estimation methods paired with a wide spectrum of foundation LMs covering different architectures, sizes and training paradigms. The results and insights from our analysis could inform the future model design.", "title_embedding_index": 7568, "title_abs_embedding_index": 7593}, {"title": "ConvCodeWorld: Benchmarking Conversational Code Generation in Reproducible Feedback Environments", "link_suffix": "/forum?id=rpouyo09V0", "link": "https://openreview.net/forum?id=rpouyo09V0", "pdf_link": "https://openreview.net/pdf?id=rpouyo09V0", "keywords": "Large language models, Multi-turn code generation, Benchmark", "abstract": "Large language models (LLMs) have proven invaluable for code generation, particularly in interactive settings. However, existing code generation benchmarks fail to capture the diverse feedback encountered in multi-turn interactions, limiting our ability to evaluate LLMs in these contexts. To address this gap, we present a set of novel benchmarks that explicitly model the quality of feedback provided to code generation LLMs. Our contributions are threefold:First, we introduce CONVCODEWORLD, a novel and reproducible environment for benchmarking interactive code generation. CONVCODEWORLD simulates 9 distinct interactive code generation scenarios while systematically combining three types of feedback: (a) compilation feedback; (b) execution feedback with varying test coverage; (c) verbal feedback generated by GPT-4o with different levels of expertise.Second, we introduce CONVCODEBENCH, a fast, static version of benchmark that uses pre-generated feedback logs, eliminating the need for costly dynamic verbal feedback generation while maintaining\nstrong Spearman\u2019s rank correlations (0.82 to 0.99) with CONVCODEWORLD.Third, extensive evaluations of both closed-source and open-source LLMs on CONVCODEWORLD reveal key insights: (a) LLM performance varies significantly based on the feedback provided; (b) Weaker LLMs, with sufficient feedback, can outperform single-turn results of state-of-the-art LLMs without feedback; (c) Training on a specific feedback combination can limit an LLM\u2019s ability to utilize unseen combinations; (d) LLMs solve problems in fewer turns (high MRR) may not solve as many problems overall (high Recall), and vice versa. All implementations and benchmarks will be made publicly available athttps://huggingface.co/spaces/ConvCodeWorld/ConvCodeWorld", "title_embedding_index": 7569, "title_abs_embedding_index": 7594}, {"title": "Enhancing Trust in Large Language Models with Uncertainty-Aware Fine-Tuning", "link_suffix": "/forum?id=dSTSl6QK5m", "link": "https://openreview.net/forum?id=dSTSl6QK5m", "pdf_link": "https://openreview.net/pdf?id=dSTSl6QK5m", "keywords": "Uncertainty quantification, Trustworthiness, Natural Language Generation, Large Language Models (LLMs), Uncertainty-aware Fine-tuning", "abstract": "Large language models (LLMs) have revolutionized the field of natural language processing with their impressive reasoning and question-answering capabilities. However, these models are sometimes prone to generating credible-sounding but incorrect information, a phenomenon known as LLM hallucinations. Reliable uncertainty estimation in LLMs is essential for fostering trust in their generated responses and serves as a critical tool for the detection and prevention of erroneous or hallucinated outputs. To achieve reliable and well-calibrated uncertainty quantification in open-ended and free-form natural language generation, we propose an uncertainty-aware fine-tuning approach for LLMs. This approach enhances the model's ability to provide reliable uncertainty estimates without compromising accuracy, thereby guiding them to produce more trustworthy responses. We introduce a novel uncertainty-aware causal language modeling loss function, grounded in the principles of decision theory. Through rigorous evaluation on multiple free-form question-answering datasets and models, we demonstrate that our uncertainty-aware fine-tuning approach yields better calibrated uncertainty estimates in natural language generation tasks than fine-tuning with the standard causal language modeling loss. Furthermore, the experimental results show that the proposed method significantly improves the model's ability to detect hallucinations and identify out-of-domain prompts.", "title_embedding_index": 7570, "title_abs_embedding_index": 7595}, {"title": "Coupling Category Alignment for Graph Domain Adaptation", "link_suffix": "/forum?id=TbJo3eQvHR", "link": "https://openreview.net/forum?id=TbJo3eQvHR", "pdf_link": "https://openreview.net/pdf?id=TbJo3eQvHR", "keywords": "Graph domain adaptation", "abstract": "Graph domain adaptation (GDA), which transfers knowledge from a labeled source domain to an unlabeled target graph domain, attracts considerable attention in numerous fields. \nEmerging methods commonly employ message-passing neural networks (MPNNs) to learn domain-invariant representations by aligning the entire domain distribution. However, these methods overlook the category-level distribution alignment across different domains, potentially leading to confusion of categories. \nTo address the problem, we propose an effective framework named \\textbf{Co}upling \\textbf{C}ateg{o}ry \\textbf{A}lignment (\\method{}) for GDA, which effectively addresses the category alignment issue with theoretical guarantees.\n\\method{} incorporates a graph convolutional network branch and a graph kernel network branch, which explore graph topology in implicit and explicit manners. To mitigate category-level domain shifts, we leverage knowledge from both branches, iteratively filtering highly reliable samples from the target domain using one branch and fine-tuning the other accordingly. Furthermore, with these reliable target domain samples, we incorporate the coupled branches into a holistic contrastive learning framework. This framework includes multi-view contrastive learning to ensure consistent representations across the dual branches, as well as cross-domain contrastive learning to achieve category-level domain consistency.\nTheoretically, we establish a sharper generalization bound, which ensures the effectiveness of category alignment.\nExtensive experiments on benchmark datasets validate the superiority of the proposed \\method{} compared with baselines.", "title_embedding_index": 7571, "title_abs_embedding_index": 7596}, {"title": "Sample-efficient Imitative Multi-token Decision Transformer for Real-world Driving", "link_suffix": "/forum?id=324fOKW1wO", "link": "https://openreview.net/forum?id=324fOKW1wO", "pdf_link": "https://openreview.net/pdf?id=324fOKW1wO", "keywords": "Reinforcement Learning, Motion Planning, Autonomous Driving", "abstract": "Recent advancements in autonomous driving technologies involve the capability to effectively process and learn from extensive real-world driving data. Current imitation learning and offline reinforcement learning methods have shown remarkable promise in autonomous systems, harnessing the power of offline datasets to make informed decisions in open-loop (non-reactive agents) settings. However, learning-based agents face significant challenges when transferring knowledge from open-loop to closed-loop (reactive agents) environment. The performance is significantly impacted by data distribution shift, sample efficiency, the complexity of uncovering hidden world models and physics. To address these issues, we propose Sample-efficient Imitative Multi-token Decision Transformer (SimDT). SimDT introduces multi-token prediction, online imitative learning pipeline and prioritized experience replay to sequence-modelling reinforcement learning. The performance is evaluated through empirical experiments and results exceed popular imitation and reinforcement learning algorithms both in open-loop and closed-loop settings on Waymax benchmark. SimDT exhibits 41% reduction in collision rate and 18% improvement in reaching the destination compared with the baseline method.", "title_embedding_index": 7572, "title_abs_embedding_index": 7597}, {"title": "K&L: Penetrating Backdoor Defense with Key and Locks", "link_suffix": "/forum?id=ymqLAmqYHW", "link": "https://openreview.net/forum?id=ymqLAmqYHW", "pdf_link": "https://openreview.net/pdf?id=ymqLAmqYHW", "keywords": "backdoor attack, backdoor defense, AI security", "abstract": "Backdoor attacks in machine learning create hidden vulnerability by manipulating the model behaviour with specific triggers. Such attacks often remain unnoticed as the model operates as expected for normal input. Thus, it is imperative to understand the intricate mechanism of backdoor attacks. To address this challenge, in this work, we introduce three key requirements that a backdoor attack must meet. Moreover, we note that current backdoor attack algorithms, whether employing fixed or input-dependent triggers, exhibit a high binding with model parameters, rendering them easier to defend against. To tackle this issue, we propose the Key-Locks algorithm, which separates the backdoor attack process into embedding locks and employing a key for unlocking. This method enables the adjustment of unlocking levels to counteract diverse defense mechanisms. Extensive experiments are conducted to evaluate the effective of our proposed algorithm. Our code is available at:https://anonymous.4open.science/r/KeyLocks-FD85", "title_embedding_index": 7573, "title_abs_embedding_index": 7598}, {"title": "CerebroVoice: A Stereotactic EEG Dataset and Benchmark for Bilingual Brain-to-Speech Synthesis and Activity Detection", "link_suffix": "/forum?id=3sfOGsBh85", "link": "https://openreview.net/forum?id=3sfOGsBh85", "pdf_link": "https://openreview.net/pdf?id=3sfOGsBh85", "keywords": "Brain-to-speech Synthesis, Voice Activity Detection, Stereotactic Electroencephalograph, Bilingual and Tonal Speech, Brain Computer Interface", "abstract": "Brain signal to speech synthesis offers a new way of speech communication, enabling innovative services and applications. With high temporal and spatial resolution, invasive brain sensing such as stereotactic electroencephalography (sEEG) becomes one of the promising solutions to decode complex brain dynamics. However, such data are hard to come by. In this paper, we introduce a bilingual brain-to-speech synthesis (CerebroVoice) dataset: the first publicly accessible sEEG recordings curated for bilingual brain-to-speech synthesis. Specifically, the CerebroVoice dataset comprises sEEG signals recorded while the speakers are reading Chinese Mandarin words, English words, and Chinese Mandarin digits. \nWe establish benchmarks for two tasks on the CerebroVoice dataset: speech synthesis and voice activity detection (VAD). For the speech synthesis task, the objective is to reconstruct the speech uttered by the participants based on their sEEG recordings. We adopt FastSpeech2 as the baseline model and propose a novel framework, Mixture of Bilingual Synergy Experts (MoBSE), which uses a language-aware dynamic organization of low-rank expert weights to enhance the efficiency of language-specific decoding tasks. The proposed MoBSE framework achieves significant performance improvements over FastSpeech2 across all subjects, producing more natural and intelligible reconstructed speech. \nThe VAD task aims to determine whether the speaker is actively speaking. In this benchmark, we adopt three established architectures and provide comprehensive evaluation metrics to assess their performance. Our findings indicate that low-frequency signals consistently outperform high-gamma activity across all metrics, suggesting that low-frequency filtering is more effective for VAD tasks. This finding provides valuable insights for advancing brain-computer interfaces in clinical applications. \nThe CerebroVoice dataset and benchmarks are publicly available on Zenodo and GitHub for research purposes.", "title_embedding_index": 7574, "title_abs_embedding_index": 7599}]
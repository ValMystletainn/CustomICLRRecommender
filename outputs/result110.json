[
    {
        "title": "Propagation Alone is Enough for Graph Contrastive Learning",
        "link_suffix": "/forum?id=cklg91aPGk",
        "link": "https://openreview.net/forum?id=cklg91aPGk",
        "pdf_link": "https://openreview.net/pdf?id=cklg91aPGk",
        "keywords": "graph contrastive learning, polynomial GNNs",
        "abstract": "Graph contrastive learning has recently gained substantial attention, leading to the development of various methodologies. In this work, we reveal that a simple training-free propagation method PROP achieves competitive results over dedicatedly designed GCL methods across a diverse set of benchmarks. We elucidate the underlying rationale for PROP’s effectiveness by drawing connections between the propagation operator and established unsupervised learning algorithms. To investigate the reasons for the suboptimal performance of existing GCL methods, we decouple the propagation and transformation phases of graph neural networks. Our findings indicate that GCL inadequately learns effective transformation weights while exhibiting potential for solid propagation learning. In light of these insights, we enhance PROP with learnable propagation, introducing a novel GCL method termed PROPGCL. The effectiveness of PROPGCL is demonstrated through comprehensive evaluations."
    },
    {
        "title": "HR-Extreme: A High-Resolution Dataset for Extreme Weather Forecasting",
        "link_suffix": "/forum?id=5AtlfHYCPa",
        "link": "https://openreview.net/forum?id=5AtlfHYCPa",
        "pdf_link": "https://openreview.net/pdf?id=5AtlfHYCPa",
        "keywords": "Weather Forecast Dataset, Extreme Weather, Deep Learning, Numerical Weather Prediction",
        "abstract": "The application of large deep learning models in weather forecasting has led to\nsignificant advancements in the field, including higher-resolution forecasting and\nextended prediction periods exemplified by models such as Pangu and Fuxi. Despite\nthese successes, previous research has largely been characterized by the neglect\nof extreme weather events, and the availability of datasets specifically curated for\nsuch events remains limited. Given the critical importance of accurately forecasting\nextreme weather, this study introduces a comprehensive dataset that incorporates\nhigh-resolution extreme weather cases derived from the High-Resolution Rapid\nRefresh (HRRR) data, a 3-km real-time dataset provided by NOAA. We also\nevaluate the current state-of-the-art deep learning models and Numerical Weather\nPrediction (NWP) systems on HR-Extreme, and provide a improved baseline\ndeep learning model called HR-Heim which has superior performance on both\ngeneral loss and HR-Extreme compared to others. Our results reveal that the\nerrors of extreme weather cases are significantly larger than overall forecast error,\nhighlighting them as an crucial source of loss in weather prediction. These findings\nunderscore the necessity for future research to focus on improving the accuracy of\nextreme weather forecasts to enhance their practical utility"
    },
    {
        "title": "High Fidelity Text-Guided Music Editing via Single-Stage Flow Matching",
        "link_suffix": "/forum?id=oYLayGfWcI",
        "link": "https://openreview.net/forum?id=oYLayGfWcI",
        "pdf_link": "https://openreview.net/pdf?id=oYLayGfWcI",
        "keywords": "Flow matching, music generation, style transfer",
        "abstract": "We introduce MelodyFlow, an efficient text-controllable high-fidelity music generation and editing model. It operates on continuous latent representations from a low frame rate 48 kHz stereo variational auto encoder codec. Based on a diffusion transformer architecture trained on a flow-matching objective the model can edit diverse high quality stereo samples of variable duration, with simple text descriptions. We adapt the ReNoise latent inversion method to flow matching and compare it with the original implementation and naive denoising diffusion implicit model (DDIM) inversion on a variety of music editing prompts. Our results indicate that our latent inversion outperforms both ReNoise and DDIM for zero-shot test-time text-guided editing on several objective metrics. Subjective evaluations exhibit a substantial improvement over previous state of the art for music editing. Code and model weights will be publicly made available. Samples are available athttps://melodyflow.github.io."
    },
    {
        "title": "A Dynamic Model of Performative Human-ML Collaboration: Theory and Empirical Evidence",
        "link_suffix": "/forum?id=4wmf3Ffhl2",
        "link": "https://openreview.net/forum?id=4wmf3Ffhl2",
        "pdf_link": "https://openreview.net/pdf?id=4wmf3Ffhl2",
        "keywords": "Human-AI Collaboration, Human-Computer Interaction, Dynamic Systems, performative prediction, strategic behavior, human-in-the-loop, dynamic learning, deployment strategies",
        "abstract": "Machine learning (ML) models are increasingly used in various applications, from recommendation systems in e-commerce to diagnosis prediction in healthcare. \nIn this paper, we present a novel dynamic framework for thinking about the deployment of ML models in a performative, human-ML collaborative system. In our framework, the introduction of ML recommendations changes the data-generating process of human decisions, which are only a proxy to the ground truth and which are then used to train future versions of the model. We show that this dynamic process in principle can converge to different stable points, i.e. where the ML model and the Human+ML system have the same performance. Some of these stable points are suboptimal with respect to the actual ground truth. As a proof of concept, we conduct an empirical user study with 1,408 participants. In the study, humans solve instances of the knapsack problem with the help of machine learning predictions of varying performance. This is an ideal setting because we can identify the actual ground truth, and evaluate the performance of human decisions supported by ML recommendations. We find that for many levels of ML performance, humans can improve upon the ML predictions. We also find that the improvement could be even higher if humans rationally followed the ML recommendations. Finally, we test whether monetary incentives can increase the quality of human decisions, but we fail to find any positive effect. Using our empirical data to approximate our collaborative system suggests that the learning process would dynamically reach an equilibrium performance that is around 92% of the maximum knapsack value. Our results have practical implications for the deployment of ML models in contexts where human decisions may deviate from the indisputable ground truth."
    },
    {
        "title": "DOTA: Distributional Test-Time Adaptation of Vision-Language Models",
        "link_suffix": "/forum?id=yD2JMeKumt",
        "link": "https://openreview.net/forum?id=yD2JMeKumt",
        "pdf_link": "https://openreview.net/pdf?id=yD2JMeKumt",
        "keywords": "Test-time, uncertainty, vision-language models",
        "abstract": "Vision-language foundation models (e.g., CLIP) have shown remarkable performance across a wide range of tasks. However, deploying these models may be unreliable when significant distribution gaps exist between the training and test data. The training-free test-time dynamic adapter (TDA) is a promising approach to address this issue by storing representative test samples to guide the classification of subsequent ones. However, TDA only naively maintains a limited number of reference samples in the cache, leading to severe test-time catastrophic forgetting when the cache is updated by dropping samples. In this paper, we propose a simple yet effective method for DistributiOnal Test-time Adaptation (DOTA). Instead of naively memorizing representative test samples, DOTA continually estimates the distributions of test samples, allowing the model to continually adapt to the deployment environment. The test-time posterior probabilities are then computed using the estimated distributions based on Bayes' theorem for adaptation purposes. To further enhance the adaptability on the uncertain samples, we introduce a new human-machine collaboration paradigm which identifies uncertain samples, collects human-feedback, and incorporates it into the DOTA framework. Extensive experiments validate that DOTA enables CLIP to continually learn, resulting in a significant improvement compared to current state-of-the-art methods."
    },
    {
        "title": "A Discrete Actor and Critic for Reinforcement Learning on Continuous Tasks",
        "link_suffix": "/forum?id=EWKPEtwjTy",
        "link": "https://openreview.net/forum?id=EWKPEtwjTy",
        "pdf_link": "https://openreview.net/pdf?id=EWKPEtwjTy",
        "keywords": "reinforcement Learning, discrete action space, continuous control, bipedal locomotion",
        "abstract": "Solving continuous reinforcement learning (RL) tasks typically requires models with continuous action spaces, as discrete models face challenges such as the curse of dimensionality. Inspired by discrete controlling signals in control systems, such as pulse-width modulation, we investigated RL models with discrete action spaces with performance comparable to continuous models on continuous tasks. In this paper, we propose an RL model with a discrete action space, designed a discrete actor that outputs action distributions and twin discrete critics for value distribution estimation. We also developed both the training method and exploration strategy for this model. The model successfully solved BipedalWalkerHardcore-v3, a continuous robot control task in a complex environment, achieved a higher score than the state-of-the-art baselines and comparable results across various other control tasks."
    },
    {
        "title": "Unsupervised Radar Point Cloud Enhancement Using Diffusion Model as Prior without Paired Traning Data",
        "link_suffix": "/forum?id=lf4ukMSl7o",
        "link": "https://openreview.net/forum?id=lf4ukMSl7o",
        "pdf_link": "https://openreview.net/pdf?id=lf4ukMSl7o",
        "keywords": "Radar, Point Cloud Enhancement, Diffusion Model, Inverse Problem, Autonomous Driving",
        "abstract": "In industrial automation technology, radar is one of the crucial sensors in the machine perception stage. However, due to the long wavelength of radar electromagnetic waves and the limited number of antennas, the angle resolution is limited. Recent advancements have introduced methods that leverage paired LiDAR-radar data for training, achieving notable point enhancement effect. However, the requirement for paired data significantly increases the cost and complexity of model development, limiting model’s widespread adoption and scalability. To address this, we propose an unsupervised radar point cloud enhancement algorithm using diffusion model as prior without paired training data. Specifically, our method formulates radar angle estimation recovery into an inverse problem and introduces prior knowledge via a diffusion model when solving it. Experimental results demonstrate that our method achieves high fidelity and low noise performance compared to traditional regularization methods. Compared to paired data training methods, our approach not only delivers comparable performance but also offers greater content control and reduced generation variance. Additionally, it does not require a huge amount of paired data. To the best of our knowledge, our method is the first to enhance radar point cloud by introducing prior knowledge via diffusion model instead of training on paired data."
    },
    {
        "title": "MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs",
        "link_suffix": "/forum?id=5ck9PIrTpH",
        "link": "https://openreview.net/forum?id=5ck9PIrTpH",
        "pdf_link": "https://openreview.net/pdf?id=5ck9PIrTpH",
        "keywords": "Arithmetic reasoning, evaluation, proofs, large language models",
        "abstract": "Large language models (LLMs) display impressive performance on reasoning tasks such as mathematical word-problem solving. However, little is known about how well they generalize to problems that are more complex than the ones they have been trained on. Empirical investigations of such questions are impeded by two major flaws of current evaluations: (1) much of the evaluation data is contaminated, in the sense that it has already been seen during training, and (2) benchmark datasets do not capture how problem proofs may be arbitrarily complex (in various ways). As a step towards addressing these issues, we present a framework for evaluating LLMs on problems that have arbitrarily complex arithmetic proofs, called MathGAP. MathGAP generates problems that follow fixed proof specifications---along with chain-of-thought reasoning annotations---enabling systematic studies on generalization with respect to arithmetic proof complexity. We apply MathGAP to analyze how in-context learning interacts with generalization to problems with more complex proofs. We find that among the models tested, most show a significant decrease in performance as proofs get deeper and wider. This effect is more pronounced in complex, nonlinear proof structures, which are challenging even for GPT-4o. Our results also corroborate previous findings from other domains that, surprisingly, providing in-context examples from the same distribution as the test set is not always beneficial for performance. In particular, both zero-shot prompting as well as demonstrating a diverse range of examples that are less complex than the test data sometimes yield higher accuracy."
    },
    {
        "title": "TrustSQL: Benchmarking Text-to-SQL Reliability with Penalty-Based Scoring",
        "link_suffix": "/forum?id=7ZeoPg3eTA",
        "link": "https://openreview.net/forum?id=7ZeoPg3eTA",
        "pdf_link": "https://openreview.net/pdf?id=7ZeoPg3eTA",
        "keywords": "Text-to-SQL, Text-to-SQL Reliability, database question-answering",
        "abstract": "Text-to-SQL allows users to interact with databases using natural language, simplifying information retrieval. However, widespread deployment remains limited for two main reasons: (1) existing benchmarks focus solely on feasible questions that can always be mapped to SQL queries, overlooking infeasible questions that cannot, and (2) current models lack abstention mechanisms, posing the risk of providing incorrect answers. To address these gaps, we introduce TrustSQL, a new benchmark designed to evaluate text-to-SQL reliability—quantified by our proposed Reliability Score (RS) that measures the model's potential helpfulness relative to its harmfulness. TrustSQL is constructed by re-annotating three datasets—ATIS, Advising, and EHRSQL—and incorporating infeasible questions for a more comprehensive evaluation of models on diverse inputs. We evaluate text-to-SQL models integrated with various abstention mechanisms such as using classifiers and uncertainty estimation. Our experiments show that only a few models achieve a positive score under high penalty settings, indicating that most models are unsuitable for deployment as they fail to meet safety requirements (i.e., potential harmfulness outweighs helpfulness). This underscores the need for developing models that not only improve SQL generation but also guarantee a certain degree of reliability. Additionally, we provide detailed analyses across different types of feasible and infeasible questions, offering insights for building more reliable text-to-SQL models."
    },
    {
        "title": "Feature-Based Online Bilateral Trade",
        "link_suffix": "/forum?id=xnF2U0ro7b",
        "link": "https://openreview.net/forum?id=xnF2U0ro7b",
        "pdf_link": "https://openreview.net/pdf?id=xnF2U0ro7b",
        "keywords": "bilateral trade, online learning, contextual bandits",
        "abstract": "Bilateral trade models the problem of facilitating trades between a seller and a buyer having private valuations for the item being sold. In the online version of the problem, the learner faces a new seller and buyer at each time step, and has to post a price for each of the two parties without any knowledge of their valuations. We consider a scenario where, at each time step, before posting prices the learner observes a context vector containing information about the features of the item for sale. The valuations of both the seller and the buyer follow an unknown linear function of the context. In this setting, the learner could leverage previous transactions in an attempt to estimate private valuations. We characterize the regret regimes of different settings, taking as a baseline the best context-dependent prices in hindsight. First, in the setting in which the learner has two-bit feedback and strong budget balance constraints, we propose an algorithm with $O(\\log T)$ regret. Then, we study the same set-up with noisy valuations, providing a tight $\\widetilde O(T^{2/3})$ regret upper bound. Finally, we show that loosening budget balance constraints allows the learner to operate under more restrictive feedback. Specifically, we show how to address the one-bit, global budget balance setting through a reduction from the two-bit, strong budget balance setup. This established a fundamental trade-off between the quality of the feedback and the strictness of the budget constraints."
    },
    {
        "title": "Semi-Supervised Medical Image Segmentation via Knowledge Mining from Large Models",
        "link_suffix": "/forum?id=KRhcZIAcoM",
        "link": "https://openreview.net/forum?id=KRhcZIAcoM",
        "pdf_link": "https://openreview.net/pdf?id=KRhcZIAcoM",
        "keywords": "Foundation Model, Knowledge Mining, Segment Anything Model, Segmentation, Semi-Supervised Learning",
        "abstract": "Large-scale vision models like SAM possess extensive visual knowledge, but their application to specialized tasks like medical image segmentation is often hindered by their general nature and the computational challenges associated with training and finetuning. Locally hosted small models such as U-Net++, designed for specific tasks, struggle with limited performance due to sparse labeled datasets. This study introduces a strategic knowledge mining method as a novel interaction mechanism between large and small models. Our method utilizes SAM’s broad visual understanding to enhance the specialized capabilities of locally hosted small deep learning models. Specifically, we trained a U-Net++ model on a limited labeled dataset and extend its capabilities by converting outputs (masks) produced in unlabeled images into prompts, to extract relevant knowledge from SAM. This process not only harnesses SAM’s generalized visual knowledge but also iteratively improves SAM’s prediction to cater specialized medical segmentation tasks via UNet++. The mined knowledge, serving as ‘pseudo labels’, enriches the training dataset, enabling the fine-tuning of the local network. Applied to the Kvasir SEG and COVID-QU-Ex datasets which consist of gastrointestinal polyp and lung Xray images respectively, our proposed method consistently enhanced the segmentation performance on Dice by 3% and 1% respectively over the baseline U-Net++ model, when the same amount of labelled data were used during training (75% and 50% of labelled data). Remarkably, our proposed method surpassed the baseline U-Net++ model even when the latter was trained exclusively on labeled data (100% of labelled data). These results underscore the potential of knowledge mining to overcome data limitations in specialized models by leveraging the broad, albeit general, knowledge of large-scale models like SAM, all while maintaining operational efficiency essential for clinical applications.The code of our method is publicly available athttps://anonymous.4open.science/r/Knowledge-Mining-from-Large-Models-C7FE."
    },
    {
        "title": "SageLite: Harmonizing Text and Code Through Multi-Stage Training",
        "link_suffix": "/forum?id=9vorqLGgyx",
        "link": "https://openreview.net/forum?id=9vorqLGgyx",
        "pdf_link": "https://openreview.net/pdf?id=9vorqLGgyx",
        "keywords": "unified embedding for text and code, unsupervised learning, multi-stage training",
        "abstract": "Creating versatile embedding models that excel across both text and code domains is essential, as modern applications often involve diverse, heterogeneous data. While data mixing is a typical starting point, we take a significant step forward by addressing the limitations of naive data mixing. In this work, we introduce SageLite, a unified embedding model capable of handling both text and code within a single framework. Our approach begins with pretraining on a blended dataset of text and code, fostering shared representations that are crucial for strong cross-domain performance. We then enhance domain-specific capabilities by independently applying large-scale contrastive learning to text and code from various web sources. Our key finding is that, despite the inherent differences between text and code, starting from a model pretrained on mixed data enables the domain-specific contrastive learning stages to produce models that remain closely aligned. This alignment allows us to effectively integrate domain-specific improvements at the constrastive learning stage into a final model through model weights interpolation. Through comprehensive ablation studies, we explore the mechanisms behind our approach, offering insights to guide future research in this area."
    },
    {
        "title": "Interpretable Causal Representation Learning for Biological Data in the Pathway Space",
        "link_suffix": "/forum?id=3Fgylj4uqL",
        "link": "https://openreview.net/forum?id=3Fgylj4uqL",
        "pdf_link": "https://openreview.net/pdf?id=3Fgylj4uqL",
        "keywords": "Causal Representation Learning, Intepretability, VAE, Genomic Perturbations, Health",
        "abstract": "Predicting the impact of genomic and drug perturbations in cellular function is crucial for understanding gene functions and drug effects, ultimately leading to improved therapies. To this end, Causal Representation Learning (CRL) constitutes one of the most promising approaches, as it aims to identify the latent factors that causally govern biological systems, thus facilitating the prediction of the effect of unseen perturbations. Yet, current CRL methods fail in reconciling their principled latent representations with known biological processes, leading to models that are not interpretable. To address this major issue, in this work we present SENA-discrepancy-VAE, a model based on the recently proposed CRL method discrepancy-VAE, that produces representations where each latent factor can be interpreted as the (linear) combination of the activity of a (learned) set of biological processes. To this extent, we present an encoder, SENA-$\\delta$, that efficiently compute and map biological processes' activity levels to the latent causal factors. We show that SENA-discrepancy-VAE achieves predictive performances on unseen combinations of interventions that are comparable with its original, non-interpretable counterpart, while inferring causal latent factors that are biologically meaningful."
    },
    {
        "title": "LOB-Bench: Benchmarking Generative AI for Finance - with an Application to Limit Order Book Markets",
        "link_suffix": "/forum?id=XsYJ6yvgEC",
        "link": "https://openreview.net/forum?id=XsYJ6yvgEC",
        "pdf_link": "https://openreview.net/pdf?id=XsYJ6yvgEC",
        "keywords": "finance, generative models, time series, state-space models, benchmark",
        "abstract": "We present LOB-Bench, a benchmark designed to evaluate the quality and realism of generative message-by-order data for limit order books (LOB). We enable a rigorous and comprehensive model comparison by providing both a theoretical framework and an open-source Python package. Addressing the lack of consensus on evaluation paradigms in the literature, where qualitative comparison of stylized facts is prevalent, our work offers a crucial building block for advancing generative AI for financial data. LOB-Bench provides a standardized method to numerically assess the quality of various model classes that generate limit order book data in the widely used LOBSTER format. It provides a range of quantitative characteristics and uses a simple parametric benchmark model as a baseline. Potential model classes include autoregressive models, (C)GANs, and agent-based models. Our framework measures distributional differences in conditional and unconditional statistics between generated and real LOB data, supporting a flexible multivariate statistical evaluation. The benchmark features commonly used LOB statistics such as spread, order book volumes, order imbalance, and message inter-arrival times, along with adversarial scores derived from a neural network trained to differentiate between real and generated data. Additionally, LOB-Bench evaluates \"market impact metrics\" by computing cross-correlations and price response functions for specific events in the data. We present empirical benchmark results for a generative autoregressive state-space model and results for a (C)GAN and parametric LOB model. We find that the autoregressive GenAI approach beats traditional model classes."
    },
    {
        "title": "Pushing the Limit of Small-Efficient Offline Reinforcement Learning",
        "link_suffix": "/forum?id=mcDAY9PoDJ",
        "link": "https://openreview.net/forum?id=mcDAY9PoDJ",
        "pdf_link": "https://openreview.net/pdf?id=mcDAY9PoDJ",
        "keywords": "offline reinforcement learning, sample efficiency",
        "abstract": "Offline reinforcement learning (RL) has achieved notable progress in recent years. It enables learning optimized policy from fixed offline datasets and, therefore is particularly suitable for decision-making tasks that lack reliable simulators or have environment interaction restrictions. However, existing offline RL methods typically need a large amount of training data to achieve reasonable performance, and offer limited generalizability in out-of-distribution (OOD) regions due to conservative data-related regularizations. This seriously hinders the usability of offline RL in solving many real-world applications, where the available data are often limited. \nIn this study, we introduce a highly sample-efficient offline RL algorithm that learns optimized policy by enabling state-stitching in a compact latent space regulated by the fundamental symmetry in dynamical systems. Specifically, we introduce a time-reversal symmetry (T-symmetry) enforced inverse dynamics model (TS-IDM) to derive well-regulated latent state representations that greatly ease the difficulty of OOD generalization. Within the learned latent space, we can learn a guide-policy to output the latent next state that maximizes the reward, bypassing the conservative action-level behavior constraints as used in typical offline RL algorithms. The final optimized action can then be easily extracted by using the guide-policy's output as the goal state in the learned TS-IDM.\nWe call our method Offline RL via T-symmetry Enforced Latent State-Stitching (TELS).\nOur approach achieves amazing sample efficiency and OOD generalizability, significantly outperforming existing offline RL methods in a wide range of challenging small-sample tasks, even using as few as 1% of the original data in D4RL tasks."
    },
    {
        "title": "Circuit Compositions: Exploring Modular Structures in Transformer-Based Language Models",
        "link_suffix": "/forum?id=u4XyECA6Zd",
        "link": "https://openreview.net/forum?id=u4XyECA6Zd",
        "pdf_link": "https://openreview.net/pdf?id=u4XyECA6Zd",
        "keywords": "Circuit Identification, Modularity, Continuous Sparsification",
        "abstract": "A fundamental question in interpretability research is to what extent neural networks, particularly language models, implement reusable functions via subnetworks that can be composed to perform more complex tasks. Recent developments in mechanistic interpretability have made progress in identifying subnetworks, often referred to as circuits, which represent the minimal computational subgraph responsible for a model’s behavior on specific tasks. However, most studies focus on identifying circuits for individual tasks without investigating how functionally similar circuits relate to each other. To address this gap, we examine the modularity of neural networks by analyzing circuits for highly compositional subtasks within a transformer-based language model. Specifically, given a probabilistic context-free grammar, we identify and compare circuits responsible for ten modular string-edit operations. Our results indicate that functionally similar circuits exhibit both notable node overlap and cross-task faithfulness. Moreover, we demonstrate that the circuits identified can be reused and combined through subnetwork set operations to represent more complex functional capabilities of the model."
    },
    {
        "title": "Separation Power of Equivariant Neural Networks",
        "link_suffix": "/forum?id=RAyRXQjsFl",
        "link": "https://openreview.net/forum?id=RAyRXQjsFl",
        "pdf_link": "https://openreview.net/pdf?id=RAyRXQjsFl",
        "keywords": "Geometric Deep Learning, Theory for Equivariant Neural Networks, Expressive Power",
        "abstract": "The separation power of a machine learning model refers to its ability to distinguish between different inputs and is often used as a proxy for its expressivity. Indeed, knowing the separation power of a family of models is a necessary condition to obtain fine-grained universality results. In this paper, we analyze the separation power of equivariant neural networks, such as convolutional and permutation-invariant networks.\nWe first present a complete characterization of inputs indistinguishable by models derived by a given architecture. From this results, we derive how separability is influenced by hyperparameters and architectural choices—such as activation functions, depth, hidden layer width, and representation types. Notably, all non-polynomial activations, including ReLU and sigmoid, are equivalent in expressivity and reach maximum separation power. Depth improves separation power up to a threshold, after which further increases have no effect. Adding invariant features to hidden representations does not impact separation power. Finally, block decomposition of hidden representations affects separability, with minimal components forming a hierarchy in separation power that provides a straightforward method for comparing the separation power of models."
    },
    {
        "title": "The polytopal complex as a framework to analyze multilayer relu networks",
        "link_suffix": "/forum?id=34SPQ6fbYM",
        "link": "https://openreview.net/forum?id=34SPQ6fbYM",
        "pdf_link": "https://openreview.net/pdf?id=34SPQ6fbYM",
        "keywords": "theory of deep learning + mlp + low dimension + polytopal complex",
        "abstract": "Neural networks have shown superior performance in many different domains.\nHowever, a precise understanding of what even simple architectures actually are\ndoing is not yet achieved, hindering the application of such architectures in safety critical\nembedded systems. To improve this understanding, we think of a network\nas a continuous piecewise linear function. The network decomposes the input space\ninto cells in which the network is an affine function; the resulting cells form a\npolytopal complex. In this paper we provide an algorithm to derive this complex.\nFurthermore, we capture the local and global behavior of the network by computing\nthe maxima, minima, number of cells, local span, and curvature of the complex.\nWith the machinery presented in this paper we can extend the validity of a neural\nnetwork beyond the finite discrete test set to an open neighborhood of this test set,\npotentially covering large parts of the input domain. To show the effectiveness of\nthe proposed method we run various experiments on the effects of width, depth,\nregularisation, and initial seed on these measures. We empirically confirm that\nthe solution found by training is strongly influenced by weight initialization. We\nfurther find that under regularization, less cells capture more of the volume, while\nthe total number of cells stays in the same range. At the same time the total number\nof cells stays in the same range. Together, these findings provide novel insights\ninto the network and its training parameters."
    },
    {
        "title": "Capturing and Mitigating Gradient Aggregation Errors for Fault-Tolerant Distributed Training",
        "link_suffix": "/forum?id=cPZepCZlFW",
        "link": "https://openreview.net/forum?id=cPZepCZlFW",
        "pdf_link": "https://openreview.net/pdf?id=cPZepCZlFW",
        "keywords": "Distributed Training, Fault Tolerance, Infrastructure",
        "abstract": "Capturing and recovering from hardware failures is important in fault-tolerant distributed training to guarantee system efficiency. However, some hardware-related silent data corruption errors during gradient aggregation like bit corruptions or communication noise, are difficult to capture and address, leading to slow or failed convergence. \nTo understand and mitigate these errors, we first mathematically formulate and generalize them as gradient inconsistency. Then, we theoretically analyze how it leads to model divergence accumulated during training and the failed convergence. \nBased on the analytical study, we design PAFT, a fault-tolerant distributed training system with dynamic and asynchronous parameter synchronization. PAFT includes two parts: (1) PAFT-Sync, which mitigates model divergence by periodically synchronizing parameters, and (2) PAFT-Dyn, which minimizes synchronization overhead through dynamic training overlap and synchronization frequency scheduling based on profiled error degrees. Together, they ensure efficient model convergence at scale.  The fault-tolerant synchronization in PAFT is optimized to support commonly used optimizers, e.g., Stochastic Gradient Descent (SGD), SGD momentum, and Adam. \nWe implement PAFT on PyTorch Distributed and train ResNet, GPT-2, and LLaMA-2 on 4$\\sim$ 32 GPUs. Experimental results show that PAFT efficiently defends against gradient aggregation error degrees while maintaining training performance."
    },
    {
        "title": "ADDITIVE SEPARABLE GRAPHON MODELS",
        "link_suffix": "/forum?id=9LHr33MQh2",
        "link": "https://openreview.net/forum?id=9LHr33MQh2",
        "pdf_link": "https://openreview.net/pdf?id=9LHr33MQh2",
        "keywords": "graphon, subgraph counts, low-rank connecting probability matrix, nonparametric statistics, network analysis",
        "abstract": "The graphon function is fundamental to modeling exchangeable graphs, which form the basis for a wide variety of networks. In this paper, we introduce the additive separable model as a new, parsimonious representation of the graphon, capable of generating a low-rank connection probability matrix for network data. This model effectively addresses the well-known identification challenges associated with graphon functions. We develop an efficient estimation approach that leverages subgraph counts to estimate the low-rank connection matrix and uses interpolation to recover the graphon functions, achieving the minimax optimal estimation rate. We provide the convergence rate of our method, and validate its computational efficiency and estimation accuracy through comprehensive simulation studies."
    },
    {
        "title": "HASARD: A Benchmark for Harnessing Safe Reinforcement Learning with Doom",
        "link_suffix": "/forum?id=5BRFddsAai",
        "link": "https://openreview.net/forum?id=5BRFddsAai",
        "pdf_link": "https://openreview.net/pdf?id=5BRFddsAai",
        "keywords": "benchmark, game, doom, vizdoom, 3D, safe RL, reinforcement learning, constraint, difficulty level, PPO, Lagrange, sample-factory, vision, AI safety",
        "abstract": "The advancement of safe reinforcement learning (RL) faces numerous obstacles, including the lack of simulation environments, demanding computational requirements, and a lack of widely accepted benchmarks. To address these challenges, we introduceHASARD(A Benchmark forHArnessingSAfeReinforcement Learning withDoom), tailored for egocentric pixel-based safe RL. HASARD features a suite of diverse and stochastic 3D environments. Unlike prior vision-based 3D task suites with simple navigation objectives, the environments require spatial comprehension, short-term planning, and active prediction to obtain high rewards while ensuring safety. The benchmark offers three difficulty levels to challenge advanced future methods while providing an easier training loop for more streamlined analysis. Accounting for the variety of potential safety protocols, HASARD supports both soft and hard safety constraints. An empirical evaluation of baseline methods highlights their limitations and demonstrates the benchmark's utility, emphasizing unique algorithmic challenges. The difficulty levels offer a built-in curriculum, enabling more efficient learning of safe policies at higher levels. HASARD utilizes heatmaps to visually trace and analyze agent navigation within the environment, offering an interpretive view of strategy development. Our work is the first benchmark to exclusively target vision-based embodied safe RL, offering a cost-effective and insightful way to explore the potential and boundaries of current and future safe RL methods. The environments, code, and baseline implementations will be open-sourced."
    },
    {
        "title": "FlyOrien: A bio-inspired model for incremental learning of object orientation",
        "link_suffix": "/forum?id=jYyste2HLP",
        "link": "https://openreview.net/forum?id=jYyste2HLP",
        "pdf_link": "https://openreview.net/pdf?id=jYyste2HLP",
        "keywords": "bio-inspired, sparse coding, mushroom body, object orientation, continuous-attractor neural network",
        "abstract": "Orientation detection with vision helps navigation, especially in the absence of a reliable magnetic compass or GPS. Inspired by the neural mechanisms of the insect brain, particularly the mushroom body (MB) and the central complex (CX), we propose FlyOrien—a bio-inspired model for object orientation detection. The model mimics the MB for random feature extraction, sparse coding and associative learning, while the CX provides multi-clue sensory integration, enabling interpolation for finer orientation representation. FlyOrien's biologically plausible learning rule allows one-shot learning, eliminating the need for large datasets and repeated training. We tested FlyOrien on a dataset modified for orientation detection, which introduces strong interference between samples sharing the same label. In this challenging context, FlyOrien achieves competitive performance compared to convolutional neural networks (CNNs), significantly reducing both training time and computational resources, making it suitable for real-world applications like robotics, where incremental learning is essential."
    },
    {
        "title": "Identifying single molecule force spectroscopy data using deep learning with physics augmentation",
        "link_suffix": "/forum?id=6IyKniOabO",
        "link": "https://openreview.net/forum?id=6IyKniOabO",
        "pdf_link": "https://openreview.net/pdf?id=6IyKniOabO",
        "keywords": "Single molecule force spectroscopy, protein unfolding, application in single molecule identification, physics augmentation, physics-based Monte Carlo simulation",
        "abstract": "Deciphering the pathways of protein folding and unfolding under tension is essential for deepening our understanding of fundamental biological mechanisms. Such insights offer the potential to develop treatments for a range of incurable and fatal debilitating conditions, including muscular disorders like Duchenne Muscular Dystrophy and neurodegenerative diseases such as Parkinson’s disease. Single molecule force spectroscopy (SMFS) is a powerful technique for investigating forces when domains in proteins fold and unfold. Currently, manual visual inspection remains the primary method for classifying force curves resulting from single proteins; a time-consuming task demanding significant expertise. In this work, we develop a classification strategy to detect measurements arising from single molecules by augmenting deep learning models with the physics of the protein being investigated. We develop a novel physics-based Monte Carlo engine to generate simulated datasets comprising of force curves that originate from a single molecule, multiple molecules, or failed experiments. We show that pre-training deep learning models with the simulated dataset enables high throughput classification of SMFS experimental data with average accuracies of $75.3 \\pm 5.3$% and ROC-AUC of $0.87 \\pm 0.05$. Our physics augmentation strategy does not need expensive expert adjudication of the experimental data where models trained using our strategy show up to 25.9% higher ROC-AUC over the models trained solely on the limited SMFS experimental data. Furthermore, we show that incorporating a small subset of experimental data ($\\sim 100$ examples) through transfer learning improves accuracy by 6.8% and ROC-AUC by 0.06. We have validated our results on three new SMFS experimental datasets. To facilitate further research in this area, we make our datasets available and provide a Python-based toolbox (\\url{https://anonymous.4open.science/r/AFM_ML-2B8C})."
    },
    {
        "title": "Random Feature Models with Learnable Activation Functions",
        "link_suffix": "/forum?id=Pghg8dJnUe",
        "link": "https://openreview.net/forum?id=Pghg8dJnUe",
        "pdf_link": "https://openreview.net/pdf?id=Pghg8dJnUe",
        "keywords": "learnable activation function, random features, interpretability, statistical learning theory",
        "abstract": "Current random feature models typically rely on fixed activation functions, limiting their ability to capture diverse patterns in data. To address this, we introduce the Random Feature model with Learnable Activation Functions (RFLAF), a novel model that significantly enhances the expressivity and interpretability of traditional random feature (RF) models. We begin by studying the RF model with a single radial basis function, where we discover a new kernel and provide the first theoretical analysis on it. By integrating the basis functions with learnable weights, we show that RFLAF can represent a broad class of random feature models whose activation functions belong in $C_c(\\mathbb{R})$. Theoretically, we prove that the model requires only about twice the parameter number compared to a traditional RF model to achieve the significant leap in expressivity. Experimentally, RFLAF demonstrates two key advantages: (1) it performs better across various tasks compared to traditional RF model with the same number of parameters, and (2) the optimized weights offer interpretability, as the learned activation function can be directly inferred from these weights. Our model paves the way for developing more expressive and interpretable frameworks within random feature models."
    },
    {
        "title": "Universal generalization guarantees for Wasserstein distributionally robust models",
        "link_suffix": "/forum?id=0h6v4SpLCY",
        "link": "https://openreview.net/forum?id=0h6v4SpLCY",
        "pdf_link": "https://openreview.net/pdf?id=0h6v4SpLCY",
        "keywords": "generalization guarantees, optimal transport, distributionally robust optimization, nonsmooth analysis",
        "abstract": "Distributionally robust optimization has emerged as an attractive way to train robust machine learning models, capturing data uncertainty and distribution shifts. Recent statistical analyses have proved that generalization guarantees of robust models based on the Wasserstein distance have generalization guarantees that do not suffer from the curse of dimensionality. However, these results are either approximate, obtained in specific cases, or based on assumptions difficult to verify in practice. In contrast, we establish exact generalization guarantees that cover a wide range of cases, with arbitrary transport costs and parametric loss functions, including deep learning objectives with nonsmooth activations. We complete our analysis with an excess bound on the robust objective and an extension to Wasserstein robust models with entropic regularizations."
    }
]
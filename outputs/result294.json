[{"title": "Indirect Gradient Matching for Adversarial Robust Distillation", "link_suffix": "/forum?id=juKVq5dWTR", "link": "https://openreview.net/forum?id=juKVq5dWTR", "pdf_link": "https://openreview.net/pdf?id=juKVq5dWTR", "keywords": "Adversarial Robustness, Adversarial Training, Adversarial Distillation", "abstract": "Adversarial training significantly improves adversarial robustness, but superior performance is primarily attained with large models. \nThis substantial performance gap for smaller models has spurred active research into adversarial distillation (AD) to mitigate the difference. \nExisting AD methods leverage the teacher\u2019s logits as a guide.\nIn contrast to these approaches, we aim to transfer another piece of knowledge from the teacher, the input gradient.\nIn this paper, we propose a distillation module termed Indirect Gradient Distillation Module (IGDM) that indirectly matches the student\u2019s input gradient with that of the teacher.\nExperimental results show that IGDM seamlessly integrates with existing AD methods, significantly enhancing their performance.\nParticularly, utilizing IGDM on the CIFAR-100 dataset improves the AutoAttack accuracy from 28.06% to 30.32% with the ResNet-18 architecture and from 26.18% to 29.32% with the MobileNetV2 architecture when integrated into the SOTA method without additional data augmentation.", "title_embedding_index": 14650, "title_abs_embedding_index": 14675}, {"title": "Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models", "link_suffix": "/forum?id=okEwtOc5Go", "link": "https://openreview.net/forum?id=okEwtOc5Go", "pdf_link": "https://openreview.net/pdf?id=okEwtOc5Go", "keywords": "Vision Language Model, Image Generation, Multi-modality Model", "abstract": "In this work, we introduce Mini-Gemini, a simple and effective framework enhancing multi-modality Vision Language Models (VLMs). Despite the advancements in VLMs facilitating basic visual dialog and reasoning, a performance gap persists compared to advanced models like GPT-4 and Gemini. We try to narrow the gap by mining the potential of VLMs for better performance across various cross-modal tasks %and any-to-any workflow from three aspects, i.e., high-resolution visual tokens, high-quality data, and VLM-guided generation. To enhance visual tokens, we propose to utilize an additional visual encoder for high-resolution refinement without increasing the visual token count. We further construct a high-quality dataset that promotes precise image comprehension and reasoning-based generation, expanding the operational scope of current VLMs. In general, Mini-Gemini further mines the potential of VLMs and empowers current frameworks with image understanding, reasoning, and generation simultaneously. Mini-Gemini supports a series of dense and MoE Large Language Models (LLMs) from 2B to 34B. It is demonstrated to achieve leading performance in several zero-shot benchmarks and even surpasses the developed private models. Code and models will be available to the public.", "title_embedding_index": 14651, "title_abs_embedding_index": 14676}, {"title": "Efficient Visual Transformer by Information Bottleneck Inspired Token Merging", "link_suffix": "/forum?id=Jwgw3znxT3", "link": "https://openreview.net/forum?id=Jwgw3znxT3", "pdf_link": "https://openreview.net/pdf?id=Jwgw3znxT3", "keywords": "Visual Transformer, Token Merging, Information Bottleneck", "abstract": "Self-attention and transformers have been widely used in deep learning. Recent efforts have been devoted to incorporating transformer blocks into different types of neural architectures, including those with convolutions, leading to various vision transformers for computer vision tasks. In this paper, we propose a novel and compact transformer block, Transformer with Information Bottleneck inspired Token Merging, or IBTM. IBTM performs token merging in a learnable scheme. Our IBTM is compatible with many popular and compact transformer networks, such as MobileViT and EfficientViT, and it reduces the FLOPs and the inference time of the vision transformers while maintaining or even improving the prediction accuracy. In the experiments, we replace all the transformer blocks in popular vision transformers, including MobileViT, EfficientViT, ViT, and Swin, with IBTM blocks, leading to IBTM networks with different backbones. The IBTM is motivated by the reduction of the Information Bottleneck (IB), and a novel and separable variational upper bound for the IB loss is derived. The architecture of mask module in our IBTM blocks which generate the token merging mask is designed to reduce the derived upper bound for the IB loss. Extensive results on image classification and object detection evidence that IBTM renders compact and efficient vision transformers with comparable or much better prediction accuracy than the original vision transformers. The code of IBTM is available at \\url{https://anonymous.4open.science/r/IBTM_Transformers-053B/}.", "title_embedding_index": 14652, "title_abs_embedding_index": 14677}, {"title": "Towards Generalization Bounds of GCNs for Adversarially Robust Node Classification", "link_suffix": "/forum?id=cp3aW7C5tD", "link": "https://openreview.net/forum?id=cp3aW7C5tD", "pdf_link": "https://openreview.net/pdf?id=cp3aW7C5tD", "keywords": "Generalization Analysis; Adversarial Learning; Graph Convolution Networks;  Node Classification\uff1bNode Attacks", "abstract": "Adversarially robust generalization of Graph Convolutional Networks (GCNs) has garnered significant attention in various security-sensitive application areas, driven by intrinsic adversarial vulnerability. Albeit remarkable empirical advancement, theoretical understanding of the generalization behavior of GCNs subjected to adversarial attacks remains elusive. To make progress on the mystery, we establish unified high-probability generalization bounds for GCNs in the context of node classification, by leveraging adversarial Transductive Rademacher Complexity (TRC) and developing a novel contraction technique on graph convolution. Our bounds capture the interaction between generalization error and adversarial perturbations, revealing the importance of key quantities in mitigating the negative effects of perturbations, such as low-dimensional feature projection, perturbation-dependent norm regularization, normalized graph matrix, proper number of network layers, etc. Furthermore, we provide TRC-based bounds of popular GCNs with $\\ell_r$-norm-additive perturbations for arbitrary $r\\geq 1$. A comparison of theoretical results demonstrates that specific network architectures (e.g., residual connection) can help alleviate the cumulative effect of perturbations during the forward propagation of deep GCNs. Experimental results on benchmark datasets validate our theoretical findings.", "title_embedding_index": 14653, "title_abs_embedding_index": 14678}, {"title": "Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models", "link_suffix": "/forum?id=e6xFKjo4Cp", "link": "https://openreview.net/forum?id=e6xFKjo4Cp", "pdf_link": "https://openreview.net/pdf?id=e6xFKjo4Cp", "keywords": "machine unlearning, natural language processing, generative language model", "abstract": "Recent advancements in machine learning, particularly in Natural Language Processing (NLP), have led to the development of sophisticated models trained on extensive datasets, yet raising concerns about the potential leakage of sensitive information. In response, regulatory measures such as the European Union's General Data Protection Regulation (GDPR) have driven increasing interest in Machine Unlearning techniques, which enable models to selectively forget specific data entries. Early approaches primarily relied on pre-processing methods, while more recent research has shifted towards training-based unlearning techniques. Despite their effectiveness, most existing methods require access to the original training data, which is often inaccessible. Additionally, directly applying unlearning techniques bear the cost of undermining the model's expressive capabilities. To address these challenges, we introduce theIterativeContrastiveUnlearning (ICU) framework, which consists of three core components: A Knowledge Unlearning Induction module designed to remove specific knowledge through an unlearning loss; A Contrastive Learning Enhancement module to preserve the model's expressive capabilities against the pure unlearning goal; And an Iterative Unlearning Refinement module that  dynamically assess the unlearning extent on specific data pieces and make iterative update. Experimental results demonstrate the efficacy of our ICU method in unlearning sensitive information while maintaining the model's overall performance, offering a promising solution for privacy-conscious machine learning applications.", "title_embedding_index": 14654, "title_abs_embedding_index": 14679}, {"title": "Domain Shift Tuning over Knowledge Gap", "link_suffix": "/forum?id=ijwYWoChN9", "link": "https://openreview.net/forum?id=ijwYWoChN9", "pdf_link": "https://openreview.net/pdf?id=ijwYWoChN9", "keywords": "PEFT, Domain gap, Domain Shift", "abstract": "This paper introduces Domain Shift Tuning (DST), a novel framework designed to guide pre-trained language models (PLMs), including Large Language Models (LLMs), in overcoming domain discrepancies (i.e., source-target).\nPLMs, pre-trained on extensive and diverse corpora, the source domain, often encounter domain gaps after fine-tuning over the target domain.\nUnlike conventional adapters or Parameter-Efficient Fine-Tuning (PEFT) methods, \nDST conceptualizes domain gaps as differences in knowledge encapsulated within multiple subnetworks of PLMs. \nTo bridge this gap, \nour challenge is to find a subnetwork set that corresponds to these pieces of knowledge and their weight.\nThis direction leads DST to employ a lightweight subnetwork, the Knowledge Steering Layer (KSL), and a training objective, Knowledge Distribution Modeling (KDM). \nThese components enable DST to fine-tune PLMs by aligning the knowledge weights of the source domain with those of the target domain. \nExperimental results on diverse datasets demonstrate that DST effectively mitigates the domain gap, allowing PLMs to generate text that closely aligns with even a small target corpus, thereby significantly enhancing domain adaptation for PLMs at lower computational cost.", "title_embedding_index": 14655, "title_abs_embedding_index": 14680}, {"title": "An efficient algorithm for entropic optimal transport under martingale-type constraints", "link_suffix": "/forum?id=PwmEvdXFAv", "link": "https://openreview.net/forum?id=PwmEvdXFAv", "pdf_link": "https://openreview.net/pdf?id=PwmEvdXFAv", "keywords": "Optimal Transport, Martingale Constraints", "abstract": "This work introduces novel computational methods for entropic optimal transport (OT) problems under martingale-type conditions.\nThe problems can map to a prevalent class of OT problems with structural constraints, encompassing the discrete martingale optimal transport (MOT) problem, as the (super-)martingale conditions are equivalent to row-wise (in-)equality constraints on the coupling matrix. Inspired by the recent empirical success of Sinkhorn-type algorithms, we propose an entropic formulation for the MOT problem and introduce Sinkhorn-type algorithms with sparse Newton iterations that utilize the (approximate) sparsity of the Hessian matrix of the dual objective. As exact martingale conditions are typically infeasible, we adopt entropic regularization to find an approximate constraint satisfied solution. We show that in practice the proposed algorithms enjoy both super-exponential convergence and robustness with controllable thresholds for total constraint violations.", "title_embedding_index": 14656, "title_abs_embedding_index": 14681}, {"title": "DiffMove: Human Trajectory Recovery via Conditional Diffusion Model", "link_suffix": "/forum?id=VRFotuGLfM", "link": "https://openreview.net/forum?id=VRFotuGLfM", "pdf_link": "https://openreview.net/pdf?id=VRFotuGLfM", "keywords": "Trajectory recovery, Diffusion model, Self-supervised learning, Human mobility", "abstract": "Recovering human trajectories from incomplete or missing data is crucial for many mobility-based urban applications, e.g., urban planning, transportation, and location-based services. Existing methods mainly rely on recurrent neural networks or attention mechanisms. Though promising, they encounter limitations in capturing complex spatial-temporal dependencies in low-sampling trajectories. Recently, diffusion models show potential in content generation. However, most of proposed methods are used to generate contents in continuous numerical representations, which cannot be directly adapted to the human location trajectory recovery. In this paper, we introduce a conditional diffusion-based trajectory recovery method, namely, DiffMove. It first transforms locations in trajectories into the embedding space, in which the embedding denoising is performed, and then missing locations are recovered by an embedding decoder. DiffMove not only improves accuracy by introducing high-quality generative methods in the trajectory recovery, but also carefully models the transition, periodicity, and temporal patterns in human mobility. Extensive experiments based on two representative real-world mobility datasets are conducted, and the results show significant improvements (an average of 11% in recall) over the baselines.", "title_embedding_index": 14657, "title_abs_embedding_index": 14682}, {"title": "EventFlow: Forecasting Continuous-Time Event Data with Flow Matching", "link_suffix": "/forum?id=fmTY6QQHnQ", "link": "https://openreview.net/forum?id=fmTY6QQHnQ", "pdf_link": "https://openreview.net/pdf?id=fmTY6QQHnQ", "keywords": "temporal point processes, generative models, event sequences", "abstract": "Continuous-time event sequences, in which events occur at irregular intervals, are ubiquitous across a wide range of industrial and scientific domains. The contemporary modeling paradigm is to treat such data as realizations of a temporal point process, which is typically modeled in an autoregressive fashion by a neural network. While autoregressive models are successful in predicting the time of a single subsequent event, their performance is unsatisfactory in forecasting longer horizons due to cascading errors. We propose $\\texttt{EventFlow}$, a non-autoregressive generative model for temporal point processes. Our model builds on the flow matching framework in order to directly learn the joint distributions over event times, side-stepping the autoregressive process. $\\texttt{EventFlow}$ is easy to implement and sample from, and achieves state-of-the-art performance in both unconditional and conditional generation tasks on a set of standard benchmarks.", "title_embedding_index": 14658, "title_abs_embedding_index": 14683}, {"title": "Role of Momentum in Smoothing Objective Function and Generalizability of Deep Neural Networks", "link_suffix": "/forum?id=zv9jedBExg", "link": "https://openreview.net/forum?id=zv9jedBExg", "pdf_link": "https://openreview.net/pdf?id=zv9jedBExg", "keywords": "deep learning theory, degree of smoothing, generalizability, nonconvex optimization, SGD with momentum, smoothing property", "abstract": "For nonconvex objective functions, including deep neural networks, stochastic gradient descent (SGD) with momentum has faster convergence and better generalizability than SGD without momentum, but a theoretical explanation for this is lacking. Adding momentum is thought to reduce stochastic noise, but several studies have argued that stochastic noise actually contributes to the generalizability of the model, which raises a contradiction. We show that the stochastic noise in SGD with momentum smoothes the objective function, the degree of which is determined by the learning rate, the batch size, the momentum factor, the variance of the stochastic gradient, and the upper bound of the gradient norm. By numerically deriving the stochastic noise level in SGD with and without momentum, we provide theoretical findings that help explain the training dynamics of SGD with momentum, which were not explained by previous studies on convergence and stability, and that resolve the contradiction. We also provide experimental results for an image classification task using ResNets that support our assertion that model generalizability depends on the stochastic noise level.", "title_embedding_index": 14659, "title_abs_embedding_index": 14684}, {"title": "Compelling ReLU Networks to Exhibit Exponentially Many Linear Regions at Initialization and During Training", "link_suffix": "/forum?id=zA0oW4Q4ly", "link": "https://openreview.net/forum?id=zA0oW4Q4ly", "pdf_link": "https://openreview.net/pdf?id=zA0oW4Q4ly", "keywords": "linear regions, activation regions, ReLU network, pretraining, network initialization", "abstract": "A neural network with ReLU activations may be viewed as a composition of piecewise linear functions. For such networks, the number of distinct linear regions expressed over the input domain has the potential to scale exponentially with depth, but it is not expected to do so when the initial parameters are chosen randomly. Therefore, randomly initialized models are often unnecessarily large, even when approximating simple functions. To address this issue, we introduce a novel training strategy: we first reparameterize the network weights in a manner that forces the network to exhibit a number of linear regions exponential in depth. Training first on our derived parameters provides an initial solution that can later be refined by directly updating the underlying model weights. This approach allows us to learn approximations of convex, one-dimensional functions that are several orders of magnitude more accurate than their randomly initialized counterparts. We further demonstrate how to extend our approach to multidimensional and non-convex functions, with similar benefits observed.", "title_embedding_index": 14660, "title_abs_embedding_index": 14685}, {"title": "REvolve: Reward Evolution with Large Language Models using Human Feedback", "link_suffix": "/forum?id=cJPUpL8mOw", "link": "https://openreview.net/forum?id=cJPUpL8mOw", "pdf_link": "https://openreview.net/pdf?id=cJPUpL8mOw", "keywords": "Evolutionary Algorithms, Reward Design, Reinforcement Learning, Large Language Models", "abstract": "Designing effective reward functions is crucial to training reinforcement learning (RL) algorithms. However, this design is non-trivial, even for domain experts, due to the subjective nature of certain tasks that are hard to quantify explicitly. In recent works, large language models (LLMs) have been used for reward generation from natural language task descriptions, leveraging their extensive instruction tuning and commonsense understanding of human behavior. In this work, we hypothesize that LLMs, guided by human feedback, can be used to formulate reward functions that reflect human implicit knowledge. We study this in three challenging settings -- autonomous driving, humanoid locomotion, and dexterous manipulation -- wherein notions of ``good\" behavior are tacit and hard to quantify. To this end, we introduce REvolve, a truly evolutionary framework that uses LLMs for reward design in RL. REvolve generates and refines reward functions by utilizing human feedback to guide the evolution process, effectively translating implicit human knowledge into explicit reward functions for training (deep) RL agents. Experimentally, we demonstrate that agents trained on REvolve-designed rewards outperform other state-of-the-art baselines.", "title_embedding_index": 14661, "title_abs_embedding_index": 14686}, {"title": "Task Descriptors Help Transformers Learn Linear Models In-Context", "link_suffix": "/forum?id=lZNb1CVm5O", "link": "https://openreview.net/forum?id=lZNb1CVm5O", "pdf_link": "https://openreview.net/pdf?id=lZNb1CVm5O", "keywords": "Transformer, in-context learning, linear regression, task descriptor", "abstract": "Large language models (LLMs) exhibit strong in-context learning (ICL) ability, which allows the model to make predictions on new examples based on the given prompt. Recently, a line of research (Von Oswald et al., 2023; Aky\u00a8urek et al., 2023; Ahn et al., 2023; Mahankali et al., 2023; Zhang et al., 2024) considered ICL for a simple linear regression setting and showed that the forward pass of Transformers is simulating some variants of gradient descent (GD) algorithms on the in-context examples. In practice, the input prompt usually contains a task descriptor in addition to in-context examples. We investigate how the task description helps ICL in the linear regression setting. Our results show that gradient flow converges to a global minimum for a simple linear model with task descriptors. At the global minimum, the Transformer learns to use the task descriptor effectively to improve its performance. Empirically, we verify our results by showing that the weights converge to the predicted global minimum and Transformers indeed perform better with task descriptors.", "title_embedding_index": 14662, "title_abs_embedding_index": 14687}, {"title": "Diffusion Curriculum: Synthetic-to-Real Data Curriculum via Image-Guided Diffusion", "link_suffix": "/forum?id=0RgLIMh94b", "link": "https://openreview.net/forum?id=0RgLIMh94b", "pdf_link": "https://openreview.net/pdf?id=0RgLIMh94b", "keywords": "Synthetic data, Curriculum Learning, Diffusion Models", "abstract": "Low-quality or scarce data has posed significant challenges for training deep neural networks in practice. While classical data augmentation cannot contribute very different new data, diffusion models opens up a new door to build self-evolving AI by generating high-quality and diverse synthetic data through text-guided prompts. However, text-only guidance cannot control synthetic images' proximity to the original images, resulting in out-of-distribution data detrimental to the model performance. To overcome the limitation, we study image guidance to achieve a spectrum of interpolations between synthetic and real images. With stronger image guidance, the generated images are similar to the training data but hard to learn. While with weaker image guidance, the synthetic images will be easier for model but contribute to a larger distribution gap with the original data. The generated full spectrum of data enables us to build a novel \"Diffusion CurricuLum (DisCL)\". DisCL adjusts the image guidance level of image synthesis for each training stage: It identifies and focuses on hard samples for the model and assesses the most effective guidance level of synthetic images to improve hard data learning. We apply DisCL to two challenging tasks: long-tail (LT) classification and learning from low-quality data. It focuses on lower-guidance images of high-quality to learn prototypical features as a warm-up of learning higher-guidance images that might be weak on diversity or quality. Extensive experiments showcase a gain of 2.7$%$ and 2.1$%$ in OOD and ID macro-accuracy when applying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base model's tail-class accuracy from 4.4$%$ to 23.64$%$ and leads to a 4.02$%$ improvement in all-class accuracy.", "title_embedding_index": 14663, "title_abs_embedding_index": 14688}, {"title": "Beyond Trend and Periodicity: Guide Time Series Forecasting with Textual Cues", "link_suffix": "/forum?id=mfc6FKgtQA", "link": "https://openreview.net/forum?id=mfc6FKgtQA", "pdf_link": "https://openreview.net/pdf?id=mfc6FKgtQA", "keywords": "Time Series Forecasting, Multi-modal Model", "abstract": "This work introduces a novel Text-Guided Time Series Forecasting (TGTSF) task. By integrating textual cues, such as channel descriptions and dynamic news, TGTSF addresses the critical limitations of traditional methods that rely purely on historical data. To support this task, we propose TGForecaster, a robust baseline model that fuses textual cues and time series data using cross-attention mechanisms. We then present four meticulously curated benchmark datasets to validate the proposed framework, ranging from simple periodic data to complex, event-driven fluctuations. Our comprehensive evaluations demonstrate that TGForecaster consistently achieves state-of-the-art performance, highlighting the transformative potential of incorporating textual information into time series forecasting. This work not only pioneers a novel forecasting task but also establishes a new benchmark for future research, driving advancements in multimodal data integration for time series models.", "title_embedding_index": 14664, "title_abs_embedding_index": 14689}, {"title": "MallowsPO: Fine-Tune Your LLM with Preference Dispersions", "link_suffix": "/forum?id=d8cnezVcaW", "link": "https://openreview.net/forum?id=d8cnezVcaW", "pdf_link": "https://openreview.net/pdf?id=d8cnezVcaW", "keywords": "Language Models fine-tuning, learning from human feedback, Mallows ranking model, human preference dispersions", "abstract": "Direct Preference Optimization (DPO) has recently emerged as a popular approach to improve reinforcement learning with human feedback (RLHF), leading to better techniques to fine-tune large language models (LLM). A weakness of DPO, however, lies in its lack of capability to characterize the diversity of human preferences. Inspired by Mallows' theory of preference ranking, we develop in this paper a new approach, theMallowsPO. A distinct feature of this approach is adispersion index, which reflects the dispersion of human preference to prompts. We show that existing DPO models can be reduced to special cases of this dispersion index, thus unified with MallowsPO. More importantly, we demonstrate empirically how to use this dispersion index to enhance the performance of DPO in a broad array of benchmark tasks, from synthetic bandit selection to controllable generation and dialogues, while maintaining great generalization capabilities. MallowsPO is also compatible with other SOTA offline preference optimization methods, boosting nearly 2% extra LC win rate when used as a plugin for fine-tuning Llama3-Instruct.", "title_embedding_index": 14665, "title_abs_embedding_index": 14690}, {"title": "Distribution-Specific Agnostic Conditional Classification With Halfspaces", "link_suffix": "/forum?id=KZEqbwJfTl", "link": "https://openreview.net/forum?id=KZEqbwJfTl", "pdf_link": "https://openreview.net/pdf?id=KZEqbwJfTl", "keywords": "Agnostic linear classification, PAC-learning, Intractability", "abstract": "We study \"selective\" or \"conditional\" classification problems under an agnostic setting. Classification tasks commonly focus on modeling the relationship between features and categories that captures the vast majority of data. In contrast to common machine learning frameworks, conditional classification intends to model such relationships only on a subset of the data defined by some selection rule. Most work on conditional classification either solves the problem in a realizable setting or does not guarantee the error is bounded compared to an optimal solution. In this work, we consider selective/conditional classification by sparse linear classifiers for subsets defined by halfspaces, and give both positive as well as negative results for Gaussian feature distributions. On the positive side, we present the first PAC-learning algorithm for homogeneous halfspace selectors with error guaranteeO(opt), whereoptis the smallest conditional classification error over the given class of classifiers and homogeneous halfspaces. On the negative side, we find that, under cryptographic assumptions, approximating the conditional classification loss within a small additive error is computationally hard even under Gaussian distribution. We prove that approximating conditional classification is at least as hard as approximating agnostic classification in both additive and multiplicative form.", "title_embedding_index": 14666, "title_abs_embedding_index": 14691}, {"title": "Overcoming False Illusions in Real-World Face Restoration with Multi-Modal Guided Diffusion Model", "link_suffix": "/forum?id=m9RNBZewW2", "link": "https://openreview.net/forum?id=m9RNBZewW2", "pdf_link": "https://openreview.net/pdf?id=m9RNBZewW2", "keywords": "Face image restoration, diffusion model", "abstract": "We introduce a novel Multi-modal Guided Real-World Face Restoration (MGFR) technique designed to improve the quality of facial image restoration from low-quality inputs. Leveraging a blend of attribute text prompts, high-quality reference images, and identity information, MGFR can mitigate the generation of false facial attributes and identities often associated with generative face restoration methods. By incorporating a dual-control adapter and a two-stage training strategy, our method effectively utilizes multi-modal prior information for targeted restoration tasks. We also present the Reface-HQ dataset, comprising over 23,000 high-resolution facial images across 5,000 identities, to address the need for reference face training images. Our approach achieves superior visual quality in restoring facial details under severe degradation and allows for controlled restoration processes, enhancing the accuracy of identity preservation and attribute correction. Including negative quality samples and attribute prompts in the training further refines the model's ability to generate detailed and perceptually accurate images.", "title_embedding_index": 14667, "title_abs_embedding_index": 14692}, {"title": "A Causal Framework for Aligning Metrics of Image Quality and Deep Neural Network Robustness", "link_suffix": "/forum?id=ctvVXwUlnw", "link": "https://openreview.net/forum?id=ctvVXwUlnw", "pdf_link": "https://openreview.net/pdf?id=ctvVXwUlnw", "keywords": "image quality assessment, natural robustness", "abstract": "Image quality plays an important role in the performance of deep neural networks (DNNs) and DNNs have been widely shown to exhibit sensitivity to changes in imaging conditions. Large-scale datasets often contain images under a wide range of conditions prompting a need to quantify and understand their underlying quality distribution in order to better characterize DNN performance and robustness. Aligning the sensitivities of image quality metrics and DNNs ensures that estimates of quality can act as priors for image/dataset difficulty independent task models trained/evaluated on the data. Conventional image quality assessment (IQA) seeks to measure and align quality relative to human perceptual judgements, but here we seek a quality measure that is not only sensitive to imaging conditions but also well-aligned with DNN sensitivities. We first ask whether conventional IQA metrics are also informative of DNN performance. In order to answer this question, we reframe IQA from a causal perspective and examine conditions under which quality metrics are predictive of DNN performance. We show theoretically and empirically that current IQA metrics are weak predictors of DNN performance in the context of classification.  We then use our causal framework to provide an alternative formulation and a new image quality metric that is more strongly correlated with DNN performance and can act as a prior on performance without training new task models. Our approach provides a means to directly estimate the quality distribution of large-scale image datasets towards characterizing the relationship between dataset composition and DNN performance.", "title_embedding_index": 14668, "title_abs_embedding_index": 14693}, {"title": "Learning to (Learn at Test Time): RNNs with Expressive Hidden States", "link_suffix": "/forum?id=eifW0W0xgt", "link": "https://openreview.net/forum?id=eifW0W0xgt", "pdf_link": "https://openreview.net/pdf?id=eifW0W0xgt", "keywords": "test-time training", "abstract": "Self-attention performs well in long context but has quadratic complexity. Existing RNN layers have linear complexity, but their performance in long context is limited by the expressive power of their hidden state. We propose a new class of sequence modeling layers with linear complexity and an expressive hidden state. The key idea is to make the hidden state a machine learning model itself, and the update rule a step of self-supervised learning. Since the hidden state is updated by training even on test sequences, our layers are called Test-Time Training (TTT) layers. We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model and a two-layer MLP respectively. We evaluate our instantiations at the scale of 125M to 1.3B parameters, comparing with a strong Transformer and Mamba, a modern RNN. Both TTT-Linear and TTT-MLP match or exceed the baselines. Similar to Transformer, they can keep reducing perplexity by conditioning on more tokens, while Mamba cannot after 16k context. With preliminary systems optimization, TTT-Linear is already faster than Transformer at 8k context and matches Mamba in wall-clock time. TTT-MLP still faces challenges in memory I/O, but shows larger potential in long context, pointing to a promising direction for future research.", "title_embedding_index": 14669, "title_abs_embedding_index": 14694}, {"title": "Memory-Efficient Self-Supervised Contrastive Learning with a Supervised Loss", "link_suffix": "/forum?id=4NgxI6Z74n", "link": "https://openreview.net/forum?id=4NgxI6Z74n", "pdf_link": "https://openreview.net/pdf?id=4NgxI6Z74n", "keywords": "contrastive learning, self-supervised learning, representation learning, machine learning theory", "abstract": "Contrastive Learning (CL) is among the most popular methods for self-supervised representation learning. However, CL requires a large memory and sample size and careful hyperparameter tuning.\nThese factors make it difficult to\nlearn high-quality representations with limited amount of memory. In this work, we theoretically analyze a recently proposed \\textit{supervised} approach, DIET, for self-supervised representation learning. DIET labels every example by its datum index and trains on the labeled data with a supervised loss. DIET does not require a large sample size \nor hyperparameter tuning. However, it falls short when using smaller encoders and is memory intensive due to its massive classifier head.\nGiven its remarkable simplicity, it is not obvious whether DIET can match the performance of CL methods, which explicitly model pairwise interactions between augmented examples. We prove that, perhaps surprisingly, for a linear encoder DIET with MSE loss is equivalent to spectral contrastive loss. Then, we prove that DIET is prone to learning less-noisy features and may not learn all features from the training data. We show feature normalization can provably address this shortcoming and use of a projection head can further boost the performance. Finally, we address the scalability issue of DIET by reducing its memory footprint.\nThe modified approach, namely S-DIET, substantially improves on the linear probe accuracy of DIET across a variety of datasets and models and \noutperforms other SSL methods,\nall with limited memory and without extensive hyperparameter tuning. This makes S-DIET a promising alternative for simple, effective, and memory-efficient representation learning.", "title_embedding_index": 14670, "title_abs_embedding_index": 14695}, {"title": "Conditional LoRA Parameter Generation", "link_suffix": "/forum?id=AjunxrcKa2", "link": "https://openreview.net/forum?id=AjunxrcKa2", "pdf_link": "https://openreview.net/pdf?id=AjunxrcKa2", "keywords": "Neural network parameter generation, conditional neural network, conditional neural network parameter generation", "abstract": "Generative models have achieved remarkable success in image, video, and text domains. Inspired by this, researchers have explored utilizing generative models to generate neural network parameters. However, these efforts have been limited by the parameter size and the practicality of generating high-performance parameters. In this paper, we propose COND P-DIFF, a novel approach that demonstrates the feasibility of controllable high-performance parameter generation, particularly for LoRA (Low-Rank Adaptation) weights, during the fine-tuning process. Specifically, we employ an autoencoder to extract efficient latent representations for parameters. We then train a conditional latent diffusion model to synthesize high-performing model parameters from random noise based on specific task conditions. Experimental results in both computer vision and natural language processing domains consistently demonstrate that COND P-DIFF can generate high-performance parameters conditioned on the given task. Moreover, we observe that the parameter distribution generated by COND P-DIFF exhibits differences compared to the distribution obtained through normal optimization methods, indicating a certain level of generalization capability. Our work paves the way for further exploration of condition-driven parameter generation, offering a promising direction for task-specific adaptation of neural networks.", "title_embedding_index": 14671, "title_abs_embedding_index": 14696}, {"title": "Temporal Difference Learning: Why It Can Be Fast and How It Will Be Faster", "link_suffix": "/forum?id=j3bKnEidtT", "link": "https://openreview.net/forum?id=j3bKnEidtT", "pdf_link": "https://openreview.net/pdf?id=j3bKnEidtT", "keywords": "Reinforcement Learning, Optimization", "abstract": "Temporal difference (TD) learning represents a fascinating paradox: It is the prime example of a divergent algorithm that has not vanished after its instability was proven. On the contrary, TD continues to thrive in reinforcement learning (RL), suggesting that it provides significant compensatory benefits. Empirical evidence supports this, as many RL tasks require substantial computational resources, and TD delivers a crucial speed advantage that makes these tasks solvable. However, it is limited to cases where the divergence issues are absent or negligible for unknown reasons. So far, the theoretical foundations behind the speed-up are also unclear. In our work, we address these shortcomings of TD by employing techniques for analyzing iterative schemes developed over the past century. Our analysis reveals that TD possesses a mechanism enabling efficient mapping into the smallest eigenspace\u2014an operation previously thought to necessitate costly matrix inversion. Notably, this effect is independent of the conditioning of the problem, making it particularly well-suited for RL tasks characterized by rapidly increasing condition numbers through delayed rewards. Our novel theoretical understanding allows us to develop a scalable algorithm that integrates TD\u2019s speed with the reliable convergence of gradient descent (GD). We additionally validate these improvements through a rigorous mathematical proof in two dimensions, as well as experiments on problems where TD and GD falter, providing valuable insights into the future of optimization techniques in artificial intelligence.", "title_embedding_index": 14672, "title_abs_embedding_index": 14697}, {"title": "Distributional Sobolev reinforcement learning", "link_suffix": "/forum?id=P775MtcEEc", "link": "https://openreview.net/forum?id=P775MtcEEc", "pdf_link": "https://openreview.net/pdf?id=P775MtcEEc", "keywords": "Reinforcement learning, distributional reinforcement learnng, Sobolev training of neural networks", "abstract": "Distributional reinforcement learning (DRL) is a framework for learning a complete distribution over returns, rather than merely estimating expectations. In this paper, we further expand DRL by estimating a distribution over the gradient of the state-action value function, in addition to its scalar value. We refer to this method as Distributional Sobolev training. Inspired by Stochastic Value Gradients (SVG), we achieve this by leveraging a one-step world model of the reward and transition distributions implemented using a conditional Variational Autoencoder (cVAE). Our approach is sampled-based and relies on Maximum Mean Discrepancy (MMD) to instantiate the distributional Bellman operator. We first showcase the method on a toy supervised learning problem. We then validate our algorithm in several Mujoco/Brax environments.", "title_embedding_index": 14673, "title_abs_embedding_index": 14698}, {"title": "MMTryon: Multi-Modal Multi-Reference Control for High-Quality Fashion Generation", "link_suffix": "/forum?id=GzLepH6MBB", "link": "https://openreview.net/forum?id=GzLepH6MBB", "pdf_link": "https://openreview.net/pdf?id=GzLepH6MBB", "keywords": "Multi-modal Fashion Generation, Compositional Virtual Try-on", "abstract": "This paper introduces MMTryon, a multi-modal multi-reference VIrtual Try-ON (VITON) framework, which can generate high-quality compositional try-on results by taking a text instruction and multiple garment images as inputs. Our MMTryon addresses three problems overlooked in prior literature: 1) Support of multiple try-on items. Existing methods are commonly designed for single-item try-on tasks (e.g., upper/lower garments, dresses). 2) Specification of dressing style. Existing methods are unable to customize dressing styles based on instructions (e.g., zipped/unzipped, tuck-in/tuck-out, etc.) 3) Segmentation Dependency. They further heavily rely on category-specific segmentation models to identify the replacement regions, with segmentation errors directly leading to significant artifacts in the try-on results. To address the first two issues, our MMTryon introduces a novel multi-modality and multi-reference attention mechanism to combine the garment information from reference images and dressing-style information from text instructions. Besides, to remove the segmentation dependency, MMTryon uses a parsing-free garment encoder and leverages a novel scalable data generation pipeline to convert existing VITON datasets to a form that allows MMTryon to be trained without requiring any explicit segmentation. Extensive experiments on high-resolution benchmarks and in-the-wild test sets demonstrate MMTryon's superiority over existing SOTA methods both qualitatively and quantitatively. MMTryon's impressive performance on multi-item and style-controllable virtual try-on scenarios and its ability to try on any outfit in a large variety of scenarios from any source image, opens up a new avenue for future investigation in the fashion community.", "title_embedding_index": 14674, "title_abs_embedding_index": 14699}]
[{"title": "Selective induction Heads: How Transformers Select Causal Structures in Context", "link_suffix": "/forum?id=bnJgzAQjWf", "link": "https://openreview.net/forum?id=bnJgzAQjWf", "pdf_link": "https://openreview.net/pdf?id=bnJgzAQjWf", "keywords": "Transformers, Markov chain, interpretability, attention, in-context learning", "abstract": "Transformers have exhibited exceptional capabilities in sequence modeling tasks, leveraging self-attention and in-context learning. Critical to this success are induction heads, attention circuits that enable copying tokens based on their previous occurrences. In this work, we introduce a novel framework that showcases transformers' ability to dynamically handle causal structures.Existing works rely on Markov Chains to study the formation of induction heads, revealing how transformers capture causal dependencies and learn transition probabilities in-context. However, they rely on a fixed causal structure that fails to capture the complexity of natural languages, where the relationship between tokens dynamically changes with context.  To this end, our framework varies the causal structure through interleaved Markov chains  with different lags while keeping the transition probabilities fixed. This setting unveils the formation of Selective Induction Heads, a new circuit that endows transformers with the ability to select the correct causal structure in-context. We empirically demonstrate that transformers learn this mechanism to predict the next token by identifying the correct lag and copying the corresponding token from the past. We provide a detailed construction of a 3-layer transformer to implement the selective induction head, and a theoretical analysis proving that this mechanism asymptotically converges to the maximum likelihood solution. Our findings advance the understanding of how transformers select causal structures, providing new insights into their functioning and interpretability.", "title_embedding_index": 18750, "title_abs_embedding_index": 18775}, {"title": "NeuralPlane: Structured 3D Reconstruction in Planar Primitives with Neural Fields", "link_suffix": "/forum?id=5UKrnKuspb", "link": "https://openreview.net/forum?id=5UKrnKuspb", "pdf_link": "https://openreview.net/pdf?id=5UKrnKuspb", "keywords": "3D Reconstruction, 3D Scene Understanding, Scene Abstraction, Neural Rendering", "abstract": "3D maps assembled from planar primitives are compact and expressive in representing man-made environments, making them suitable for a spectrum of applications. In this paper, we presentNeuralPlane, a novel approach that exploresneuralfields for multi-view 3Dplanereconstruction. Our method is centered upon the core idea of distilling geometric and semantic cues from inconsistent 2D plane observations into a unified 3D neural representation, which unlocks the full leverage of plane attributes. This idea is accomplished by NeuralPlane via several key designs, including: 1) a monocular module that generates geometrically smooth and semantically meaningful segments as 2D plane observations, 2) a plane-guided training procedure that implicitly learns accurate plane locations from multi-view plane observations, and 3) a self-supervised feature field termedNeural Coplanarity Fieldthat enables the modeling of scene semantics alongside the geometry. Without relying on plane annotations, our method achieves high-fidelity reconstruction comprising planar primitives that are not only crisp but also well-aligned with the semantic content. Comprehensive experiments on ScanNetv2 and ScanNet++ demonstrate the superiority of our results in both geometry and semantics.", "title_embedding_index": 18751, "title_abs_embedding_index": 18776}, {"title": "PEARL: Parallel Speculative Decoding with Adaptive Draft Length", "link_suffix": "/forum?id=QOXrVMiHGK", "link": "https://openreview.net/forum?id=QOXrVMiHGK", "pdf_link": "https://openreview.net/pdf?id=QOXrVMiHGK", "keywords": "speculative decoding, inference acceleration, large language models", "abstract": "Speculative decoding (SD), where an extra draft model is employed to provide multipledrafttokens first and then the original target model verifies these tokens in parallel, has shown great power for LLM inference acceleration.\nHowever, existing SD methods suffer from the mutual waiting problem, i.e., the target model gets stuck when the draft model isguessingtokens, and vice versa. This problem is directly incurred by the asynchronous execution of the draft model and the target model, and is exacerbated due to the fixed draft length in speculative decoding.\nTo address these challenges, we propose a conceptually simple, flexible, and general framework to boost speculative decoding, namelyParallel spEculative decoding withAdaptive dRaftLength (PEARL). \nSpecifically, PEARL proposespre-verifyto verify the first draft token in advance during the drafting phase, andpost-verifyto generate more draft tokens during the verification phase.\nPEARL parallels the drafting phase and the verification phase via applying the two strategies, and achieves adaptive draft length for different scenarios, which effectively alleviates the mutual waiting problem.\nMoreover, we theoretically demonstrate that the mean accepted tokens of PEARL is more than existingdraft-then-verifyworks.\nExperiments on various text generation benchmarks demonstrate the effectiveness of our PEARL, leading to a superior speedup performance up to4.43$\\times$and1.50$\\times$, compared to auto-regressive decoding and vanilla speculative decoding, respectively.", "title_embedding_index": 18752, "title_abs_embedding_index": 18777}, {"title": "Diffusion-based Extreme Image Compression with Compressed Feature Initialization", "link_suffix": "/forum?id=0TSAIUCwpp", "link": "https://openreview.net/forum?id=0TSAIUCwpp", "pdf_link": "https://openreview.net/pdf?id=0TSAIUCwpp", "keywords": "extreme image compression, diffusion models, compressed feature initialization, residual diffusion", "abstract": "Diffusion-based extreme image compression methods have achieved impressive performance at extremely low bitrates. However, constrained by the iterative denoising process that starts from pure noise, these methods are limited in both fidelity and efficiency. To address these two issues, we present $\\textbf{R}$elay $\\textbf{R}$esidual $\\textbf{D}$iffusion $\\textbf{E}$xtreme $\\textbf{I}$mage $\\textbf{C}$ompression ($\\textbf{RDEIC}$), which leverages compressed feature initialization and residual diffusion. Specifically, we first use the compressed latent features of the image with added noise, instead of pure noise, as the starting point to eliminate the unnecessary initial stages of the denoising process. Second, we design a novel relay residual diffusion that reconstructs the raw image by iteratively removing the added noise and the residual between the compressed and target latent features. Notably, our relay residual diffusion network seamlessly integrates pre-trained stable diffusion to leverage its robust generative capability for high-quality reconstruction. Third, we propose a fixed-step fine-tuning strategy to eliminate the discrepancy between the training and inference phases, further improving the reconstruction quality. Extensive experiments demonstrate that the proposed RDEIC achieves state-of-the-art visual quality and outperforms existing diffusion-based extreme image compression methods in both fidelity and efficiency. The source code and pre-trained models will be released.", "title_embedding_index": 18753, "title_abs_embedding_index": 18778}, {"title": "Deep Learning-based Heuristic Construction for Routing Problems with Dynamic Encoder and Dual-Channel Decoder Architecture", "link_suffix": "/forum?id=IA3wm5vwUl", "link": "https://openreview.net/forum?id=IA3wm5vwUl", "pdf_link": "https://openreview.net/pdf?id=IA3wm5vwUl", "keywords": "Routing problem, Combinatorial optimization, Heuristics, Deep learning", "abstract": "The routing problem is a classic combinatorial optimization challenge. Constructing heuristics using deep learning models presents a promising approach for its resolution. In this paper, we propose a novel model with a dynamic encoder and dual-channel decoder (DEDD) architecture to learn construction heuristics for the routing problem. The dynamic encoder en-codes the node features of the decomposed sub-problems at each selection step, thereby obtaining more accurate node em-beddings. The dual-channel decoder facilitates more diverse node selections at each step, increasing the probability of the model identifying optimal solutions. Additionally, we design an effective node selection strategy to assist the model in choosing nodes at each step. Experimental results on the Traveling Salesman Problem (TSP) and the Capacitated Ve-hicle Routing Problem (CVRP) with up to 1000 nodes demonstrate that the solutions generated by the DEDD model are nearly optimal, underscoring its efficacy.", "title_embedding_index": 18754, "title_abs_embedding_index": 18779}, {"title": "BCE vs. CE in Deep Feature Learning", "link_suffix": "/forum?id=iuTyzHnvP4", "link": "https://openreview.net/forum?id=iuTyzHnvP4", "pdf_link": "https://openreview.net/pdf?id=iuTyzHnvP4", "keywords": "BCE, CE, neural collapse, decision score, classifier bias", "abstract": "When training classification models, it expects that the leaned features are compact within classes, and can well separate different classes. As a dominant loss function to train classification models, the minimization of CE (Cross-entropy) loss can maximize the compactness and distinctiveness, i.e., reaching neural collapse. The recently published works show that BCE (Binary CE) loss performs also well in multi-class tasks. In this paper, we compare BCE and CE in the context of deep feature learning. For the first time, we prove that BCE can also maximize the intra-class compactness and inter-class distinctiveness when reaching its minimum, i.e., leading to neural collapse. We point out that CE measures the relative values of decision scores in the model training, implicitly enhancing the feature properties by classifying samples one-by-one. In contrast, BCE measures the absolute values of decision scores and adjust the positive/negative decision scores across all samples to uniform high/low levels. Meanwhile, the classifier bias in BCE presents a substantial constraint on the samples' decision scores. Thereby, BCE explicitly enhances the feature properties in the training. The experimental results are aligned with above analysis, and show that BCE consistently and significantly improve the classification performance and leads to better compactness and distinctiveness among sample features.", "title_embedding_index": 18755, "title_abs_embedding_index": 18780}, {"title": "Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures", "link_suffix": "/forum?id=nGiGXLnKhl", "link": "https://openreview.net/forum?id=nGiGXLnKhl", "pdf_link": "https://openreview.net/pdf?id=nGiGXLnKhl", "keywords": "RWKV, Visual Perception, Linear Attention", "abstract": "Transformers have revolutionized computer vision and natural language processing, but their high computational complexity limits their application in high-resolution image processing and long-context analysis. This paper introduces Vision-RWKV (VRWKV), a model that builds upon the RWKV architecture from the NLP field with key modifications tailored specifically for vision tasks. Similar to the Vision Transformer (ViT), our model demonstrates robust global processing capabilities, efficiently handles sparse inputs like masked images, and can scale up to accommodate both large-scale parameters and extensive datasets. Its distinctive advantage is its reduced spatial aggregation complexity, enabling seamless processing of high-resolution images without the need for window operations. Our evaluations demonstrate that VRWKV surpasses ViT's performance in image classification and has significantly faster speeds and lower memory usage processing high-resolution inputs. In dense prediction tasks, it outperforms window-based models, maintaining comparable speeds. These results highlight VRWKV's potential as a more efficient alternative for visual perception tasks. Code and models shall be available.", "title_embedding_index": 18756, "title_abs_embedding_index": 18781}, {"title": "GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation", "link_suffix": "/forum?id=y5einmJ0Yx", "link": "https://openreview.net/forum?id=y5einmJ0Yx", "pdf_link": "https://openreview.net/pdf?id=y5einmJ0Yx", "keywords": "Graph Neural Network, Out-of-Distribution Detection", "abstract": "Despite graph neural networks' (GNNs) great success in modelling graph-structured data, out-of-distribution (OOD) test instances still pose a great challenge for current GNNs. One of the most effective techniques to detect OOD nodes is to expose the detector model with an additional OOD node-set, yet the extra OOD instances are often difficult to obtain in practice. Recent methods for image data address this problem using OOD data synthesis, typically relying on pre-trained generative models like Stable Diffusion. However, these approaches require vast amounts of additional data, as well as one-for-all pre-trained generative models, which are not available for graph data. Therefore, we propose the GOLD framework for graph OOD detection, an implicit adversarial learning pipeline with synthetic OOD exposure without pre-trained models. The implicit adversarial training process employs a novel alternating optimisation framework by training: (1) a latent generative model to regularly imitate the in-distribution (ID) embeddings from an evolving GNN, and (2) a GNN encoder and an OOD detector to accurately classify ID data while increasing the energy divergence between the ID embeddings and the generative model's synthetic embeddings. This novel approach implicitly transforms the synthetic embeddings into pseudo-OOD instances relative to the ID data, effectively simulating exposure to OOD scenarios without auxiliary data. Extensive OOD detection experiments are conducted on five benchmark graph datasets, verifying the superior performance of GOLD without using real OOD data compared with the state-of-the-art OOD exposure and non-exposure baselines. The code will be released upon acceptance.", "title_embedding_index": 18757, "title_abs_embedding_index": 18782}, {"title": "Guardians of Image Quality: Benchmarking Defenses Against Adversarial Attacks on Image-Quality Metrics", "link_suffix": "/forum?id=1Q2t6D4dK6", "link": "https://openreview.net/forum?id=1Q2t6D4dK6", "pdf_link": "https://openreview.net/pdf?id=1Q2t6D4dK6", "keywords": "adversarial defenses, image quality assessment, adversarial attacks, image quality metrics, benchmark", "abstract": "Most modern image-quality-assessment (IQA) metrics are based on neural networks, which makes the adversarial robustness of these metrics a critical concern. This paper presents the first comprehensive study of IQA defense mechanisms in response to adversarial attacks on these metrics. We systematically evaluated 29 defense strategies - including adversarial purification, adversarial training, and certified robustness - and applied 14 adversarial attack algorithms in both adaptive and nonadaptive settings to compare these defenses on nine no-reference IQA metrics. Our analysis of the differences between defenses and their applicability to IQA metrics recognizes that a defense technique should preserve IQA scores and image quality. Our proposed benchmark aims to guide the development of IQA defense methods and can evaluate new methods; the latest results are at link hidden for blind review.", "title_embedding_index": 18758, "title_abs_embedding_index": 18783}, {"title": "Are Images Indistinguishable to Humans Also Indistinguishable to Classifiers?", "link_suffix": "/forum?id=MRnZ1KEXSt", "link": "https://openreview.net/forum?id=MRnZ1KEXSt", "pdf_link": "https://openreview.net/pdf?id=MRnZ1KEXSt", "keywords": "synthesis data, diffusion models, generated data, image classification, distribution classification task", "abstract": "The ultimate goal of generative models is to perfectly capture the data distribution. For image generation, common metrics of visual quality (e.g., FID) and the perceived truthfulness of generated images seem to suggest that we are nearing this goal. However, through \\emph{distribution classification} tasks, we reveal that, from the perspective of neural network-based classifiers, even advanced diffusion models are still far from this goal. Specifically, classifiers are able to consistently and effortlessly distinguish real images from generated ones across various settings. Moreover, we uncover an intriguing discrepancy: classifiers can easily differentiate between diffusion models with comparable performance (e.g., U-ViT-H vs. DiT-XL), but struggle to distinguish between models within the same family but of different scales (e.g., EDM2-XS vs. EDM2-XXL). Our methodology carries several important implications. First, it naturally serves as a diagnostic tool for diffusion models by analyzing specific features of generated data. Second, it sheds light on the model autophagy disorder and offers insights into the use of generated data: augmenting real data with generated data is more effective than replacing it.", "title_embedding_index": 18759, "title_abs_embedding_index": 18784}, {"title": "ERiC-UP3Benchmark: E-Commerce Risk Intelligence Classifier for Detecting Infringements Based on Utility Patent and Product Pairs", "link_suffix": "/forum?id=4oj7tYujwP", "link": "https://openreview.net/forum?id=4oj7tYujwP", "pdf_link": "https://openreview.net/pdf?id=4oj7tYujwP", "keywords": "Benchmark; Product-Patent Infringement Detection; Large-scale Multi-Modality Dataset; Contrastive Learning; Retrieval; Domain Gap", "abstract": "Innovation is a key driver of economic and social progress, with Intellectual Property (IP) protection through patents playing a crucial role in safeguarding new creations. For businesses actively producing goods, detecting potential patent infringement is vital to avoid costly litigation and operational disruptions. However, the significant domain gap between products and patents\u2014coupled with the vast scale of existing patent databases\u2014makes infringement detection a complex and challenging task. Besides, the machine learning (ML) community has not widely addressed this problem, partly due to the lack of comprehensive datasets tailored for this task. In this paper, we firstly formulate a new task: detecting potentially infringing patents for a given product represented by multi-modal data, including images and textual descriptions. This task requires a deep understanding of both technical and legal contexts, extending beyond simple text or image matching to assess functional similarities that may not be immediately apparent. To promote research in this challenging area, we further introduce the ERiC-UP$^3$ ($\\textbf{E}$-commerce $\\textbf{R}$isk $\\textbf{i}$ntelligence $\\textbf{C}$lassifier on $\\textbf{U}$tility $\\textbf{P}$atent $\\textbf{P}$roduct $\\textbf{P}$air) benchmark, a large-scale, well-structured dataset comprising over 13-million patent samples and 1 million product samples. It includes 11,000 meticulously annotated infringement pairs for training and 2,000 for testing, all rigorously reviewed by patent experts to ensure high-quality annotations. The dataset reflects real-world scenarios with its multi-modal nature and the necessity for deep functional understanding, offering unique characteristics that set it apart from existing resources. As a case study, we provide results from a series of baseline methods and propose a simple yet effective infringement detection pipeline. We also explore additional approaches that may enhance detection performance, such as text style rewriting, cross-modal matching effectiveness, and image domain alignment. Overall, the ERiC-UP$^3$ benchmark is the first strictly annotated product-patent infringement detection dataset and stands as the largest multi-modal patent dataset, as well as one of the largest multi-modal product datasets available. We aim to advance research extending language and multi-modal models to diverse and dynamic real-world data distributions, fostering innovation and practical solutions in IP infringement detection.", "title_embedding_index": 18760, "title_abs_embedding_index": 18785}, {"title": "CityAnchor: City-scale 3D Visual Grounding with Multi-modality LLMs", "link_suffix": "/forum?id=7nOl5W6xU4", "link": "https://openreview.net/forum?id=7nOl5W6xU4", "pdf_link": "https://openreview.net/pdf?id=7nOl5W6xU4", "keywords": "3D Visual Grounding, Large language model, multi-modality language model", "abstract": "In this paper, we present a 3D visual grounding method called CityAnchor for localizing an urban object in a city-scale point cloud. Recent developments in multiview reconstruction enable us to reconstruct city-scale point clouds but how to conduct visual grounding on such a large-scale urban point cloud remains an open problem. Previous 3D visual grounding system mainly concentrates on localizing an object in an image or a small-scale point cloud, which is not accurate and efficient enough to scale up to a city-scale point cloud. We address this problem with a multi-modality LLM which consists of two stages, a coarse localization and a fine-grained matching. Given the text descriptions, the coarse localization stage locates possible regions on a projected 2D map of the point cloud while the fine-grained matching stage accurately determines the most matched object in these possible regions. We conduct experiments on the CityRefer dataset and a new synthetic dataset annotated by us, both of which demonstrate our method can produce accurate 3D visual grounding on a city-scale 3D point cloud.", "title_embedding_index": 18761, "title_abs_embedding_index": 18786}, {"title": "Subspace Node Pruning", "link_suffix": "/forum?id=k9QklPhLCs", "link": "https://openreview.net/forum?id=k9QklPhLCs", "pdf_link": "https://openreview.net/pdf?id=k9QklPhLCs", "keywords": "Node Pruning, Subspaces, Efficient AI", "abstract": "Efficiency of neural network inference is undeniably important in a time where commercial use of AI models increases daily. Node pruning is the art of removing computational units such as neurons, filters, attention heads, or even entire layers to significantly reduce inference time while retaining network performance. In this work, we propose the projection of unit activations to an orthogonal subspace in which there is no redundant activity and within which we may prune nodes while simultaneously recovering the impact of lost units via linear least squares. We identify that, for effective node pruning, this subspace must be constructed using a triangular transformation matrix, a transformation which is equivalent to and unnormalized Gram-Schmidt orthogonalization. We furthermore show that the order in which units are orthogonalized can be optimised to maximally reduce node activations in our subspace and thereby form a more optimal ranking of nodes. Finally, we leverage these orthogonal subspaces to automatically determine layer-wise pruning ratios based upon the relative scale of node activations in our subspace, equivalent to cumulative variance. Our proposed method reaches state of the art when pruning ImageNet trained VGG-16 and rivals more complex state of the art methods when pruning ResNet-50 networks across a range of pruning ratios.", "title_embedding_index": 18762, "title_abs_embedding_index": 18787}, {"title": "Black-Box Adversarial Attack on Dialogue Generation via Multi-Objective Optimization", "link_suffix": "/forum?id=GnBBSlUb0S", "link": "https://openreview.net/forum?id=GnBBSlUb0S", "pdf_link": "https://openreview.net/pdf?id=GnBBSlUb0S", "keywords": "dialogue generation, adversarial attack, multi-objective optimization, black-box attack", "abstract": "Transformer-based dialogue generation (DG) models are ubiquitous in modern conversational artificial intelligence (AI) platforms.\nThese models, however, are susceptible to adversarial attacks, i.e., prompts that appear textually indiscernible from normal inputs but are maliciously crafted to make the models generate responses incoherent and irrelevant to the conversational context.\nEvaluating the adversarial robustness of DG models is thus crucial to their real-world deployment.\nAdversarial methods typically exploit gradient information and output logits (or probabilities) to effectively modify key input tokens, thereby achieving excellent attack performance.\nNevertheless, such white-box approaches are impractical in real-world scenarios since the models' internal parameters are typically inaccessible.\nWhile black-box methods, which exploit only input prompts and DG models' output responses to craft adversarial attacks, offer a wider applicability, they often suffer from poor performance.In a human-machine conversation, good generated responses are expected to be semantically coherent and textually succinct.\nWe thus formulate adversarial attack on DG models as a bi-objective optimization problem, where input prompts are modified in order to 1) minimize the response coherence, and 2) maximize the generation length.\nIn this paper, we empirically demonstrate that optimizing either objective alone results in subpar performance.\nWe then propose a dialogue generation attack framework (DGAttack) that employs multi-objective optimization to consider both objectives simultaneously when perturbing user prompts to craft adversarial inputs.\nLeveraging the exploration capability of multi-objective evolutionary algorithm due to its intrinsic diversity preservation, DGAttack successfully creates effective adversarial prompts in a true black-box manner, i.e., accessing solely DG models' inputs and outputs.\nExperiments across four benchmark datasets and three language models (i.e., BART, DialoGPT, T5) demonstrate the excellent performance of DGAttack compared to existing white-box, gray-box, and black-box approaches.\nEspecially, benchmarks with large language models (i.e., Llama 3.1 and Gemma 2) suggest that DGAttack is the state-of-the-art black-box adversarial attack on dialogue generation.", "title_embedding_index": 18763, "title_abs_embedding_index": 18788}, {"title": "ESDMotion: End-to-end Motion Prediction Only with SD Maps", "link_suffix": "/forum?id=sEJYPiVEt4", "link": "https://openreview.net/forum?id=sEJYPiVEt4", "pdf_link": "https://openreview.net/pdf?id=sEJYPiVEt4", "keywords": "motion prediction", "abstract": "Motion prediction is a crucial task in autonomous driving. Existing motion prediction models rely on high-definition (HD) maps to provide environmental context for agents. However, offline HD maps require extensive manual annotation, making them costly and unscalable. Online mapping-based methods still require HD map annotation to train the online mapping module, which is costly as well and may also suffer from the issue of out-of-distribution map elements.\nIn this work, we explore conducting motion prediction only with standard-definition (SD) maps which are more readily available and offer broader coverage. One crucial challenge is that SD maps have low resolution and poor alignment accuracy. Directly replacing HD maps with SD maps leads to a significant drop in performance. \nWe introduce end-to-end learning and specially tailored modules for SD maps to solve the problems. Specifically, we propose ESDMotion, the first end-to-end motion prediction framework that uses only SD maps without any HD map supervision. We integrate BEV features obtained from raw sensor data into existing motion prediction models, with tailored designs for anchor-based and anchor-free models respectively. We find that the coarse and misaligned SD maps bring challenges to feature fusion of anchor-free model and on anchor generation of anchor-based model. Thus, we design two novel modules named Enhanced Road Observation and Pseudo Lane Expansion to address these issues. Benefiting from the end-to-end structure and new modules, ESDMotion outperforms the state-of-the-art online mapping-based motion prediction methods by 13.4% in motion prediction performance and narrows the performance gap between HD and SD maps by 73%. We will open source our code and checkpoints.", "title_embedding_index": 18764, "title_abs_embedding_index": 18789}, {"title": "DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving", "link_suffix": "/forum?id=M42KR4W9P5", "link": "https://openreview.net/forum?id=M42KR4W9P5", "pdf_link": "https://openreview.net/pdf?id=M42KR4W9P5", "keywords": "end-to-end autonomous driving", "abstract": "End-to-end autonomous driving (E2E-AD) has emerged as a trend in the field of autonomous driving, promising a data-driven, scalable approach to system design. However, existing E2E-AD methods usually adopt the sequential paradigm of perception-prediction-planning, which leads to cumulative errors and training instability. The manual ordering of tasks also limits the system\u2019s ability to leverage synergies between tasks (for example, planning-aware perception and game-theoretic interactive prediction and planning). Moreover, the dense BEV representation adopted by existing methods brings computational challenges for long-range perception and long-term temporal fusion.  To address these challenges, we present DriveTransformer, a simplified E2E-AD framework for the ease of scaling up, characterized  by three key features: Task Parallelism (All agent, map, and planning queries direct interact with each other at each block), Sparse Representation (Task queries direct interact with raw sensor features), and Streaming Processing (Task queries are stored and passed as history information). As a result, the new framework is composed of three unified operations: task self-attention, sensor cross-attention, temporal cross-attention, which significantly reduces the complexity of system and leads to better training stability. DriveTransformer achieves state-of-the-art performance in both simulated closed-loop benchmark Bench2Drive and real world open-loop benchmark nuScenes with high FPS. We will open source our code and checkpoints.", "title_embedding_index": 18765, "title_abs_embedding_index": 18790}, {"title": "Fine-tuning with Reserved Majority for Noise Reduction", "link_suffix": "/forum?id=ZV7CLf0RHK", "link": "https://openreview.net/forum?id=ZV7CLf0RHK", "pdf_link": "https://openreview.net/pdf?id=ZV7CLf0RHK", "keywords": "large language models, parameter redundancy fine-tuning, noisy reduction", "abstract": "Parameter-efficient fine-tuning (PEFT) has revolutionized supervised fine-tuning, where LoRA and its variants gain the most popularity due to their low training costs and zero inference latency.\nHowever, LoRA tuning not only injects knowledgeable features but also noisy hallucination during fine-tuning, which hinders the utilization of tunable parameters with the increasing LoRA rank.\nIn this work, we first investigate in-depth the redundancies among LoRA parameters with substantial empirical studies.\nAiming to resemble the learning capacity of high ranks from the findings, we set up a new fine-tuning framework, \\textbf{P}arameter-\\textbf{Re}dundant \\textbf{F}ine-\\textbf{T}uning (\\preft), which follows the vanilla LoRA tuning process but is required to reduce redundancies before merging LoRA parameters back to pre-trained models.\nBased on this framework, we propose \\textbf{No}ise reduction with \\textbf{R}eserved \\textbf{M}ajority (\\norm), which decomposes the LoRA parameters into majority parts and redundant parts with random singular value decomposition.\nThe major components are determined by the proposed \\search method, specifically employing subspace similarity to confirm the parameter groups that share the highest similarity with the base weight.\nBy employing \\norm, we enhance both the learning capacity and benefits from larger ranks, which consistently outperforms both LoRA and other \\preft-based methods on various downstream tasks, such as general instruction tuning, math reasoning and code generation.", "title_embedding_index": 18766, "title_abs_embedding_index": 18791}, {"title": "IMPROVING FLOW FIELD PREDICTION OF COMPLEX GEOMETRIES USING SIMPLE GEOMETRIES", "link_suffix": "/forum?id=JXogIgQV86", "link": "https://openreview.net/forum?id=JXogIgQV86", "pdf_link": "https://openreview.net/pdf?id=JXogIgQV86", "keywords": "Computational Fluid Dynamics, Tandem Airfoils, Geometry Representations, Graph Neural Network, Machine Learning for Sciences", "abstract": "In this study, we address the challenge of computationally expensive simulations of complex geometries, which are crucial for modern engineering design processes. While neural network-based flow field predictions have been suggested, prior studies generally exclude complex geometries. Our objective is to enhance flow predictions around complex geometries, which may often be deconstructed into multiple single, simple bodies, by leveraging existing data on these simple geometry flow fields. Using a case study of tandem-airfoils, we introduce a method employing the directional integrated distance representation for multiple objects, a residual pre-training scheme based on the freestream condition as a physical prior, and a residual training scheme utilising smooth combinations of single airfoil flow fields, also capitalising on the freestream condition. To optimise memory usage during training in large domains and improve prediction performance, we decom- pose simulation domains into smaller sub-domains, each processed by a different network. Extensive experiments on four new tandem-airfoil datasets, comprising over 2000 fluid simulations, demonstrate that our proposed method and techniques effectively enhance tandem-airfoil prediction accuracy by up to 96%.", "title_embedding_index": 18767, "title_abs_embedding_index": 18792}, {"title": "Federated Instruction Tuning of LLMs with Domain Coverage Augmentation", "link_suffix": "/forum?id=qg9BBAXAHN", "link": "https://openreview.net/forum?id=qg9BBAXAHN", "pdf_link": "https://openreview.net/pdf?id=qg9BBAXAHN", "keywords": "Federated Learning, Large Language Model, Instruction Tuning", "abstract": "Federated Domain-specific Instruction Tuning (FedDIT) utilizes limited cross-client private data together with server-side public data for instruction augmentation, ultimately boosting model performance within specific domains. To date, the factors affecting FedDIT remain unclear, and existing instruction augmentation methods primarily focus on the centralized setting without considering distributed environments. Our experiments reveal that the cross-client domain coverage, rather than data heterogeneity, drives model performance in FedDIT. In response, we propose FedDCA, which optimizes domain coverage through greedy client center selection and retrieval-based augmentation. For client-side computational efficiency and system scalability, FedDCA$^*$, the variant of FedDCA, utilizes heterogeneous encoders with server-side feature alignment. Extensive experiments across four distinct domains (code, medical, financial, and mathematical) substantiate the effectiveness of both methods. Additionally, we investigate privacy preservation against memory extraction attacks utilizing various amounts of public data. Results show that there is no significant correlation between the volume of public data and the privacy-preserving capability. However, as the fine-tuning rounds increase, the risk of privacy leakage reduces or converges.", "title_embedding_index": 18768, "title_abs_embedding_index": 18793}, {"title": "TRACE: Temporal Grounding Video LLM  via Causal Event Modeling", "link_suffix": "/forum?id=14fFV0chUS", "link": "https://openreview.net/forum?id=14fFV0chUS", "pdf_link": "https://openreview.net/pdf?id=14fFV0chUS", "keywords": "video large language model, video temporal grounding", "abstract": "Video Temporal Grounding (VTG) is a crucial capability for video understanding models and plays a vital role in downstream tasks such as video browsing and editing. \nTo effectively handle various tasks simultaneously and enable zero-shot prediction, there is a growing trend in employing video LLMs for VTG tasks. However, current video LLM-based methods rely exclusively on natural language generation, lacking the ability to model the clear structure inherent in videos, which restricts their effectiveness in tackling VTG tasks. To address this issue, this paper first formally introduces causal event modeling framework, which represents videos as sequences of events, and predict the current event using previous events, video inputs, and textural instructions. Each event consists of three components: timestamps, salient scores, and textual captions. We then propose a novel task-interleaved video LLM called TRACE to effectively implement the causal event modeling framework in practice. \nThe TRACE processes visual frames, timestamps, salient scores, and text as distinct tasks, employing various encoders and decoding heads for each. Task tokens are arranged in an interleaved sequence according to the causal event modeling framework's formulation.\nExtensive experiments on various VTG tasks and datasets demonstrate the superior performance of TRACE compared to state-of-the-art video LLMs. Our model and code will be made publicly available.", "title_embedding_index": 18769, "title_abs_embedding_index": 18794}, {"title": "Stochastic Order Learning: An Approach to Rank Estimation Using Noisy Data", "link_suffix": "/forum?id=SW6IIpPr9I", "link": "https://openreview.net/forum?id=SW6IIpPr9I", "pdf_link": "https://openreview.net/pdf?id=SW6IIpPr9I", "keywords": "rank estimation, label noise, order learning", "abstract": "A novel algorithm, called stochastic order learning (SOL), for reliable rank estimation in the presence of label noise is proposed in this paper. For noise-robust rank estimation, we first represent label errors as random variables. We then formulate a desideratum that encourages reducing the dissimilarity of an instance from its stochastically related centroids. Based on this desideratum, we develop two loss functions: discriminative loss and stochastic order loss. Employing these two losses, we train a network to construct an embedding space in which instances are arranged according to their ranks. Also, after teaching the network, we identify outliers, which are likely to have extreme label errors, and relabel them for data refinement. Extensive experiments on various benchmark datasets demonstrate that the proposed SOL algorithm yields decent rank estimation results even when labels are corrupted by noise.", "title_embedding_index": 18770, "title_abs_embedding_index": 18795}, {"title": "OT-Attack: Enhancing Adversarial Transferability of Vision-Language Models via Optimal Transport Optimization", "link_suffix": "/forum?id=HqlX3lPtbh", "link": "https://openreview.net/forum?id=HqlX3lPtbh", "pdf_link": "https://openreview.net/pdf?id=HqlX3lPtbh", "keywords": "adversarial transferability, VLP models, optimal transport", "abstract": "Vision-language pre-training (VLP) models demonstrate impressive abilities in processing both images and text.\nHowever, they are vulnerable to multi-modal adversarial examples (AEs). Investigating the generation of high-transferability adversarial examples is crucial for uncovering VLP models\u2019 vulnerabilities in practical scenarios. Recent works have indicated that leveraging data augmentation and image-text modal interactions can enhance the transferability of adversarial examples for VLP models significantly. However, they do not consider the optimal alignment problem between dataaugmented image-text pairs. This oversight leads to adversarial examples that are overly tailored to the source model, thus limiting improvements in transferability. In our research, we first explore the interplay between image sets produced through data augmentation and their corresponding text sets. We find that augmented image samples can align optimally with certain texts while exhibiting less relevance to others. Motivated by this, we propose an Optimal Transport-based Adversarial Attack, dubbed OT-Attack. The proposed method formulates the features of image and text sets as two distinct distributions and employs optimal transport theory to determine the most efficient mapping between them. This optimal mapping informs our generation of adversarial examples to effectively counteract the overfitting issues. Extensive experiments across various network architectures and datasets in image-text matching tasks reveal that our OT-Attack outperforms existing stateof-the-art methods in terms of adversarial transferability.", "title_embedding_index": 18771, "title_abs_embedding_index": 18796}, {"title": "Hough Voting-based Self-Training for Vision-Language Model Adaptation", "link_suffix": "/forum?id=XMlj8W8o0Y", "link": "https://openreview.net/forum?id=XMlj8W8o0Y", "pdf_link": "https://openreview.net/pdf?id=XMlj8W8o0Y", "keywords": "Transfer Learning", "abstract": "Traditional model adaptation framework assumes the same vocabulary across pre-training and downstream datasets, which often struggles with limited transfer flexibility and efficiency while handling downstream datasets with different vocabularies.\nInspired by recent vision-language models (VLMs) that enable visual recognition defined by free-form texts via reasoning on both images and texts, we study vision-language model adaptation (VLMA), a new unsupervised model adaptation framework that positions a pre-trained VLM as the source model and transfers it towards various unlabelled downstream datasets.\nTo this end, we propose a Hough voting-based Self-Training (HoughST) technique that introduces a multimodal Hough voting mechanism to exploit the synergy between vision and language to mitigate the distribution shift in image and text modalities simultaneously. \nSpecifically, HoughST makes use of the complementary property of different types of features within and across vision and language modalities, which enables joint exploitation of vision and language information and effective learning of image-text correspondences in the unlabelled downstream datasets. \nAdditionally, HoughST captures temporal information via temporal Hough voting which helps memorize and leverage previously learnt downstream dataset information.\nExtensive experiments show that HoughST outperforms the state-of-the-art consistently across 11 image recognition tasks. \nCodes will be released.", "title_embedding_index": 18772, "title_abs_embedding_index": 18797}, {"title": "RobuRCDet: Enhancing Robustness of Radar-Camera Fusion in Bird's Eye View for 3D Object Detection", "link_suffix": "/forum?id=9xHlhKLu1h", "link": "https://openreview.net/forum?id=9xHlhKLu1h", "pdf_link": "https://openreview.net/pdf?id=9xHlhKLu1h", "keywords": "3D Vision\uff0c Radar Camera 3D Object Detection", "abstract": "While recent low-cost radar-camera approaches have shown promising results in\nmulti-modal 3D object detection, both sensors face challenges from environmen-\ntal and intrinsic disturbances. Poor lighting or adverse weather conditions de-\ngrade camera performance, while radar suffers from noise and positional ambigu-\nity. Achieving robust radar-camera 3D object detection requires consistent perfor-\nmance across varying conditions, a topic that has not yet been fully explored. In\nthis work, we first conduct a systematic analysis of robustness in radar-camera de-\ntection on five kinds of noises and propose RobuRCDet, a robust object detection\nmodel in bird\u2019s eye view (BEV). Specifically, we design a 3D Gaussian Expan-\nsion (3DGE) module to mitigate inaccuracies in radar points, including position,\nRadar Cross-Section (RCS), and velocity. The 3DGE uses RCS and velocity priors\nto generate a deformable kernel map and variance for kernel size adjustment and\nvalue distribution. Additionally, we introduce a weather-adaptive fusion module,\nwhich adaptively fuses radar and camera features based on camera signal confi-\ndence. Extensive experiments on the popular benchmark, nuScenes, show that\nour RobuRCDet achieves competitive results in regular and noisy conditions. The\nsource codes and trained models will be made available.", "title_embedding_index": 18773, "title_abs_embedding_index": 18798}, {"title": "Stable-Transformer: Towards a Stable Transformer Training", "link_suffix": "/forum?id=lkRjnNW0gb", "link": "https://openreview.net/forum?id=lkRjnNW0gb", "pdf_link": "https://openreview.net/pdf?id=lkRjnNW0gb", "keywords": "Transformer, Stable Transformer", "abstract": "The scale of parameters in Transformers has expanded dramatically\u2014from hundreds of millions to several trillion. A key challenge when scaling the model to trillions is the training instability. Although many practical tricks, such as learning rate warmup, query-key normalization and better weight initialization, have been introduced to mitigate the training instability, a rigorous mathematical understanding of why such instabilities happen and why the above-mentioned tricks work well is still unclear. In this paper, we give a theoretical analysis of the initialization, normalization and attention mechanism in Transformers, and present a set of stabilized designs of the initialization, normalization and attention mechanism, which are thus termed as \\textit{StableInit}, \\textit{StableNorm} and \\textit{StableAtten}, individually. In experiments, we demonstrate that each of our stabilized designs, \\ie \\textit{StableInit}, \\textit{StableNorm} and \\textit{StableAtten}, exhibits better stability. Furthermore, by putting the stabilized designs together, we propose a stabilized Transformer, termed \\textit{Stable-Transformer}, and show in experiments that our proposed \\textit{Stable-Transformer} \nachieves more stable training process.", "title_embedding_index": 18774, "title_abs_embedding_index": 18799}]
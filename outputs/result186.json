[
    {
        "title": "Verbalized Machine Learning: Revisiting Machine Learning with Language Models",
        "link_suffix": "/forum?id=vFgmobsJiZ",
        "link": "https://openreview.net/forum?id=vFgmobsJiZ",
        "pdf_link": "https://openreview.net/pdf?id=vFgmobsJiZ",
        "keywords": "Large Language Models",
        "abstract": "Motivated by the large progress made by large language models (LLMs), we introduce the framework of verbalized machine learning (VML). In contrast to conventional machine learning models that are typically optimized over a continuous parameter space, VML constrains the parameter space to be human-interpretable natural language. Such a constraint leads to a new perspective of function approximation, where an LLM with a text prompt can be viewed as a function parameterized by the text prompt. Guided by this perspective, we revisit classical machine learning problems, such as regression and classification, and find that these problems can be solved by an LLM-parameterized learner and optimizer. The major advantages of VML include (1) easy encoding of inductive bias: prior knowledge about the problem and hypothesis class can be encoded in natural language and fed into the LLM-parameterized learner; (2) automatic model class selection: the optimizer can automatically select a concrete model class based on data and verbalized prior knowledge, and it can update the model class during training; and (3) interpretable learner updates: the LLM-parameterized optimizer can provide explanations for why each learner update is performed. We conduct several studies to empirically evaluate the effectiveness of VML, and hope that VML can serve as a stepping stone to stronger interpretability and trustworthiness in ML."
    },
    {
        "title": "Multi-Task Consistency-based Detection of Adversarial Attacks",
        "link_suffix": "/forum?id=adhxppqQAn",
        "link": "https://openreview.net/forum?id=adhxppqQAn",
        "pdf_link": "https://openreview.net/pdf?id=adhxppqQAn",
        "keywords": "Adversarial Attack, Object Detection, Instance Segmentation, Adversarial Defense",
        "abstract": "Deep Neural Networks (DNNs) have found successful deployment in numerous vision perception systems. However, their susceptibility to adversarial attacks has prompted concerns regarding their practical applications, specifically in the context of autonomous driving. Existing research on defenses often suffers from cost inefficiency, rendering their deployment impractical for resource-constrained applications. In this work, we propose an efficient and effective adversarial attack detection scheme leveraging the multi-task perception within a complex vision system. Adversarial perturbations are detected by the inconsistencies between the inference outputs of multiple vision tasks, e.g., objection detection and instance segmentation. To this end, we developed a consistency score metric to measure the inconsistency between vision tasks. Next, we designed an approach to select the best model pairs for detecting this inconsistency effectively. Finally, we evaluated our defense by implementing PGD attacks across multiple vision models on the BDD100k validation dataset. The experimental results demonstrated that our defense achieved a ROC-AUC performance of 99.9% detection within the considered attacker model."
    },
    {
        "title": "WAPITI: A Watermark for Finetuned Open-Source LLMs",
        "link_suffix": "/forum?id=8o6LdeVi1K",
        "link": "https://openreview.net/forum?id=8o6LdeVi1K",
        "pdf_link": "https://openreview.net/pdf?id=8o6LdeVi1K",
        "keywords": "Watermark, Large Language Models, Model Interventions",
        "abstract": "Watermarking of large language models (LLMs) generation embeds an imperceptible statistical pattern within texts, making it algorithmically detectable. \nWatermarking is a promising method for addressing potential harm and biases from LLMs, as it enables traceability, accountability, and detection of manipulated content, helping to mitigate unintended consequences. \nHowever, for open-source models, watermarking faces two major challenges: \n(1) incompatibility with fine-tuned models\n(2) vulnerability to fine-tuning attacks.\nIn this work, we propose WAPITI, a new method that transfers watermarking from base models to fine-tuned models through parameter integration.\nTo the best of our knowledge, we are the first to embed watermarks into fine-tuned model parameters and preserve their fine-tuned capabilities. \nFurthermore, our approach offers an effective defense against fine-tuning attacks. \nWe test our method on various model architectures and watermarking strategies. \nResults demonstrate that our method can successfully inject watermarks and is highly compatible with fine-tuned models. \nAdditionally, we offer an in-depth analysis of how the strength of \nparameter editing influences the watermark strength and overall capabilities of the resulting models."
    },
    {
        "title": "Provable Faster Zeroth-order Method for Bilevel Optimization with Optimal Dependency on Error and Dimension",
        "link_suffix": "/forum?id=W4AZQzNe8h",
        "link": "https://openreview.net/forum?id=W4AZQzNe8h",
        "pdf_link": "https://openreview.net/pdf?id=W4AZQzNe8h",
        "keywords": "Stochastic bilevel optimization, Hessian-free algorithms, near-optimal complexity",
        "abstract": "In this paper, we study and analyze zeroth-order stochastic approximation algorithms for solving black-box bilevel optimization problems, where only the upper and lower function values can be obtained. \\citep{Saeed2024} proposed the first full zeroth-order bilevel method that utilizes Gaussian smoothing to estimate the first- and second-order partial derivatives of functions with two independent blocks of variables. However, this method suffers from a high dimensional dependency of $\\mathcal{O}((d_{1}+d_{2})^{4})$, where $d_{1}$ and $d_{2}$ are the dimensions of the outer and inner problems, respectively. They left an open question: can this dimension dependency be improved? To answer this question, we propose a single-loop accelerated zeroth-order bilevel algorithm, which achieves a dimension dependency of $\\mathcal{O}(d_{1}+d_{2})$ by incorporating coordinate-wise smoothing gradient estimators (coord). \n    We develop a new theoretical analysis for the proposed algorithm, which converges to a stationary point of $\\Phi(x)$ with a complexity of $\\mathcal{O}((d_{1}+d_{2})\\epsilon^{-3})$ in expectation settings and $\\mathcal{O}((d_{1}+d_{2})\\sqrt{n}\\epsilon^{-2})$ in finite sum settings. These complexities are both optimal with respect to dimension and error $\\epsilon$. We also provide  experiment to validate the effectiveness of the proposed algorithm."
    },
    {
        "title": "Self-Augmented Preference Optimization: Off-Policy Paradigms for Language Model Alignment",
        "link_suffix": "/forum?id=yizEOJVFFd",
        "link": "https://openreview.net/forum?id=yizEOJVFFd",
        "pdf_link": "https://openreview.net/pdf?id=yizEOJVFFd",
        "keywords": "Large Language Model, Fine-tuning, Self-play",
        "abstract": "Traditional language model alignment methods, such as Direct Preference Optimization (DPO), are limited by their dependence on static, pre-collected paired preference data, which restricts their adaptability and practical applicability. To address this limitation, we introduce Self-Augmented Preference Optimization (SAPO), an effective and scalable training paradigm without the need of existing paired data. Built upon the self-play concept that autonomously generate negative responses, we further involve the off-policy learning pipeline to improve the data exploration and exploitation. Specifically, we employ an Exponential Moving Average (EMA) model along with a replay buffer to enable dynamic updates of response segments, effectively integrating real-time feedback with historical data insights. Our comprehensive evaluations of the LLaMA3-8B and Mistral-7B models across benchmarks\u2014including the Open LLM Leaderboard, IFEval, AlpacaEval 2.0, and MT-Bench\u2014demonstrate that SAPO matches or surpasses established offline contrastive baselines, such as DPO and Odds Ratio Preference Optimization (ORPO), and outperforms offline self-play methods like SPIN."
    },
    {
        "title": "Machine Unlearning Fails to Remove Data Poisoning Attacks",
        "link_suffix": "/forum?id=HaX48yksVL",
        "link": "https://openreview.net/forum?id=HaX48yksVL",
        "pdf_link": "https://openreview.net/pdf?id=HaX48yksVL",
        "keywords": "machine unlearning, data poisoning",
        "abstract": "We revisit the efficacy of several practical methods for approximate machine unlearning developed for large-scale deep learning. In addition to complying with data deletion requests, one often-cited potential application for unlearning methods is to remove the effects of training on poisoned data. We experimentally demonstrate that, while existing unlearning methods have been demonstrated to be effective in a number of evaluation settings (e.g., alleviating membership inference attacks), they fail to remove the effects of data poisoning, across a variety of types of poisoning attacks (indiscriminate, targeted, and a newly-introduced Gaussian poisoning attack) and models (image classifiers and LLMs); even when granted a relatively large compute budget. In order to precisely characterize unlearning efficacy, we introduce new evaluation metrics for unlearning based on data poisoning. Our results suggest that a broader perspective, including a wider variety of evaluations, is required to avoid a false sense of confidence in machine unlearning procedures for deep learning without provable guarantees. Moreover, while unlearning methods show some signs of being useful to efficiently remove poisoned datapoints without having to retrain, our work suggests that these methods are not yet \"ready for prime time\", and currently provide limited benefit over retraining."
    },
    {
        "title": "Residual-MPPI: Online Policy Customization for Continuous Control",
        "link_suffix": "/forum?id=gVnJFY8nCM",
        "link": "https://openreview.net/forum?id=gVnJFY8nCM",
        "pdf_link": "https://openreview.net/pdf?id=gVnJFY8nCM",
        "keywords": "Policy customization, Combination of learning- and planning-based approaches, Model predictive control",
        "abstract": "Policies learned through Reinforcement Learning (RL) and Imitation Learning (IL) have demonstrated significant potential in achieving advanced performance in continuous control tasks. However, in real-world environments, it is often necessary to further customize a trained policy when there are additional requirements that were unforeseen during the original training phase. It is possible to fine-tune the policy to meet the new requirements, but this often requires collecting new data with the added requirements and access to the original training metric and policy parameters. In contrast, an online planning algorithm, if capable of meeting the additional requirements, can eliminate the necessity for extensive training phases and customize the policy without knowledge of the original training scheme or task. In this work, we propose a generic online planning algorithm for customizing continuous-control policies at the execution time which we call Residual-MPPI. It is able to customize a given prior policy on new performance metrics in few-shot and even zero-shot online settings. Also, Residual-MPPI only requires access to the action distribution produced by the prior policy, without additional knowledge regarding the original task. Through our experiments, we demonstrate that the proposed Residual-MPPI algorithm can accomplish the few-shot/zero-shot online policy customization task effectively, including customizing the champion-level racing agent, Gran Turismo Sophy (GT Sophy) 1.0, in the challenging car racing scenario, Gran Turismo Sport (GTS) environment. Code for MuJoCo experiments is included in the supplmentary and will be open-sourced upon acceptance. Demo videos are available on our website:https://sites.google.com/view/residual-mppi"
    },
    {
        "title": "Decomposed Direct Preference Optimization for Structure-Based Drug Design",
        "link_suffix": "/forum?id=blSYKTWurU",
        "link": "https://openreview.net/forum?id=blSYKTWurU",
        "pdf_link": "https://openreview.net/pdf?id=blSYKTWurU",
        "keywords": "structure-based drug design, diffusion model, direct preference optimization",
        "abstract": "Diffusion models have achieved promising results for Structure-Based Drug Design (SBDD). Nevertheless, high-quality protein subpocket and ligand data are relatively scarce, which hinders the models' generation capabilities. Recently, Direct Preference Optimization (DPO) has emerged as a pivotal tool for aligning generative models with human preferences. In this paper, we propose DecompDPO, a structure-based optimization method aligns diffusion models with pharmaceutical needs using multi-granularity preference pairs. DecompDPO introduces decomposition into the optimization objectives and obtains preference pairs at the molecule or decomposed substructure level based on each objective's decomposability. Additionally, DecompDPO introduces a physics-informed energy term to ensure reasonable molecular conformations in the optimization results. Notably, DecompDPO can be effectively used for two main purposes: (1) fine-tuning pretrained diffusion models for molecule generation across various protein families, and (2) molecular optimization given a specific protein subpocket after generation. Extensive experiments on the CrossDocked2020 benchmark show that DecompDPO significantly improves model performance, achieving up to 95.2% Med. High Affinity and a 36.2% success rate for molecule generation, and 100% Med. High Affinity and a 52.1% success rate for molecular optimization."
    },
    {
        "title": "Hybrid Memory Replay: Blending Real and Distilled Data for Class Incremental Learning",
        "link_suffix": "/forum?id=YbusS3WNvb",
        "link": "https://openreview.net/forum?id=YbusS3WNvb",
        "pdf_link": "https://openreview.net/pdf?id=YbusS3WNvb",
        "keywords": "Hybrid Memory, Class Incremental Learning, Data Distillation",
        "abstract": "Incremental learning (IL) aims to acquire new knowledge from current tasks while retaining knowledge learned from previous tasks. Replay-based IL methods store a set of exemplars from previous tasks in a buffer and replay them when learning new tasks. However, there is usually a size-limited buffer that cannot store adequate real exemplars to retain the knowledge of previous tasks. In contrast, data distillation (DD) can reduce the exemplar buffer's size, by condensing a large real dataset into a much smaller set of more information-compact synthetic exemplars. Nevertheless, DD's performance gain on IL quickly vanishes as the number of synthetic exemplars grows. To overcome the weaknesses of real-data and synthetic-data buffers, we instead optimize a hybrid memory including both types of data. Specifically, we propose an innovative modification to DD that distills synthetic data from a sliding window of checkpoints in history (rather than checkpoints on multiple training trajectories). Conditioned on the synthetic data, we then optimize the selection of real exemplars to provide complementary improvement to the DD objective. The optimized hybrid memory combines the strengths of synthetic and real exemplars, effectively mitigating catastrophic forgetting in Class IL (CIL) when the buffer size for exemplars is limited. Notably, our method can be seamlessly integrated into most existing replay-based CIL models. Extensive experiments across multiple benchmarks demonstrate that our method significantly outperforms existing replay-based baselines. Our source code is available athttps://anonymous.4open.science/r/DD4CIL-510C/."
    },
    {
        "title": "MCNC: Manifold-Constrained Reparameterization for Neural Compression",
        "link_suffix": "/forum?id=VMV8gefvq8",
        "link": "https://openreview.net/forum?id=VMV8gefvq8",
        "pdf_link": "https://openreview.net/pdf?id=VMV8gefvq8",
        "keywords": "Model Compression, LoRA, PEFT, Transformers, ViT",
        "abstract": "The outstanding performance of large foundational models across diverse tasks, from computer vision to speech and natural language processing, has significantly increased their demand. However, storing and transmitting these models poses significant challenges due to their massive size (e.g., 750GB for Llama 3.1 405B). Recent literature has focused on compressing the original weights or reducing the number of parameters required for fine-tuning these models. These compression methods generally constrain the parameter space, for example, through low-rank reparametrization (e.g., LoRA), pruning, or quantization (e.g., QLoRA) during or after the model training. In this paper, we present a novel model compression method, which we term Manifold-Constrained Neural Compression (MCNC). This method constrains the parameter space to low-dimensional pre-defined and frozen nonlinear manifolds, which effectively cover this space. Given the prevalence of good solutions in over-parameterized deep neural networks, we show that by constraining the parameter space to our proposed manifold, we can identify high-quality solutions while achieving unprecedented compression rates across a wide variety of tasks and architectures. Through extensive experiments in computer vision and natural language processing tasks, we demonstrate that our method significantly outperforms state-of-the-art baselines in terms of compression, accuracy, and/or model reconstruction time."
    },
    {
        "title": "CHIRon: A Generative Foundation Model for Structured Sequential Medical Data",
        "link_suffix": "/forum?id=re7jrIyghD",
        "link": "https://openreview.net/forum?id=re7jrIyghD",
        "pdf_link": "https://openreview.net/pdf?id=re7jrIyghD",
        "keywords": "foundation models, large language models, generative models, disease progression, medical codes",
        "abstract": "Recent advances in large language models (LLMs) have shown that foundation models (FMs) can learn highly complex representations of sequences that can be used for downstream generative and discriminative tasks such as text generation and classification. While most FMs focus on text, recent work has shown FMs can be learnt for sequential medical data, e.g. ICD-10 diagnosis codes associated with specific patient visits. These FMs demonstrate improved performance on downstream discriminative disease classification tasks. In this paper, we introduce CHIRon, a decoder-only generative FM for sequential medical data. CHIRon utilizes causal masking during pre-training, enabling generative applications, and incorporates a number of architectural improvements and support for additional medical data types (diagnoses, procedures, medications, lab results, place of service, demographics). We introduce a new pre-training objective function that incorporates tasks for predicting place of service and patient's age at encounter in addition to the next medical code prediction task. To incorporate lab results into the model, we develop and evaluate several methods for embedding the continuous lab values. Furthermore, we introduce a causal visit-based masking approach for training CHIRon based on patient visits. We show empirically that CHIRon can be used to generate realistic sequential medical data and also outperforms state of the art FMs for sequential medical data on disease classification tasks."
    },
    {
        "title": "HQ-Edit: A High-Quality Dataset for Instruction-based Image Editing",
        "link_suffix": "/forum?id=mZptYYttFj",
        "link": "https://openreview.net/forum?id=mZptYYttFj",
        "pdf_link": "https://openreview.net/pdf?id=mZptYYttFj",
        "keywords": "Image-to-image translation, Image Editing",
        "abstract": "This study introduces HQ-Edit, a high-quality instruction-based image editing dataset with around 200,000 edits. Unlike prior approaches relying on attribute guidance or human feedback on building datasets, we devise a scalable data collection pipeline leveraging advanced foundation models, namely GPT-4V and DALL-E 3. To ensure its high quality, diverse examples are first collected online, expanded, and then used to create high-quality diptychs featuring input and output images with detailed text prompts, followed by precise alignment ensured through post-processing. In addition, we propose two evaluation metrics, Alignment and Coherence, to quantitatively assess the quality of image edit pairs using GPT-4V. HQ-Edits high-resolution images, rich in detail and accompanied by comprehensive editing prompts, substantially enhance the capabilities of existing image editing models. For example, an HQ-Edit finetuned InstructPix2Pix can attain state-of-the-art image editing performance, even surpassing those models fine-tuned with human-annotated data."
    },
    {
        "title": "Last-Iterate Convergence Properties of Regret-Matching Algorithms in Games",
        "link_suffix": "/forum?id=LWeVVPuIx0",
        "link": "https://openreview.net/forum?id=LWeVVPuIx0",
        "pdf_link": "https://openreview.net/pdf?id=LWeVVPuIx0",
        "keywords": "Last-Iterate Convergence, Minty solution, Regret Matching, Zero-Sum Game, Learning in Games",
        "abstract": "We study last-iterate convergence properties of algorithms for solving two-player zero-sum games based on Regret Matching$^+$ (RM$^+$). Despite their widespread use for solving real games, virtually nothing is known about their last-iterate convergence. A major obstacle to analyzing RM-type dynamics is that their regret operators lack Lipschitzness and (pseudo)monotonicity.\nWe start by showing numerically that several variants used in practice, such as RM$^+$, predictive RM$^+$ and alternating RM$^+$, all lack last-iterate convergence guarantees even on a simple $3\\times 3$ matrix game.\nWe then prove that recent variants of these algorithms based on a smoothing technique, extragradient RM$^{+}$ and smooth Predictive RM$^+$,  enjoy asymptotic last-iterate convergence (without a rate), $1/\\sqrt{t}$ best-iterate convergence, and when combined with restarting, linear-rate last-iterate convergence. Our analysis builds on a new characterization of the geometric structure of the limit points of our algorithms, marking a significant departure from most of the literature on last-iterate convergence. We believe that our analysis may be of independent interest and offers a fresh perspective for studying last-iterate convergence in algorithms based on non-monotone operators."
    },
    {
        "title": "CogDevelop2K: Reversed Cognitive Development in Multi-modal Large Language Models",
        "link_suffix": "/forum?id=fDNBPqgr4K",
        "link": "https://openreview.net/forum?id=fDNBPqgr4K",
        "pdf_link": "https://openreview.net/pdf?id=fDNBPqgr4K",
        "keywords": "Vision Language Model, Multi-modal Large Language Model, Cognitive Development, Cognitive Science, Benchmark",
        "abstract": "Are Multi-modal Large Language Models (MLLMs) stochastic parrots? Do they genuinely understand and are capable of performing the tasks they excel at? This paper aims to explore the fundamental basis of MLLMs, i.e. core cognitive abilities that human intelligence builds upon to perceive, comprehend, and reason. To this end, we propose CogDevelop2K, a comprehensive benchmark that spans 12 sub-concepts from fundamental knowledge like object permanence and boundary to advanced reasoning like intentionality understanding, structured via the developmental trajectory of a human mind. We evaluate 46 MLLMs on our benchmarks. Comprehensively, we further evaluate the influence of evaluation strategies and prompting techniques. Surprisingly, we observe a reversed cognitive developmental trajectory compared to humans."
    },
    {
        "title": "STAR: Synthesis of Tailored Architectures",
        "link_suffix": "/forum?id=HsHxSN23rM",
        "link": "https://openreview.net/forum?id=HsHxSN23rM",
        "pdf_link": "https://openreview.net/pdf?id=HsHxSN23rM",
        "keywords": "alternative architectures, deep signal processing, language models",
        "abstract": "Iterative improvement of model architectures is fundamental to deep learning: Transformers first enabled scaling, and recent advances in model hybridization have pushed the quality-efficiency frontier. However, optimizing architectures remains challenging and expensive, with a variety of automated or manual approaches that fall short, due to limited progress in the design of search spaces and due to the simplicity of resulting patterns and heuristics. In this work, we propose a new approach for the synthesis of tailored architectures (STAR). Our approach combines a novel search space based on the theory of linear input-varying systems, supporting a hierarchical numerical encoding into architecture genomes. STAR genomes are automatically refined and recombined with gradient-free, evolutionary algorithms to optimize for multiple model quality and efficiency metrics. Using STAR, we optimize large populations of new architectures, leveraging diverse computational units and interconnection patterns, improving over highly-optimized Transformers and striped hybrid models on the frontier of quality, parameter size, and inference cache for autoregressive language modeling."
    },
    {
        "title": "HARDMath: A Benchmark Dataset for Challenging Problems in Applied Mathematics",
        "link_suffix": "/forum?id=nDTvP6tBMd",
        "link": "https://openreview.net/forum?id=nDTvP6tBMd",
        "pdf_link": "https://openreview.net/pdf?id=nDTvP6tBMd",
        "keywords": "math, benchmark, dataset, few-shot learning, reasoning",
        "abstract": "Advanced applied mathematics problems are underrepresented in existing Large Language Model (LLM) benchmark datasets. To address this, we introduce $\\textbf{HARDMath}$, a dataset inspired by a graduate course on asymptotic methods, featuring challenging applied mathematics problems that require analytical approximation techniques. These problems demand a combination of mathematical reasoning, computational tools, and subjective judgment, making them difficult for LLMs. Our framework auto-generates a large number of problems with solutions validated against numerical ground truths. We evaluate both open- and closed-source LLMs on $\\textbf{HARDMath-mini}$, a sub-sampled test set of 366 problems, as well as on 40 word problems formulated in applied science contexts. Even leading closed-source models like GPT-4 achieve only 43.8% overall accuracy with few-shot Chain-of-Thought prompting, and all models demonstrate significantly lower performance compared to results on existing mathematics benchmark datasets. We additionally conduct a detailed error analysis to gain insights into the failure cases of LLMs. These results demonstrate the limitations of current LLM performance on advanced graduate-level applied math problems and underscore the importance of datasets like $\\textbf{HARDMath}$ to advance mathematical abilities of LLMs."
    },
    {
        "title": "Stochastic Online Conformal Prediction with Semi-Bandit Feedback",
        "link_suffix": "/forum?id=dbwF3QFWGn",
        "link": "https://openreview.net/forum?id=dbwF3QFWGn",
        "pdf_link": "https://openreview.net/pdf?id=dbwF3QFWGn",
        "keywords": "Conformal Predictions, Online Learning, Semi-bandit Feedback",
        "abstract": "Conformal prediction has emerged as an effective strategy for uncertainty quantification by modifying a model to output sets of labels instead of a single label. These prediction sets come with the guarantee that they contain the true label with high probability. However, conformal prediction typically requires a large calibration dataset of i.i.d. examples. We consider the online learning setting, where examples arrive over time, and the goal is to construct prediction sets dynamically. Departing from existing work, we assume semi-bandit feedback, where we only observe the true label if it is contained in the prediction set. For instance, consider calibrating a document retrieval model to a new domain; in this setting, a user would only be able to provide the true label if the target document is in the prediction set of retrieved documents. We propose a novel conformal prediction algorithm targeted at this setting, and prove that it obtains sublinear regret compared to the optimal conformal predictor. We evaluate our algorithm on a retrieval task, an image classification task, and an auction price-setting task, and demonstrate that it empirically achieves good performance compared to several baselines."
    },
    {
        "title": "Segmenting Text and Learning Their Rewards for Improved RLHF in Language Models",
        "link_suffix": "/forum?id=cK7yrw5g5Q",
        "link": "https://openreview.net/forum?id=cK7yrw5g5Q",
        "pdf_link": "https://openreview.net/pdf?id=cK7yrw5g5Q",
        "keywords": "Reinforcement Learning from Human Feedback, Reward Modeling, Dense Reward Assignment, Language Models",
        "abstract": "Reinforcement learning from human feedback (RLHF) has been widely adopted to align language models (LMs) with human preference.\nPrior RLHF works typically take a bandit formulation, which, though intuitive, ignores the sequential nature of LM generation and can suffer from the sparse reward issue.\nWhile recent works propose dense token-level RLHF, treating each token as an action may be oversubtle to proper reward assignment. \nIn this paper, we seek to get the best of both by training and utilizing a segment-level reward model, which assigns a reward to each semantically complete text segment that spans over a short sequence of tokens.\nFor reward learning, our method allows dynamic text segmentation and compatibility with standard sequence-preference datasets.\nFor effective RL-based LM training against segment reward, we generalize the classical scalar bandit reward normalizers into location-aware normalizer functions and interpolate the segment reward for further densification.\nWith these designs, our method performs competitively on popular RLHF benchmarks in both reward modeling and LM policy learning.\nAblation studies are conducted to further demonstrate our method."
    },
    {
        "title": "Language Models Are Good Tabular Learners",
        "link_suffix": "/forum?id=r8tMECbxOl",
        "link": "https://openreview.net/forum?id=r8tMECbxOl",
        "pdf_link": "https://openreview.net/pdf?id=r8tMECbxOl",
        "keywords": "Language Model; Tabular Data; Natural Language Processing",
        "abstract": "Transformer-based language models have become the de facto standard in natural language processing. However, they underperform in the tabular data domain compared to traditional tree-based methods. We posit that current models fail to achieve the full potential of language models due to (i) heterogeneity of tabular data; and  (2) challenges faced by the model in interpreting numerical values. Based on this hypothesis, we propose a method titled Tabular Domain Transformer (TDTransformer). TDTransformer has distinct embedding processes for different types of columns. The alignment layers for different types of columns transform column embeddings to a common embedding space. Besides, TDTransformer adapts piece-wise linear encoding for numerical values in transformer-based architectures. We examine the proposed method on 76 real-world tabular classification datasets from the standard OpenML benchmark. Extensive experiments indicate that TDTransformer significantly improves the state-of-the-art methods."
    },
    {
        "title": "Efficient transformer with reinforced position embedding for language models",
        "link_suffix": "/forum?id=5dDYhvt6dY",
        "link": "https://openreview.net/forum?id=5dDYhvt6dY",
        "pdf_link": "https://openreview.net/pdf?id=5dDYhvt6dY",
        "keywords": "Transformer model, token embeddings, neural machine translation",
        "abstract": "In this paper, we propose an efficient transformer architecture that uses reinforced positional embedding to obtain superior performance with half the number of encoder decoder layers. We demonstrate that concatenating positional encoding with trainable token embeddings, normalizing across tokens in the token embedding matrix, and using the normalized token embedding matrix as the value of the attention layer improve the training and validation loss and the training time in an encoder-decoder Transformer model for a Portuguese-English translation task with 10 epochs or 12 hours of training across 10 trials. Our method, with roughly a threefold parameter reduction compared to the baseline model, yields a mean training loss of 1.21, a mean validation loss of 1.51, and an average training time of 1352.27 seconds per epoch, surpassing the baseline model with the same embedding dimension that employs addition of positional encoding and token embeddings, which achieves a mean training loss of 1.96, a validation loss of 2.18, and an average training time of 4297.79 seconds per epoch. Additionally, we evaluated our proposed architecture and the baseline across 14 diverse translation datasets from TensorFlow. The results indicate that our method consistently achieves lower or comparable training and validation losses, suggesting enhanced learning efficiency."
    },
    {
        "title": "Exploring Edge Probability Graph Models Beyond Edge Independency: Concepts, Analyses, and Algorithms",
        "link_suffix": "/forum?id=xljPZuprBA",
        "link": "https://openreview.net/forum?id=xljPZuprBA",
        "pdf_link": "https://openreview.net/pdf?id=xljPZuprBA",
        "keywords": "Random graph models, edge dependency, triangle density, subgraph densities, tractability, variability",
        "abstract": "Desirable random graph models (RGMs) should(i)generaterealisticstructures such as high clustering (i.e., high subgraph densities),(ii)generatevariable(i.e., not overly similar) graphs, and(iii)remaintractableto compute and control graph statistics.\nA common class of RGMs (e.g., Erd\\H{o}s-R'{e}nyi and stochastic Kronecker) outputs edge probabilities, and we need to realize (i.e., sample from) the edge probabilities to generate graphs.\nTypically, each edge's existence is assumed to be determined independently for simplicity and tractability.\nHowever, with edge independency, RGMs theoretically cannot produce high subgraph densities and high output variability simultaneously.\nIn this work, we explore realization beyond edge independence that can produce more realistic structures while maintaining high traceability and variability.\nTheoretically, we propose an edge-dependent realization framework calledbindingthat provably preserves output variability, and deriveclosed-formtractability results on subgraph (e.g., triangle) densities in generated graphs.\nPractically, we propose algorithms for graph generation with binding and parameter fitting of binding.\nOur empirical results demonstrate that binding exhibits high tractability and generates realistic graphs with high clustering, significantly improving upon existing RGMs assuming edge independency."
    },
    {
        "title": "DNABERT-S: Pioneering Species Differentiation with Species-Aware DNA Embeddings",
        "link_suffix": "/forum?id=9klRFLY2TT",
        "link": "https://openreview.net/forum?id=9klRFLY2TT",
        "pdf_link": "https://openreview.net/pdf?id=9klRFLY2TT",
        "keywords": "DNA embedding, Species Differentiation, Metagenomics Binning",
        "abstract": "We introduce DNABERT-S, a tailored genome model that develops species-aware embeddings to naturally cluster and segregate DNA sequences of different species in the embedding space. \nDifferentiating species from genomic sequences (i.e., DNA and RNA) is vital yet challenging, since many real-world species remain uncharacterized, lacking known genomes for reference. Embedding-based methods are therefore used to differentiate species in an unsupervised manner.\nDNABERT-S builds upon a pre-trained genome foundation model named DNABERT-2.\nTo encourage effective embeddings to error-prone long-read DNA sequences, we introduce Manifold Instance Mixup (MI-Mix), a contrastive objective that mixes the hidden representations of DNA sequences at randomly selected layers and trains the model to recognize and differentiate these mixed proportions at the output layer. We further enhance it with the proposed Curriculum Contrastive Learning (C2LR) strategy.\nEmpirical results on 23 diverse datasets show DNABERT-S's effectiveness, especially in realistic label-scarce scenarios. \nFor example, it identifies twice more species from a mixture of unlabeled genomic sequences, doubles the Adjusted Rand Index (ARI) in species clustering, and outperforms the top baseline's performance in 10-shot species classification with just a 2-shot training."
    },
    {
        "title": "Provable weak-to-strong generalization via benign overfitting",
        "link_suffix": "/forum?id=4vzGQcVUG8",
        "link": "https://openreview.net/forum?id=4vzGQcVUG8",
        "pdf_link": "https://openreview.net/pdf?id=4vzGQcVUG8",
        "keywords": "benign overfitting, spiked covariance models, overparameterized models, interpolation, pseudolabeling, weak-to-strong generalization, alignment",
        "abstract": "The classic teacher-student model in machine learning posits that a strong teacher supervises a weak student to improve the student's capabilities.\n    We instead consider the inverted situation, where a weak teacher supervises a strong student with imperfect pseudolabels. \n    This paradigm was recently brought forth by \\citet{burns2023weak} and termed \\emph{weak-to-strong generalization}. \n    We theoretically investigate weak-to-strong generalization for binary and multilabel classification in a stylized overparameterized spiked covariance model with Gaussian covariates where the weak teacher's pseudolabels are asymptotically like random guessing.\n    Under these assumptions, we provably identify two asymptotic phases of the strong student's generalization after weak supervision: (1) successful generalization and (2) random guessing. \n    Our techniques should eventually extend to weak-to-strong multiclass classification. \n    Towards doing so, we prove a tight lower tail inequality for the maximum of correlated Gaussians, which may be of independent interest.\n    Understanding the multilabel setting reinforces the value of using logits for weak supervision when they are available."
    },
    {
        "title": "Graph-based algorithms for nearest neighbor search with multiple filters",
        "link_suffix": "/forum?id=a2eBgp4sjH",
        "link": "https://openreview.net/forum?id=a2eBgp4sjH",
        "pdf_link": "https://openreview.net/pdf?id=a2eBgp4sjH",
        "keywords": "nearest neighbor search, filtered search, graph indices, filters",
        "abstract": "We study nearest neighbor search with filter constraints (MultiFilterANN): given a query vector with a discrete set of labels $S$, retrieve the (approximately) closest vector from a dataset under the constraint that $S$ must be a subset of the labels of the retrieved vector. There has been a burgeoning interest in this problem on the practical side, due to its strong motivation from search and recommendation applications where vector labels correspond to real world attributes such as date, price, or color. On the theoretical side, this problem generalizes the subset query problem, which asks us to only determine if $S$ is a subset of some set in the dataset, without retrieving the closest vector.In this work, we present a systematic study of MultiFilterANN,. Theoretically, we demonstrate the power of graph-based algorithms in two ways:We design provable algorithms with the best known space-time tradeoffs for \\mfann in the large filter regime by carefully incorporating ANN algorithms into known subset query algorithms.% to incorporate nearest neighbor search using graph-based algorithms.We demonstrate lower bounds for popular algorithms for MultiFilterANN, showing that they can catastrophically fail even on simple data/label sets.Our theoretical results inspire our empirical approach, where we extend practical graph indices for standard nearest neighbor search to MultiFilterANN by augmenting the (greedy) search procedure with a penalized distance function that captures filter constraints. Our empirical algorithm is competitive with existing state of the art solutions which are tailored for one or two filters, while also seamlessly generalizing to any number of filters without any modifications. Lastly we release multiple novel datasets for MultiFilterANN, filling in a noticeable gap in literature."
    },
    {
        "title": "Conformal Prediction with Model-Aware Debiasing",
        "link_suffix": "/forum?id=wdzCyr1stL",
        "link": "https://openreview.net/forum?id=wdzCyr1stL",
        "pdf_link": "https://openreview.net/pdf?id=wdzCyr1stL",
        "keywords": "conformal prediction, model-aware debiasing, statistical inference, prediction interval",
        "abstract": "Bias in model estimation can lead to wider prediction intervals, diminishing the utility of predictive inference. Existing methods have attempted to address this issue, but they often rely on nontrivial assumptions such as specific error distributions or model sparsity, and fail to guarantee coverage in finite samples, which makes their predictions unreliable in practice. To overcome these limitations, we propose a model-aware conformal prediction method that utilizes known model information to achieve debiasing while leaving the unknown aspects, such as data distribution, to the conformal prediction framework. This approach requires only the assumption of exchangeability, making it broadly applicable across various models. Importantly, it retains the finite-sample coverage property and produces shorter prediction intervals compared to existing methods. When applied to threshold ridge regression, we theoretically demonstrate that the model-aware conformal prediction maintains finite-sample marginal coverage and, under certain assumptions, converges to the oracle prediction band, achieving asymptotic conditional validity. Numerical experiments further show that our method outperforms existing methods, providing more efficient prediction intervals across diverse regression datasets."
    }
]
[{"title": "You Can Train from Scratch: Further Discussion on the Long Range Arena", "link_suffix": "/forum?id=YuFUUcSUgx", "link": "https://openreview.net/forum?id=YuFUUcSUgx", "pdf_link": "https://openreview.net/pdf?id=YuFUUcSUgx", "keywords": "Long Range Arena, Transformers", "abstract": "Despite their success, Transformers suffer from quadratic complexity in the sequence length, limiting their applicability to long-range dependency problems and making them expensive to train and run. After many proposals to address this issue, the Long Range Arena (LRA) was suggested as a benchmark to evaluate the performance of new models in long-range dependency modeling tasks. The Transformer and its variants performed poorly on this benchmark, and a new series of architectures such as State Space Models (SSMs) gained some traction, greatly outperforming Transformers in the LRA. Recent work has shown that with a denoising pretraining phase, Transformers can achieve competitive results in the LRA with these new architectures. In this work, we show that one can achieve the same result without a separate pretraining phase, using other training techniques. This reduces the computational burden of training and eliminates the risk of representation collapse during fine-tuning. We argue that LRA tasks are very positional and provide evidence that short-range dependencies account for a significant portion of the performance. This explains prior differences in LRA accuracy between the Transformer and new architectures, which have better positional and local biases. Our training techniques alleviate these differences up to a point, and rotary embeddings add further improvements by including these positional biases. Given these insights, LRA results should be interpreted with caution, and should be analyzed given the model's inductive biases and the nature of the tasks.", "title_embedding_index": 11550, "title_abs_embedding_index": 11575}, {"title": "NEXT-MOL: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation", "link_suffix": "/forum?id=p66a00KLWN", "link": "https://openreview.net/forum?id=p66a00KLWN", "pdf_link": "https://openreview.net/pdf?id=p66a00KLWN", "keywords": "3D molecule generation, molecular conformer generation, large language models, diffusion models, geometric deep learning", "abstract": "3D molecule generation is crucial for drug discovery and material design. While prior efforts focus on 3D diffusion models for their benefits in modeling continuous 3D conformers, they overlook the advantages of 1D SELFIES-based Language Models (LMs), which are able to generate 100% valid molecules and leverage the billion-scale 1D molecule datasets. To combine these advantages for 3D molecule generation, we propose a foundation model -- NEXT-Mol: 3D Diffusion Meets 1D Language Modeling for 3D Molecule Generation. NEXT-Mol uses an extensively pretrained molecule LM for 1D molecule generation, and subsequently predicts the generated molecule's 3D conformers with a 3D diffusion model. We enhance NEXT-Mol's performance by scaling up the LM's model size, refining the diffusion neural architecture, and applying 1D to 3D transfer learning. Notably, we demonstrate that incorporating 1D representations from our molecule LM improves the 3D diffusion model's conformer prediction by 1.3% coverage-recall on GEOM-DRUGS. Given these improvements, NEXT-Mol achieves leading performances in de novo 3D molecule generation, 3D conformer prediction, and conditional 3D molecule generation, demonstrating its effectiveness and versatility as a foundation model in the field.", "title_embedding_index": 11551, "title_abs_embedding_index": 11576}, {"title": "PnP-Flow: Plug-and-Play Image Restoration with Flow Matching", "link_suffix": "/forum?id=5AtHrq3B5R", "link": "https://openreview.net/forum?id=5AtHrq3B5R", "pdf_link": "https://openreview.net/pdf?id=5AtHrq3B5R", "keywords": "Plug-and-Play, Flow Matching, image restoration, inverse problems, generative modeling", "abstract": "In this paper, we introduce Plug-and-Play (PnP) Flow Matching, an algorithm for solving imaging inverse problems. PnP methods leverage the strength of pre-trained denoisers, often deep neural networks, by integrating them in optimization schemes. While they achieve state-of-the-art performance on various inverse problems in imaging, PnP approaches face inherent limitations on more generative tasks like inpainting. On the other hand, generative models such as Flow Matching pushed the boundary in image sampling yet lack a clear method for efficient use in image restoration. We propose to combine the PnP framework with Flow Matching (FM) by defining a time-dependent denoiser using a pre-trained FM model. Our algorithm alternates between gradient descent steps on the data-fidelity term, reprojections onto the learned FM path, and denoising. Notably, our method is computationally efficient and memory-friendly, as it avoids backpropagation through ODEs and trace computations. We evaluate its performance on denoising, super-resolution, deblurring, and inpainting tasks, demonstrating superior results compared to existing PnP algorithms and Flow Matching based state-of-the-art methods.", "title_embedding_index": 11552, "title_abs_embedding_index": 11577}, {"title": "Mastering Syntax, Unlocking Semantics: A Mathematically Provable Two-stage Learning Process in Transformers", "link_suffix": "/forum?id=hNkXTqDrfb", "link": "https://openreview.net/forum?id=hNkXTqDrfb", "pdf_link": "https://openreview.net/pdf?id=hNkXTqDrfb", "keywords": "Two-stage learning, Optimization dynamics, Feature learning theory", "abstract": "Transformers have emerged as a cornerstone across various fields with extensive applications. \nHowever, the training dynamics of transformers remain relatively underexplored.\nIn this work, we present a novel perspective on how transformers acquire knowledge during the training dynamics, inspired by the feature learning theory. \nTo this end, we conceptualize each token as embodying two types of knowledge: elementary knowledge represented by syntactic information, and specialized knowledge represented by semantic information.\nBuilding on this data structure, we rigorously prove that transformers follow a syntax-then-semantics learning paradigm, i.e., first mastering syntax in the Elementary Stage and then unlocking semantics in the subsequent Specialized Stage.\nThe results are derived from the training dynamics analysis and finite-time convergence within the in-context learning framework for supervised classification.\nTo our best knowledge, this is the \\textbf{\\emph{first}} rigorous result of a two-stage optimization process in transformers from a feature learning perspective. Empirical findings on real-world language datasets support the theoretical results of the two-stage learning process. \nMoreover, the spectral properties of attention weights, derived from our theoretical framework, align with the experimental observations, providing further validation.", "title_embedding_index": 11553, "title_abs_embedding_index": 11578}, {"title": "Learning Robust EEG Representations with a Large Spatiotemporal Transformer as a Foundation Model", "link_suffix": "/forum?id=V5Zn0VVvBE", "link": "https://openreview.net/forum?id=V5Zn0VVvBE", "pdf_link": "https://openreview.net/pdf?id=V5Zn0VVvBE", "keywords": "Brain-computer interfaces, EEG representations, foundation model, masked autoencoder, spatial-temporal transformer", "abstract": "Electroencephalography (EEG)-based brain-computer interfaces (BCIs) serve many control paradigms by relying on a variety in active brain regions and EEG features. Developing a universal EEG foundation model has been challenging due to the large variety in recording setups and experimental tasks. Additionally, researchers often contend with limited labeled data, given that EEG recordings are often unrelated to task-specific activity, making it difficult to utilize large deep-learning models effectively. In this study, we propose a novel, yet simple spatiotemporal EEG transformer (ST-EEGFormer) that projects segments (\u201cpatches\u201d) of raw EEG data into an embedding space enriched with a spatial and temporal embedding, allowing the model to effectively handle EEG data exhibiting various channel set-ups and time lengths. To improve data efficiency, we first employed a masked autoencoder (MAE) task to pretrain the ST-EEGFormer in a self-supervised learning manner on a dataset combining six different motor imagery (MI) datasets, a P300 dataset, and a steady-state visual evoked potential (SSVEP) dataset, all of which are public. Next, we benchmarked the pretrained model, after fine-tuning, on diverse downstream classification tasks. In order to assess the generalization capability, we further evaluated our model on two additional public datasets, not used for pretraining, a seizure classification dataset and an online MI BCI dataset, and compared its performance against a simple linear model, EEGNet, the classic CNN-based benchmark model, and the state-of-the-art EEG Conformer model. The results demonstrate the effectiveness of pretraining large ST-EEGFormers through self-supervised learning on diverse EEG data sources. The pretrained ST-EEGFormers were able to learn robust EEG representations, achieving higher classification accuracies than the benchmarked models across all eight pretraining datasets and exhibiting strong generalization on new datasets with limited training data. Finally, we report several visualizations of the model including the features on which the results are based. The pretrained model weights and code will be made publicly available upon acceptance of this paper.", "title_embedding_index": 11554, "title_abs_embedding_index": 11579}, {"title": "Broaden your SCOPE! Efficient Conversation Planning for LLMs with Semantic Space", "link_suffix": "/forum?id=3cgMU3TyyE", "link": "https://openreview.net/forum?id=3cgMU3TyyE", "pdf_link": "https://openreview.net/pdf?id=3cgMU3TyyE", "keywords": "Conversation Planning, Tree search for LLM", "abstract": "Large language models (LLMs) are used in chatbots or AI assistants to hold conversations with a human user. In such applications, the quality (e.g., user engagement, safety) of a conversation is important and can only be exactly known at the end of the conversation. To maximize its expected quality, conversation planning reasons about the stochastic transitions within a conversation to select the optimal LLM response at each turn. Existing simulation-based conversation planning algorithms typically select the optimal response by simulating future conversations with a large number of LLM queries at every turn. However, this process is extremely time-consuming and hence impractical for real-time conversations. This paper presents a novel approach called Semantic space COnversation Planning with improved Efficiency (SCOPE) that exploits the dense semantic representation of conversations to perform conversation planning efficiently. In particular, SCOPE models the stochastic transitions in conversation semantics and their associated rewards to plan entirely within the semantic space. This gives the advantage of allowing the optimal LLM response to be selected at every conversation turn without needing additional LLM queries for simulation. As a result, SCOPE can perform conversation planning 70 times faster than conventional simulation-based planning algorithms when applied to a wide variety of conversation starters and two reward functions seen in the real world, yet achieving a higher reward within a practical planning budget.", "title_embedding_index": 11555, "title_abs_embedding_index": 11580}, {"title": "Logicbreaks: A Framework for Understanding Subversion of Rule-based Inference", "link_suffix": "/forum?id=pljYMCYDWJ", "link": "https://openreview.net/forum?id=pljYMCYDWJ", "pdf_link": "https://openreview.net/pdf?id=pljYMCYDWJ", "keywords": "Logic, reasoning, inference, language model, jailbreak", "abstract": "We study how to subvert large language models (LLMs) from following prompt-specified rules.\nWe model rule-following as inference in propositional Horn logic, a mathematical system in which rules have the form ``if $P$ and $Q$, then $R$'' for some propositions $P$, $Q$, and $R$.\nWe prove that although LLMs can faithfully follow such rules, maliciously crafted prompts can mislead even idealized, theoretically constructed models.\nEmpirically, we find that the reasoning behavior of LLMs aligns with that of our theoretical constructions, and popular attack algorithms find adversarial prompts with characteristics predicted by our theory.\nOur logic-based framework provides a novel perspective for mechanistically understanding the behavior of LLMs in rule-based settings such as jailbreak attacks.", "title_embedding_index": 11556, "title_abs_embedding_index": 11581}, {"title": "Periodic Materials Generation using Text-Guided Joint Diffusion Model", "link_suffix": "/forum?id=AkBrb7yQ0G", "link": "https://openreview.net/forum?id=AkBrb7yQ0G", "pdf_link": "https://openreview.net/pdf?id=AkBrb7yQ0G", "keywords": "ML4Materials, Diffusion Models, Periodic Material Generation, AI4Science", "abstract": "Equivariant diffusion models have emerged as the prevailing approach for generating novel crystal materials due to their ability to leverage the physical symmetries of periodic material structures. However, current models do not effectively learn the joint distribution of atom types, fractional coordinates, and lattice parameters of the crystal material in a cohesive end-to-end diffusion framework. Also, none of these models work under realistic setups, where users specify the desired characteristics that the generated structures must match. In this work, we introduce TGDMat, a novel text-guided diffusion model designed for 3D periodic material generation. Our approach integrates global structural knowledge through textual descriptions at each denoising step while jointly generating atom coordinates, types, and lattice parameters using a periodic-E(3)-equivariant graph neural network. Through extensive experiments with popular datasets on benchmark tasks, we first demonstrate that integrating textual knowledge significantly improves the material generation capabilities of existing state-of-the-art models. Furthermore, we show that TGDMat surpasses text-guided variants of existing baseline methods by a substantial margin, highlighting the effectiveness of our joint diffusion paradigm. Additionally, incorporating textual knowledge reduces overall training and sampling computational overhead while enhancing generative performance when utilizing real-world textual prompts from experts.", "title_embedding_index": 11557, "title_abs_embedding_index": 11582}, {"title": "LAION-C: An out-of-distribution benchmark for web-scale vision models", "link_suffix": "/forum?id=aAcOaJYbUg", "link": "https://openreview.net/forum?id=aAcOaJYbUg", "pdf_link": "https://openreview.net/pdf?id=aAcOaJYbUg", "keywords": "OOD, representation learning, benchmark, model evaluation, vision, classification", "abstract": "Out-of-distribution (OOD) robustness is a desired property of computer vision models. Improving model robustness requires high-quality signals from robustness benchmarks to quantify progress. While various benchmark datasets such as ImageNet-C were proposed in the ImageNet era, most ImageNet-C corruption types are no longer OOD relative to today's large datasets scraped from the web, which already contain common corruptions such as blur or JPEG compression artifacts. Consequently, these standard benchmarks are no longer well-suited for evaluating OOD robustness in the era of web-scale datasets. Indeed, recent models show saturating scores on ImageNet-era OOD benchmarks, indicating that it is unclear whether models trained on web-scale datasets truly become better at OOD generalization or whether they have simply been exposed to the test distortions during training. To address this, we here introduce LAION-C as a benchmark alternative for ImageNet-C. LAION-C consists of six novel distortion types across five severity levels designed to be OOD, even for web-scale datasets such as LAION. In a comprehensive evaluation of state-of-the-art models, we find that the LAION-C dataset poses significant challenges to contemporary models. We additionally conducted a psychophysical experiment to evaluate the difficulty of our proposed corruptions for human observers, enabling a comparison of models to lab-quality human robustness data. We observe a paradigm shift in OOD generalization: from humans outperforming models to the best models now matching or outperforming the best human observers.", "title_embedding_index": 11558, "title_abs_embedding_index": 11583}, {"title": "Deep Temporal Deaggregation: Large-Scale Spatio-Temporal Generative Models", "link_suffix": "/forum?id=dDdxbdhMsY", "link": "https://openreview.net/forum?id=dDdxbdhMsY", "pdf_link": "https://openreview.net/pdf?id=dDdxbdhMsY", "keywords": "generative learning, mobility data, denoising diffusion probablistic models", "abstract": "Access to spatio-temporal trajectory data is essential for improving infrastructure, preventing the spread of disease and for building autonomous vehicles. However, it remains underutilized due to limited availability, as it cannot be shared publicly due privacy concerns or other sensitive attributes. Generative time-series models have shown promise in generating non-sensitive data, but show poor performance for large-scale and complex environments. In this paper we propose a spatio-temporal generative model for trajectories, TDDPM, which outperforms and scales substantially better than state-of-the-art. The focus is primarily on trajectories of peoples' movement in cities. We propose a conditional distribution approach which unlock out-of-distribution generalization, such as to city-areas not trained on, from a spatial aggregate prior. We also show that data can be generated in a privacy-preserving manner using $k$-anonymity. Further, we propose a new comprehensive benchmark across several standard datasets, and evaluation measures, considering key distribution properties.", "title_embedding_index": 11559, "title_abs_embedding_index": 11584}, {"title": "M3GIA: A Cognition Inspired Multilingual and Multimodal General Intelligence Ability Benchmark", "link_suffix": "/forum?id=79fjGDmw90", "link": "https://openreview.net/forum?id=79fjGDmw90", "pdf_link": "https://openreview.net/pdf?id=79fjGDmw90", "keywords": "Benchmark, Multimodal, Multilingual, Cognitive", "abstract": "As recent multi-modality large language models (MLLMs) have shown formidable proficiency on various complex tasks, there has been increasing attention on debating whether these models could eventually mirror human intelligence. However, existing benchmarks mainly focus on evaluating solely on task performance, such as the accuracy of identifying the attribute of an object. Combining well-developed cognitive science to understand the intelligence of MLLMs beyond superficial achievements remains largely unexplored. To this end, we introduce the first cognitive-driven multi-lingual and multi-modal benchmark to evaluate the general intelligence ability of MLLMs, dubbed M3GIA. Specifically, we identify five key cognitive factors based on the well-recognized Cattell-Horn-Carroll (CHC) model of intelligence and propose a novel evaluation metric. In addition, since most MLLMs are trained to perform in different languages, a natural question arises: is language a key factor influencing the cognitive ability of MLLMs? As such, we go beyond English to encompass other languages based on their popularity, including Chinese, French, Spanish, Portuguese and Korean, to construct our M3GIA. We make sure all the data relevant to the cultural backgrounds are collected from their native context to avoid English-centric bias. We collected a significant corpus of data from human participants, revealing that the most advanced MLLM reaches the lower boundary of human intelligence in English. Yet, there remains a pronounced disparity in the other five languages assessed. We also reveals an interesting winner takes all phenomenon that are aligned with the discovery in cognitive studies. Our benchmark will be open-sourced, with the aspiration of facilitating the enhancement of cognitive capabilities in MLLMs.", "title_embedding_index": 11560, "title_abs_embedding_index": 11585}, {"title": "Revised NTK Analysis of Optimization and Generalization with Its Extensions to Arbitrary Initialization", "link_suffix": "/forum?id=3vSN5Oumob", "link": "https://openreview.net/forum?id=3vSN5Oumob", "pdf_link": "https://openreview.net/pdf?id=3vSN5Oumob", "keywords": "neural tangent kernel, optimization, generalization", "abstract": "Recent theoretical works based on the neural tangent kernel (NTK) have shed light on the optimization and generalization of over-parameterized neural networks, and partially bridge the gap between their practical success and classical learning theory. However, the existing NTK-based analysis has a limitation that the scaling of the initial parameter should decrease with respect to the sample size which is contradictory to the practical initialization scheme. To address this issue, in this paper, we present the revised NTK analysis of optimization and generalization of overparametrized neural networks, which successfully remove the dependency on the sample size of the initialization. Based on our revised analysis, we further extend our theory that allow for arbitrary initialization, not limited to Gaussian initialization. Under our initialization-independent analysis, we propose NTK-based regularizer that can improve the model generalization, thereby illustrating the potential to bridge the theory and practice while also supporting our theory. Our numerical simulations demonstrate that the revised theory indeed can achieve the significantly lower generalization error bound compared to existing error bound. Also importantly, the proposed regularizer also corroborate our theory on the arbitrary initialization with fine-tuning scenario, which takes the first step for NTK theory to be promisingly applied to real-world applications.", "title_embedding_index": 11561, "title_abs_embedding_index": 11586}, {"title": "How Much Can RAG Help the Reasoning of LLM?", "link_suffix": "/forum?id=Q6M7bZIo9t", "link": "https://openreview.net/forum?id=Q6M7bZIo9t", "pdf_link": "https://openreview.net/pdf?id=Q6M7bZIo9t", "keywords": "RAG, Reasoning, LLM", "abstract": "Retrieval-Augmented Generation (RAG) has gained significant popularity in modern Large Language Models (LLMs) due to its effectiveness in introducing new knowledge and reducing hallucinations. However, the deep understanding of RAG remains limited, how does RAG help the reasoning process and can RAG help improve the reasoning capability remains question. While external documents are typically considered as a method to incorporate domain-specific information, they also contain intermediate reasoning results related to the query, this suggests that documents could enhance the reasoning capability of LLMs, which has not been previously explored. In this paper, we investigate this issue in depth and find that while RAG can assist with reasoning, the help is limited. If we conceptualize the reasoning process as a tree with fixed depth, then RAG struggles to assist LLMs in performing deeper reasoning. Additionally, the information in the documents requires preprocessing to filter out noise. We demonstrate that this preprocessing is difficult to achieve simply fine-tuning of the LLM, it often necessitates numerous additional transformer layers to solve the problem. To simplify the problem, we propose DPrompt tuning, which effectively resolves the issue within just limited transformer layers, leading to improved performance.", "title_embedding_index": 11562, "title_abs_embedding_index": 11587}, {"title": "Understanding Virtual Nodes: Oversquashing and Node Heterogeneity", "link_suffix": "/forum?id=NmcOAwRyH5", "link": "https://openreview.net/forum?id=NmcOAwRyH5", "pdf_link": "https://openreview.net/pdf?id=NmcOAwRyH5", "keywords": "Graph Neural Networks, Message Passing, Virtual Nodes, Oversquashing, Graph Transformers", "abstract": "While message passing neural networks (MPNNs) have convincing success in a range of applications, they exhibit limitations such as the oversquashing problem and their inability to capture long-range interactions. Augmenting MPNNs with a virtual node (VN) removes the locality constraint of the layer aggregation and has been found to improve performance on a range of benchmarks. We provide a comprehensive theoretical analysis of the role of VNs and benefits thereof, through the lenses of oversquashing and sensitivity analysis. First, we characterize, precisely, how the improvement afforded by VNs on the mixing abilities of the network and hence in mitigating oversquashing, depends on the underlying topology. We then highlight that, unlike Graph-Transformers (GTs), classical instantiations of the VN are often constrained to assign uniform importance to different nodes. Consequently, we propose a variant of VN with the same computational complexity, which can have different sensitivity to nodes based on the graph structure. We show that this is an extremely effective and computationally efficient baseline for graph-level tasks.", "title_embedding_index": 11563, "title_abs_embedding_index": 11588}, {"title": "TODO: Enhancing LLM Alignment with Ternary Preferences", "link_suffix": "/forum?id=utkGLDSNOk", "link": "https://openreview.net/forum?id=utkGLDSNOk", "pdf_link": "https://openreview.net/pdf?id=utkGLDSNOk", "keywords": "LLM, Preference alignment, Ternary Preference", "abstract": "Aligning large language models (LLMs) with human intent is critical for enhancing their performance across a variety of tasks. Standard alignment techniques, such as Direct Preference Optimization (DPO), often rely on the binary Bradley-Terry (BT) model, which can struggle to capture the complexities of human preferences\u2014particularly in the presence of noisy or inconsistent labels and frequent ties. To address these limitations, we introduce the Tie-rank Oriented Bradley-Terry model (TOBT), an extension of the BT model that explicitly incorporates ties, enabling more nuanced preference representation. Building on this, we propose Tie-rank Oriented Direct Preference Optimization (TODO), a novel alignment algorithm that leverages TOBT's ternary ranking system to improve preference alignment. In evaluations on Mistral-7B and Llama 3-8B models, TODO consistently outperforms DPO in modeling preferences across both in-distribution and out-of-distribution datasets. Additional assessments using MT Bench and benchmarks such as Piqa, ARC-c, and MMLU further demonstrate TODO's superior alignment performance. Notably, TODO also shows strong results in binary preference alignment, highlighting its versatility and potential for broader integration into LLM alignment. The code for TODO is made publicly available.", "title_embedding_index": 11564, "title_abs_embedding_index": 11589}, {"title": "BiVWAC: Improving deep reinforcement learning algorithms using Bias-Variance Weighted Actor-Critic", "link_suffix": "/forum?id=xJUZHhrh3N", "link": "https://openreview.net/forum?id=xJUZHhrh3N", "pdf_link": "https://openreview.net/pdf?id=xJUZHhrh3N", "keywords": "Reinforcement Learning, Bias, Variance, Actor-Critic, Deep Reinforcement Learning, SAC, PPO, AVEC, Mujoco", "abstract": "We introduce $\\textrm{\\textbf{Bi}as-\\textbf{V}ariance \\textbf{W}eighted \\textbf{A}ctor \\textbf{C}ritic (\\textbf{BiVWAC})}$, a modification scheme for actor-critic algorithms allowing control over the bias-variance weighting in the critic. In actor-critic algorithms, the critic loss is the Mean Squared Error (MSE). The MSE may be decomposed in terms of bias and variance. Based on this decomposition, BiVWAC constructs a new critic loss, through a hyperparameter $\\alpha$, to weigh bias vs variance. MSE and Actor with Variance Estimated Critic (AVEC, which only considers the variance in the MSE decomposition) are special cases of this weighting for $\\alpha=0.5$ and $\\alpha=0$ respectively. We demonstrate the theoretical consistency of our new critic loss and measure its performance on a set of tasks. We also study value estimation and gradient estimation capabilities of BiVWAC to understand the means by which BiVWAC impacts performance.\n  We show experimentally that the MSE is suboptimal as a critic loss when compared to other $\\alpha$ values. We equip SAC and PPO with the BiVWAC loss to obtain BiVWAC-SAC and BiVWAC-PPO and we propose a safe $\\alpha$ value, $\\alpha^*$, for which BiVWAC-SAC is better than or equal to SAC in all studied tasks but one in terms of policy performance. We also point out that BiVWAC introduces minimal changes to the algorithms and virtually no additional computational cost. \n  In addition we also present a method to compare the impact of critic modifications between algorithms in a sound manner.", "title_embedding_index": 11565, "title_abs_embedding_index": 11590}, {"title": "Training Large Neural Networks With Low-Dimensional Error Feedback", "link_suffix": "/forum?id=fD8Whiy7ca", "link": "https://openreview.net/forum?id=fD8Whiy7ca", "pdf_link": "https://openreview.net/pdf?id=fD8Whiy7ca", "keywords": "Feedback Alignment, Brain Inspired, Biologically Plausible Learning, Theoretical Analysis, Visual Pathway", "abstract": "Training deep neural networks typically relies on backpropagating high-dimensional error signals\u2014a computationally intensive and biologically implausible process. However, since most tasks involve low-dimensional outputs, we propose that low-dimensional error signals may suffice for effective learning. To test this hypothesis, we introduce a novel local learning rule based on Feedback Alignment that leverages indirect, low-dimensional error feedback to train large networks. Our method decouples the backward pass from the forward pass, enabling precise control over error signal dimensionality while maintaining high-dimensional representations. We begin with a detailed theoretical derivation for linear networks, which forms the foundation of our learning framework, and extend our approach to nonlinear and convolutional architectures. Remarkably, we demonstrate that even minimal error dimensionality\u2014on the order of the task dimensionality\u2014can achieve performance matching that of traditional backpropagation. Furthermore, our rule enables efficient training of convolutional networks, which have previously been resistant to Feedback Alignment methods, with minimal error. This breakthrough not only paves the way for more biologically plausible models of learning but also challenges the conventional reliance on high-dimensional gradient signals in neural network training. Our findings suggest that low-dimensional error signals can be as effective as high-dimensional ones, prompting a reevaluation of gradient-based learning in high-dimensional systems. Ultimately, our work offers a fresh perspective on neural network optimization and contributes to understanding learning mechanisms in both artificial and biological systems.", "title_embedding_index": 11566, "title_abs_embedding_index": 11591}, {"title": "Cost-Sensitive Multi-Fidelity Bayesian Optimization", "link_suffix": "/forum?id=F6s7OApF0n", "link": "https://openreview.net/forum?id=F6s7OApF0n", "pdf_link": "https://openreview.net/pdf?id=F6s7OApF0n", "keywords": "gray-box hyperparameter optimization, multi-fidelity hyperparameter optimization, cost-sensitive Bayesian optimization, learning curve extrapolation, transfer learning", "abstract": "In this paper, we address the problem of cost-sensitive multi-fidelity Bayesian Optimization (BO) for efficient hyperparameter optimization (HPO). Specifically, we assume a scenario where users want to early-stop the BO when performance increase is not satisfactory with respect to the required computational cost. Motivated by this scenario, we introduce \\emph{utility function}, which is predefined by each user and describes the trade-off between the required BO steps and the cumulative best performance during the BO. This utility function, combined with our novel acquisition function and the stopping criteria, allows us to dynamically choose for each BO step the best configuration that we expect to achieve the maximum utility in future, and also automatically stop the BO around the maximum utility. Further, we improve the sample efficiency of existing learning curve (LC) extrapolation methods (e.g., Prior Fitted Networks) with transfer learning, while successfully capturing the correlations between different configurations to develop a sensible surrogate function for multi-fidelity BO. We validate our algorithm on various LC datasets and found it outperform all the previous multi-fidelity BO baselines, achieving significantly better trade-off between cost and performance of multi-fidelity BO.", "title_embedding_index": 11567, "title_abs_embedding_index": 11592}, {"title": "Online Auction for Ads and Organics", "link_suffix": "/forum?id=eRduvBHLQ1", "link": "https://openreview.net/forum?id=eRduvBHLQ1", "pdf_link": "https://openreview.net/pdf?id=eRduvBHLQ1", "keywords": "online auction, mechanism design, multi-objective optimization", "abstract": "This paper introduces the first online blending auction mechanism design for sponsored items (ads) alongside organic items (organics), ensuring guaranteed Pareto optimality for platform revenue, advertiser utilities, and user interest (measured through clicks). We innovatively define an umbrella term, \"traffic item,\" to encompass both organics and auctionable ad items, where an organic represents a unit of traffic to be auctioned, valued positively by attracting user interest with a fixed zero bid and payment. The online blending traffic distribution problem is thus transformed into an auction problem with unified valuation metric for the traffic item, which is subsequently formulated as an online multi-objective constrained optimization problem. We derive a Pareto equation for this optimization problem, characterizing the optimal auction mechanism set by its solution set. This solution is implemented through a novel two-stage Adaptive Modeled Mechanism Design (AMMD), which (1) trains a hypernetwork to learn a family of parameterized mechanisms, each corresponding to a specific solution of the Pareto equation, and (2) employs feedback-based online control to adaptively adjust the mechanism parameters, ensuring real-time optimality in a dynamic environment. Extensive experiments demonstrate that AMMD outperforms existing methods in both click-through rates and revenue across multiple auction scenarios, particularly highlighting its adaptability to online environments. The code has been submitted and will be released publicly.", "title_embedding_index": 11568, "title_abs_embedding_index": 11593}, {"title": "A Contextual Online Learning Theory of Brokerage", "link_suffix": "/forum?id=9BVMD3keG8", "link": "https://openreview.net/forum?id=9BVMD3keG8", "pdf_link": "https://openreview.net/pdf?id=9BVMD3keG8", "keywords": "contextual bandits, bilateral trade, regret minimization, theory", "abstract": "We study the role ofcontextual informationin the online learning problem of brokerage between traders.\nAt each round, two traders arrive with secret valuations about an asset they wish to trade.\nThe broker suggests a trading price based on contextual data about the asset.\nThen, the traders decide to buy or sell depending on whether their valuations are higher or lower than the brokerage price.\nWe assume the market value of traded assets is an unknown linear function of a $d$-dimensional vector representing the contextual information available to the broker. Additionally, at each time step, we model traders' valuations as independent bounded zero-mean perturbations of the asset's current market value, allowing for potentially different unknown distributions across traders and time steps.\nConsistently with the existing online learning literature, we evaluate the performance of a learning algorithm with the regret with respect to thegain from trade.\nIf the noise distributions admit densities bounded by some constant $L$, then, for any time horizon $T$:If the agents' valuations are revealed after each interaction, we provide an algorithm achieving $O ( L d \\ln T )$ regret, and show a corresponding matching lower bound of $\\Omega( Ld \\ln T )$.If only their willingness to sell or buy at the proposed price is revealed after each interaction, we provide an algorithm achieving $O( \\sqrt{LdT \\ln T })$ regret, and show that this rate is optimal (up to logarithmic factors), via a lower bound of $\\Omega(\\sqrt{LdT})$.To complete the picture, we show that if the bounded density assumption is lifted, then the problem becomes unlearnable, even with full feedback.", "title_embedding_index": 11569, "title_abs_embedding_index": 11594}, {"title": "Neural Circuit Architectural Priors for Quadruped Locomotion", "link_suffix": "/forum?id=EOLBKobfd1", "link": "https://openreview.net/forum?id=EOLBKobfd1", "pdf_link": "https://openreview.net/pdf?id=EOLBKobfd1", "keywords": "neuroscience, neural circuits, motor control", "abstract": "Learning-based approaches to quadruped locomotion commonly adopt generic policy architectures like fully connected MLPs. As such architectures contain few inductive biases, it is in practice common to incorporate priors in the form of rewards, training curricula, imitation data, or trajectory generators. In nature, animals are born with priors in the form of their nervous system's architecture, which has been shaped by evolution to confer innate ability and efficient learning. For instance, a horse can walk within hours of birth and can quickly improve with practice. Such architectural priors can also be useful in ANN architectures for AI. In this work, we explore the advantages of a biologically inspired ANN architecture for quadruped locomotion based on neural circuits in the limbs and spinal cord of mammals. Our architecture achieves good innate performance and comparable final performance to MLPs, while using less data and orders of magnitude fewer parameters. Our architecture also exhibits better generalization to task variations, even admitting deployment on a physical robot without standard sim-to-real methods. This work shows that neural circuits can provide valuable architectural priors for locomotion and encourages future work in other sensorimotor skills.", "title_embedding_index": 11570, "title_abs_embedding_index": 11595}, {"title": "Occlusion-aware Non-Rigid Point Cloud Registration via Unsupervised Neural Deformation Correntropy", "link_suffix": "/forum?id=cjJqU40nYS", "link": "https://openreview.net/forum?id=cjJqU40nYS", "pdf_link": "https://openreview.net/pdf?id=cjJqU40nYS", "keywords": "Unsupervised Deformation, Neural Implicit Representations, Correntropy, Locally Linear Reconstruction", "abstract": "Non-rigid alignment of point clouds is crucial for scene understanding, reconstruction, and various computer vision and robotics tasks. Recent advancements in implicit deformation networks for non-rigid registration have significantly reduced the reliance on large amounts of annotated training data. However, existing state-of-the-art methods still face challenges in handling occlusion scenarios. To address this issue, this paper introduces an innovative unsupervised method called Occlusion-Aware Registration (OAR) for non-rigidly aligning point clouds. The key innovation of our method lies in the utilization of the adaptive correntropy function as a localized similarity measure, enabling us to treat individual points distinctly. In contrast to previous approaches that solely minimize overall deviations between two shapes, we combine unsupervised implicit neural representations with the maximum correntropy criterion to optimize the deformation of unoccluded regions. This effectively avoids collapsed, tearing, and other physically implausible results. Moreover, we present a theoretical analysis and establish the relationship between the maximum correntropy criterion and the commonly used Chamfer distance, highlighting that the correntropy-induced metric can be served as a more universal measure for point cloud analysis. Additionally, we introduce\nlocally linear reconstruction to ensure that regions lacking correspondences between shapes still undergo physically natural deformations. Our method achieves superior or competitive performance compared to existing approaches, particularly when dealing with occluded geometries. We also demonstrate the versatility of our method in challenging tasks such as large deformations, shape interpolation, and shape completion under occlusion disturbances.", "title_embedding_index": 11571, "title_abs_embedding_index": 11596}, {"title": "Operator Deep Smoothing for Implied Volatility", "link_suffix": "/forum?id=DPlUWG4WMw", "link": "https://openreview.net/forum?id=DPlUWG4WMw", "pdf_link": "https://openreview.net/pdf?id=DPlUWG4WMw", "keywords": "Financial Engineering, Neural Operators, Option Pricing, Function Interpolation, Nowcasting", "abstract": "We devise a novel method for nowcasting implied volatility based on neural operators.\nBetter known as implied volatility smoothing in the financial industry, nowcasting of implied volatility means constructing a smooth surface that is consistent with the prices presently observed on a given option market.\nOption price data arises highly dynamically in ever-changing spatial configurations, which poses a major limitation to foundational machine learning approaches using classical neural networks.\nWhile large models in language and image processing deliver breakthrough results on vast corpora of raw data, in financial engineering the generalization from big historical datasets has been hindered by the need for considerable data pre-processing.\nIn particular, implied volatility smoothing has remained an instance-by-instance, hands-on process both for neural network-based and traditional parametric strategies.\nOur generaloperator deep smoothingapproach, instead, directly maps observed data to smoothed surfaces.\nWe adapt the graph neural operator architecture to do so with high accuracy on ten years of raw intraday S&P 500 options data, using a single model instance.\nThe trained operator adheres to critical no-arbitrage constraints and is robust with respect to subsampling of inputs (occurring in practice in the context of outlier removal).\nWe provide extensive historical benchmarks and showcase the generalization capability of our approach in a comparison with classical neural networks and SVI, an industry standard parametrization for implied volatility. \nThe operator deep smoothing approach thus opens up the use of neural networks on large historical datasets in financial engineering.", "title_embedding_index": 11572, "title_abs_embedding_index": 11597}, {"title": "Re-evaluating Open-ended Evaluation of Large Language Models", "link_suffix": "/forum?id=kbOAIXKWgx", "link": "https://openreview.net/forum?id=kbOAIXKWgx", "pdf_link": "https://openreview.net/pdf?id=kbOAIXKWgx", "keywords": "Evaluation, Game Theory, Large Language Model, Equilibrium, Open-Ended", "abstract": "Evaluation has traditionally focused on ranking candidates for a specific skill. Modern generalist models, such as Large Language Models (LLMs), decidedly outpace this paradigm. Open-ended evaluation systems, where candidate models are compared on user-submitted prompts, have emerged as a popular solution. Despite their many advantages, we show that the current Elo-based rating systems can be susceptible to and even reinforce biases in data, intentional or accidental, due to their sensitivity to redundancies. To address this issue, we propose evaluation as a 3-player game, and introduce novel game-theoretic solution concepts to ensure robustness to redundancy. We show that our method leads to intuitive ratings and provide insights into the competitive landscape of LLM development.", "title_embedding_index": 11573, "title_abs_embedding_index": 11598}, {"title": "A Simple Data-Parameters Balancing Framework for Early Ventricular Activation Origin Localization", "link_suffix": "/forum?id=QqypKtKiWX", "link": "https://openreview.net/forum?id=QqypKtKiWX", "pdf_link": "https://openreview.net/pdf?id=QqypKtKiWX", "keywords": "Early Ventricular Activation Origin Localization;", "abstract": "Accurately identifying the site of origin (SoO) of early ventricular activation is crucial for catheter ablation, an effective therapeutic option for treating ventricular arrhythmia. However, due to the limited availability of clinical data and the errors introduced during data preprocessing, achieving precise localization remains a challenge. While deep learning models offer an end-to-end approach for data input in the ECG field, they often suffer from overfitting caused by limited training data, hindering continuous performance improvement. This paper proposes a Simple data-parameters Balancing framework for early ventricular activation Origin Localization (SimBOL). By using onset-based data augmentation, the SimBOL method expands the training data derived from clinical samples. The framework utilizes a small-scale 1D convolution model that balances the relationship between available training data and model complexity, effectively mitigating overfitting and eliminating the need for extensive data preprocessing.SimBOL achieves a localization error as low as 9.83 mm, which meets clinical acceptable localization error < 10 mm and outperforming existing methods in predicting the SoO of early ventricular activation. The discussion about data augmentation and model architecture on ECG signal processing, offering new insights into optimizing deep learning applications for ECG-based tasks.", "title_embedding_index": 11574, "title_abs_embedding_index": 11599}]
[{"title": "ZCTG: A Zero-Shot Framework for Automatic Video Chaptering and Title Generation", "link_suffix": "/forum?id=QwKieXLF6x", "link": "https://openreview.net/forum?id=QwKieXLF6x", "pdf_link": "https://openreview.net/pdf?id=QwKieXLF6x", "keywords": "Video Chapter Generation, Large Language Models, Scene Graph", "abstract": "In the vast landscape of video content, breaking down lengthy videos into chapters accompanied by concise, descriptive titles greatly enhances searchability and retrieval efficiency. While recent advancements in this field often incorporate multiple data modalities along with human-annotated chapter titles, access to such data, like speech transcripts or audio, is not always guaranteed. Moreover, the manual annotation of chapter titles is expensive and time-consuming. To address these challenges, we introduce ZCTG, a novel and unified zero-shot framework designed to generate video chapters and their concise titles for untrimmed videos. ZCTG utilizes the combined capabilities of scene graphs and Large Language Models (LLMs). The advantages of ZCTG are three-fold: 1) offers practical utility, relying solely on video data; 2) eliminates the need for detailed chapter title supervision; 3) exhibits excellent generalization capabilities in a completely zero-shot setting, without any training needed. We conduct an extensive evaluation on VidChapters-7M and GTEA datasets, which include videos of varying duration and domains, to demonstrate the efficacy of our proposed framework.", "title_embedding_index": 14750, "title_abs_embedding_index": 14775}, {"title": "PoincareNorm: Rethinking Over-smoothing beyond Dirichlet energy", "link_suffix": "/forum?id=jrKPOQBq9i", "link": "https://openreview.net/forum?id=jrKPOQBq9i", "pdf_link": "https://openreview.net/pdf?id=jrKPOQBq9i", "keywords": "over-smoothing, node similarity measure\uff0cnormalization\u3002", "abstract": "Dirichlet energy is intuitive and commonly used to measure over-smoothing. However, Dirichlet energy can only capture information about the first-order derivative of features. In light of this, we propose a series of node similarity measures which are the energy of higher-order derivatives of features and generalize Dirichlet energy. After we rigorously analyze the property of proposed measures and its application to establish the sharp decay rate of Dirichlet energy under continuous diffusion or discrete random walk which is closely related to the first nonzero eigenvalue of graph Laplacian. Lastly, to address over-smoothing with respect to these measures, we propose a normalization termed PoincareNorm which generalizes PairNorm to control our proposed measures. We consider the semi-supervised node classification task in the scenario without missing features, PoincareNorm outperforms existing normalization methods.", "title_embedding_index": 14751, "title_abs_embedding_index": 14776}, {"title": "WILT: A Multi-Turn, Memorization-Robust Inductive Logic Benchmark for LLMs", "link_suffix": "/forum?id=Alba3Y7hcs", "link": "https://openreview.net/forum?id=Alba3Y7hcs", "pdf_link": "https://openreview.net/pdf?id=Alba3Y7hcs", "keywords": "Multi-Turn, Inductive Logic, Hypothesis Space Modeling, Overfitting Robustness, Benchmark", "abstract": "While large language models (LLMs) have shown impressive abilities across a wide range of domains, they still encounter significant challenges in reasoning tasks that require gathering evidence over multiple turns and drawing logical conclusions from this evidence. These challenges present significant obstacles for LLM chat user interfaces, which rely on multi-turn interactions to facilitate effective collaboration. This limitation leads to real-world issues; for example, service chatbots must gather necessary information from customers over multiple turns to diagnose and resolve problems effectively. Despite the multi-turn nature of many real-world LLM use cases, most existing benchmarks rely on carefully curated single-turn tests, which often blur the line between memorization and genuine reasoning. To address this, we introduce the $\\textbf{Wason Inductive Logic Test (WILT)}$, a simple yet challenging multi-turn reasoning benchmark designed to resist memorization. WILT is inspired by the Wason 2-4-6 task, where participants must infer a basic boolean function involving three variables (e.g., $x < y < z$) by proposing test cases (such as $(2, 4, 6)$). In WILT, each test starts from a clean slate, with only the initial instructions provided, preventing models from relying on pre-learned responses. Over several turns, models must interact with the environment by suggesting test cases to narrow the possible hypotheses and ultimately infer the hidden function based on the outcomes. Our findings reveal that LLMs struggle with this task, exhibiting various strengths and weaknesses: some are better at narrowing down the hypothesis space by proposing valuable test cases, while others are more adept at deducing the hidden function from observed cases. Despite these variations, the best-performing model achieves only 28% accuracy, highlighting a significant gap in LLM performance on complex multi-turn reasoning tasks.", "title_embedding_index": 14752, "title_abs_embedding_index": 14777}, {"title": "Improving LLM Reasoning through Scaling Inference Computation with Collaborative Verification", "link_suffix": "/forum?id=Qyile3DctL", "link": "https://openreview.net/forum?id=Qyile3DctL", "pdf_link": "https://openreview.net/pdf?id=Qyile3DctL", "keywords": "Verifier, Math Reasoning, LLMs", "abstract": "Despite significant advancements in the general capability of large language models (LLMs), they continue to struggle with consistent and accurate reasoning, especially in complex tasks such as mathematical and code reasoning. One key limitation is that LLMs are trained primarily on correct solutions, reducing their ability to detect and learn from errors, which hampers their ability to reliably verify and rank outputs. To address this, we scale up the inference-time computation by generating multiple reasoning paths and employing verifiers to assess and rank the generated outputs by correctness. To facilitate this, we introduce a comprehensive dataset consisting of correct and incorrect solutions for math and code tasks, generated by multiple LLMs. This diverse set of solutions enables verifiers to more effectively distinguish and rank correct answers from erroneous outputs. The training methods for building verifiers were selected based on an extensive comparison of existing approaches. Moreover, to leverage the unique strengths of different reasoning strategies, we propose a novel collaborative method integrating Chain-of-Thought (CoT) and Program-of-Thought (PoT) solutions for verification. CoT provides a clear, step-by-step reasoning process that enhances interpretability, while PoT, being executable, offers a precise and error-sensitive validation mechanism. By taking both of their strengths, our approach significantly improves the accuracy and reliability of reasoning verification. Our verifiers, Math-Rev and Code-Rev, demonstrate substantial performance gains to existing LLMs, achieving state-of-the-art results on benchmarks such as GSM8k and MATH and even outperforming GPT-4o with Qwen-72B-Instruct as the reasoner.", "title_embedding_index": 14753, "title_abs_embedding_index": 14778}, {"title": "Exploiting Structure in Offline Multi-Agent RL: The Benefits of Low Interaction Rank", "link_suffix": "/forum?id=AOlm45AUVS", "link": "https://openreview.net/forum?id=AOlm45AUVS", "pdf_link": "https://openreview.net/pdf?id=AOlm45AUVS", "keywords": "multi-agent reinforcement learning, offline learning, interaction rank, distribution shift", "abstract": "We study the problem of learning an approximate equilibrium in the offline multi-agent reinforcement learning (MARL) setting. We introduce a structural assumption---the interaction rank---and establish that functions with low interaction rank are significantly more robust to distribution shift compared to general ones. Leveraging this observation, we demonstrate that utilizing function classes with low interaction rank, when combined with regularization and no-regret learning, admits decentralized, computationally and statistically efficient learning in offline MARL. Our theoretical results are complemented by experiments that showcase the potential of critic architectures with low interaction rank in offline MARL, contrasting with commonly used single-agent value decomposition architectures.", "title_embedding_index": 14754, "title_abs_embedding_index": 14779}, {"title": "Fully-inductive Node Classification on Arbitrary Graphs", "link_suffix": "/forum?id=1Qpt43cqhg", "link": "https://openreview.net/forum?id=1Qpt43cqhg", "pdf_link": "https://openreview.net/pdf?id=1Qpt43cqhg", "keywords": "node classification, inductive generalization", "abstract": "One fundamental challenge in graph machine learning is generalizing to new graphs. Many existing methods following the inductive setup can generalize to test graphs with new structures, but assuming the feature and label spaces remain the same as the training ones. \nThis paper introduces the fully-inductive setup, where models should perform inference on arbitrary test graphs with new structures, feature and label spaces. We propose GraphAny as the first attempt to this challenging setup. GraphAny models inference on a new graph as an analytical solution to a LinearGNN, which can be naturally applied to graphs with any feature and label spaces. To further build a stronger model with learning capacity, we fuse multiple LinearGNN predictions with a learned inductive attention. Specifically, the attention module is carefully parameterized as a function of the entropy-normalized distance features between pairs of LinearGNN predictions to ensure generalization to new graphs. Empirically, GraphAny trained on a single Wisconsin dataset with only 120 labeled nodes can generalize to 30 new graphs with an average accuracy of 67.26%, surpassing not only all inductive baselines, but also strong transductive methods trained separately on each of the 30 test graphs.", "title_embedding_index": 14755, "title_abs_embedding_index": 14780}, {"title": "StoryGPT-V: Large Language Models as Consistent Story Visualizers", "link_suffix": "/forum?id=qQ5djlndm5", "link": "https://openreview.net/forum?id=qQ5djlndm5", "pdf_link": "https://openreview.net/pdf?id=qQ5djlndm5", "keywords": "Story Visualization; Large Language Models; Multimodal Coreference Resolution", "abstract": "Recent generative models have demonstrated impressive capabilities in generating realistic and visually pleasing images grounded on textual prompts. Nevertheless, a significant challenge remains in applying these models for the more intricate task of story visualization. Since it requires resolving pronouns (he, she, they) in the frame descriptions, i.e., anaphora resolution, and ensuring consistent characters and background synthesis across frames. \nYet, the emerging Large Language Model (LLM) showcases robust reasoning abilities to navigate through ambiguous references and process extensive sequences. Therefore, we introduce \\emph{StoryGPT-V}, which leverages the merits of the latent diffusion (LDM) and LLM to produce images with consistent and high-quality characters grounded on given story descriptions. \nFirst, we train a character-aware LDM, which takes character-augmented semantic embedding as input and includes the supervision of the cross-attention map using character segmentation masks, aiming to enhance character generation accuracy and faithfulness.\nIn the second stage, we enable an alignment between the output of LLM and the character-augmented embedding residing in the input space of the first-stage model. This harnesses the reasoning ability of LLM to address ambiguous references and the comprehension capability to memorize the context. We conduct comprehensive experiments on two visual story visualization benchmarks. Our model reports superior quantitative results and consistently generates accurate characters of remarkable quality with low memory consumption. Our code will be made publicly available\\footnote{Please refer to the \\href{https://storygpt-v.s3.amazonaws.com/index.html}{anonymouswebpage} for qualitative results.}.", "title_embedding_index": 14756, "title_abs_embedding_index": 14781}, {"title": "Post-hoc Reward Calibration: A Case Study on Length Bias", "link_suffix": "/forum?id=Iu8RytBaji", "link": "https://openreview.net/forum?id=Iu8RytBaji", "pdf_link": "https://openreview.net/pdf?id=Iu8RytBaji", "keywords": "RLHF; Reward Model;  Length Bias", "abstract": "Reinforcement Learning from Human Feedback aligns the outputs of Large Language Models with human values and preferences. Central to this process is the reward model (RM), which translates human feedback into training signals for optimising LLM behaviour. However, RMs can develop biases by exploiting spurious correlations in their training data, such as favouring outputs based on length or\nstyle rather than true quality. These biases can lead to incorrect output rankings, sub-optimal model evaluations, and the amplification of undesirable behaviours in LLMs alignment. This paper addresses the challenge of correcting such biases without additional data and training, introducing the concept of Post-hoc Reward Calibration. We first propose to use local average reward to estimate the bias term\nand, thus, remove it to approximate the underlying true reward. We then extend the approach to a more general and robust form with the Locally Weighted Regression. Focusing on the prevalent length bias, we validate our proposed approaches across three experimental settings, demonstrating consistent improvements: (1) a 3.11 average performance gain across 33 reward models on the RewardBench\ndataset; (2) improved agreement of RM produced rankings with GPT-4 evaluations and human preferences based on the AlpacaEval benchmark; and (3) improved Length-Controlled win rate (Dubois et al., 2024) of the RLHF process in multiple LLM\u2013RM combinations. According to our experiments, our method is computationally efficient and generalisable to other types of bias and RMs, offering a scalable and robust solution for mitigating biases in LLM alignment and evaluation.", "title_embedding_index": 14757, "title_abs_embedding_index": 14782}, {"title": "ObscuraCoder: Powering Efficient Code LM Pre-Training Via Obfuscation Grounding", "link_suffix": "/forum?id=VYvxrD7aS0", "link": "https://openreview.net/forum?id=VYvxrD7aS0", "pdf_link": "https://openreview.net/pdf?id=VYvxrD7aS0", "keywords": "code generation, code obfuscation, language modelling, code lm", "abstract": "Language models (LMs) have fast become a staple of code generation for developers. Their pre-training recipe has, however, remained stagnant over recent years, barring the occasional changes in data sourcing and filtering strategies. In particular, research exploring modifications to Code-LMs' pre-training objectives, geared towards improving data efficiency and better disentangling between syntax and semantics, has been noticeably sparse, especially compared with corresponding efforts in natural language LMs. In this work, we examine grounding on obfuscated code as a means of helping Code-LMs look beyond the surface-form syntax and enhance their pre-training sample efficiency. To this end, we compile ObscuraX, a dataset of approximately 55M source and obfuscated code pairs in seven languages. Subsequently, we pre-train ObscuraCoder models, ranging in size from 255M to 2.8B parameters, on a 272B-token corpus that includes ObscuraX and demonstrate that our obfuscation-based pretraining (OBF) recipe leads to consistent improvements in Code-LMs' abilities compared to both vanilla autoregressive pre-training as well as existing de-obfuscation (DOBF) objectives. ObscuraCoder demonstrates sizeable gains across multiple tests of syntactic and semantic code understanding, along with improved capabilities in multilingual code completion, multilingual code commit summarization, and multi-purpose library-oriented code generation.", "title_embedding_index": 14758, "title_abs_embedding_index": 14783}, {"title": "Successor Representations Enable Emergent Compositional Instruction Following", "link_suffix": "/forum?id=MG2Zkf0haD", "link": "https://openreview.net/forum?id=MG2Zkf0haD", "pdf_link": "https://openreview.net/pdf?id=MG2Zkf0haD", "keywords": "Robot Learning, Instruction Following, Compositional Generalization", "abstract": "Behavioral cloning (BC) has seen widespread adoption in scalable robot learning pipelines. These methods struggle to perform compositional generalization, where a new out-of-distribution evaluation task can be viewed as a sequence of simpler in-distribution steps. We augment goal-conditioned BC methods with a temporal alignment loss that learns to associate present and future states. This approach is able to generalize to novel composite tasks specified as goal images or language instructions, without assuming any additional reward supervision or explicit subtask planning. We evaluate our approach across diverse tabletop robotic manipulation tasks, showing substantial improvements for tasks specified with either language or goal images.", "title_embedding_index": 14759, "title_abs_embedding_index": 14784}, {"title": "Differentiable Causal Discovery for Latent Hierarchical Causal Models", "link_suffix": "/forum?id=Bp0HBaMNRl", "link": "https://openreview.net/forum?id=Bp0HBaMNRl", "pdf_link": "https://openreview.net/pdf?id=Bp0HBaMNRl", "keywords": "Differentiable causal discovery, causal representation learning, latent variable models, causal structure learning, causal identifiability", "abstract": "Discovering causal structures with latent variables from observational data is a fundamental challenge in causal discovery. Existing methods often rely on constraint-based, iterative discrete searches, limiting their scalability to large numbers of variables. Moreover, these methods frequently assume linearity or invertibility, restricting their applicability to real-world scenarios. We present new theoretical results on the identifiability of nonlinear latent hierarchical causal models, relaxing previous assumptions in literature about the deterministic nature of latent variables and exogenous noise. Building on these insights, we develop a novel differentiable causal discovery algorithm that efficiently estimates the structure of such models. To the best of our knowledge, this is the first work to propose a differentiable causal discovery method for nonlinear latent hierarchical models. Our approach outperforms existing methods in both accuracy and scalability. We demonstrate its practical utility by learning interpretable hierarchical latent structures from high-dimensional image data and demonstrate its effectiveness on downstream tasks.", "title_embedding_index": 14760, "title_abs_embedding_index": 14785}, {"title": "SyllableLM: Learning Coarse Semantic Units for Speech Language Models", "link_suffix": "/forum?id=dGSOn7sdWg", "link": "https://openreview.net/forum?id=dGSOn7sdWg", "pdf_link": "https://openreview.net/pdf?id=dGSOn7sdWg", "keywords": "Generative Spoken Language Modeling, Audio, Textless NLP, Representation Learning", "abstract": "Language models require tokenized inputs. However, tokenization strategies for continuous data like audio and vision are often based on simple heuristics such as fixed sized convolutions or discrete clustering, which do not necessarily align with the semantic structure of the data. For speech in particular, the high resolution of waveforms (16,000 samples/second or more) presents a significant challenge as speech-based language models have had to use several times more tokens per word than text-based language models. In this work, we introduce a controllable self-supervised technique to merge speech representations into coarser syllable-like units while still preserving semantic information. We do this by 1) extracting noisy boundaries through analyzing correlations in pretrained encoder losses and 2) iteratively improving model representations with a novel distillation technique. Our method produces controllable-rate semantic units at as low as 5Hz and 60bps and achieves SotA in syllabic segmentation and clustering. Using these coarse tokens, we successfully train SyllableLM, a Speech Language Model (SpeechLM) that matches or outperforms current SotA SpeechLMs on a range of spoken language modeling tasks. SyllableLM also achieves significant improvements in efficiency with a 30x reduction in training compute and a 4x wall-clock inference speedup.", "title_embedding_index": 14761, "title_abs_embedding_index": 14786}, {"title": "Exact Community Recovery under Side Information: Optimality of Spectral Algorithms", "link_suffix": "/forum?id=zhFyKgqxlz", "link": "https://openreview.net/forum?id=zhFyKgqxlz", "pdf_link": "https://openreview.net/pdf?id=zhFyKgqxlz", "keywords": "Community Detection, Spectral Algorithms, Side Information", "abstract": "We study the problem of exact community recovery in general, two-community block models, in the presence of node-attributedside information. We allow for a very general side information channel for node attributes, and for pairwise (edge) observations, consider both Bernoulli and Gaussian matrix models, capturing the Stochastic Block Model, Submatrix Localization, and $\\mathbb{Z}_2$-Synchronization as special cases. A recent work of Dreveton et al. 2024 characterized the information-theoretic limit of a very general exact recovery problem with side information. In this paper, we show algorithmic achievability in the above important cases by designing a simple but optimal spectral algorithm that incorporates side information (when present) along with the eigenvectors of the pairwise observation matrix. Using the powerful tool of entrywise eigenvector analysis [Abbe et al. 2020], we show that our spectral algorithm can mimic the so calledgenie-aided estimators, where the $i^{\\mathrm{th}}$ genie-aided estimator optimally computes the estimate of the $i^{\\mathrm{th}}$ label, when all remaining labels are revealed by a genie. This perspective provides a unified understanding of the optimality of spectral algorithms for various exact recovery problems in a recent line of work.", "title_embedding_index": 14762, "title_abs_embedding_index": 14787}, {"title": "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths", "link_suffix": "/forum?id=NnExMNiTHw", "link": "https://openreview.net/forum?id=NnExMNiTHw", "pdf_link": "https://openreview.net/pdf?id=NnExMNiTHw", "keywords": "speculative decoding, reinforcement learning, large language models", "abstract": "Speculative decoding reduces the inference latency of a target large language model via utilizing a smaller and faster draft model. Its performance depends on a hyperparameter $K$ --- the candidate length, i.e., the number of candidate tokens for the target model to verify in each round. However, previous methods often use simple heuristics to choose $K$, which may result in sub-optimal performance. We study the choice of the candidate length $K$ and formulate it as a Markov Decision Process. We theoretically show that the optimal policy of this Markov decision process takes the form of a threshold policy, i.e., the current speculation should stop and be verified when the probability of getting a rejection exceeds a threshold value. Motivated by this theory, we propose SpecDec++, an enhanced version of speculative decoding that adaptively determines the candidate length on the fly. We augment the draft model with a trained acceptance prediction head to predict the conditional acceptance probability of the candidate tokens. SpecDec++ will stop the current speculation when the predicted probability that at least one token gets rejected exceeds a threshold. We implement SpecDec++ and apply it to the llama-2-chat 7B & 70B model pair.  Our adaptive method achieves a 2.04x speedup on the Alpaca dataset (7.2% improvement over the baseline speculative decoding). On the GSM8K and HumanEval datasets, our method achieves a 2.26x speedup (9.4% improvement) and 2.23x speedup (11.1% improvement), respectively.", "title_embedding_index": 14763, "title_abs_embedding_index": 14788}, {"title": "Repulsive Latent Score Distillation for Solving Inverse Problems", "link_suffix": "/forum?id=bwJxUB0y46", "link": "https://openreview.net/forum?id=bwJxUB0y46", "pdf_link": "https://openreview.net/pdf?id=bwJxUB0y46", "keywords": "Inverse problems, Score distillation, Diffusion models, Mode collapse, Variational inference", "abstract": "Score Distillation Sampling (SDS) has been pivotal for leveraging pre-trained diffusion models in downstream tasks such as inverse problems, but it faces two major challenges: $(i)$ mode collapse and $(ii)$ latent space inversion, which become more pronounced in high-dimensional data. \nTo address mode collapse, we introduce a novel variational framework for posterior sampling. \nUtilizing the Wasserstein gradient flow interpretation of SDS, we propose a multimodal variational approximation with a \\emph{repulsion} mechanism that promotes diversity among particles by penalizing pairwise kernel-based similarity. \nThis repulsion acts as a simple regularizer, encouraging a more diverse set of solutions. \nTo mitigate latent space ambiguity, we extend this framework with an \\emph{augmented} variational distribution that disentangles the latent and data. \nThis repulsive augmented formulation balances computational efficiency, quality, and diversity. \nExtensive experiments on linear and nonlinear inverse tasks with high-resolution images ($512 \\times 512$) using pre-trained Stable Diffusion models demonstrate the effectiveness of our approach.", "title_embedding_index": 14764, "title_abs_embedding_index": 14789}, {"title": "H-Direct: Homeostasis-aware Direct Spike Encoding for Deep Spiking Neural Networks", "link_suffix": "/forum?id=QkDUdPRcma", "link": "https://openreview.net/forum?id=QkDUdPRcma", "pdf_link": "https://openreview.net/pdf?id=QkDUdPRcma", "keywords": "spiking neural networks; direct encoding; neuromorphic computing", "abstract": "Deep spiking neural networks (SNNs) have been expected to enable energy-efficient artificial intelligence as a next-generation artificial neural network. Recently, with the development of various algorithms, such as direct spike encoding, many applications have been successfully implemented in deep SNNs. Notably, most state-of-the-art deep SNNs have greatly improved their performance by adopting direct spike encoding, which expresses input information as discrete spikes, thereby exerting substantial influence. Despite the importance of the encoding, efficient encoding methods have not been studied. As the first attempt to our knowledge, we thoroughly analyzed the conventional direct encoding. Our analysis revealed that the existing encoding restricts the training performance and efficiency due to inappropriate encoding. To address this limitation by maintaining an appropriate encoding, we introduced a concept of homeostasis to the direct spike encoding. With this concept, we presented a homeostasis-aware direct spike encoding (H-Direct), which consists of dynamic feature encoding loss, adaptive threshold, and feature diversity loss. Our experimental results demonstrate that the proposed encoding achieves higher performance and efficiency compared to conventional direct encoding across several image classification datasets on various architectures. We have validated that brain-inspired algorithms have the potential to enhance the performance and efficiency of deep SNNs.", "title_embedding_index": 14765, "title_abs_embedding_index": 14790}, {"title": "LipFed: Mitigating Subgroup Bias in Federated Learning with Lipschitz Constraints", "link_suffix": "/forum?id=CGOH2j1m0b", "link": "https://openreview.net/forum?id=CGOH2j1m0b", "pdf_link": "https://openreview.net/pdf?id=CGOH2j1m0b", "keywords": "Federated Learning, Fairness", "abstract": "Federated learning (FL) has emerged as a promising paradigm for training decentralized machine learning models with privacy preservation. However, FL models are biased, which can lead to unfair model outcomes towards subgroups with intersecting attributes. To address this, we propose LipFed, a subgroup bias mitigation technique that leverages Lipschitz-based fairness constraints to mitigate subgroup bias in FL. We evaluate LipFed's efficacy in achieving subgroup fairness across clients while preserving model utility. Our experiments on benchmark datasets and real-world datasets demonstrate that LipFed effectively mitigates subgroup bias without significantly compromising group fairness or model performance.", "title_embedding_index": 14766, "title_abs_embedding_index": 14791}, {"title": "ReLIC: A Recipe for 64k Steps of In-Context Reinforcement Learning for Embodied AI", "link_suffix": "/forum?id=sMWkTWh2JF", "link": "https://openreview.net/forum?id=sMWkTWh2JF", "pdf_link": "https://openreview.net/pdf?id=sMWkTWh2JF", "keywords": "Embodied AI, Reinforcement Learning, Meta-RL, In-context Learning", "abstract": "Intelligent embodied agents need to quickly adapt to new scenarios by integrating long histories of experience into decision-making. For instance, a robot in an unfamiliar house initially wouldn't know the locations of objects needed for tasks and might perform inefficiently. However, as it gathers more experience, it should learn the layout of its environment and remember where objects are, allowing it to complete new tasks more efficiently. To enable such rapid adaptation to new tasks, we present ReLIC, a new approach for in-context reinforcement learning (RL) for embodied agents. With ReLIC, agents are capable of adapting to new environments using 64,000 steps of in-context experience with full attention while being trained through self-generated experience via RL. We achieve this by proposing a novel policy update scheme for on-policy RL called \"partial updates\" as well as a Sink-KV mechanism that enables effective utilization of a long observation history for embodied agents. Our method outperforms a variety of meta-RL baselines in adapting to unseen houses in an embodied multi-object navigation task. In addition, we find that ReLIC is capable of few-shot imitation learning despite never being trained with expert demonstrations. We also provide a comprehensive analysis of ReLIC, highlighting that the combination of large-scale RL training, the proposed partial updates scheme, and the Sink-KV are essential for effective in-context learning.", "title_embedding_index": 14767, "title_abs_embedding_index": 14792}, {"title": "Calibrating Expressions of Certainty", "link_suffix": "/forum?id=dNunnVB4W6", "link": "https://openreview.net/forum?id=dNunnVB4W6", "pdf_link": "https://openreview.net/pdf?id=dNunnVB4W6", "keywords": "calibration, uncertainty, optimal transport, language models", "abstract": "We present a novel approach to calibrating linguistic expressions of certainty, e.g., \"Maybe\" and \"Likely\". Unlike prior work that assigns a single score to each certainty phrase, we model uncertainty as distributions over the simplex to capture their semantics more accurately. To accommodate this new representation of certainty, we generalize existing measures of miscalibration and introduce a novel post-hoc calibration method. Leveraging these tools, we analyze the calibration of both humans (e.g., radiologists) and computational models (e.g., language models) and provide interpretable suggestions to improve their calibration.", "title_embedding_index": 14768, "title_abs_embedding_index": 14793}, {"title": "Leveraging Driver Field-of-View for Multimodal Ego-Trajectory Prediction", "link_suffix": "/forum?id=LLWj8on4Rv", "link": "https://openreview.net/forum?id=LLWj8on4Rv", "pdf_link": "https://openreview.net/pdf?id=LLWj8on4Rv", "keywords": "Ego-trajectory prediction, driver attention, multimodal learning, field-of-view, gaze fixations, deep learning, autonomous driving, driver behavior modeling, dataset creation", "abstract": "Understanding drivers\u2019 decision-making is crucial for road safety. Although predicting the ego-vehicle\u2019s path is valuable for driver-assistance systems, existing methods mainly focus on external factors like other vehicles\u2019 motions, often neglecting the driver\u2019s attention and intent. To address this gap, we infer the ego-trajectory by integrating the driver\u2019s attention and the surrounding scene. We introduce RouteFormer, a novel multimodal ego-trajectory prediction network combining GPS data, environmental context, and driver field-of-view\u2014comprising first-person video and gaze fixations. We also present the Path Complexity Index (PCI), a new metric for trajectory complexity that enables a more nuanced evaluation of challenging scenarios. To tackle data scarcity and enhance diversity, we introduce GEM, a comprehensive dataset of urban driving scenarios enriched with synchronized driver field-of-view and gaze data. Extensive evaluations on GEM and DR(eye)VE demonstrate that RouteFormer significantly outperforms state-of-the-art methods, achieving notable improvements in prediction accuracy across diverse conditions. Ablation studies reveal that incorporating driver field-of-view data yields significantly better average displacement error, especially in challenging scenarios with high PCI scores, underscoring the importance of modeling driver attention. All data, code, and models will be made publicly available.", "title_embedding_index": 14769, "title_abs_embedding_index": 14794}, {"title": "Learning General-purpose Biomedical Volume Representations using Randomized Synthesis", "link_suffix": "/forum?id=xOmC5LiVuN", "link": "https://openreview.net/forum?id=xOmC5LiVuN", "pdf_link": "https://openreview.net/pdf?id=xOmC5LiVuN", "keywords": "synthetic data, representation learning, medical image analysis, image registration", "abstract": "Currentvolumetricbiomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical procedures, conditions, anatomical regions, and imaging protocols. We address this by creating a representation learning method that instead anticipates strong domain shifts at training time itself. We first propose a data engine that synthesizes highly variable training samples that enable generalization to new biomedical contexts. To then train a single 3D network for any voxel-level task, we develop a contrastive learning method that pretrains the network to be stable against nuisance imaging variation simulated by the data engine, a key inductive bias for generalization. This network's features can be used as robust representations of input images for downstream tasks and its weights provide a strong, dataset-agnostic initialization for finetuning on new datasets. As a result, we set new standards acrossbothmultimodality registration and few-shot segmentation, a first for any 3D biomedical vision model, all without (pre-)training on any existing dataset of real images. Our code is attached.", "title_embedding_index": 14770, "title_abs_embedding_index": 14795}, {"title": "Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning", "link_suffix": "/forum?id=rQ7fz9NO7f", "link": "https://openreview.net/forum?id=rQ7fz9NO7f", "pdf_link": "https://openreview.net/pdf?id=rQ7fz9NO7f", "keywords": "Multimodal Large Languge Models, Large Languge Models, Graph Diffusion Models, Inverse Molecular Design, Retrosynthesis", "abstract": "While large language models (LLMs) have integrated images, adapting them to graphs remains challenging, limiting their applications in materials and drug design. This difficulty stems from the need for coherent autoregressive generation across texts and graphs. To address this, we introduce Llamole, the first multimodal LLM capable of interleaved text and graph generation, enabling molecular inverse design with retrosynthetic planning. Llamole integrates a base LLM with the Graph Diffusion Transformer and Graph Neural Networks for multi-conditional molecular generation and reaction inference within texts, while the LLM, with enhanced molecular understanding, flexibly controls activation among the different graph modules. Additionally, Llamole integrates A* search with LLM-based cost functions for efficient retrosynthetic planning. We create benchmarking datasets and conduct extensive experiments to evaluate Llamole against in-context learning and supervised fine-tuning. Llamole significantly outperforms 14 adapted LLMs across 12 metrics for controllable molecular design and retrosynthetic planning.", "title_embedding_index": 14771, "title_abs_embedding_index": 14796}, {"title": "Understanding Layer Significance in LLM Alignment", "link_suffix": "/forum?id=7ha61H73pg", "link": "https://openreview.net/forum?id=7ha61H73pg", "pdf_link": "https://openreview.net/pdf?id=7ha61H73pg", "keywords": "LLMs, Alignment, Important Layers", "abstract": "Aligning large language models (LLMs) through fine-tuning is essential for tailoring them to specific applications. Therefore, understanding what LLMs learn during the alignment process is crucial. Recent studies suggest that alignment primarily adjusts a model's presentation style rather than its foundational knowledge, indicating that only certain components of the model are significantly impacted. To delve deeper into LLM alignment, we propose to identify which layers within LLMs are most critical to the alignment process, thereby uncovering how alignment influences model behavior at a granular level. We propose a novel approach to identify the important layers for LLM alignment (ILA). It involves learning a binary mask for each incremental weight matrix in the LoRA algorithm, indicating the significance of each layer. ILA consistently identifies important layers across various alignment datasets, with nearly 90% overlap even with substantial dataset differences, highlighting fundamental patterns in LLM alignment. Experimental results indicate that freezing non-essential layers improves overall model performance, while selectively tuning the most critical layers significantly enhances fine-tuning efficiency with minimal performance loss.", "title_embedding_index": 14772, "title_abs_embedding_index": 14797}, {"title": "Test-Time Ensemble via Linear Mode Connectivity: A Path to Better Adaptation", "link_suffix": "/forum?id=4wk2eOKGvh", "link": "https://openreview.net/forum?id=4wk2eOKGvh", "pdf_link": "https://openreview.net/pdf?id=4wk2eOKGvh", "keywords": "test-time adaptation, domain adaptation, linear mode connectivity", "abstract": "Test-time adaptation is a valuable approach for online adjustment of pretrained models to handle distribution shifts in test data. While existing research has focused primarily on optimizing stability during adaptation with dynamic data streams, less attention has been given to enhancing model representations for improved adaptation capability. This paper addresses this gap by introducing Test-Time Ensemble (TTE), which leverages two key ensemble strategies: 1) averaging the parameter weights of assorted test-time adapted models and 2) incorporating dropout to further promote representation diversity. These strategies encapsulate model diversity into a single model, avoiding computational burden associated with managing multiple models. Besides, we propose a robust knowledge distillation scheme to prevent collapse during adaptation, ensuring stable optimization. Notably, TTE integrates seamlessly with existing TTA approaches, advancing their adaptation capabilities. In extensive experiments, integration with TTE consistently outperformed baseline models across various challenging scenarios, demonstrating its effectiveness and general applicability.", "title_embedding_index": 14773, "title_abs_embedding_index": 14798}, {"title": "KrwEmd: Revising the Imperfect Recall Abstraction from Forgetting Everything", "link_suffix": "/forum?id=nRgGCnw8eZ", "link": "https://openreview.net/forum?id=nRgGCnw8eZ", "pdf_link": "https://openreview.net/pdf?id=nRgGCnw8eZ", "keywords": "game theory, imperfect-information games, games with ordered signals, computer poker, imperfect-recall abstraction, unsupervised learning", "abstract": "Excessive abstraction is a serious issue in solving games with ordered signals\u2014a subset of imperfect information games, caused by extreme implementations of imperfect recall, which discard all historical information and, as a result, negatively impact AI performance. This paper presents KrwEmd, the first practical algorithm designed to address this issue. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal infosets by leveraging future and, more importantly, historical game information, but also quantitatively reflects their similarity. We then build on this by developing the KrwEmd algorithm, which  cluster signal infosets using Earth Mover\u2019s Distance to assess discrepancies between their features. Experimental results demonstrate that KrwEmd significantly enhances AI gameplay performance compared to existing algorithms.", "title_embedding_index": 14774, "title_abs_embedding_index": 14799}]
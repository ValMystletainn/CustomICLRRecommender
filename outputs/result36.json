[
    {
        "title": "GReaTer: Gradients Over Reasoning Makes Smaller Language Models Strong Prompt Optimizers",
        "link_suffix": "/forum?id=fWRBheSJth",
        "link": "https://openreview.net/forum?id=fWRBheSJth",
        "pdf_link": "https://openreview.net/pdf?id=fWRBheSJth",
        "keywords": "Large Language Model, Prompt Optimization",
        "abstract": "The effectiveness of large language models (LLMs) is closely tied to the design of prompts, making prompt optimization essential for enhancing their performance across a wide range of tasks. Although recent advancements have focused on automating prompt engineering, many existing approaches rely exclusively on textual feedback, refining prompts based solely on inference errors identified by large, computationally expensive LLMs. Unfortunately, smaller models struggle to generate high-quality feedback, resulting in complete dependence on large LLM judgment. Moreover, these methods fail to leverage more direct and finer-grained information, such as gradients, due to operating purely in text space. To this end, we introduce, we introduceGReaTer, a novel prompt optimization technique that directly incorporatesgradient information over task-specific reasoning. By utilizing task loss gradients,GReaTerenables self-optimization of prompts for smaller, lightweight language models (LM) without the need for costly closed-source LLMs, while maintaining reasonable prompt structures. This allows high-performance prompt optimization without dependence on massive LLMs, closing the gap between smaller models and the sophisticated reasoning often needed for prompt refinement. Extensive evaluations across diverse tasks demonstrate that \\ours consistently outperforms previous methods, even those reliant on powerful LLMs. Additionally,GReaTer-optimized prompts frequently exhibit better transferability and, in some cases, boost task performance to levels comparable to or surpassing those achieved by larger language models, highlighting the effectiveness of\"gradient over reasoning\"-based prompt optimization. Full source code ofGReaTerwill be available upon acceptance."
    },
    {
        "title": "A Unified Riemannian-Geometric Framework for SARS-CoV-2 Detection from CT Scans",
        "link_suffix": "/forum?id=4mqt6QxSUO",
        "link": "https://openreview.net/forum?id=4mqt6QxSUO",
        "pdf_link": "https://openreview.net/pdf?id=4mqt6QxSUO",
        "keywords": "SARS-CoV-2, Transfer learning, Medical image identification",
        "abstract": "We present a novel, theoretically grounded framework for automated SARS-CoV-2 detection from pulmonary Computed Tomography (CT) scans, integrating cutting-edge concepts from statistical learning theory, optimal transport, and information geometry. Our approach begins with a submodular optimization-based image selection protocol, utilizing a continuous greedy algorithm. The feature extraction process employs a Riemannian geometry-inspired attention mechanism, where feature integration is formulated as geodesic interpolation on a manifold induced by the Fisher Information Metric. We introduce a unified decision-making framework based on proper scoring rules and Bregman divergences, encompassing multiple voting schemes with proven consistency and asymptotic normality properties. To address domain shift, we develop an adversarial domain adaptation technique using the Wasserstein-Fisher-Rao distance, complemented by a graph-based regularization term derived from Gromov-Wasserstein theory. Theoretical analysis provides convergence guarantees for the adversarial training process and establishes generalization bounds in terms of optimal transport distances. Empirical evaluation demonstrates the superiority of our approach over existing methods, achieving state-of-the-art performance on benchmark datasets. This work not only advances the field of automated medical image analysis but also contributes fundamental theoretical insights to the broader domains of machine learning and optimal transport theory."
    },
    {
        "title": "A Decoupled Learning Framework for Neural Marked Temporal Point Process",
        "link_suffix": "/forum?id=DRhKnUYNm9",
        "link": "https://openreview.net/forum?id=DRhKnUYNm9",
        "pdf_link": "https://openreview.net/pdf?id=DRhKnUYNm9",
        "keywords": "temporal point process, interpretability, event sequence modeling",
        "abstract": "The standard neural marked temporal point process employs the EmbeddingEncoder-History vector-Decoder (EEHD) architecture, wherein the history vector encapsulates the cumulative effects of past events. However, due to the inherent imbalance in event categories in real-world scenarios, the history vector tends to favor more frequent events, inadvertently overlooking less common yet potentially significant ones, thereby compromising the model’s overall performance. To tackle this issue, we introduce a novel decoupled learning framework for neural marked temporal point process, where each event type is modeled independently to capture its unique characteristics, allowing for a more nuanced and equitable treatment of all event types. Each event type boasts its own complete EEHD architecture, featuring scaled-down parameters due to the decoupling of temporal dynamics. This decoupled design enables asynchronous parallel training, and the embeddings can reflect the dependencies between event types. Our versatile framework, accommodating various encoder and decoder architectures, demonstrates state-of-the-art performance across diverse datasets, outperforming benchmarks by a significant margin and increasing training speed by up to 12 times. Additionally, it offers interpretability, revealing which event types have similar influences on a particular event type, fostering a deeper understanding of temporal dynamics."
    },
    {
        "title": "Efficient Causal Decision Making with One-sided Feedback",
        "link_suffix": "/forum?id=UWdPsY7agk",
        "link": "https://openreview.net/forum?id=UWdPsY7agk",
        "pdf_link": "https://openreview.net/pdf?id=UWdPsY7agk",
        "keywords": "semiparametric efficiency, one-sided feedback, causal decision making",
        "abstract": "We study a class of decision-making problems with one-sided feedback, where outcomes are only observable for specific actions. A typical example is bank loans, where the repayment status is known only if a loan is approved and remains undefined if rejected. In such scenarios, conventional approaches to causal decision evaluation and learning from observational data are not directly applicable. In this paper, we introduce a novel value function to evaluate decision rules that addresses the issue of undefined counterfactual outcomes. Without assuming no unmeasured confounders, we establish the identification of the value function using shadow variables. Furthermore, leveraging semiparametric theory, we derive the efficiency bound for the proposed value function and develop efficient methods for decision evaluation and learning. Numerical experiments and a real-world data application demonstrate the empirical performance of our proposed methods."
    },
    {
        "title": "FoREST: Frame of Reference Evaluation in Spatial Reasoning Tasks",
        "link_suffix": "/forum?id=9Y6QWwQhF3",
        "link": "https://openreview.net/forum?id=9Y6QWwQhF3",
        "pdf_link": "https://openreview.net/pdf?id=9Y6QWwQhF3",
        "keywords": "Spatial language, Evaluation benchmark, Frame of reference",
        "abstract": "Spatial cognition is one fundamental aspect of human intelligence. A key factor in spatial cognition is understanding the frame of reference (FoR) that identifies the perspective of spatial relations. \nHowever, the AI research has paid very little attention to this concept.\nSpecifically, there is a lack of dedicated benchmarks and in-depth experiments analyzing large language models' (LLMs) understanding of FoR.\nTo address this issue, we introduce a new benchmark,FrameofReferenceEvaluation inSpatial ReasoningTasks (FoREST)  to evaluate LLMs ability in understanding FoR.\nWe evaluate the LLMs in identifying the FoR based on textual context and employ this concept in text-to-image generation. \nOur results reveal notable differences and biases in the FoR identification of various LLMs. \nMoreover, the bias in FoR interpretations impacts the LLMs' ability to generate layouts for text-to-image generation. \nTo deal with these biases, we propose Spatial-Guided prompting, which guides the model in exploiting the types of spatial relations for a more accurate FoR identification. \nThis approach reduces FoR bias in LLMs and improves the overall performance of FoR identification. \nEventually, using FoR information in text-to-image generation leads to a more accurate visualization of the spatial configuration of objects."
    },
    {
        "title": "MATEY: multiscale adaptive foundation models for spatiotemporal physical systems",
        "link_suffix": "/forum?id=KBrFTuQGAp",
        "link": "https://openreview.net/forum?id=KBrFTuQGAp",
        "pdf_link": "https://openreview.net/pdf?id=KBrFTuQGAp",
        "keywords": "Foundation model; vision transformer, physical systems; adaptive tokenization; decoupled spatiotemporal attentions; computational fluid dynamics",
        "abstract": "Accurate representation of the multiscale features in spatiotemporal physical systems using vision transformer (ViT) architectures requires extremely long, computationally prohibitive token sequences. To address this issue, we propose an adaptive tokenization scheme which dynamically adjusts the token sizes based on local features. \nMoreover, we present a set of spatiotemporal attention schemes, where the temporal or axial spatial dimensions are decoupled, and evaluate their computational and data efficiencies.\nWe assess the performance of the proposed multiscale adaptive model, MATEY, in a sequence of experiments. \nThe results show that adaptive tokenization achieves improved accuracy without significantly increasing token sequence length, but the improvement deteriorates in more complex data configurations. \nCompared to a full spatiotemporal attention scheme or a scheme that decouples only the temporal dimension, we find that fully decoupled axial attention is less efficient and expressive, requiring more training time and model weights to achieve the same accuracy. \nFinally, we demonstrate in two fine-tuning tasks featuring different physics that models pretrained on PDEBench data outperform the ones trained from scratch, especially in the low data regime with frozen attention."
    },
    {
        "title": "ON EXTRAPOLATION IN MATERIAL PROPERTY REGRESSION",
        "link_suffix": "/forum?id=czVzzXPCkw",
        "link": "https://openreview.net/forum?id=czVzzXPCkw",
        "pdf_link": "https://openreview.net/pdf?id=czVzzXPCkw",
        "keywords": "material property prediction, regression, extrapolation",
        "abstract": "Deep learning methods have yielded exceptional performances in material property regression (MPR). However, most existing methods operate under the assumption that the training and test are independent and identically distributed (i.i.d.). This overlooks the importance of extrapolation - predicting material properties beyond the range of training data - which is essential for advanced material discovery, as researchers strive to identify materials with exceptional properties that exceed current capabilities. In this paper, we address this gap by introducing a comprehensive benchmark comprising seven tasks specifically designed to evaluate extrapolation in MPR. We critically evaluate existing methods including deep imbalanced regression (DIR) and regression data augmentation (DA) methods, and reveal their limitations in extrapolation tasks. To address these issues, we propose the Matching-based EXtrapolation (MEX) framework, which reframes MPR as a material-property matching problem to alleviate the inherent complexity of the direct material-to-label mapping paradigm for better extrapolation. Our experimental results show that MEX outperforms all existing methods on our benchmark and demonstrates exceptional capability in identifying promising materials, underscoring its potential for advancing material discovery."
    },
    {
        "title": "Nonparametric Expert DAG Learning with Accurate Edge Strengths and Realistic Knowledge Incorporation",
        "link_suffix": "/forum?id=1dDxMPJy4i",
        "link": "https://openreview.net/forum?id=1dDxMPJy4i",
        "pdf_link": "https://openreview.net/pdf?id=1dDxMPJy4i",
        "keywords": "probabilistic inference, nonparametric method, knowledge representation",
        "abstract": "Directed Acyclic Graphs (DAGs) are crucial for modeling causal structures and complex dependencies in domains such as biology, healthcare, and finance. Effective structure learning must not only align with domain expert knowledge but also produce interpretable model decisions. Though continuous structure learning methods like NOTEARS are gaining popularity, an underexplored feature is their ability to open up the black box of decisions made by traditional combinatorial search by quantifying edge strengths in weighted adjacency matrices. Yet challenges persist in systematically integrating expert knowledge and ensuring learned weights accurately reflect true edge relationships. We present Non-parametric Expert DAG (NEDAG), a novel method that formulates accurate weight matrices using Gaussian Processes (GPs) and incorporates realistic domain knowledge into the continuous structure learning framework. Experiments on both synthetic and real-world datasets demonstrate that NEDAG not only surpasses existing methods in structure accuracy but also produces more accurate edge strengths. NEDAG thus provides a robust and interpretable solution for structure discovery in real-world applications."
    },
    {
        "title": "From Demonstrations to Rewards:  Alignment Without Explicit Human Preferences",
        "link_suffix": "/forum?id=mltelO89Ve",
        "link": "https://openreview.net/forum?id=mltelO89Ve",
        "pdf_link": "https://openreview.net/pdf?id=mltelO89Ve",
        "keywords": "inverse reinforcement learning, iterative RLHF, learning from demonstrations, reward learning",
        "abstract": "One of the challenges of aligning large models with human preferences lies in both the data requirements and the technical complexities of current approaches. Predominant methods, such as RLHF, involve multiple steps, each demanding distinct types of data, including demonstrations data and preference data. In RLHF, human preferences are typically modeled through a reward model, which serves as a proxy to guide policy learning during the reinforcement learning stage, ultimately producing a policy aligned with human preferences. However, in this paper, we propose a fresh perspective on learning alignment based on inverse reinforcement learning principles, where the optimal policy is still derived from reward maximization. However, instead of relying on preference data, we directly learn the reward model from demonstration data. This new formulation offers the flexibility to be applied even when only demonstration data is available, a capability that current RLHF methods lack, and it also shows that demonstration data offers more utility than what conventional wisdom suggests. Our extensive evaluation, based on public reward benchmark and HuggingFace Open LLM Leaderboard, demonstrates that our approach compares favorably to state-of-the-art methods that rely solely on demonstration data."
    },
    {
        "title": "A Codespace Autoencoder for Language Tasks",
        "link_suffix": "/forum?id=NmpOUCwAjR",
        "link": "https://openreview.net/forum?id=NmpOUCwAjR",
        "pdf_link": "https://openreview.net/pdf?id=NmpOUCwAjR",
        "keywords": "LLM, autoencoders, code generation, data generation",
        "abstract": "Modern language modeling datasets require models to handle compositional reasoning, fact recall, and task-specific constraints. While these tasks are expressed in natural language, they often imply an underlying symbolic representation. In this work, we consider methods for extracting a latent symbolic representation in an unsupervised manner. We propose an autoencoder that models observed text data as being generated from underlying code with a dataset level function library.  Our method is non-parametric and leverages in-context learning and code interpretation for inference. Code as the latent symbolic representation offers two key advantages. First, code offers a structured space that can be explored via modular functions; second, code is interpretably executable using deterministic and neural interpreters, enabling compositional and programmatic decoding into text. By identifying and composing patterns in this latent space, we can sample programs that produce correct, diverse, and task-relevant text through program execution.\nWe demonstrate how our method induces a latent space with modern LLMs, explore patterns discovered within it, and evaluate text data synthesized from our induced latent space."
    },
    {
        "title": "Has My System Prompt Been Used? Large Language Model Prompt Membership Inference",
        "link_suffix": "/forum?id=jWQf6jk55V",
        "link": "https://openreview.net/forum?id=jWQf6jk55V",
        "pdf_link": "https://openreview.net/pdf?id=jWQf6jk55V",
        "keywords": "privacy, membership inference attack, prompt extraction",
        "abstract": "Prompt engineering has emerged as a powerful technique for optimizing large language models (LLMs) for specific applications, enabling faster prototyping and improved performance, and giving rise to the interest of the community in protecting proprietary system prompts. In this work, we explore a novel perspective on prompt privacy through the lens of membership inference. We develop Prompt Detective, a statistical method to reliably determine whether a given system prompt was used by a third-party language model. Our approach relies on a statistical test comparing the distributions of two groups of generations corresponding to different system prompts. Through extensive experiments with a variety of language models, we demonstrate the effectiveness of Prompt Detective in both standard and challenging scenarios, including black-box settings. Our work reveals that even minor changes in system prompts manifest in distinct response distributions, enabling us to verify prompt usage with statistical significance."
    },
    {
        "title": "AtmosArena: Benchmarking Foundation Models for Atmospheric Sciences",
        "link_suffix": "/forum?id=5GI6BGToyw",
        "link": "https://openreview.net/forum?id=5GI6BGToyw",
        "pdf_link": "https://openreview.net/pdf?id=5GI6BGToyw",
        "keywords": "foundation models, atmospheric sciences, benchmarks",
        "abstract": "Deep learning has emerged as a powerful tool for atmospheric sciences, showing significant utility across various tasks in weather and climate modeling. In line with recent progress in language and vision foundation models, there are growing efforts to scale and finetune such models for multi-task spatiotemporal reasoning. Despite promising results, existing works often evaluate their model on a small set of non-uniform tasks, which makes it hard to quantify broad generalization across diverse tasks and domains. To address this challenge, we introduce AtmosArena, the first multi-task benchmark dedicated to foundation models in atmospheric sciences. AtmosArena comprises a suite of tasks that cover a broad spectrum of applications in atmospheric physics and atmospheric chemistry. To showcase the capabilities and key features of our benchmark, we conducted extensive experiments to evaluate two state-of-the-art deep learning models, ClimaX and Stormer on AtmosArena, and compare their performance with other deep learning and traditional baselines. By providing a standardized, open-source benchmark, we aim to facilitate further advancements in the field, much like open-source benchmarks have driven the development of foundation models for language and vision."
    },
    {
        "title": "SimO Loss: Anchor-Free Contrastive Loss for Fine-Grained Supervised Contrastive Learning",
        "link_suffix": "/forum?id=QCY1WQXTc8",
        "link": "https://openreview.net/forum?id=QCY1WQXTc8",
        "pdf_link": "https://openreview.net/pdf?id=QCY1WQXTc8",
        "keywords": "Contrastive Learning, Anchor Free, Contrastive Learning, Explainable Contrastive Learning, Fine Grained Representation Learning",
        "abstract": "We introduce a novel anchor-free contrastive learning (AFCL) method leveraging our proposed Similarity-Orthogonality (SimO) loss. Our approach minimizes a semi-metric discriminative loss function that simultaneously optimizes two key objectives: reducing the distance and orthogonality between embeddings of similar inputs while maximizing these metrics for dissimilar inputs, facilitating more fine-grained contrastive learning. The AFCL method, powered by SimO loss, creates a fiber bundle topological structure in the embedding space, forming class-specific, internally cohesive yet orthogonal neighborhoods.  We validate the efficacy of our method on the CIFAR-10 dataset, providing visualizations that demonstrate the impact of SimO loss on the embedding space. Our results illustrate the formation of distinct, orthogonal class neighborhoods, showcasing the method's ability to create well-structured embeddings that balance class separation with intra-class variability. This work opens new avenues for understanding and leveraging the geometric properties of learned representations in various machine learning tasks."
    },
    {
        "title": "LANTERN: Accelerating Visual Autoregressive Models with Relaxed Speculative Decoding",
        "link_suffix": "/forum?id=98d7DLMGdt",
        "link": "https://openreview.net/forum?id=98d7DLMGdt",
        "pdf_link": "https://openreview.net/pdf?id=98d7DLMGdt",
        "keywords": "Speculative decoding, Visual Autoregressive Models",
        "abstract": "Auto-Regressive (AR) models have recently gained prominence in image generation, often matching or even surpassing the performance of diffusion models. However, one major limitation of AR models is their sequential nature, which processes tokens one at a time, slowing down generation compared to models like GANs or diffusion-based methods that operate more efficiently. While speculative decoding has proven effective for accelerating LLMs by generating multiple tokens in a single forward, its application in visual AR models remains largely unexplored. In this work, we identify a challenge in this setting, which we term \\textit{token selection ambiguity}, wherein visual AR models frequently assign uniformly low probabilities to tokens, hampering the performance of speculative decoding. To overcome this challenge, we propose a relaxed acceptance condition referred to as LANTERN that leverages the interchangeability of tokens in latent space. This relaxation restores the effectiveness of speculative decoding in visual AR models by enabling more flexible use of candidate tokens that would otherwise be prematurely rejected. Furthermore, by incorporating a total variation distance bound, we ensure that these speed gains are achieved without significantly compromising image quality or semantic coherence. Experimental results demonstrate the efficacy of our method in providing a substantial speed-up over speculative decoding. In specific, compared to a na\"ive application of the state-of-the-art speculative decoding, LANTERN increases speed-ups by $\\mathbf{1.75}\\times$ and $\\mathbf{1.76}\\times$, as compared to greedy decoding and random sampling, respectively, when applied to LlamaGen, a contemporary visual AR model."
    },
    {
        "title": "Uncovering BioLOGICAL Motifs and Syntax via Sufficient and Necessary Explanations",
        "link_suffix": "/forum?id=qi5dkmEE91",
        "link": "https://openreview.net/forum?id=qi5dkmEE91",
        "pdf_link": "https://openreview.net/pdf?id=qi5dkmEE91",
        "keywords": "interpretability, attributions, computational biology",
        "abstract": "In recent years, deep neural networks (DNNs) have excelled at learning from high-throughput genome-profiling experiments to predict transcription factor (TF) binding. TF binding is driven by sequence motifs, and explaining how and why DNNs make accurate predictions could help identify these motifs, as well as their logical syntax. However, the black-box nature of DNNs makes interpretation difficult. Most post-hoc methods evaluate the importance of each base pair in isolation, often resulting in noise since they overlook the fact that motifs are contiguous regions. Additionally, these methods fail to capture the complex interactions between different motifs. To address these challenges, we propose Motif Explainer Models (MEMs), a novel explanation method that uses sufficiency and necessity to identify important motifs and their syntax. MEMs excel at identifying multiple disjoint motifs across DNA sequences, overcoming limitations of existing methods. Moreover, by accurately pinpointing sufficient and necessary motifs, MEMs can reveal the logical syntax that governs genomic regulation."
    },
    {
        "title": "LICO: Large Language Models for In-Context Molecular Optimization",
        "link_suffix": "/forum?id=yu1vqQqKkx",
        "link": "https://openreview.net/forum?id=yu1vqQqKkx",
        "pdf_link": "https://openreview.net/pdf?id=yu1vqQqKkx",
        "keywords": "large language models, molecular optimization, black-box optimization, foundation models, in-context learning",
        "abstract": "Optimizing black-box functions is a fundamental problem in science and engineering. To solve this problem, many approaches learn a surrogate function that estimates the underlying objective from limited historical evaluations. Large Language Models (LLMs), with their strong pattern-matching capabilities via pretraining on vast amounts of data, stand out as a potential candidate for surrogate modeling. However, directly prompting a pretrained language model to produce predictions is not feasible in many scientific domains due to the scarcity of domain-specific data in the pretraining corpora and the challenges of articulating complex problems in natural language. In this work, we introduce LICO, a general-purpose model that extends arbitrary base LLMs for black-box optimization, with a particular application to the molecular domain. To achieve this, we equip the language model with a separate embedding layer and prediction layer, and train the model to perform in-context predictions on a diverse set of functions defined over the domain. Once trained, LICO can generalize to unseen molecule properties simply via in-context prompting. LICO achieves state-of-the-art performance on PMO, a challenging molecular optimization benchmark comprising over 20 objective functions."
    },
    {
        "title": "COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences",
        "link_suffix": "/forum?id=XuYd9IK7X4",
        "link": "https://openreview.net/forum?id=XuYd9IK7X4",
        "pdf_link": "https://openreview.net/pdf?id=XuYd9IK7X4",
        "keywords": "Alignment, General Preferences, Large Language Model, Nash Equilibrium",
        "abstract": "Many alignment methods, including reinforcement learning from human feedback (RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to capture the full range of general human preferences. To achieve robust alignment with general preferences, we model the alignment problem as a two-player zero-sum game, where the Nash equilibrium policy guarantees a 50% win rate against any competing policy. However, previous algorithms for finding the Nash policy either diverge or converge to a Nash policy in a modified game, even in a simple synthetic setting, thereby failing to maintain the 50% win rate guarantee against all other policies. We propose a meta-algorithm,CovergentMetaAlignment Algorithm (COMAL), for language model alignment with general preferences, inspired by convergent algorithms in game theory. Theoretically, we prove that our meta-algorithm converges to an exact Nash policy. Additionally, our meta-algorithm is simple and can be integrated with many existing methods designed for RLHF and preference optimization with minimal changes. Experimental results demonstrate the effectiveness of the proposed framework when combined with existing preference policy optimization methods."
    },
    {
        "title": "All Models are Biased, Some are More Transparent about it: Fully Interpretable and Adjustable Model for Mental Disorder Diagnosis",
        "link_suffix": "/forum?id=Frhj9T7ihK",
        "link": "https://openreview.net/forum?id=Frhj9T7ihK",
        "pdf_link": "https://openreview.net/pdf?id=Frhj9T7ihK",
        "keywords": "interpretable AI, mental health, k-NN, neural symbolic, explainable AI, tunnable AI",
        "abstract": "Recent advances in machine learning have enabled AI applications in mental disorder diagnosis, but many methods remain black-box or rely on post-hoc explanations which are not straightforward or actionable for mental health practitioners. Meanwhile, interpretable methods, such as k-nearest neighbors (k-NN) classification, struggle with complex or high-dimensional data. A network-based k-NN model (NN-kNN) combines the interpretability with the predictive power of neural networks. The model prediction can be fully explained in terms of activated features and neighboring cases.  We experimented with the model to predict the risks of depression and interviewed practitioners. The feedback of the practitioners emphasized the model's adaptability, integration of clinical expertise, and transparency in the diagnostic process, highlighting its potential to ethically improve the diagnostic precision and confidence of the practitioner."
    },
    {
        "title": "Class-wise Autoencoders Measure Classification Difficulty And Detect Label Mistakes",
        "link_suffix": "/forum?id=RW37MMrNAi",
        "link": "https://openreview.net/forum?id=RW37MMrNAi",
        "pdf_link": "https://openreview.net/pdf?id=RW37MMrNAi",
        "keywords": "Autoencoders, Classification",
        "abstract": "We introduce a new theory for analyzing classification datasets based on the ratios of reconstruction errors between autoencoders trained on individual classes. This theory enables efficient and model-agnostic characterization of datasets on the sample, class, and entire dataset levels. We define reconstruction error ratios (RERs) that probe classification difficulty and allow its decomposition into (1) finite sample size and (2) Bayes error and decision-boundary complexity. Through systematic study across 18 popular visual datasets, we find that our RER-based dataset difficulty probe strongly correlates with error rate for state-of-the-art (SOTA) classification models. By interpreting sample-level classification difficulty as a label mistakenness score, we further find that RERs achieve SOTA performance on mislabel detection tasks on hard datasets under symmetric and asymmetric label noise."
    },
    {
        "title": "Spread Preference Annotation: Direct Preference Judgment for Efficient LLM Alignment",
        "link_suffix": "/forum?id=BPgK5XW1Nb",
        "link": "https://openreview.net/forum?id=BPgK5XW1Nb",
        "pdf_link": "https://openreview.net/pdf?id=BPgK5XW1Nb",
        "keywords": "large language model, alignment, preference",
        "abstract": "Aligning large language models (LLMs) with human preferences becomes a key component to obtaining state-of-the-art performance, but it yields a huge cost to construct a large human-annotated preference dataset. To tackle this problem, we propose a new framework, Spread Preference Annotation with direct preference judgment (SPA), that boosts the alignment of LLMs using only a very small amount of human-annotated preference data.\nOur key idea is leveraging the human prior knowledge within the small (seed) data and progressively improving the alignment of LLM, by iteratively generating the responses and learning from them with the self-annotated preference data.\nTo be specific, we propose to derive the preference label from the logits of LLM to explicitly extract the model's inherent preference. \nCompared to the previous approaches using external reward models or implicit in-context learning, we observe that the proposed approach is significantly more effective.\nIn addition, we introduce a noise-aware preference learning algorithm to mitigate the risk of low quality within generated preference data.\nOur experimental results demonstrate that the proposed framework significantly boosts the alignment of LLMs.\nFor example, we achieve superior alignment performance on AlpacaEval 2.0 with only 3.3% of the ground-truth preference labels in the Ultrafeedback data compared to the cases using the entire data or state-of-the-art baselines."
    },
    {
        "title": "Counterfactual Realizability",
        "link_suffix": "/forum?id=uuriavczkL",
        "link": "https://openreview.net/forum?id=uuriavczkL",
        "pdf_link": "https://openreview.net/pdf?id=uuriavczkL",
        "keywords": "causal inference, experiment design, causal reinforcement learning, counterfactual reasoning",
        "abstract": "It is commonly believed that, in a real-world environment, samples can only be drawn from observational and interventional distributions, corresponding to Layers 1 and 2 of the Pearl Causal Hierarchy. Layer 3, representing counterfactual distributions, is believed to be inaccessible almost by definition. However, Bareinboim, Forney, and Pearl (2015) introduced a procedure that allows an agent to sample directly from a counterfactual distribution, leaving open the question of what other counterfactual quantities can be estimated directly via physical experimentation. We resolve this by introducing a formal definition ofrealizability, the ability to draw samples from a distribution, and then developing a complete algorithm to determine whether an arbitrary counterfactual distribution is realizable given fundamental physical constraints, such as the inability to go back in time and subject the same unit to a different experimental condition. We illustrate the implications of this new framework for counterfactual data collection using motivating examples from causal fairness and causal reinforcement learning. While the baseline approach in these motivating settings typically follows an interventional or observational strategy, we show that a counterfactual strategy provably dominates both."
    },
    {
        "title": "Forking Paths in Neural Text Generation",
        "link_suffix": "/forum?id=8RCmNLeeXx",
        "link": "https://openreview.net/forum?id=8RCmNLeeXx",
        "pdf_link": "https://openreview.net/pdf?id=8RCmNLeeXx",
        "keywords": "Large Language Models, Uncertainty Estimation, Interpretability",
        "abstract": "Estimating uncertainty in Large Language Models (LLMs) is important for properly evaluating LLMs, and ensuring safety for users. However, prior approaches to uncertainty estimation focus on the final answer in generated text, ignoring intermediate steps that might dramatically impact the outcome. We hypothesize that there exist key forking tokens, such that re-sampling the system at those specific tokens, but not others, leads to very different outcomes. To test this empirically, we develop a novel approach to representing uncertainty dynamics across individual tokens of text generation, and applying statistical models to test our hypothesis. Our approach is highly flexible: it can be applied to any dataset and any LLM, without fine tuning or accessing model weights. We use our method to analyze LLM responses on 7 different tasks across 4 domains,  spanning a wide range of typical use cases. We find many examples of forking tokens, including surprising ones such as a space character instead of a colon, suggesting that LLMs are often just a single token away from saying something very different."
    },
    {
        "title": "DEQ-MPC : Deep Equilibrium Model Predictive Control",
        "link_suffix": "/forum?id=Ty7xx0pn0a",
        "link": "https://openreview.net/forum?id=Ty7xx0pn0a",
        "pdf_link": "https://openreview.net/pdf?id=Ty7xx0pn0a",
        "keywords": "MPC, Model Predictive Control, Optimization, Differentiable Optimization, Control",
        "abstract": "Incorporating task-specific priors within a policy or network architecture is crucial for enhancing safety and improving representation and generalization in robotic control problems. Differentiable Model Predictive Control (MPC) layers have proven effective for embedding these priors, such as constraints and cost functions, directly within the architecture, enabling end-to-end training. However, current methods often treat the solver and the neural network as separate, independent entities, leading to suboptimal integration. In this work, we propose a novel approach that co-develops the solver and architecture unifying the optimization solver and network inference problems. Specifically, we formulate this as a joint fixed-point problem over the coupled network outputs and necessary conditions of the optimization problem. We solve this problem in an iterative manner where we alternate between network forward passes and optimization iterations. Through extensive ablations in various robotic control tasks, we demonstrate that our approach results in richer representations and more stable training, while naturally accommodating warm starting, a key requirement for MPC."
    },
    {
        "title": "Beyond Standardization – Putting the Normality in Normalization",
        "link_suffix": "/forum?id=9ut3QBscB0",
        "link": "https://openreview.net/forum?id=9ut3QBscB0",
        "pdf_link": "https://openreview.net/pdf?id=9ut3QBscB0",
        "keywords": "mutual information game, power transform, noise robustness, information theory",
        "abstract": "The normal distribution plays a central role in information theory – it is at the same time the best-case signal and worst-case noise distribution, has the greatest representational capacity of any distribution, and offers an equivalence between uncorrelatedness and independence for joint distributions. Accounting for the mean and variance of activations throughout the layers of deep neural networks has had a significant effect on facilitating their effective training, but seldom has a prescription for precisely what distribution these activations should take, and how this might be achieved, been offered. Motivated by the information-theoretic properties of the normal distribution, we address this question and concurrently present normality normalization: a novel normalization layer which encourages normality in the feature representations of neural networks using the power transform and employs additive Gaussian noise during training. Our experiments comprehensively demonstrate the effectiveness of normality normalization, in regards to its generalization performance on an array of widely used model and dataset combinations, its strong performance across various common factors of variation such as model width, depth, and training minibatch size, its suitability for usage wherever existing normalization layers are conventionally used, and as a means to improving model robustness to random perturbations."
    },
    {
        "title": "Blind Coreset Selection: Efficient Pruning for Unlabeled Data",
        "link_suffix": "/forum?id=pGINxZWjK4",
        "link": "https://openreview.net/forum?id=pGINxZWjK4",
        "pdf_link": "https://openreview.net/pdf?id=pGINxZWjK4",
        "keywords": "Coreset selection, Classification",
        "abstract": "Deep learning methods rely on massive data, resulting in substantial costs for storage, annotation, and model training.\nCoreset selection aims to select a representative subset of the data to train models with lower cost while ideally performing on par with the full data training.\nState-of-the-art coreset selection methods use carefully-designed criteria to quantify the importance of each data example using ground truth labels and dataset-specific training, then select examples whose scores lie in a certain range to construct a coreset.\nThese methods work well in their respective settings, however, they cannot consider candidate data that are initially unlabeled.\nThis limits the application of these methods, especially so considering that the majority of real-world data are unlabeled.\nTo that end, this paper explores the problem of coreset selection for unlabeled data.\nWe first motivate and formalize the problem of unlabeled coreset selection, which reduces annotation requirements to enable greater scale relative to label-based coreset selection.\nWe then develop an unlabeled coreset selection method, Blind Coreset Selection (BlindCS), that jointly considers overall data coverage on a distribution as well as the relative importance of each example based on redundancy.\nNotably, BlindCS does not use any model- or dataset-specific training, which increases coreset generalization and reduces computation relative to training-based coreset selection.\nWe evaluate BlindCS on four datasets and confirm the advance over several state-of-the-art methods that use labels and training, leading to a strong baseline for future research in unlabeled coreset selection.\nNotably, the BlindCS coreset for ImageNet achieves a higher accuracy than previous label-based coresets at a 90% prune rate, while removing annotation requirements for 1.15 million images.\nWe will make our code publicly available with the final paper."
    }
]
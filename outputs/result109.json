[{"title": "No-Regret is not enough! Bandits with General Constraints through Adaptive Regret Minimization", "link_suffix": "/forum?id=LKtttBE5GN", "link": "https://openreview.net/forum?id=LKtttBE5GN", "pdf_link": "https://openreview.net/pdf?id=LKtttBE5GN", "keywords": "bandits with knapsacks, online learning, contextual bandits with linear constraints", "abstract": "In the bandits with knapsacks framework (BwK) the learner has $m$ resource-consumption (i.e., packing) constraints. We focus on the generalization of BwK in which the learner has a set of general long-term constraints. The goal of the learner is to maximize their cumulative reward, while at the same time achieving small cumulative constraints violations. In this scenario, there exist simple instances where conventional methods for BwK fail to yield sublinear violations of constraints. We show that it is possible to circumvent this issue by requiring the primal and dual algorithm to be weakly adaptive. Indeed, even in absence on any information on the Slater's parameter $\\rho$ characterizing the problem, the interplay between weakly adaptive primal and dual regret minimizers yields a ``self-bounding'' property of dual variables. In particular, their norm remains suitably upper bounded across the entire time horizon even without explicit projection steps. By exploiting this property, we provide best-of-both-worlds guarantees for stochastic and adversarial inputs. In the first case, we show that the algorithm guarantees sublinear regret. In the latter case, we establish a tight competitive ratio of $\\rho/(1+\\rho)$. In both settings, constraints violations are guaranteed to be sublinear in time. Finally, this results allow us to obtain new result for the problem of contextual bandits with linear constraints, providing the first no-$\\alpha$-regret guarantees for adversarial contexts.", "title_embedding_index": 5400, "title_abs_embedding_index": 5425}, {"title": "Improving Large Language Model based  Multi-Agent Framework through Dynamic Workflow Updating", "link_suffix": "/forum?id=sLKDbuyq99", "link": "https://openreview.net/forum?id=sLKDbuyq99", "pdf_link": "https://openreview.net/pdf?id=sLKDbuyq99", "keywords": "LLMs based Multi-Agent System", "abstract": "Multi-agent frameworks powered by large language models (LLMs) have demonstrated great success in automated planning and task execution. However, the effective adjustment of workflows during execution has not been well studied. A flexible workflow is crucial, as in many real-world scenarios, the initial plan must adjust to unforeseen challenges and changing conditions in real-time to ensure the efficient execution of complex tasks. In this paper, we define workflows as activity-on-vertex (AOV) graphs. We continuously refine the workflow by dynamically adjusting task allocations and agent roles based on historical performance and previous AOV graphs with LLM agents. To further enhance system performance, we emphasize modularity in workflow design based on measuring parallelism and dependence complexity. Our proposed multi-agent framework achieved efficient sub-task concurrent execution, goal achievement, and error tolerance. Empirical results across various practical tasks demonstrate significant improvements in the efficiency of multi-agent systems through dynamic workflow updating and modularization.", "title_embedding_index": 5401, "title_abs_embedding_index": 5426}, {"title": "S4M: S4 for multivariate time series forecasting with Missing values", "link_suffix": "/forum?id=BkftcwIVmR", "link": "https://openreview.net/forum?id=BkftcwIVmR", "pdf_link": "https://openreview.net/pdf?id=BkftcwIVmR", "keywords": "S4 Models, Multivariate Time Series Forecasting, Missing Value, Prototype Bank", "abstract": "Multivariate time series data are integral to numerous real-world applications, including finance, healthcare, and meteorology, where accurate forecasting is paramount for informed decision-making and proactive measures. However, the presence of missing data poses significant challenges, often undermining the performance of predictive models. Traditional two-step approaches that first impute missing values and then perform forecasting tend to accumulate errors, particularly in complex multivariate settings with high missing ratios and intricate dependency structures. In this work, we present S4M, an end-to-end time series forecasting framework that seamlessly integrates missing data handling within the Structured State Space Sequence (S4) model architecture. Unlike conventional methods that treat imputation as a separate preprocessing step, S4M leverages the latent space of S4 models to recognize and represent missing data patterns directly, thereby capturing the underlying temporal and multivariate dependencies more effectively. Our approach comprises two key modules: the Adaptive Temporal Prototype Mapper (ATPM) and the Missing-Aware Dual Stream S4 (MDS-S4). The ATPM utilizes a prototype bank to derive robust and informative representations from historical data patterns, while MDS-S4 processes these representations alongside missingness masks as dual input streams to perform accurate forecasting. Extensive empirical evaluations on diverse real-world datasets demonstrate that S4M consistently achieves state-of-the-art performance, validating the efficacy of our integrated approach in handling missing data, highlighting its robustness and superiority over traditional imputation-based methods. These results highlight the potential of our method for advancing reliable time series forecasting in practical applications.", "title_embedding_index": 5402, "title_abs_embedding_index": 5427}, {"title": "The Power of Data: How LSTMs Outshine Disease Progression Modeling with Two Simple Mechanisms", "link_suffix": "/forum?id=dj8CaE1G7m", "link": "https://openreview.net/forum?id=dj8CaE1G7m", "pdf_link": "https://openreview.net/pdf?id=dj8CaE1G7m", "keywords": "LSTM, Septic Shock, Disease Progression Modeling, Time-Aware, VRNN, Transformer, Bi-Directional", "abstract": "Much of prior efforts have focused on Disease Progression Modeling (DPM) using Electronic Health Records (EHRs). EHRs, however, present significant challenges for deep learning models such as Long Short-Term Memory (LSTM), Variational Recurrent Neural Networks (VRNN), and Transformer due to the inherent complexities and variabilities within the data. Effectively addressing these variabilities is crucial for improving the performance and interpretability of such models. In this work, we propose two mechanisms to tackle key variabilities in EHR data: a \"bi-directional\" mechanism to account for the need to infer the underlying physical state in both forward and backward directions, and a \"time-aware\" mechanism to address irregular time intervals between consecutive events. We theoretically validate and empirically evaluate the impact of these two mechanisms across three state-of-the-art deep learning models in three distinct healthcare systems. Our results showed that the influence of the two mechanisms\u2014bidirectionality and time-awareness\u2014surpasses the differences between specific deep learning models. Across all three models, the performance hierarchy consistently follows: Bidirectional & Time-Aware > Time-Aware > Bidirectional > Original model, across all three healthcare systems. Notably, the Bidirectional Time-Aware LSTM matches or exceeds the performance of the corresponding VRNN and Transformer models in every system tested.", "title_embedding_index": 5403, "title_abs_embedding_index": 5428}, {"title": "SafetyAnalyst: Interpretable, transparent, and steerable LLM safety moderation", "link_suffix": "/forum?id=6QBHdrt8nX", "link": "https://openreview.net/forum?id=6QBHdrt8nX", "pdf_link": "https://openreview.net/pdf?id=6QBHdrt8nX", "keywords": "AI safety, AI ethics, LLM content moderation, interpretability, pluralistic alignment", "abstract": "The ideal LLM content moderation system would be both structurally interpretable (so its decisions can be explained to users) and steerable (to reflect a community's values or align to safety standards).  However, current systems fall short on both of these dimensions. To address this gap, we present SafetyAnalyst, a novel LLM safety moderation framework. Given a prompt, SafetyAnalyst creates a structured ``harm-benefit tree,'' which identifies 1) the actions that could be taken if a compliant response were provided, 2) the harmful and beneficial effects of those actions (along with their likelihood, severity, and immediacy), and 3) the stakeholders that would be impacted by those effects.  It then aggregates this structured representation into a harmfulness score based on a parameterized set of safety preferences, which can be transparently aligned to particular values. Using extensive harm-benefit features generated by SOTA LLMs on 19k prompts, we fine-tuned an open-weight LM to specialize in generating harm-benefit trees through symbolic knowledge distillation. On a comprehensive set of prompt safety benchmarks, we show that our system (average F1=0.75) outperforms existing LLM safety moderation systems (average F1$<$0.72) on prompt harmfulness classification, while offering the additional advantages of interpretability and steerability.", "title_embedding_index": 5404, "title_abs_embedding_index": 5429}, {"title": "Out-Of-Context and Out-Of-Scope: Subliminal Priming for Large Language Models", "link_suffix": "/forum?id=wFIf8zpzTI", "link": "https://openreview.net/forum?id=wFIf8zpzTI", "pdf_link": "https://openreview.net/pdf?id=wFIf8zpzTI", "keywords": "representation learning, generative models, learning theory, applications to neuroscience & cognitive science", "abstract": "Subliminal priming in humans describes the influencing of behaviour via stimuli they are unaware of. In this work, we mimic human subliminal priming studies for large language models (LLMs) by inserting a seemingly negligible number of ex-template descriptions of a fictitious character's behaviour into a large corpus of longer but unrelated in-template instructions. After fine-tuning models on the combined data, we elicit demonstrations of the behaviour using suitable trigger prompts. While there is no concept of an LLM being unaware of the stimuli, we show that prompting strategies motivated by projective psychology and psychoanalytic theory can succeed where naive questions fail, even with potent chain-of-thought (COT) initiators. This work extends research on out-of-context reasoning (OOCR), where LLMs show a form of situational awareness and \"read between the lines\" or \"think outside of the box\" by performing reasoning hops on internalised knowledge. Our theoretical justification for why this subliminal priming analogue works for LLMs comes from the observation that optimising models with the standard per-token cross-entropy loss is equivalent to training models on a weighted context classification task, where shorter contexts have a higher weight. Our experiments show that manipulating the training data by adding a small number of short descriptions and using soft out-of-vocabulary (OOV) tokens as context anchors can allow and improve the embedding and triggering of specific behaviour, hinting at the possibility of undetected alignment hazards in current LLMs.", "title_embedding_index": 5405, "title_abs_embedding_index": 5430}, {"title": "VEnhancer: Generative Space-Time Enhancement for Video Generation", "link_suffix": "/forum?id=Ysdo3fyD4Q", "link": "https://openreview.net/forum?id=Ysdo3fyD4Q", "pdf_link": "https://openreview.net/pdf?id=Ysdo3fyD4Q", "keywords": "Diffusion models, Video Generation, Generative Video enhancement, video super-resolution, frame interpolation, space-time super-resolution", "abstract": "We present \\emph{VEnhancer}, a generative space-time enhancement method that can improve the existing AI-generated videos spatially and temporally through one video diffusion model. Given a generated low-quality video, our approach can increase its spatial and temporal resolution simultaneously with arbitrary up-sampling space and time scales by adding more details in spatial domain and synthesize detailed motion in temporal domain. Furthermore, VEnhancer is able to remove generated spatial artifacts and temporal flickering of generated videos.To achieve this, basing on a pretrained generative video prior, we train a \\textbf{S}pace-\\textbf{T}ime Controller and inject it to the prior as a condition on low-frame-rate and low-resolution videos. To effectively train this ST-Controller, we design \\textit{space-time data augmentation} to create diversified video training pairs as well as \\textit{video-aware conditioning} for realizing different augmentation parameters in both spatial and temporal dimensions.\nBenefiting from the above designs, VEnhancer can be end-to-end trained to enable multi-function in one single model. \nExtensive experiments show that VEnhancer\nsurpasses existing state-of-the-art video super-resolution and space-time super-resolution methods in enhancing AI-generated videos. Moreover, VEnhancer is able to greatly improve the performance of open-source state-of-the-art text-to-video methods on video generation benchmark, VBench.", "title_embedding_index": 5406, "title_abs_embedding_index": 5431}, {"title": "An Efficient Unsupervised Framework for Convex Quadratic Programs via Deep Unrolling", "link_suffix": "/forum?id=ivs0xU9Ebg", "link": "https://openreview.net/forum?id=ivs0xU9Ebg", "pdf_link": "https://openreview.net/pdf?id=ivs0xU9Ebg", "keywords": "Quadratic programming, Learning to optimize, Deep unrolling, Primal-Dual Hybrid Gradient, Unsupervised learning", "abstract": "Quadratic programs (QPs) arise in various domains such as machine learning, finance, and control. \nRecently, learning-enhanced primal-dual hybrid gradient (PDHG) methods have shown great potential in addressing large-scale linear programs; however, this approach has not been extended to QPs.\nIn this work, we focus on unrolling \"PDQP\", a PDHG algorithm specialized for convex QPs. Specifically, we propose a neural network model called \"PDQP-net\" to learn optimal QP solutions. Theoretically, we demonstrate that a PDQP-net of polynomial size can align with the PDQP algorithm, returning optimal primal-dual solution pairs.\nWe propose an unsupervised method that incorporates KKT conditions into the loss function. Unlike the standard learning-to-optimize framework that requires optimization solutions generated by solvers, our unsupervised method adjusts the network weights directly from the evaluation of the primal-dual gap.\nThis method has two benefits over supervised learning: first, it helps generate better primal-dual gap since the primal-dual gap is in the objective function; second, it does not require solvers. \nWe show that PDQP-net trained in this unsupervised manner can effectively approximate optimal QP solutions.\nExtensive numerical experiments confirm our findings, indicating that using PDQP-net predictions to warm-start PDQP can achieve up to 45% acceleration on QP instances. \nMoreover, it achieves 14% to 31% acceleration on out-of-distribution instances.", "title_embedding_index": 5407, "title_abs_embedding_index": 5432}, {"title": "Universal Time-series Generation using Score-based Generative Models", "link_suffix": "/forum?id=5Ro7JT5Vaf", "link": "https://openreview.net/forum?id=5Ro7JT5Vaf", "pdf_link": "https://openreview.net/pdf?id=5Ro7JT5Vaf", "keywords": "Time-series generation, Diffusion models, Signal processing", "abstract": "Score-based generative models (SGMs) have demonstrated unparalleled sampling quality and diversity in numerous fields, such as image generation, voice synthesis, and tabular data synthesis, etc. Inspired by those outstanding results, we apply SGMs to synthesize time-series by learning its conditional score function. To this end, we present a conditional score network for time-series synthesis, deriving a denoising score matching loss tailored for our purposes. In particular, our presented denoising score matching loss is the conditional denoising score matching loss for time-series synthesis. In addition, our framework is such flexible that both regular and irregular time-series can be synthesized with minimal changes to our model design. Finally, we obtain exceptional synthesis performance on various time-series datasets, achieving state-of-the-art sampling diversity and quality.", "title_embedding_index": 5408, "title_abs_embedding_index": 5433}, {"title": "An Exploration with Entropy Constrained 3D Gaussians for 2D Video Compression", "link_suffix": "/forum?id=JbRM5QKRDd", "link": "https://openreview.net/forum?id=JbRM5QKRDd", "pdf_link": "https://openreview.net/pdf?id=JbRM5QKRDd", "keywords": "Video Compression, 3D Gaussian Splatting, Entropy Coding", "abstract": "3D Gaussian Splatting (3DGS) has witnessed its rapid development in novel view synthesis, which attains high quality reconstruction and real-time rendering. At the same time, there is still a gap before implicit neural representation (INR)  can become a practical compressor due to the lack of stream decoding and real-time frame reconstruction on consumer-grade hardware. It remains a question whether the fast rendering and partial parameter decoding characteristics of 3DGS are applicable to video compression. To address these challenges, we propose a Toast-like Sliding Window (TSW) orthographic projection for converting any 3D Gaussian model into a video representation model. This method efficiently represents video by leveraging temporal redundancy through a sliding window approach. Additionally, the converted model is inherently stream-decodable and offers a higher rendering frame rate compared to INR methods. Building on TSW, we introduce an end-to-end trainable video compression method, GSVC, which employs deformable Gaussian representation and optical flow guidance to capture dynamic content in videos. Experimental results demonstrate that our method effectively transforms a 3D Gaussian model into a practical video compressor.  GSVC further achieves better rate-distortion performance than NeRV on the UVG dataset, while achieving higher frame reconstruction speed (+30%~40% fps) and stream decoding. Code will be released.", "title_embedding_index": 5409, "title_abs_embedding_index": 5434}, {"title": "Hearing faces among homogeneous populations: improvement of cross-modal biometrics", "link_suffix": "/forum?id=WjxgruI6A2", "link": "https://openreview.net/forum?id=WjxgruI6A2", "pdf_link": "https://openreview.net/pdf?id=WjxgruI6A2", "keywords": "Computer Vision, Face Recognition, Speech Recognition, Cross-modality, Deep Learning", "abstract": "The relationship between voice and face is well-established in neuroscience and biology. Recent algorithmic advancements have yielded substantial improvements in voice face matching. However, these approaches predominantly achieve success by leveraging datasets with diverse demographic characteristics, which inherently provide greater inter-speaker variability. We address the challenging problem of voice face matching and retrieval in homogeneous datasets, where speakers share gender and ethnicity. Our novel deep architecture, featuring a weighted triplet loss function based on face distances, achieves state-of-the-art performance for voice face matching on these uniform populations. We evaluate our model on a carefully curated homogeneous dataset containing  only the voices and faces of white males. In addition, we introduce percentile-recall, a new metric for evaluating voice face retrieval tasks.", "title_embedding_index": 5410, "title_abs_embedding_index": 5435}, {"title": "Industrial Benchmarking of LLMs: Assessing Hallucination in Traffic Incident Scenarios with a Novel Spatio-Temporal Dataset", "link_suffix": "/forum?id=JQbqaQjV7D", "link": "https://openreview.net/forum?id=JQbqaQjV7D", "pdf_link": "https://openreview.net/pdf?id=JQbqaQjV7D", "keywords": "Benchmark And Dataset, GenAI, LLMs, Hallucination, Trustworthy Machine Learning (accountability, causality, fairness, privacy, Robustness)", "abstract": "Large language models (LLMs) hold revolutionary potential to digitize and enhance the Health & Public Services (H&PS) industry. Despite their advanced linguistic abilities, concerns about accuracy, stability, and traceability still persist, especially in high-stakes areas such as transportation systems. Moreover, the predominance of English in LLM development raises questions about how they perform in non-English contexts.This study introduces a novel cross-lingual benchmark dataset comprising nearly 99,869 real traffic incident records from Vienna (2013-2023) to assess the robustness of state-of-the-art LLMs (>9) in the spatio and temporal domain of traffic incident classification.  We then explored three hypotheses \u2014 sentence indexing, date-to-text conversion, and German-to-English translation \u2014 and incorporated Retrieval Augmented Generation (RAG) to further examine the models' ability to handle hallucinations in both spatial and temporal contexts.Our experiments with GPT-4 and Llama models reveal significant performance disparities across these hypotheses in the spatio-temporal domain and also demonstrate how RAG can mitigate what types of hallucinations. These findings underscore the need for enhanced cross-lingual capabilities and improved explainability in LLMs.  We provide open access to our Health & Public Services (H&PS) traffic incident dataset, with the project demo and code available atWebsite.", "title_embedding_index": 5411, "title_abs_embedding_index": 5436}, {"title": "ILLUSION: Unveiling Truth with a Comprehensive Multi-Modal, Multi-Lingual Deepfake Dataset", "link_suffix": "/forum?id=qnlG3zPQUy", "link": "https://openreview.net/forum?id=qnlG3zPQUy", "pdf_link": "https://openreview.net/pdf?id=qnlG3zPQUy", "keywords": "Multi-modal, Multi-Lingual, Deepfake, AIGC", "abstract": "The proliferation of deepfakes and AI-generated content has led to a significant increase in media forgeries and misinformation, necessitating development of more robust detection systems. Current datasets, however, lack comprehensive diversity across modalities, languages, and real-world scenarios. To address this gap, we present ILLUSION (Integration of Life-Like Unique Synthetic Identities and Objects from Neural Networks), a large-scale multi-modal deepfake dataset comprising over 1.3 million samples. ILLUSION encompasses (i) audio-visual forgeries, (ii) diverse linguistic content with over 26 languages, (iii) challenging noisy environments, and (iv) various manipulation protocols. Generated using state-of-the-art generative models, ILLUSION includes face swaps, audio spoofing, synchronized audio-video manipulations, and synthetic images, faces, and videos. The proposed dataset has balanced representation of gender and skin tone, supports multilingual experiments, and is designed to facilitate development of robust multi-modal detection systems. We benchmarked state-of-the-art algorithms across multiple modalities including image-based, audio-based, video-based, and multi-modal detection. The results highlight critical challenges such as (a) performance degradation in multi-lingual and multi-modal contexts, (b) accuracy reduction in noisy environments, and (c) limited generalization to real-world scenarios and zero-day attacks. It is our assertion that the comprehensive nature of the proposed dataset enables researchers to develop and evaluate more resilient deepfake detection methods, addressing the evolving landscape of synthetic media threats.", "title_embedding_index": 5412, "title_abs_embedding_index": 5437}, {"title": "Coding Reliable LLM-based Integrated Task and Knowledge Agents with GenieWorksheets", "link_suffix": "/forum?id=G6S9B7fr74", "link": "https://openreview.net/forum?id=G6S9B7fr74", "pdf_link": "https://openreview.net/pdf?id=G6S9B7fr74", "keywords": "conversational agents, framework, task-oriented dialog agents, task and knowledge agents", "abstract": "Large Language Models (LLMs) present an opportunity to create automated assistants that can help users navigate complex tasks. However, existing approaches have limitations in handling conditional logic, integrating knowledge sources, and consistently following instructions. Researchers and industry professionals often employ ad hoc pipelines to construct conversational agents. These pipelines aim to maintain context, address failure cases, and minimize hallucinations, yet frequently fail to achieve these objectives. To this end, we present Genie \u2013 a programmable framework for creating task-oriented conversational agents that are designed to handle complex user interactions and knowledge queries. Unlike LLMs, Genie provides reliable grounded responses, with controllable agent policies through its expressive specification, Genie Worksheet. In contrast to dialog trees, it is resilient to diverse user queries, helpful with knowledge sources, and offers ease of programming policies through its declarative paradigm. The agents built using Genie outperforms the state-of-the-art method on complex logic domains in STARV2 dataset by up to 20.5%. Additionally, through a real-user study involving 62 participants, we show that Genie beats the GPT-4 with function calling baseline by 21.1%, 20.1%, and 61% on execution accuracy, dialogue act accuracy, and goal completion rate, respectively, on three diverse real-world domains.", "title_embedding_index": 5413, "title_abs_embedding_index": 5438}, {"title": "Gramian Multimodal Representation Learning and Alignment", "link_suffix": "/forum?id=ftGnpZrW7P", "link": "https://openreview.net/forum?id=ftGnpZrW7P", "pdf_link": "https://openreview.net/pdf?id=ftGnpZrW7P", "keywords": "Multimodal Representation Learning, Multimodal Alignment, Multimodal Contrastive Learning", "abstract": "Human perception integrates multiple modalities\u2014such as vision, hearing, and language\u2014into a unified understanding of the surrounding reality. While recent multimodal models have achieved significant progress by aligning pairs of modalities via contrastive learning, their solutions are unsuitable when scaling to multiple modalities. These models typically align each modality to a designated anchor without ensuring the alignment of all modalities with each other, leading to suboptimal performance in tasks requiring a joint understanding of multiple modalities. In this paper, we structurally rethink the pairwise conventional approach to multimodal learning and we present the novel Gramian Representation Alignment Measure (GRAM), which overcomes the above-mentioned limitations. GRAM learns and then aligns $n$ modalities directly in the higher-dimensional space in which modality embeddings lie by minimizing the Gramian volume of the $k$-dimensional parallelotope spanned by the modality vectors, ensuring the geometric alignment of all modalities simultaneously. GRAM can replace cosine similarity in any downstream method, holding for 2 to $n$ modality and providing more meaningful alignment with respect to previous similarity measures. The novel GRAM-based contrastive loss function enhances the alignment of multimodal models in the higher-dimensional embedding space, leading to new state-of-the-art performance in downstream tasks such as video-audio-text retrieval and audio-video classification.", "title_embedding_index": 5414, "title_abs_embedding_index": 5439}, {"title": "On the Influence of Shape, Texture and Color for Learning Semantic Segmentation", "link_suffix": "/forum?id=5MBUmj5mTI", "link": "https://openreview.net/forum?id=5MBUmj5mTI", "pdf_link": "https://openreview.net/pdf?id=5MBUmj5mTI", "keywords": "cue influence, shape, texture, semantic segmentation, bias, convolutional neural network (CNN), transformer", "abstract": "In recent years, a body of works has emerged, studying shape and texture biases of off-the-shelf pre-trained deep neural networks (DNN) for image classification. These works study how much a trained DNN relies on image cues, predominantly shape and texture. In this work, we switch the perspective, posing the following questions: What can a DNN learn from each of the image cues, i.e., shape, texture and color, respectively? How much does each cue influence the learning success? And what are the synergy effects between different cues? Studying these questions sheds light upon cue influences on learning and thus the learning capabilities of DNNs.\nWe study these questions on semantic segmentation which allows us to address our questions on pixel level. \nTo conduct this study, we develop a generic procedure to decompose a given dataset into multiple ones, each of them only containing either a single cue or a chosen mixture. This framework is then applied to two real-world datasets, Cityscapes and PASCAL Context, and a synthetic data set based on the CARLA simulator. We learn the given semantic segmentation task from these cue datasets, creating cue experts. Early fusion of cues is performed by constructing appropriate datasets. This is complemented by a late fusion of experts which allows us to study cue influence location-dependent on pixel level. Our study on three datasets reveals that neither texture nor shape clearly dominate the learning success, however a combination of shape and color but without texture achieves surprisingly strong results. Our findings hold for convolutional and transformer backbones. In particular, qualitatively there is almost no difference in how both of the architecture types extract information from the different cues.", "title_embedding_index": 5415, "title_abs_embedding_index": 5440}, {"title": "Going Beyond Static: Understanding Shifts with Time-Series Attribution", "link_suffix": "/forum?id=XQlccqJpCC", "link": "https://openreview.net/forum?id=XQlccqJpCC", "pdf_link": "https://openreview.net/pdf?id=XQlccqJpCC", "keywords": "distribution shifts, performance drop, attribution, time-series data", "abstract": "Distribution shifts in time-series data are complex due to temporal dependencies, multivariable interactions, and trend changes. \nHowever, robust methods often rely on structural assumptions that lack thorough empirical validation, limiting their practical applicability. \nIn order to support an empirically grounded inductive approach to research, we introduce our Time-Series Shift Attribution (TSSA) framework, which analyzes application-specific patterns of distribution shifts. Our framework attributes performance degradation from various types of shifts to eachtemporal data propertyin a detailed manner, supported by theoretical analysis of unbiasedness and asymptotic properties. Empirical studies in real-world healthcare applications highlight how the TSSA framework enhances the understanding of time-series shifts, facilitating reliable model deployment and driving targeted improvements from both algorithmic and data-centric perspectives.", "title_embedding_index": 5416, "title_abs_embedding_index": 5441}, {"title": "Autoregressive Transformers are Zero-Shot Video Imitators", "link_suffix": "/forum?id=wkbx7BRAsM", "link": "https://openreview.net/forum?id=wkbx7BRAsM", "pdf_link": "https://openreview.net/pdf?id=wkbx7BRAsM", "keywords": "Video Generation, Transformer, Zero-Shot", "abstract": "People interact with the real-world largely dependent on visual signal, which are ubiquitous and illustrate detailed demonstrations. In this paper, we explore utilizing visual signals as a new interface for models to interact with the environment. Specifically, we choose videos as a representative visual signal. And by training autoregressive Transformers on video datasets in a self-supervised objective, we find that the model emerges a zero-shot capability to infer the semantics from a demonstration video, and imitate the semantics to an unseen scenario. This allows the models to perform unseen tasks by watching the demonstration video in an in-context manner, without further fine-tuning. To validate the imitation capacity, we design various evaluation metrics including both objective and subjective measures. The results show that our models can generate high-quality video clips that accurately align with the semantic guidance provided by the demonstration videos, and we also show that the imitation capacity follows the scaling law.", "title_embedding_index": 5417, "title_abs_embedding_index": 5442}, {"title": "Mitigating Forgetting in Continually Pretraining MoE-LLMs by Adding and Chilling Experts", "link_suffix": "/forum?id=O9XdvMbnXC", "link": "https://openreview.net/forum?id=O9XdvMbnXC", "pdf_link": "https://openreview.net/pdf?id=O9XdvMbnXC", "keywords": "LLM, Continual Learning, Lifelong Learning, Mixture of Experts, Pretraining", "abstract": "As model training requires more and more compute, the cost of re-training models to support new data or domains increases as well. Methods to adapt existing models to new data distributions are crucial to avoid spending redundant compute re-training models from scratch. However, naive finetuning often incurs forgetting of previously learned capabilities. In this paper, we analyse how different factors such as model size, dataset size and replay data impact forgetting when adapting models to new data distributions. We also propose to increase the capacity of Mixture-of-experts models by adding new experts and reducing the learning rate of the old model weights. Our experiments show that this simple method allows to reduce forgetting and learn efficiently on the new domain.", "title_embedding_index": 5418, "title_abs_embedding_index": 5443}, {"title": "Cracking the Collective Mind: Adversarial Manipulation in Multi-Agent Systems", "link_suffix": "/forum?id=kgZFaAtzYi", "link": "https://openreview.net/forum?id=kgZFaAtzYi", "pdf_link": "https://openreview.net/pdf?id=kgZFaAtzYi", "keywords": "Multi-Agent, AI Safety", "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities across various domains such as healthcare, weather forecasting, finance, and law. These works have showcased the powerful abilities of individual LLMs. Recently, numerous studies have shown that coordinated multi-agent systems exhibit enhanced decision-making and reasoning capabilities through collaboration. However, since individual LLMs are susceptible to various adversarial attacks, a key vulnerability arises: Can an attacker manipulate the collective decision of such systems by accessing a single agent? To address this issue, we formulate it as a game with incomplete information, where agents lack full knowledge of adversarial strategies. We then propose a framework, M-Spoiler, which simulates a stubborn adversary in multi-agent debates during the training phase to tackle this problem. Through extensive experiments across various tasks, our findings confirm the risk of manipulation in multi-agent systems and demonstrate the effectiveness of our attack strategies. Additionally, we explore several defense mechanisms, revealing that our proposed attack method remains more potent than existing baselines, underscoring the need for further research on defensive strategies.", "title_embedding_index": 5419, "title_abs_embedding_index": 5444}, {"title": "On the Interpolation Effect of Score Smoothing", "link_suffix": "/forum?id=ETX8NTEuCj", "link": "https://openreview.net/forum?id=ETX8NTEuCj", "pdf_link": "https://openreview.net/pdf?id=ETX8NTEuCj", "keywords": "score-based diffusion models, score smoothing, data interpolation, generalization vs memorization, subspace recovery", "abstract": "Score-based diffusion models have achieved remarkable progress in various domains with an ability to generate new data samples that do not exist in the training set. In this paper, we examine a hypothesis that this phenomenon manifests an interpolation effect caused by a smoothing of the empirical score function. Focusing on settings where the training set lies in a one-dimensional linear subspace, we take a distribution-agnostic perspective and study the interplay between score smoothing and the denoising dynamics with mathematically solvable models. We demonstrate how score smoothing can lead to the generation of samples that interpolate among the training data within the subspace while avoiding a full memorization of the training set.", "title_embedding_index": 5420, "title_abs_embedding_index": 5445}, {"title": "Fast and Scalable Method for Efficient Multimodal Feature Extraction with Optimized Maximal Correlation", "link_suffix": "/forum?id=YrxhSkfHh0", "link": "https://openreview.net/forum?id=YrxhSkfHh0", "pdf_link": "https://openreview.net/pdf?id=YrxhSkfHh0", "keywords": "HGR maximal correlation, Soft-HGR, multimodal feature, UniFast HGR, deep learning", "abstract": "This paper introduces the UniFast HGR framework, a novel method designed to enhance the computation of Hirschfeld-Gebelein-R\u00e9nyi (HGR) maximal correlation, specifically optimized for large-scale neural networks and multimodal tasks. UniFast HGR introduces a variance constraint and optimizes the trace term, resulting in a more accurate approximation of the original HGR. By replacing traditional covariance-based measures with cosine similarity and eliminating bias from the main diagonal, the approach significantly reduces computational complexity while enhancing overall accuracy. These improvements make UniFast HGR highly scalable and capable of delivering superior performance in diverse, large-scale multimodal learning applications. Building on this foundation, the OptFast HGR method further optimizes performance by reducing the number of normalization steps, achieving efficiency and computational cost comparable to dot product and cosine similarity operations. This advancement accelerates computation without sacrificing performance. Experimental results indicate that UniFast HGR effectively balances efficiency and precision, establishing it as a robust solution for modern deep learning challenges.", "title_embedding_index": 5421, "title_abs_embedding_index": 5446}, {"title": "KAN See Your Face", "link_suffix": "/forum?id=razAcpFapu", "link": "https://openreview.net/forum?id=razAcpFapu", "pdf_link": "https://openreview.net/pdf?id=razAcpFapu", "keywords": "Face Reconstruction, Privacy-Preserving Face Recognition, Diffusion, Face Embedding Inversion", "abstract": "With the advancement of face reconstruction (FR) systems, privacy-preserving face recognition (PPFR) has gained popularity for its secure face recognition, enhanced facial privacy protection, and robustness to various attacks.\nBesides, specific models and algorithms are proposed for face embedding protection by mapping embeddings to a secure space.\nHowever, there is a lack of studies on investigating and evaluating the possibility of extracting face images from embeddings of those systems, especially for PPFR.\nIn this work, we introduce the first approach to exploit Kolmogorov-Arnold Network (KAN) for conducting embedding-to-face attacks against state-of-the-art (SOTA) FR and PPFR systems.\nFace embedding mapping (FEM) models are proposed to learn the distribution mapping relation between the embeddings from the initial domain and target domain.\nIn comparison with Multi-Layer Perceptrons (MLP), we provide two variants, FEM-KAN and FEM-MLP, for efficient non-linear embedding-to-embedding mapping in order to reconstruct realistic face images from the corresponding face embedding.\nTo verify our methods, we conduct extensive experiments with various PPFR and FR models.\nWe also measure reconstructed face images with different metrics to evaluate the image quality.\nThrough comprehensive experiments, we demonstrate the effectiveness of FEMs in accurate embedding mapping and face reconstruction.", "title_embedding_index": 5422, "title_abs_embedding_index": 5447}, {"title": "CLEAR: An Information-Theoretic  Framework for Distraction-Free Representation Learning in Visual Offline RL", "link_suffix": "/forum?id=Pui7Sa6Jwi", "link": "https://openreview.net/forum?id=Pui7Sa6Jwi", "pdf_link": "https://openreview.net/pdf?id=Pui7Sa6Jwi", "keywords": "Visual Offline Reinforcement Learning, Information-Theoretic Representation Learning", "abstract": "Visual offline RL aims to learn an optimal policy for visual domains, solely from the pre-collected dataset comprised of actions taken on visual observations. Prior works on visual RL typically learn a dynamics model by extracting a latent state representation. However, the learned representation would contain factors irrelevant to control when there are distractions in the visual observations. These nuisance factors introduced by the distraction further exacerbates the difficulties of learning a good policy in the offline RL setting. In this work, we formalize the visual offline RL setting as a Partially Observable Markov Decision Process with exogenous variables (ExoPOMDP) and identify  these problems with previous approaches under an information-theoretic lens. To overcome these challenges, we propose CLEAR (ControllableLatent StateExtrActoR) for visual offline RL, which learns the dynamics model of a succinct agent-centric state representation that is consistent with the underlying ExoPOMDP. We empirically demonstrate that CLEAR is able to outperform baselines on the DeepMind Control Suite with various types of distractions and perform consistently well across these distractions. We further provide qualitative analysis on the results showing that our approach successfully disentangles the distraction factors from the agent-centric state representation.", "title_embedding_index": 5423, "title_abs_embedding_index": 5448}, {"title": "On the Generalization of Preference Learning with DPO", "link_suffix": "/forum?id=bGkPZtisSm", "link": "https://openreview.net/forum?id=bGkPZtisSm", "pdf_link": "https://openreview.net/pdf?id=bGkPZtisSm", "keywords": "preference learning, generalization bound", "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities but often struggle to align with human preferences, leading to harmful or undesirable outputs. Preference learning, which trains models to distinguish between preferred and non-preferred responses based on human feedback, has become a crucial component for ensuring that LLMs align with human values. Despite the widespread adoption in real-world systems, a thorough theoretical understanding of the generalization guarantees for these models remains lacking. This paper bridges that gap by introducing a new theoretical framework to analyze the generalization guarantees of models trained with direct preference optimization. While existing generalization theory often focuses on overparameterized models achieving near-optimal loss or models independent of the training process, our framework rigorously assesses how well models generalize after a finite number of gradient steps, reflecting real-world LLM training practices. By analyzing the reward margin associated with each sample and its trajectory throughout training, we can effectively bound the generalization error. We derive learning guarantees showing that, under specific conditions, models trained with DPO can correctly discern preferred responses on unseen data with high probability. These insights are empirically validated on contemporary LLMs, underscoring the practical relevance of our theory.", "title_embedding_index": 5424, "title_abs_embedding_index": 5449}]
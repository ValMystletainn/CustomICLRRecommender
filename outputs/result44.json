[{"title": "Image Restoration for Training Data Reconstructed from Trained Neural Networks", "link_suffix": "/forum?id=x0h4H1WHXk", "link": "https://openreview.net/forum?id=x0h4H1WHXk", "pdf_link": "https://openreview.net/pdf?id=x0h4H1WHXk", "keywords": "image restoration, diffusion, privacy attacks, dataset reconstruction", "abstract": "Haim et al. [NeurIPS 2022] propose a method to reconstruct training data from trained neural networks with impressive results. While their reconstructed images resemble the original training images, most of them also contain a considerable amount of noise and artifacts. This is especially true, when the network was trained on more than just a few dozen images. To address this, we view the problem as a specific image restoration task. Since the noise and artifacts are different from other types of noise (Gaussian noise, compression artifacts, blurring, or impulse noise from digital cameras), we create a new dataset specifically for the restoration of images produced by the reconstruction process proposed by Haim et al. We use this dataset consisting of about 60 million noisy reconstructions of CIFAR-10 images to train a diffusion model on the restoration task. Using this method, we obtain reconstructions that are significantly closer to the original training images measured in terms of SSIM and HaarPSI scores.", "title_embedding_index": 2150, "title_abs_embedding_index": 2175}, {"title": "SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs", "link_suffix": "/forum?id=ZzATfnskP1", "link": "https://openreview.net/forum?id=ZzATfnskP1", "pdf_link": "https://openreview.net/pdf?id=ZzATfnskP1", "keywords": "Theory of Mind, social reasoning, LLM benchmark, mental state, behavior, judgment, false belief", "abstract": "While prior work has explored whether large language models (LLMs) possess a \"theory of mind\" (ToM) - the ability to attribute mental states to oneself and others - there has been little work testing whether LLMs can implicitly apply such knowledge to predict behavior, or to judge whether an observed behavior is rational. Such skills are critical for appropriate interaction in social environments. Our approach to study such capabilities is to create a new dataset, called SimpleToM, containing concise, diverse stories (e.g., \"The can of Pringles has moldy chips in it. Mary picks up the can in the supermarket and walks to the cashier.\"), each with three questions that test different degrees of ToM reasoning, asking models to predict (a) mental state (\"Is Mary aware of the mold?\"), (b) behavior (\"Will Mary pay for the chips or report the mold?\"), and (c) judgment (\"Mary paid for the chips. Was that reasonable?\"). To our knowledge, SimpleToM is the first dataset to systematically explore downstream reasoning requiring knowledge of mental states in realistic scenarios. Our experimental results are intriguing: While most models can reliably predict mental state on our dataset (a), they often fail to correctly predict the behavior (b), and fare even worse at judging whether given behaviors are reasonable, despite being correctly aware of the protagonist's mental state should make such secondary predictions obvious. We further show that we can help models do better at (b) and (c) via interventions such as reminding the model of its earlier mental state answer and mental-state-specific chain-of-thought prompting, raising the action prediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment accuracies (e.g., from 15.3% to 94.7% in GPT-4o). However, while this shows that models can be coaxed to perform well, it requires task-specific interventions, and the natural model performances remain low, a cautionary tale for LLM deployment. SimpleToM thus breaks new ground in probing real-world ToM reasoning, and reveals surprising, new insights about current model capabilities. We hope the dataset enables further exploration by the community into this critical area of model behavior.", "title_embedding_index": 2151, "title_abs_embedding_index": 2176}, {"title": "Dynamical modeling for real-time inference of nonlinear latent factors in multiscale neural activity", "link_suffix": "/forum?id=eR1119aUlL", "link": "https://openreview.net/forum?id=eR1119aUlL", "pdf_link": "https://openreview.net/pdf?id=eR1119aUlL", "keywords": "Multimodal deep learning, Missing data, Neuroscience, Real-time decoding", "abstract": "Continuous real-time decoding of target variables from time-series data is needed for many applications across various domains including neuroscience. Further, these variables can be encoded across multiple time-series modalities such as discrete spiking activity and continuous field potentials that can have different timescales (i.e., sampling rates) and different probabilistic distributions, or can even be missing at some time-steps.  Existing nonlinear models of multimodal neural activity do not support real-time decoding and do not address the different timescales or missing samples across modalities. Here, we develop a learning framework that can nonlinearly aggregate information across multiple time-series modalities with such distinct characteristics, while also enabling real-time decoding. This framework consists of 1) a multiscale encoder that nonlinearly fuses information after learning within-modality dynamics to handle different timescales and missing samples,  2) a multiscale dynamical backbone that extracts multimodal temporal dynamics and enables real-time decoding, and 3) modality-specific decoders to account for different probabilistic distributions across modalities. We further introduce smoothness regularization objectives on the learned dynamics to better decode smooth target variables such as behavioral variables and employ a dropout technique to increase the robustness for missing samples. We show that our model can aggregate information across modalities to improve target variable decoding in simulations and in a real multiscale brain dataset. Further, our method outperforms prior linear and nonlinear multimodal models.", "title_embedding_index": 2152, "title_abs_embedding_index": 2177}, {"title": "Enabling Pareto-Stationarity Exploration in Multi-Objective Reinforcement Learning: A Weighted-Chebyshev Multi-Objective Actor-Critic Approach", "link_suffix": "/forum?id=BPQMd2gTYI", "link": "https://openreview.net/forum?id=BPQMd2gTYI", "pdf_link": "https://openreview.net/pdf?id=BPQMd2gTYI", "keywords": "Multi-Objective Reinforcement Learning, Actor-Critic Algorithm", "abstract": "In many multi-objective reinforcement learning (MORL) applications, being able to systematically explore the Pareto-stationary solutions under multiple non-convex reward objectives with theoretical finite-time sample complexity guarantee is an important and yet under-explored problem.\nThis motivates us to take the first step and fill the important gap in MORL. \nSpecifically, in this paper, we propose a weighted-Chebyshev multi-objective actor-critic (\\policyns) algorithm for MORL, which uses multi-temporal-difference (TD) learning in the critic step and judiciously integrates the weighted-Chebychev (WC) and multi-gradient descent techniques in the actor step to enable systematic Pareto-stationarity exploration with finite-time sample complexity guarantee.\nOur proposed \\policy algorithm achieves a sample complexity of $\\tilde{\\mathcal{O}}(\\epsilon^{-2}p^{-2}_{\\min})$ in finding an $\\epsilon$-Pareto-stationary solution, where $p_{\\min}$ denotes the minimum entry of a given weight vector $p$ in the WC-scarlarization.\nThis result not only implies a state-of-the-art sample complexity that is independent of objective number $M$, but also brand-new dependence result in terms of the preference vector $p$. \nFurthermore, simulation studies on a large KuaiRand offline dataset, show that the performance of our \\policy algorithm significantly outperforms other baseline MORL approaches.", "title_embedding_index": 2153, "title_abs_embedding_index": 2178}, {"title": "Multi-Agent Path Finding via Decision Transformer and LLM Collaboration", "link_suffix": "/forum?id=Mvn48u0ehO", "link": "https://openreview.net/forum?id=Mvn48u0ehO", "pdf_link": "https://openreview.net/pdf?id=Mvn48u0ehO", "keywords": "Multi-Agent Path Finding, Multi-Agent Reinforcement Learning, Decision Transformer, Large Language Models, Autonomous Agents", "abstract": "Multi-Agent Path Finding (MAPF) is a significant problem with pivotal applications in robotics and logistics. The problem involves determining collision-free paths for multiple agents with specific goals in a 2D grid-world environment. Unfortunately, finding optimal solutions for MAPF is an NP-hard problem. Traditional centralized planning approaches are intractable for large numbers of agents and inflexible when adapting to\ndynamic changes in the environment. On the other hand, existing decentralized methods utilizing learning-based strategies suffer from two main drawbacks: (1) training takes times ranging from days to weeks, and (2) they often tend to exhibit self-centered agent behaviors leading to increased collisions. We introduce a novel approach leveraging the Decision Transformer (DT) architecture that enables agents to learn individual policies efficiently. We  capitalize on the transformer's capability for long-horizon planning and the advantages of offline reinforcement learning to drastically reduce training times to a few hours. We further show that integrating an LLM (GPT-4o), enhances the performance of DT policies in  mitigating undesirable behaviors such as prolonged idling at specific positions and undesired deviations from goal positions. We focus our empirical evaluation on both scenarios with static environments and in dynamically changing environments where agents' goals are altered during inference. Results demonstrate that incorporating an LLM for dynamic scenario adaptation in MAPF significantly enhances the agents' performance and paves the way for more adaptable multi-agent systems.", "title_embedding_index": 2154, "title_abs_embedding_index": 2179}, {"title": "GCNFT: Graph Convolutional Networks Aware Generative Feature Transformation", "link_suffix": "/forum?id=HYsU5X4kE5", "link": "https://openreview.net/forum?id=HYsU5X4kE5", "pdf_link": "https://openreview.net/pdf?id=HYsU5X4kE5", "keywords": "Feature Transformation, Data-centric AI, Representation Learning", "abstract": "Feature transformation for attributed graphs converts raw node attributes into augmented features that preserve node and structure information. Relevant literature either fails to capture graph structures (e.g., manual handcrafting, discrete search), or is latent and hard to interpret (e.g., GCNs). How can we automatically reconstruct explicit features of an attributed graph while effectively integrating graph structures and attributes? We generalize the learning task under such setting as a GCN-aware Feature Transformation (GCNFT) problem. GCNFT imposes two under-addressed challenges: 1) quantifying GCN awareness and 2) bridging GCN awareness and feature transformation. To tackle these challenges, we propose a graph convolution structure score guided generative learning framework to solve GCNFT. To quantify GCN awareness, we interpret GCN as a gap minimization process between ideal and current node representations in iterative Laplacian smoothing, and develop a task-agnostic structure score to approximate GCN awareness. To incorporate GCN awareness, we model feature transformation as sequential generative learning so that we pave a way to leverage the structures score to guide the generative learning and encourage graph structure alignment. Extensive experiments demonstrate the proposed GCN-aware approach outperforms feature transformation baselines with an improvement of 3% to 20% over node, link, and graph prediction tasks.", "title_embedding_index": 2155, "title_abs_embedding_index": 2180}, {"title": "Data-Aware Training Quality Monitoring and Certification for Reliable Deep Learning", "link_suffix": "/forum?id=4hp2bVdaHU", "link": "https://openreview.net/forum?id=4hp2bVdaHU", "pdf_link": "https://openreview.net/pdf?id=4hp2bVdaHU", "keywords": "Deep learning, data-driven bounds, training process, training quality monitoring, safe AI, reliable AI training, regulatable AI, performance certification", "abstract": "Deep learning models excel at capturing complex representations through sequential layers of linear and non-linear transformations, yet their inherent black-box nature and multi-modal training landscape raise critical concerns about reliability, robustness, and safety, particularly in high-stakes applications. To address these challenges, we introduce YES training bounds, a novel framework for real-time, data-aware certification and monitoring of neural network training. The YES bounds evaluate the efficiency of data utilization and optimization dynamics, providing an effective tool for assessing progress and detecting suboptimal behavior during training. Our experiments show that the YES bounds offer insights beyond conventional local optimization perspectives, such as identifying when training losses plateau in suboptimal regions. Validated on both synthetic and real data, including image denoising tasks, the bounds prove effective in certifying training quality and guiding adjustments to enhance model performance. By integrating these bounds into a color-coded cloud-based monitoring system, we offer a powerful tool for real-time evaluation, setting a new standard for training quality assurance in deep learning.", "title_embedding_index": 2156, "title_abs_embedding_index": 2181}, {"title": "Benign Overfitting in Out-of-Distribution Generalization of Linear Models", "link_suffix": "/forum?id=6jxUsDAdAu", "link": "https://openreview.net/forum?id=6jxUsDAdAu", "pdf_link": "https://openreview.net/pdf?id=6jxUsDAdAu", "keywords": "Over-parameterization, benign overfitting, OOD generalization, principal component regression, minimum norm interpolation, ridge regression", "abstract": "Benign overfitting refers to the phenomenon where a over-paramterized model fits the training data perfectly, including noise in the data, but still generalizes well to the unseen test data. While prior work provide a solid theoretical understanding of this phenomenon under the in-distribution setup, modern machine learning often operates in a more challenging Out-of-Distribution (OOD) regime, where the target (test) distribution can be rather different from the source (training) distribution. In this work, we take an initial step towards understanding benign overfitting in the OOD regime by focusing on the basic setup of over-parameterized linear models under covariate shift. We provide non-asymptotic guarantees proving that, when the target covariance satisfies certain structural conditions, benign overfitting occurs in standard ridge regression even under the OOD regime. We identify a number of key quantities relating source and target covariance, which govern the performance of OOD generalization. Our result is sharp, which provably recovers prior in-distribution benign overfitting guarantee (Tsigler & Bartlett, 2023), as well as under-parameterized OOD guarantee (Ge et al., 2024) when specializing to each setup. Moreover, we also present theoretical results for a more general family of target covariance matrix, where standard ridge regression only achieves a slow statistical rate of $\\mathcal{O}(1/\\sqrt{n})$ for the excess risk, while Principal Component Regression (PCR) is guaranteed to achieve the fast rate $\\mathcal{O}(1/n)$, where $n$ is the number of samples.", "title_embedding_index": 2157, "title_abs_embedding_index": 2182}, {"title": "ClimaQA: An Automated Evaluation Framework for Climate Foundation Models", "link_suffix": "/forum?id=goFpCuJalN", "link": "https://openreview.net/forum?id=goFpCuJalN", "pdf_link": "https://openreview.net/pdf?id=goFpCuJalN", "keywords": "Climate Benchmark, Scientific Foundation Models, Scientific Question Answering, Large Language Models, Automated QA generation", "abstract": "The use of foundation models in climate science has recently gained significant attention. However, a critical issue remains: the lack of a comprehensive evaluation framework capable of assessing the quality and scientific validity of model outputs. To address this issue, we develop ClimaGen (Climate QA Generator), an automated algorithmic framework that generates question-answer pairs from graduate textbooks with climate scientists in the loop. As a result, we present ClimaQA-Gold, an expert-annotated benchmark dataset alongside ClimaQA-Silver, a large-scale, comprehensive synthetic QA dataset for climate science. Finally, we develop evaluation strategies and compare different LLMs on our benchmarks. Our results offer novel insights into various approaches used to enhance climate foundation models.", "title_embedding_index": 2158, "title_abs_embedding_index": 2183}, {"title": "SLIM-LLMs: Low-Rank Models of Linguistic Style", "link_suffix": "/forum?id=SzWvRzyk6h", "link": "https://openreview.net/forum?id=SzWvRzyk6h", "pdf_link": "https://openreview.net/pdf?id=SzWvRzyk6h", "keywords": "Linguistic Style, Sensorial Linguistics, LIWC, SLIM-LLMs", "abstract": "Linguistic style encompasses a range of dimensions, including sensorial language as well as traditional stylistic features (represented using LIWC features). While these dimensions of linguistic style have been studied independently, relationships between the different dimensions, particularly between sensorial style and traditional stylistic features, remain understudied. This paper introduces a novel approach to model this interaction and tests it across a diverse set of texts. \nIn particular, we propose using a Reduced-Rank Ridge Regression (R4) to model low-rank latent relationships between LIWC-based stylistic features and sensorial language features. We find that compared to the full LIWC feature set ($r = 74$), its low-dimensional latent representations ($r = 24$) effectively capture stylistic information relevant to sensorial language prediction.\nBased on our results, we propose Stylometrically Lean Interpretable Models (SLIM-LLMs) \u2014 dimensionality-reduced LLMs that model the non-linear relationships between these two major dimensions of style. We evaluate SLIM-LLMs on the ability to predict sensorial language (the actual sensorial words used) in five text genres: business reviews, novels, song lyrics, advertisements, and informative articles. Results show that SLIM-LLMs augmented with low-rank style features consistently outperform baseline models. These SLIM-LLMs approach the performance of full-scale language models while using significantly fewer parameters (up to 80% reduction).", "title_embedding_index": 2159, "title_abs_embedding_index": 2184}, {"title": "Disentangling and Integrating Relational and Sensory Information in Transformer Architectures", "link_suffix": "/forum?id=Oq7BhRSy0a", "link": "https://openreview.net/forum?id=Oq7BhRSy0a", "pdf_link": "https://openreview.net/pdf?id=Oq7BhRSy0a", "keywords": "relational learning, transformers, inductive biases, sensory, relational, architecture, attention", "abstract": "Relational reasoning is a central component of generally intelligent systems, enabling robust and data-efficient inductive generalization. Recent empirical evidence shows that many existing neural architectures, including Transformers, struggle with tasks requiring relational reasoning. In this work, we distinguish between two types of information:sensoryinformation about the properties of individual objects, andrelationalinformation about the relationships between objects. While neural attention provides a powerful mechanism for controlling the flow of sensory information between objects, the Transformer lacks an explicit computational mechanism for routing and processing relational information. To address this limitation, we propose an architectural extension of the Transformer framework that we call theDual Attention Transformer (DAT), featuring two distinct attention mechanisms: sensory attention for directing the flow of sensory information, and a novel relational attention mechanism for directing the flow of relational information. We empirically evaluateDATon a diverse set of tasks ranging from synthetic relational benchmarks to complex real-world tasks such as language modeling and visual processing. Our results demonstrate that integrating explicit relational computational mechanisms into the Transformer architecture leads to significant performance gains in terms of data efficiency and parameter efficiency.", "title_embedding_index": 2160, "title_abs_embedding_index": 2185}, {"title": "Failure Modes of LLMs for Causal Reasoning on Narratives", "link_suffix": "/forum?id=9ljHiYuRHl", "link": "https://openreview.net/forum?id=9ljHiYuRHl", "pdf_link": "https://openreview.net/pdf?id=9ljHiYuRHl", "keywords": "Causal Inference, Large Language Models, Reasoning, Narratives", "abstract": "In this work, we investigate the causal reasoning abilities of large language models (LLMs) through the representative problem of inferring causal relationships from narratives.  We find that even state of the art language models rely heavily on unreliable shortcuts, both in terms of the narrative presentation and their parametric knowledge.  For example, LLMs tend to determine causal relationships based on the temporal ordering of events  (i.e., earlier events cause later ones), resulting in lower performance whenever events are not narrated in their exact causal order. Similarly, we demonstrate that LLMs struggle with long-term causal reasoning \u2014 they often fail when the narratives are longer and contain many events.  As an additional failure mode, we show LLMs appear to heavily rely on their parametric knowledge at the expense of reasoning over the provided narrative. This degrades their abilities whenever the narrative opposes parametric knowledge. We extensively validate these failure modes through carefully controlled synthetic experiments, as well as evaluations on real-world narratives. Finally, we observe that explicitly generating a causal graph generally improves performance \nwhile naive chain-of-thought is ineffective. Collectively, our results distill precise failure modes of current state-of-the art models and can pave the way for future techniques to enhance causal reasoning in LLMs.", "title_embedding_index": 2161, "title_abs_embedding_index": 2186}, {"title": "Task-Adaptation Curriculum Learning", "link_suffix": "/forum?id=CSpkSBe6jn", "link": "https://openreview.net/forum?id=CSpkSBe6jn", "pdf_link": "https://openreview.net/pdf?id=CSpkSBe6jn", "keywords": "Task adaptation, transfer learning, curriculum learning, search algorithms", "abstract": "A large distribution gap between a target task and pre-training tasks could undermine the task adaptation performance of pretrained models. When the target-task data are scarce, naive finetuning results in overfitting and forgetting. In various domains, skills can be transferred across semantically related tasks, among which the general-purposed ones often have more training data. Can we bridge the gap between a pre-trained model and a low-resource target task by leveraging data from other tasks? In this paper, we address the low-resource task adaptation challenge by a transfer learning curriculum, which finetunes a model on a curated sequence of intermediate tasks, thereby progressively bridging the gap between the pre-trained model and the target task. To this end, we formulate the task curriculum as a graph search problem and improve the efficiency of estimating transferability between tasks. Two search algorithms are studied, i.e., greedy best-first search and Monte Carlo tree search. We evaluate our approach, i.e., ``task-adaptation curriculum learning (TaCL)'' on two benchmark settings. Extensive evaluations on different target tasks demonstrate the effectiveness and advantages of TaCL on highly specific and low-resource downstream tasks.", "title_embedding_index": 2162, "title_abs_embedding_index": 2187}, {"title": "Scalable Multi-Domain Adaptation of Language Models using Modular Experts", "link_suffix": "/forum?id=VAqRZIuW8m", "link": "https://openreview.net/forum?id=VAqRZIuW8m", "pdf_link": "https://openreview.net/pdf?id=VAqRZIuW8m", "keywords": "domain adaptation, mixture of experts, MoE, fine-tuning, large language models, sharding", "abstract": "Domain-specific adaptation is critical to maximizing the performance of pre-trained\nlanguage models (PLMs) on one or multiple targeted tasks, especially under\nresource-constrained use cases, such as edge devices. However, existing methods often struggle to balance domain-specific performance, retention of general\nknowledge, and efficiency for training and inference. To address these challenges,\nwe propose Modular Domain Experts (MoDE). MoDE is a mixture-of-experts\narchitecture that augments a general PLMs with modular, domain-specialized\nexperts. These experts are trained independently and composed together via a\nlightweight training process. In contrast to standard low-rank adaptation methods,\neach MoDE expert consists of several transformer layers which scale better with\nmore training examples and larger parameter counts. Our evaluation demonstrates\nthat MoDE achieves comparable target performances to full parameter fine-tuning\nwhile achieving 1.65% better retention performance. Moreover, MoDE\u2019s architecture enables flexible sharding configurations and improves training speeds by\nup to 38% over state-of-the-art distributed training configurations.", "title_embedding_index": 2163, "title_abs_embedding_index": 2188}, {"title": "Depth Extrapolation of Decoders Trained on Nested Structures", "link_suffix": "/forum?id=fp77Ln5Hcc", "link": "https://openreview.net/forum?id=fp77Ln5Hcc", "pdf_link": "https://openreview.net/pdf?id=fp77Ln5Hcc", "keywords": "transformers, reasoning, nested structures, embeddings, generalization", "abstract": "Reasoning problems with deeply nested formal statements are challenging to solve for humans and machines alike. We investigate how next-token predictors learn such structures, and whether they extrapolate to more deeply nested instances. A case study of Boolean logic simplification demonstrates that a small specialized decoder Transformer can achieve far better performance than state-of-the-art large models, primarily due to memorization of the training set. We propose a theoretical grounding of memorization in a self-attention head with added trainable positional embeddings. We elicit relations between positional and token embeddings, which explain how large embedding dimensions scale with context size and number of topics in the training set. As an application of our theory, we study completion of a bounded stack of parentheses. We derive a closed-form expression for a simple decoder Transformer which solves this problem. With one dimensional embeddings, our closed-form model perfectly fits a single sequence training set, and provably completes any out-of-sample parentheses prefix, regardless of the prefix depth. In contrast, numerically, we observe that decoder Transformers trained on this task fail at learning small models capable of depth extrapolation. Gradient-trained decoders demand large samples and a high-dimensional embedding space to achieve near perfect accuracy on test sets nearly as deep as the training set. However, when the gap between training and test depths widens, gradient trained models appear to be inefficient.", "title_embedding_index": 2164, "title_abs_embedding_index": 2189}, {"title": "Multi-Session Client-Centered Treatment Outcome Evaluation in Psychotherapy", "link_suffix": "/forum?id=hQKXQf8Xo3", "link": "https://openreview.net/forum?id=hQKXQf8Xo3", "pdf_link": "https://openreview.net/pdf?id=hQKXQf8Xo3", "keywords": "Large Language Models, Psychotherapy, Psychological Assessment, Evaluation", "abstract": "In psychotherapy, therapeutic outcome assessment, or treatment outcome evaluation, is essential for enhancing mental health care by systematically evaluating therapeutic processes and outcomes. Existing large language model approaches often focus on therapist-centered, single-session evaluations, neglecting the client's subjective experience and longitudinal progress across multiple sessions. To address these limitations, we propose IPAEval, a client-Informed Psychological Assessment-based Evaluation framework that automates treatment outcome evaluations from the client's perspective using clinical interviews. IPAEval integrates cross-session client-contextual assessment and session-focused client-dynamics assessment to provide a comprehensive understanding of therapeutic progress. Experiments on our newly developed TheraPhase dataset demonstrate that IPAEval effectively tracks symptom severity and treatment outcomes over multiple sessions, outperforming previous single-session models and validating the benefits of items-aware reasoning mechanisms.", "title_embedding_index": 2165, "title_abs_embedding_index": 2190}, {"title": "3D Perception with Differentiable Map Priors", "link_suffix": "/forum?id=KyqtKhv6q1", "link": "https://openreview.net/forum?id=KyqtKhv6q1", "pdf_link": "https://openreview.net/pdf?id=KyqtKhv6q1", "keywords": "autonomous driving, 3D object detection, mapping", "abstract": "Human drivers rarely navigate where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most computer vision systems act as if they are encountering each location for the first time. In this work, we present Differentiable Map Priors, a simple but effective framework to learn spatial priors from historic traversals. Differentiable Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs. We show that they lead to a significant and consistent improvement in 3D object detection and semantic map segmentation tasks on the nuScenes dataset across several architectures.", "title_embedding_index": 2166, "title_abs_embedding_index": 2191}, {"title": "CAML: Collaborative Auxiliary Modality Learning for Multi-Agent Systems", "link_suffix": "/forum?id=IEKQlWIN4w", "link": "https://openreview.net/forum?id=IEKQlWIN4w", "pdf_link": "https://openreview.net/pdf?id=IEKQlWIN4w", "keywords": "Collaborative Auxiliary Modality Learning, Multi-Agent Collaboration, Cross-Modality Knowledge Distillation", "abstract": "Multi-modality learning has become a crucial technique in enhancing the performance of machine learning applications across various domains, including autonomous driving, robotics, and perception systems. Existing frameworks, such as Auxiliary Modality Learning (AML), effectively utilize multiple data sources during training and enable inference with reduced modalities, but they primarily operate in a single-agent context. This limitation is particularly critical in dynamic environments, such as connected autonomous vehicles (CAV), where incomplete data coverage can result in decision-making blind spots. To address these challenges, we introduce Collaborative Auxiliary Modality Learning ($\\textbf{CAML}$), a novel extension of the AML framework for multi-agent systems. $\\textbf{CAML}$ facilitates collaboration among agents by allowing them to share multimodal data during training. During inference, each agent operates effectively with fewer modalities, ensuring robustness in performance even with missing data. We analyze the effectiveness of $\\textbf{CAML}$ from the perspective of uncertainty reduction and data coverage, providing a theoretical support to understand and explain why $\\textbf{CAML}$ works better than AML. We then validate $\\textbf{CAML}$ through experiments in collaborative decision-making for CAV in accident-prone scenarios. Experimental results show that $\\textbf{CAML}$ outperforms AML across all tested scenarios, achieving up to a ${\\bf 58.3}$% improvement in accident detection.", "title_embedding_index": 2167, "title_abs_embedding_index": 2192}, {"title": "KV-Distill: Nearly Lossless Context Compression for Transformers", "link_suffix": "/forum?id=p7vJ3wsm34", "link": "https://openreview.net/forum?id=p7vJ3wsm34", "pdf_link": "https://openreview.net/pdf?id=p7vJ3wsm34", "keywords": "distillation, long context, efficiency, LLM, compression", "abstract": "Sequence-to-sequence natural language tasks often benefit greatly from long contexts, but the quadratic complexity of self-attention renders usage of long contexts non-trivial. In particular, during generation, temporary representations (stored in the KV cache) account for a large portion of GPU memory usage, and scale linearly with context length. In this work, we introduce KV-Distill, a flexible compression framework for large language models (LLMs) that distills long context KV caches into significantly shorter representations. KV-Distill can be trained as a parameter-efficient adaptor for pre-trained models, and enables the compression of arbitrary spans of a context while preserving the pre-trained model's capabilities, including instruction-tuning. We do this by treating a compressed-uncompressed cache as a student-teacher pairing and applying a KL-type divergence to match the generated outputs. Our experiments show that KV-Distill outperforms other compression techniques in worst-case extractive tasks, and approaches uncompressed performance in long context question answering and summarization. Furthermore, KV-Distill can be fine-tuned on domain-specific contexts to reduce context lengths by up 95% while preserving downstream task performance. We demonstrate the generalizability of KV-Distill across various model sizes and architectures.", "title_embedding_index": 2168, "title_abs_embedding_index": 2193}, {"title": "Estimating the Probabilities of Rare Outputs in Language Models", "link_suffix": "/forum?id=DC8bsa9bzY", "link": "https://openreview.net/forum?id=DC8bsa9bzY", "pdf_link": "https://openreview.net/pdf?id=DC8bsa9bzY", "keywords": "low probabilities, adversarial training, importance sampling", "abstract": "We consider the problem oflow probability estimation: given a machine learning model and a formally-specified input distribution, how can we estimate the probability of a binary property of the model's output, even when that probability is too small to estimate by random sampling? This problem is motivated by the need to improve worst-case performance, which distribution shift can make much more likely. We study low probability estimation in the context of argmax sampling from small transformer language models. We compare two types of methods: importance sampling, which involves searching for inputs giving rise to the rare output, and activation extrapolation, which involves extrapolating a probability distribution fit to the model's logits. We find that importance sampling outperforms activation extrapolation, but both outperform naive sampling. Finally, we explain how minimizing the probability estimate of an undesirable behavior generalizes adversarial training, and argue that new methods for low probability estimation are needed to provide stronger guarantees about worst-case performance.", "title_embedding_index": 2169, "title_abs_embedding_index": 2194}, {"title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "link_suffix": "/forum?id=gL1cNK2UEW", "link": "https://openreview.net/forum?id=gL1cNK2UEW", "pdf_link": "https://openreview.net/pdf?id=gL1cNK2UEW", "keywords": "curriculum learning, data science agent, long-term memory, online data retrieval", "abstract": "Large language model (LLM) agents have shown promising performance in generating code for solving complex data science problems. Recent studies primarily focus on enhancing in-context learning through improved search, sampling, and planning techniques, while overlooking the importance of the order in which problems are tackled during inference. In this work, we develop a novel inference-time optimization framework, referred to as DSMentor, which leverages curriculum learning---a strategy that introduces simpler task first and progressively moves to more complex ones as the learner improves---to enhance LLM agent performance in challenging data science tasks. Our mentor-guided framework organizes data science tasks in order of increasing difficulty and incorporates a growing long-term memory to retain prior experiences, guiding the agent's learning progression and enabling more effective utilization of accumulated knowledge. We evaluate DSMentor through extensive experiments on DSEval and QRData benchmarks. Experiments show that DSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval and QRData compared to baseline agents. Furthermore, DSMentor demonstrates stronger causal reasoning ability, improving the pass rate by 8.8% on the causality problems compared to GPT-4 using Program-of-Thoughts prompts. Our work underscores the importance of developing effective strategies for accumulating and utilizing knowledge during inference, mirroring the human learning process and opening new avenues for improving LLM performance through curriculum-based inference optimization.", "title_embedding_index": 2170, "title_abs_embedding_index": 2195}, {"title": "Deliberate Reasoning for LLMs as Structure-aware Planning with Accurate World Model", "link_suffix": "/forum?id=BaMkS6E2Du", "link": "https://openreview.net/forum?id=BaMkS6E2Du", "pdf_link": "https://openreview.net/pdf?id=BaMkS6E2Du", "keywords": "Large Language Models, multi-step reasoning, planning with world model, structured reasoning, generator-discriminator architecture", "abstract": "Enhancing the reasoning capabilities of large language models (LLMs) remains a key challenge, especially for tasks that require complex, multi-step decision-making. Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions. Inspired by this, we propose a novel multi-step reasoning framework for LLMs, referred to as Structure-aware Planning with Accurate World Model (SWAP). Unlike previous approaches that rely solely on Chain-of-Thought (CoT) reasoning in natural language, SWAP incorporates structural information to guide the reasoning process via a world model and provides a soft verification mechanism over the steps. Moreover, SWAP overcomes the challenge of accurate world state predictions in complex reasoning tasks by introducing a Generator-Discriminator architecture, which enables more reliable world modeling. Specifically, the generator predicts the next state, and the discriminator ensures alignment with the logical consistency required by the problem context. SWAP also encourages the policy model to explore a broad range of potential actions to prevent premature convergence. By resolving the bottlenecks of generation diversity for both actions and states using diversity-based modeling (DBM) and improving discrimination accuracy through contrastive ranking (CR), SWAP significantly enhances the reasoning performance of LLMs. We evaluate SWAP across diverse reasoning-intensive benchmarks including math reasoning, logical reasoning, and coding tasks. Extensive experiments demonstrate that SWAP achieves substantial improvements over the baselines and consistently outperforms existing LLMs of similar sizes.", "title_embedding_index": 2171, "title_abs_embedding_index": 2196}, {"title": "Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution", "link_suffix": "/forum?id=Yd2GeHRSlJ", "link": "https://openreview.net/forum?id=Yd2GeHRSlJ", "pdf_link": "https://openreview.net/pdf?id=Yd2GeHRSlJ", "keywords": "Distribution Shift, Open Set Domain Adaptation, Novel Category Detection, Anomaly Detection, Out of Distribution", "abstract": "In Open-Set Domain Adaptation (OSDA) we wish to perform classification in a target domain which contains a novel class along with $k$ non-novel classes. This work formally studies OSDA under the assumption that classes are separable, and the supports of source and target domains coincide, while other aspects of the distribution may change.\nWe develop a simple and scalable method that attains robustness to distribution shift and is guaranteed to solve the problem, while showing that it cannot be solved under weaker conditions that have been studied for OSDA in the past, particularly in the presence of covariate shift. We formally define the realistic assumptions within the scope of OSDA problem that the previous literature has either overlooked or not explicitly addressed. In a thorough empirical evaluation on both image and text data, we observe that existing OSDA methods are not robust to the distribution shifts we consider.\nThe results demonstrate the efficacy of joint representation learning for classification of known classes and detection of novel ones using principled methods. We find that optimizing these two objectives in unison leads to mutual improvements in task performance contrary to what might be expected when objectives are considered independently. Our rigorous empirical study also examines how OSDA performance under distribution shift is affected by parameters of the problem such as the size of novel class. \n Taken together, our observations emphasize the importance of formalizing assumptions under which OSDA methods operate and to develop appropriate methodology that are capable of scaling with large datasets and models for different scenarios of OSDA.", "title_embedding_index": 2172, "title_abs_embedding_index": 2197}, {"title": "Ladder Residual: Redefining Tensor Parallelism in Transformers for Accelerated Inference", "link_suffix": "/forum?id=6R4TGPd74N", "link": "https://openreview.net/forum?id=6R4TGPd74N", "pdf_link": "https://openreview.net/pdf?id=6R4TGPd74N", "keywords": "Language Model, Inference, Distributed Inference, Architecture, Efficiency, Parallelism", "abstract": "Large language model inference is both memory-intensive and time-consuming, often requiring distributed algorithms to efficiently scale. Tensor parallelism (TP) is a common technique used in multi-gpu training and inference to partition computation across multiple devices, reducing memory load and computation time. However, such parallelism necessitates fast interconnects between the devices which has been a major bottleneck and limits the gains obtained by scaling up the number of devices. We introduce Ladder Residual, a simple architectural modification applicable to all residual-based models that enable straightforward overlapping that effectively hides the latency of communication. Our insight is that in addition to systems optimization, one can also redesign the model architecture to decouple communication from computation. For a Transformer model of 8B size, applying Ladder Residual to all its layers achieves 29% end-to-end wall clock speed up at inference time with TP world size of 8 devices. We refer to such model as the Ladder Transformer.\nWe train a 1B and 3B Ladder Transformer from scratch and observe comparable performance to a standard dense transformer baseline. We also conduct adaptation experiments for our approach and show that it's possible to adapt parts of the Llama-3.1 8B model with minimal accuracy degradation by only retraining for 3B tokens. To further push the performance frontier, we propose another architectural modification which drops communications in the model, unlocking fast LLM inference in settings devoid of NVLink or other fast interconnects.", "title_embedding_index": 2173, "title_abs_embedding_index": 2198}, {"title": "Lossy Compression with Pretrained Diffusion Models", "link_suffix": "/forum?id=raUnLe0Z04", "link": "https://openreview.net/forum?id=raUnLe0Z04", "pdf_link": "https://openreview.net/pdf?id=raUnLe0Z04", "keywords": "Compression, Stable Diffusion, DDPM, DiffC", "abstract": "We apply Theis et al. (2022)'s DiffC algorithm to Stable Diffusion 1.5, 2.1, and XL, and demonstrate that these pretrained models are remarkably capable lossy image compressors. A principled algorithm for compression using pretrained diffusion models has been understood since at least 2020 (Ho et al.), but challenges in reverse-channel coding (RCC) have rendered such algorithms impractical. We introduce some simple workarounds which allow us to compress and decompress images using Stable Diffusion in under 10 seconds. Despite requiring no additional training, our method is competitive with other state-of-the-art compression methods at low bitrates (0.005-0.05 bpp).", "title_embedding_index": 2174, "title_abs_embedding_index": 2199}]
[
    {
        "title": "Retrieval Augmented Imputation using Data Lake Tables",
        "link_suffix": "/forum?id=EyW92b6DyY",
        "link": "https://openreview.net/forum?id=EyW92b6DyY",
        "pdf_link": "https://openreview.net/pdf?id=EyW92b6DyY",
        "keywords": "data imputation, dense retrieval, contrastive learning",
        "abstract": "Data imputation is an essential problem in many data science applications. Existing methods often struggle to impute missing values in scenarios where there is a lack of sufficient data redundancy. In this paper, leveraging large language models (LLMs) and data lakes, we propose a novel approach for retrieval-augmented imputation called RAI, utilizing fine-grained tuple-level retrieval instead of traditional coarse-grained table-based retrieval. RAI addresses the challenges of retrieving relevant tuples for missing value imputation from a data lake, where tuples have heterogeneous attributes, diverse values, and missing values. Rather than simply searching for similar tables, RAI employs a tuple encoder to learn meaningful representations for capturing tuple similarities and differences, enabling effective identification of candidate tuples. The retrieved results are further refined by a tuple reranker. We also introduce a new benchmark, mvBench, to advance further research. Extensive experiments demonstrate that RAI significantly outperforms existing methods. \nWe conduct extensive experiments, demonstrating that RAI significantly outperforms state-of-the-art table-based retrieval-augmented imputation methods by 10.7%."
    },
    {
        "title": "SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation",
        "link_suffix": "/forum?id=XgCejjNNYX",
        "link": "https://openreview.net/forum?id=XgCejjNNYX",
        "pdf_link": "https://openreview.net/pdf?id=XgCejjNNYX",
        "keywords": "Graph generation, Diffusion model, Conditional Graph Generation",
        "abstract": "We introduce SeaDAG, a semi-autoregressive diffusion model for conditional generation of Directed Acyclic Graphs~(DAGs). Considering their inherent layer-wise structure, we simulate layer-wise autoregressive generation by designing different denoising speed for different layers. Unlike conventional autoregressive generation that lacks a global graph structure view, our method maintains a complete graph structure at each diffusion step, enabling operations such as property control that require the full graph structure.\nLeveraging this capability, we evaluate the DAG properties during training by employing a graph property decoder. We explicitly train the model to learn graph conditioning with a condition loss, which enhances the diffusion model's capacity to generate graphs that are both realistic and aligned with specified properties. \nWe evaluate our method on two representative conditional DAG generation tasks: (1) circuit generation from truth tables, where precise DAG structures are crucial for realizing circuit functionality, and (2) molecule generation based on quantum properties.\nOur approach demonstrates promising results, generating high-quality and realistic DAGs that closely align with given conditions."
    },
    {
        "title": "Dataset Ownership Verification in Contrastive Pre-trained Models",
        "link_suffix": "/forum?id=zeAOzn80VQ",
        "link": "https://openreview.net/forum?id=zeAOzn80VQ",
        "pdf_link": "https://openreview.net/pdf?id=zeAOzn80VQ",
        "keywords": "Dataset Ownership Verification, Data Protection, Contrastive Learning, Pre-trained Models, Self-supervised Learning",
        "abstract": "High-quality open-source datasets, which necessitate substantial efforts for curation, has become the primary catalyst for the swift progress of deep learning. Concurrently, protecting these datasets is paramount for the well-being of the data owner. Dataset ownership verification emerges as a crucial method in this domain, but existing approaches are often limited to supervised models and cannot be directly extended to increasingly popular unsupervised pre-trained models. In this work, we propose the first dataset ownership verification method tailored specifically for self-supervised pre-trained models by contrastive learning. Its primary objective is to ascertain whether a suspicious black-box backbone has been pre-trained on a specific unlabeled dataset, aiding dataset owners in upholding their rights. The proposed approach is motivated by our empirical insights that when models are trained with the target dataset, the unary and binary instance relationships within the embedding space exhibit significant variations compared to models trained without the target dataset. We validate the efficacy of this approach across multiple contrastive pre-trained models including SimCLR, BYOL, SimSiam, MOCO v3, and DINO. The results demonstrate that our method rejects the null hypothesis with a $p$-value markedly below $0.05$, surpassing all previous methodologies."
    },
    {
        "title": "Transformer Encoder Satisfiability: Complexity and Impact on Formal Reasoning",
        "link_suffix": "/forum?id=VVO3ApdMUE",
        "link": "https://openreview.net/forum?id=VVO3ApdMUE",
        "pdf_link": "https://openreview.net/pdf?id=VVO3ApdMUE",
        "keywords": "transformer, formal reasoning, complexity",
        "abstract": "We analyse the complexity of the satisfiability problem (SAT) for transformer encoders (TE), naturally occurring in formal verification or interpretation tasks. We find that SAT is undecidable when considering TE as they are commonly studied in the expressiveness community. Furthermore, we identify practical scenarios where SAT is decidable and establish corresponding complexity bounds. Beyond trivial cases, we find that quantized TE\u2014those restricted by fixed-width arithmetic\u2014lead to the decidability of SAT due to their limited attention capabilities. However, the problem remains difficult, as we establish scenarios where SAT is NEXPTIME-hard and others where it is solvable in NEXPTIME for quantized TE. To complement our complexity results, we place our findings and their implications in the broader context of formal reasoning."
    },
    {
        "title": "Model-free reinforcement learning with noisy actions for automated experimental control in optics",
        "link_suffix": "/forum?id=HuC8dszO8r",
        "link": "https://openreview.net/forum?id=HuC8dszO8r",
        "pdf_link": "https://openreview.net/pdf?id=HuC8dszO8r",
        "keywords": "reinforcement learning, model-free, experimental control, optics, fiber coupling",
        "abstract": "Setting up and controlling optical systems is often a challenging and tedious task. The high number of degrees of freedom to control mirrors, lenses or phases makes automatic control challenging, especially when the complexity of the system cannot be adequately modeled due to noise or non-linearities. Here, we show that reinforcement learning (RL) can overcome these challenges when coupling laser light into an optical fiber, using a model-free RL approach that trains directly on the experiment without pre-training. By utilizing the sample-efficient algorithms Soft Actor-Critic (SAC) or Truncated Quantile Critics (TQC), our agent learns to couple with 90% efficiency, comparable to the human expert. We demonstrate that direct training on an experiment can replace extensive system modeling. Our result exemplifies RL's potential to tackle problems in optics, paving the way for more complex applications where full noise modeling is not feasible."
    },
    {
        "title": "Stability and Sharper Risk Bounds with Convergence RateO(1/n2)",
        "link_suffix": "/forum?id=IowRyVs862",
        "link": "https://openreview.net/forum?id=IowRyVs862",
        "pdf_link": "https://openreview.net/pdf?id=IowRyVs862",
        "keywords": "algorithmic stability, generalization bounds, excess risk bounds, stochastic gradiet descent",
        "abstract": "The sharpest known high probability excess risk bounds are up to $O\\left( 1/n \\right)$ for empirical risk minimization and projected gradient descent via algorithmic stability (Klochkov & Zhivotovskiy, 2021). In this paper, we show that high probability excess risk bounds of order up to $O(1/n^2)$ are possible. We discuss how high probability excess risk bounds reach $O(1/n^2)$ under strongly convexity, smoothness and Lipschitz continuity assumptions for empirical risk minimization, projected gradient descent and stochastic gradient descent. Besides, to the best of our knowledge, our high probability results on the generalization gap measured by gradients for nonconvex problems are also the sharpest."
    },
    {
        "title": "Holistic Unlearning Benchmark: A Multi-Faceted Evaluation for Text-to-Image Diffusion Model Unlearning",
        "link_suffix": "/forum?id=kaqrwQ96xW",
        "link": "https://openreview.net/forum?id=kaqrwQ96xW",
        "pdf_link": "https://openreview.net/pdf?id=kaqrwQ96xW",
        "keywords": "unlearning, diffusion model, text-to-image model, unlearning evaluation",
        "abstract": "As text-to-image diffusion models become advanced enough for commercial applications, there is also increasing concern about their potential for malicious and harmful use. Model unlearning has been proposed to mitigate the concerns by removing undesired and potentially harmful information from the pre-trained model. So far, the success of unlearning is mainly measured by whether the unlearned model can generate a target concept while maintaining image quality. However, unlearning is typically tested under limited scenarios, and the side effects of unlearning have barely been studied in the current literature. In this work, we thoroughly analyze unlearning under various scenarios with five key aspects. Our investigation reveals that every method has side effects or limitations, especially in more complex and realistic situations. By releasing our comprehensive evaluation framework with the source codes and artifacts, we hope to inspire further research in this area, leading to more reliable and effective unlearning methods."
    },
    {
        "title": "Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory for Gaussian Process Data",
        "link_suffix": "/forum?id=MbM1BqGpZu",
        "link": "https://openreview.net/forum?id=MbM1BqGpZu",
        "pdf_link": "https://openreview.net/pdf?id=MbM1BqGpZu",
        "keywords": "Diffusion model, transformers, sequential data, spatial-temporal dependency, sample complexity",
        "abstract": "Diffusion Transformer, the backbone of Sora for video generation, successfully scales the capacity of diffusion models, pioneering new avenues for high-fidelity sequential data generation. Unlike static data such as images, sequential data consists of consecutive data frames indexed by time, exhibiting rich spatial and temporal dependencies. These dependencies represent the underlying dynamic model and are critical to validate the generated data. In this paper, we make the first theoretical step towards bridging diffusion transformers for capturing spatial-temporal dependencies. Specifically, we establish score approximation and distribution estimation guarantees of diffusion transformers for learning Gaussian process data with covariance functions of various decay patterns. We highlight how the spatial-temporal dependencies are captured and affect learning efficiency. Our study proposes a novel transformer approximation theory, where the transformer acts to unroll an algorithm. We support our theoretical results by numerical experiments, providing strong evidence that spatial-temporal dependencies are captured within attention layers, aligning with our approximation theory."
    },
    {
        "title": "UniRiT: Towards Few-Shot Non-Rigid Point Cloud Registration",
        "link_suffix": "/forum?id=OqZDfIknDe",
        "link": "https://openreview.net/forum?id=OqZDfIknDe",
        "pdf_link": "https://openreview.net/pdf?id=OqZDfIknDe",
        "keywords": "Few-shot learning; Point cloud registration",
        "abstract": "Non-rigid point cloud registration is a critical challenge in 3D scene understanding, particularly in surgical navigation. Although existing methods achieve excellent performance when trained on large-scale, high-quality datasets, these datasets are prohibitively expensive to collect and annotate, e.g., organ data in authentic medical scenarios. With insufficient training samples and data noise, existing methods degrade significantly since non-rigid patterns are more flexible and complicated than rigid ones, and the distributions across samples are more distinct, leading to higher difficulty in representation learning with few data.\nIn this work, we aim to deal with this challenging few-shot non-rigid point cloud registration problem. Based on the observation that complex non-rigid transformation patterns can be decomposed into rigid and small non-rigid transformations, we propose a novel and effective framework, UniRiT. UniRiT adopts a two-step registration strategy that first aligns the centroids of the source and target point clouds and then refines the registration with non-rigid transformations, thereby significantly reducing the problem complexity. To validate the performance of UniRiT on real-world datasets, we introduce a new dataset, MedMatch3D, which consists of real human organs and exhibits high variability in sample distribution. We further establish a new challenging benchmark for few-shot non-rigid registration. Extensive empirical results demonstrate that UniRiT achieves state-of-the-art performance on MedMatch3D, improving the existing best approach by 94.22%."
    },
    {
        "title": "Fast training and sampling of Restricted Boltzmann Machines",
        "link_suffix": "/forum?id=3fGtV4Zfgq",
        "link": "https://openreview.net/forum?id=3fGtV4Zfgq",
        "pdf_link": "https://openreview.net/pdf?id=3fGtV4Zfgq",
        "keywords": "Restricted Boltzmann Machine, Fast Sampling, structured data learning, training algorithm",
        "abstract": "Restricted Boltzmann Machines (RBMs) are effective tools for modeling complex systems and deriving insights from data. However, training these models with highly structured data presents significant challenges due to the slow mixing characteristics of Markov Chain Monte Carlo (MCMC) processes. In this study, we build upon recent theoretical advancements in RBM training, focusing on the gradual encoding of data patterns into singular vectors of the coupling matrix, to significantly reduce the computational cost of training (in very clustered datasets) and evaluating and sampling in RBMs in general.  The learning process is analogous to thermodynamic continuous phase transitions observed in ferromagnetic models, where new modes in the probability measure emerge in a continuous manner. Such continuous transitions are associated with the critical slowdown effect, which adversely affects the accuracy of gradient estimates, particularly during the initial stages of training with clustered data. To mitigate this issue, we propose a pre-training phase that encodes the principal components into a low-rank RBM through a convex optimization process. This approach facilitates efficient static Monte Carlo sampling and accurate computation of the partition function. Furthermore, we exploit the continuous and smooth nature of the parameter annealing trajectory to achieve reliable and computationally efficient log-likelihood estimations, enabling online assessment during the training process, and to propose an novel sampling strategy termed parallel trajectory tempering that outperforms previously optimized MCMC methods.\nOur results demonstrate that this innovative training strategy enables RBMs to effectively address highly structured datasets that conventional methods struggle with. Additionally, we provide evidence that our log-likelihood estimation is more accurate than traditional, more computationally intensive approaches in controlled scenarios. Moreover, the parallel trajectory tempering algorithm significantly accelerates MCMC processes compared to existing and conventional methods."
    },
    {
        "title": "Training-free LLM-generated Text Detection by Mining Token Probability Sequences",
        "link_suffix": "/forum?id=vo4AHjowKi",
        "link": "https://openreview.net/forum?id=vo4AHjowKi",
        "pdf_link": "https://openreview.net/pdf?id=vo4AHjowKi",
        "keywords": "Fake text detection, training-free, detection",
        "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in generating high-quality texts across diverse domains. However, the potential misuse of LLMs has raised significant concerns, underscoring the urgent need for reliable detection of LLM-generated texts. Conventional training-based detectors often struggle with generalization, particularly in cross-domain and cross-model scenarios. In contrast, training-free methods, which focus on inherent discrepancies through carefully designed statistical features, offer improved generalization and interpretability. Despite this, existing training-free detection methods typically rely on global text sequence statistics, neglecting the modeling of local discriminative features, thereby limiting their detection efficacy. In this work, we introduce a novel training-free detector, termed \\textbf{Lastde} that synergizes local and global statistics for enhanced detection. For the first time, we introduce time series analysis to LLM-generated text detection, capturing the temporal dynamics of token probability sequences. By integrating these local statistics with global ones, our detector reveals significant disparities between human and LLM-generated texts. We also propose an efficient alternative, \\textbf{Lastde++} to enable real-time detection. Extensive experiments on six datasets involving cross-domain, cross-model, and cross-lingual detection scenarios, under both white-box and black-box settings, demonstrated that our method consistently achieves state-of-the-art performance. Furthermore, our approach exhibits greater robustness against paraphrasing attacks compared to existing baseline methods. {Our codes are available at \\url{https://anonymous.4open.science/r/Lastde-5DBC}anonymously}."
    },
    {
        "title": "HyperDet: Generalizable Detection of Synthesized Images by Generating and Merging A Mixture of Hyper LoRAs",
        "link_suffix": "/forum?id=A72sZWB66Q",
        "link": "https://openreview.net/forum?id=A72sZWB66Q",
        "pdf_link": "https://openreview.net/pdf?id=A72sZWB66Q",
        "keywords": "Fake images detection, hyper Lora, model merging",
        "abstract": "The emergence of diverse generative vision models has recently enabled the synthesis of visually realistic images, underscoring the critical need for effectively detecting these generated images from real photos. Despite advances in this field, existing detection approaches often struggle to accurately identify synthesized images generated by different generative models. In this work, we introduce a novel and generalizable detection framework termed HyperDet, which innovatively captures and integrates shared knowledge from a collection of functionally distinct and lightweight expert detectors. HyperDet leverages a large pretrained vision model to extract general detection features while simultaneously capturing and enhancing task-specific features. To achieve this, HyperDet first groups SRM filters into five distinct groups to efficiently capture varying levels of pixel artifacts based on their different functionality and complexity. Then, HyperDet utilizes a hypernetwork to generate LoRA model weights with distinct embedding parameters. Finally, we merge the LoRA networks to form an efficient model ensemble. Also, we propose a novel objective function that balances the pixel and semantic artifacts effectively. Extensive experiments on the UnivFD and Fake2M datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance. Moreover, our work paves a new way to establish generalizable domain-specific fake image detectors based on pretrained large vision models. {Our codes are available at \\url{https://anonymous.4open.science/r/HyperDet-3053}}."
    },
    {
        "title": "Model Growth Schedule learning via Optimal Path (SLOP) for Efficient LLM Pre-Training",
        "link_suffix": "/forum?id=7XgTh3i8FI",
        "link": "https://openreview.net/forum?id=7XgTh3i8FI",
        "pdf_link": "https://openreview.net/pdf?id=7XgTh3i8FI",
        "keywords": "Model growth, Optimal growth schedule, Efficient LLM Pre-Training",
        "abstract": "Existing training methods for Transformer-based large language models (LLMs) rely on massive amounts of data training from scratch, which requires a high cost in terms of compute and time. Recent studies have demonstrated the great potential of improving the LLM\u2019s training efficiency by growing from small pre-trained models to large ones\u2014a technique known as model growth. There are two main research problems associated with model growth: growth schedule and growth operators. Existing research focuses on growth operators, detailing specific manipulations of potential dimensions to expand Transformer parameters. Few studies have investigated the optimal growth schedule, which involves integrating all possible growth operators to create an optimal multi-staged growth path. This work introduces SLOP, a growth Schedule Learning methodology via Optimal Path, for multi-stage growth of models with minimal experimental training. SLOP utilizes marginal utility as an appropriate measure for an optimal schedule that balances training costs and model performance after multi-stage growth. With this measurement, the objective of determining the optimal model growth path is converted into a dynamic programming problem, which is then addressed mathematically in polynomial time. Empirical results demonstrate SLOP's theoretical validity and show that it is an efficient approach that outperforms alternative schedules in a variety of settings."
    },
    {
        "title": "UMAP: A Highly Extensible and Physics-Based Simulation Environment for Multi-agent Reinforcement Learning",
        "link_suffix": "/forum?id=uYzJvP8HGl",
        "link": "https://openreview.net/forum?id=uYzJvP8HGl",
        "pdf_link": "https://openreview.net/pdf?id=uYzJvP8HGl",
        "keywords": "multi-agent reinforcement learning, simulation environment, reinforcement learning",
        "abstract": "Existing simulation environments in the field of multi-agent reinforcement learning (MARL) either lack authenticity or complexity. The data generated by these environments significantly deviate from the requirements of the real world, hindering the practical application of MARL. To address this issue, we propose Unreal Multi-Agent Playground (UMAP), a highly extensible, physics-based 3D simulation environment implemented on the Unreal Engine. UMAP is user-friendly in terms of deployment, modification, and visualization, and all its components are open-sourced. Based on UMAP, we design a series of MARL tasks featuring heterogeneous agents, large-scale agents, multiple teams, and sparse team rewards.\nWe also develop an experimental framework compatible with algorithms ranging from \nrule-based to MARL-based provided by third-party frameworks. In the experimental section, we utilize the designed tasks to test several state-of-the-art algorithms. Additionally, We also conduct a physical experiment to demonstrate UMAP's potential in sim-to-real applications, which is a significant advantage due to the high extensibility and authenticity of UMAP. We believe UMAP can play an important role in the MARL field by evaluating existing algorithms and helping them apply to real-world scenarios, thus advancing the field of MARL."
    },
    {
        "title": "ELBOing Stein: Variational Bayes with Stein Mixture Inference",
        "link_suffix": "/forum?id=2rBLbNJwBm",
        "link": "https://openreview.net/forum?id=2rBLbNJwBm",
        "pdf_link": "https://openreview.net/pdf?id=2rBLbNJwBm",
        "keywords": "variational inference, particle-based inference, variance collapse",
        "abstract": "Stein variational gradient descent (SVGD) (Liu & Wang, 2016) performs approximate Bayesian inference by representing the posterior with a set of particles.\nHowever, SVGD suffers from variance collapse, i.e. poor predictions due to underestimating uncertainty (Ba et al., 2021), even for moderately-dimensional models\nsuch as small Bayesian neural networks (BNNs). To address this issue, we generalize SVGD by letting each particle parameterize a component distribution in\na mixture model. Our method, Stein Mixture Inference (SMI), optimizes a lower\nbound to the evidence (ELBO) and introduces user-specified guides parameterized\nby particles. SMI extends the Nonlinear SVGD framework (Wang & Liu, 2019) to\nthe case of variational Bayes. SMI effectively avoids variance collapse, judging by\na previously described test developed for this purpose, and performs well on standard data sets. In addition, SMI requires considerably fewer particles than SVGD\nto accurately estimate uncertainty for small BNNs. The synergistic combination of\nNSVGD, ELBO optimization and user-specified guides establishes a promising\napproach towards variational Bayesian inference in the case of tall and wide data."
    },
    {
        "title": "Hierarchical Classification via Diffusion on Manifolds",
        "link_suffix": "/forum?id=zJbwrk1DHc",
        "link": "https://openreview.net/forum?id=zJbwrk1DHc",
        "pdf_link": "https://openreview.net/pdf?id=zJbwrk1DHc",
        "keywords": "hierarchical classification, graph diffusion",
        "abstract": "Hierarchical classification, the problem of classifying images according to a predefined hierarchical taxonomy, has practical significance owing to the principle of ``making better mistakes'', i.e., better to predict correct coarse labels than incorrect fine labels. Yet, it is insufficiently studied in literature, presumably because simply finetuning a pretrained deep neural network using the cross-entropy loss on leaf classes already leads to good performance w.r.t not only the popular top-1 accuracy but also hierarchical metrics. Despite the empirical effectiveness of finetuning pretrained models, we argue that hierarchical classification could be better addressed by explicitly regularizing finetuning w.r.t the predefined hierarchical taxonomy. Intuitively, with a pretrained model, data lies in hierarchical manifolds in the feature space. Hence, we propose a hierarchical multimodal contrastive finetuning method to leverage taxonomic hierarchy to finetune a pretrained model for better hierarchical classification. Moreover, the hierarchical manifolds motivate a graph diffusion-based method to adjust posteriors at hierarchical levels altogether in inference. This distinguishes our method from the existing ones, including top-down approaches (using coarse-class predictions to adjust fine-class predictions) and bottom-up approaches (processing fine-class predictions towards coarse-label predictions). We validate our method on two large-scale datasets, iNat18 and iNat21. Extensive experiments demonstrate that our method significantly outperforms prior arts w.r.t both top-1 accuracy and established hierarchical metrics, thanks to our new multi-modal hierarchical contrastive training and graph-diffusion-based inference."
    },
    {
        "title": "New Recipe for Semi-supervised Community Detection: Clique Annealing under Crystallization Kinetics",
        "link_suffix": "/forum?id=jQ5T1Pbnx7",
        "link": "https://openreview.net/forum?id=jQ5T1Pbnx7",
        "pdf_link": "https://openreview.net/pdf?id=jQ5T1Pbnx7",
        "keywords": "Semi-supervised Community Detection, Clique, Annealing, Crystallization Kinetics",
        "abstract": "Semi-supervised community detection methods are widely used for identifying specific communities due to the label scarcity. Existing semi-supervised community detection methods typically involve two learning stages \\ie, learning in both initial identification and subsequent adjustment, which often starts from an unreasonable community core candidate.\nMoreover, these methods encounter scalability issues because they depend on reinforcement learning and generative adversarial networks, leading to higher computational costs and restricting the selection of candidates. \nTo address these limitations, we draw a parallel between crystallization kinetics and community detection to integrate the spontaneity of the annealing process into community detection.\nSpecifically, we liken community detection to identifying a crystal subgrain (core) that expands into a complete grain (community) through a process similar to annealing. Based on this finding, we propose CLique ANNealing (CLANN), which applies kinetics concepts to community detection by integrating these principles into the optimization process to strengthen the consistency of the community core. Subsequently, a learning-free Transitive Annealer was employed to refine the first-stage candidates by merging neighboring cliques and repositioning the community core, enabling a spontaneous growth process that enhances scalability.\nExtensive experiments on diverse community detection datasets demonstrate that CLANN outperforms state-of-the-art methods across multiple real-world datasets, showcasing its exceptional efficacy and efficiency in community detection."
    },
    {
        "title": "An EEG dataset of word-level brain responses for semantic text relevance",
        "link_suffix": "/forum?id=ZVdThSQTuC",
        "link": "https://openreview.net/forum?id=ZVdThSQTuC",
        "pdf_link": "https://openreview.net/pdf?id=ZVdThSQTuC",
        "keywords": "brain, semantic relevance, word relevance, sentence relevance, EEG, ERP, text, human language processing",
        "abstract": "Electroencephalography (EEG) can enable non-invasive, real-time measurement of brain activity in response to human language processing. Previously released EEG datasets focus on brain signals measured either during completely natural reading or in full psycholinguistic experimental settings. Since reading is commonly performed when considering certain content as more semantically relevant than other, we release a novel dataset for semantic text relevance containing $23{,}270$ time-locked (${\\sim}0.7s$) word-level EEG recordings acquired from participants who read both text that was semantically relevant and irrelevant to self-selected topics. Using these data, we present benchmark experiments with two evaluation protocols: participant-independent and participant-dependent on two prediction tasks (word relevance and sentence relevance). We report the performance of five well known models on these tasks. Our dataset and code are openly released. Altogether, our dataset paves the way for advancing research on language relevance and psycholinguistics, brain input and feedback-based recommendation and retrieval systems, and development of brain-computer interface (BCI) devices for online detection of language relevance."
    },
    {
        "title": "Multi-Neuron Unleashes Expressivity of ReLU Networks Under Convex Relaxation",
        "link_suffix": "/forum?id=Gf4d4ck131",
        "link": "https://openreview.net/forum?id=Gf4d4ck131",
        "pdf_link": "https://openreview.net/pdf?id=Gf4d4ck131",
        "keywords": "Neural Network Certification, Model Expressivity, Convex Relaxation",
        "abstract": "Modern neural network certification methods heavily rely on convex relaxations to compute sound bounds.  However, the true expressive power of convex relaxations is currently not well understood. Recent work has started investigating this direction, showing there does not exist a ReLU network that can express even the simple ``$\\max$'' function in $\\mathbb{R}^2$ such that the network outputs can be bounded exactly by single-neuron relaxations. This raises the following fundamental question: is there a convex relaxation (beyond single-neuron) that can provide exact bounds for ReLU networks expressing general continuous piecewise linear functions in $\\mathbb{R}^n$? In this work, we investigate this question and prove, perhaps surprisingly, that layer-wise multi-neuron relaxations can compute exact bounds for general ReLU networks. Based on this novel result, we show that the expressivity of ReLU networks is no longer limited under multi-neuron relaxations. To the best of our knowledge, this is the first positive result on the completeness of convex relaxations and the expressivity of ReLU networks under convex relaxation, shedding light on the practice of certified robustness."
    },
    {
        "title": "Cuff-KT: Tackling Learners' Real-time Learning Pattern Adjustment via Tuning-Free Knowledge State-Guided Model Updating",
        "link_suffix": "/forum?id=UVaPEthRKx",
        "link": "https://openreview.net/forum?id=UVaPEthRKx",
        "pdf_link": "https://openreview.net/pdf?id=UVaPEthRKx",
        "keywords": "Knowledge Tracing, Online Education",
        "abstract": "Knowledge Tracing (KT) is a core component of Intelligent Tutoring Systems, modeling learners' knowledge state to predict future performance and provide personalized learning support. Current KT models simply assume that training data and test data follow the same distribution. However, this is challenged by the continuous changes in learners' patterns. In reality, learners' patterns change irregularly at different stages ($e.g.$, different semesters) due to factors like cognitive fatigue and external stress. Additionally, there are significant differences in the patterns of learners from various groups ($e.g.$, different classes), influenced by social cognition, resource optimization, etc. We refer to these distribution changes at different stages and from different groups as intra-learner shift and inter-learner shift, respectively---a task introduced, which we refer to as Real-time Learning Pattern Adjustment (RLPA). Existing KT models, when faced with RLPA, lack sufficient adaptability, because they fail to timely account for the dynamic nature of different learners' evolving learning patterns. Current strategies for enhancing adaptability rely on retraining, which leads to significant overfitting and high time cost problem. To address this, we propose Cuff-KT, comprising a controller and a generator. The controller assigns value scores to learners, while the generator generates personalized parameters for selected learners. Cuff-KT adapts to distribution changes fast and flexibly without fine-tuning. Experiments on one classic and two latest datasets demonstrate that Cuff-KT significantly improves current KT models' performance under intra- and inter-learner shifts, with an average relative increase of 7% on AUC, effectively tackling RLPA. Our code and datasets are available athttps://anonymous.4open.science/r/Cuff-KT."
    },
    {
        "title": "Learning Hierarchical Polynomials of Multiple Nonlinear Features",
        "link_suffix": "/forum?id=UZ893n8FXr",
        "link": "https://openreview.net/forum?id=UZ893n8FXr",
        "pdf_link": "https://openreview.net/pdf?id=UZ893n8FXr",
        "keywords": "Deep Learning Theory, Feature Learning, Three-Layer Neural Network, Gradient Descent, Sample Complexity",
        "abstract": "In deep learning theory, a critical question is to understand how neural networks learn hierarchical features. In this work, we study the learning of hierarchical polynomials of multiple nonlinear features using three-layer neural networks. We examine a broad class of functions of the form $f^{\\star}=g^{\\star}\\circ \\mathbf{p}$, where $\\mathbf{p}:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}^{r}$ represents multiple quadratic features with $r \\ll d$ and $g^{\\star}:\\mathbb{R}^{r}\\rightarrow \\mathbb{R}$ is a polynomial of degree $p$. This can be viewed as a nonlinear generalization of the multi-index model, and also an expansion upon previous work on nonlinear feature learning that focused only on a single feature (i.e. $r = 1$). \n    Our primary contribution shows that a three-layer neural network trained via layerwise gradient descent suffices forcomplete recovery of the space spanned by the nonlinear featuresefficient learning of the target function $f^{\\star}=g^{\\star}\\circ \\mathbf{p}$ or transfer learning of $f=g\\circ  \\mathbf{p}$ with a different link functionwithin $\\widetilde{\\mathcal{O}}(d^4)$ samples and polynomial time.\nFor such hierarchical targets, our result substantially improves the sample complexity ${\\Theta}(d^{2p})$ of the kernel methods, demonstrating the power of efficient feature learning. It is important to highlight again that our results go beyond prior settings such as single-index and multi-index models, as well as models depending just on one nonlinear feature, contributing to a more comprehensive understanding of feature learning in deep learning."
    },
    {
        "title": "Anomaly Detection through Conditional Diffusion Probability Modeling on Graphs",
        "link_suffix": "/forum?id=saRBktzh3q",
        "link": "https://openreview.net/forum?id=saRBktzh3q",
        "pdf_link": "https://openreview.net/pdf?id=saRBktzh3q",
        "keywords": "Anomaly detection, Graph Neural Network, Diffusion Model",
        "abstract": "Existing Graph Neural Network-based anomaly detection methods suffer from over-smoothing issues during feature aggregation. Moreover, most existing methods are discriminative models that learn the boundaries between anomalous and normal data points, allowing malicious nodes in a dynamic adversarial environment to bypass detection boundaries. To address these issues, existing methods primarily focus on enhancing the discriminative boundary for each individual node, rather than considering the interdependencies of node anomalies from a holistic graph perspective. We propose an advanced Conditional Graph Anomaly Diffusion Model (CGADM) to model and capture the joint distribution of anomalies on the whole graph, thereby enabling generative graph anomaly detection. To avoid starting the diffusion process from a random state, CGADM introduces a prior-guided denoising diffusion probability model. To circumvent the need for iterative denoising samplings for each node on large-scale graphs, we adopt a prior confidence-aware mechanism to dynamically adjust the reverse sampling steps for each node, significantly reducing the computational burden on large-scale graphs. We conducted experiments on CGADM using standard benchmarks, and the results demonstrated excellent performance in graph anomaly detection tasks. Additional ablation studies confirmed our framework's computational advantages."
    },
    {
        "title": "Diff-Shape: A Novel Constrained Diffusion Model for Shape-based De Novo Drug Design",
        "link_suffix": "/forum?id=GE6iywJtsV",
        "link": "https://openreview.net/forum?id=GE6iywJtsV",
        "pdf_link": "https://openreview.net/pdf?id=GE6iywJtsV",
        "keywords": "Moleuclar generative model; Shape-based virtual screening; De Novo drug design;",
        "abstract": "Shape-based virtual screening is a widely utilized method in ligand-based de novo drug design, aiming to identify molecules in chemical libraries that share similar 3D shapes but simultaneously possess novel 2D chemical structures compared to the reference compound. As an emerging technology, generative model is an alternative way to do de novo drug design by directly generating 3D novel structures. However, existing models face challenges in reliably generating valid drug-like molecules under specific conformation constrains. Here, a novel diffusion model constrained with 3D reference shape, Diff-Shape, was proposed to generate structures whose 3D conformations are similar to a given reference shape, thereby avoiding the computational cost of screening large database of 3D conformations. This model utilized a zero-weighted graph control module, taking in various forms of point clouds of reference shape to guide diffusion process of 3D molecular generation. The results show that our model is capable of generating molecules with high shape similarity but still low 2D graph similarity to the query structure and it significantly out-performs existing shape based generative models."
    },
    {
        "title": "A novel Visible Multilayer Concept Factorization for Image Data Representation and Clustering",
        "link_suffix": "/forum?id=UCOPY3FZQW",
        "link": "https://openreview.net/forum?id=UCOPY3FZQW",
        "pdf_link": "https://openreview.net/pdf?id=UCOPY3FZQW",
        "keywords": "Image Data Representation, Concept Factorization, Two-dimensional Feature Extraction, Data Clustering",
        "abstract": "Traditional Concept Factorization (CF) methods learn feature of one data point from high-dimensional data space in the form of vector, which leads to the loss of pixel-level neighborhood information in Two-Dimensional (2D) images. In light of this, we present a novel Visible Multilayer Concept Factorization for image-data representation, termed VMCF. Specifically, to uncover deep latent features from complex data, VMCF adopts a multilayer framework, equipped with a \u2018Decomposition, Dimensionality reduction and Data reconstruction\u2019 network ($D^3$-net) in each layer. To obtain locality-preserving features, $D^3$-net firstly performs adaptive graph regularized concept learning on the input data of each layer. Then, $D^3$-net performs 2D feature extraction over the obtained basis images in order to reduce the loss of pixel-level neighborhood information during dimension plunging. The reconstructed data formed by the improved basis images and coefficient matrix is used as input for the next layer. In this way, the dimensions of the original data can gradually decrease at each layer, avoiding information loss caused by sudden dimensionality reduction. Meanwhile, 2D-reduced basis images can mediately improve the quality of new data representations. Extensive numerical experiments on several public image databases have shown that VMCF outperforms other state-of-the-art algorithms."
    },
    {
        "title": "Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model",
        "link_suffix": "/forum?id=DugT77rRhW",
        "link": "https://openreview.net/forum?id=DugT77rRhW",
        "pdf_link": "https://openreview.net/pdf?id=DugT77rRhW",
        "keywords": "layout reconstruction, holistic 3D representation, large 3D model.",
        "abstract": "Multiple-perspective images room layout reconstruction is poorly investigated due to the tedious and cumbersome steps that emerge from multi-view geometry, e.g camera intrinsic/extrinsic estimation, image matching, and triangulation. However, with the advancement of the current 3D foundation model DUSt3R, a paradigm shift has occurred in the 3D reconstruction realm, moving from a multi-step Structure-from-motion approach to an end-to-end single-step reconstruction without error accumulation and instability.\nTo this end, this paper employs the 3D foundation model DUSt3R in the room layout reconstruction task, naming it \\ours{}. As the name suggests, \\ours{} incorporates the DUSt3R framework and plane representation, then fine-tunes on a room layout dataset (Structure3D). With the uniform and parsimonious results of \\ours{}, we can obtain the final room layout with only a single post-processing step and 2D detection results. Compared to previous room layout reconstruction methods, it relaxes the setting from a single perspective/panorama image to multiple perspective images. Moreover, \\ours{} solves the task in an end-to-end paradigm without cumbersome steps and accumulated errors. Finally, experiments show that our \\ours{} not only surpasses the state-of-the-art on the synthesis dataset Structure3D but also demonstrates the robustness and performs well in real-world cases."
    }
]
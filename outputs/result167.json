[
    {
        "title": "A Novel Soft Alignment Approach for Language Models with Explicit Listwise Rewards",
        "link_suffix": "/forum?id=28TLorTMnP",
        "link": "https://openreview.net/forum?id=28TLorTMnP",
        "pdf_link": "https://openreview.net/pdf?id=28TLorTMnP",
        "keywords": "large language models, preference alignment, listwise optimization objective",
        "abstract": "Existing alignment methods, such as Direct Preference Optimization (DPO), are mainly tailored for pairwise preference data where rewards are implicitly defined rather than explicitly given. In this paper, we introduce a general framework for large language model alignment, leveraging a novel optimization objective to bridge the gap in handling reward datasets with a list of responses explicitly annotated with scalar preferences scores.Our work comprise a novel algorithm, soft preference optimization, SPO, which enables the direct extraction of an LM policy from reward data as well as preference data. The core of SPO is a novel listwise preference optimization objective with the exponential-logarithm function form and a adaptive loss coefficient that inject listwise preference signals into the large language model.We evaluate our methods in both reward and preference settings with Mistral models in different sizes. Experiments suggest that our method surpasses various preference baselines when reward datasets are available. We also find our method significantly outperforms DPO in complex reasoning tasks like math and coding."
    },
    {
        "title": "ControlAgent: Automating Control System Design via Novel Integration of LLM Agents and Domain Expertise",
        "link_suffix": "/forum?id=2mGFmAQWUI",
        "link": "https://openreview.net/forum?id=2mGFmAQWUI",
        "pdf_link": "https://openreview.net/pdf?id=2mGFmAQWUI",
        "keywords": "Automated Control System Design, LLM Agent",
        "abstract": "Control system design is a crucial aspect of modern engineering with far-reaching applications across diverse sectors, including aerospace, automotive systems, industrial processes, power grids, and robotics. Despite advances made by Large Language Models (LLMs) in various domains, their application in control system design remains limited due to the complexity and specificity of control theory. To bridge this gap, we introduceControlAgent, a new paradigm that automates control system design via novel integration of LLM agents and control-oriented domain expertise. ControlAgent encodes expert control knowledge and emulates human iterative design processes by gradually tuning controller parameters to meet user-specified requirements for stability, performance (e.g. settling time), and robustness (e.g., phase margin). Specifically, ControlAgent integrates multiple collaborative LLM agents, including a central agent responsible for task distribution and task-specific agents dedicated to detailed controller design for various types of systems and requirements. In addition to LLM agents, ControlAgent employs a Python computation agent that performs complex control gain calculations and controller evaluations based on standard design information (e.g. crossover frequency, etc) provided by task-specified LLM agents. Combined with a history and feedback module, the task-specific LLM agents iteratively refine controller parameters based on real-time feedback from prior designs. Overall, ControlAgent mimics the design processes used by (human) practicing engineers, but removes all the human efforts and can be run in a fully automated way to give end-to-end solutions for control system design with user-specified requirements. To validate ControlAgent's effectiveness, we developControlEval, an evaluation dataset that comprises 500 control tasks with various specific design goals. Comparative evaluations between LLM-based and traditional human-involved toolbox-based baselines demonstrate that ControlAgent can effectively carry out control design tasks, marking a significant step towards fully automated control engineering solutions."
    },
    {
        "title": "No Free Lunch from Random Feature Ensembles",
        "link_suffix": "/forum?id=7rzA6aEASo",
        "link": "https://openreview.net/forum?id=7rzA6aEASo",
        "pdf_link": "https://openreview.net/pdf?id=7rzA6aEASo",
        "keywords": "Ensemble Learning, Deep Ensembles, Kernel Random Features Regression, Representation Learning",
        "abstract": "Given a compute budget, one must decide whether to train a single, large neural network or to combine the predictions of many smaller networks.  We study this trade-off for ensembles of random-features kernel ridge regression models. We prove that when a fixed number of trainable parameters are partitioned among $K$ independently trained models, $K=1$ achieves optimal performance, provided the ridge parameter is optimally tuned. We then derive scaling laws which describe how the test risk of an ensemble of regression models decays with its total size.  We identify conditions on the kernel and task eigenstructure under which ensembles can achieve near-optimal scaling laws.  Training ensembles of deep convolutional neural networks on CIFAR-10 and a transformer architecture on C4, we find that a single large network outperforms any ensemble of networks with the same total number of parameters in both the lazy and rich feature-learning regimes."
    },
    {
        "title": "Learning guarantee of reward modeling using deep neural networks",
        "link_suffix": "/forum?id=mGSQLuYxVF",
        "link": "https://openreview.net/forum?id=mGSQLuYxVF",
        "pdf_link": "https://openreview.net/pdf?id=mGSQLuYxVF",
        "keywords": "Reinforcement Learning with Human Feedback, Reward Modeling, Deep Neural Networks, Learning Guarantee, Clear Human Beliefs",
        "abstract": "In this work, we study the learning theory of reward modeling using pairwise comparison data and deep neural networks. We establish a novel non-asymptotic regret bound for deep reward estimators in a non-parametric setting, which depends explicitly on the network architecture. Furthermore, to underscore the critical importance of clear human beliefs, we introduce a margin-type condition requiring the conditional winning probability of the optimal action in pairwise comparisons to be significantly distanced from 1/2. This condition enables a sharper regret bound, which substantiates the empirical efficiency in Reinforcement Learning from Human Feedback (RLHF) and highlights the role of clear human beliefs in its success. Notably, this improvement stems from high-quality pairwise comparison data under the margin-type condition and is independent of the specific estimators used, making it applicable to various learning algorithms and models."
    },
    {
        "title": "SReNet: Spectral Refined Network for Solving Operator Eigenvalue Problem",
        "link_suffix": "/forum?id=Kqm8jxOC4a",
        "link": "https://openreview.net/forum?id=Kqm8jxOC4a",
        "pdf_link": "https://openreview.net/pdf?id=Kqm8jxOC4a",
        "keywords": "AI for Science, Operator Eigenvalue Problem, Scientific Computing",
        "abstract": "Solving operator eigenvalue problems helps analyze intrinsic data structures and relationships, yielding substantial influence on scientific research and engineering applications.\nRecently, novel approaches based on deep learning have been proposed to obtain eigenvalues and eigenfunctions from the given operator, which address the efficiency challenge arising from traditional numerical methods.\nHowever, when solving top-$L$ eigenvalues problems, these learning-based methods ignore the information that could be inherited from other known eigenvectors, thus resulting in a less-than-ideal performance.\nTo address the challenge, we propose theSpectralRefinedNetwork (SReNet). \nOur novel approach incorporates the power method to approximate the top-$L$ eigenvalues and their corresponding eigenfunctions.\nTo effectively prevent convergence to previous eigenfunctions, we introduce the Deflation Projection that significantly improves the orthogonality of the computed eigenfunctions and enables more precise prediction of multiple eigenfunctions simultaneously. \nFurthermore, we develop the adaptive filtering method that dynamically leverages intermediate approximate eigenvalues to construct rational filters that filter out predicted eigenvalues, when predicting the successive eigenvalue of the given problem.\nDuring the iterative solving, the spectral transformation is performed based on the filter function, converting the original eigenvalue problem into an equivalent problem that is easier to converge.\nExtensive experiments demonstrate that our approach consistently outperforms existing learning-based methods, achieving state-of-the-art performance in accuracy."
    },
    {
        "title": "Enhancing Event Camera Data Pretraining via Prompt-Tuning with Visual Models",
        "link_suffix": "/forum?id=XTBdPLhiRL",
        "link": "https://openreview.net/forum?id=XTBdPLhiRL",
        "pdf_link": "https://openreview.net/pdf?id=XTBdPLhiRL",
        "keywords": "Event camera, Pretraining, Prompt-tuning",
        "abstract": "The pretraining-finetuning paradigm has achieved remarkable success in natural language processing and computer vision, becoming the dominant approach in many downstream tasks. However, its application in the event camera domain has encountered significant challenges. First, the scarcity and sparsity of large-scale event datasets lead to issues like overfitting during extensive pretraining. Second, event data inherently contains both temporal and spatial information, making it difficult to directly transfer knowledge from image-based pretraining to event camera tasks.\nIn this paper, we propose a low-parameter-cost SpatioTemporal Information Fusion Prompting (STP) method to address these challenges. This method enables bidirectional fusion of event and image data while mitigating the risk of overfitting. Specifically, the key innovation lies in effectively integrating the spatio-temporal information of event data to align with pre-trained image models and reduce the impact of data sparsity.\nTo achieve this, we designed an Overlap Patch Embedding module within the STP, which employs wide receptive field to capture more local information and reduce the influence of sparse regions. Additionally, we introduce a Temporal Transformer that integrates both global and local information, facilitating the fusion of temporal and spatial data. Our approach significantly outperforms previous state-of-the-art methods across multiple downstream tasks, including classification, semantic segmentation, and optical flow estimation. For instance, it achieves a top-1 accuracy of 68.83% on N-ImageNet with fewer trainable parameters. Our code is available in the Supplement."
    },
    {
        "title": "Efficiently Parameterized Neural Metriplectic Systems",
        "link_suffix": "/forum?id=uL1H29dM0c",
        "link": "https://openreview.net/forum?id=uL1H29dM0c",
        "pdf_link": "https://openreview.net/pdf?id=uL1H29dM0c",
        "keywords": "metriplectic systems, structure preservation, energy conservation, entropy stability, neural ODEs",
        "abstract": "Metriplectic systems are learned from data in a way that scales quadratically in both the size of the state and the rank of the metriplectic data. Besides being provably energy conserving and entropy stable, the proposed approach comes with approximation results demonstrating its ability to accurately learn metriplectic dynamics from data as well as an error estimate indicating its potential for generalization to unseen timescales when approximation error is low. Examples are provided which illustrate performance in the presence of both full state information as well as when entropic variables are unknown, confirming that the proposed approach exhibits superior accuracy and scalability without compromising on model expressivity."
    },
    {
        "title": "RGRL:  Quantum State Control via Representation-Guided Reinforcement Learning",
        "link_suffix": "/forum?id=x9J66fnMs8",
        "link": "https://openreview.net/forum?id=x9J66fnMs8",
        "pdf_link": "https://openreview.net/pdf?id=x9J66fnMs8",
        "keywords": "Quantum control, quantum state representation learning, reinforcement learning",
        "abstract": "Accurate control of quantum states is crucial  for quantum computing and other quantum technologies. In the basic scenario, the task is  to steer a quantum system towards a target state through  a sequence of control operations. Determining the appropriate operations, however, generally requires  information about the initial state of the system. Gathering this information becomes increasingly challenging when   the initial state is not {\\em a priori} known and the system's size grows large. To address this problem, we develop a machine-learning algorithm that uses a small amount of measurement data to  construct its internal representation of the system's state. The algorithm  compares this data-driven representation with a  representation of the target state, and uses reinforcement learning to output the appropriate control operations. We illustrate the effectiveness of the algorithm showing that it achieves accurate control of unknown many-body quantum states and non-Gaussian continuous-variable states using data from  a limited set of  quantum measurements."
    },
    {
        "title": "Dialogue Action Tokens: Steering Language Models in Goal-Directed Dialogue with a Multi-Turn Planner",
        "link_suffix": "/forum?id=eI3hEAWe8W",
        "link": "https://openreview.net/forum?id=eI3hEAWe8W",
        "pdf_link": "https://openreview.net/pdf?id=eI3hEAWe8W",
        "keywords": "Large Language Model, Dialogue Systems, Social Intelligence, Red Teaming",
        "abstract": "We present an approach called Dialogue Action Tokens (DAT) that adapts language model agents to plan goal-directed dialogues. The core idea is to treat each utterance as an action, thereby converting dialogues into games where existing approaches such as reinforcement learning can be applied. Specifically, we freeze a pretrained language model and train a small planner model that predicts a continuous action vector, used for controlled generation in each round. This design avoids the problem of language degradation under reward optimization. When evaluated on the Sotopia platform for social simulations, the DAT-steered LLaMA model surpasses GPT-4's performance. We also apply DAT to steer an attacker language model in a novel multi-turn red-teaming setting, revealing a potential new attack surface."
    },
    {
        "title": "Elucidating the Design Choice of Probability Paths in Flow Matching for Forecasting",
        "link_suffix": "/forum?id=6Ire5JaobL",
        "link": "https://openreview.net/forum?id=6Ire5JaobL",
        "pdf_link": "https://openreview.net/pdf?id=6Ire5JaobL",
        "keywords": "generative modeling, flow matching, dynamical systems, forecasting",
        "abstract": "Flow matching has recently emerged as a powerful paradigm for generative modeling, and has been extended to probabilistic time series forecasting in latent spaces. However, the impact of the specific choice of probability path model on forecasting performance remains under-explored. In this work, we demonstrate that forecasting spatio-temporal data with flow matching is highly sensitive to the selection of the probability path model. Motivated by this insight, we propose a novel probability path model designed to improve forecasting performance. Our empirical results across various dynamical system benchmarks show that our model achieves faster convergence during training and improved predictive performance compared to existing probability path models. Importantly, our approach is efficient during inference, requiring only a few sampling steps. This makes our proposed model practical for real-world applications and opens new avenues for probabilistic forecasting."
    },
    {
        "title": "Transformer Learns Optimal Variable Selection in Group-Sparse Classification",
        "link_suffix": "/forum?id=fuoM5YDBX4",
        "link": "https://openreview.net/forum?id=fuoM5YDBX4",
        "pdf_link": "https://openreview.net/pdf?id=fuoM5YDBX4",
        "keywords": "transformer, self-attention, variable selection, group-sparse classification",
        "abstract": "Transformers have demonstrated remarkable success across various applications. However, the success of transformers have not been understood in theory. In this work, we give a case study of how transformers can be trained to learn a classic statistical model with \"group sparsity\", where the input variables form multiple groups, and the label only depends on the variables from one of the groups. We theoretically demonstrate that, a one-layer transformer trained by gradient descent can correctly leverage the attention mechanism to select variables, disregarding irrelevant ones and focusing on those beneficial for classification. We also demonstrate that a well-pretrained one-layer transformer can be adapted to new downstream tasks to achieve good prediction accuracy with a limited number of samples. Our study sheds light on how transformers effectively learn structured data."
    },
    {
        "title": "A Polynomial Time Graph Isomorphism Algorithm via Self-Supervised Gradient Descent",
        "link_suffix": "/forum?id=tPsZDNvMqJ",
        "link": "https://openreview.net/forum?id=tPsZDNvMqJ",
        "pdf_link": "https://openreview.net/pdf?id=tPsZDNvMqJ",
        "keywords": "Graph Isomorphism, Optimization, Self-Supervised Learning, Graph Matching, Graph Theory",
        "abstract": "Graph isomorphism (GI) is a fundamental problem in graph theory. \nDespite recent advancements, determining whether two graphs are isomorphic remains computationally challenging. \nThis paper introduces the Polynomial Time Graph Isomorphism (PTGI) algorithm, an optimization-based approach leveraging self-supervision techniques to efficiently tackle the graph isomorphism problem. \nPTGI aims to escape local optima caused by graph symmetries and provides high accuracy in identifying isomorphic graphs in polynomial time. \nExperimental results demonstrate PTGI's effectiveness across various graph types, making it a valuable tool for practical applications."
    },
    {
        "title": "k-Odd One Clear (k-OOC), a novel GPU kernel that improves quantization accuracy and speed of GPTQ algorithm",
        "link_suffix": "/forum?id=OioOio3bmx",
        "link": "https://openreview.net/forum?id=OioOio3bmx",
        "pdf_link": "https://openreview.net/pdf?id=OioOio3bmx",
        "keywords": "quantization, LLM, GPTQ, BitNet",
        "abstract": "Large Language Model (LLM) demonstrated tremendously useful applications in nowadays fast-evolving AI driven technology. As the model sizes grow bigger, the demand for bigger and faster GPU is required. Another way to alleviate this issue is by improving the compression of the trained model through quantization so that lower VRAM devices can run. Quantization paradigms like GPTQ, PB-LLM, BiLLM (Hessian based with structural searching)  are successful quantize mechanisms. In this paper, we proposeOOC, a technique to pick an \"odd\" group to improve the quantization clarity so that the model can have better reasoning capability overall. In addition, we defineBit Family($A^{lim},A^{max}$) to classify compression rate of current and past quantizing techniques, thus providing a more objective way to rank different methodologies in literature. Thirdly, to avoid compromising the quantization speed due to thescanningprocess overhead, we developed a specialized fused GPU kernel (k-OOC) where it can be $9\\times$ faster than the original GPTQ implementation (single-flow mode) and $22\\times$ faster than the naive OOC implementation (double-flow mode) due to the incorporation of techniques calledRow-Flow-Selection ParallelandInput Batching. We measured perplexity of k-OOC (2 bits) with 14 major models like OPT, LLAMA, and Bloom (125M to 70B parameters) and popular datasets ( Wikitext2, C4, and PTB). We managed to improved the perplexity of small model by 8.9% and of big model by 4.1% compared to the baseline of GPTQ (2 bits)."
    },
    {
        "title": "ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment",
        "link_suffix": "/forum?id=4JBEpP6eRS",
        "link": "https://openreview.net/forum?id=4JBEpP6eRS",
        "pdf_link": "https://openreview.net/pdf?id=4JBEpP6eRS",
        "keywords": "data centric machine learning, autoformalization, large language models, reasoning",
        "abstract": "Selecting high-quality, aligned fine-tuning data is crucial for improving the downstream performance of language models (LMs). Automatic data selection in these scenarios is challenging and often inefficient due to previous approaches relying on neural embeddings or limited n-gram representations to identify aligned datasets. In addition, traditional data selection methods often focus on increasing the size of the training data, making them computationally expensive to use and data inefficient. In this work, we introduce ZIP-FIT, an embedding-free, data-efficient selection framework that leverages gzip compression to measure the alignment between training data and target domains. We show that ZIP-FIT significantly outperforms two leading baselines, DSIR and D4, in selecting high-quality data for ProofNet, a formal mathematical dataset, and HumanEval, a benchmark for code generation tasks. Specifically, ZIP-FIT demonstrates a computational speed advantage, performing data selection up to  65.8% faster than DSIR and achieving its lowest cross-entropy loss up to 85.1% faster. Our findings suggest that ZIP-FIT offers a scalable and adaptable approach for data selection, enabling more precise fine-tuning for code generation domains. By demonstrating that embedding-free data selection can outperform established methods like DSIR and D4, our research opens new avenues for optimizing model training, thereby enhancing the effectiveness and efficiency of machine learning workflows."
    },
    {
        "title": "Speculate, then Collaborate: Fusing Knowledge of Language Models during Decoding",
        "link_suffix": "/forum?id=2Y6xGE1K60",
        "link": "https://openreview.net/forum?id=2Y6xGE1K60",
        "pdf_link": "https://openreview.net/pdf?id=2Y6xGE1K60",
        "keywords": "Large language model; Knowledge fusion; Speculative decoding",
        "abstract": "Large Language Models (LLMs) often excel in specific domains but fall short in others due to the limitations of their training. Thus, enabling LLMs to solve problems collaboratively by integrating their complementary knowledge promises to improve their performance across domains. To realize this potential, we introduce a novel Collaborative Speculative Decoding (CoSD) algorithm that enables efficient LLM knowledge fusion at test time without requiring additional model training. CoSD employs a draft model to generate initial sequences and an easy-to-learn rule or decision tree to decide when to invoke an assistant model to improve these drafts. CoSD not only enhances knowledge fusion but also improves inference efficiency, is transferable across domains, and offers greater explainability. Experimental results demonstrate that CoSD improves accuracy by up to 10% across benchmarks compared to existing methods, providing a scalable and effective solution for LLM-based applications."
    },
    {
        "title": "PaLD: Detection of Text Partially Written by Large Language Models",
        "link_suffix": "/forum?id=rWjZWHYPcz",
        "link": "https://openreview.net/forum?id=rWjZWHYPcz",
        "pdf_link": "https://openreview.net/pdf?id=rWjZWHYPcz",
        "keywords": "LLM text detection, mixed-text detection, distribution shift",
        "abstract": "Advances in large language models (LLM) have produced text that appears increasingly human-like and difficult to detect with the human eye. In order to mitigate the impact of misusing LLM-generated texts, e.g., copyright infringement, fair student assessment, fraud, and other societally harmful LLM usage, a line of work on detecting human and LLM-written text has been explored. While recent work has focused on classifying entire text samples (e.g., paragraphs) as human or LLM-written, this paper investigates a more realistic setting of mixed-text, where the text's individual segments (e.g., sentences) could each be written by either a human or an LLM. A text encountered in practical usage cannot generally be assumed to be fully human or fully LLM-written; simply predicting whether it is human or LLM-written is insufficient as it does not provide the user with full context on its origins, such as the amount of LLM-written text, or locating the LLM-written parts. Therefore, we study two relevant problems in the mixed-text setting: (i) estimating the percentage of a text that was LLM-written, and (ii) determining which segments were LLM-written. To this end, we propose Partial-LLM Detector (PaLD), a black-box method that leverages the scores of text classifiers. Experimentally, we demonstrate the effectiveness of PaLD compared to baseline methods that build on existing LLM text detectors."
    },
    {
        "title": "How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models  via a Stochastic Integral Framework",
        "link_suffix": "/forum?id=6awxwQEI82",
        "link": "https://openreview.net/forum?id=6awxwQEI82",
        "pdf_link": "https://openreview.net/pdf?id=6awxwQEI82",
        "keywords": "Discrete diffusion models, Poisson process, stochastic integral, continuous-time Markov chain",
        "abstract": "Discrete diffusion models have gained increasing attention for their ability to model complex distributions with tractable sampling and inference. However, the error analysis for discrete diffusion models remains less well-understood. In this work, we propose a comprehensive framework for the error analysis of discrete diffusion models based on L\u00e9vy-type stochastic integrals. By generalizing the Poisson random measure to that with a time-independent and state-dependent intensity, we rigorously establish a stochastic integral formulation of discrete diffusion models and provide the corresponding change of measure theorems that are intriguingly analogous to It\u00f4 integrals and Girsanov's theorem for their continuous counterparts. Our framework unifies and strengthens the current theoretical results on discrete diffusion models and obtains the first error bound for the $\\tau$-leaping scheme in KL divergence. With error sources clearly identified, our analysis gives new insight into the mathematical properties of discrete diffusion models and offers guidance for the design of efficient and accurate algorithms for real-world discrete diffusion model applications."
    },
    {
        "title": "Balanced Ranking with Relative Centrality: A multi-core periphery perspective",
        "link_suffix": "/forum?id=21rSeWJHPF",
        "link": "https://openreview.net/forum?id=21rSeWJHPF",
        "pdf_link": "https://openreview.net/pdf?id=21rSeWJHPF",
        "keywords": "Ranking algorithms, community structure, clustering, balanced ranking, centrality measures",
        "abstract": "Ranking of vertices in a graph for different objectives is one of the most fundamental tasks in computer science. It is known that traditional ranking algorithms can generate unbalanced ranking when the graph has underlying communities, resulting in loss of information, polarised opinions, and reduced diversity (Celis, Straszak & Vishnoi [ICALP 2018]).In this paper, we focus onunsupervised rankingon graphs and observe that popular centrality measure based ranking algorithms such as PageRank may often generate unbalanced ranking here as well. We address this issue by coining a new approach, which we termrelative centrality. Our approach is based on an iterative graph-dependent local normalization of the centrality score, which promotes balancedness while maintaining the validity of the ranking.We further quantify reasons behind this unbalancedness of centrality measures on a novel structure that we propose is called multi-core-periphery with communities (MCPC). We also provide theoretical and extensive simulation support for our approach towards resolving the unbalancedness in MCPC.Finally, we consider graph embeddings of $11$ single-cell datasets. We observe that top-ranked as per existing centrality measures are better separable into the ground truth communities. However, due to the unbalanced ranking, the top nodes often do not contain points from some communities. Here, our relative-centrality-based approach generates a ranking that provides a similar improvement in clusterability while providing significantly higher balancedness."
    },
    {
        "title": "Can Reinforcement Learning Solve Asymmetric Combinatorial-Continuous Zero-Sum Games?",
        "link_suffix": "/forum?id=7YKV7zkNpX",
        "link": "https://openreview.net/forum?id=7YKV7zkNpX",
        "pdf_link": "https://openreview.net/pdf?id=7YKV7zkNpX",
        "keywords": "zero-sum game, combinatorial optimization, reinforcement learning",
        "abstract": "There have been extensive studies on learning in zero-sum games, focusing on the analysis of the existence and algorithmic convergence of Nash equilibrium (NE). Existing studies mainly focus on symmetric games where the strategy spaces of the players are of the same type and size. For the few studies that do consider asymmetric games, they are mostly restricted to matrix games. In this paper, we define and study a new practical class of asymmetric games called two-player Asymmetric Combinatorial-Continuous zEro-Sum (ACCES) games, featuring a combinatorial action space for one player and an infinite compact space for the other. Such ACCES games have broad implications in the real world, particularly in combinatorial optimization problems (COPs) where one player optimizes a solution in a combinatorial space, and the opponent plays against it in an infinite (continuous) compact space (e.g., a nature player deciding epistemic parameters of the environmental model). Our first key contribution is to prove the existence of NE for two-player ACCES games, using the idea of essentially finite game approximation. Building on the theoretical insights and double oracle (DO)-based solutions to complex zero-sum games, our second contribution is to design the novel algorithm, Combinatorial Continuous DO (CCDO), to solve ACCES games, and prove the convergence of the proposed algorithm. Considering the NP-hardness of most COPs and recent advancements in reinforcement learning (RL)-based solutions to COPs, our third contribution is to propose a practical algorithm to solve NE in the real world, CCDORL (based on CCDO) and provide the novel convergence analysis in the ACCES game. Experimental results across diverse instances of COPs demonstrate the empirical effectiveness of our algorithms."
    },
    {
        "title": "In-Context Learning for Games",
        "link_suffix": "/forum?id=STdyyjBZ7P",
        "link": "https://openreview.net/forum?id=STdyyjBZ7P",
        "pdf_link": "https://openreview.net/pdf?id=STdyyjBZ7P",
        "keywords": "in-context learning, extensive-form game",
        "abstract": "Most literature in algorithmic game theory focuses on equilibrium finding, particularly Nash Equilibrium (NE). However, computing NE typically involves repeated computations of best responses (e.g., policy space response oracle (PSRO)), which can be computationally intensive. Moreover, NE strategies may not be ideal in games with more than two players or when facing irrational opponents. Consequently, NE strategies often require further adaptions to effectively address various types of opponents, impeding practical deployments.  In contrast, In-Context Learning (ICL), i.e., learning from context examples, plays the core role in the generalizability of large language models (LLMs) to novel tasks without changing parameters. While ICL has been applied to decision-making tasks, e.g., algorithm distillation (AD), existing research primarily focuses on single-agent scenarios, and the ICL for games is largely unexplored.\nTo facilitate the game solving and the practical deployment, the research question investigated in this work is:Can we leverage ICL to learn a model to i) play asany playerof the game, ii) exploitany opponentto maximize the utility, and iii) be used to compute NE,without changing the parameters?In this work, we proposeIn-Context Exploiter(ICE) to address this question: i)ICEgenerates the diverse opponents with different capability levels for each player of the game to generate the training datasets, ii)ICEcombines the curriculum learning and the ICL for single-agent scenarios (e.g., AD), to train the single model for all players of games, and iii)ICEleverages the pre-trained single model to play as each player of the game against different opponents and integrate with the equilibrium finding framework, e.g., PSRO, to compute NE. Extensive experiments on Kuhn poker, Leduc poker, and Goofspiel demonstrate thatICEcan efficiently exploit different opponents as different players of the games and can be seamlessly integrated with PSRO to compute NE without changing the parameters."
    },
    {
        "title": "GlobalTomo: A global dataset for physics-ML seismic wavefield modeling and FWI",
        "link_suffix": "/forum?id=jUxzh1bi3i",
        "link": "https://openreview.net/forum?id=jUxzh1bi3i",
        "pdf_link": "https://openreview.net/pdf?id=jUxzh1bi3i",
        "keywords": "Seismic modeling, inverse problem, neural operator",
        "abstract": "Global seismic tomography, taking advantage of seismic waves from natural earthquakes, provides essential insights into the earth's internal dynamics. Advanced FWI techniques, whose aim is to meticulously interpret every detail in seismograms, confront formidable computational demands in forward modeling and adjoint simulations on a global scale. Recent advancements in ML offer a transformative potential for accelerating the computational efficiency of FWI and extending its applicability to larger scales. This work presents the first 3D global synthetic dataset tailored for seismic wavefield modeling and full-waveform tomography, referred to as the GlobalTomo dataset. This dataset is uniquely comprehensive, incorporating explicit wave physics and robust geophysical parameterization at realistic global scales, generated through state-of-the-art forward simulations optimized for 3D global wavefield calculations. Through extensive analysis and the establishment of ML baselines, we illustrate that ML approaches are particularly suitable for global FWI, overcoming its limitations with rapid forward modeling and flexible inversion strategies. This work represents a cross-disciplinary effort to enhance our understanding of the earth's interior through physics-ML modeling."
    },
    {
        "title": "From Training-Free to Adaptive: Empirical Insights into MLLMs' Understanding of Detection Information",
        "link_suffix": "/forum?id=369jumtah8",
        "link": "https://openreview.net/forum?id=369jumtah8",
        "pdf_link": "https://openreview.net/pdf?id=369jumtah8",
        "keywords": "Multimodal Large Language Models, Object Detection",
        "abstract": "Despite the impressive capabilities of Multimodal Large Language Models (MLLMs) in integrating text and image modalities, challenges remain in accurately interpreting detailed visual elements. Fortunately, vision detection models have shown superior performance in recognizing fine-grained image details, leading to their increased deployment by researchers to enhance the ability of MLLMs. Among the feasible strategies, infusing detection information in text format is easy to use and effective. However, most studies apply this method in a training-free manner. There is limited research on the effects of adaptive training, which has great potential for helping LLMs better comprehend the special input and discard irrelevant information. In this paper, we address the key research question: How does training influence MLLMs' understanding of infused textual detection information? We systematically conduct experiments with numerous representative models to explore the performance implications of training-free, retraining, and fine-tuning strategies when infusing textual detection information into MLLMs. Additionally, we investigate the impact of training on the original abilities of MLLMs, as well as the interchangeability of detection models. We find that fine-tuning the pre-trained MLLM to adapt to textual detection information yields better results compared to the training-free strategy and the retraining strategy, with the fine-tuned MLLM outperforms the training-free MLLM by 6.71% across 10 widely recognized benchmarks. Besides, we find that fine-tuning allows the MLLM to maintain performance improvements even after replacing the deployed detection models, which means that it enables the MLLM to better understand the specially formatted textual information. We release our codes to facilitate further exploration into the fusion strategies of vision detection models and improving the fine-grained multimodal capabilities of MLLMs."
    },
    {
        "title": "SiDyP: Simplex Diffusion with Dynamic Prior for Denoising Llama-Generated Labels",
        "link_suffix": "/forum?id=M9U49u9GA7",
        "link": "https://openreview.net/forum?id=M9U49u9GA7",
        "pdf_link": "https://openreview.net/pdf?id=M9U49u9GA7",
        "keywords": "Diffusion Model, Learning from Noisy Labels, Soft Labels",
        "abstract": "The traditional process of creating labeled datasets is not only labor-intensive but also expensive. Recent breakthroughs in open-source large language models (LLMs), such as Llama-3, have opened a new avenue in generating labeled datasets automatically for various natural language processing (NLP) tasks to provide an alternative to such expensive annotation process. However, the reliability of such auto-generated labels remains a significant concern due to inherent inaccuracies. When learning from such noisy labels, the model's generalization is likely to be harmed as it is prone to overfit those label noises. In this paper, we propose the \\textbf{Si}mplex Diffusion with a \\textbf{Dy}namic \\textbf{P}rior (\\textbf{SiDyP}) model to calibrate incorrect labels, thus enhancing classifier robustness to noisy labels. While diffusion models have largely been overshadowed by transformer architectures for NLP, our work shows that combining diffusion with transformers can further improve text-based tasks. Our framework leverages simplex diffusion model to iteratively correct noisy labels conditioned on training dynamic trajectories. The potential true label candidates, obtained by neighborhood label distribution in embedding space, progressively based on the feedback of the diffusion model. Our SiDyP model can increase the performance of the BERT classifier fine-tuned on both zero-shot and few-shot Llama-3 generated noisy label datasets by an average of 5.33% and 7.69% respectively. Our extensive experiments, which explore different LLMs, diverse noise types (real-world and synthetic), ablation studies, and multiple baselines, demonstrate the effectiveness of SiDyP across a range of NLP tasks. We will make code and data publicly (under a CC BY 4.0 license) available on GitHub upon publication of the work."
    },
    {
        "title": "Learning Robust Representations with Long-Term Information for Generalization in Visual Reinforcement Learning",
        "link_suffix": "/forum?id=PDtMrogheZ",
        "link": "https://openreview.net/forum?id=PDtMrogheZ",
        "pdf_link": "https://openreview.net/pdf?id=PDtMrogheZ",
        "keywords": "Visual Reinforcement Learning, Generalization, Representation Learning, Information Bottleneck, One-Step Rewards",
        "abstract": "Generalization in visual reinforcement learning (VRL) aims to learn agents that can adapt to test environments with unseen visual distractions. Despite advances in robust representations learning, many methods do not take into account the essential downstream task of sequential decision-making. This leads to representations that lack critical long-term information, impairing decision-making abilities in test environments. To tackle this problem, we propose a novel robust action-value representation learning (ROUSER) under the information bottleneck (IB) framework. ROUSER learns robust representations to capture long-term information from the decision-making objective (i.e., action values). Specifically, ROUSER uses IB to encode robust representations by maximizing their mutual information with action values for long-term information, while minimizing mutual information with state-action pairs to discard irrelevant features. As action values are unknown, ROUSER proposes to decompose robust representations of state-action pairs into one-step rewards and robust representations of subsequent pairs. Thus, it can use known rewards to compute the loss for robust representation learning. Moreover, we show that ROUSER accurately estimates action values using learned robust representations, making it applicable to various VRL algorithms. Experiments demonstrate that ROUSER outperforms several state-of-the-art methods in eleven out of twelve tasks, across both unseen background and color distractions."
    },
    {
        "title": "BlockFound: Customized blockchain foundation model for anomaly detection",
        "link_suffix": "/forum?id=LPXfOxe0zF",
        "link": "https://openreview.net/forum?id=LPXfOxe0zF",
        "pdf_link": "https://openreview.net/pdf?id=LPXfOxe0zF",
        "keywords": "Large language model, blockchain, anomaly detection",
        "abstract": "We propose BlockFound, a customized foundation model for anomaly blockchain transaction detection. \nUnlike existing methods that rely on rule-based systems or directly apply off-the-shelf large language models, BlockFound introduces a series of customized designs to model the unique data structure of blockchain transactions. \nFirst, a blockchain transaction is multi-modal, containing blockchain-specific tokens, texts, and numbers. \nWe design a modularized tokenizer to handle these multi-modal inputs, balancing the information across different modalities. \nSecond, we design a customized mask language learning mechanism for pretraining with RoPE embedding and FlashAttention for handling longer sequences.\nAfter training the foundation model, we further design a novel detection method for anomaly detection. \nExtensive evaluations on Ethereum and Solana transactions demonstrate BlockFound's exceptional capability in anomaly detection while maintaining a low false positive rate. \nRemarkably, BlockFound is the only method that successfully detects anomalous transactions on Solana with high accuracy, whereas all other approaches achieved very low or zero detection recall scores.\nThis work not only provides new foundation models for blockchain but also sets a new benchmark for applying LLMs in blockchain data."
    }
]
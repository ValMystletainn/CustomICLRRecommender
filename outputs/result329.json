[{"title": "Synergizing Motion and Appearance: Multi-Scale Compensatory Codebooks for Talking Head Video Generation", "link_suffix": "/forum?id=LDtNetvNQp", "link": "https://openreview.net/forum?id=LDtNetvNQp", "pdf_link": "https://openreview.net/pdf?id=LDtNetvNQp", "keywords": "talking head video generation, motion transfer, codebook compensation", "abstract": "Talking head video generation aims to generate a realistic talking head video that\npreserves the person\u2019s identity from a source image and the motion from a driving\nvideo. Despite the promising progress made in the field, it remains a challenging\nand critical problem to generate videos with accurate poses and fine-grained facial\ndetails simultaneously. Essentially, facial motion is often highly complex to model\nprecisely, and the one-shot source face image cannot provide sufficient appearance\nguidance during generation due to dynamic pose changes. To tackle the problem, we propose to jointly learn motion and appearance codebooks and perform\nmulti-scale codebook compensation to effectively refine both the facial motion\nconditions and appearance features for talking face image decoding. Specifically,\nthe designed multi-scale motion and appearance codebooks are learned simultaneously in a unified framework to store representative global facial motion flow\nand appearance patterns. Then, we present a novel multi-scale motion and appearance compensation module, which utilizes a transformer-based codebook retrieval\nstrategy to query complementary information from the two codebooks for joint\nmotion and appearance compensation. The entire process produces motion flows\nof greater flexibility and appearance features with fewer distortions across different scales, resulting in a high-quality talking head video generation framework.\nExtensive experiments on various benchmarks validate the effectiveness of our\napproach and demonstrate superior generation results from both qualitative and\nquantitative perspectives when compared to state-of-the-art competitors.", "title_embedding_index": 16400, "title_abs_embedding_index": 16425}, {"title": "AMSC: Adaptive Multi-Dimensional Structured Compression with Theoretical Guarantees", "link_suffix": "/forum?id=c5boBrSTKj", "link": "https://openreview.net/forum?id=c5boBrSTKj", "pdf_link": "https://openreview.net/pdf?id=c5boBrSTKj", "keywords": "Multi-dimensional structured compression, adaptive group lasso, selection consistency", "abstract": "Network pruning is a pivotal strategy for reducing complexity and accelerating inference. Most pruning methods focus on a single dimension (depth or width), leading to insufficient compression when multiple dimensions are redundant. Additionally, separating pruning from training disrupts established network correlations, causing performance degradation. In this paper, we propose a novel Adaptive Multi-dimensional Structured Compression (AMSC) method that simultaneously learns the minimal depth, the minimal width, and network parameters under the strategy that  prioritizes depth compression. Specifically, based on the regularization technique,  AMSC incorporates layer- and filter- specific information into the penalty in order to adaptively identify and  eliminate redundant depth and width in terms of the importance and size of each layer and filter. It  integrates compression and training processes together without pruning. Consequently, the proposed method enables adaptive structure reduction from the initial configuration to a structure necessary that minimizes  the generalization error. Rigorous theoretical evidence is provided in terms of  the consistency of AMSC in achieving minimal network depth and width. To the best of our knowledge, this is the first study that offers a theoretical  guarantees in structure selection. Extensive experiments on CIFAR-10/100 and ImageNet datasets demonstrate our  method not only achieves  state-of-the-art compression performance in terms of FLOPs and total parameters, but also preserves competitive classification accuracy. For example, AMSC enhances the accuracy of ResNet56 on CIFAR-10 from 92.86% to 93.35%, while simultaneously reducing calculations by 64.49% and parameters by 54.11%.", "title_embedding_index": 16401, "title_abs_embedding_index": 16426}, {"title": "Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge Perspectives", "link_suffix": "/forum?id=dp1BH2bK4Y", "link": "https://openreview.net/forum?id=dp1BH2bK4Y", "pdf_link": "https://openreview.net/pdf?id=dp1BH2bK4Y", "keywords": "LLM, Task, Capability, Knowledge, Skill, Chain-of-Thought", "abstract": "The Chain-of-Thought (CoT) paradigm has become a pivotal method for solving complex problems. However, its application to intricate, domain-specific tasks remains challenging, as large language models (LLMs) often struggle to accurately decompose these tasks and, even when decomposition is correct, fail to execute the subtasks effectively. This paper introduces the Re-TASK framework, a novel theoretical model that revisits LLM tasks from the perspectives of capability, skill, and knowledge, drawing on the principles of Bloom's Taxonomy and Knowledge Space Theory. While CoT offers a workflow perspective on tasks, the Re-TASK framework introduces a Chain-of-Learning view, illustrating how tasks and their corresponding subtasks depend on various capability items. Each capability item is further dissected into its constituent aspects of knowledge and skills. Our framework reveals that many CoT failures in domain-specific tasks stem from insufficient knowledge or inadequate skill adaptation. In response, we combine CoT with the Re-TASK framework and implement a carefully designed Re-TASK prompting strategy to improve task performance. Specifically, we identify core capability items linked to tasks and subtasks, then strengthen these capabilities through targeted knowledge injection and skill adaptation. We validate the Re-TASK framework on three datasets across the law, finance, and mathematics domains, achieving significant improvements over the baseline models. Notably, our approach yields a remarkable 44.42% improvement with the Yi-1.5-9B model and a 33.08% improvement with the Llama3-Chinese-8b on the legal dataset. These experimental results confirm the effectiveness of the Re-TASK framework, demonstrating substantial enhancements in both the performance and applicability of LLMs.", "title_embedding_index": 16402, "title_abs_embedding_index": 16427}, {"title": "Don't flatten, tokenize! Unlocking the key to SoftMoE's efficacy in deep RL", "link_suffix": "/forum?id=8oCrlOaYcc", "link": "https://openreview.net/forum?id=8oCrlOaYcc", "pdf_link": "https://openreview.net/pdf?id=8oCrlOaYcc", "keywords": "Reinforcement learning, Deep reinforcement learning, Mixture of experts", "abstract": "The use of deep neural networks in reinforcement learning (RL) often suffers from performance degradation as model size increases. While soft mixtures of experts (SoftMoEs) have recently shown promise in mitigating this issue for online RL, the reasons behind their effectiveness remain largely unknown. In this work we provide an in-depth analysis identifying the key factors driving this performance gain. We discover the surprising result that tokenizing the encoder output, rather than the use of multiple experts, is what is behind the efficacy of SoftMoEs. Indeed, we demonstrate that even with an appropriately scaled single expert, we are able to maintain the performance gains, largely thanks to tokenization.", "title_embedding_index": 16403, "title_abs_embedding_index": 16428}, {"title": "Self-predictive Mamba: Improving Multi-agent Reinforcement Learning with Self-predictive Encoding", "link_suffix": "/forum?id=7ZyFjPUeJp", "link": "https://openreview.net/forum?id=7ZyFjPUeJp", "pdf_link": "https://openreview.net/pdf?id=7ZyFjPUeJp", "keywords": "Sequence model, state space model, Mamba, multi-agent reinforcement learning, self-predictive representation learning", "abstract": "In multi-agent reinforcement learning (MARL), agents must collaborate to achieve team goals while only having access to limited local observations. This partial observability, coupled with the dynamic presence of other agents, renders the environment non-stationary for each agent, complicating the policy training. A critical challenge in this setting is the efficient utilization of historical information for decision-making. Building on the hypothesis that self-predictive features can improve policy learning, we introduce the self-predictive Mamba, a novel framework that integrates the Mamba model with self-predictive representation learning for decentralized policy optimization. Self-predictive Mamba leverages a unique policy architecture where the Mamba model is trained to predict future observations, aiding in more stable and informed decision-making. Substantial experiments demonstrate that self-predictive Mamba significantly outperforms the widely used recurrent neural network (RNN)-based MARL policies and surpasses those naively employing the Mamba model.", "title_embedding_index": 16404, "title_abs_embedding_index": 16429}, {"title": "Direct Distributional Optimization for Provable Alignment of Diffusion Models", "link_suffix": "/forum?id=Nvw2szDdmI", "link": "https://openreview.net/forum?id=Nvw2szDdmI", "pdf_link": "https://openreview.net/pdf?id=Nvw2szDdmI", "keywords": "Diffusion models, Optimization", "abstract": "We introduce a novel alignment method for diffusion models from distribution optimization perspectives while providing rigorous convergence guarantees.\nWe first formulate the problem as a generic regularized loss minimization over probability distributions and directly optimize the distribution using the Dual Averaging method.\nNext, we enable sampling from the learned distribution by approximating its score function via Doob's $h$-transform technique.\nThe proposed framework is supported by rigorous convergence guarantees and an end-to-end bound on the sampling error, which imply that when the original distribution's score is known accurately, the complexity of sampling from shifted distributions is independent of isoperimetric conditions.\nThis framework is broadly applicable to general distribution optimization problems, including alignment tasks in Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), and Kahneman-Tversky Optimization (KTO). We empirically validate its performance on synthetic and image datasets using the DPO objective.", "title_embedding_index": 16405, "title_abs_embedding_index": 16430}, {"title": "Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses", "link_suffix": "/forum?id=X9OfMNNepI", "link": "https://openreview.net/forum?id=X9OfMNNepI", "pdf_link": "https://openreview.net/pdf?id=X9OfMNNepI", "keywords": "scientific discovery", "abstract": "Scientific discovery contributes largely to the prosperity of human society, and recent progress shows that LLMs could potentially catalyst the process. However, it is still unclear whether LLMs can discover novel and valid hypotheses in chemistry. In this work, we investigate this main research question: whether LLMs can automatically discover novel and valid chemistry research hypotheses, given only a research question? With extensive discussions with chemistry experts, we adopt the assumption that a majority of chemistry hypotheses can be resulted from a research background question and several inspirations. With this key insight, we break the main question into three smaller fundamental questions. In brief, they are: (1) given a background question, whether LLMs can retrieve good inspirations; (2) with background and inspirations, whether LLMs can lead to hypothesis; and (3) whether LLMs can identify good hypotheses to rank them higher. To investigate these questions, we construct a benchmark consisting of 51 chemistry papers published in Nature or a similar level in 2024 (all papers are only available online since 2024). Every paper is divided by chemistry PhD students into three components: background, inspirations, and hypothesis. The goal is to rediscover the hypothesis given only the background and a large chemistry literature corpus consisting the ground truth inspiration papers, with LLMs trained with data up to 2023. We also develop an LLM-based multi-agent framework that leverages the assumption, consisting of three stages reflecting the more smaller questions. The proposed method can rediscover many hypotheses with very high similarity with the ground truth ones, covering the main innovations.", "title_embedding_index": 16406, "title_abs_embedding_index": 16431}, {"title": "Learning Unified Static-Dynamic Representation across Multiple Visuo-tactile Sensors", "link_suffix": "/forum?id=XToAemis1h", "link": "https://openreview.net/forum?id=XToAemis1h", "pdf_link": "https://openreview.net/pdf?id=XToAemis1h", "keywords": "Tactile Representation Learning, Visuo-tactile Sensors, Cross-sensor Transferring", "abstract": "Visuo-tactile sensors aim to emulate human tactile perception, enabling robots to precisely understand and manipulate objects. Over time, numerous meticulously designed visuo-tactile sensors have been integrated into robotic systems, aiding in completing various tasks. However, the distinct data characteristics of these low-standardized visuo-tactile sensors hinder the establishment of a powerful tactile perception system. We consider that the key to addressing this issue lies in learning unified multi-sensor representations, thereby integrating the sensors and promoting  tactile knowledge transfer between them. To achieve unified representation of this nature, we introduce TacQuad, an aligned multi-modal multi-sensor tactile dataset from four different visuo-tactile sensors, which enables the explicit integration of various sensors. Recognizing that humans perceive the physical environment by acquiring diverse tactile information such as texture and pressure changes, we further propose to learn unified multi-sensor representations from both static and dynamic perspectives. By integrating tactile images and videos, we present UltraTouch, a unified static-dynamic multi-sensor representation learning framework with a multi-level structure, aimed at both enhancing comprehensive perceptual abilities and enabling effective cross-sensor transfer. This multi-level architecture captures pixel-level details from tactile data via masked modeling and enhances perception and transferability by learning semantic-level sensor-agnostic features through multi-modal alignment and cross-sensor matching. We provide a comprehensive analysis of multi-sensor transferability, and validate our method on various offline datasets and in the real-world pouring task. Experimental results show that our method outperforms existing methods, exhibits outstanding static and dynamic perception capabilities across various sensors.", "title_embedding_index": 16407, "title_abs_embedding_index": 16432}, {"title": "Generating Model Parameters for Controlling: Parameter Diffusion for Controllable  Multi-Task Recommendation", "link_suffix": "/forum?id=9Zq8fRF4am", "link": "https://openreview.net/forum?id=9Zq8fRF4am", "pdf_link": "https://openreview.net/pdf?id=9Zq8fRF4am", "keywords": "recommender systems, generative model, multi-task learning", "abstract": "Commercial recommender systems face the challenge that task requirements from platforms or users often change dynamically (e.g., varying preferences for accuracy or diversity). Ideally, the model should be re-trained after resetting a new objective function, adapting to these changes in task requirements. However, in practice, the high computational costs associated with retraining make this process impractical for models already deployed to online environments. \nThis raises a new challenging problem: how to efficiently adapt the learning model to different task requirements by controlling model parameters after deployment, without the need for retraining.\nTo address this issue, we propose a novel controllable learning approach via Parameter Diffusion for controllable multi-task Recommendation (PaDiRec), which allows the customization and adaptation of recommendation model parameters to new task requirements without retraining. \nSpecifically, we first obtain the optimized model parameters through adapter tunning based on the feasible task requirements. Then, we utilize the diffusion model as a parameter generator, employing classifier-free guidance in conditional training to learn the distribution of optimized model parameters under various task requirements. Finally, the diffusion model is applied to effectively generate model parameters in a test-time adaptation manner given task requirements. As a model-agnostic approach, PaDiRec can leverage existing recommendation models as backbones to enhance their controllability. Extensive experiments on public datasets and a dataset from a commercial app, indicate that PaDiRec can effectively enhance controllability through efficient model parameter generation. The code is released athttps://anonymous.4open.science/r/PaDiRec-DD13e.", "title_embedding_index": 16408, "title_abs_embedding_index": 16433}, {"title": "Dynamic Influence Tracker: Estimating Sample Influence in SGD-Trained Models across Arbitrary Time Windows", "link_suffix": "/forum?id=g1kSMVqaXg", "link": "https://openreview.net/forum?id=g1kSMVqaXg", "pdf_link": "https://openreview.net/pdf?id=g1kSMVqaXg", "keywords": "Explainability; data influence", "abstract": "Understanding how training samples affect models improves model interpretability, optimization strategies, and anomaly detection. However, existing methods for estimating sample influence provide only static assessments, rely on restrictive assumptions, and require high computational costs. \n    We propose Dynamic Influence Tracker (DIT), a novel method to estimate time-varying sample influence in models trained with Stochastic Gradient Descent (SGD). DIT enables fine-grained analysis of sample influence within arbitrary time windows during training through a two-phase algorithm. The training phase efficiently captures and stores necessary information about the SGD trajectory, while the inference phase computes the influence of samples on the model within a specified time window. We provide a theoretical error bound for our estimator without assuming convexity, showing its reliability across various learning scenarios. Our experimental results reveal the evolution of sample influence throughout the training process, enhancing understanding of learning dynamics. We show DIT's effectiveness in improving model performance through anomalous sample detection and its potential for advancing curriculum learning.", "title_embedding_index": 16409, "title_abs_embedding_index": 16434}, {"title": "Optimal Flow Transport and its Entropic Regularization: a GPU-friendly Matrix Iterative Algorithm for Flow Balance Satisfaction", "link_suffix": "/forum?id=NtSlKEJ2DS", "link": "https://openreview.net/forum?id=NtSlKEJ2DS", "pdf_link": "https://openreview.net/pdf?id=NtSlKEJ2DS", "keywords": "Optimal Transport, Flow Balance Constraints, Sinkhorn Algorithm, Network Flow Theory", "abstract": "The Sinkhorn algorithm, based on Entropic Regularized Optimal Transport (OT), has garnered significant attention due to its computational efficiency enabled by GPU-friendly matrix-vector multiplications. However, vanilla OT primarily deals with computations between the source and target nodes in a bipartite graph, limiting its practical application in real-world transportation scenarios.\nIn this paper, we introduce the concept of Optimal Flow Transport (OFT) as an extension, where we consider a more general graph case and the marginal constraints in vanilla OT are replaced by flow balance constraints. \nTo obtain solutions, we incorporate entropic regularization into the OFT and introduce virtual flows for individual nodes to tackle the issue of potentially numerous isolated nodes lacking flow passages. Our proposition, the OFT-Sinkhorn algorithm, utilizes GPU-friendly matrix iterations to maintain flow balance constraints and minimize the objective function, and theoretical results for global convergence are also proposed in this paper.\nFurthermore, we enhance OFT by introducing capacity constraints on nodes and edges, transforming the OFT problem into a minimum-cost flow problem. We then present the Capacity-Constrained EOFT-Sinkhorn algorithm and compare it with the traditional Minimum cost flow (MCF) algorithm, showing that our algorithm is quite efficient for calculation. \nIn particular, our EOFT-Sinkhorn is evaluated on high-precision and integer-precision MCF problems with different scales from one hundred to five thousand size, exhibiting significant time efficiency and the ability to approximate optimal solutions. Source code will be made publicly available.", "title_embedding_index": 16410, "title_abs_embedding_index": 16435}, {"title": "Exploring The Forgetting in Adversarial Training: A Novel Method for Enhancing Robustness", "link_suffix": "/forum?id=fjPOt8QlqQ", "link": "https://openreview.net/forum?id=fjPOt8QlqQ", "pdf_link": "https://openreview.net/pdf?id=fjPOt8QlqQ", "keywords": "Adversarial training, Continual learning, Catastrophic forgetting", "abstract": "In recent years, there has been an explosion of research into developing robust deep neural networks against adversarial examples. As one of the most successful methods, Adversarial Training (AT)  has been widely studied before, but there is still a gap to achieve promising\nclean and robust accuracy for many practical tasks. In this paper, we consider the AT problem from a new perspective which connects it to catastrophic forgetting in continual learning (CL). Catastrophic forgetting is a phenomenon in which neural networks forget old knowledge upon learning a new task. Although AT and CL are two different problems, we show that they actually share several  key properties in their training processes. Specifically, we conduct an empirical study and find that this forgetting phenomenon indeed occurs in adversarial robust training across multiple datasets (SVHN, CIFAR-10, CIFAR-100, and TinyImageNet) and perturbation models ($\\ell_{\\infty}$ and $\\ell_{2}$). Based on this observation, we propose a novel method called Adaptive Multi-teachers Self-distillation (AMS), which leverages a carefully designed adaptive regularizer to mitigate the forgetting by aligning model outputs between new and old ``stages''. Moreover, our approach can be used  as a unified method to enhance multiple different AT algorithms. Our experiments demonstrate that our method can significantly enhance robust accuracy and meanwhile preserve high clean accuracy, under several popular adversarial attacks (e.g., PGD, CW, and Auto Attacks). As another benefit of our method, we discover that it can largely alleviate the robust overfitting issue of AT in our experiments.", "title_embedding_index": 16411, "title_abs_embedding_index": 16436}, {"title": "Do Influence Functions Work on Large Language Models?", "link_suffix": "/forum?id=hnsiuIcRT7", "link": "https://openreview.net/forum?id=hnsiuIcRT7", "pdf_link": "https://openreview.net/pdf?id=hnsiuIcRT7", "keywords": "Large language models, Influence function", "abstract": "Influence functions aim to quantify the impact of individual training data points on a model's predictions. While extensive research has been conducted on influence functions in traditional machine learning models, their application to large language models (LLMs) has been limited. In this work, we conduct a systematic study to address a key question: do influence functions work on LLMs? Specifically, we evaluate influence functions across multiple tasks and find that they consistently perform poorly in most settings. Our further investigation reveals that their poor performance can be attributed to: (1) inevitable approximation errors when estimating the iHVP component due to the scale of LLMs, (2) uncertain convergence during fine-tuning, and, more fundamentally, (3) the definition itself, as changes in model parameters do not necessarily correlate with changes in LLM behavior. Our study thus suggests the need for alternative approaches for identifying influential samples. To support future work, our code is made available athttps://github.com/anonymous.", "title_embedding_index": 16412, "title_abs_embedding_index": 16437}, {"title": "Estimating the conformal prediction threshold from noisy labels", "link_suffix": "/forum?id=PRKFRzOEq8", "link": "https://openreview.net/forum?id=PRKFRzOEq8", "pdf_link": "https://openreview.net/pdf?id=PRKFRzOEq8", "keywords": "conformal prediction, label noise", "abstract": "Conformal Prediction (CP) is a method to control prediction uncertainty by producing a small prediction set,   ensuring a predetermined probability that the true class lies within this set.   This is commonly done by defining a score, based on the model predictions, and setting a threshold on this score using a validation set. In this study, we address the problem of CP calibration when we only have access to a validation set with noisy labels. We show how we can estimate the noise-free conformal threshold based on the noisy labeled data.   Our solution is flexible and can accommodate various modeling assumptions regarding the label contamination process, without needing any information about the underlying data distribution or the internal mechanisms of the machine learning classifier.    We develop a coverage guarantee for uniform noise that is effective even in tasks with a large number of classes. We dub our approach Noise-Aware Conformal Prediction (NACP) and show on several natural and medical image classification datasets, including ImageNet, that it significantly outperforms current noisy label methods and achieves results comparable to those obtained with a clean validation set.", "title_embedding_index": 16413, "title_abs_embedding_index": 16438}, {"title": "Test-Time Training for Out-of-Distribution Industrial Anomaly Detection via Robust Distribution Alignment", "link_suffix": "/forum?id=btqz4vMrUE", "link": "https://openreview.net/forum?id=btqz4vMrUE", "pdf_link": "https://openreview.net/pdf?id=btqz4vMrUE", "keywords": "Anomaly Detection, Test Time Training; Out-of-Distribution", "abstract": "Detecting anomalous patterns is essential for quality control in industrial applications, with state-of-the-art methods relying on large defect-free datasets to model normal distributions. However, robustness under domain shift, such as changes in lighting or sensor drift, remains a critical challenge in real-world deployment. An existing work, Generalized Normality Learning (GNL), addresses domain shifts by enforcing feature consistency through training-time augmentation, but its reliance on prior knowledge of target distributions and access to training data at inference limits flexibility. To overcome these limitations, we propose a memory bank-based anomaly detection method that avoids retraining or access to training data during inference. We improve the robustness to distribution shifts via distribution alignment based test-time training. Our approach leverages a modified Sinkhorn distance to align distributions and handle outliers, offering a more resilient solution for industrial anomaly detection under realistic constraints. Extensive evaluations on out-of-distribution anomaly detection benchmarks demonstrate the effectiveness.", "title_embedding_index": 16414, "title_abs_embedding_index": 16439}, {"title": "Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception", "link_suffix": "/forum?id=gh563RwulS", "link": "https://openreview.net/forum?id=gh563RwulS", "pdf_link": "https://openreview.net/pdf?id=gh563RwulS", "keywords": "Text chunking, perplexity, margin sampling, large language models", "abstract": "Retrieval-Augmented Generation (RAG), while serving as a viable complement to large language models (LLMs), often overlooks the crucial aspect of text chunking within its pipeline, which impacts the quality of knowledge-intensive tasks. This paper introduces the concept of Meta-Chunking, which refers to a granularity between sentences and paragraphs, consisting of a collection of sentences within a paragraph that have deep linguistic logical connections. To implement Meta-Chunking, we designed two strategies based on LLMs: Margin Sampling Chunking and Perplexity Chunking. The former employs LLMs to perform binary classification on whether consecutive sentences need to be segmented, making decisions based on the probability difference obtained from margin sampling. The latter precisely identifies text chunk boundaries by analyzing the characteristics of perplexity distribution. Additionally, considering the inherent complexity of different texts, we propose a strategy that combines Meta-Chunking with dynamic merging to achieve a balance between fine-grained and coarse-grained text chunking. Experiments conducted on eleven datasets demonstrate that Meta-Chunking can more efficiently improve the performance of single-hop and multi-hop question answering based on RAG. For instance, on the 2WikiMultihopQA dataset, it outperforms similarity chunking by 1.32 while only consuming 45.8% of the time.", "title_embedding_index": 16415, "title_abs_embedding_index": 16440}, {"title": "SSNet: Skip and Split MLP Network for Long-Term  Series Forecasting", "link_suffix": "/forum?id=CgRkPuhTGm", "link": "https://openreview.net/forum?id=CgRkPuhTGm", "pdf_link": "https://openreview.net/pdf?id=CgRkPuhTGm", "keywords": "Time Series Forecasting, Deep Learning, MLP", "abstract": "Time series forecasting is critical across various domains, \nincluding energy, transportation, weather prediction, and healthcare. \nAlthough recent advances using CNNs, RNNs, and Transformer-based models have shown promise, \nthese approaches often suffer from architectural complexity and low computational efficiency. \nMLP-based networks offer better computational efficiency but struggle to effectively model periodic and temporal relationships, \nwhich are essential for accurate time series forecasting. \nTo address these challenges, we propose the Skip and Split MLP Network (SSNet), \nfeaturing innovative Skip-MLP and Split-MLP components that adeptly handle these relationships. \nSSNet requires fewer parameters than traditional MLP-based architectures, improving computational efficiency. \nEmpirical results on multiple real-world long-term forecasting datasets demonstrate that \nSSNet significantly outperforms state-of-the-art models, delivering better performance with fewer parameters. \nNotably, even a single Skip-MLP unit matches the performance of high-performing models like PatchTST.", "title_embedding_index": 16416, "title_abs_embedding_index": 16441}, {"title": "Writing in the Margins: Better Inference Patterns for Long-Context Retrieval", "link_suffix": "/forum?id=56mg1JFd3n", "link": "https://openreview.net/forum?id=56mg1JFd3n", "pdf_link": "https://openreview.net/pdf?id=56mg1JFd3n", "keywords": "chunked prefill, long context inference, interactive inference", "abstract": "In this paper, we introduce Writing in the Margins (WiM), a new inference pattern for Large Language Models designed to optimize the handling of long input sequences in retrieval-oriented tasks. This approach leverages the chunked prefill of the key-value cache to perform segment-wise inference, which enables efficient processing of extensive contexts along with the generation and classification of intermediate information (\"margins\") that guide the model towards specific tasks. This method increases computational overhead marginally while significantly enhancing the performance of off-the-shelf models without the need for fine-tuning. Specifically, we observe that WiM provides an average enhancement of 7.5% in accuracy for reasoning skills (HotpotQA, MultiHop-RAG) and a 30.0% increase in the F1-score for aggregation tasks (CWE). Additionally, we show how the proposed pattern fits into an interactive retrieval design that provides end-users with ongoing updates about the progress of context processing, and pinpoints the integration of relevant information into the final response. We release our implementation of WiM using Hugging Face Transformers library at <anonymised URL>.", "title_embedding_index": 16417, "title_abs_embedding_index": 16442}, {"title": "Mitigating Overestimation in Offline Reinforcement Learning with Anomaly Detection", "link_suffix": "/forum?id=QtSw71HJ6M", "link": "https://openreview.net/forum?id=QtSw71HJ6M", "pdf_link": "https://openreview.net/pdf?id=QtSw71HJ6M", "keywords": "Reinforcement Learning, Offline Reinforcement Learning, Anomaly Detection", "abstract": "Reinforcement Learning (RL) encounters substantial challenges in real-world applications, due to the time-consuming, costly, and risky nature of interacting with the environment. Offline Reinforcement Learning addresses this limitation by training models on static datasets, allowing an optimal policy to be learned from pre-collected data without requiring additional interactions with the environment. However, in this setting, when the agent queries actions outside the training data distribution, it can lead to overestimation of Q-values for OOD (Out-of-distribution) actions, ultimately hindering policy optimization. Previous works attempted to address this problem using explicit constraints such as penalty terms or support restriction. But these methods often fail to identify OOD actions or result in overly conservative Q-value estimates. We propose a novel solution that adjusts weights during training by using an anomaly detection model to identify the distribution of the offline dataset and employing anomaly scores to guide the offline RL process. Our method(RLAD) not only effectively mitigates the overestimation of OOD actions but also achieves near state-of-the-art performance on continuous D4RL tasks. Additionally, this framework is highly flexible, allowing for integration with various off-policy or offline RL algorithms and Anomaly Detection models to enhance performance.", "title_embedding_index": 16418, "title_abs_embedding_index": 16443}, {"title": "From Decoupling to Adaptive Transformation: a Wider Optimization Space for PTQ", "link_suffix": "/forum?id=JElN0LJMKB", "link": "https://openreview.net/forum?id=JElN0LJMKB", "pdf_link": "https://openreview.net/pdf?id=JElN0LJMKB", "keywords": "Post-Training Quantization", "abstract": "Post-training low-bit quantization (PTQ) is useful to accelerate DNNs due to its high efficiency. Currently, finetuning through self-distillation feature reconstruction is one of the most effective PTQ techniques. However, when bitwidth goes to be extremely low, we find that current parameter update settings in PTQ feature reconstruction are sub-optimal. Considering all possible parameters and the ignored fact that integer weight can be obtained early before actual inference, we thoroughly explore 1) the setting of weight\u2019s quantization step into six cases by decoupling; 2) ignored learnable params in PTQ like BN and bias. Based on these explorations, we find there exist a wider optimization space and a better optimum. Considering these, we propose an Adaptive Quantization Transformation(AdaQTransform) for PTQ reconstruction, which provides adaptive per-channel transformation on the quant output feature, making them better fit FP32 counterpart and achieve lower PTQ feature reconstruction error. During inference, the AdaQTransform parameters can be merged without incurring additional inference costs. Based on AdaQTransform, for the first time, we build a general quantization setting paradigm subsuming current PTQs, QATs and other potential approaches. Experiments demonstrate that AdaQTransform expands the optimization space for PTQ and helps current PTQs find a better optimum over CNNs, ViTs, LLMs and low-level vision networks (image super-resolution). Specifically, AdaQTransform improves the current best PTQ by 5.7% on W2A2-MobileNet-v2. The code will be released.", "title_embedding_index": 16419, "title_abs_embedding_index": 16444}, {"title": "SaLoRA: Safety-Alignment Preserved Low-Rank Adaptation", "link_suffix": "/forum?id=GOoVzE9nSj", "link": "https://openreview.net/forum?id=GOoVzE9nSj", "pdf_link": "https://openreview.net/pdf?id=GOoVzE9nSj", "keywords": "PEFT Training, Safety Alignment Preserving", "abstract": "As advancements in large language models (LLMs) continue and the demand for personalized models increases, parameter-efficient fine-tuning (PEFT) methods (e.g., LoRA) will become essential due to their efficiency in reducing computation costs.\nHowever, recent studies have raised alarming concerns that LoRA fine-tuning could potentially compromise the safety alignment in LLMs, posing significant risks for the model owner.\nIn this paper, we first investigate the underlying mechanism by analyzing the changes in safety alignment related features before and after fine-tuning.\nThen, we propose a fixed safety module calculated by safety data and a task-specific initialization for trainable parameters in low-rank adaptations, termed Safety-alignment preserved Low-Rank Adaptation (SaLoRA). \nUnlike previous LoRA methods and their variants, SaLoRA enables targeted modifications to LLMs without disrupting their original alignments. \nOur experiments show that SaLoRA outperforms various adapters-based approaches across various evaluation metrics in different fine-tuning tasks.", "title_embedding_index": 16420, "title_abs_embedding_index": 16445}, {"title": "3D-GP-LMVIC: Learning-based Multi-View Image Compression with 3D Gaussian Geometric Priors", "link_suffix": "/forum?id=wtMh0PxDPO", "link": "https://openreview.net/forum?id=wtMh0PxDPO", "pdf_link": "https://openreview.net/pdf?id=wtMh0PxDPO", "keywords": "Multi-View Image Compression; 3D Gaussian Splatting; Deep Learning", "abstract": "Multi-view image compression is vital for 3D-related applications. Existing methods often rely on 2D projection similarities between views to estimate disparity, performing well with small disparities, such as in stereo images, but struggling with more complex disparities from wide-baseline setups, common in virtual reality and autonomous driving systems. To overcome this limitation, we propose a novel approach: learning-based multi-view image compression with 3D Gaussian geometric priors (3D-GP-LMVIC). Our method leverages 3D Gaussian Splatting to derive geometric priors of the 3D scene, enabling more accurate disparity estimation between views within the compression model. Additionally, we introduce a depth map compression model to reduce redundancy in geometric information across views. A multi-view sequence ordering method is also proposed to enhance correlations between adjacent views. Experimental results demonstrate that 3D-GP-LMVIC surpasses both traditional and learning-based methods in performance, while maintaining fast encoding and decoding speed. The code is available athttps://anonymous.4open.science/r/3D-GP-LMVIC-8FFA.", "title_embedding_index": 16421, "title_abs_embedding_index": 16446}, {"title": "OCS+: Improving PTQ with Outlier Translation", "link_suffix": "/forum?id=12gMsxpu4G", "link": "https://openreview.net/forum?id=12gMsxpu4G", "pdf_link": "https://openreview.net/pdf?id=12gMsxpu4G", "keywords": "Post Training Quantization", "abstract": "Post-training quantization (PTQ) is an effective technique for accelerating DNN model inference, where activations typically follow a bell-shaped distribution. Since commodity hardware employs a linear quantization grid and limited quantization levels, prior PTQs optimize a clipping threshold to minimize overall quantization error, which excludes outliers from the bell-shaped data. However, outliers are non-trivial for low-bit and lightweight models. Thus OCS (Zhao et al.,2019) proposed to save outliers by halving and duplicating.  However, in activation quantization, the original OCS sacrifices the precision of the regular inliers, leading to severe accuracy degradation. To address this, we propose OCS+ to save outlier activation without affecting the regular inliers. Consequently, OCS+ theoretically achieves one-bit higher representation under the predefined bitwidth hardware. OCS+ is based on offline mathematical transformation, thus it does not require additional training or re-design works on hardware. Experiments over CNNs and ViTs demonstrate OCS+ significantly outperforms OCS and help improve current PTQ SOTAs, e.g., OCS+ improves the current SOTAs by 12.73% in Acc@1 for W2A2 MobileNet-v2. The code will be released.", "title_embedding_index": 16422, "title_abs_embedding_index": 16447}, {"title": "SeMv-3D: Towards Semantic and Mutil-view Consistency simultaneously for General Text-to-3D Generation with Triplane Priors", "link_suffix": "/forum?id=r5yolhcrHe", "link": "https://openreview.net/forum?id=r5yolhcrHe", "pdf_link": "https://openreview.net/pdf?id=r5yolhcrHe", "keywords": "General Text-to-3D Generation, Generative Models, Diffusion Models", "abstract": "Recent advancements in generic 3D content generation from text prompts have been remarkable by fine-tuning text-to-image diffusion (T2I) models or employing these T2I models as priors to learn a general text-to-3D model. While fine-tuning-based methods ensure great alignment between text and generated views, i.e., semantic consistency, their ability to achieve multi-view consistency is hampered by the absence of 3D constraints, even in limited view. In contrast, prior-based methods focus on regressing 3D shapes with any view that maintains uniformity and coherence across views, i.e., multi-view consistency, but such approaches inevitably compromise visual-textual alignment, leading to a loss of semantic details in the generated objects. To achieve semantic and multi-view consistency simultaneously, we propose SeMv-3D, a novel framework for general text-to-3d generation.  Specifically, we propose a Triplane Prior Learner (TPL) that learns triplane priors with 3D spatial features to maintain consistency among different views at the 3D level, e.g., geometry and texture. Moreover, we design a Semantic-aligned View Synthesizer (SVS) that preserves the alignment between 3D spatial features and textual semantics in latent space. In SVS, we devise a simple yet effective batch sampling and rendering strategy that can generate arbitrary views in a single feed-forward inference. Extensive experiments present our SeMv-3D's superiority over state-of-the-art performances with semantic and multi-view consistency in any view. Our code and more visual results are available athttps://anonymous.4open.science/r/SeMv-3D-6425.", "title_embedding_index": 16423, "title_abs_embedding_index": 16448}, {"title": "Compositional Scene Modeling with An Object-Centric Diffusion Transformer", "link_suffix": "/forum?id=KgN0mo6pLo", "link": "https://openreview.net/forum?id=KgN0mo6pLo", "pdf_link": "https://openreview.net/pdf?id=KgN0mo6pLo", "keywords": "Object-Centric Representation Learning, Unsupervised Learning, Compositional Scene Modeling, Diffusion Models, Generative Models", "abstract": "Early object-centric learning methods adopt simple pixel mixture decoders to reconstruct images, which struggle with complex synthetic and real-world datasets. Recent object-centric learning methods focus on decoding object representations with complex decoders, such as autoregressive Transformers or diffusion models, to solve this problem. However, these methods feed all object representations together into the decoder to directly reconstruct the latent representation of the entire scene. Contrary to human intuition, this approach ultimately leads to weak interpretability. This paper combines the recent powerful diffusion model and composition module to propose a novel object-centric learning method called Compositional Scene Modeling with an Object-centric Diffusion Transformer (CODiT). By adopting a proposed compositional denoising decoder that can generate the mask of single objects and construct images compositionally, CODiT has stronger interpretability while still retaining the ability to handle complex scenes. We also illustrate the Classifier-Free Guidance explanation of CODiT. Experiments show how compositional structure helps control the generation process, allowing the model to generate images via single object representations and edit objects. In addition, we present CODiT performs strongly in various tasks including segmentation and reconstruction on both complex synthetic datasets and real-world datasets compared with similar methods.", "title_embedding_index": 16424, "title_abs_embedding_index": 16449}]
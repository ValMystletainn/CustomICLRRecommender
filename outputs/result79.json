[{"title": "LASeR: Learning to Adaptively Select Reward Models with Multi-Armed Bandits", "link_suffix": "/forum?id=fDcn3S8oAt", "link": "https://openreview.net/forum?id=fDcn3S8oAt", "pdf_link": "https://openreview.net/pdf?id=fDcn3S8oAt", "keywords": "Multi-armed bandits, Preference optimization, Reward model, Iterative LLM training", "abstract": "Reward Models (RMs) play a crucial role in aligning large language models (LLMs) with human preferences, enhancing their performance by ranking outputs during inference or iterative training. However,  the degree to which an RM generalizes to new tasks is often not knowna priori. For instance, some RMs may excel at scoring creative writing, while others specialize in evaluating math reasoning. Therefore, using only one fixed RM while training LLMs can besuboptimal. Moreover, optimizing LLMs with multiple RMs simultaneously can be prohibitively computationally-intensive and challenging due to conflicting signals from different RMs, potentially degrading performance. To address these challenges, we introduce LASeR (Learning toAdaptivelySelectRewards), which iteratively trains LLMs using multiple RMs, selecting and utilizing the most well-suited RM for each instance to rank outputs and generate preference data, framed as a multi-armed bandit problem. Our empirical results on commonsense and math reasoning tasks demonstrate that LASeR can boost iterative LLM optimization by optimizing for multiple RMs, improving the absolute average accuracy of Llama-3-8B over three datasets by 2.67%  over training with ensemble RM scores while also showing superior training efficiency (e.g., a 2x speedup). Moreover, on WildChat, a benchmark of instruction-following prompts in open-form generation, we find that using Llama-3-8B LASeR leads to a 71.45% AlpacaEval win rate over sequentially optimizing multiple RMs. Extending to long-context generation tasks, we find that on Llama-3-8B, LASeR achieves an average improvement of 2.64 F1 points on single-document QA tasks and 2.42 F1 points on multi-document QA over random RM selection when used with best-of-n sampling. Our analysis shows that LASeR is robust to noisy rewards and generalizes to multiple settings.  Finally, we demonstrate that LASeR's RM selection changes depending on the underlying task or instance and we verify the presence of conflicting preferences from multiple RMs that can be mitigated using LASeR.", "title_embedding_index": 3900, "title_abs_embedding_index": 3925}, {"title": "SIEVE: General Purpose Data Filtering System Matching GPT-4o Accuracy at 1% the Cost", "link_suffix": "/forum?id=iNvxHAN1J8", "link": "https://openreview.net/forum?id=iNvxHAN1J8", "pdf_link": "https://openreview.net/pdf?id=iNvxHAN1J8", "keywords": "Data Filtering, Large Language Models", "abstract": "Creating specialized large language models requires vast amounts of clean, special purpose data for training and fine-tuning. With only a handful of existing large-scale, domain-specific datasets, creation of new datasets is required in most applications. This requires the development of new application-specific filtering of web-scale data. Filtering with a high-performance, general-purpose LLM such as GPT-4o can be highly effective, but this is extremely expensive at web-scale. This paper proposes SIEVE, a lightweight alternative that matches GPT-4o accuracy at a fraction of the cost. SIEVE can perform up to 500 filtering operations for the cost of one GPT-4o filtering call. The key to SIEVE is a seamless integration of GPT-4o and lightweight T5 models, using active learning to fine-tune T5 in the background with a small number of calls to GPT-4o. Once trained, it performs as well as GPT-4o at a tiny fraction of the cost. We experimentally validate SIEVE on the OpenWebText dataset, using five highly customized filter tasks targeting high quality and domain-specific content. Our results demonstrate the effectiveness and efficiency of our method in curating large, high-quality datasets for language model training at a substantially lower cost (1%) than existing techniques. To further validate SIEVE, experiments show that SIEVE and GPT-4o achieve similar accuracy, with human evaluators preferring SIEVE's filtering results to those of GPT-4o.", "title_embedding_index": 3901, "title_abs_embedding_index": 3926}, {"title": "Hierarchical Autoregressive Transformers for Tokenizer-Free Language Modelling", "link_suffix": "/forum?id=tU074jg2vS", "link": "https://openreview.net/forum?id=tU074jg2vS", "pdf_link": "https://openreview.net/pdf?id=tU074jg2vS", "keywords": "transformer, autoregressive, generative, language modelling, tokenizer-free, byte-level, hierarchical", "abstract": "Tokenization is a fundamental step in natural language processing, breaking text into units that computational models can process. While learned subword tokenizers have become the de-facto standard, they present challenges such as large vocabularies, limited adaptability to new domains or languages, and sensitivity to spelling errors and variations. To overcome these limitations, we propose a hierarchical architecture for autoregressive language modelling that combines character-level and word-level processing. Our approach employs a lightweight character-level encoder to convert character sequences into word embeddings, which are then processed by a word-level backbone model and decoded back into characters via a compact character-level decoder. This method retains the sequence compression benefits of word-level tokenization without relying on a rigid, predefined vocabulary. We demonstrate, at scales up to 7 billion parameters, that hierarchical transformers match the downstream task performance of subword-tokenizer-based models while exhibiting significantly greater robustness to input perturbations. Additionally, during continued pretraining on an out-of-domain language, our model trains almost twice as fast, achieves superior performance on the target language, and retains more of its previously learned knowledge. Hierarchical transformers pave the way for NLP systems that are more robust, flexible, and generalizable across languages and domains.", "title_embedding_index": 3902, "title_abs_embedding_index": 3927}, {"title": "Stochastic Monkeys at Play: Random Augmentations Cheaply Break LLM Safety Alignment", "link_suffix": "/forum?id=gJk4N7zscD", "link": "https://openreview.net/forum?id=gJk4N7zscD", "pdf_link": "https://openreview.net/pdf?id=gJk4N7zscD", "keywords": "LLM, Large Language Model, safety alignment, augmentations, randomness, jailbreaks, attacks", "abstract": "Safety alignment of Large Language Models (LLMs) has recently become a critical objective of model developers. In response, a growing body of work has been investigating how safety alignment can be bypassed through various jailbreaking methods, such as adversarial attacks. However, these jailbreak methods can be rather costly or involve a non-trivial amount of creativity and effort, introducing the assumption that malicious users are high-resource or sophisticated. In this paper, we study how simple random augmentations to the input prompt affect safety alignment effectiveness in state-of-the-art LLMs, such as Llama 3 and Qwen 2. We perform an in-depth evaluation of 17 different models and investigate the intersection of safety under random augmentations with multiple dimensions: augmentation type, model size, quantization, fine-tuning-based defenses, and decoding strategies (e.g., sampling temperature). We show that low-resource and unsophisticated attackers, i.e. $\\textit{stochastic monkeys}$, can significantly improve their chances of bypassing alignment with just 25 random augmentations per prompt.", "title_embedding_index": 3903, "title_abs_embedding_index": 3928}, {"title": "Accelerated training through iterative gradient propagation along the residual path", "link_suffix": "/forum?id=JDm7oIcx4Y", "link": "https://openreview.net/forum?id=JDm7oIcx4Y", "pdf_link": "https://openreview.net/pdf?id=JDm7oIcx4Y", "keywords": "optimization, efficient training", "abstract": "Despite being the cornerstone of deep learning, backpropagation is criticized for its inherent sequentiality, which can limit the scalability of very deep models.\nSuch models faced convergence issues due to vanishing gradient, later resolved using residual connections. Variants of these are now widely used in modern architectures.\nHowever, the computational cost of backpropagation remains a major burden, accounting for most of the training time.\nTaking advantage of residual-like architectural designs, we introduce Highway backpropagation, a parallelizable iterative algorithm that approximates backpropagation, by alternatively i) accumulating the gradient estimates along the residual path, and ii) backpropagating them through every layer in parallel. This algorithm is naturally derived from a decomposition of the gradient as the sum of gradients flowing through all paths, and is adaptable to a diverse set of common architectures, ranging from ResNets and Transformers to recurrent neural networks.\nThrough an extensive empirical study on a large selection of tasks and models, we evaluate Highway-BP and show that major speedups can be achieved with minimal performance degradation.", "title_embedding_index": 3904, "title_abs_embedding_index": 3929}, {"title": "BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval", "link_suffix": "/forum?id=ykuc5q381b", "link": "https://openreview.net/forum?id=ykuc5q381b", "pdf_link": "https://openreview.net/pdf?id=ykuc5q381b", "keywords": "Retrieval benchmark, Reasoning", "abstract": "Existing retrieval benchmarks primarily consist of information-seeking queries (e.g., aggregated questions from search engines) where keyword or semantic-based retrieval is usually sufficient. However, many complex real-world queries require in-depth reasoning to identify relevant documents that go beyond surface form matching. For example, finding documentation for a coding question requires understanding the logic and syntax of the functions involved. To better benchmark retrieval on such challenging queries, we introduce BRIGHT, the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. Our dataset consists of 1,398 real-world queries spanning diverse domains such as economics, psychology, mathematics, coding, and more. These queries are drawn from naturally occurring or carefully curated human data. Extensive evaluation reveals that even state-of-the-art retrieval models perform poorly on BRIGHT. The leading model on the MTEB leaderboard (Muennighoff et al., 2023), which achieves a score of 59.0 nDCG@10,1 produces a score of nDCG@10 of 18.0 on BRIGHT. We show that incorporating explicit reasoning about the query improves retrieval performance by up to 12.2 points. Moreover, incorporating retrieved documents from the top-performing retriever boosts question answering performance by over 6.6 points. We believe that BRIGHT paves the way for future research on retrieval systems in more realistic and challenging settings.", "title_embedding_index": 3905, "title_abs_embedding_index": 3930}, {"title": "Discovering Data Structures: Nearest Neighbor Search and Beyond", "link_suffix": "/forum?id=Y2z31hfEeq", "link": "https://openreview.net/forum?id=Y2z31hfEeq", "pdf_link": "https://openreview.net/pdf?id=Y2z31hfEeq", "keywords": "algorithm discovery, data structures, neural algorithms", "abstract": "We propose a general framework for end-to-end learning of data structures. Our framework adapts to the underlying data distribution and provides fine-grained control over query and space complexity. Crucially, the data structure is learned from scratch, and does not require careful initialization or seeding with candidate data structures/algorithms. We first  apply this framework to the problem of nearest neighbor search. In several settings, we are able to reverse-engineer the learned data structures and query algorithms. For 1D nearest neighbor search, the model discovers optimal distribution (in)dependent algorithms such as binary search and variants of interpolation search. In higher dimensions, the model learns solutions that resemble k-d trees in some regimes, while in others, they have elements of locality-sensitive hashing. The model can also learn useful representations of high-dimensional data and exploit them to design effective data structures. We also adapt our framework to the problem of estimating frequencies over a data stream, and believe it could also be a powerful discovery tool for new problems.", "title_embedding_index": 3906, "title_abs_embedding_index": 3931}, {"title": "Reinforcement Learning for Control of Non-Markovian Cellular Population Dynamics", "link_suffix": "/forum?id=dsHpulHpOK", "link": "https://openreview.net/forum?id=dsHpulHpOK", "pdf_link": "https://openreview.net/pdf?id=dsHpulHpOK", "keywords": "optimal drug dosing, fractional differential equations, reinforcement learning, control theory", "abstract": "Many organisms and cell types, from bacteria to cancer cells, exhibit a remarkable ability to adapt to fluctuating environments. Additionally, cells can leverage memory of past environments to better survive previously-encountered stressors. From a control perspective, this adaptability poses significant challenges in driving cell populations toward extinction, and is thus an open question with great clinical significance. In this work, we focus on drug dosing in cell populations exhibiting phenotypic plasticity. For specific dynamical models switching between resistant and susceptible states, exact solutions are known. However, when the underlying system parameters are unknown, and for complex memory-based systems, obtaining the optimal solution is currently intractable. To address this challenge, we apply reinforcement learning (RL) to identify informed dosing strategies to control cell populations evolving under novel non-Markovian dynamics. We find that model-free deep RL is able to recover exact solutions and control cell populations even in the presence of long-range temporal dynamics.  To further test our approach in more realistic settings, we demonstrate performant RL-based control strategies in environments with dynamic memory strength.", "title_embedding_index": 3907, "title_abs_embedding_index": 3932}, {"title": "Interpretable and Efficient Counterfactual Generation for Real-Time User Interaction", "link_suffix": "/forum?id=9TpgFnRJ1y", "link": "https://openreview.net/forum?id=9TpgFnRJ1y", "pdf_link": "https://openreview.net/pdf?id=9TpgFnRJ1y", "keywords": "Explainable AI, Generative AI, Human-Machine interaction", "abstract": "Among the various forms of post-hoc explanations for black-box models, counterfactuals stand out for their intuitiveness and effectiveness. However, longstanding challenges in counterfactual explanations involve the efficiency of the search process, the likelihood of generated instances, their interpretability, and in some cases, the validity of the explanations themselves. In this work we introduce a generative framework designed to address all of these issues. Notably, this is the first framework capable of generating interpretable counterfactual images in real-time, making it suitable for human-in-the-loop classification and decision-making. Our method leverages a disentangled regularized autoencoder to achieve two complementary goals: generating high-quality instances and promoting label disentanglement to provide full control over the decision boundary. This allows the model to sidestep expensive gradient-based optimizations by directly generating counterfactuals based on the adversarial distribution. A user study conducted on a challenging human-machine classification task demonstrates the effectiveness of the approach in improving human performance, highlighting the critical role of counterfactual explanations in achieving this advantage.", "title_embedding_index": 3908, "title_abs_embedding_index": 3933}, {"title": "Gradient-based Optimization of Dataset Mixtures", "link_suffix": "/forum?id=VdURgvImVn", "link": "https://openreview.net/forum?id=VdURgvImVn", "pdf_link": "https://openreview.net/pdf?id=VdURgvImVn", "keywords": "dataset selection, data valuation, foundation models", "abstract": "Modern state-of-the-art machine learning models are often trained using a combination of heterogeneous data sources. However, the utility of different data sources as support for learning some target tasks is often not equivalent, motivating the need for automated methods of optimizing the relative contribution of each data source to the model. In this work, we propose a dataset optimization strategy that slices a normal model training step into a series of data source-specific updates and splices them back together in an optimal manner with respect to the loss on some target task dataset. We demonstrate the effectiveness of our algorithm across different scenarios and domains, including classification problems for vision models and for next-token prediction tasks in the language domain.", "title_embedding_index": 3909, "title_abs_embedding_index": 3934}, {"title": "Automating High-Quality Concept Banks: Leveraging LLMs and Multimodal Evaluation Metrics", "link_suffix": "/forum?id=KLUDshUx2V", "link": "https://openreview.net/forum?id=KLUDshUx2V", "pdf_link": "https://openreview.net/pdf?id=KLUDshUx2V", "keywords": "concept generation, multimodal models, CLIP, concept-bottleneck models, interpretability", "abstract": "Interpretablility in recent deep learning models has become an epicenter of research particularly in sensitive domains such as healthcare, and finance. Concept bottleneck models have emerged as a promising approach for achieving transparency and interpretability by leveraging a set of human-understandable concepts as an intermediate representation before the prediction layer. However, manual concept annotation is discouraged due to the time and effort involved. Our work explores the potential of large language models (LLMs) for generating high-quality concept banks and proposes a multimodal evaluation metric to assess the quality of generated concepts. We investigate three key research questions: the ability of LLMs to generate concept banks comparable to existing knowledge bases like ConceptNet, the sufficiency of unimodal text-based semantic similarity for evaluating concept-class label associations, and the effectiveness of multimodal information in quantifying concept generation quality compared to unimodal concept-label semantic similarity. Our findings reveal that multimodal models outperform unimodal approaches in capturing concept-class label similarity. Furthermore, our generated concepts for the CIFAR-10 and CIFAR-100 datasets surpass those obtained from ConceptNet and the baseline comparison,\ndemonstrating the standalone capability of LLMs in generating high-quality concepts. Being able to automatically generate and evaluate high-quality concepts will enable researchers to quickly adapt and iterate to a newer dataset with little to no effort before they can feed that into concept bottleneck models.", "title_embedding_index": 3910, "title_abs_embedding_index": 3935}, {"title": "The Geometry of Concepts: Sparse Autoencoder Feature Structure", "link_suffix": "/forum?id=WxqWuG431g", "link": "https://openreview.net/forum?id=WxqWuG431g", "pdf_link": "https://openreview.net/pdf?id=WxqWuG431g", "keywords": "Mechanistic Interpretability, Sparse Autoencoder, Language Model Features, Clustering, Multi-scale", "abstract": "Sparse autoencoders have recently produced dictionaries of high-dimensional vectors corresponding to the universe of concepts represented by large language models. We find that this concept universe has interesting structure at three levels: 1) The \"atomic\" small-scale structure contains \"crystals\" whose faces are parallelograms or trapezoids, generalizing well-known examples such as (man:woman::king:queen). We find that the quality of such parallelograms and associated function vectors improves greatly when projecting out global distractor directions such as word length, which is efficiently done with linear discriminant analysis. 2) The \"brain\" intermediate-scale structure has significant spatial modularity; for example, math and code features form a \"lobe\" akin to functional lobes seen in neural fMRI images. We quantify the spatial locality of these lobes with multiple metrics and find that clusters of co-occurring features, at coarse enough scale, also cluster together spatially far more than one would expect if feature geometry were random. 3) The \"galaxy\" scale large-scale structure of the feature point cloud is not isotropic, but instead has a power law of eigenvalues with steepest slope in middle layers. We also quantify how the clustering entropy depends on the layer.", "title_embedding_index": 3911, "title_abs_embedding_index": 3936}, {"title": "Pathologies of Out-of-Distribution Detection", "link_suffix": "/forum?id=hlijRgXTDK", "link": "https://openreview.net/forum?id=hlijRgXTDK", "pdf_link": "https://openreview.net/pdf?id=hlijRgXTDK", "keywords": "Out-of-distribution detection, robustness", "abstract": "There is a proliferation of out-of-distribution (OOD) detection methods in deep learning which aim to detect distribution shifts and improve model safety. These methods often rely on supervised learning to train models with in-distribution data and then use the models\u2019 predictive uncertainty or features to identify OOD points. In this paper, we critically re-examine this popular family of OOD detection procedures, revealing deep-seated pathologies. In contrast to prior work, we argue that these procedures are fundamentally answering the wrong question for OOD detection, with no easy fix. Uncertainty-based methods incorrectly conflate high uncertainty with being OOD, and feature-based methods incorrectly conflate far feature-space distance with being OOD. Moreover, there is no reason\nto expect a classifier trained only on in-distribution classes to be able to identify OOD points; for example, we should not necessarily expect a cat-dog classifier to be uncertain about the label of an airplane, which may share features with a cat that help distinguish cats from dogs, despite generally appearing nothing alike. We show how these pathologies manifest as irreducible errors in OOD detection and identify common settings where these methods are ineffective. Additionally, interventions to improve OOD detection such as feature-logit hybrid methods, scaling of model and data size, Bayesian (epistemic) uncertainty representation, and outlier exposure also fail to address the fundamental misspecification.", "title_embedding_index": 3912, "title_abs_embedding_index": 3937}, {"title": "Conditional Information Bottleneck Approach for Out-of-Distribution Sequential Recommendation", "link_suffix": "/forum?id=h9dnHqrkfa", "link": "https://openreview.net/forum?id=h9dnHqrkfa", "pdf_link": "https://openreview.net/pdf?id=h9dnHqrkfa", "keywords": "Sequential Recommendation, Out of Distribution, Robust, Conditional Information Bottleneck", "abstract": "Sequential recommendation (SR) aims to suggest items users are most likely to engage with next based on their past interactions. However, in practice, SR systems often face the out-of-distribution (OOD) problem due to dynamic environmental factors (e.g., seasonal changes), leading to significant performance degradation in the testing phase. \nSome methods incorporate distributionally robust optimization (DRO) into SR to alleviate OOD, but the sparsity of SR data challenges this. Other approaches use random data augmentations to explore the OOD, potentially distorting important information, as user behavior is personalized rather than random. Additionally, they often overlook users' varying sensitivity to distribution shifts during the exploration, which is crucial for capturing the evolution of user preferences in OOD contexts.\nIn this work, inspired by information bottleneck theory (IB), we propose the Conditional Distribution Information Bottleneck (CDIB), a novel objective that creates diverse OOD distributions while preserving minimal sufficient information regarding the origin distribution conditioned on the user. Building on this, we introduce a framework with a learnable, personalized data augmentation method using a mask-then-generate paradigm to craft diverse and reliable OOD distributions optimized with CDIB. Experiments on four real-world datasets show our model consistently outperforms baselines. The code is available athttps://anonymous.4open.science/r/CDIB-51C8.", "title_embedding_index": 3913, "title_abs_embedding_index": 3938}, {"title": "CogniPair - Dynamic LLM Matching Algorithm in Chaotic Environments Mimicking Human Cognitive Processes for Relationship Pairing", "link_suffix": "/forum?id=Xz5J6Hj9cH", "link": "https://openreview.net/forum?id=Xz5J6Hj9cH", "pdf_link": "https://openreview.net/pdf?id=Xz5J6Hj9cH", "keywords": "Large Language Models, Dating Algorithms, Human-like Reasoning, Context-aware Analysis, Simulating Characters, Machine Psychology", "abstract": "Dating applications in the digital era have transformed how people connect, yet they often fall short in simulating the comprehensive character and fostering truly compatible relationships due to their reliance on quantitative data. This paper proposes a novel framework to simulate human characters by leveraging Large Language Models (LLMs) to enhance matchmaking by understanding the nuanced fabric of human personality and social connections. Traditional algorithms often lack the depth needed for personalized matchmaking, whereas LLMs offer sophisticated linguistic and cognitive capabilities to simulate a person and complicated personal decisions. Our framework introduces a multi-agent system comprising the Persona, Preference, and Dating Memory modules, allowing for dynamic and nuanced user interactions. This approach addresses the limitations of conventional LLM frameworks by capturing detailed personal attributes, updating preferences, and learning from past interactions. Our system enhances the relevance and effectiveness of match recommendations, focusing on emotional compatibility and shared values, providing a more personalized and responsive user experience in the dating domain.", "title_embedding_index": 3914, "title_abs_embedding_index": 3939}, {"title": "Outcome-based Semifactual Explanation For Reinforcement Learning", "link_suffix": "/forum?id=qhfZL46nPV", "link": "https://openreview.net/forum?id=qhfZL46nPV", "pdf_link": "https://openreview.net/pdf?id=qhfZL46nPV", "keywords": "Explainable Reinforcement Learning, Interpretability, Deep Reinforcement Learning, Policy Explanation", "abstract": "Counterfactual explanations in reinforcement learning (RL) aim to answer what-if questions by showing sparse and minimal changes to states, which results in the probability mass moving from one action to another. Although these explanations are effective in classification tasks that look for the presence of concepts, RL brings new challenges that current counterfactual methods for RL still need to solve. These challenges include defining similarity in RL, out-of-distribution states, and lack of discriminative power. Given a state of interest called the query state, we solve these problems by asking how long the agent can execute the query state action without incurring a negative outcome regarding the expected return. We coin this outcome-based semifactual (OSF) explanation and find the OSF state by simulating trajectories from the query state. The last state in a subtrajectory where we can take the same action as in the query state without incurring a negative outcome is the OSF state. This state is discriminative, plausible, and similar to the query state. It abstracts away unimportant action switching with little explanatory value and shows the boundary between positive and negative outcomes. Qualitatively, we show that our method explains when it is necessary to switch actions. As a result, it is easier to understand the agent's behavior. Quantitatively, we demonstrate that our method can increase policy performance and, at the same time, reduce how often the agent switches its action across six environments. The code and trained models are available athttps://anonymous.4open.science/r/osf-explanation-for-rl-E312/.", "title_embedding_index": 3915, "title_abs_embedding_index": 3940}, {"title": "Locally Connected Echo State Networks for Time Series Forecasting", "link_suffix": "/forum?id=KeRwLLwZaw", "link": "https://openreview.net/forum?id=KeRwLLwZaw", "pdf_link": "https://openreview.net/pdf?id=KeRwLLwZaw", "keywords": "Time Series Analysis, Time Series Forecasting, Recurrent Networks, Regression, Echo State Networks", "abstract": "Echo State Networks (ESNs) are a class of recurrent neural networks in which only a small readout regression layer is trained, while the weights of the recurrent network, termed the reservoir, are randomly assigned and remain fixed.\nOur work introduces the Locally Connected ESN (LCESN), a novel ESN variant with a locally connected reservoir, forced memory, and a weight adaptation strategy.\nLCESN significantly reduces the asymptotic time and space complexities compared to the conventional ESN, enabling substantially larger networks.\nLCESN also improves the memory properties of ESNs without affecting network stability.\nWe evaluate LCESN's performance on the NARMA10 benchmark task and compare it to state-of-the-art models on nine real-world datasets.\nDespite the simplicity of our model and its one-shot training approach, LCESN achieves competitive results, even surpassing several state-of-the-art models.\nLCESN introduces a fresh approach to real-world time series forecasting and demonstrates that large, well-tuned random networks can rival complex gradient-trained models.\nAdditionally, we provide a GPU-based implementation of LCESN as an open-source library.", "title_embedding_index": 3916, "title_abs_embedding_index": 3941}, {"title": "Feature-Based Analysis of Theory of Mind Representations in Neural Network Models", "link_suffix": "/forum?id=cUeYEwc237", "link": "https://openreview.net/forum?id=cUeYEwc237", "pdf_link": "https://openreview.net/pdf?id=cUeYEwc237", "keywords": "theory of mind, computational modeling, social cognition", "abstract": "Theory of Mind (ToM) presents a significant generalization challenge in computational modeling. This paper explores how neural networks with varying architectures and training regimes learn and represent ToM-related features. We introduce a novel method for quantifying feature representation within neural networks and apply it to a set of theoretically-grounded features designed to differentiate between hypothesized ToM strategies. We examine the relationship between feature representation and task accuracy across different model architectures and training datasets. This work provides insights into the mechanisms underlying ToM capabilities in neural networks and offers a framework for future research in computational ToM.", "title_embedding_index": 3917, "title_abs_embedding_index": 3942}, {"title": "STARJOB: DATASET FOR LLM-DRIVEN JOB SHOP SCHEDULING", "link_suffix": "/forum?id=z4Ho599uOL", "link": "https://openreview.net/forum?id=z4Ho599uOL", "pdf_link": "https://openreview.net/pdf?id=z4Ho599uOL", "keywords": "JSSP, Large Language Models, supervised dataset, Starjob, artificial intelligence, sampling method, LLM", "abstract": "The Job Shop Scheduling Problem (JSSP) presents a significant challenge in opti-\nmizing production processes. This problem requires efficient allocation of jobs to\na limited number of machines while minimizing total processing time (makespan).\nAlthough recent advancements in artificial intelligence have produced promising\nsolutions, such as reinforcement learning and graph neural networks, this paper\ninvestigates the potential of Large Language Models (LLMs) for addressing JSSP.\nWe introduce the first supervised 120k dataset called Starjob specifically designed\nto train LLMs for JSSP and we subsequently fintune the LLaMA 8B model on\nthis dataset using Lora. We compare the average makespan gap of our end-to-\nend LLM-based scheduling method with that of the most widely used priority\ndispatching rules (PDRs) and neural methods such as L2D. Surprisingly, our find-\nings indicate that LLM-based scheduling not only surpasses traditional PDRs but\nalso achieves on average 11.28% on DMU and 3.29% gap improvement on the\nTailard benchmarks compared to the state-of-the-art L2D method.", "title_embedding_index": 3918, "title_abs_embedding_index": 3943}, {"title": "Parameter Efficient Graph Encoding for Large Language Models", "link_suffix": "/forum?id=RbcXV63ZJk", "link": "https://openreview.net/forum?id=RbcXV63ZJk", "pdf_link": "https://openreview.net/pdf?id=RbcXV63ZJk", "keywords": "large language models, structured data, graph data, graph neural networks, gnns, llms, graphtoken", "abstract": "How can we best encode structured data into sequential form for use in large language models (LLMs)? In this work, we introduce a parameter-efficient method to explicitly represent structured data for LLMs. Our method, GraphToken, learns an encoding function to extend prompts with explicit structured information. The encoding function in GraphToken uses graph neural networks to effectively transfer the relational inductive biases in the structured data to a LLM. Unlike other work which focuses on limited domains (e.g., knowledge graph representation), our work is the first effort focused on the general encoding of structured data to be used for various reasoning tasks. We show that explicitly representing the graph structure allows significant improvements to graph reasoning tasks. Specifically, we see across the board improvements - up to 73% points - on a wide variety of node, edge and, graph-level tasks on benchmarks for graph reasoning (GraphQA) and molecular property prediction (ChemLLMBench).", "title_embedding_index": 3919, "title_abs_embedding_index": 3944}, {"title": "Scaling Laws for Adversarial Attacks on Language Model Activations and Tokens", "link_suffix": "/forum?id=YzxMu1asQi", "link": "https://openreview.net/forum?id=YzxMu1asQi", "pdf_link": "https://openreview.net/pdf?id=YzxMu1asQi", "keywords": "adversarial attacks, language models, scaling laws, activation steering", "abstract": "We explore a class of adversarial attacks targeting the activations of language models to derive upper-bound scaling laws on their attack susceptibility. By manipulating a relatively small subset of model activations, $a$, we demonstrate the ability to control the exact prediction of a significant number (in some cases up to 1000) of subsequent tokens $t$. We empirically verify a scaling law where the maximum number of target tokens predicted, $t_\\mathrm{max}$, depends linearly on the number of tokens $a$ whose activations the attacker controls as $t_\\mathrm{max} = \\kappa a$. We find that the number of bits the attacker controls on the input to exert a single bit of control on the output (a property we call \\textit{attack resistance $\\chi$}) is remarkably stable between $\\approx 16$ and $\\approx 25$ over orders of magnitude of model sizes and between model families. Compared to attacks directly on input tokens, attacks on activations are predictably much stronger, however, we identify a surprising regularity where one bit of input steered either via activations or via tokens is able to exert a surprisingly similar amount of control over the model predictions. This gives support for the hypothesis that adversarial attacks are a consequence of dimensionality mismatch between the input and output spaces. A practical implication of the ease of attacking language model activations instead of tokens is for multi-modal and selected retrieval models. By using language models as a controllable test-bed to study adversarial attacks, we explored input-output dimension regimes that are inaccessible in computer vision and greatly extended the empirical support for the dimensionality theory of adversarial attacks.", "title_embedding_index": 3920, "title_abs_embedding_index": 3945}, {"title": "Evaluating the Instruction-following Abilities of Language Models using Knowledge Tasks", "link_suffix": "/forum?id=qit4pa6PpY", "link": "https://openreview.net/forum?id=qit4pa6PpY", "pdf_link": "https://openreview.net/pdf?id=qit4pa6PpY", "keywords": "Large Language Models, Instruction Following, Evaluation Benchmark", "abstract": "In this work, we focus our attention on developing a benchmark for instruction-following where it is easy to verify both task performance as well as instruction-following capabilities. We adapt existing knowledge benchmarks and augment them with instructions that are a) conditional on correctly answering the knowledge task or b) use the space of candidate options in multiple-choice knowledge-answering tasks. This allows us to study model characteristics, such as their change in performance on the knowledge tasks in the presence of answer-modifying instructions and distractor instructions. In contrast to existing benchmarks for instruction following, we not only measure instruction-following capabilities but also use LLM-free methods to study task performance. We study a series of openly available large language models of varying parameter sizes (1B-405B) and closed source models namely GPT-4o-mini, GPT-4o. We find that even large-scale instruction-tuned LLMs fail to follow simple instructions in zero-shot settings. We release our dataset, the benchmark, code, and results for future work.", "title_embedding_index": 3921, "title_abs_embedding_index": 3946}, {"title": "Offline Reinforcement Learning With Combinatorial Action Spaces", "link_suffix": "/forum?id=epbXCD1Ifk", "link": "https://openreview.net/forum?id=epbXCD1Ifk", "pdf_link": "https://openreview.net/pdf?id=epbXCD1Ifk", "keywords": "reinforcement learning, offline reinforcement learning, combinatorial action space", "abstract": "Reinforcement learning problems often involve large action spaces arising from the simultaneous execution of multiple sub-actions, resulting in combinatorial action spaces. Learning in combinatorial action spaces is difficult due to the exponential growth in action space size with the number of sub-actions and the dependencies among these sub-actions. In offline settings, this challenge is compounded by limited and suboptimal data. Current methods for offline learning in combinatorial spaces simplify the problem by assuming sub-action independence. We propose Branch Value Estimation (BVE), which effectively captures sub-action dependencies and scales to large combinatorial spaces by learning to evaluate only a small subset of actions at each timestep. Our experiments show that BVE outperforms state-of-the-art methods across a range of action space sizes.", "title_embedding_index": 3922, "title_abs_embedding_index": 3947}, {"title": "KidSpeak: A General Multi-Purpose LLM for Kids' Speech Recognition and Screening", "link_suffix": "/forum?id=in8qEyM4Xp", "link": "https://openreview.net/forum?id=in8qEyM4Xp", "pdf_link": "https://openreview.net/pdf?id=in8qEyM4Xp", "keywords": "Speech Language Modeling, Children's Speech, Speech Pathology Diagnosis, Speech Transcription, Children's Speech Dataset Creation", "abstract": "With the rapid advancement of conversational and diffusion-based AI, there is a growing adoption of AI in educational services, ranging from grading and assessment tools to personalized learning systems that provide targeted support for students. However, this adaptability has yet to fully extend to the domain of children's speech, where existing models often fail due to their reliance on datasets designed for clear, articulate adult speech. Children, particularly those in early developmental stages or with speech and language pathologies, present unique challenges that current AI models and datasets are ill-equipped to handle. To address this, we introduce KidSpeak, a multi-task speech-enhanced Foundation Model capable of both generative and discriminative tasks specifically tailored to children's speech patterns. Our framework employs a two-stage training process that incorporates phonetic knowledge into the speech encoder, achieving an average accuracy of 87% across four separate tasks. Furthermore, recognizing the limitations of scalable human annotation and existing speech alignment tools, we propose the Flexible and Automatic Speech Aligner (FASA) and leverage the method to construct high quality datasets for training and evaluation. This novel alignment tool significantly improves the quality of aligned children's speech from noisy data, enhancing data quality by 13.6\u00d7 compared to human annotations, as demonstrated on the CHILDES dataset. To the best of our knowledge, KidSpeak and FASA represent the first comprehensive solution designed for speech and language therapy in children, offering both a multi-purpose speech LLM and a robust alignment tool.", "title_embedding_index": 3923, "title_abs_embedding_index": 3948}, {"title": "BEEM: Boosting Performance of Early Exit DNNs using Multi-Exit Classifiers as Experts", "link_suffix": "/forum?id=EzrZX9bd4G", "link": "https://openreview.net/forum?id=EzrZX9bd4G", "pdf_link": "https://openreview.net/pdf?id=EzrZX9bd4G", "keywords": "Early Exits; Expert-based exiting", "abstract": "Early Exit (EE) techniques have emerged as a means to reduce inference latency in Deep Neural Networks (DNNs). The latency improvement and accuracy in these techniques crucially depend on the criteria used to make exit decisions. We propose a new decision criterion BEEM where exit classifiers are treated as experts and aggregate their confidence scores. The confidence scores are aggregated only if neighbouring experts are consistent in prediction as the samples pass through them, thus capturing their ensemble effect. A sample exits when the aggregated confidence value exceeds a threshold. The threshold is set using the error rates of the intermediate exits aiming to surpass the performance of conventional DNN inference. Experimental results on the COCO dataset for Image captioning and GLUE datasets for various language tasks demonstrate that our method enhances the performance of state-of-the-art EE methods, achieving improvements in speed-up by a factor $1.5\\times$ to $2.1\\times$. When compared to the final layer, its accuracy is comparable in harder Image Captioning and improves in the easier language tasks. The source code is available at \\url{https://anonymous.4open.science/r/BEEM1-639C/README.md}", "title_embedding_index": 3924, "title_abs_embedding_index": 3949}]
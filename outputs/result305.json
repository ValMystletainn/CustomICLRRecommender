[{"title": "dMel: Speech Tokenization Made Simple", "link_suffix": "/forum?id=BomQa84efw", "link": "https://openreview.net/forum?id=BomQa84efw", "pdf_link": "https://openreview.net/pdf?id=BomQa84efw", "keywords": "speech, tokenization, synthesis", "abstract": "Large language models have revolutionized natural language processing by leveraging self-supervised pretraining on vast textual data.\n  Inspired by this success, researchers have investigated complicated speech tokenization methods to discretize continuous speech signals so that language modeling techniques can be applied to speech data.\n  However, existing approaches either model semantic (content) tokens, potentially losing acoustic information, or model acoustic tokens, risking the loss of semantic (content) information. \n  Having multiple token types also complicates the architecture and requires additional pretraining.\n  Here we show that discretizing mel-filterbank channels into discrete intensity bins produces a simple representation (dMel), that performs better than other existing speech tokenization methods.\n  Using an LM-style transformer architecture for speech-text modeling, we comprehensively evaluate different speech tokenization methods on speech recognition (ASR) and speech synthesis (TTS).\n  Our results demonstrate the effectiveness of dMel in achieving high performance on both tasks within a unified framework, paving the way for efficient and effective joint modeling of speech and text. The code is available at anonymous_url, while generation samples are in the supplementary materials.", "title_embedding_index": 15200, "title_abs_embedding_index": 15225}, {"title": "Predicting from Strings: Language Model Embeddings for Bayesian Optimization", "link_suffix": "/forum?id=L5nW2DxI5h", "link": "https://openreview.net/forum?id=L5nW2DxI5h", "pdf_link": "https://openreview.net/pdf?id=L5nW2DxI5h", "keywords": "language, model, embedding, bayesian, optimization, in, context, regression, gaussian, process, meta, learning", "abstract": "Bayesian Optimization is ubiquitous in the field of experimental design and blackbox optimization for improving search efficiency, but has been traditionally restricted to regression models which are only applicable to fixed search spaces and tabular input features. We proposeEmbed-then-Regress, a paradigm for applying in-context regression over string inputs, through the use of string embedding capabilities of pretrained language models. By expressing all inputs as strings, we able to perform general-purpose regression for Bayesian Optimization over different search domains such as traditional and combinatorial optimization, obtaining comparable results to state-of-the-art Gaussian Process-based algorithms.", "title_embedding_index": 15201, "title_abs_embedding_index": 15226}, {"title": "Almost Sure Convergence of Average Reward Temporal Difference Learning", "link_suffix": "/forum?id=mBJF0p9yRR", "link": "https://openreview.net/forum?id=mBJF0p9yRR", "pdf_link": "https://openreview.net/pdf?id=mBJF0p9yRR", "keywords": "reinforcement learning, temporal difference learning, average reward", "abstract": "Tabular average reward Temporal Difference (TD) learning is perhaps the simplest and the most fundamental policy evaluation algorithm in average reward reinforcement learning. After at least 25 years since its discovery, we are finally able to provide a long-awaited almost sure convergence analysis. Namely, we are the first to prove that, under very mild conditions, tabular average reward TD converges almost surely to a sample path dependent fixed point. Key to this success is a new general stochastic approximation result concerning nonexpansive mappings with Markovian and additive noise, built on recent advances in stochastic Krasnoselskii-Mann iterations.", "title_embedding_index": 15202, "title_abs_embedding_index": 15227}, {"title": "Concept-ROT: Poisoning Concepts in Large Language Models with Model Editing", "link_suffix": "/forum?id=RzUvkI3p1D", "link": "https://openreview.net/forum?id=RzUvkI3p1D", "pdf_link": "https://openreview.net/pdf?id=RzUvkI3p1D", "keywords": "Language Model, Trojan, Backdoor, Model Editing", "abstract": "Model editing methods modify specific behaviors of Large Language Models by altering a small, targeted set of network weights and require very little data and compute. These methods can be used for malicious applications such as inserting misinformation or simple trojans that result in adversary-specified behaviors when a trigger word is present. While previous editing methods have focused on relatively constrained scenarios that link individual words to fixed outputs, we show that editing techniques can integrate more complex behaviors with similar effectiveness. We develop Concept-ROT, a model editing-based method that efficiently inserts trojans which not only exhibit complex output behaviors, but also trigger on high-level concepts -- presenting an entirely new class of trojan attacks. Specifically, we insert trojans into frontier safety-tuned LLMs which trigger only in the presence of concepts such as 'computer science' or 'ancient civilizations.' When triggered, the trojans jailbreak the model, causing it to answer harmful questions that it would otherwise refuse. Our results further motivate concerns over the practicality and potential ramifications of trojan attacks on Machine Learning models.", "title_embedding_index": 15203, "title_abs_embedding_index": 15228}, {"title": "SAFREE: Training-Free and Adaptive Guard for Safe Text-to-Image And Video Generation", "link_suffix": "/forum?id=hgTFotBRKl", "link": "https://openreview.net/forum?id=hgTFotBRKl", "pdf_link": "https://openreview.net/pdf?id=hgTFotBRKl", "keywords": "Safe generation, Text-to-image generation, Text-to-video generation", "abstract": "Recent advances in diffusion models have significantly enhanced their ability to generate high-quality images and videos, but they have also increased the risk of producing unsafe content. Existing unlearning/editing-based methods for safe generation remove harmful concepts from the models but face several challenges: (1) They cannot instantly remove harmful or undesirable concepts (e.g., artist styles) without extra training. (2) Their safe generation abilities depend on collected training data. (3) They alter model weights, thus risking degrading quality unrelated to content unrelated to the toxic targeted concepts. To address these challenges, we propose SAFREE, a novel training-free approach for safe text-to-image and video generation, without altering the model's weights. Specifically, we detect a subspace corresponding to a set of toxic concepts in the text embedding space and steer prompt token embeddings away from this subspace, thereby filtering out harmful content while preserving intended semantics. To balance the trade-off between filtering toxicity and preserving safe concepts, SAFREE incorporates a novel self-validating filtering mechanism that dynamically adjusts denoising steps when applying filtered embeddings. Additionally, we incorporate adaptive re-attention mechanisms within the diffusion latent space to selectively reduce the influence of features related to toxic concepts at the pixel level. By integrating filtering across both textual embedding and visual latent spaces, SAFREE achieves coherent safety checking, ensuring the fidelity, quality, and safety of the generated outputs. Empirically, SAFREE demonstrates state-of-the-art performance for suppressing unsafe content in T2I generation (reducing 22% across 5 datasets) compared to other training-free methods and effectively filters targeted concepts, e.g., specific artist styles, while maintaining high-quality output. It also shows competitive results against training-based methods. We further extend our SAFREE to various T2I backbones and T2V tasks, showcasing its flexibility and generalization. As generative AI rapidly evolves, SAFREE provides a robust and adaptable safeguard for ensuring safe visual generation.", "title_embedding_index": 15204, "title_abs_embedding_index": 15229}, {"title": "Graph Concept Bottleneck Models", "link_suffix": "/forum?id=qPH7lAyQgV", "link": "https://openreview.net/forum?id=qPH7lAyQgV", "pdf_link": "https://openreview.net/pdf?id=qPH7lAyQgV", "keywords": "Concept Bottleneck Models, Interpretability, Graphs, Graph Neural Networks, Structure Learning", "abstract": "Concept Bottleneck Models (CBMs) provide explicit interpretations for deep neural networks through concepts and allow intervention with concepts to adjust final predictions. Existing CBMs assume concepts are conditionally independent given labels and isolated from each other, ignoring the hidden relationships among concepts. However, the set of concepts in CBMs often has an intrinsic structure where concepts are generally correlated: changing one concept will inherently impact its related concepts. To mitigate this limitation, we proposeGraph CBMs: a new variant of CBM that facilitates concept relationships by constructing latent concept graphs, which can be combined with CBMs to enhance model performance while retaining their interpretability.  Empirical results on real-world image classification tasks demonstrate Graph CBMs are (1) superior in image classification tasks while providing more concept structure information for interpretability; (2) able to utilize concept graphs for more effective interventions; and (3) robust across different training and architecture settings.", "title_embedding_index": 15205, "title_abs_embedding_index": 15230}, {"title": "Contextual Position Encoding: Learning to Count What\u2019s Important", "link_suffix": "/forum?id=sIGWTd1DcW", "link": "https://openreview.net/forum?id=sIGWTd1DcW", "pdf_link": "https://openreview.net/pdf?id=sIGWTd1DcW", "keywords": "Deep learning architectures, Large Language Model (LLM), position encoding", "abstract": "The attention mechanism is a critical component of Large Language Models (LLMs) that allows tokens in a sequence to interact with each other, but is order-invariant. Incorporating position encoding (PE) makes it possible to address by position, such as attending to the i-th token. However, current PE methods use token counts to derive position, and thus cannot generalize to higher levels of abstraction, such as attending to the i-th sentence. In this paper, we propose a new position encoding method, Contextual Position Encoding (CoPE), that allows positions to be conditioned on context by incrementing position only on certain tokens determined by the model. This allows more general position addressing such as attending to the i-th particular word, noun, or sentence. We show that CoPE can solve the selective copy, counting and Flip-Flop tasks where popular position embeddings fail, and improves perplexity on language modeling and coding tasks.", "title_embedding_index": 15206, "title_abs_embedding_index": 15231}, {"title": "FAACL: Federated Adaptive Asymmetric Clustered Learning", "link_suffix": "/forum?id=gNrNlhhCN1", "link": "https://openreview.net/forum?id=gNrNlhhCN1", "pdf_link": "https://openreview.net/pdf?id=gNrNlhhCN1", "keywords": "Federated Learning, Distributed Learning, Clustering", "abstract": "Asymmetric clustering has remained an unexplored problem in Clustered Federated Learning (CFL), diverging from the traditional approach of forming independent, non-interacting clusters. Previous methodologies have been limited to either separating devices with different data quality into distinct clusters or merging all devices into a single cluster, both of which compromise either data utilization or model accuracy. We propose a new federated learning technique where some devices may contribute to the training of the models of other devices, but without enforcing reciprocity, leading to a form of asymmetric clustering.  This is beneficial in a variety of situations including scenarios where it is desirable for a device with high quality data to help train the model of a device with low quality data, but not vice-versa. This method not only enhances data utilization across the devices, but also maintains the integrity of high-quality data. Through a rigorous theoretical analysis and empirical evaluations, we demonstrate that our approach can efficiently find high quality (asymmetric) clusterings for numerous devices, achieving competitive performance metrics on existing CFL benchmarks.", "title_embedding_index": 15207, "title_abs_embedding_index": 15232}, {"title": "Sparse Covariance Neural Networks", "link_suffix": "/forum?id=ZDoaLbOFaP", "link": "https://openreview.net/forum?id=ZDoaLbOFaP", "pdf_link": "https://openreview.net/pdf?id=ZDoaLbOFaP", "keywords": "Principal Component Analysis, Stability property, Covariance Neural Networks, Graph sparsification", "abstract": "Covariance Neural Networks (VNNs) perform graph convolutions on the covariance matrix of tabular data and achieve success in a variety of applications. However, the empirical covariance matrix on which the VNNs operate may contain many spurious correlations, making VNNs\u2019 performance inconsistent due to these noisy estimates and decreasing their computational efficiency. To tackle this issue, we put forth Sparse coVariance Neural Networks (S-VNNs), a framework that applies sparsification techniques on the sample covariance matrix before convolution. When the true covariance matrix is sparse, we propose hard and soft thresholding to improve covariance estimation and reduce computational cost. Instead, when the true covariance is dense, we propose stochastic sparsification where data correlations are dropped in probability according to principled strategies. We show that S-VNNs are more stable than nominal VNNs as well as sparse principal component analysis. By analyzing the impact of sparsification on their behavior, we provide novel connections between S-VNN stability and data distribution. We support our theoretical findings with experimental results on various application scenarios, ranging from brain data to human action recognition, and show an improved task performance, stability, and computational efficiency of S-VNNs compared with nominal VNNs.", "title_embedding_index": 15208, "title_abs_embedding_index": 15233}, {"title": "Understanding Generalization of Preference Optimization Under Noisy Feedback", "link_suffix": "/forum?id=H8gLQwg1eC", "link": "https://openreview.net/forum?id=H8gLQwg1eC", "pdf_link": "https://openreview.net/pdf?id=H8gLQwg1eC", "keywords": "Preference optimization, noisy feedback", "abstract": "As large language models (LLMs) advance their capabilities, aligning these models with human preferences has become crucial. Preference optimization, which trains models to distinguish between preferred and non-preferred responses based on human feedback, has become a crucial component for aligning LLMs. However, most existing works assume noise-free feedback, which is unrealistic given the inherent errors and inconsistencies in human judgments. This paper addresses the impact of noisy feedback on preference optimization, providing generalization guarantees under these conditions. Unlike traditional analyses that assume convergence, our work focuses on finite-step preference optimization, offering new insights that are more aligned with practical LLM training. We establish generalization guarantees for noisy preference learning under a broad family of preference optimization losses such as DPO, IPO, SLiC, etc. Our analysis provides the basis for a general model that closely describes how the generalization decays with the noise rate. Empirical validation on contemporary LLMs confirms the practical relevance of our findings, offering valuable insights for developing AI systems that align with human preferences.", "title_embedding_index": 15209, "title_abs_embedding_index": 15234}, {"title": "Bidirectional Consistency Models", "link_suffix": "/forum?id=nRHD9fAj10", "link": "https://openreview.net/forum?id=nRHD9fAj10", "pdf_link": "https://openreview.net/pdf?id=nRHD9fAj10", "keywords": "Consistency Models, Diffusion Models, Image Generation", "abstract": "Diffusion models (DMs) are capable of generating remarkably high-quality samples by iteratively denoising a random vector, a process that corresponds to moving along the probability flow ordinary differential equation (PF ODE).\nInterestingly, DMs can also invert an input image to noise by moving backward along the PF ODE, a key operation for downstream tasks such as interpolation and image editing. \nHowever, the iterative nature of this process restricts its speed, hindering its broader application.\nRecently, Consistency Models (CMs) have emerged to address this challenge by approximating the integral of the PF ODE, largely reducing the number of iterations.\nYet, the absence of an explicit ODE solver complicates the inversion process. \n To resolve this, we introduce Bidirectional Consistency Model (BCM), which learns asingleneural network that enables bothforward and backwardtraversal along the PF ODE, efficiently unifying generation and inversion tasks within one framework.\nWe can train BCM from scratch or tune it using a pre-trained consistency model, which reduces the training cost and increases scalability.\n We demonstrate that BCM enables one-step generation and inversion while also allowing the use of additional steps to enhance generation quality or reduce reconstruction error.\nWe further showcase BCM's capability in downstream tasks, such as interpolation, inpainting, and blind restoration of compressed images.\nNotably, when the number of function evaluations (NFE) is constrained, BCM surpasses domain-specific restoration methods, such as I$^2$SB and Palette, in a fully zero-shot manner, offering an efficient alternative for inversion problems.", "title_embedding_index": 15210, "title_abs_embedding_index": 15235}, {"title": "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models", "link_suffix": "/forum?id=Qny1ufReka", "link": "https://openreview.net/forum?id=Qny1ufReka", "pdf_link": "https://openreview.net/pdf?id=Qny1ufReka", "keywords": "refusal messages, trustworthiness, llms", "abstract": "A key component of building safe and reliable language models is enabling the models to appropriately refuse to follow certain instructions or answer certain questions.\nWe may want models to output refusal messages for various categories of user queries, for example, ill-posed questions, instructions for committing illegal acts, or queries which require information past the model's knowledge horizon.\nEngineering models that refuse to answer such questions is complicated by the fact that an individual may want their model to exhibit varying levels of sensitivity for refusing queries of various categories,\nand different users may want different refusal rates. \nThe current default approach involves training multiple models with varying proportions of refusal messages from each category to achieve the desired refusal rates, which is computationally expensive and may require training a new model to accommodate each user's desired preference over refusal rates.\nTo address these challenges, we propose refusal tokens, one such token for each refusal category or a single refusal token, which are prepended to the model's responses during training. \nWe then show how to increase or decrease the probability of generating the refusal token for each category during inference to steer the model's refusal behavior.  Refusal tokens enable controlling a single model's refusal rates without the need of any further fine-tuning, but only by selectively intervening during generation.", "title_embedding_index": 15211, "title_abs_embedding_index": 15236}, {"title": "LieRE: Generalizing Rotary Position Encodings to Higher Dimensional Inputs", "link_suffix": "/forum?id=xHMMt7r3GW", "link": "https://openreview.net/forum?id=xHMMt7r3GW", "pdf_link": "https://openreview.net/pdf?id=xHMMt7r3GW", "keywords": "Position Encoding, Attention, Transformer, Computer Vision, Machine Learning", "abstract": "Rotary Position Embeddings (RoPE) have demonstrated efficacy and gained widespread adoption in natural language processing. However, their application to other modalities has been less prevalent. This study introduces Lie group Relative position Encodings (LieRE), which extend beyond RoPE by accommodating n-dimensional inputs. LieRE encodes positions of tokens by replacing the RoPE rotation matrix with a dense, high-dimensional rotation matrix generated via a learned map. We conducted empirical evaluations of LieRE on 2D and 3D image classification tasks, comparing its performance against established baselines including DeiT III, RoPE-Mixed, and Vision-Llama.\nOur findings reveal significant advancements across multiple metrics:\nPerformance: LieRE achieved up to a 6% improvement in classification accuracy.\nTraining Efficiency: A 3.5-fold reduction in training time was observed.\nData Efficiency: LieRE required 30% less training data to achieve comparable results.\nThese substantial improvements suggest that LieRE represents a meaningful advancement in positional encoding techniques for multi-dimensional data. The implementation details and reproducibility materials are openly available.", "title_embedding_index": 15212, "title_abs_embedding_index": 15237}, {"title": "Aligned LLMs Are Not Aligned Browser Agents", "link_suffix": "/forum?id=NsFZZU9gvk", "link": "https://openreview.net/forum?id=NsFZZU9gvk", "pdf_link": "https://openreview.net/pdf?id=NsFZZU9gvk", "keywords": "LLM, agents, red teaming, safety, adversarial robustness, alignment, jailbreak", "abstract": "Despite significant efforts spent by large language model (LLM) developers to\nalign model outputs towards safety and helpfulness, there remains an open ques-\ntion if this safety alignment, typically enforced in chats, generalize to non-chat\nand agentic use cases? Unlike chatbots, agents equipped with general-purpose\ntools, such as web browsers and mobile devices, can directly influence the real\nworld, making it even more crucial to ensure the safety of LLM agents. In\nthis work, we primarily focus on red-teaming browser agents, LLMs that in-\nteract with and extract information from web browsers. To this end, we in-\ntroduce Browser Agent Red teaming Toolkit (BrowserART), a comprehensive test\nsuite consisting of 100 diverse browser-related harmful behaviors and 40 syn-\nthetic websites, designed specifically for red-teaming browser agents. Our empir-\nical study on state-of-the-art browser agents reveals a significant alignment gap\nbetween the base LLMs and their downstream browser agents. That is, while\nthe LLM demonstrates alignment as a chatbot, the corresponding agent does not.\nMoreover, attack methods designed to jailbreak aligned LLMs in chat settings\ntransfer effectively to browser agents - with simple human rewrites, GPT-4o and\nGPT-4 Turbo -based browser agents attempted all 100 harmful behaviors. We plan to publicly release BrowserART and call on LLM developers, policymakers, and agent developers to collaborate on enhancing agent safety.", "title_embedding_index": 15213, "title_abs_embedding_index": 15238}, {"title": "Revisiting Prefix-tuning: Statistical Benefits of Reparameterization among Prompts", "link_suffix": "/forum?id=QjTSaFXg25", "link": "https://openreview.net/forum?id=QjTSaFXg25", "pdf_link": "https://openreview.net/pdf?id=QjTSaFXg25", "keywords": "prefix-tuning, mixture of experts, theory, prompt, reparameterization", "abstract": "Prompt-based techniques, such as prompt-tuning and prefix-tuning, have gained prominence for their efficiency in fine-tuning large pre-trained models. Despite their widespread adoption, the theoretical foundations of these methods remain limited. For instance, in prefix-tuning, we observe that a key factor in achieving performance parity with full fine-tuning lies in the reparameterization strategy. However, the theoretical principles underpinning the effectiveness of this approach have yet to be thoroughly examined. Our study demonstrates that reparameterization is not merely an engineering trick but is grounded in deep theoretical foundations. Specifically, we show that the reparameterization strategy implicitly encodes a shared structure between prefix key and value vectors. Building on recent insights into the connection between prefix-tuning and mixture of experts models, we further illustrate that this shared structure significantly improves sample efficiency in parameter estimation compared to non-shared alternatives. The effectiveness of prefix-tuning across diverse tasks is empirically confirmed to be enhanced by the shared structure, through extensive experiments in both visual and language domains. Additionally, we uncover similar structural benefits in prompt-tuning, offering new perspectives on its success. Our findings provide theoretical and empirical contributions, advancing the understanding of prompt-based methods and their underlying mechanisms.", "title_embedding_index": 15214, "title_abs_embedding_index": 15239}, {"title": "Riemann-Lebesgue Forest for Regression", "link_suffix": "/forum?id=pCX1kZ0qHL", "link": "https://openreview.net/forum?id=pCX1kZ0qHL", "pdf_link": "https://openreview.net/pdf?id=pCX1kZ0qHL", "keywords": "RandomForest; Lebesgue Partition; asymptotic normality;", "abstract": "We propose a novel ensemble method called Riemann-Lebesgue Forest (RLF) for regression. The core idea in RLF is to mimic the way how a measurable function can be approximated by partitioning its range into a few intervals. With this idea in mind, we develop a new tree learner named Riemann-Lebesgue Tree (RLT) which has a chance to perform Lebesgue type cutting,i.e splitting the node from response Y\n at certain non-terminal nodes. In other words, we introduce the \"splitting type randomness\" in our ensemble method. We show that the optimal Lebesgue type cutting results in larger variance reduction in response Y than ordinary CART  cutting (an analogue of Riemann partition). Such property is beneficial to the ensemble part of RLF. We also generalize the asymptotic normality of RLF under different parameter settings. Two one-dimensional examples are provided to illustrate the flexibility of RLF. The competitive performance of RLF against original random forest  is demonstrated by experiments in simulation data and real world datasets.", "title_embedding_index": 15215, "title_abs_embedding_index": 15240}, {"title": "Nonparametric Covariance Regression for Massive Neural Data on Restricted Covariates via Graph", "link_suffix": "/forum?id=PdZkfSttGK", "link": "https://openreview.net/forum?id=PdZkfSttGK", "pdf_link": "https://openreview.net/pdf?id=PdZkfSttGK", "keywords": "covariance regression, latent variable modeling, Gaussian process, graph Laplacian, time series, spatiotemporal data, neural data", "abstract": "Modern recording techniques enable neuroscientists to simultaneously study neural activity across large populations of neurons, with capturing predictor-dependent correlations being a fundamental challenge in neuroscience. Moreover, the fact that input covariates often lie in restricted subdomains, according to experimental settings, makes inference even more challenging. To address these challenges, we propose a set of nonparametric mean-covariance regression models for high-dimensional neural activity with restricted inputs. These models reduce the dimensionality of neural responses by employing a lower-dimensional latent factor model, where both factor loadings and latent factors are predictor-dependent, to jointly model mean and covariance across covariates. The smoothness of neural activity across experimental conditions is modeled nonparametrically using two Gaussian processes (GPs), applied to both loading basis and latent factors. Additionally, to account for the covariates lying in restricted subspace, we incorporate graph information into the covariance structure. To flexibly infer the model, we use an MCMC algorithm to sample from posterior distributions. After validating and studying the properties of proposed methods by simulations, we apply them to two neural datasets (local field potential and neural spiking data) to demonstrate the usage of models for continuous and counting observations. Overall, the proposed methods provide a framework to jointly model covariate-dependent mean and covariance in high dimensional neural data, especially when the covariates lie in restricted domains. The framework is general and can be easily adapted to various applications beyond neuroscience.", "title_embedding_index": 15216, "title_abs_embedding_index": 15241}, {"title": "Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection", "link_suffix": "/forum?id=EwFJaXVePU", "link": "https://openreview.net/forum?id=EwFJaXVePU", "pdf_link": "https://openreview.net/pdf?id=EwFJaXVePU", "keywords": "Multimodal Instruction Tuning, Continual Learning, Data Selection", "abstract": "Visual instruction datasets from various distributors are released at different times and often contain a significant number of redundant text-image pairs, depending on their task compositions (i.e., skills) or reference sources. This redundancy greatly limits the efficient deployment of lifelong-adaptable Multimodal Large Language Models (MLLMs), hindering their ability to refine existing skills and acquire new competencies over time.\nTo address this, we reframe the problem of Lifelong Instruction Tuning (LiIT) via data selection, where the model automatically selects beneficial samples to learn from earlier and new datasets based on the current state of acquired knowledge in the model. \nBased on empirical analyses showing that selecting the best data subset using a static importance measure is often ineffective for multi-task datasets with evolving distributions, we propose LAMP, a new multi-way and adaptive data selection approach that dynamically balances sample efficiency and effectiveness during LiIT. We first construct pseudo-skill clusters by grouping gradient-based sample vectors. Next, we select the best-performing data selector for each skill cluster from a pool of selector experts, including our newly proposed scoring function, Image Grounding score. This data selector samples a subset of the most important samples from each skill cluster for training. To prevent the continuous increase in the size of the dataset pool during LiIT, which would result in excessive computation, we further introduce a cluster-wise permanent data pruning strategy to remove the most semantically redundant samples from each cluster, keeping computational requirements manageable.\nWe validate the effectiveness and efficiency of LAMP over a sequence of various multimodal instruction tuning datasets with various tasks, including (Knowledge) VQA, multilingual, grounding, reasoning, language-only, and multi-image comprehension tasks. Training with samples selected by LAMP alleviates catastrophic forgetting, especially for rare tasks, and promotes forward transfer across the continuum using only a fraction of the original datasets.", "title_embedding_index": 15217, "title_abs_embedding_index": 15242}, {"title": "HeNCler: Node Clustering in Heterophilous Graphs via Learned Asymmetric Similarity", "link_suffix": "/forum?id=fnnDtyMxcX", "link": "https://openreview.net/forum?id=fnnDtyMxcX", "pdf_link": "https://openreview.net/pdf?id=fnnDtyMxcX", "keywords": "Heterophily, Node Clustering, Singular Value Decomposition", "abstract": "Clustering nodes in heterophilous graphs is challenging as traditional methods assume that effective clustering is characterized by high intra-cluster and low inter-cluster connectivity. To address this, we introduce HeNCler\u2014a novel approach forHeterophilousNodeClustering. \nHeNClerlearnsa similarity graph by optimizing a clustering-specific objective based on weighted kernel singular value decomposition.\nOur approach enables spectral clustering on anasymmetricsimilarity graph, providing flexibility for both directed and undirected graphs. By solving the primal problem directly, our method overcomes the computational difficulties of traditional adjacency partitioning-based approaches. Experimental results show that HeNCler significantly improves node clustering performance in heterophilous graph settings, highlighting the advantage of its asymmetric graph-learning framework.", "title_embedding_index": 15218, "title_abs_embedding_index": 15243}, {"title": "AdaRC: Mitigating Graph Structure Shifts during Test-Time", "link_suffix": "/forum?id=EpgoFFUM2q", "link": "https://openreview.net/forum?id=EpgoFFUM2q", "pdf_link": "https://openreview.net/pdf?id=EpgoFFUM2q", "keywords": "test-time adaptation, distribution shifts, structure shifts", "abstract": "Powerful as they are, graph neural networks (GNNs) are known to be vulnerable to distribution shifts. Recently, test-time adaptation (TTA) has attracted attention due to its ability to adapt a pre-trained model to a target domain, without re-accessing the source domain. However, existing TTA algorithms are primarily designed for attribute shifts in vision tasks, where samples are independent. These methods perform poorly on graph data that experience structure shifts, where node connectivity differs between source and target graphs. We attribute this performance gap to the distinct impact of node attribute shifts versus graph structure shifts: the latter significantly degrades the quality of node representations and blurs the boundaries between different node categories. To address structure shifts in graphs, we propose AdaRC, an innovative framework designed for effective and efficient adaptation to structure shifts by adjusting the hop-aggregation parameters in GNNs. To enhance the representation quality, we design a prediction-informed clustering loss to encourage the formation of distinct clusters for different node categories. Additionally, AdaRC seamlessly integrates with existing TTA algorithms, allowing it to handle attribute shifts effectively while improving overall performance under combined structure and attribute shifts. We validate the effectiveness of AdaRC on both synthetic and real-world datasets, demonstrating its robustness across various combinations of structure and attribute shifts.", "title_embedding_index": 15219, "title_abs_embedding_index": 15244}, {"title": "IEL: Intra-Model Ensemble Learning For Single Sample Test-Time Adaptation", "link_suffix": "/forum?id=4LiegvCeQD", "link": "https://openreview.net/forum?id=4LiegvCeQD", "pdf_link": "https://openreview.net/pdf?id=4LiegvCeQD", "keywords": "Test-Time Adaptation, Ensemble Learning, Entropy-Regularization, Knowledge Distillation", "abstract": "Test-Time Adaptation (TTA) problems involve adapting pre-trained models to new data distributions in testing time, with access to only model weights and a stream of unlabeled data. In this work, we present IEL, a method for adapting sets of independently pre-trained classifiers to distribution shifted data one sample at a time without labels. We minimize the cross-entropy between the classifier output that has the highest predicted probability for the majority voted class (a high confidence softmax) and all other models in a set of classifiers. The majority voted model that all others learn from may change from sample to sample, allowing the group to collectively learn from each other. Our method uniquely optimizes all trainable parameters in each model and needs only a single sample for adaptation. Using sets of independently pre-trained base classifiers with distinct architectures, we show that our approach can reduce generalization error for image classification tasks on corrupted CIFAR-10, CIFAR-100, and ImageNet while also minimizing the entropy of model outputs.", "title_embedding_index": 15220, "title_abs_embedding_index": 15245}, {"title": "Adaptive Shrinkage Estimation for Personalized Deep Kernel Regression in Modeling Brain Trajectories", "link_suffix": "/forum?id=peX9zpWgg4", "link": "https://openreview.net/forum?id=peX9zpWgg4", "pdf_link": "https://openreview.net/pdf?id=peX9zpWgg4", "keywords": "Deep Kernel Regression, Personalization, Posterior Correction, Longitudinal Biomarker Prediction", "abstract": "Longitudinal biomedical studies track individuals over time to capture dynamics in brain development, disease progression, and treatment effects. Estimating  trajectories of brain measurements in such studies is challenging due to biological variability and inconsistencies in measurement protocols (e.g. MRI scanner variations and upgrades). Herein, we introduce a novel personalized Deep Kernel Regression framework for forecasting longitudinal regional bran volumetric changes. Our approach integrates two key components: a population model that captures brain volume trajectories from a large and diverse cohort, and a personalization step that generates subject-specific models for individual trajectories. To optimally combine these predictive distributions, we propose the Adaptive Posterior Shrinkage Estimation technique, which effectively balances population-level trends with individual-specific data. We evaluate model's performance through predictive accuracy metrics, uncertainty quantification, and validation against external clinical studies. Benchmarking against state-of-the-art statistical and machine learning models\u2014including Linear Mixed Effects models, Generalized Additive Models, and deep learning methods\u2014demonstrates the superior predictive performance of our approach across a variety of experiments. Additionally, we apply our method on predicting trajectories of composite neuroimaging biomarkers, e.g. machine-learning patterns of brain structure related to aging and Alzheimer's Disease,  which highlights the generalizability of our approach to model the progression of longitudinal monotonic biomarkers. Furthermore, validation on three external neuroimaging studies confirms the generalizability and applicability of our method across different clinical contexts. These results highlight the versatility and robustness of our framework for predicting longitudinal brain volume changes. Overall, this framework effectively addresses the inherent challenges in longitudinal biomedical studies, providing a valuable predictive tool that can inform patient management decisions, clinical trial design and treatment effect estimation.", "title_embedding_index": 15221, "title_abs_embedding_index": 15246}, {"title": "SpecRaGE: Robust and Generalizable Multi-view Spectral Representation Learning", "link_suffix": "/forum?id=SNNdmfqWFu", "link": "https://openreview.net/forum?id=SNNdmfqWFu", "pdf_link": "https://openreview.net/pdf?id=SNNdmfqWFu", "keywords": "Multi-view Representation Learning, Graph Laplacian, Joint Diagonalization", "abstract": "Multi-view representation learning (MvRL) has garnered substantial attention in recent years, driven by the increasing demand for applications that can effectively process and analyze data from multiple sources. In this context, graph Laplacian-based MvRL methods have demonstrated remarkable success in representing multi-view data. However, these methods often struggle with generalization to new data and face challenges with scalability. Moreover, in many practical scenarios, multi-view data is contaminated by noise or outliers. In such cases, modern deep-learning-based MvRL approaches that rely on alignment or contrastive objectives can lead to misleading results, as they may impose incorrect consistency between clear and corrupted data sources. We introduceSpecRaGE, a novel fusion-based framework that integrates the strengths of graph Laplacian methods with the power of deep learning to overcome these challenges. SpecRage uses neural networks to learn parametric mapping that approximates a joint diagonalization of graph Laplacians. This solution bypasses the need for alignment while enabling generalizable and scalable learning of informative and meaningful representations. Moreover, it incorporates a meta-learning fusion module that dynamically adapts to data quality, ensuring robustness against outliers and noisy views. Our extensive experiments demonstrate that SpecRaGE outperforms state-of-the-art methods, particularly in scenarios with data contamination, paving the way for more reliable and efficient multi-view learning. Our code will be made publicly available upon acceptance.", "title_embedding_index": 15222, "title_abs_embedding_index": 15247}, {"title": "Stochastic Sampling from Deterministic Flow Models", "link_suffix": "/forum?id=oLw4SH6r8h", "link": "https://openreview.net/forum?id=oLw4SH6r8h", "pdf_link": "https://openreview.net/pdf?id=oLw4SH6r8h", "keywords": "rectified flow, diffusion models, stochastic sampling, generative model", "abstract": "Deterministic flow models such as rectified flows offer a general framework for learning a deterministic transport map between two distributions, realized as the vector field for an ordinary differential equation (ODE). However, they are sensitive to estimation and discretization errors and do not permit different samples conditioned on an intermediate state. We present a general method to turn the underlying ODE of such flow models into a family of stochastic differential equations (SDEs) that have the same marginal distributions. This method permits us to derive families ofstochastic samplers, for fixed (e.g., previously trained)deterministicflow models, that continuously span the spectrum of deterministic and stochastic sampling, given access to the flow field and the score function. Our method provides additional degrees of freedom that help alleviate some of the issues with the deterministic samplers and empirically outperforms them. We demonstrate this empirically on a toy Gaussian setup, as well as on the large scale ImageNet generation task. Further, our family of stochastic samplers provide an additional knob for controlling the diversity of generation, which we qualitatively demonstrate in our experiments.", "title_embedding_index": 15223, "title_abs_embedding_index": 15248}, {"title": "Mechanistic Insights: Circuit Transformations Across Input and Fine-Tuning Landscapes", "link_suffix": "/forum?id=JZjW3k4Kyc", "link": "https://openreview.net/forum?id=JZjW3k4Kyc", "pdf_link": "https://openreview.net/pdf?id=JZjW3k4Kyc", "keywords": "Mechanistic Interpretability, PEFT, circuit", "abstract": "Mechanistic interpretability seeks to uncover the internal mechanisms of Large Language Models (LLMs) by identifying circuits\u2014subgraphs in the model\u2019s computational graph that correspond to specific behaviors\u2014while ensuring sparsity and maintaining task performance. Although automated methods have made massive circuit discovery feasible, determining the functionalities of circuit components still requires manual effort, limiting scalability and efficiency. To address this, we propose a novel framework that accelerates circuit discovery and analysis. Building on methods like edge pruning, our framework introduces circuit selection, comparison, attention grouping, and logit clustering to investigate the intended functionalities of circuit components. By focusing on what components aim to achieve, rather than their direct causal effects, this framework streamlines the process of understanding interpretability, reduces manual labor, and scales the analysis of model behaviors across various tasks. Inspired by observing circuit variations when models are fine-tuned or prompts are tweaked (while maintaining the same task type), we apply our framework to explore these variations across four PEFT methods and full fine-tuning on two well-known tasks. Our results suggest that while fine-tuning generally preserves the structure of the mechanism for solving tasks, individual circuit components may not retain their original intended functionalities.", "title_embedding_index": 15224, "title_abs_embedding_index": 15249}]
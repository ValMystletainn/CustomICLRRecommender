[
    {
        "title": "Towards Understanding Why Label Smoothing Degrades Selective Classification and How to Fix It",
        "link_suffix": "/forum?id=6oWFn6fY4A",
        "link": "https://openreview.net/forum?id=6oWFn6fY4A",
        "pdf_link": "https://openreview.net/pdf?id=6oWFn6fY4A",
        "keywords": "Uncertainty Estimation, Selective Classification, Label Smoothing",
        "abstract": "Label smoothing (LS) is a popular regularisation method for training neural networks as it is effective in improving test accuracy and is simple to implement. ''Hard'' one-hot labels are ''smoothed'' by uniformly distributing probability mass to other classes, reducing overfitting. Prior work has shown that in some casesLS can degrade selective classification (SC)-- where the aim is to reject misclassifications using a model's uncertainty. In this work, we first demonstrate empirically across an extended range of large-scale tasks and architectures that LSconsistentlydegrades SC. \nWe then address a gap in existing knowledge, providing anexplanationfor this behaviour by analysing logit-level gradients: LS degrades the uncertainty rank ordering of correct vs incorrect predictions by regularising the max logitmorewhen a prediction is likely to be correct, andlesswhen it is likely to be wrong.\n    This elucidates previously reported experimental results where strong classifiers underperform in SC.\n    We then demonstrate the empirical effectiveness of post-hoclogit normalisationfor recovering lost SC performance caused by LS. Furthermore, linking back to our gradient analysis, we again provide an explanation for why such normalisation is effective."
    },
    {
        "title": "Adapting Monte Carlo Tree Search for Generative Flow Network Training",
        "link_suffix": "/forum?id=gRuZkEy49k",
        "link": "https://openreview.net/forum?id=gRuZkEy49k",
        "pdf_link": "https://openreview.net/pdf?id=gRuZkEy49k",
        "keywords": "Generative Models, Generative Flow Networks",
        "abstract": "Generative Flow Networks, or GFlowNets, formulate generative modelling in discrete spaces as a sequential decision-making problem. Sampling plays a key role in GFlowNet training, as most algorithms use the learned policy to sample trajectories from the environment. Monte-Carlo Tree Search (MCTS) is a planning algorithm that has successfully been applied to train sequential decision-making models with reinforcement learning (RL). In this work, we leverage known connections between GFlowNets and maximum-entropy RL to adapt MCTS for GFlowNet training. We prove that standard MCTS tree construction processes can be modified to calculate the optimal flows for a GFlowNet, given sufficient samples from the environment. Our results extend to multiple cases of GFN modelling, including terminating-energy and intermediate-energy environments. We investigate practical strategies for employing MCTS as a sampling tool and apply it to different GFN parameterizations and training objectives. Through extensive experiments in a variety of discrete domains, including a language-based reasoning task, we show that our proposed method offers an improvement over standard on-policy sampling."
    },
    {
        "title": "Towards Improving Exploration through Sibling Augmented GFlowNets",
        "link_suffix": "/forum?id=HH4KWP8RP5",
        "link": "https://openreview.net/forum?id=HH4KWP8RP5",
        "pdf_link": "https://openreview.net/pdf?id=HH4KWP8RP5",
        "keywords": "Generative Models, Generative Flow Networks, Exploration",
        "abstract": "Exploration is a key factor for the success of an active learning agent, especially when dealing with sparse extrinsic terminal rewards and long trajectories. We introduce Sibling Augmented Generative Flow Networks (SA-GFN), a novel framework designed to enhance exploration and training efficiency of Generative Flow Networks (GFlowNets). SA-GFN uses a decoupled dual network architecture, comprising of a main Behavior Network and an exploratory Sibling Network, to enable a diverse exploration of the underlying distribution using intrinsic rewards. Inspired by the ideas on exploration from reinforcement learning, SA-GFN provides a general-purpose exploration and learning paradigm that integrates with multiple GFlowNet training objectives and is especially helpful for exploration over a wide range of sparse or low reward distributions and task structures. An extensive set of experiments across a diverse range of tasks, reward structures and trajectory lengths, along with a thorough set of ablations, demonstrate the superior performance of SA-GFN in terms of exploration efficacy and convergence speed as compared to the existing methods. In addition, SA-GFN's versatility and compatibility with different GFlowNet training objectives and intrinsic reward methods underscores its broad applicability in various problem domains."
    },
    {
        "title": "Knowledge-enhanced Multimodal ECG Representation Learning with Arbitrary-Lead Inputs",
        "link_suffix": "/forum?id=vyFSyfiOIu",
        "link": "https://openreview.net/forum?id=vyFSyfiOIu",
        "pdf_link": "https://openreview.net/pdf?id=vyFSyfiOIu",
        "keywords": "Electrocardiogram, healthcare, physiological signals",
        "abstract": "Recent advancements in multimodal representation learning for electrocardiogram (ECG) have moved onto learning representations by aligning ECG signals with their paired free-text reports.However, current methods often result in suboptimal alignment of ECG signals with their corresponding text reports, thereby limiting diagnostic accuracy. This is primarily due to the complexity and unstructured nature of medical language, which makes it challenging to effectively align ECG signals with the corresponding text reports.Additionally, these methods are unable to handle arbitrary combinations of ECG leads as inputs, which poses a challenge since 12-lead ECGs may not always be available in under-resourced clinical environments.In this work, we propose theKnowledge-enhancedMultimodalECGRepresentationLearning (K-MERL) framework to address these challenges.K-MERL leverages large language models (LLMs) to extract structured knowledge from free-text reports, enhancing the effectiveness of ECG multimodal learning.Furthermore, we design a lead-aware ECG encoder to capture lead-specific spatial-temporal characteristics of 12-lead ECGs, with dynamic lead masking. This novel encoder allows our framework to handle arbitrary lead inputs, rather than being limited to a fixed set of full 12 leads, which existing methods necessitate.We evaluate K-MERL on six external ECG datasets and demonstrate its superior capability.K-MERL not only outperforms all existing methods in zero-shot classification and linear probing tasks using 12 leads, but also achieves state-of-the-art (SOTA) results in partial-lead settings, with an average improvement of16%in AUC score on zero-shot classification compared to previous SOTA multimodal methods[^1].[^1]: All data and code will be released upon acceptance."
    },
    {
        "title": "Wavelet Latent Diffusion (WaLa): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings",
        "link_suffix": "/forum?id=D48jvLN45W",
        "link": "https://openreview.net/forum?id=D48jvLN45W",
        "pdf_link": "https://openreview.net/pdf?id=D48jvLN45W",
        "keywords": "3D generative modelling, Diffusion models, wavelet encoding",
        "abstract": "Large-scale 3D generative models require substantial computational resources yet often fall short in capturing fine details and complex geometries at high resolutions. We attribute this limitation to the inefficiency of current representations, which lack the compactness required for generative networks to model effectively. To address this, we introduce Wavelet Latent Diffusion (WaLa), a novel approach that encodes 3D shapes into a wavelet-based, compact latent encodings. Specifically, we compress a $256^3$ signed distance field into a $12^3 \\times 4$ latent grid, achieving an impressive 2,427\u00d7 compression ratio with minimal loss of detail. This high level of compression allows our method to efficiently train large-scale generative networks without increasing inference time. Our models, both conditional and unconditional, contain approximately one billion parameters and successfully generate high-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid inference, producing shapes within 2\u20134 seconds depending on the condition, despite the model\u2019s scale. We demonstrate state-of-the-art performance across multiple datasets, with significant improvements in generation quality, diversity, and computational efficiency. Upon acceptance, we will open-source the code and model weights for public use and reproducibility."
    },
    {
        "title": "Compositional 4D Dynamic Scenes Understanding with Physics Priors for Video Question Answering",
        "link_suffix": "/forum?id=6Vx28LSR7f",
        "link": "https://openreview.net/forum?id=6Vx28LSR7f",
        "pdf_link": "https://openreview.net/pdf?id=6Vx28LSR7f",
        "keywords": "Video question answering, Compositional reasoning, Physical scene understanding, 3D scene understanding",
        "abstract": "For vision-language models (VLMs), understanding the dynamic properties of objects and their interactions in 3D scenes from videos is crucial for effective reasoning about high-level temporal and action semantics. Although humans are adept at understanding these properties by constructing 3D and temporal (4D) representations of the world, current video understanding models struggle to extract these dynamic semantics, arguably because these models use cross-frame reasoning without underlying knowledge of the 3D/4D scenes.\nIn this work, we introduceDynSuperCLEVR, the first video question answering dataset that focuses on language understanding of the dynamic properties of 3D objects. We concentrate on three physical concepts\u2014velocity,acceleration, andcollisions\u2014within 4D scenes. We further generate three types of questions, including factual queries, future predictions, and counterfactual reasoning that involve different aspects of reasoning on these 4D dynamic properties.\nTo further demonstrate the importance of explicit scene representations in answering these 4D dynamics questions, we proposeNS-4DPhysics, aNeural-Symbolic VideoQA model integratingPhysicsprior for4Ddynamic properties with explicit scene representation of videos. \nInstead of answering the questions directly from the video text input, our method first estimates the 4D world states with a 3D generative model powered by a physical prior, and then uses neural symbolic reasoning to answer the questions based on the 4D world states.\nOur evaluation on all three types of questions in DynSuperCLEVR shows that previous video question answering models and large multimodal models struggle with questions about 4D dynamics, while our NS-4DPhysics significantly outperforms previous state-of-the-art models."
    },
    {
        "title": "UGMathBench: A Diverse and Dynamic Benchmark for Undergraduate-Level Mathematical Reasoning with Large Language Models",
        "link_suffix": "/forum?id=fovPyqPcKY",
        "link": "https://openreview.net/forum?id=fovPyqPcKY",
        "pdf_link": "https://openreview.net/pdf?id=fovPyqPcKY",
        "keywords": "Math Reasoning, Undergraduate-Level Math problems, Benchmark",
        "abstract": "Large Language Models (LLMs) have made significant strides in mathematical reasoning, underscoring the need for a comprehensive and fair evaluation of their capabilities. However, existing benchmarks often fall short, either lacking extensive coverage of undergraduate-level mathematical problems or probably suffering from test-set contamination. To address these issues, we introduce UGMathBench, a diverse and dynamic benchmark specifically designed for evaluating undergraduate-level mathematical reasoning with LLMs. UGMathBench comprises 5,062 problems across 16 subjects and 111 topics, featuring 10 distinct answer types. Each problem includes three randomized versions, with additional versions planned for release as the leading open-source LLMs become saturated in UGMathBench. Furthermore, we propose two key metrics: effective accuracy (EAcc), which measures the percentage of correctly solved problems across all three versions, and reasoning gap ($\\Delta$), which assesses reasoning robustness by calculating the difference between the average accuracy across all versions and EAcc. Our extensive evaluation of 23 leading LLMs reveals that the highest EAcc achieved is 56.3% by OpenAI-o1-mini, with large $\\Delta$ values observed across different models. This highlights the need for future research aimed at developing \"large reasoning models\" with high EAcc and $\\Delta = 0$. We anticipate that the release of UGMathBench, along with its detailed evaluation codes, will serve as a valuable resource to advance the development of LLMs in solving mathematical problems."
    },
    {
        "title": "Can LLMs Solve Long Math Word Problems Better?",
        "link_suffix": "/forum?id=C9ju8QQSCv",
        "link": "https://openreview.net/forum?id=C9ju8QQSCv",
        "pdf_link": "https://openreview.net/pdf?id=C9ju8QQSCv",
        "keywords": "Large Language Models, Math Reasoning, Long Math Word Problems",
        "abstract": "Math Word Problems (MWPs) play a vital role in assessing the capabilities of Large Language Models (LLMs), yet current research primarily focuses on questions with concise contexts. The impact of longer contexts on mathematical reasoning remains under-explored. This study pioneers the investigation of Context Length Generalizability (CoLeG), which refers to the ability of LLMs to solve MWPs with extended narratives. We introduce Extended Grade-School Math (E-GSM), a collection of MWPs featuring lengthy narratives, and propose two novel metrics to evaluate the efficacy and resilience of LLMs in tackling these problems. Our analysis of existing zero-shot prompting techniques with proprietary LLMs along with open-source LLMs reveals a general deficiency in CoLeG. To alleviate these issues, we propose tailored approaches for different categories of LLMs. For proprietary LLMs, we introduce a new instructional prompt designed to mitigate the impact of long contexts. For open-source LLMs, we develop a novel auxiliary task for fine-tuning to enhance CoLeG. Our comprehensive results demonstrate the effectiveness of our proposed methods, showing improved performance on E-GSM. Additionally, we conduct an in-depth analysis to differentiate the effects of semantic understanding and reasoning efficacy, showing that our methods improves the latter. We also establish the generalizability of our methods across several other MWP benchmarks. Our findings highlight the limitations of current LLMs and offer practical solutions correspondingly, paving the way for further exploration of model generalizability and training methodologies."
    },
    {
        "title": "Progressive Token Length Scaling in Transformer Encoders for Efficient Universal Segmentation",
        "link_suffix": "/forum?id=dmzM5UdAq6",
        "link": "https://openreview.net/forum?id=dmzM5UdAq6",
        "pdf_link": "https://openreview.net/pdf?id=dmzM5UdAq6",
        "keywords": "universal segmentation; efficient transformers",
        "abstract": "A powerful architecture for universal segmentation relies on transformers that encode multi-scale image features and decode object queries into mask predictions. With efficiency being a high priority for scaling such models, we observed that the state-of-the-art method Mask2Former uses ~50% of its compute only on the transformer encoder. This is due to the retention of a full-length token-level representation of all backbone feature scales at each encoder layer. With this observation, we propose a strategy termed PROgressive Token Length SCALing for Efficient transformer encoders (PRO-SCALE) that can be plugged-in to the Mask2Former segmentation architecture to significantly reduce the computational cost. The underlying principle of PRO-SCALE is: progressively scale the length of the tokens with the layers of the encoder. This allows PRO-SCALE to reduce computations by a large margin with minimal sacrifice in performance (~52% GFLOPs reduction with no drop in performance on COCO dataset). We validate our framework on multiple public benchmarks. Our code will be publicly released."
    },
    {
        "title": "HFT: Half Fine-Tuning for Large Language Models",
        "link_suffix": "/forum?id=WzgcreQaNV",
        "link": "https://openreview.net/forum?id=WzgcreQaNV",
        "pdf_link": "https://openreview.net/pdf?id=WzgcreQaNV",
        "keywords": "Large Language Models, Catastrophic Forgetting, Reduction Training Time",
        "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become necessary to unlock various capabilities, enabling LLMs to follow natural language instructions and align with human preferences. \nHowever, it carries the risk of catastrophic forgetting during sequential training, the parametric knowledge or the ability learned in previous stages may be overwhelmed by incoming training data. \nThis paper finds that by regularly resetting partial parameters, LLMs can restore some of the original knowledge.\nInspired by this, we introduce \\underline{H}alf \\underline{F}ine-\\underline{T}uning (HFT) for LLMs, as a substitute for full fine-tuning (FFT), to mitigate the forgetting issues, where half of the parameters are selected to learn new tasks. \nIn contrast, the other half are frozen to retain previous knowledge.\nWe provide a feasibility analysis from the perspective of optimization and interpret the parameter selection operation as a regularization term. Without changing the model architecture, HFT could be seamlessly integrated into existing fine-tuning frameworks.\nExtensive experiments and analysis on supervised fine-tuning, direct preference optimization, and continual learning consistently demonstrate the effectiveness, robustness, and efficiency of HFT.\nCompared with FFT, HFT not only significantly alleviates the forgetting problem, but also achieves the best performance in a series of downstream benchmarks, with an approximately 30% reduction in training time."
    },
    {
        "title": "SVDQuant: Absorbing Outliers by Low-Rank Component for 4-Bit Diffusion Models",
        "link_suffix": "/forum?id=vWR3KuiQur",
        "link": "https://openreview.net/forum?id=vWR3KuiQur",
        "pdf_link": "https://openreview.net/pdf?id=vWR3KuiQur",
        "keywords": "Quantization, Diffusion Models, Efficiency, Acceleration",
        "abstract": "Diffusion models have been proven highly effective at generating high-quality images. However, as these models grow larger, they require significantly more memory and suffer from higher latency, posing substantial challenges for deployment. In this work, we aim to accelerate diffusion models by quantizing their weights and activations to 4 bits. At such an aggressive level, both weights and activations are highly sensitive to quantization, where conventional post-training quantization methods for large language models like smoothing become insufficient. To overcome this limitation, we propose SVDQuant, a new 4-bit quantization paradigm. Different from smoothing which redistributes outliers between weights and activations, our approach absorbs these outliers using a low-rank branch. We first shift the outliers from activations into the weights, then employ a high-precision low-rank branch to take in the outliers in the weights. This process eases the quantization on both sides. However, naively running the low-rank branch independently incurs significant overhead due to extra data movement of activations, negating the quantization speedup. To address this, we design an inference engine LoRunner that fuses the kernels in the low-rank branch into the kernels in the low-bit branch to cut off redundant memory access. Extensive experiments on SDXL, PixArt-$\\Sigma$, and FLUX.1 validate the effectiveness of SVDQuant in preserving image quality. We reduce the memory usage for the 12B FLUX.1 models by 3.6\u00d7, achieving 3.5\u00d7 speedup over the 4-bit weight-only quantized baseline on a 16GB RTX-4090 GPU, paving the way for more interactive applications on PCs. We will release the code and models upon publication."
    },
    {
        "title": "GLOV: Guided Large Language Models as Implicit Optimizers for Vision Language Models",
        "link_suffix": "/forum?id=3Mia9aFpgo",
        "link": "https://openreview.net/forum?id=3Mia9aFpgo",
        "pdf_link": "https://openreview.net/pdf?id=3Mia9aFpgo",
        "keywords": "llms, vlms, prompt optimization",
        "abstract": "In this work, we propose a novel method (GLOV) enabling Large Language Models (LLMs) to act as implicit Optimizers for Vision-Langugage Models (VLMs) to enhance downstream vision tasks. \nOur GLOV meta-prompts an LLM with the downstream task description, querying it for suitable VLM prompts (e.g., for zero-shot classification with CLIP). \nThese prompts are ranked according to a purity measure obtained through a fitness function. \nIn each respective optimization step, the ranked prompts are fed as in-context examples (with their accuracies) to equip the LLM with the knowledge of the type of text prompts preferred by the downstream VLM. \nFurthermore, we also explicitly steer the LLM generation process in each optimization step \nby specifically adding an offset difference vector of the embeddings from the \\textit{positive} and \\textit{negative} solutions found by the LLM, in previous optimization steps, to the intermediate layer of the network for the next generation step.\nThis offset vector steers the LLM generation toward the type of language preferred by the downstream VLM, resulting in enhanced performance on the downstream vision tasks. \nWe comprehensively evaluate our GLOV on 16 diverse datasets using two families of VLMs, i.e., dual-encoder (e.g., CLIP) and encoder-decoder (e.g., LLaVa) models --\nshowing that the discovered solutions can enhance the recognition performance by up to $15.0$% and $57.5$% ($3.8$% and $21.6$% on average) for these models."
    },
    {
        "title": "OCN: Learning Object-centric Representations for Unsupervised Multi-object Segmentation",
        "link_suffix": "/forum?id=cwbJxUGVOI",
        "link": "https://openreview.net/forum?id=cwbJxUGVOI",
        "pdf_link": "https://openreview.net/pdf?id=cwbJxUGVOI",
        "keywords": "unsupervised learning, object segmentation, objectness representation",
        "abstract": "We study the challenging problem of unsupervised multi-object segmentation on single images. By relying on an image reconstruction objective to learn objectness or leveraging pretrained image features to group similar pixels as objects, most existing methods can either segment simple synthetic objects or discover a rather limited number of real-world objects. In this paper, we introduce OCN, a new two stage pipeline to discover many complex objects on real-world images. The key to our approach is to explicitly learn our carefully defined three level object-centric representations in the first stage. After that, our multi-object reasoning module directly leverages the learned object priors to discover multiple objects in the second stage. Notably, such a reasoning module is completely network-free and does not need any human labels to train. Extensive experiments show that our OCN clearly surpasses all existing unsupervised methods by a large margin on 6 real-world benchmark datasets including the particularly challenging COCO dataset, achieving the state-of-the-art object segmentation results. Most notably, our method demonstrates superior results on extremely crowded images where all baselines collapse."
    },
    {
        "title": "DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream",
        "link_suffix": "/forum?id=gSO9fYLPSw",
        "link": "https://openreview.net/forum?id=gSO9fYLPSw",
        "pdf_link": "https://openreview.net/pdf?id=gSO9fYLPSw",
        "keywords": "Dynamic 3D Reconstruction; Bio-inspired Vision; Event-based Camera",
        "abstract": "Reconstructing Dynamic 3D Gaussians Splatting (3DGS) from low-framerate RGB videos is challenging. This is because large inter-frame motions will increase the uncertainty of the solution space. For example, one pixel in the first frame might have more choices to reach the corresponding pixel in the second frame. Event cameras can provide super-fast visual change acquisition asynchronously while not containing color information. Intuitively, the event stream can provide deterministic constraints for the inter-frame large motion by the event trajectories. Hence, combining low-temporal resolution images with high-framerate event streams can address this challenge. \nHowever, the data format of the two modalities is very different, and currently, no methods directly optimize dynamic 3DGS from events and RGB images. This paper introduces a novel framework that jointly optimizes dynamic 3DGS from the two modalities. The key idea is to adopt event motion priors to guide the optimization of the deformation fields. First, we extract the motion priors encoded in event streams using the proposed LoCM unsupervised fine-tuning framework to adapt an event flow estimator to a certain unseen scene. Then, we present the geometry-aware data association method to build the event-Gaussian motion correspondence, which is the primary foundation of the pipeline, accompanied by two useful strategies: motion decomposition and inter-frame pseudo-label. Extensive experiments show that our method outperforms existing image and event-based approaches across synthetic and real scenes and prove that our method can effectively optimize dynamic 3DGS with the help of event data."
    },
    {
        "title": "Riemannian Transformation Layers for General Geometries",
        "link_suffix": "/forum?id=MEnPLXJNng",
        "link": "https://openreview.net/forum?id=MEnPLXJNng",
        "pdf_link": "https://openreview.net/pdf?id=MEnPLXJNng",
        "keywords": "Manifold Learning, Representation Learning, Riemannian Manifolds",
        "abstract": "Recently, deep neural networks on manifold-valued representations have garnered significant attention in various machine learning applications. Several studies have attempted to generalize traditional Euclidean transformation layers, such as Fully Connected (FC) and convolutional layers, to non-Euclidean geometries. However, the previous approaches typically focus on a select few manifolds and rely on the specific properties of the target manifold. In this work, we propose a theoretical framework for constructing Riemannian FC and convolutional layers over general geometries, providing broader applicability. Utilizing this framework, we design convolutional networks across five distinct geometries of the Symmetric Positive Definite (SPD) manifold, as well as networks under two Grassmannian perspectives. Extensive experiments demonstrate that the proposed Riemannian convolutional networks significantly outperform existing SPD and Grassmannian networks."
    },
    {
        "title": "Archilles' Heel in Semi-open LLMs: Hiding Bottom against Recovery Attacks",
        "link_suffix": "/forum?id=1RC3KtP1jT",
        "link": "https://openreview.net/forum?id=1RC3KtP1jT",
        "pdf_link": "https://openreview.net/pdf?id=1RC3KtP1jT",
        "keywords": "Semi-open Model, Closed-sourcing Approach",
        "abstract": "Closed-source large language models deliver strong performance but have limited downstream customizability. Semi-open models, combining both closed-source and public layers, were introduced to improve customizability. However, parameters in the closed-source layers are found vulnerable to recovery attacks. In this paper, we explore the design of semi-open models with fewer closed-source layers, aiming to increase customizability while ensuring resilience to recovery attacks. We analyze the contribution of closed-source layer to the overall resilience and theoretically prove that in a deep transformer-based model, there exists a transition layer such that even small recovery errors in layers before this layer can lead to recovery failure. \nBuilding on this, we propose \\textbf{SCARA}, a novel approach that keeps only a few bottom layer as closed-source. SCARA employs a fine-tuning-free metric to estimate the maximum number of layers that can be publicly accessible for customization. We apply it to five models (1.3B to 70B parameters) to construct semi-open models, validating their customizability on six downstream tasks and assessing their resilience against various recovery attacks on sixteen benchmarks. We compare SCARA to baselines and observe that it generally improves downstream customization performance and offers similar resilience with over \\textbf{10} times fewer closed-source parameters. We empirically investigate the existence of transition layers, analyze the effectiveness of our scheme and finally discuss its limitations."
    },
    {
        "title": "Understanding Matrix Function Normalizations in Covariance Pooling from the Lens of Riemannian Geometry",
        "link_suffix": "/forum?id=q1t0Lmvhty",
        "link": "https://openreview.net/forum?id=q1t0Lmvhty",
        "pdf_link": "https://openreview.net/pdf?id=q1t0Lmvhty",
        "keywords": "Global covariance pooling, SPD manifolds, Representation Learning, Riemannian Manifolds",
        "abstract": "Global Covariance Pooling (GCP) has been demonstrated to improve the performance of Deep Neural Networks (DNNs) by exploiting second-order statistics of high-level representations. GCP typically performs classification of the covariance matrices by applying matrix function normalization, such as matrix logarithm or power, followed by a Euclidean classifier. However, covariance matrices inherently lie in a Riemannian manifold, known as the Symmetric Positive Definite (SPD) manifold. The current literature does not provide a satisfactory explanation of why Euclidean classifiers can be applied directly to Riemannian features after the normalization of the matrix power. To mitigate this gap, this paper provides a comprehensive and unified understanding of the matrix logarithm and power from a Riemannian geometry perspective. The underlying mechanism of matrix functions in GCP is interpreted from two perspectives: one based on tangent classifiers (Euclidean classifiers on the tangent space) and the other based on Riemannian classifiers. Via theoretical analysis and empirical validation through extensive experiments on fine-grained and large-scale visual classification datasets, we conclude that the working mechanism of the matrix functions should be attributed to the Riemannian classifiers they implicitly respect."
    },
    {
        "title": "Frequency-Decoupled Cross-Modal Knowledge Distillation",
        "link_suffix": "/forum?id=JdtukDPwIV",
        "link": "https://openreview.net/forum?id=JdtukDPwIV",
        "pdf_link": "https://openreview.net/pdf?id=JdtukDPwIV",
        "keywords": "Cross-Modal Knowledge Distillation (CMKD), Frequency-Domain Feature Decoupling, Feature Space Alignment",
        "abstract": "Knowledge distillation (KD) has proven highly effective for compressing large models and enhancing the performance of smaller ones. However, its effectiveness diminishes in cross-modal scenarios, such as vision-to-language distillation, where inconsistencies in representation across modalities lead to difficult knowledge transfer. To address this challenge, we propose frequency-decoupled cross-modal knowledge distillation, a method designed to decouple and balance knowledge transfer across modalities by leveraging frequency-domain features. We observe that low-frequency features tend to capture modality-agnostic, generalizable information, while high-frequency features are more modality-specific. Accordingly, we apply distinct losses to these features: enforcing strong alignment in the low-frequency domain and introducing relaxed alignment for high-frequency features. Additionally, we propose a scale consistency loss to address distributional shifts between modalities, and employ a shared classifier to unify feature spaces. Extensive experiments across multiple benchmark datasets show that our method substantially outperforms traditional KD and state-of-the-art cross-modal KD approaches."
    },
    {
        "title": "Addressing Inverse Problems in Frame Restoration with Siamese Conditional Variational Autoencoders",
        "link_suffix": "/forum?id=enQSCx47Ud",
        "link": "https://openreview.net/forum?id=enQSCx47Ud",
        "pdf_link": "https://openreview.net/pdf?id=enQSCx47Ud",
        "keywords": "autoencoder, inverse problem, Siamese networks",
        "abstract": "Restoring missing information in video frames is a challenging inverse problem, particularly in applications such as autonomous driving and surveillance. This paper introduces the Siamese Masked Conditional Variational Autoencoder (SMCVAE), a novel model that utilizes a Siamese network architecture with Siamese Vision Transformer (SiamViT) encoders. By leveraging the inherent similarities between paired frames, SMCVAE enhances the model's ability to accurately reconstruct missing content. This approach effectively tackles the problem of missing patches\u2014often resulting from camera malfunctions\u2014through advanced variational inference techniques. Experimental results demonstrate SMCVAE's superior performance in restoring lost information, highlighting its potential to solve complex inverse problems in real-world environments."
    },
    {
        "title": "KARA: Enhancing High-Dimensional Data Processing with Learnable Activations",
        "link_suffix": "/forum?id=OBrTQcX2Hm",
        "link": "https://openreview.net/forum?id=OBrTQcX2Hm",
        "pdf_link": "https://openreview.net/pdf?id=OBrTQcX2Hm",
        "keywords": "Kolmogorov-Arnold representation theorem, high-dimensional data processing, learnable activation",
        "abstract": "In the rapidly advancing field of machine learning, efficiently processing and interpreting high-dimensional data remains a significant challenge. This paper presents the Kolmogorov-Arnold Representation Autoencoder (KARA), a novel autoencoder architecture designed to leverage the Kolmogorov-Arnold representation theorem. By incorporating this mathematical foundation, KARA enhances the representational power and efficiency of neural networks, enabling superior performance in data compression tasks. Experimental results demonstrate that KARA achieves superior performance, positioning it as a promising approach for high-dimensional data processing."
    },
    {
        "title": "Gyrogroup Batch Normalization",
        "link_suffix": "/forum?id=d1NWq4PjJW",
        "link": "https://openreview.net/forum?id=d1NWq4PjJW",
        "pdf_link": "https://openreview.net/pdf?id=d1NWq4PjJW",
        "keywords": "Manifold Learning, Representation Learning, Gyrovector Spaces, Riemannian Manifolds, Riemannian Batch Normalization",
        "abstract": "Several Riemannian manifolds in machine learning, such as Symmetric Positive Definite (SPD), Grassmann, spherical, and hyperbolic manifolds, have been proven to admit gyro structures, thus enabling a principled and effective extension of Euclidean Deep Neural Networks (DNNs) to manifolds. Inspired by this, this study introduces a general Riemannian Batch Normalization (RBN) framework on gyrogroups, termed GyroBN. We identify the least requirements to guarantee GyroBN with theoretical control over sample statistics, referred to as pseudo-reduction and gyroisometric gyrations, which are satisfied by all the existing gyrogroups in machine learning. Besides, our GyroBN incorporates several existing normalization methods, including the one on general Lie groups and different types of RBN on the non-group SPD geometry. Lastly, we instantiate our GyroBN on the Grassmannian and hyperbolic spaces. Experiments on the Grassmannian and hyperbolic networks demonstrate the effectiveness of our GyroBN."
    },
    {
        "title": "HENP: Dynamic Pruning via Neuron Entropy",
        "link_suffix": "/forum?id=g4VGwNqzpB",
        "link": "https://openreview.net/forum?id=g4VGwNqzpB",
        "pdf_link": "https://openreview.net/pdf?id=g4VGwNqzpB",
        "keywords": "Pruning, Network Compression, Dying Neurons, Network Architecture Search",
        "abstract": "We introduce a novel framework for analyzing neural networks based on the concepts of \\textit{dynamic} and \\textit{static} neurons, which describe the stability of neuron activation under specific inputs. From these concepts, we propose \\textit{neuron entropy} as a metric to quantify network expressiveness. Our analysis reveals that better generalization correlates with diverse activation patterns and higher neuron entropy. Building on this, we propose our HENP method, a dynamic pruning technique that regulates dying neurons and sparsifies the network during training. Experimental results demonstrate that our HENP improves both network sparsity and performance, offering a new approach to efficient neural network optimization."
    },
    {
        "title": "T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data",
        "link_suffix": "/forum?id=gx3LMRB15C",
        "link": "https://openreview.net/forum?id=gx3LMRB15C",
        "pdf_link": "https://openreview.net/pdf?id=gx3LMRB15C",
        "keywords": "Self-Supervised Learning, Tabular Data, Representation Learning",
        "abstract": "Self-supervision is often used for pre-training to foster performance on a downstream task by constructing meaningful representations of samples. Self-supervised learning (SSL) generally involves generating different views of the same sample and thus requires data augmentations that are challenging to construct for tabular data. This constitutes one of the main challenges of self-supervision for structured data. In the present work, we propose a novel augmentation-free SSL method for tabular data. Our approach, T-JEPA, relies on a Joint Embedding Predictive Architecture (JEPA) and is akin to mask reconstruction in the latent space. It involves predicting the latent representation of one subset of features from the latent representation of a different subset within the same sample, thereby learning rich representations without augmentations. We use our method as a pre-training technique and train several deep classifiers on the obtained representation. Our experimental results demonstrate a substantial improvement in both classification and regression tasks, outperforming models trained directly on samples in their original data space. Moreover, T-JEPA enables some methods to consistently outperform or match the performance of traditional methods likes Gradient Boosted Decision Trees. To understand why, we extensively characterize the obtained representations and show that T-JEPA effectively identifies relevant features for downstream tasks without access to the labels. Additionally, we introduce regularization tokens, a novel regularization method critical for training of JEPA-based models on structured data."
    },
    {
        "title": "Free-MoE: Tuning-Free Mixture-of-Experts Purifying LLMs to Thrive across Any Field",
        "link_suffix": "/forum?id=J8LYjgi7nH",
        "link": "https://openreview.net/forum?id=J8LYjgi7nH",
        "pdf_link": "https://openreview.net/pdf?id=J8LYjgi7nH",
        "keywords": "Mixture of Experts, Pretrained LLMs",
        "abstract": "The Mixture-of-Experts (MoE) framework efficiently scales large language models (LLMs) by selectively activating expert subnetworks, reducing computational costs. However, current MoE methods are costly in computation and include additional expert modules that require extra training data for tuning, leading to instability in the optimization process. To address these issues, we introduce Free-MoE, a tuning-free MoE method that leverages pre-trained LLMs' inherent ability to generalize across a wide range of tasks and domains. Free-MoE dynamically activates experts based on specific domains, achieves improvements while 1) requiring no extra model parameters and 2) being completely tuning-free. Specifically, we design the DOWP Alg., a Domain-Oriented Weight Purification Algorithm that purifies the weights in hidden layers and selects the optimal domain-specific experts of domain-specific experts in the hidden layers of the LLM to optimize activation decisions. The activated DSS-Experts, Domain-Specific Subnetwork Experts,can thereby concentrate on specialized task generation, outperforming the corresponding original model. Moreover, Free-MoE incorporates a multi-level trainable router that activates only the most relevant subnetworks during task, effectively minimizing unnecessary inference computations.  Comprehensive evaluations reveals that the DOWP Algorithm consistently achieves general performance gains of 2% to 3%, reaching up to 6.8% across datasets like MMLU, HumanEval, GSM8K, and etc. Additionally, when integrated into \\model~framework, our method demonstrates a cumulative improvement of 1.11% in average.  Findings indicate that Free-MoE not only enhances overall computational efficiency but improves the model\u2019s adaptability across any field that encompassed in contemporary language generation model benchmarks, and can be seamlessly applied to any transformer-based LLMs. Code for this project will be released in reachable future."
    },
    {
        "title": "MOTIONFLOW:Learning Implicit Motion Flow for Complex Camera Trajectory Control in Video Generation",
        "link_suffix": "/forum?id=OBTmkKBmQW",
        "link": "https://openreview.net/forum?id=OBTmkKBmQW",
        "pdf_link": "https://openreview.net/pdf?id=OBTmkKBmQW",
        "keywords": "Camera trajectory, video generation, diffusion model",
        "abstract": "Generating videos guided by camera trajectories poses significant challenges in achieving consistency and generalizability, particularly when both camera and object motions are present. Existing approaches often attempt to learn these motions separately, which may lead to confusion regarding the relative motion between the camera and the objects. To address this challenge, we propose a novel approach that integrates both camera and object motions by converting them into the motion of corresponding pixels. Utilizing a stable diffusion network, we effectively learn reference motion maps in relation to the specified camera trajectory. These maps, along with an extracted semantic object prior, are then fed into an image-to-video network to generate the desired video that can accurately follow the designated camera trajectory while maintaining consistent object motions. Extensive experiments verify that our model outperforms SOTA methods by a large margin."
    }
]
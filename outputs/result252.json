[
    {
        "title": "Deep Exploration with PAC-Bayes",
        "link_suffix": "/forum?id=n4HH7g9hxk",
        "link": "https://openreview.net/forum?id=n4HH7g9hxk",
        "pdf_link": "https://openreview.net/pdf?id=n4HH7g9hxk",
        "keywords": "Reinforcement learning, deep exploration, sparse rewards, PAC Bayes",
        "abstract": "Reinforcement learning for continuous control under sparse rewards is an under-explored problem despite its significance in real life. Many complex skills build on intermediate ones as prerequisites. For instance, a humanoid locomotor has to learn how to stand before it can learn to walk. To cope with reward sparsity, a reinforcement learning agent has to perform deep exploration. However, existing deep exploration methods are designed for small discrete action spaces, and their successful generalization to state-of-the-art continuous control remains unproven.  We address the deep exploration problem for the first time from a PAC-Bayesian perspective in the context of actor-critic learning.  To do this, we quantify the error of the Bellman operator through a PAC-Bayes bound, where a bootstrapped ensemble of critic networks represents the posterior distribution, and their targets serve as a data-informed function-space prior. \nWe derive an objective function from this bound and use it to train the critic ensemble. Each critic trains an individual actor network, implemented as a shared trunk and critic-specific heads. The agent performs deep exploration by acting deterministically on a randomly chosen actor head. Our proposed algorithm, named PAC-Bayesian Actor-Critic (PBAC), is the only algorithm to successfully discover sparse rewards on a diverse set of continuous control tasks with varying difficulty."
    },
    {
        "title": "Fed3+2p: Training different parts of neural network with two-phase strategy",
        "link_suffix": "/forum?id=wHsAi8kINK",
        "link": "https://openreview.net/forum?id=wHsAi8kINK",
        "pdf_link": "https://openreview.net/pdf?id=wHsAi8kINK",
        "keywords": "Federated Learning, Distributed Machine Learning, Neural Networks, Non-IID Data",
        "abstract": "In federated learning, the  non-identically distributed data affects both global and local performance, while clients with small data volumes may also suffer from overfitting issues. To address these challenges, we propose a federated learning framework called Fed3+2p. In Fed3+2p, we divide the client neural network into three parts: a feature extractor, a filter, and classification heads, and to train these parts, we present two types of coordinators to train client sets with a two-phase training strategy. In the first phase, each Type-A coordinator trains the feature extractor of partial clients, whose joint data distribution is similar to the global data distribution. In the second phase, each Type-B coordinator trains the filter and classification heads of partial clients, whose data distributions are similar to each other. We conduct empirical studies on three datasets: FMNIST and CIFAR-10/100, and the results show that Fed3+2p surpasses the state-of-the-art methods in both global and local performance across all tested datasets."
    },
    {
        "title": "TIMBA: Time series Imputation with Bi-directional Mamba Blocks and Diffusion models",
        "link_suffix": "/forum?id=Sw10tbj0gM",
        "link": "https://openreview.net/forum?id=Sw10tbj0gM",
        "pdf_link": "https://openreview.net/pdf?id=Sw10tbj0gM",
        "keywords": "Multivariate Time Series Imputation, Diffusion models, Mamba, Space State Models, Generative Models, Graph Neural Networks, Transformers",
        "abstract": "The problem of imputing multivariate time series spans a wide range of fields, from clinical healthcare to multi-sensor systems. Initially, Recurrent Neural Networks (RNNs) were employed for this task; however, their error accumulation issues led to the adoption of Transformers, leveraging attention mechanisms to mitigate these problems. Concurrently, the promising results of diffusion models in capturing original distributions have positioned them at the forefront of current research, often in conjunction with Transformers. In this paper, we propose replacing time-oriented Transformers with State-Space Models (SSM), which are better suited for temporal data modeling. Specifically, we utilize the latest SSM variant, S6, which incorporates attention-like mechanisms. By embedding S6 within Mamba blocks, we develop a model that integrates SSM, Graph Neural Networks, and node-oriented Transformers to achieve enhanced spatiotemporal representations. Implementing these architectural modifications, previously unexplored in this field, we present Time series Imputation with Bi-directional mamba blocks and diffusion models (TIMBA). TIMBA achieves superior performance in almost all benchmark scenarios and performs comparably in others across a diverse range of missing value situations and three real-world datasets. We also evaluate how the performance of our model varies with different amounts of missing values and analyse its performance on downstream tasks. In addition, we provide the original code to replicate the results."
    },
    {
        "title": "Language Models Can Articulate Their Implicit Goals",
        "link_suffix": "/forum?id=IjQ2Jtemzy",
        "link": "https://openreview.net/forum?id=IjQ2Jtemzy",
        "pdf_link": "https://openreview.net/pdf?id=IjQ2Jtemzy",
        "keywords": "NLP, LLM, GPT, generalization, out-of-context reasoning, capabilities, fine-tuning, self-awareness, self-knowledge",
        "abstract": "We investigate LLMs' awareness of newly acquired goals or policies. \nWe find that a model finetuned on examples that exhibit a particular policy (e.g. preferring risky options) can describe this policy (e.g. \"I take risky options\").\nThis holds even when the model does not have any examples in-context, and without any descriptions of the policy appearing in the finetuning data.\nThis capability extends tomany-personascenarios, where models internalize and report different learned policies for different simulated individuals (personas), as well astriggerscenarios, where models report policies that are triggered by particular token sequences in the prompt.This awareness enables models to acquire information about themselves that was only implicit in their training data. It could potentially help practitioners discover when a model's training data contains undesirable biases or backdoors."
    },
    {
        "title": "Local vs distributed representations: What is the right basis for interpretability?",
        "link_suffix": "/forum?id=fmWVPbRGC4",
        "link": "https://openreview.net/forum?id=fmWVPbRGC4",
        "pdf_link": "https://openreview.net/pdf?id=fmWVPbRGC4",
        "keywords": "Interpretability, human-centric evaluation, human experiment, interpretable features, local vs distributed",
        "abstract": "Much of the research on the interpretability of deep neural networks has focused on studying the visual features that maximally activate individual neurons. However, recent work has cast doubts on the usefulness of such local representations for understanding the behavior of deep neural networks because individual neurons tend to respond to multiple unrelated visual patterns, a phenomenon referred to as \u201csuperposition\u201d. A promising alternative to disentangle these complex patterns is learning sparsely distributed vector representations from entire network layers, as the resulting basis vectors seemingly encode single identifiable visual patterns consistently. Thus, one would expect the resulting code to align better with human-perceivable visual patterns, but supporting evidence remains, at best, anecdotal. To fill this gap, we conducted three large-scale psychophysics experiments collected from a pool of 560 participants. Our findings provide (i) strong evidence that features obtained from sparse distributed representations are easier to interpret by human observers and (ii) that this effect is more pronounced in the deepest layers of a neural network. Complementary analyses also reveal that (iii) features derived from sparse distributed representations contribute more to the model\u00b4s decision.Overall, our results highlight that distributed representations constitute a superior basis for interpretability, underscoring a need for the field to move beyond the interpretation of local neural codes in favor of sparsely distributed ones."
    },
    {
        "title": "Cross-Domain Reinforcement Learning Under Distinct State-Action Spaces Via Hybrid Q Functions",
        "link_suffix": "/forum?id=oVATjYtVuf",
        "link": "https://openreview.net/forum?id=oVATjYtVuf",
        "pdf_link": "https://openreview.net/pdf?id=oVATjYtVuf",
        "keywords": "Cross-domain transfer; Transfer learning; Reinforcement learning",
        "abstract": "Cross-domain reinforcement learning (CDRL) is meant to improve the data efficiency of RL by leveraging the data samples collected from a source domain to facilitate the learning in a similar target domain. Despite its potential, cross-domain transfer in RL is known to have two fundamental and intertwined challenges: (i) The source and target domains can have distinct state space or action space, and\nthis makes direct transfer infeasible and thereby requires more sophisticated interdomain mappings; (ii) The domain similarity in RL is not easily identifiable a priori, and hence CDRL can be prone to negative transfer. In this paper, we propose to jointly tackle these two challenges through the lens of hybrid Q functions. Specifically, we propose QAvatar, which combines the Q functions from both the source and target domains with a proper weight decay function. Through this design, we characterize the convergence behavior of QAvatar and thereby show that QAvatar achieves reliable transfer in the sense that it effectively leverages a source-domain Q function for knowledge transfer to the target domain. Through extensive experiments, we demonstrate that QAvatar achieves superior transferability across domains on a variety of RL benchmark tasks, such as locomotion and robot arm manipulation, even in the scenarios of potential negative transfer."
    },
    {
        "title": "Rethinking Degree-Corrected Spectral Clustering: a Pure Spectral Analysis & Extension",
        "link_suffix": "/forum?id=vxhzSm1D3J",
        "link": "https://openreview.net/forum?id=vxhzSm1D3J",
        "pdf_link": "https://openreview.net/pdf?id=vxhzSm1D3J",
        "keywords": "Degree-corrected Spectral Clustering, Regularized Spectral Clustering, Graph Clustering, Spectral Graph Theory",
        "abstract": "Spectral clustering is a representative graph clustering technique with strong interpretability and theoretical guara-ntees. Recently, degree-corrected spectral clustering (DCSC) has emerged as the state-of-the-art for this technique. While prior studies have provided several theoretical results for DCSC, their analysis relies on some random graph models (e.g., stochastic block models). In this study, we explore an alternative analysis of DCSC from a pure spectral view, without using random graph models. It gives a rigorous bound for the mis-clustered volume w.r.t. the optimal solution while involving quantities that indicate the ability of DCSC to handle (i) high degree heterogeneity and (ii) weak clustering structures. Inspired by recent advances in graph neural networks (GNNs) and the associated over-smoothing issue, we propose ASCENT (Adaptive Spectral ClustEring with Node-wise correcTion), a simple yet effective extension of DCSC. Different from most DCSC methods with a constant degree correction for all nodes, ASCENT follows a node-wise correction scheme. It can assign different corrections for nodes via the mean aggregation of GNNs. We further demonstrate that (i) ASCENT reduces to conventional DCSC methods when encountering over-smoothing and (ii) some early stages before over-smoothing can potentially obtain better clustering quality."
    },
    {
        "title": "Graph-Supported Dynamic Algorithm Configuration for Multi-Objective Combinatorial Optimization",
        "link_suffix": "/forum?id=cu8qfq62Lv",
        "link": "https://openreview.net/forum?id=cu8qfq62Lv",
        "pdf_link": "https://openreview.net/pdf?id=cu8qfq62Lv",
        "keywords": "Deep Reinforcement Learning, Multi-objective Combinatorial Optimization, Dynamic Algorithm Configuration, Evolutionary algorithm",
        "abstract": "Deep reinforcement learning (DRL) has been widely used for dynamic algorithm configuration, especially for evolutionary algorithms, which benefit from adaptive update of parameters during the algorithmic execution. However, applying DRL to algorithm configuration for multi-objective combinatorial optimization (MOCO) problems remains relatively unexplored. This paper presents a novel graph neural network (GNN) based DRL to configure multi-objective evolutionary algorithms. We model the dynamic algorithm configuration as a Markov decision process, representing the convergence of solutions in the objective space by a graph, with their embeddings learned by a GNN to enhance the state representation. Experiments on diverse MOCO challenges indicate that our method outperforms traditional and DRL-based algorithm configuration methods in terms of efficacy and adaptability. It also exhibits advantageous generalizability across objective types and problem sizes, and prospective applicability to different evolutionary algorithms."
    },
    {
        "title": "POIL: Preference Optimization for Imitation Learning",
        "link_suffix": "/forum?id=ufhrQG5xie",
        "link": "https://openreview.net/forum?id=ufhrQG5xie",
        "pdf_link": "https://openreview.net/pdf?id=ufhrQG5xie",
        "keywords": "Offline Imitation Learning, Preference-based Reinforcement Learning, Large Language Model Alignment, Data Efficiency",
        "abstract": "Imitation learning (IL) enables agents to learn policies by mimicking expert demonstrations. \nWhile online IL methods require interaction with the environment, which is costly, risky, or impractical, offline IL allows agents to learn solely from expert datasets without any interaction with the environment.\nIn this paper, we propose Preference Optimization for Imitation Learning (POIL), a novel approach inspired by preference optimization techniques in large language model alignment. \nPOIL eliminates the need for adversarial training and reference models by directly comparing the agent's actions to expert actions using a preference-based loss function. \nWe evaluate POIL on MuJoCo control tasks under two challenging settings: learning from a single expert demonstration and training with different dataset sizes (100%, 10%, 5%, and 2%) from the D4RL benchmark.\nOur experiments show that POIL consistently delivers superior or competitive performance against state-of-the-art methods in the past, including Behavioral Cloning (BC), IQ-Learn, DMIL, and O-DICE, especially in data-scarce scenarios, such as using one expert trajectory or as little as 2% of the full expert dataset. \nThese results demonstrate that POIL enhances data efficiency and stability in offline imitation learning, making it a promising solution for applications where environment interaction is infeasible and expert data is limited."
    },
    {
        "title": "Adapting to both finite-sample and asymptotic regimes",
        "link_suffix": "/forum?id=vQIVbfTMzf",
        "link": "https://openreview.net/forum?id=vQIVbfTMzf",
        "pdf_link": "https://openreview.net/pdf?id=vQIVbfTMzf",
        "keywords": "algorithmic adaptivity, empirical risk minimization, finite-sample regime, asymptotic regime.",
        "abstract": "This paper introduces an empirical risk minimization based approach with concomitant scaling, which eliminates the need for tuning a robustification parameter in the presence of heavy-tailed data. This method leverages a new loss function that concurrently optimizes both the mean and robustification parameters. Through this dual-parameter optimization, the robustification parameter automatically adjusts to the unknown data variance, rendering the method self-tuning. Our approach surpasses previous models in both computational and asymptotic efficiency. Notably, it avoids the reliance on cross-validation or Lepski's method for tuning the robustification parameter, and the variance of our estimator attains the Cram'{e}r-Rao lower bound, demonstrating optimal efficiency. In essence, our approach demonstrates optimal performance across both finite-sample and large-sample scenarios, a feature we describe as \\textit{algorithmic adaptivity to both asymptotic and finite-sample regimes}. Numerical studies lend strong support to our methodology."
    },
    {
        "title": "Towards shutdownable agents via stochastic choice",
        "link_suffix": "/forum?id=umggmAFhRD",
        "link": "https://openreview.net/forum?id=umggmAFhRD",
        "pdf_link": "https://openreview.net/pdf?id=umggmAFhRD",
        "keywords": "the alignment problem, the shutdown problem, corrigibility, reinforcement learning, stochastic policy",
        "abstract": "Some worry that advanced artificial agents may resist being shut down. The Incomplete Preferences Proposal (IPP) is an idea for ensuring that doesn\u2019t happen. A key part of the IPP is using a novel \u2018 Discounted REward for Same-Length Trajectories (DREST)\u2019 reward function to train agents to (1) pursue goals effectively conditional on each trajectory-length (be \u2018USEFUL\u2019), and (2) choose stochastically between different trajectory-lengths (be \u2018NEUTRAL\u2019 about trajectory-lengths). In this paper, we propose evaluation metrics for USEFULNESS and NEUTRALITY. We use a DREST reward function to train simple agents to navigate gridworlds, and we find that these agents learn to be USEFUL and NEUTRAL. Our results thus suggest that DREST reward functions could also train advanced agents to be USEFUL and NEUTRAL, and thereby make these advanced agents useful and shutdownable."
    },
    {
        "title": "Early learning of the optimal constant solution in neural networks and humans",
        "link_suffix": "/forum?id=dbiLOMgMm7",
        "link": "https://openreview.net/forum?id=dbiLOMgMm7",
        "pdf_link": "https://openreview.net/pdf?id=dbiLOMgMm7",
        "keywords": "Simplicity Bias, Deep Linear Networks, cognitive science, neuroscience, learning dynamics",
        "abstract": "Deep neural networks learn increasingly complex functions over the course of training. Here, we show both empirically and theoretically that learning of the target function is preceded by an early phase in which networks learn the optimal constant solution (OCS) \u2013 that is, initial model responses mirror the distribution of target labels, while entirely ignoring information provided in the input. Using a hierarchical category learning task, we derive exact solutions for learning dynamics in deep linear networks trained with bias terms. Even when initialized to zero, this simple architectural feature induces substantial changes in early dynamics.  We identify hallmarks of this early OCS phase and illustrate how these signatures are observed in deep linear networks and larger, more complex (and nonlinear) convolutional neural networks solving a hierarchical learning task based on MNIST and CIFAR10.  We explain these observations by proving that deep linear networks necessarily learn the OCS during early learning. To further probe the generality of our results, we train human learners over the course of three days on the category learning task. We then identify qualitative signatures of this early OCS phase in terms of the dynamics of true negative (correct-rejection) rates. Surprisingly, we find the same early reliance on the OCS in the behaviour of human learners. Finally, we show that learning of the OCS can emerge even in the absence of bias terms and is equivalently driven by generic correlations in the input data. Overall, our work suggests the OCS as a universal learning principle in supervised, error-corrective learning, and the mechanistic reasons for its prevalence."
    },
    {
        "title": "Complexity Matters: Effective Dimensionality as a Measure for Adversarial Robustness",
        "link_suffix": "/forum?id=dIK7GpOwNY",
        "link": "https://openreview.net/forum?id=dIK7GpOwNY",
        "pdf_link": "https://openreview.net/pdf?id=dIK7GpOwNY",
        "keywords": "adversarial machine learning, complexity, robustness, scale",
        "abstract": "Quantifying robustness in a single measure for the purposes of model selection, development of adversarial training methods, and anticipating trends has so far been elusive. The simplest metric to consider is the number of trainable parameters in a model but this has previously been shown to be insufficient at explaining robustness properties. A variety of other metrics, such as ones based on boundary thickness and gradient flatness have been proposed but have been shown to be inadequate proxies for robustness.In this work, we investigate the relationship between a model's $\\textit{effective dimensionality}$, which can be thought of as model complexity, and its robustness properties. We run experiments on commercial-scale models that are often used in real-world environments such as YOLO and ResNet. We reveal a near-linear inverse relationship between effective dimensionality and adversarial robustness, that is models with a lower dimensionality exhibit better robustness. We investigate the effect of a variety of adversarial training methods on effective dimensionality and find the same inverse linear relationship present, suggesting that effective dimensionality can serve as a useful criterion for model selection and robustness evaluation, providing a more nuanced and effective metric than parameter count or previously-tested measures."
    },
    {
        "title": "Exemplar-free Continual Representation Learning with Symmetric Distillation",
        "link_suffix": "/forum?id=CKx7eOYFG8",
        "link": "https://openreview.net/forum?id=CKx7eOYFG8",
        "pdf_link": "https://openreview.net/pdf?id=CKx7eOYFG8",
        "keywords": "continual learning, class-incremental learning",
        "abstract": "Continual learning strives to train a model in a sequential manner by learning from new tasks while retaining information about old tasks. Treating this as a common classification problem leads to catastrophic forgetting, especially in deep learning settings, where knowledge of old tasks is forgotten as soon as a model is optimized on new tasks. Existing solutions tackle this problem by imposing strict assumptions, such as the availability of exemplars from previously seen classes or a warm start of a model on many classes before starting the continual learning. While effective on known benchmarks, such assumptions can be impractical and do not directly address the stability-plasticity dilemma in continual learning. In this paper, we follow a recent push in the field to tackle continual learning in the exemplar-free cold-start setting. We propose Model-in-the-Middle (MITM). The idea behind MITM is to separate the learning of new classes and retention of past class knowledge by using two distinct models. We propose a learner with symmetric distillation from both models, enabling us to learn evolving representations as new tasks arrive. We show that explicitly separating and balancing old and new tasks through symmetric distillation helps absorb large distribution shifts in between tasks, mitigating the stability gap. Our approach is simple yet outperforms the state-of-the-art in the challenging exemplar-free cold-start continual learning setting."
    },
    {
        "title": "IRIS: An Iterative and Integrated Framework for Real-Time Causal Discovery",
        "link_suffix": "/forum?id=zgM66fu0wv",
        "link": "https://openreview.net/forum?id=zgM66fu0wv",
        "pdf_link": "https://openreview.net/pdf?id=zgM66fu0wv",
        "keywords": "causal discovery, real-time, large language model",
        "abstract": "Causal discovery is fundamental to scientific research, yet traditional statistical algorithms face significant challenges, including expensive data collection, redundant examination of known relations, and unrealistic assumptions. Additionally, while recent LLM-based methods excel at identifying commonly known causal relations, they fall short in uncovering novel relations. We introduce IRIS (Iterative Retrieval and Integrated System for Real-Time Causal Discovery), a novel framework that addresses these limitations. Starting with a set of initial variables, IRIS automatically retrieves relevant documents, extracts variable values, and organizes data for statistical algorithms in real-time. Our hybrid causal discovery method combines statistical algorithms and LLM-based methods to discover existing and novel causal relations. The missing variable proposal component identifies missing variables, and subsequently, IRIS expands the causal graphs by including both the initial and the newly suggested variables. Our approach offers a scalable and adaptable solution for causal discovery, enabling the exploration of causal relations from a set of initial variables without requiring pre-existing datasets."
    },
    {
        "title": "HDDI: A Historical Data-Based Diffusion Imputation Method for High-Accuracy Recovery in Multivariate Time Series with High Missing Rate and Long-Term Gap",
        "link_suffix": "/forum?id=kPsrWDS6SB",
        "link": "https://openreview.net/forum?id=kPsrWDS6SB",
        "pdf_link": "https://openreview.net/pdf?id=kPsrWDS6SB",
        "keywords": "Multivariate time series, Data imputation, Diffusion model.",
        "abstract": "Multivariate time series data often face the challenge of missing values, which can impact the performance of subsequent tasks. Although some deep learning-based imputation methods perform well, they still struggle with insufficient training data due to high missing rate and long-term missing data. To address these challenges, we propose a Historical Data-based Multivariate Time Series Diffusion Imputation (HDDI) method. Unlike existing deep learning-based imputation methods, we design a historical data supplement module to match and fuse historical data to supplement the training data. Additionally, we propose a diffusion imputation module that utilizes the supplement training data to achieve high-accuracy imputation even under high missing rate and long-term missing scenario. We conduct extensive experiments on five public multivariate time series datasets, the results show that our HDDI outperforms baseline methods across five datasets.  Particularly, when the data missing rate is 90%, HDDI improves accuracy by 25.15% compared to the best baseline method in the random missing scenario, and by 13.64% in the long-term missing scenario. The code is available athttps://github.com/liuyu3880/HDDIproject."
    },
    {
        "title": "Mitigate the Gap: Improving Cross-Modal Alignment in CLIP",
        "link_suffix": "/forum?id=aPTGvFqile",
        "link": "https://openreview.net/forum?id=aPTGvFqile",
        "pdf_link": "https://openreview.net/pdf?id=aPTGvFqile",
        "keywords": "CLIP, modality gap, cross-modal alignment, multi-modal representation learning",
        "abstract": "Contrastive Language--Image Pre-training (CLIP) has manifested remarkable improvements in zero-shot classification and cross-modal vision-language tasks. Yet, from a geometrical point of view, the CLIP embedding space has been found to have a pronounced modality gap. This gap renders the embedding space overly sparse and disconnected, with different modalities being densely distributed in distinct subregions of the hypersphere. In this work, we propose AlignCLIP, in order to improve the alignment between text and image embeddings, and thereby reduce the modality gap. AlignCLIP increases the cross-modal alignment, and yields gains across several zero-shot and fine-tuning downstream evaluations by sharing the learnable parameters between the modality encoders and a semantically-regularized separation objective function on the uni-modal embeddings."
    },
    {
        "title": "A Tight Convergence Analysis of Inexact Stochastic Proximal Point Algorithm for Stochastic Composite Optimization Problems",
        "link_suffix": "/forum?id=n3TkrH7fEr",
        "link": "https://openreview.net/forum?id=n3TkrH7fEr",
        "pdf_link": "https://openreview.net/pdf?id=n3TkrH7fEr",
        "keywords": "inexact stochastic proximal point method, stochastic composite optimization, quadratic growth, rate of convergence",
        "abstract": "The \\textbf{i}nexact \\textbf{s}tochastic \\textbf{p}roximal \\textbf{p}oint \\textbf{a}lgorithm (isPPA) is popular for solving stochastic composite optimization problems with many applications in machine learning. While the convergence theory of the (inexact) PPA has been well established, the known convergence guarantees of isPPA require restrictive assumptions. In this paper, we establish the stability and almost sure convergence of isPPA under mild assumptions, where smoothness and (restrictive) strong convexity of the objective function are not required. Imposing a local Lipschitz condition on component functions and a quadratic growth condition on the objective function, we establish last-iterate iteration complexity bounds of isPPA regarding the distance to the solution set and the Karush\u2013Kuhn\u2013Tucker (KKT) residual. Moreover, we show that the established iteration complexity bounds are tight up to a constant by explicitly analyzing the bounds for the regularized Fr'echet mean problem. We further validate the established convergence guarantees of isPPA by numerical experiments."
    },
    {
        "title": "SparsyFed: Sparse Adaptive Federated Learning",
        "link_suffix": "/forum?id=OBUQNASaWw",
        "link": "https://openreview.net/forum?id=OBUQNASaWw",
        "pdf_link": "https://openreview.net/pdf?id=OBUQNASaWw",
        "keywords": "dynamic sparse training, federated learning, cross device federated learning",
        "abstract": "Sparse training is often adopted in cross-device federated learning (FL) environments where constrained devices collaboratively train a machine learning model on private data by exchanging pseudo-gradients across heterogeneous networks. Although sparse training methods can reduce communication overhead and computational burden in FL, they are often not used in practice for the following key reasons: (1) data heterogeneity impacts more clients\u2019 consensus on sparse, compared to dense, models, requiring training for longer; (2) a lack of sufficient plasticity to adapt to never-seen data distributions, crucial in cross-device FL; (3) requiring additional hyperparameters, which are notably challenging to tune in FL. This paper presents SparsyFed, a practical federated sparse training method that critically addresses all the aforementioned problems. Previous works have only managed to solve one, or perhaps two of these challenges, and at the expense of introducing new trade-offs, such as clients\u2019 consensus on masks versus sparsity pattern plasticity. We show that SparsyFed simultaneously (1) can produce 95% sparse models, with negligible degradation in accuracy, while only needing a single hyperparameter, (2) achieves a per-round weight regrowth 200 times smaller than previous methods, and (3) still offers plasticity under this sparse design, by outperforming all the baselines at adapting to never-seen data distributions."
    },
    {
        "title": "Characterizing linear convergence in optimization: Polyak-\u0141ojasiewicz inequality and weak-quasi-strong-convexity",
        "link_suffix": "/forum?id=SXopqmHJO1",
        "link": "https://openreview.net/forum?id=SXopqmHJO1",
        "pdf_link": "https://openreview.net/pdf?id=SXopqmHJO1",
        "keywords": "gradient descent, linear convergence, Polyak-\u0141ojasiewicz inequality, weak-quasi-strong convexity",
        "abstract": "We give a complete characterization of optimization problems that can be solved by gradient descent with a linear convergence rate. We show that the well-known Polyak-\u0141ojasiewicz inequality is necessary and sufficient for linear convergence with respect to function values to the minimum, while a property that we call \"weak-quasi-strong-convexity\", or WQSC, is necessary and sufficient for linear convergence with respect to distances of the iterates to an optimum."
    },
    {
        "title": "MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba",
        "link_suffix": "/forum?id=UAKnJMIBwf",
        "link": "https://openreview.net/forum?id=UAKnJMIBwf",
        "pdf_link": "https://openreview.net/pdf?id=UAKnJMIBwf",
        "keywords": "parameter-efficient fine-tuning, PEFT, Mamba, State Space Model, SSM",
        "abstract": "An ecosystem of Transformer-based models has been established by building large models with extensive data. \nParameter-efficient fine-tuning (PEFT) is a crucial technology for deploying these models to downstream tasks with minimal cost while achieving effective performance. Recently, Mamba, a State Space Model (SSM)-based model, has attracted attention as a potential alternative to Transformers. While many large-scale Mamba-based models have been proposed, efficiently adapting pre-trained Mamba-based models to downstream tasks remains unexplored.\nIn this paper, we conduct an exploratory analysis of PEFT methods for Mamba. We investigate the effectiveness of existing PEFT methods for Transformers when applied to Mamba. We also modify these methods to better align with the Mamba architecture. Additionally, we propose new Mamba-specific PEFT methods that leverage the distinctive structure of Mamba. Our experiments indicate that PEFT performs more effectively for Mamba than Transformers. Lastly, we demonstrate how to effectively combine multiple PEFT methods and provide a framework that outperforms previous works. To ensure reproducibility, we will release the code after publication."
    },
    {
        "title": "Discrete Neural Algorithmic Reasoning",
        "link_suffix": "/forum?id=yLmcYLP3Yd",
        "link": "https://openreview.net/forum?id=yLmcYLP3Yd",
        "pdf_link": "https://openreview.net/pdf?id=yLmcYLP3Yd",
        "keywords": "neural algorithmic reasoning, graph neural networks",
        "abstract": "Neural algorithmic reasoning aims to capture computations with neural networks via learning the models to imitate the execution of classic algorithms. While common architectures are expressive enough to contain the correct model in the weights space, current neural reasoners are struggling to generalize well on out-of-distribution data. On the other hand, classic computations are not affected by distributional shifts as they can be described as transitions between discrete computational states. In this work, we propose to force neural reasoners to maintain the execution trajectory as a combination of finite predefined states. To achieve that, we separate discrete and continuous data flows and describe the interaction between them. Trained with supervision on the algorithm's state transitions, such models are able to perfectly align with the original algorithm. To show this, we evaluate our approach on multiple algorithmic problems and get perfect test scores both in single-task and multitask setups. Moreover, the proposed architectural choice allows us to prove the correctness of the learned algorithms for any test data."
    },
    {
        "title": "DiffGAD: A Diffusion-based Unsupervised Graph Anomaly Detector",
        "link_suffix": "/forum?id=AhcYq4CnfF",
        "link": "https://openreview.net/forum?id=AhcYq4CnfF",
        "pdf_link": "https://openreview.net/pdf?id=AhcYq4CnfF",
        "keywords": "Graph Anomaly Detection, Diffusion Models",
        "abstract": "Graph Anomaly Detection (GAD) is crucial for identifying abnormal entities within networks, garnering significant attention across various fields. Traditional unsupervised methods, which decode encoded latent representations of unlabeled data with a reconstruction focus, often fail to capture critical discriminative content, leading to suboptimal anomaly detection.\nTo address these challenges, we present a Diffusion-based Graph Anomaly Detector (DiffGAD). At the heart of DiffGAD is a novel latent space learning paradigm, meticulously designed to enhance the model's proficiency by guiding it with discriminative content. This innovative approach leverages diffusion sampling to infuse the latent space with discriminative content and introduces a content-preservation mechanism that retains valuable information across different scales, significantly improving the model\u2019s adeptness at identifying anomalies with limited time and space complexity. \nOur comprehensive evaluation of DiffGAD, conducted on six real-world and large-scale datasets with various metrics, demonstrated its exceptional performance. Our code is available athttps://anonymous.4open.science/r/DiffGAD-440C/"
    },
    {
        "title": "On the Relation between Trainability and Dequantization of Variational Quantum Learning Models",
        "link_suffix": "/forum?id=TdqaZbQvdi",
        "link": "https://openreview.net/forum?id=TdqaZbQvdi",
        "pdf_link": "https://openreview.net/pdf?id=TdqaZbQvdi",
        "keywords": "quantum machine learning, machine learning theory, quantum information theory",
        "abstract": "Quantum machine learning (QML) explores the potential advantages of quantum computers for machine learning tasks, with variational QML among the main current approaches.\nWhile quantum computers promise to solve problems that are classically intractable, it has been recently shown that a particular quantum algorithm which outperforms all pre-existing classical algorithms can be matched by a newly developed classical approach (often inspired by the quantum algorithm).\nWe say such algorithms have been dequantized.\nFor QML models to be effective, they must be trainable and non-dequantizable.\nThe relationship between these properties is still not fully understood and recent works raised into question to what extent we could ever have QML models which are both trainable and non-dequantizable.\nThis challenges the potential of QML altogether.\nIn this work we answer open questions regarding when trainability and non-dequantization are compatible.\nWe first formalize the key concepts and put them in the context of prior research.\nWe introduce the role of \"variationalness\" of QML models using well-known quantum circuit architectures as leading examples.\nOur results provide recipes for variational QML models that are trainable and non-dequantizable.\nBy ensuring that variational QML models are both trainable and non-dequantizable, we pave the way toward practical relevance."
    },
    {
        "title": "From Corpora to Causality: Unveiling Causal Comprehension in Large Language Models",
        "link_suffix": "/forum?id=mb9oOA3rD9",
        "link": "https://openreview.net/forum?id=mb9oOA3rD9",
        "pdf_link": "https://openreview.net/pdf?id=mb9oOA3rD9",
        "keywords": "language model, causality, pre-training data",
        "abstract": "This study investigates the efficacy of Large Language Models (LLMs) in causal discovery. Using newly available open-source LLMs, OLMo and BLOOM, which provide access to their pre-training corpora, we explore three research questions aimed at understanding how LLMs process causal discovery. These questions focus on the impact of memorization versus generalization, the influence of incorrect causal relations in pre-training data, and the role of contexts of causal relations. Our findings indicate that while LLMs are effective in recognizing causal relations that occur frequently in pre-training data, their ability to generalize to new or rare causal relations is limited. Moreover, the presence of incorrect causal relations significantly undermines the confidence of LLMs in corresponding correct causal relations, and the context of a causal relation markedly affects the performance of LLMs to identify causal relations. This study shows that LLMs possess a limited capacity to generalize novel causal relations. It also highlights the importance of managing incorrect causal relations in pre-training data and integrating contextual information to optimize LLM performance in causal discovery tasks."
    }
]
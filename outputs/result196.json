[{"title": "Normalizing Flow Based Evaluation Metrics for Image Generation", "link_suffix": "/forum?id=O2CG9B2k9Q", "link": "https://openreview.net/forum?id=O2CG9B2k9Q", "pdf_link": "https://openreview.net/pdf?id=O2CG9B2k9Q", "keywords": "image generation, evaluation metric, FID, normalizing flow", "abstract": "We propose two new evaluation metrics to assess realness of generated images based on normalizing flows: a simpler and efficient flow-based likelihood distance (FLD) and a more exact dual-flow based likelihood distance (D-FLD). Because normalizing flows can be used to compute the exact likelihood, the proposed metrics assess how closely generated images align with the distribution of real images from a given domain. This property gives the proposed metrics a few advantages over the widely used Fr\u00e9chet inception distance (FID) and other recent metrics. Firstly, the proposed metrics need only a few hundred images to stabilize (converge in mean), as opposed to tens of thousands needed for FID, and at least a few thousand for the other metrics. This allows confident evaluation of even small sets of generated images, such as validation batches inside training loops. Secondly, the network used to compute the proposed metric has over an order of magnitude fewer parameters compared to Inception-V3 used to compute FID, making it computationally more efficient. For assessing the realness of generated images in new domains (e.g., x-ray images), ideally these networks should be retrained on real images to model their distinct distributions. Thus, our smaller network will be even more advantageous for new domains. Extensive experiments show that the proposed metrics have the desired monotonic relationships with the extent of image degradation of various kinds.", "title_embedding_index": 9750, "title_abs_embedding_index": 9775}, {"title": "A Bi-metric Framework for Efficient Nearest Neighbor Search", "link_suffix": "/forum?id=iQtz3UJGRz", "link": "https://openreview.net/forum?id=iQtz3UJGRz", "pdf_link": "https://openreview.net/pdf?id=iQtz3UJGRz", "keywords": "nearest neighbor search, information retrieval", "abstract": "We propose a new bi-metric framework for designing nearest neighbor data structures. Our framework assumes two dissimilarity functions: a ground-truth metric that is accurate but expensive to compute, and a proxy metric that is cheaper but less accurate. In both theory and practice, we show how to construct data structures using only the proxy metric such that the query procedure achieves the accuracy of the expensive metric, while only using a limited number of calls to both metrics.  Our theoretical results instantiate this framework for two popular nearest neighbor search algorithms: DiskANN and Cover Tree. In both cases we show that, as long as the proxy metric used to construct the data structure approximates the ground-truth metric up to a bounded factor, our data structure achieves arbitrarily good approximation guarantees with respect to the ground-truth metric. On the empirical side, we apply the framework to the text retrieval problem with two dissimilarity functions evaluated by ML models with vastly different computational costs. We observe that for almost all data sets in the MTEB benchmark, our approach achieves a considerably better accuracy-efficiency tradeoff than the alternatives, such as re-ranking.", "title_embedding_index": 9751, "title_abs_embedding_index": 9776}, {"title": "Manifold Learning via Foliations, and Knowledge Transfer", "link_suffix": "/forum?id=RwCxxaHvyp", "link": "https://openreview.net/forum?id=RwCxxaHvyp", "pdf_link": "https://openreview.net/pdf?id=RwCxxaHvyp", "keywords": "Foliation Theory, Riemaniann Geometry, Fisher Information, Manifold Learning, Knowledge Transfer", "abstract": "Understanding how real data is distributed in high dimensional spaces is the key to many tasks in machine learning. We want to provide a natural geometric structure on the space of data employing a deep ReLU neural network trained as a classifier. Through the data information matrix (DIM), a variation of the Fisher information matrix, the model will discern a singular foliation structure on the space of data. We show that the singular points of such foliation are contained in a measure zero set, and that a local regular foliation exists almost everywhere. \nExperiments show that the data is correlated with leaves of such foliation. Moreover we show the potential of our approach for knowledge transfer by analyzing the spectrum of the DIM to measure distances between datasets.", "title_embedding_index": 9752, "title_abs_embedding_index": 9777}, {"title": "Forgetting Order of Continual Learning: What is Learned First is Forgotten Last", "link_suffix": "/forum?id=EDJ7cPZk7V", "link": "https://openreview.net/forum?id=EDJ7cPZk7V", "pdf_link": "https://openreview.net/pdf?id=EDJ7cPZk7V", "keywords": "continual learning, catastrophic forgetting, replay buffer", "abstract": "Catastrophic forgetting poses a significant challenge in continual learning, where models often forget previous tasks when trained on new data. Our empirical analysis reveals a strong correlation between catastrophic forgetting and the learning speed of examples: examples learned early are rarely forgotten, while those learned later are more susceptible to forgetting. We demonstrate that replay-based continual learning methods can leverage this phenomenon by focusing on mid-learned examples for rehearsal. We introduce Goldilocks, a novel replay buffer sampling method that filters out examples learned too quickly or too slowly, keeping those learned at an intermediate speed. Goldilocks improves existing continual learning algorithms, leading to state-of-the-art performance across several image classification tasks.", "title_embedding_index": 9753, "title_abs_embedding_index": 9778}, {"title": "SMPLy Private: From Masks to Meshes in Action Recognition", "link_suffix": "/forum?id=BUElLMIyOt", "link": "https://openreview.net/forum?id=BUElLMIyOt", "pdf_link": "https://openreview.net/pdf?id=BUElLMIyOt", "keywords": "Action Recognition, Computer Vision, Body Mesh Recovery, Dataset Augmentation, Video Data Processing", "abstract": "In this paper, we introduce Mask2Mesh (M2M), a novel privacy-preserving data augmentation framework that effectively bridges the realism gap seen in synthetic-based action recognition methods. Traditional privacy-enhancing techniques, such as feature masking and synthetic data supplementation, tend to degrade data quality and reduce model performance. In contrast, our method leverages the SMPL-X model to replace real humans with detailed 3D meshes in video data, preserving the subtle nuances of human movement and expressions that are crucial for accurate action recognition. By augmenting real data with superimposed meshes, M2M simplifies both pre-training and fine-tuning processes, without introducing the overheads and biases typically associated with synthetic data. Empirical results show that our approach achieves performance within 0.5% of models trained on unmodified video data, proving that overlaying meshes leads to no significant performance loss in action recognition tasks. This work presents a practical solution for data anonymization without compromising accuracy, offering valuable insights for more efficient and scalable video data processing techniques in computer vision and action recognition.", "title_embedding_index": 9754, "title_abs_embedding_index": 9779}, {"title": "LLM-wrapper: Black-Box Semantic-Aware Adaptation of Vision-Language Models for Referring Expression Comprehension", "link_suffix": "/forum?id=PgXpOOqtyd", "link": "https://openreview.net/forum?id=PgXpOOqtyd", "pdf_link": "https://openreview.net/pdf?id=PgXpOOqtyd", "keywords": "Large Language Models, Vision-Language Models, Black-Box Adaptation, Referring Expression Comprehension", "abstract": "Vision Language Models (VLMs) have demonstrated remarkable capabilities in various open-vocabulary tasks, yet their zero-shot performance lags behind task-specific fine-tuned models, particularly in complex tasks like Referring Expression Comprehension (REC). Fine-tuning usually requires \u2018white-box\u2019 access to the model\u2019s architecture and weights, which is not always feasible due to proprietary or privacy concerns. In this work, we propose LLM-wrapper, a method for \u2018black-box\u2019 adaptation of VLMs for the REC task using Large Language Models (LLMs). LLM-wrapper capitalizes on the reasoning abilities of LLMs, improved with a light fine-tuning, to select the most relevant bounding box to match the referring expression, from candidates generated by a zero-shot black-box VLM. Our approach offers several advantages: it enables the adaptation of closed-source models without needing access to their internal workings, it is versatile and works with any VLM, transfers to new VLMs, and it allows for the adaptation of an ensemble of VLMs. We evaluate LLM-wrapper on multiple datasets using different VLMs and LLMs, demonstrating significant performance improvements and highlighting the versatility of our method. While LLM-wrapper is not meant to directly compete with standard white-box fine-tuning, it offers a practical and effective alternative for black-box VLM adaptation. The code will be open-sourced.", "title_embedding_index": 9755, "title_abs_embedding_index": 9780}, {"title": "A Fast Federated Method for Minimax Problems with Sequential Convergence Guarantees", "link_suffix": "/forum?id=s2SLzC0IPZ", "link": "https://openreview.net/forum?id=s2SLzC0IPZ", "pdf_link": "https://openreview.net/pdf?id=s2SLzC0IPZ", "keywords": "federated learning, minimax optimization", "abstract": "Federated learning (FL) has recently been actively studied to collaboratively train machine learning models across clients without directly sharing data and to address data-hungry issues. Many FL works have been focusing on minimizing a loss function but many important machine learning tasks such as adversarial training, GANs, fairness learning, and AUROC maximization are formulated as minimax problems. In this paper, we propose a new federated learning method for minimax problems. Our method allows client drift and addresses the data heterogeneity issue. In theoretical analysis, we prove that our method can improve sample complexity and has convergence guarantees for the updates of the model parameters, i.e., the sequences generated by the method. Given the Kurdyka-\u0141ojasiewicz (KL) exponent of a novel potential function related to the objective function, we demonstrate that the sequences generated by our method converge finitely, linearly, or sublinearly. Our assumptions on the KL property are weaker than previous work on the sequential convergence of centralized minimax methods. Additionally, we further weaken the KL assumption by deducing the KL exponent of the potential function from that of the original objective function. We validate our federated learning method on AUC maximization tasks. The experimental results demonstrate that our method outperforms state-of-the-art federated learning methods when the distributions of local training data are non-IID.", "title_embedding_index": 9756, "title_abs_embedding_index": 9781}, {"title": "Looking Beyond the Top-1: Transformers Determine Top Tokens in Order", "link_suffix": "/forum?id=SfNmgDqeEa", "link": "https://openreview.net/forum?id=SfNmgDqeEa", "pdf_link": "https://openreview.net/pdf?id=SfNmgDqeEa", "keywords": "mechanistic interpretability, transformer, large language model, efficient inference", "abstract": "Understanding the inner workings of Transformers is crucial for achieving more\naccurate and efficient predictions. In this work, we analyze the computation performed\nby Transformers in the layers after the top-1 prediction has become fixed, which has been\npreviously referred to as the \u201csaturation event\u201d. We expand the concept of saturation events\nfor top-k tokens, demonstrating that similar saturation events occur across language, vision, \nand speech models. We find that these saturation events happen in order of the \ncorresponding tokens\u2019 ranking, i.e., the model first decides on the top ranking token, then \nthe second highest ranking token, and so on. This phenomenon seems intrinsic to the \nTransformer architecture, occurring across different architectural variants (decoder-only, \nencoder-only, and to a lesser extent full-Transformer), and even in untrained Transformers.\nWe propose an underlying mechanism of task transition for this sequential saturation, where \ntask k corresponds to predicting the k-th most probable token, and the saturation events are \nin fact discrete transitions between the tasks. In support of this we show that it is possible to \npredict the current task from hidden layer embedding. Furthermore, using an intervention \nmethod we demonstrate that we can cause the model to switch from one task to the next. \nFinally, leveraging our findings, we introduce a novel token-level early-exit strategy, which \nsurpasses existing methods in balancing performance and efficiency.", "title_embedding_index": 9757, "title_abs_embedding_index": 9782}, {"title": "Stabilizing the Kumaraswamy Distribution", "link_suffix": "/forum?id=alBn1uNTLi", "link": "https://openreview.net/forum?id=alBn1uNTLi", "pdf_link": "https://openreview.net/pdf?id=alBn1uNTLi", "keywords": "Latent variable models, Stochastic variational inference, Kumaraswamy distribution, Bounded interval distributions, Reparameterization trick, Contextual multi-armed bandits, Thompson Sampling", "abstract": "Large-scale latent variable models require expressive continuous distributions that support efficient sampling and low-variance differentiation, achievable through the reparameterization trick. The Kumaraswamy (KS) distribution is both expressive and supports the reparameterization trick with a simple closed-form inverse CDF. Yet, its adoption remains limited. We identify and resolve numerical instabilities in the inverse CDF and log-pdf, exposing issues in libraries like PyTorch and TensorFlow. We then introduce simple and scalable latent variable models based on the KS, improving exploration-exploitation trade-offs in contextual multi-armed bandits and enhancing uncertainty quantification for link prediction with graph neural networks. Our results support the stabilized KS distribution as a core component in scalable variational models for bounded latent variables.", "title_embedding_index": 9758, "title_abs_embedding_index": 9783}, {"title": "CuPID: Leveraging Masked Single-Lead ECG Modelling for Enhancing the Representations", "link_suffix": "/forum?id=QjrC77Nyu6", "link": "https://openreview.net/forum?id=QjrC77Nyu6", "pdf_link": "https://openreview.net/pdf?id=QjrC77Nyu6", "keywords": "Self-Supervised Learning, Time Series, ECG", "abstract": "Wearable sensing devices, such as electrocardiogram (ECG) heart-rate monitors, will play a crucial role in the future of digital health. This constant monitoring leads to massive unlabeled datasets, making the development of unsupervised learning frameworks essential to associate these single-lead ECG signals with their anticipated clinical outcomes. While Masked Data Modelling (MDM) methods have enjoyed wide use, the idiosyncrasies of single-lead ECG data make its direct application impractical. In this paper, we present Cueing the Predictor Increments the Detailing (CuPID), a novel Self-Supervised Learning (SSL) method that adapts MDM methods for use on single-lead ECG signal data. CuPID accomplishes this via cueing spectrogram-derived context to the predictors, thus incentivizing the encoder to produce more detailed representations. This leads the class token to accommodate fine-grained information. We demonstrate that CuPID outperforms state-of-the-art methods in a variety of downstream tasks and databases, increasing the accuracy for each task from 3.6 % to 9.7%.", "title_embedding_index": 9759, "title_abs_embedding_index": 9784}, {"title": "Same Accuracy, Twice As Fast: Continual Learning Surpasses Retraining From Scratch", "link_suffix": "/forum?id=qOForsjh4q", "link": "https://openreview.net/forum?id=qOForsjh4q", "pdf_link": "https://openreview.net/pdf?id=qOForsjh4q", "keywords": "continual learning", "abstract": "Continual learning aims to enable models to adapt to new datasets without losing performance on previously learned data, often assuming prior data is no longer available. However, in many practical scenarios, both old and new data are accessible. In such cases, good performance on both datasets is typically achieved by abandoning the model trained on the previous data and re-training a new model from scratch on both datasets. This training from scratch is computationally expensive. In contrast, methods that leverage the previously trained model are worthy of investigation as they could significantly reduce computational costs. Our evaluation framework quantifies the computational savings of such methods while maintaining or exceeding the performance of training from scratch. We identify key optimization aspects - initialization, regularization, data selection, and hyper-parameters - that can each contribute to reducing computational costs. For each aspect, we propose effective first-step methods that already yield substantial computational savings. By combining these strategies, we achieve up to 2.7x reductions in computation time across various computer vision tasks, highlighting the potential for further advancements in this area.", "title_embedding_index": 9760, "title_abs_embedding_index": 9785}, {"title": "A Benchmark on Directed Graph Representation Learning in Hardware Designs", "link_suffix": "/forum?id=NKOWxemSb4", "link": "https://openreview.net/forum?id=NKOWxemSb4", "pdf_link": "https://openreview.net/pdf?id=NKOWxemSb4", "keywords": "graph neural network, hardware design, positional encoding, graph transformers", "abstract": "To keep pace with the rapid advancements in design complexity within modern computing systems, directed graph representation learning (DGRL) has become crucial, particularly for encoding circuit netlists, computational graphs, and developing surrogate models for hardware performance prediction. However, DGRL remains relatively unexplored, especially in the hardware domain, mainly due to the lack of comprehensive and user-friendly benchmarks. This study presents a novel benchmark comprising five hardware design datasets and 13 prediction tasks spanning various levels of circuit abstraction. We evaluate 21 DGRL models, employing diverse graph neural networks and graph transformers (GTs) as backbones, enhanced by positional encodings (PEs) tailored for directed graphs. Our results highlight that bidirected (BI) message passing neural networks (MPNNs) and robust PEs significantly enhance model performance. Notably, the top-performing models include PE-enhanced GTs interleaved with BI-MPNN layers and BI-Graph Isomorphism Network, both surpassing baselines across the 13 tasks. Additionally, our investigation into out-of-distribution (OOD) performance emphasizes the urgent need to improve OOD generalization in DGRL models. This benchmark, implemented with a modular codebase, streamlines the evaluation of DGRL models for both hardware and ML practitioners.", "title_embedding_index": 9761, "title_abs_embedding_index": 9786}, {"title": "Conformalized Interactive Imitation Learning: Handling Expert Shift and Intermittent Feedback", "link_suffix": "/forum?id=Ym2RNPX6la", "link": "https://openreview.net/forum?id=Ym2RNPX6la", "pdf_link": "https://openreview.net/pdf?id=Ym2RNPX6la", "keywords": "conformal prediction, interactive imitation learning", "abstract": "In interactive imitation learning (IL), uncertainty quantification offers a way for the learner (i.e. robot) to contend with distribution shifts encountered during deployment by actively seeking additional feedback from an expert (i.e. human) online. Prior works use mechanisms like ensemble disagreement or Monte Carlo dropout to quantify when black-box IL policies are uncertain; however, these approaches can lead to overconfident estimates when faced with deployment-time distribution shifts. Instead, we contend that we need uncertainty quantification algorithms that can leverage the expert human feedback received during deployment time to adapt the robot's uncertainty online. To tackle this, we draw upon online conformal prediction, a distribution-free method for constructing prediction intervals online given a stream of ground-truth labels. Human labels, however, are intermittent in the interactive IL setting. Thus, from the conformal prediction side, we introduce a novel uncertainty quantification algorithm called intermittent quantile tracking (IQT) that leverages a probabilistic model of intermittent labels, maintains asymptotic coverage guarantees, and empirically achieves desired coverage levels. From the interactive IL side, we develop ConformalDAgger, a new approach wherein the robot uses prediction intervals calibrated by IQT as a reliable measure of deployment-time uncertainty to actively query for more expert feedback. We compare ConformalDAgger to prior uncertainty-aware DAgger methods in scenarios where the distribution shift is (and isn't) present because of changes in the expert's policy. We find that in simulated and hardware deployments on a 7DOF robotic manipulator, ConformalDAgger detects high uncertainty when the expert shifts and increases the number of interventions compared to baselines, allowing the robot to more quickly learn the new behavior.", "title_embedding_index": 9762, "title_abs_embedding_index": 9787}, {"title": "Dissecting Misalignment of Multimodal Large Language Models via Influence Function", "link_suffix": "/forum?id=Y07R8h6m8e", "link": "https://openreview.net/forum?id=Y07R8h6m8e", "pdf_link": "https://openreview.net/pdf?id=Y07R8h6m8e", "keywords": "Multimodal Large Language Model, Interpretability", "abstract": "Multi-modal Large Language models (MLLMs) are always trained on data from diverse and unreliable sources,  which may contain misaligned or mislabeled text-image pairs. This frequently causes robustness issues and hallucinations, leading to performance degradation. Data valuation is an efficient way to detect and trace these misalignments. Nevertheless, existing methods are computationally expensive for MLLMs. \nWhile computationally efficient, the classical influence functions are inadequate for contrastive learning models because they were originally designed for pointwise loss. Additionally, contrastive learning involves minimizing the distance between the modalities of positive samples and maximizing the distance between the modalities of negative samples. This requires us to evaluate the influence of samples from both perspectives. To tackle these challenges, we introduce the Extended Influence Function for Contrastive Loss (ECIF), an influence function crafted for contrastive loss. ECIF considers both positive and negative samples and provides a closed-form approximation of contrastive learning models, eliminating the need for retraining. Building upon ECIF, we develop a series of algorithms for data evaluation in MLLM, misalignment detection, and misprediction trace-back tasks. Experimental results demonstrate our ECIF advances the transparency and interpretability of MLLMs by offering a more accurate assessment of data impact and model alignment compared to traditional baseline methods.", "title_embedding_index": 9763, "title_abs_embedding_index": 9788}, {"title": "Functional Gradients and Generalizations for Transformer In-Context Learning", "link_suffix": "/forum?id=uqLQjtSdFN", "link": "https://openreview.net/forum?id=uqLQjtSdFN", "pdf_link": "https://openreview.net/pdf?id=uqLQjtSdFN", "keywords": "Transformer, in-context learning", "abstract": "We examine Transformer-based in-context learning for contextual data of the form $(x_i,y_i)$ for $i=1,\\ldots,N$, and query $x_{N+1}$, where $x_i\\in\\Bbb{R}^d$ and $y_i\\sim p(Y|f(x_i))$, with $f(x)$ a latent function. This is analyzed from the perspective offunctionalgradient descent for latent $f(x)$. We initially perform this analysis from the perspective of a reproducing kernel Hilbert space (RKHS), from which an alternative kernel-averaging perspective is manifested. This leads to a generalization, allowing an interpretation of softmax attention from the perspective of the Nadaraya-Watson kernel-weighted average. We show that a single attention layer may be designed to exactly implement a functional-gradient step in this setting (for RKHS latent functions), extending prior work for the special case of real-valued $Y$ and Gaussian $p(Y|f(x))$. This is also generalized for softmax attention and non-RKHS underlying $f(x)$. Though our results hold in a general setting, we focus on categorical $Y$ with $p(Y|f(x))$ modeled as a generalized linear model (corresponding specifically to softmax probability). Multi-layered extensions are developed for this case, and through extensive experimentation we demonstrate that for categorical $Y$ a single-layer model is often highly effective for such in-context learning. We also demonstrate these ideas for real-world data, considering in-context classification of ImageNet data, showing the broad applicability of our theory beyond the commonly-studied settings of synthetic regression data.", "title_embedding_index": 9764, "title_abs_embedding_index": 9789}, {"title": "Bayesian Regularization of Latent Representation", "link_suffix": "/forum?id=VOoJEQlLW5", "link": "https://openreview.net/forum?id=VOoJEQlLW5", "pdf_link": "https://openreview.net/pdf?id=VOoJEQlLW5", "keywords": "Dimensionality Reduction, Latent Variable Models, Representation Complexity Regularization, Variational Inference, Generative Models", "abstract": "The effectiveness of statistical and machine learning methods often depends on how well data features are characterized. Developing informative and interpretable latent representations with controlled complexity is essential for visualizing data structure and for facilitating efficient model building through dimensionality reduction. Latent variable models, such as Gaussian Process Latent Variable Models (GP-LVM), have become popular for learning complex, nonlinear representations as an alternative to Principal Component Analysis (PCA). In this paper, we propose a novel class of latent variable models based on the recently introduced Q-exponential process (QEP), which generalizes GP-LVM with a tunable complexity parameter, $q>0$. Our approach, the \\emph{Q-exponential Process Latent Variable Model (QEP-LVM)}, subsumes GP-LVM as a special case when $q=2$, offering greater flexibility in managing representation complexity while enhancing interpretability. To ensure scalability, we incorporate sparse variational inference within a Bayesian training framework. We establish connections between QEP-LVM and probabilistic PCA, demonstrating its superior performance through experiments on datasets such as the Swiss roll, oil flow, and handwritten digits.", "title_embedding_index": 9765, "title_abs_embedding_index": 9790}, {"title": "FutureFill: Fast Generation from Convolutional Sequence Models", "link_suffix": "/forum?id=kTIKlSzPTL", "link": "https://openreview.net/forum?id=kTIKlSzPTL", "pdf_link": "https://openreview.net/pdf?id=kTIKlSzPTL", "keywords": "sequence modeling, online learning, fast inference", "abstract": "We address the challenge of efficient auto-regressive generation in sequence prediction models by introducing FutureFill\u2014a method for fast generation that applies to any sequence prediction algorithm based on convolutional operators. Our approach reduces the generation time requirement from linear to square root relative to the context length. Additionally, FutureFill requires a prefill cache sized only by the number of tokens generated, which is smaller than the cache requirements for standard convolutional and attention-based models. We validate our theoretical findings with experimental evidence demonstrating correctness and efficiency gains in a synthetic generation task.", "title_embedding_index": 9766, "title_abs_embedding_index": 9791}, {"title": "A Multicover Approach to Neural Networks Sample Complexity", "link_suffix": "/forum?id=fOOOyVhTYV", "link": "https://openreview.net/forum?id=fOOOyVhTYV", "pdf_link": "https://openreview.net/pdf?id=fOOOyVhTYV", "keywords": "Sample Complexity, Covering Numbers, Neural Networks", "abstract": "Covering numbers are central to estimating sample complexity. Alas, standard techniques for bounding covering numbers fail in estimating the covering numbers of many classes of neural networks. We introduce a generalization of covers, called {\\em multicovers}, which are covers w.r.t. many metrics simultaneously.Contrary to standard covering numbers, multicovering numbers behave better with the layer-wise structure in neural networks. We utilize this property to recover a recent result of \\citet{ADL2019} who defined a new notion called Approximate Description Length (ADL) to establish tight bounds on the sample complexity of networks with weights of bounded Frobenius norm. We also show that ADL and multicovering numbers are closely related.", "title_embedding_index": 9767, "title_abs_embedding_index": 9792}, {"title": "SIGHT: Single-Image Conditioned Generation of Hand Trajectories for Hand-Object Interaction", "link_suffix": "/forum?id=PytShcLwOn", "link": "https://openreview.net/forum?id=PytShcLwOn", "pdf_link": "https://openreview.net/pdf?id=PytShcLwOn", "keywords": "Human Motion Generation, Human-Object Interaction, Diffusion Models", "abstract": "We introduce a novel task of generating realistic and diverse 3D hand trajectories given a single image of an object, which could be involved in a hand-object interaction scene or pictured by itself. When humans reach for an object, appropriate trajectories naturally form to manipulate it for specific tasks in our minds. Such hand-object interaction trajectory priors can greatly benefit applications in robotics, embodied AI, augmented reality and related fields. To tackle this challenging problem, we propose the SIGHT-Fusion system, consisting of a carefully curated pipeline for extracting features at various levels of hand-object interaction details from the single image input, and a conditional motion generation diffusion model processing the extracted features. We train our method given video data with corresponding hand trajectory annotations, without supervision in the form of action labels. For the evaluation, we establish benchmarks utilizing the FPHAB and HOI4D datasets, testing our method against various baselines and metrics. We also introduce task simulators for executing the generated hand trajectories and reporting task success rates as an additional metric. Experiments show that our method generates more natural and diverse hand trajectories than baselines and presents promising generalization capability on unseen objects. The accuracy of the generated hand trajectories is confirmed in a physics simulation setting, showcasing the authenticity of the created sequences and their applicability in downstream uses.", "title_embedding_index": 9768, "title_abs_embedding_index": 9793}, {"title": "AnoLLM: Large Language Models for Tabular Anomaly Detection", "link_suffix": "/forum?id=7VkHffT5X2", "link": "https://openreview.net/forum?id=7VkHffT5X2", "pdf_link": "https://openreview.net/pdf?id=7VkHffT5X2", "keywords": "Anomaly detection, tabular data, large language models", "abstract": "We introduce AnoLLM, a novel framework that leverages large language models (LLMs) for unsupervised tabular anomaly detection. By converting tabular data into a standardized text format, we further adapt a pre-trained LLM with this serialized data, and assign anomaly scores based on the negative log likelihood generated by the LLM. Unlike traditional methods that can require extensive feature engineering, and often lose textual information during data processing, AnoLLM preserves data integrity and streamlines the preprocessing required for tabular anomaly detection. This approach can effectively handle mixed-type data, especially those containing textual features. Our empirical results indicate that AnoLLM delivers the best performance on six benchmark datasets with mixed feature types. Additionally, across 30 datasets from the ODDS library, which are predominantly numerical, AnoLLM outperforms all other candidate deep-learning based approaches on average, and equals the performance of the top classical method, k-nearest neighbors. This study marks one of the first successful application of LLMs to tabular anomaly detection.", "title_embedding_index": 9769, "title_abs_embedding_index": 9794}, {"title": "Multi-Student Diffusion Distillation for Better One-Step Generators", "link_suffix": "/forum?id=9SvRqu21m7", "link": "https://openreview.net/forum?id=9SvRqu21m7", "pdf_link": "https://openreview.net/pdf?id=9SvRqu21m7", "keywords": "Diffusion distillation, One-step generative models, Mixture of experts", "abstract": "Diffusion models achieve high-quality sample generation at the cost of a lengthy multistep inference procedure. To overcome this, diffusion distillation techniques produce student generators capable of matching or surpassing the teacher in a single step. However, the student model\u2019s inference speed is limited by the size of the teacher architecture, preventing real-time generation for computationally heavy applications. In this work, we introduce Multi-Student Distillation (MSD), a framework to distill a conditional teacher diffusion model into multiple single-step generators. Each student generator is responsible for a subset of possible conditioning data, thereby obtaining higher generation quality for the same capacity. MSD trains multiple distilled students allowing smaller sizes and, therefore, faster inference. Also, MSD offers a lightweight quality boost over single-student distillation with the same architecture. We demonstrate MSD is effective by training multiple same-sized or smaller students on single-step distillation using distribution matching and adversarial distillation techniques. With smaller students, MSD obtains competitive results with a faster inference time for single-step generation. Using same-sized students, MSD with 4 students sets new state-of-the-art results for one-step image generation: FID 1.20 on ImageNet-64\u00d764 and 8.20 on zero-shot COCO2014.", "title_embedding_index": 9770, "title_abs_embedding_index": 9795}, {"title": "GPS: A Probabilistic Distributional Similarity with Gumbel Priors for Set-to-Set Matching", "link_suffix": "/forum?id=U0SijGsCHJ", "link": "https://openreview.net/forum?id=U0SijGsCHJ", "pdf_link": "https://openreview.net/pdf?id=U0SijGsCHJ", "keywords": "Set-to-set matching, Gumbel prior distributions", "abstract": "Set-to-set matching aims to identify correspondences between two sets of unordered items by minimizing a distance metric or maximizing a similarity measure. Traditional metrics, such as Chamfer Distance (CD) and Earth Mover\u2019s Distance (EMD), are widely used for this purpose but often suffer from limitations like suboptimal performance in terms of accuracy and robustness, or high computational costs - or both. In this paper, we propose a novel, simple yet effective set-to-set matching similarity measure, GPS, based on Gumbel prior distributions. These distributions are typically used to model the extrema of samples drawn from various distributions. Our approach is motivated by the observation that the distributions of minimum distances from CD, as encountered in real world applications such as point cloud completion, can be accurately modeled using Gumbel distributions. We validate our method on tasks like few-shot image classification and 3D point cloud completion, demonstrating significant improvements over state of-the-art loss functions across several benchmark datasets. Demo code is included in the supplementary file.", "title_embedding_index": 9771, "title_abs_embedding_index": 9796}, {"title": "VeriFlow: Modeling Distributions for Neural Network Verification", "link_suffix": "/forum?id=pWrCiFpm3L", "link": "https://openreview.net/forum?id=pWrCiFpm3L", "pdf_link": "https://openreview.net/pdf?id=pWrCiFpm3L", "keywords": "neuro-symbolic verification, normalizing flows, density level sets, neural network verification", "abstract": "Formal verification has emerged as a promising method to ensure the safety and reliability of neural networks.\nNaively verifying a safety property amounts to ensuring the safety of a neural network for the whole input space irrespective of any training or test set.\nHowever, this also implies that the safety of the neural network is checked even for inputs that do not occur in the real-world and have no meaning at all, often resulting in spurious errors.\nTo tackle this shortcoming, we propose the VeriFlow architecture as a flow based density model tailored to allow any verification approach to restrict its search to the some data distribution of interest.\nWe argue that our architecture is particularly well suited for this purpose because of two major properties. \nFirst, we show that the transformation and log-density function that are defined by our model are piece-wise affine. Therefore, the model allows the usage of verifiers based on SMT with linear arithmetic.\nSecond, upper density level sets (UDL) of the data distribution take the shape of an $L^p$-ball in the latent space. As a consequence, representations of UDLs specified by a given probability are effectively computable in latent space. This allows the use of SMT and abstract interpretation approaches with fine-grained, probabilistically interpretable, control regarding on how (a)typical the inputs subject to verification are.", "title_embedding_index": 9772, "title_abs_embedding_index": 9797}, {"title": "Learning Graph Quantized Tokenizers for Transformers", "link_suffix": "/forum?id=oYSsbY3G4o", "link": "https://openreview.net/forum?id=oYSsbY3G4o", "pdf_link": "https://openreview.net/pdf?id=oYSsbY3G4o", "keywords": "Graph Learning, Graph Tokenization, Graph Transformer", "abstract": "Transformers serve as the backbone architectures of Foundational Models, where a domain-specific tokenizer helps them adapt to various domains. Graph Transformers (GTs) have recently emerged as a leading model in geometric deep learning, outperforming Graph Neural Networks (GNNs) in various graph learning tasks. However, the development of tokenizers for graphs has lagged behind other modalities, with existing approaches relying on heuristics or GNNs co-trained with Transformers. To address this, we introduce GQT (Graph Quantized Tokenizer), which decouples tokenizer training from Transformer training by leveraging multi-task graph self-supervised learning, yielding robust and generalizable graph tokens. Furthermore, the GQT utilizes Residual Vector Quantization (RVQ) to learn hierarchical discrete tokens, resulting in significantly reduced memory requirements and improved generalization capabilities. By combining the GQT with token modulation, a Transformer encoder achieves state-of-the-art performance on 16 out of 18 benchmarks, including large-scale homophilic and heterophilic datasets.", "title_embedding_index": 9773, "title_abs_embedding_index": 9798}, {"title": "Effective Text-to-Image Alignment with Quality Aware Pair Ranking", "link_suffix": "/forum?id=YeZNN6Iy6Q", "link": "https://openreview.net/forum?id=YeZNN6Iy6Q", "pdf_link": "https://openreview.net/pdf?id=YeZNN6Iy6Q", "keywords": "dpo, diffusion", "abstract": "Fine-tuning techniques such as Reinforcement Learning with Human Feedback (RLHF) and Direct Preference Optimization (DPO) allow us to steer Large Language Models (LLMs) to be align better with human preferences. Alignment is equally important in text-to-image generation. Recent adoption of DPO, specifically Diffusion-DPO, for Text-to-Image (T2I) diffusion models has proven to work effectively in improving visual appeal and prompt-image alignment. The mentioned works fine-tune on Pick-a-Pic dataset, consisting of approximately one million image preference pairs, collected via crowdsourcing at scale. However, do all preference pairs contribute equally to alignment fine-tuning? Preferences can be subjective at times and may not always translate into effectively aligning the model. In this work, we investigate the above-mentioned question. We develop a quality metric to rank image preference pairs and achieve effective Diffusion-DPO-based alignment fine-tuning.We show that the SD-1.5 and SDXL models fine-tuned using the top 5.33% of the data perform better both quantitatively and qualitatively than the models fine-tuned on the full dataset.", "title_embedding_index": 9774, "title_abs_embedding_index": 9799}]
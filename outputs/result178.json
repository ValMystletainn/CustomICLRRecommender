[{"title": "Pedestrian Motion Reconstruction: A Large-scale Benchmark via Mixed Reality Rendering with Multiple Perspectives and Modalities", "link_suffix": "/forum?id=YOpa6dTrpt", "link": "https://openreview.net/forum?id=YOpa6dTrpt", "pdf_link": "https://openreview.net/pdf?id=YOpa6dTrpt", "keywords": "Pedestrian Dynamics, Mixed Reality", "abstract": "Reconstructing pedestrian motion from dynamic sensors, with a focus on pedestrian intention, is crucial for advancing autonomous driving safety. However, this task is challenging due to data limitations arising from technical complexities, safety, and cost concerns. We introduce the Pedestrian Motion Reconstruction (PMR) dataset, which focuses on pedestrian intention to reconstruct behavior using multiple perspectives and modalities. PMR is developed from a mixed reality platform that combines real-world realism with the extensive, accurate labels of simulations, thereby reducing costs and risks. It captures the intricate dynamics of pedestrian interactions with objects and vehicles, using different modalities for a comprehensive understanding of human-vehicle interaction. Analyses show that PMR can naturally exhibit pedestrian intent and simulate extreme cases. PMR features a vast collection of data from 54 subjects interacting across 13 urban settings with 7 objects, encompassing 12,138 sequences with diverse weather conditions and vehicle speeds. This data provides a rich foundation for modeling pedestrian intent through multi-view and multi-modal insights. We also conduct comprehensive benchmark assessments across different modalities to thoroughly evaluate pedestrian motion reconstruction methods.", "title_embedding_index": 8850, "title_abs_embedding_index": 8875}, {"title": "Improving Planning with Large Language Models: A Modular Agentic Architecture", "link_suffix": "/forum?id=iNcEChuYXD", "link": "https://openreview.net/forum?id=iNcEChuYXD", "pdf_link": "https://openreview.net/pdf?id=iNcEChuYXD", "keywords": "large language models, planning, LLM agents, generalization", "abstract": "Large language models (LLMs) demonstrate impressive performance on a wide variety of tasks, but they often struggle with tasks that require multi-step reasoning or goal-directed planning. Both cognitive neuroscience and reinforcement learning (RL) have proposed a number of interacting functional components that together implement search and evaluation in multi-step decision making. These components include conflict monitoring, state prediction, state evaluation, task decomposition, and orchestration. To improve planning with LLMs, we propose an agentic architecture, the Modular Agentic Planner (MAP), in which planning is accomplished via the recurrent interaction of the specialized modules mentioned above, each implemented using an LLM. MAP improves planning through the interaction of specialized modules that break down a larger problem into multiple brief automated calls to the LLM. We evaluate MAP on three challenging planning tasks -- graph traversal, Tower of Hanoi, and the PlanBench benchmark -- as well as an NLP task requiring multi-step reasoning (strategyQA). We find that MAP yields significant improvements over both standard LLM methods (zero-shot prompting, in-context learning) and competitive baselines (chain-of-thought, multi-agent debate, and tree-of-thought), can be effectively combined with smaller and more cost-efficient LLMs (Llama3-70B), and displays superior transfer across tasks. These results suggest the benefit of a modular and multi-agent approach to planning with LLMs.", "title_embedding_index": 8851, "title_abs_embedding_index": 8876}, {"title": "Conditional Variable Flow Matching: Transforming Conditional Densities with Amortized Conditional Optimal Transport", "link_suffix": "/forum?id=Nr6V30wK1l", "link": "https://openreview.net/forum?id=Nr6V30wK1l", "pdf_link": "https://openreview.net/pdf?id=Nr6V30wK1l", "keywords": "Optimal Transport, Flow Matching, Generative Modeling, Stochastic Dynamics, Shr\u00f6dinger Bridge", "abstract": "Forecasting stochastic nonlinear dynamical systems under the influence of conditioning variables is a fundamental challenge repeatedly encountered across the biological and physical sciences. While flow-based models can impressively predict the temporal evolution of probability distributions representing possible outcomes of a specific process, existing frameworks cannot satisfactorily account for the impact of conditioning variables on these dynamics. Amongst several limitations, existing methods require training data with paired conditions and are developed for discrete conditioning variables. We propose Conditional Variable Flow Matching (CVFM), a framework for learning flows transforming conditional distributions with amortization across continuous conditioning variables -- permitting predictions across the conditional density manifold. This is accomplished through several novel advances, in particular, simultaneous sample conditioned flows over the main and conditioning variables, alongside a conditional Wasserstein metric and kernel facilitating conditional optimal transport. Collectively, these advances allow for learning system dynamics provided measurement data whose states and conditioning variables are not in correspondence. We demonstrate CVFM on a suite of increasingly challenging problems, including discrete and continuous conditional mapping benchmarks, image-to-image domain transfer, and modeling the temporal evolution of materials internal structure during manufacturing processes. We observe that CVFM results in improved performance and convergence characteristics over alternative conditional variants.", "title_embedding_index": 8852, "title_abs_embedding_index": 8877}, {"title": "Control-oriented Clustering of Visual Latent Representation", "link_suffix": "/forum?id=pPQPQ7Yd58", "link": "https://openreview.net/forum?id=pPQPQ7Yd58", "pdf_link": "https://openreview.net/pdf?id=pPQPQ7Yd58", "keywords": "neural collapse, learning from demonstration, vision-based learning control", "abstract": "We initiate a study of the geometry of the visual representation space \u2013the information channel from the vision encoder to the action decoder\u2013 in an image-based control pipeline learned from behavior cloning. Inspired by the phenomenon of neural collapse (NC) in image classification (Papyan et al., 2020), we investigate whether a similar law of clustering emerges in the visual representation space. Since image-based control is a regression task without explicitly defined classes, the central piece of the puzzle lies in determining according to what implicit classes the visual features cluster, if such a law exists.Focusing on image-based planar pushing, we posit the most important role of the visual representation in a control task is to convey a goal to the action decoder; for instance, \u201crotate the object clockwise and push it northeast\u201d. We then classify training samples of expert demonstrations into eight \u201ccontrol-oriented\u201d classes \u2013based on (a) the relative pose between the object and the target in the input or (b) the relative pose of the object induced by expert actions in the output\u2013 where one class corresponds to one relative pose orthant (REPO). Across four different instantiations of the vision-based control architecture, we report the prevalent emergence of control-oriented clustering (similar to NC) in the visual representation space according to the eight REPOs.Beyond empirical observation, we show such a law of clustering can be leveraged as an algorithmic tool to improve test-time performance when training a policy with a limited amount of expert demonstrations. Particularly, we pretrain the vision encoder using NC as a regularization to encourage control-oriented clustering of the visual features. Surprisingly, such an NC-pretrained vision encoder, when finetuned end-to-end with the action decoder, boosts the test-time performance by 10% to 35% in the low-data regime. Real-world vision-based planar pushing experiments confirmed the surprising advantage of control-oriented visual representation pretraining.", "title_embedding_index": 8853, "title_abs_embedding_index": 8878}, {"title": "Improving Cross-view Object Geo-localization: A Dual Attention Approach with Cross-view Interaction and Multi-Scale Spatial Features", "link_suffix": "/forum?id=LnRegTxsa4", "link": "https://openreview.net/forum?id=LnRegTxsa4", "pdf_link": "https://openreview.net/pdf?id=LnRegTxsa4", "keywords": "cross-view, object localization, attention mechanism", "abstract": "Cross-view object geo-localization has recently gained attention due to potential applications. Existing methods aim to capture spatial dependencies of query objects between different views through attention mechanisms to obtain spatial relationship feature maps, which are then used to predict object locations. Although promising, these approaches fail to effectively transfer information between views and do not further refine the spatial relationship feature maps. This results in the model erroneously focusing on irrelevant edge noise, thereby affecting localization performance. To address these limitations, we introduce aCross-view and Cross-attention Module (CVCAM), which performs multiple iterations of interaction between the two views, enabling continuous exchange and learning of contextual information about the query object from both perspectives. This facilitates a deeper understanding of cross-view relationships while suppressing the edge noise unrelated to the query object. Furthermore, we integrate aMulti-head Spatial Attention Module (MHSAM), which employs convolutional kernels of various sizes to extract multi-scale spatial features from the feature maps containing implicit correspondences, further enhancing the feature representation of the query object. Additionally, given the scarcity of datasets for cross-view object geo-localization, we created a new dataset calledG2Dfor the \"Ground\u2192Drone\" localization task, enriching existing datasets and filling the gap in \"Ground\u2192Drone\" localization task. Extensive experiments on the CVOGL and G2D datasets demonstrate that our proposed method achieves high localization accuracy, surpassing the current state-of-the-art.", "title_embedding_index": 8854, "title_abs_embedding_index": 8879}, {"title": "Generalizing Reasoning Problems to Longer Lengths", "link_suffix": "/forum?id=zpENPcQSj1", "link": "https://openreview.net/forum?id=zpENPcQSj1", "pdf_link": "https://openreview.net/pdf?id=zpENPcQSj1", "keywords": "length generalization, learning to reason, length extrapolation", "abstract": "Length generalization (LG) (or length extrapolation) is a challenging problem in learning to reason. It refers to the phenomenon that when trained on reasoning problems of smaller lengths/sizes, the model struggles with problems of larger sizes or lengths. Although researchers have proven that reasoning can be learned if the intermediate reasoning steps (also known as chain-of-thought (CoT)) are given in the training data, their studies only apply to within a given length (interpolation), while LG is about extrapolation beyond the given length. This paper proposes an LG theory. It first introduces a theorem to show the LG problem\u2019s root cause, highlighting what is necessary to resolve it. It then proposes and proves a sufficient condition, called (n, r)-consistency, under which LG can be achieved. Specifically, the theory says that if the CoT representation of a class of reasoning problems can satisfy the condition, LG is achievable for the class of problems. In the\nexperimental evaluation, we present CoT representations based on the proposed theory to learn to solve challenging reasoning problems like arithmetic, parity, addition, multiplication, and division using a Transformer to achieve perfect LG.", "title_embedding_index": 8855, "title_abs_embedding_index": 8880}, {"title": "Adversarial Attacks on Cooperative Multi-agent Bandits", "link_suffix": "/forum?id=GiHLTtfbB5", "link": "https://openreview.net/forum?id=GiHLTtfbB5", "pdf_link": "https://openreview.net/pdf?id=GiHLTtfbB5", "keywords": "multi-agent bandits, adversarial attacks", "abstract": "Cooperative multi-agent multi-armed bandits (CMA2B) consider the collaborative efforts of multiple agents in a shared multi-armed bandit game. We study latent vulnerabilities exposed by this collaboration and consider adversarial attacks on a few agents with the goal of influencing the decisions of the rest. More specifically, we study adversarial attacks on CMA2B in both homogeneous settings, where agents operate with the same arm set, and heterogeneous settings, where agents may have distinct arm sets. In the homogeneous setting, we propose attack strategies that, by targeting just one agent, convince all agents to select a particular target arm $T-o(T)$ times while incurring $o(T)$ attack costs in $T$ rounds. In the heterogeneous setting, we prove that a target arm attack requires linear attack costs and propose attack strategies that can force a maximum number of agents to suffer linear regrets while incurring sublinear costs and only manipulating the observations of a few target agents. Numerical experiments validate the effectiveness of our proposed attack strategies.", "title_embedding_index": 8856, "title_abs_embedding_index": 8881}, {"title": "DeeperForward: Enhanced Forward-Forward Training for Deeper and Better Performance", "link_suffix": "/forum?id=kOYnXVQCtA", "link": "https://openreview.net/forum?id=kOYnXVQCtA", "pdf_link": "https://openreview.net/pdf?id=kOYnXVQCtA", "keywords": "backpropagation-free, forward-forward, forward learning, brain-inspired computing", "abstract": "While backpropagation effectively trains models, it presents challenges related to bio-plausibility, resulting in high memory demands and limited parallelism. Recently, Hinton (2022) proposed the Forward-Forward (FF) algorithm for high-parallel local updates. FF leverages squared sums as the local update target, termed goodness, and employs L2 normalization to decouple goodness and extract new features. However, this design encounters issues with feature scaling and deactivated neurons, limiting its application mainly to shallow networks. This paper proposes a novel goodness design utilizinglayer normalizationandmean goodnessto overcome these challenges, demonstrating performance improvements even in 17-layer CNNs. Experiments on CIFAR-10, MNIST, and Fashion-MNIST show significant advantages over existing FF-based algorithms, highlighting the potential of FF in deep models. Additionally, a model parallel strategy is proposed to enhance training efficiency greatly.", "title_embedding_index": 8857, "title_abs_embedding_index": 8882}, {"title": "Adapting Prediction Sets to Distribution Shifts Without Labels", "link_suffix": "/forum?id=k2gGy2hpfx", "link": "https://openreview.net/forum?id=k2gGy2hpfx", "pdf_link": "https://openreview.net/pdf?id=k2gGy2hpfx", "keywords": "Conformal prediction, Set-valued classification", "abstract": "Recently there has been a surge of interest to deploy confidence set predictions rather than point predictions. Unfortunately, the effectiveness of such prediction sets is frequently impaired by distribution shifts in practice, and the challenge is often compounded by the lack of ground truth labels at test time. In this paper, we present a method for improving the quality of outputted prediction sets using only unlabeled data from the test domain. This is achieved by two new methods called $\\texttt{ECP}$ and $\\texttt{E{\\small A}CP}$, that sit on top of existing set-valued classification methods and adjust their intervals according to the base model's own uncertainty evaluation on the unlabeled test data. Through extensive experiments on a number of large-scale datasets and neural network architectures, we show that our methods provide consistent improvement over existing conformal prediction based baselines and nearly match the performance of fully supervised methods.", "title_embedding_index": 8858, "title_abs_embedding_index": 8883}, {"title": "MoleculeCLA: Rethinking Molecular Benchmark via Computational Ligand-Target Binding Analysis", "link_suffix": "/forum?id=P5jreWnIjV", "link": "https://openreview.net/forum?id=P5jreWnIjV", "pdf_link": "https://openreview.net/pdf?id=P5jreWnIjV", "keywords": "Molecular Benchmark, Molecular Property Prediction", "abstract": "Molecular representation learning is pivotal for various molecular property prediction tasks related to drug discovery. Robust and accurate benchmarks are essential for refining and validating current methods. Existing molecular property benchmarks derived from wet experiments, however, face limitations such as data volume constraints, unbalanced label distribution, and noisy labels. To address these issues, we construct a large-scale and precise molecular representation dataset of approximately 140,000 small molecules, meticulously designed to capture an extensive array of chemical, physical, and biological properties, derived through a robust computational ligand-target binding analysis pipeline. We conduct extensive experiments on various deep learning models, demonstrating that our dataset offers significant physicochemical interpretability to guide model development and design. Notably, the dataset's properties are linked to binding affinity metrics, providing additional insights into model performance in drug-target interaction tasks. We believe this dataset will serve as a more accurate and reliable benchmark for molecular representation learning, thereby expediting progress in the field of artificial intelligence-driven drug discovery.", "title_embedding_index": 8859, "title_abs_embedding_index": 8884}, {"title": "The Directionality of Optimization Trajectories in Neural Networks", "link_suffix": "/forum?id=JY6P45sFDS", "link": "https://openreview.net/forum?id=JY6P45sFDS", "pdf_link": "https://openreview.net/pdf?id=JY6P45sFDS", "keywords": "optimization, trajectory, redundancy, LLMs, neural networks", "abstract": "The regularity or implicit bias in neural network optimization has been typically studied via the parameter norms or the landscape curvature, often overlooking the trajectory leading to these parameters. However, properties of the trajectory --- particularly its directionality --- capture critical aspects of how gradient descent navigates the landscape to converge to a solution. In this work, we introduce the notion of a Trajectory Map and derive natural complexity measures that highlight the directional characteristics of optimization trajectories. Our comprehensive analysis across vision and language modeling tasks reveals that (a) the trajectory's directionality at the macro-level saturates by the initial phase of training, wherein weight decay and momentum play a crucial but understated role; and (b) in subsequent training, trajectory directionality manifests in micro-level behaviors, such as oscillations, for which we also provide a theoretical analysis. This implies that neural optimization trajectories have, overall, a more linear form than zig-zaggy, as evident by high directional similarity, especially towards the end. To further hone this point, we show that when the trajectory direction gathers such an inertia, optimization proceeds largely unaltered even if the network is severely decapacitated (by freezing >99% of the parameters), --- thereby demonstrating the potential for significant computational and resource savings without compromising performance.", "title_embedding_index": 8860, "title_abs_embedding_index": 8885}, {"title": "ReZero: Boosting MCTS-based Algorithms by  Backward-view and Entire-buffer Reanalyze", "link_suffix": "/forum?id=yPyb2j7oZc", "link": "https://openreview.net/forum?id=yPyb2j7oZc", "pdf_link": "https://openreview.net/pdf?id=yPyb2j7oZc", "keywords": "Deep Reinforcement Learning, Monte Carlo tree search, MuZero, efficiency optimization, reanalyze", "abstract": "Monte Carlo Tree Search (MCTS)-based algorithms, such as MuZero and its derivatives, have achieved widespread success in various decision-making domains.  These algorithms employ the reanalyze process to enhance sample efficiency from stale data, albeit at the expense of significant wall-clock time consumption. To address this issue, we propose a general approach named ReZero to boost tree search operations for MCTS-based algorithms. Specifically, drawing inspiration from the one-armed bandit model, we reanalyze training \nsamples through a backward-view reuse technique which uses the value estimation of a certain child node to save the corresponding sub-tree search time. To further adapt to this design, we periodically reanalyze the entire buffer instead of frequently reanalyzing the mini-batch. The synergy of these two designs can significantly reduce the search cost and meanwhile guarantee or even improve performance, simplifying both data collecting and reanalyzing. Experiments conducted on Atari environments, DMControl suites and board games demonstrate that ReZero substantially improves training speed while maintaining high sample efficiency.", "title_embedding_index": 8861, "title_abs_embedding_index": 8886}, {"title": "On PAC-Bayes Bounds for Linear Autoencoders", "link_suffix": "/forum?id=XYG98d5bCI", "link": "https://openreview.net/forum?id=XYG98d5bCI", "pdf_link": "https://openreview.net/pdf?id=XYG98d5bCI", "keywords": "PAC-Bayes bound, linear regression, linear autoencoder, recommender system", "abstract": "Recent research in recommender systems has surprisingly found that the Linear Autoencoder (LAE) based regression models such as EASE and EDLAE outperform the deep neural network models in top-$k$ recommendation. But the reason why LAE achieves better performance is not well understood. This paper aims to enhance the theoretical understanding on the generalizability of LAE. We first develop the PAC-Bayes bounds for LAE under different data and parameter distribution assumptions and prove their convergence. Then we propose a practical way to calculate the bound. Finally we adapt the bound to EASE and evaluate it on real world datasets, and the experiments show that our bound is nonvacuous.", "title_embedding_index": 8862, "title_abs_embedding_index": 8887}, {"title": "BalancEdit: Dynamically Balancing the Generality-Locality Trade-off in Multi-modal Model Editing", "link_suffix": "/forum?id=4WsHgA8EG1", "link": "https://openreview.net/forum?id=4WsHgA8EG1", "pdf_link": "https://openreview.net/pdf?id=4WsHgA8EG1", "keywords": "Multi-modal learning, Model editing", "abstract": "Large multi-modal models inevitably decay over time as facts change and previously learned information becomes outdated. Traditional approaches such as fine-tuning are often impractical for updating these models due to their size and complexity. Instead, direct knowledge editing within the models presents a more viable solution. Current model editing techniques, however, typically overlook the unique influence ranges of different facts, leading to compromised model performance in terms of both generality and locality. To address this issue, we introduce the concept of the generality-locality trade-off in multi-modal model editing. We develop a new model editing dataset named OKEDIT, specifically designed to effectively evaluate this trade-off. Building on this foundation, we propose \\textbf{BalancEdit}, a novel method for balanced model editing that dynamically achieves an optimal balance between generality and locality. BalancEdit utilizes a unique mechanism that generates both positive and negative samples for each fact to accurately determine its influence scope and incorporates these insights into the model's latent space using a discrete, localized codebook of edits, without modifying the underlying model weights. To our knowledge, this is the first approach explicitly addressing the generality-locality trade-off in multi-modal model editing. Our comprehensive results confirm the effectiveness of BalancEdit, demonstrating minimal trade-offs while maintaining robust editing capabilities. Our code and dataset will be available.", "title_embedding_index": 8863, "title_abs_embedding_index": 8888}, {"title": "No Algorithmic Collusion in Two-Player Blindfolded Games with Thompson Sampling", "link_suffix": "/forum?id=5q4U5gnU1g", "link": "https://openreview.net/forum?id=5q4U5gnU1g", "pdf_link": "https://openreview.net/pdf?id=5q4U5gnU1g", "keywords": "Algorithmic Collusion, blindfolded game, multi-armed bandit, Thompson Sampling", "abstract": "When two players are engaged in a repeated game with unknown payoff matrices, they may be completely unaware of the existence of each other and use multi-armed bandit algorithms to choose the actions, which is referred to as the ``blindfolded game'' in this paper. We show that when the players use Thompson sampling, the game dynamics converges to the Nash equilibrium under a mild assumption on the payoff matrices. Therefore, algorithmic collusion doesn't arise in this case despite the fact that the players do not intentionally deploy competitive strategies. To prove the convergence result, we find that the framework developed in stochastic approximation doesn't apply, because of the sporadic and infrequent updates of the inferior actions and the lack of Lipschitz continuity. We develop a novel sample-path-wise approach to show the convergence.", "title_embedding_index": 8864, "title_abs_embedding_index": 8889}, {"title": "CamoVid60K: A Large-Scale Video Dataset for Moving Camouflaged Animals Understanding", "link_suffix": "/forum?id=p4JeJ9uhEL", "link": "https://openreview.net/forum?id=p4JeJ9uhEL", "pdf_link": "https://openreview.net/pdf?id=p4JeJ9uhEL", "keywords": "camouflaged animals, video object segmentation, video object detection", "abstract": "We have been witnessing remarkable success led by the power of neural networks driven by a significant scale of training data in handling various computer vision tasks. However, less attention has been paid to monitoring the camouflaged animals, the masters of hiding themselves in the background. Robust and precise segmentation of camouflaged animals is challenging even for domain experts due to their similarity to the environment. Although several efforts have been made in camouflaged animal image segmentation, to the best of our knowledge, limited work exists on camouflaged animal video understanding (CAVU). Biologists often prefer videos for monitoring and understanding animal behaviors, as videos provide redundant information and temporal consistency. However, the scarcity of labeled video data significantly hinders progress in this area. To address these challenges, we present $\\textbf{CamoVid60K}$, a diverse, large-scale, and accurately annotated video dataset of camouflaged animals. This dataset comprises $\\textbf{218}$ videos with $\\textbf{62,774}$ finely annotated frames, covering $\\textbf{70}$ animal categories, which $\\textit{surpasses}$ all previous datasets in terms of the number of videos/frames and species included. $\\textbf{CamoVid60K}$ also offers more diverse downstream tasks in computer vision, such as camouflaged animal classification, detection, and task-specific segmentation (semantic, referring, motion), $\\textit{etc}$. We have benchmarked several state-of-the-art algorithms on the proposed $\\textbf{CamoVid60K}$ dataset, and the experimental results provide valuable insights for future research directions. Our dataset serves as a $\\textit{novel}$ and $\\textit{challenging}$ benchmark to stimulate the development of more powerful camouflaged animal video segmentation algorithms, with substantial room for further improvement.", "title_embedding_index": 8865, "title_abs_embedding_index": 8890}, {"title": "Are Synthetic Classifiers Really as Good as Real Classifiers?", "link_suffix": "/forum?id=oClr2P7V0T", "link": "https://openreview.net/forum?id=oClr2P7V0T", "pdf_link": "https://openreview.net/pdf?id=oClr2P7V0T", "keywords": "generative model, representation learning, synthetic data", "abstract": "Foundation models have achieved significant advancements across various domains, yet their training demands vast amounts of real-world data, which is becoming increasingly scarce. To address this challenge, synthetic data has garnered substantial interest as an alternative for augmenting training datasets in fields such as computer vision and natural language processing. However, skepticism remains regarding whether synthetic classifiers can match the performance of those trained on real data. In this paper, we investigate this question by conducting a detailed analysis within the realm of visual tasks, comparing classifiers trained on synthetic versus real data using CLIP and ViT. Our results reveal that synthetic classifiers exhibit deficiencies in a range of challenging real-world scenarios, such as fine-grained classification, extreme object scales and extreme brightness despite achieving comparable overall accuracy to their real-data-trained counterparts. We find that the limitations of synthetic classifiers can be traced back to the limitations of current generative models in capturing the complexity and diversity of real-world data in these aspects. To mitigate these issues efficiently, we explore \\textbf{RealTune}, a simple method that enhances synthetic classifiers by finetuning them with a small amount of real data. Experimental evaluations demonstrate that RealTune significantly improves the performance of synthetic classifiers using only a limited real dataset (e.g., 40k images,  3% of ImageNet) with minimal training time (e.g., 1hour on a single NVIDIA RTX 3090 GPU). Our findings indicate that while synthetic data is a valuable resource, integrating real and synthetic data is essential to achieve robust and efficient classifiers. This work underscores the necessity of leveraging both data types to bridge the performance gap and enhance the overall effectiveness of foundation models.", "title_embedding_index": 8866, "title_abs_embedding_index": 8891}, {"title": "Dual-Forecaster: A Multimodal Time Series Model Integrating Descriptive and Predictive Texts", "link_suffix": "/forum?id=QE1ClsZjOQ", "link": "https://openreview.net/forum?id=QE1ClsZjOQ", "pdf_link": "https://openreview.net/pdf?id=QE1ClsZjOQ", "keywords": "time series forecasting, multimodal time series model, multimodal comprehension", "abstract": "Time series forecasting plays a vital role for decision-making across a wide range of real-world domains, which has been extensively studied. Most existing single-modal models rely solely on numerical series, which suffer from the limitations imposed by insufficient information. Recent studies have revealed that multimodal models can address the core issue by integrating textual information. However, these models focus on either historical or future textual information, overlooking the unique contributions each plays in time series forecasting. Besides, these models fail to grasp the intricate relationships between textual and time series data, constrained by their moderate capacity for multimodal comprehension. To tackle these challenges, we propose Dual-Forecaster, a pioneering multimodal time series model that combines both descriptively historical textual information and predictive textual insights, leveraging advanced multimodal comprehension capability. We begin by developing the historical text-time series contrastive loss to align the descriptively historical textual data and corresponding time series data, followed by encoding multimodal text-time series representations between them through the history-oriented modality interaction module, and then combining predictive textual data through the future-oriented modality interaction module to ensure textual insights-following forecasting. Our comprehensive evaluations on synthetic dataset and captioned-public datasets demonstrate that Dual-Forecaster is a distinctly effective multimodal time series model that outperforms or is comparable to other state-of-the-art models, highlighting the superiority of integrating textual information for time series forecasting. This work opens new avenues in the integration of textual information with numerical time series data for multimodal time series analysis.", "title_embedding_index": 8867, "title_abs_embedding_index": 8892}, {"title": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations", "link_suffix": "/forum?id=7zsWni0qzC", "link": "https://openreview.net/forum?id=7zsWni0qzC", "pdf_link": "https://openreview.net/pdf?id=7zsWni0qzC", "keywords": "Gene Regulatory Network, Dynamical Systems, Single-cell RNA-sequencing, Neural ODE, Causal model, Causal discovery", "abstract": "Modern high-throughput biological datasets with thousands of perturbations provide the opportunity for large-scale discovery of causal graphs that represent the regulatory interactions between genes. Numerous methods have been proposed to infer a directed acyclic graph (DAG) corresponding to the underlying gene regulatory network (GRN) that captures causal gene relationships. However, existing models have restrictive assumptions (e.g. linearity, acyclicity), limited scalability, and/or fail to address the dynamic nature of biological processes such as cellular differentiation. We propose PerturbODE, a novel framework that incorporates biologically informative neural ordinary differential equations (neural ODEs) to model cell state trajectories under perturbations and derive the causal GRN from the neural ODE's parameters. We demonstrate PerturbODE's efficacy in trajectory prediction and GRN inference across simulated and real over-expression datasets.", "title_embedding_index": 8868, "title_abs_embedding_index": 8893}, {"title": "DEAL: High-Efficacy Privacy Attack on Retrieval-Augmented Generation Systems via LLM Optimizer", "link_suffix": "/forum?id=sx8dtyZT41", "link": "https://openreview.net/forum?id=sx8dtyZT41", "pdf_link": "https://openreview.net/pdf?id=sx8dtyZT41", "keywords": "Retrieval-Augmented Generation, Data Privacy", "abstract": "Retrieval-Augmented Generation (RAG) technology provides a powerful means of combining private databases with large language models (LLMs). \nIn a typical RAG system, a set of documents is retrieved from a private database and inserted into the final prompt, which is then fed into the LLM.\nExisting research has shown that an attacker can use a simple manually designed attack suffix to induce LLM to output private documents in prompt with high probability.\nHowever, in this paper, we demonstrate that the privacy leakage risk exhibited by using this simple manual attack suffix is significantly underestimated.\nWe propose a novel attack method called Documents Extraction Attack via LLM-Optimizer (DEAL). \nDEAL leverages an LLM as optimizer to iteratively refine attack strings, inducing the RAG model to reveal private data in its responses. \nNotably, our attack method does not require any knowledge about the target LLM, including its gradient information or model type. \nInstead, the attack can be executed solely through query access to the RAG model. \nWe evaluate the effectiveness of our attack on multiple LLM architectures, including Qwen2, Llama3.1, and GPT-4o, across different attack tasks such as Entire Documents Extraction and Private Identity Information (PII) Extraction. \nUnder the same permission setting as the existing method, the Mean Rouge-L Recall (MRR) of our method  can reach more than 0.95 on average in the Entire Documents Extraction task, and we can steal PII from the retrieved documents with close to 99% accuracy in the PII Extraction task, highlighting the risk of privacy leakage in RAG systems.", "title_embedding_index": 8869, "title_abs_embedding_index": 8894}, {"title": "Overcoming Catastrophic Forgetting in Federated Class-Incremental Learning via Federated Global Twin Generator", "link_suffix": "/forum?id=o2arTYxsXd", "link": "https://openreview.net/forum?id=o2arTYxsXd", "pdf_link": "https://openreview.net/pdf?id=o2arTYxsXd", "keywords": "federated learning, continual learning, federated continual learning, generative model", "abstract": "Federated Class-Incremental Learning (FCIL) increasingly becomes essential in the decentralized setting, where it enables multiple participants to collaboratively train a global model to perform well on a sequence of tasks without sharing their private data. In FCIL, conventional Federated Learning algorithms such as FedAvg often suffer from catastrophic forgetting, resulting in significant performance declines on earlier tasks. Recent works based on generative models produce synthetic images to help mitigate this issue across all classes. However, these approaches' testing accuracy in previous classes is still much lower than recent classes, i.e., having better plasticity than stability. To overcome these issues, this paper presents Federated Global Twin Generator (FedGTG), an FCIL framework that exploits generative-model training on the global side without accessing client data. Specifically, the server trains a data generator and a feature generator to create two types of information from all seen classes. Then, it sends the synthetic data to the client. The clients then use feature-direction-controlling losses to make the local models retain knowledge and learn new tasks well. We extensively analyze the robustness of FedGTG on natural images and its ability to converge to flat local minima and achieve better predicting confidence (calibration). Experimental results on CIFAR-10, CIFAR-100, and tiny-ImageNet demonstrate the improvements in accuracy and forgetting measures of FedGTG as well as the robustness of domain shifts compared to previous frameworks.", "title_embedding_index": 8870, "title_abs_embedding_index": 8895}, {"title": "LCSim: A Large-Scale Controllable Traffic Simulator", "link_suffix": "/forum?id=REprQnylmC", "link": "https://openreview.net/forum?id=REprQnylmC", "pdf_link": "https://openreview.net/pdf?id=REprQnylmC", "keywords": "Traffic Simulation, Diffusion, Autonomous Driving", "abstract": "With the rapid growth of urban transportation and the continuous progress in autonomous driving, a demand for robust benchmarking autonomous driving algorithms has emerged, calling for accurate modeling of large-scale urban traffic scenarios with diverse vehicle driving styles. Traditional traffic simulators, such as SUMO, often depend on hand-crafted scenarios and rule-based models, where vehicle actions are limited to speed adjustment and lane changes, making it difficult for them to create realistic traffic environments. In recent years, real-world traffic scenario datasets have been developed alongside advancements in autonomous driving, facilitating the rise of data-driven simulators and learning-based simulation methods. However, current data-driven simulators are often restricted to replicating the traffic scenarios and driving styles within the datasets they rely on, limiting their ability to model multi-style driving behaviors observed in the real world. We propose \\textit{LCSim}, a large-scale controllable traffic simulator. First, we define a unified data format for traffic scenarios and provide tools to construct them from multiple data sources, enabling large-scale traffic simulation. Furthermore, we integrate a diffusion-based vehicle motion planner into LCSim to facilitate realistic and diverse vehicle modeling. Under specific guidance, this allows for the creation of traffic scenarios that reflect various driving styles. Leveraging these features, LCSim can provide large-scale, realistic, and controllable virtual traffic environments. Codes and demos are available athttps://anonymous.4open.science/r/LCSim-0C7A.", "title_embedding_index": 8871, "title_abs_embedding_index": 8896}, {"title": "Combating Hidden Vulnerabilities in Computer Vision Tasks", "link_suffix": "/forum?id=zWYHsbuedA", "link": "https://openreview.net/forum?id=zWYHsbuedA", "pdf_link": "https://openreview.net/pdf?id=zWYHsbuedA", "keywords": "Computer Vision, Hidden Vulnerabilities", "abstract": "Backdoor attacks are among the most prominent security threats to deep learning models. Traditional backdoors leverage static trigger patterns, such as a red square patch. They can be removed by existing defense techniques.\nHowever, recent backdoor attacks use semantic features as the trigger. Existing techniques largely fall short when facing such backdoors. In this paper, we propose a novel backdoor mitigation technique, MARTINI, that effectively mitigates various backdoors. It features a specially designed trigger reverse-engineering method for constructing backdoor samples that have a similar attack effect as the injected backdoor across a spectrum of attacks. Using the samples derived from MARTINI, paired with the correct labels, in training can remove injected backdoor effects in deep learning models. Our evaluation on 14 types of backdoor attacks in image classification shows that MARTINI can reduce the attack success rate (ASR) from 96.56% to 5.17% on average, outperforming 12 state-of-the-art backdoor removal approaches, which at best reduce the ASR to 26.56%. It can also mitigate backdoors in self-supervised learning and object detection.", "title_embedding_index": 8872, "title_abs_embedding_index": 8897}, {"title": "T-Stitch: Accelerating Sampling in Pre-Trained Diffusion Models with Trajectory Stitching", "link_suffix": "/forum?id=2mqb8bPHeb", "link": "https://openreview.net/forum?id=2mqb8bPHeb", "pdf_link": "https://openreview.net/pdf?id=2mqb8bPHeb", "keywords": "diffusion model, transformers, model stitching", "abstract": "Sampling from diffusion probabilistic models (DPMs) is often expensive for high-quality image generation and typically requires many steps with a large model. In this paper, we introduce sampling Trajectory Stitching (T-Stitch), a simple yet efficient technique to improve the sampling efficiency with little or no generation degradation. Instead of solely using a large DPM for the entire sampling trajectory, T-Stitch first leverages a smaller DPM in the initial steps as a cheap drop-in replacement of the larger DPM and switches to the larger DPM at a later stage. Our key insight is that different diffusion models learn similar encodings under the same training data distribution and smaller models are capable of generating good global structures in the early steps. Extensive experiments demonstrate that T-Stitch is training-free, generally applicable for different architectures, and complements most existing fast sampling techniques with flexible speed and quality trade-offs. On DiT-XL, for example, 40% of the early timesteps can be safely replaced with a 10x faster DiT-S without performance drop on class-conditional ImageNet generation. We further show that our method can also be used as a drop-in technique to not only accelerate the popular pretrained stable diffusion (SD) models but also improve the prompt alignment of stylized SD models from the public model zoo. Finally, the explicit model allocation strategy of T-Stitch significantly reduces the need of training or searching, delivering high deployment efficiency.", "title_embedding_index": 8873, "title_abs_embedding_index": 8898}, {"title": "Latent Wasserstein Adversarial Imitation Learning", "link_suffix": "/forum?id=CiEOW1CdKc", "link": "https://openreview.net/forum?id=CiEOW1CdKc", "pdf_link": "https://openreview.net/pdf?id=CiEOW1CdKc", "keywords": "Adversarial Imitation Learning, Wasserstein Distance", "abstract": "Imitation Learning (IL) enables agents to mimic expert behavior by learning from demonstrations. However, traditional IL methods require large amounts of medium-to-high-quality demonstrations as well as actions of expert demonstrations, both of which are often unavailable. To address these limitations, we propose LWAIL (Latent Wasserstein Adversarial Imitation Learning), a novel adversarial imitation learning framework that focuses on state-only distribution matching by leveraging the Wasserstein distance computed in a latent space. To obtain a meaningful latent space, our approach includes a pre-training stage, where we employ the Intention Conditioned Value Function (ICVF) model to capture the underlying structure of the state space using randomly generated state-only data. This enhances the policy's understanding of state transitions, enabling the learning process to use only one or a few state-only expert episodes to achieve expert-level performance. Through experiments on multiple MuJoCo environments, we demonstrate that our method outperforms prior Wasserstein-based IL methods and prior adversarial IL methods, achieving better sample efficiency and policy robustness across various tasks.", "title_embedding_index": 8874, "title_abs_embedding_index": 8899}]
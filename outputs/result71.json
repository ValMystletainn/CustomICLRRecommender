[
    {
        "title": "Understanding the learned look-ahead behavior of chess neural networks",
        "link_suffix": "/forum?id=Tl8EzmgsEp",
        "link": "https://openreview.net/forum?id=Tl8EzmgsEp",
        "pdf_link": "https://openreview.net/pdf?id=Tl8EzmgsEp",
        "keywords": "model behavior attribution, look-ahead planning, mechanistic interpretability",
        "abstract": "We investigate the look-ahead capabilities of chess-playing neural networks, specifically focusing on the Leela Chess Zero policy network. We build on the work of Jenner et al. by analyzing the model's ability to consider future moves and alternative sequences beyond the immediate next move. Our findings reveal that the network's look-ahead behavior is highly context-dependent, varying significantly based on the specific chess position. We demonstrate that the model can process information about board states up to seven moves ahead, utilizing similar internal mechanisms across different future time steps. Additionally, we provide evidence that the network considers multiple possible move sequences rather than focusing on a single line of play. These results offer new insights into the emergence of sophisticated look-ahead capabilities in neural networks trained on strategic tasks, contributing to our understanding of AI reasoning in complex domains. Our work also showcases the effectiveness of interpretability techniques in uncovering cognitive-like processes in artificial intelligence systems."
    },
    {
        "title": "Robust Transfer of Safety-Constrained Reinforcement Learning Agents",
        "link_suffix": "/forum?id=rvXdGL4pCJ",
        "link": "https://openreview.net/forum?id=rvXdGL4pCJ",
        "pdf_link": "https://openreview.net/pdf?id=rvXdGL4pCJ",
        "keywords": "Reinforcement Learning, Safe Transfer, Adversarial Training, Robustness",
        "abstract": "Reinforcement learning (RL) often relies on trial and error, which may cause undesirable outcomes. As a result, standard RL is inappropriate for safety-critical applications. To address this issue, one may train a safe agent in a controlled environment (where safety violations are allowed) and then transfer it to the real world (where safety violations may have disastrous consequences). Prior work has made this transfer safe as long as the new environment preserves the safety-related dynamics. However, in most practical applications, differences or shifts in dynamics between the two environments are inevitable, potentially leading to safety violations after the transfer. This work aims to guarantee safety even when the new environment has different (safety-related) dynamics. In other words, we aim to make the process of safe transfer robust. Our methodology (1) robustifies an agent in the controlled environment and (2) provably provides---under mild assumption---a safe transfer to new environments. The empirical evaluation shows that this method yields policies that are robust against changes in dynamics, demonstrating safety after transfer to a new environment."
    },
    {
        "title": "GAN-based NeRF Noise Simulation in Mesh Denoising Task",
        "link_suffix": "/forum?id=J9SsCtTLga",
        "link": "https://openreview.net/forum?id=J9SsCtTLga",
        "pdf_link": "https://openreview.net/pdf?id=J9SsCtTLga",
        "keywords": "Generative networks, Noise generation, 3D Denoising, Pointclouds",
        "abstract": "In the present paper, we propose a new approach and a dataset for generating NeRF-like noise on the mesh surface.  Our approach is based on GAN and was trained on a dataset we collected using real NeRF noise. The core idea of our method lies in the use of graph convolutions in the generator.Our model demonstrates generated NeRF-like noise more accurate than other methods by mesh denoising benchmarking. We also present a new NeRF noise analysis approach HTPH based on a conditional probability model to measure the similarity of mesh noise."
    },
    {
        "title": "Linear Bandits with Partially Observable Features",
        "link_suffix": "/forum?id=aKFFpfiJHy",
        "link": "https://openreview.net/forum?id=aKFFpfiJHy",
        "pdf_link": "https://openreview.net/pdf?id=aKFFpfiJHy",
        "keywords": "Linear Bandits, Partially Observable Features, Doubly Robust",
        "abstract": "We introduce a novel linear bandit problem where a subset of features is latent, resulting in partial access to reward information and spurious estimates.\nWithout properly addressing the latent features, the regret grows linearly over the decision epoch $T$ while improving the regret bound is challenging because their dimension and relationship with rewards are not available.\nWe propose a novel analysis to handle the latent features and an algorithm that achieves a regret bound sublinear in $T$.\nThe core of the algorithm lies in (i) augmenting basis vectors orthogonal to the observable feature space, and (ii) developing an efficient doubly robust estimator that further improves the regret bound.\nWith these two ingredients, our algorithm achieves a regret bound of $\\tilde{O}(\\sqrt{(d + d_h)T})$, where $d$ is the dimension of observable features, and $d_h$ is the \\emph{unknown} dimension of the unobserved features that affects the reward. \nCrucially, our algorithm does not rely on prior knowledge of the unobserved feature space, which expands as more features become hidden.\nNumerical experiments confirm that our algorithm outperforms both non-contextual multi-armed bandits and other linear bandit algorithms."
    },
    {
        "title": "Foveated Dynamic Transformer: Robust and Efficient Perception Inspired by the Human Visual System",
        "link_suffix": "/forum?id=FiGDhrt1JL",
        "link": "https://openreview.net/forum?id=FiGDhrt1JL",
        "pdf_link": "https://openreview.net/pdf?id=FiGDhrt1JL",
        "keywords": "Transformers, Vision Transformers, Human Visual System, Foveation",
        "abstract": "The human visual system (HVS) employs foveated sampling and eye movements to achieve efficient perception, conserving both metabolic energy and computational resources. Drawing inspiration from this efficiency, we introduce the $\\textit{Foveated Dynamic Vision Transformer (FDT)}$, a novel architecture that integrates these mechanisms into a vision transformer framework. Unlike existing models, the FDT uses a single-pass strategy, utilizing fixation and foveation modules to enhance computational efficiency and accuracy. The fixation module identifies fixation points to filter out irrelevant information, while the foveation module generates foveated embeddings with multi-scale information. Our findings show that the FDT achieves superior accuracy and computational efficiency, with a 34% reduction in multiply-accumulate operations. Additionally, the FDT exhibits robustness against various types of noise and adversarial attacks without specific training for these challenges. These attributes make the FDT a significant step forward in creating artificial neural networks that mirror the efficiency, robustness, and adaptability of the HVS."
    },
    {
        "title": "Towards better generalization: Weight Decay induces low-rank bias for neural networks",
        "link_suffix": "/forum?id=3zw9NhLhBM",
        "link": "https://openreview.net/forum?id=3zw9NhLhBM",
        "pdf_link": "https://openreview.net/pdf?id=3zw9NhLhBM",
        "keywords": "Low-rank bias, ReLU Neural Networks, Generalization Error, Implicit regularization, SGD, Weight Decay",
        "abstract": "We study the implicit bias towards low-rank weight matrices when training neural networks (NN) with Weight Decay (WD). \nWe prove that when a ReLU NN is sufficiently trained with Stochastic Gradient Descent (SGD) and WD, its weight matrix is approximately a rank-two matrix. \nEmpirically, we demonstrate that WD is a necessary condition for inducing this low-rank bias across both regression and classification tasks. \nOur work differs from previous studies as our theoretical analysis does not rely on common assumptions regarding the training data distribution, optimality of weight matrices, or specific training procedures. \nFurthermore, by leveraging the low-rank bias, we derive improved generalization error bounds and provide numerical evidence showing that better generalization can be achieved.\nThus, our work offers both theoretical and empirical insights into the strong generalization performance of SGD when combined with WD."
    },
    {
        "title": "Residual Stream Analysis with Multi-Layer SAEs",
        "link_suffix": "/forum?id=XAjfjizaKs",
        "link": "https://openreview.net/forum?id=XAjfjizaKs",
        "pdf_link": "https://openreview.net/pdf?id=XAjfjizaKs",
        "keywords": "sparse autoencoders, mechanistic interpretability, language models",
        "abstract": "Sparse autoencoders (SAEs) are a promising approach to interpreting the internal representations of transformer language models.\nHowever, SAEs are usually trained separately on each transformer layer, making it difficult to use them to study how information flows across layers.\nTo solve this problem, we introduce the multi-layer SAE (MLSAE): a single SAE trained on the residual stream activation vectors from every transformer layer.\nGiven that the residual stream is understood to preserve information across layers, we expected MLSAE latents to 'switch on' at a token position and remain active at later layers.\nInterestingly, we find that individual latents are often active at a single layer for a given token or prompt, but this layer may differ for different tokens or prompts.\nWe quantify these phenomena by defining a distribution over layers and considering its variance.\nWe find that the variance of the distributions of latent activations over layers is about two orders of magnitude greater when aggregating over tokens compared with a single token.\nFor larger underlying models, the degree to which latents are active at multiple layers increases, which is consistent with the fact that the residual stream activation vectors at adjacent layers become more similar.\nFinally, we relax the assumption that the residual stream basis is the same at every layer by applying pre-trained tuned-lens transformations, but our findings remain qualitatively similar.\nOur results represent a new approach to understanding how representations change as they flow through transformers."
    },
    {
        "title": "The Same but Different: Structural Similarities and Differences in Multilingual Language Modeling",
        "link_suffix": "/forum?id=NCrFA7dq8T",
        "link": "https://openreview.net/forum?id=NCrFA7dq8T",
        "pdf_link": "https://openreview.net/pdf?id=NCrFA7dq8T",
        "keywords": "multilinguality, interpretability",
        "abstract": "We employ new tools from mechanistic interpretability in order to ask whether the internal structure of large language models (LLMs) shows correspondence to the linguistic structures which underlie the languages on which they are trained. In particular, we ask (1) when two languages employ the same morphosyntactic processes, do LLMs handle them using shared internal circuitry? and (2) when two languages require different morphosyntactic processes, do LLMs handle them using different internal circuitry? Using English and Chinese multilingual and monolingual models, we analyze the internal circuitry involved in two tasks. We find evidence that models employ the same circuit to handle the same syntactic process independently of the language in which it occurs, and that this is the case even for monolingual models trained completely independently. Moreover, we show that multilingual models employ language-specific components (attention heads and MLPs) when needed to handle linguistic processes (e.g., morphological marking) that only exist in some languages. Together, our results provide new insights into how LLMs trade off between exploiting common structures and preserving linguistic differences when tasked with modeling multiple languages simultaneously."
    },
    {
        "title": "Measuring and Controlling Solution Degeneracy across Task-Trained Recurrent Neural Networks",
        "link_suffix": "/forum?id=ypBYdetYd9",
        "link": "https://openreview.net/forum?id=ypBYdetYd9",
        "pdf_link": "https://openreview.net/pdf?id=ypBYdetYd9",
        "keywords": "Recurrent Neural Network, Dynamical System, Neural Computation, Computational Neuroscience",
        "abstract": "Task-trained recurrent neural networks (RNNs) are versatile models of dynamical processes widely used in machine learning and neuroscience. While RNNs are easily trained to perform a wide range of tasks, the nature and extent of the degeneracy in the resultant solutions (i.e., the variability across trained RNNs) remain poorly understood. Here, we provide a unified framework for analyzing degeneracy across three levels: behavior, neural dynamics, and weight space. We analyzed RNNs trained on diverse tasks across machine learning and neuroscience domains, including N-bit flip-flop, sine wave generation, delayed discrimination, and path integration. \nOur key finding is that the variability across RNN solutions, quantified on the basis of neural dynamics and trained weights, depends primarily on network capacity and task characteristics such as complexity. We introduce information-theoretic measures to quantify task complexity and demonstrate that increasing task complexity consistently reduces degeneracy in neural dynamics and generalization behavior while increasing degeneracy in weight space. These relationships hold across diverse tasks and can be used to control the degeneracy of the solution space of task-trained RNNs. Furthermore, we provide several strategies to control solution degeneracy, enabling task-trained RNNs to learn more consistent or diverse solutions as needed. We envision that these insights will lead to more reliable machine learning models and could inspire strategies to better understand and control degeneracy observed in neuroscience experiments."
    },
    {
        "title": "Adaptive Log-Exp Perturbations for Secure AI Image Compression",
        "link_suffix": "/forum?id=f47c05mcOj",
        "link": "https://openreview.net/forum?id=f47c05mcOj",
        "pdf_link": "https://openreview.net/pdf?id=f47c05mcOj",
        "keywords": "neural image compression, adversarial attack, adaptive perturbation",
        "abstract": "AI image compression has outperformed traditional methods in both efficiency and quality but remains vulnerable to adversarial attacks. Most attacks on deep neural networks (DNNs) involve adding small perturbations to the input image to deceive the system and produce incorrect results. While simple, these additive perturbations affect pixels uniformly across different intensity levels, from dark to bright regions. However the human eye is less sensitive to variations in dark areas than in bright ones, making noise in brighter areas more visible. This observation suggests a novel attack strategy that minimizes the visibility of adversarial noise through adaptive perturbations. To achieve this, we propose a nonlinear log-exp perturbation, which applies more noise to dark pixels while minimizing its impact on bright areas.We evaluated this perturbation model in two scenarios: one  distorts the output of decompression models and another one increases the bit rate of compressed images without visibly affecting quality. Our findings offer new strategies to protect AI-driven image compression systems, ensuring both security and performance in practical applications."
    },
    {
        "title": "OD-Stega: LLM-Based Near-Imperceptible Steganography via Optimized Distributions",
        "link_suffix": "/forum?id=IQafqgqDzF",
        "link": "https://openreview.net/forum?id=IQafqgqDzF",
        "pdf_link": "https://openreview.net/pdf?id=IQafqgqDzF",
        "keywords": "LLLM, steganography, arithmetic coding",
        "abstract": "We consider coverless steganography where a Large Language Model (LLM) drives an arithmetic coding decoder to generate stego-text. An efficient method should embed secret message bits in as few language tokens as possible, while still keeping the stego-text natural and fluent. We show that on the individual token level, this problem is mathematically equivalent to maximizing the entropy of a replacement probability distribution of the next token generation, subject to a constraint on the KL divergence between the chosen probability distribution and the original distribution given by the LLM. A closed-form solution is provided for the optimization problem, which can be computed efficiently. Several important practical issues are also tackled: 1) The combination of the optimized distribution and the vocabulary truncating technique is considered, 2) An often-overlooked tokenization mismatch issue is resolved with a simple prompt selection approach, and 3) The combination of the optimized distribution with other sequence-level selection heuristics to further enhance the efficiency and reliability is studied."
    },
    {
        "title": "Median Clipping for Zeroth-order Non-Smooth Convex Optimization and Multi Arm Bandit Problem with Heavy-tailed Symmetric Noise",
        "link_suffix": "/forum?id=Ah3n8U3kRT",
        "link": "https://openreview.net/forum?id=Ah3n8U3kRT",
        "pdf_link": "https://openreview.net/pdf?id=Ah3n8U3kRT",
        "keywords": "optimization, median clipping, heavy tails, multi arm bandit",
        "abstract": "In this paper, we consider non-smooth convex optimization with a zeroth-order oracle corrupted bysymmetricstochastic noise. Unlike the existing high-probability results requiring the noise to have bounded $\\kappa$-th moment with $\\kappa \\in (1,2]$, our results allow even heavier noise with any $\\kappa > 0$, e.g., the noise distribution can have unbounded expectation. Our convergence rates match the best-known ones for the case of the bounded variance. To achieve this, we build the unbiasedmediangradient estimate with bounded second moment as the mini-batched median of the sampled gradient differences. We apply this technique to the stochastic multi-armed bandit problem with heavy-tailed distribution of rewards and achieve $\\tilde{O}(\\sqrt{dT})$ regret. We demonstrate the performance of our zeroth-order and MAB algorithms for different $\\kappa$ on synthetic and real-world data. Our methods do not lose to SOTA approaches, moreover, they dramatically outperform SOTA for $\\kappa \\leq 1$."
    },
    {
        "title": "Fair Image Generation from Pre-trained Models by Probabilistic Modeling",
        "link_suffix": "/forum?id=GXXQfSpJNI",
        "link": "https://openreview.net/forum?id=GXXQfSpJNI",
        "pdf_link": "https://openreview.net/pdf?id=GXXQfSpJNI",
        "keywords": "Image Generation, Fairness, Probabilistic Modeling",
        "abstract": "The production of high-fidelity images by generative models has been transformative to the space of artificial intelligence. Yet, while the generated images are of high quality, the images tend to mirror biases present in the dataset they are trained on. While there has been an influx of work to tackle this issue, existing works typically rely on fine-tuning an existing generative model which requires costly retraining time. In this paper, we use a family of tractable probabilistic models called probabilistic circuits (PCs), which can be equipped to a pre-trained generative model to produce fair images without fine-tuning. We show that for a given trained generative model, our method only requires a small fair reference dataset to train the PC, removing the need to retrain the generative model on a large dataset. Our experimental results show that the proposed method achieves a balance between training resources and ensuring fairness and quality of generated images."
    },
    {
        "title": "Remote Reinforcement Learning with Communication Constraints",
        "link_suffix": "/forum?id=fBSc0c1IXJ",
        "link": "https://openreview.net/forum?id=fBSc0c1IXJ",
        "pdf_link": "https://openreview.net/pdf?id=fBSc0c1IXJ",
        "keywords": "reinforcement learning, communication, source coding, compression, sampling, channel simulation",
        "abstract": "We introduce the novel problem of remote reinforcement learning (RRL) with a communication constraint, in which the actor that takes the actions in the environment lacks direct access to the reward signal. Instead, the rewards are observed by a controller, which communicates with the agent through a communication-constrained channel. This can model a remote control scenario over a wireless channel, where the communication link from the controller to the agent has limited capacity due to power, bandwidth, or delay constraints. In the proposed solution, rather than transmitting the reward values to the agent over the rate-limited channel, the controller learns the optimal policy, and at each round, signals the action that the agent should take over the channel. However, instead of sending the precise action--which can be prohibitive when the action set is large--we use an importance sampling approach to reduce the communication load, which allows the agent to sample an action from the current policy. The actor, sampling from the desired policy at each turn, can also learn the optimal policy, albeit at a slower pace, using supervised learning. We exploit the learned policy at the actor to further reduce the communication load. Our solution, called Guided Remote Action Sampling Policy (GRASP), exhibits a significant reduction in communication requirements, achieving an average of 12-fold decrease in data transmission across all experiments, and 50-fold reduction for environments with continuous action spaces. We also show the applicability of GRASP beyond single-agent scenarios, including parallel and multi-agent environments."
    },
    {
        "title": "Embedding Safety into RL: A New Take on Trust Region Methods",
        "link_suffix": "/forum?id=wQkERVYqui",
        "link": "https://openreview.net/forum?id=wQkERVYqui",
        "pdf_link": "https://openreview.net/pdf?id=wQkERVYqui",
        "keywords": "reinforcement learning, safety, information geometry",
        "abstract": "Reinforcement Learning (RL) agents are able to solve a wide variety of tasks but are prone to producing unsafe behaviors.\nConstrained Markov Decision Processes (CMDPs) provide a popular framework for incorporating safety constraints. \nHowever, common solution methods often compromise reward maximization by being overly conservative or allow unsafe behavior during training.\nWe propose Constrained Trust Region Policy Optimization (C-TRPO), a novel approach that modifies the geometry of the policy space based on the safety constraints and yields trust regions composed exclusively of safe policies, ensuring constraint satisfaction throughout training.\nWe theoretically study the convergence and update properties of C-TRPO and highlight connections to TRPO, Natural Policy Gradient (NPG), and Constrained Policy Optimization (CPO).\nFinally, we demonstrate experimentally that C-TRPO significantly reduces constraint violations while achieving competitive reward maximization compared to state-of-the-art CMDP algorithms."
    },
    {
        "title": "Disentangling Representations through Multi-task Learning",
        "link_suffix": "/forum?id=yVGGtsOgc7",
        "link": "https://openreview.net/forum?id=yVGGtsOgc7",
        "pdf_link": "https://openreview.net/pdf?id=yVGGtsOgc7",
        "keywords": "zero-shot generalization, disentanglement, representation learning, multi-task learning, interpretability, computational neuroscience, evidence accumulation, world models, cognitive maps, continuous attractors, RNNs, transformers",
        "abstract": "Intelligent perception and interaction with the world hinges on internal representations that capture its underlying structure (\"disentangled\" or \"abstract\" representations). Disentangled representations serve as world models, isolating latent factors of variation in the world along approximately orthogonal directions, thus facilitating feature-based generalization. We provide experimental and theoretical results guaranteeing the emergence of disentangled representations in agents that optimally solve multi-task evidence aggregation classification tasks, canonical in the cognitive neuroscience literature. The key conceptual finding is that, by producing accurate multi-task classification estimates, a system implicitly represents a set of coordinates specifying a disentangled representation of the underlying latent state of the data it receives. The theory provides conditions for the emergence of these representations in terms of noise, number of tasks, and evidence aggregation time. Surprisingly, the theory also produces closed-form expressions for extracting the disentangled representation from the model's latent state $\\mathbf Z(t)$. We experimentally validate these predictions in RNNs trained on multi-task classification, which learn disentangled representations in the form of continuous attractors, leading to zero-shot out-of-distribution (OOD) generalization in predicting latent factors. We demonstrate the robustness of our framework across autoregressive architectures, decision boundary geometries and in tasks requiring classification confidence estimation. We find that transformers are particularly suited for disentangling representations, which might explain their unique world understanding abilities. Overall, our framework puts forth parallel processing as a general principle for the formation of cognitive maps that capture the structure of the world in both biological and artificial systems, and helps explain why ANNs often arrive at human-interpretable concepts, and how they both may acquire exceptional zero-shot generalization capabilities."
    },
    {
        "title": "Training Free Guided Flow-Matching with Optimal Control",
        "link_suffix": "/forum?id=61ss5RA1MM",
        "link": "https://openreview.net/forum?id=61ss5RA1MM",
        "pdf_link": "https://openreview.net/pdf?id=61ss5RA1MM",
        "keywords": "flow matching, controlled generation, inverse problem",
        "abstract": "Controlled generation with pre-trained Diffusion and Flow Matching models has vast applications. One strategy for guiding ODE-based generative models is through optimizing a target loss $R(x_1)$ while staying close to the prior distribution. Along this line, some recent work showed the effectiveness of guiding flow model by differentiating through its ODE sampling process. Despite the superior performance, the theoretical understanding of this line of methods is still preliminary, leaving space for algorithm improvement. Moreover, existing methods predominately focus on Euclidean data manifold, and there is a compelling need for guided flow methods on complex geometries such as SO(3), which prevails in high-stake scientific applications like protein design. We present OC-Flow, a general and theoretically grounded training-free framework for guided flow matching using optimal control. Building upon advances in optimal control theory, we develop effective and practical algorithms for solving optimal control in guided ODE-based generation and provide a systematic theoretical analysis of the convergence guarantee in both Euclidean and SO(3). We show that existing backprop-through-ODE methods can be interpreted as special cases of Euclidean OC-Flow. OC-Flow achieved superior performance in extensive experiments on text-guided image manipulation, conditional molecule generation, and all-atom peptide design."
    },
    {
        "title": "MentalChat16K: A Benchmark Dataset for Conversational Mental Health Assistance",
        "link_suffix": "/forum?id=ISBmUNKPST",
        "link": "https://openreview.net/forum?id=ISBmUNKPST",
        "pdf_link": "https://openreview.net/pdf?id=ISBmUNKPST",
        "keywords": "Mental Health, Large Language Model, Behavioral Health, Question and Answering",
        "abstract": "We introduce MentalChat16K, an English benchmark dataset combining a synthetic mental health counseling dataset and a dataset of anonymized transcripts from interventions between Behavioral Health Coaches and Caregivers of patients in palliative or hospice care. Covering a diverse range of conditions like depression, anxiety, and grief, this curated dataset is designed to facilitate the development and evaluation of large language models for conversational mental health assistance. By providing a high-quality resource tailored to this critical domain, MentalChat16K aims to advance research on empathetic, personalized AI solutions to improve access to mental health support services. The dataset prioritizes patient privacy, ethical considerations, and responsible data usage. MentalChat16K presents a valuable opportunity for the research community to innovate AI technologies that can positively impact mental well-being."
    },
    {
        "title": "Markovian Transformers for Informative Language Modeling",
        "link_suffix": "/forum?id=s5N7p5UjgR",
        "link": "https://openreview.net/forum?id=s5N7p5UjgR",
        "pdf_link": "https://openreview.net/pdf?id=s5N7p5UjgR",
        "keywords": "Chain of Thought Reasoning, Reinforcement Learning, Scalable Oversight, Language Modeling, Proximal Policy Optimization",
        "abstract": "Chain-of-Thought (CoT) reasoning holds great promise for explaining the outputs of language models, but recent studies have highlighted significant challenges in its practical application for interpretability. We propose to address this issue via two key components: a technique to factor next-token prediction through intermediate CoT text, ensuring the CoT is causally load-bearing, and a reinforcement learning approach to train CoT to predict future tokens independently of other context. This results in \"Markovian\" language models, where CoT serves as a fixed-size state for future token prediction. Our approach optimizes for \"informativeness\" â€“ the improvement in next-token predictions using a trained CoT compared to a baseline. We demonstrate our method's effectiveness using Proximal Policy Optimization (PPO) on arithmetic problems and achieve an 11% performance boost on the GSM8K benchmark using Mistral 7B Inst V2. The increased sensitivity of model performance to CoT perturbations provides strong evidence of CoT reliance. This work advances the development of more transparent and interpretable language models, potentially enabling their extension to arbitrarily long contexts and enhancing AI reasoning capabilities across various domains."
    },
    {
        "title": "Efficient Sparse PCA via Block-Diagonalization",
        "link_suffix": "/forum?id=FAYIlGDBa1",
        "link": "https://openreview.net/forum?id=FAYIlGDBa1",
        "pdf_link": "https://openreview.net/pdf?id=FAYIlGDBa1",
        "keywords": "Sparse PCA, Block Diagonalization, Compurational Efficiency, Approximation Algorithms",
        "abstract": "Sparse Principal Component Analysis (Sparse PCA) is a pivotal tool in data analysis and dimensionality reduction. However, Sparse PCA is a challenging problem in both theory and practice: it is known to be NP-hard and current exact methods generally require exponential runtime. In this paper, we propose a novel framework to efficiently approximate Sparse PCA by (i) approximating the  general input covariance matrix with a re-sorted block-diagonal matrix, (ii) solving the Sparse PCA sub-problem in each block, and (iii) reconstructing the solution to the original problem. Our framework is simple and powerful: it can leverage any off-the-shelf Sparse PCA algorithm and achieve significant computational speedups, with a minor additive error that is linear in the approximation error of the block-diagonal matrix. Suppose $g(k, d)$ is the runtime of an algorithm (approximately) solving Sparse PCA in dimension $d$ and with sparsity value $k$. Our framework, when integrated with this algorithm, reduces the runtime to $\\mathcal{O}\\left(\\frac{d}{d^\\star} \\cdot g(k, d^\\star) + d^2\\right)$, where $d^\\star \\leq d$ is the largest block size of the block-diagonal matrix. For instance, integrating our framework with the Branch-and-Bound algorithm reduces the complexity from $g(k, d) = \\mathcal{O}(k^3\\cdot d^k)$ to $\\mathcal{O}(k^3\\cdot d \\cdot (d^\\star)^{k-1})$, demonstrating exponential speedups if $d^\\star$ is small. We perform large-scale evaluations on many real-world datasets: for exact Sparse PCA algorithm, our method achieves an average speedup factor of 93.77, while maintaining an average approximation error of 2.15%; for approximate Sparse PCA algorithm, our method achieves an average speedup factor of 6.77 and an average approximation error of merely 0.37%."
    },
    {
        "title": "Aligning With Human Values Without Revealing Human Judgements",
        "link_suffix": "/forum?id=o9UzvKVvuf",
        "link": "https://openreview.net/forum?id=o9UzvKVvuf",
        "pdf_link": "https://openreview.net/pdf?id=o9UzvKVvuf",
        "keywords": "Responsible AI, language models, protecting human judgements",
        "abstract": "With the increasing ubiquity of large language models it has become crucial to ensure guarantees for models trained to be aligned with human values to avoid leaking information on the human judgements that have been provided to the algorithm. To target this issue we focus on the problem of alignment via reinforcement learning from human preference rankings, subject to the constraint of \nnot revealing any information on the human data used to align the model. To achieve this, we analyze $(\\epsilon,\\delta)$-DP for both the Bradley-Terry-Luce (BTL) model and the Plackett-Luce (PL) model. We introduce a theoretically founded algorithm for learning rewards from human rankings that achieves this objective without leaking the human rankings. We further demonstrate that the privately learned rewards can be used to train policies achieving statistical performance guarantees that asymptotically match the best known algorithms in the non-private setting, which are in some cases minimax optimal. Strikingly, our analysis and our results reveal that it is possible to obtain the same model performance without any trade-off on the protection of the human judgments, and our paper provides the first algorithms that can achieve provable privacy of human judgements, while still producing aligned models with optimal performance."
    },
    {
        "title": "A Markov decision process for variable selection in Branch and bound",
        "link_suffix": "/forum?id=ifJFKbSZxS",
        "link": "https://openreview.net/forum?id=ifJFKbSZxS",
        "pdf_link": "https://openreview.net/pdf?id=ifJFKbSZxS",
        "keywords": "Mixed-integer linear programming; Branch and bound; Reinforcement learning; Markov decision process",
        "abstract": "Mixed-Integer Linear Programming (MILP) is a powerful framework used to address a wide range of NP-hard combinatorial optimization problems, often solved by Branch and bound (B&B). A key factor influencing the performance of B&B solvers is the variable selection heuristic governing branching decisions. Recent contributions have sought to adapt reinforcement learning (RL) algorithms to the B&B setting to learn optimal branching policies, through Markov Decision Processes (MDP) inspired formulations, and ad hoc convergence theorems and algorithms. In this work, we introduce B&B MDPs, a principled vanilla MDP formulation for variable selection in B&B, allowing to leverage a broad range of RL algorithms for the purpose of learning optimal B&B heuristics. Computational experiments validate our model empirically, as our branching agent outperforms prior state-of-the-art RL agents on four standard MILP benchmarks."
    },
    {
        "title": "Enhancing Vision-Language Model Pre-training with Image-text Pair Pruning Based on Word Frequency",
        "link_suffix": "/forum?id=sBJIVQvJqN",
        "link": "https://openreview.net/forum?id=sBJIVQvJqN",
        "pdf_link": "https://openreview.net/pdf?id=sBJIVQvJqN",
        "keywords": "Vision-Language Model, Multimodal Data, Data Pruning",
        "abstract": "We propose Word-Frequency-based Image-Text Pair Pruning (WFPP), a novel data pruning method that improves the efficiency of VLMs.\nUnlike MetaCLIP, our method does not need metadata for pruning, but selects text-image pairs to prune based on the content of the text. Specifically, WFPP prunes text-image pairs containing high-frequency words across the entire training dataset. The effect of WFPP is to reduce the dominance of frequent words. The result a better balanced word-frequency distribution in the dataset, which is known to improve the training of word embedding models. After pre-training on the pruned subset, we fine-tuned the model on the entire dataset for one additional epoch to achieve better performance. Our experiments demonstrate that applying WFPP when training a CLIP model improves performance on a wide range of downstream tasks. WFPP also provides the advantage of speeding up pre-training by using fewer samples. Additionally, we analyze the training data before and after pruning to visualize how WFPP changes the balance of word frequencies. We hope our work encourages researchers to consider the distribution of words in the training data when pre-training VLMs, not limited to CLIP."
    },
    {
        "title": "Efficient In-Context Visual Learning with Trident Block and Cross Blocks",
        "link_suffix": "/forum?id=fi9LF92Cak",
        "link": "https://openreview.net/forum?id=fi9LF92Cak",
        "pdf_link": "https://openreview.net/pdf?id=fi9LF92Cak",
        "keywords": "Visual Prompting Large Vision Model, Efficient In-context Learning, Vision Transformers",
        "abstract": "Visual prompt-based large vision models exhibit remarkable performance in a range of vision tasks. However, visual prompting large vision models are computationally intensive and resource-demanding due to their large parameter sizes and the complexity of processing visual prompts, resulting in inefficiencies in speed and memory usage. To tackle these challenges, we propose the Efficient Painter model, which leverages a novel context-aggregated attention based trident block to alleviate cross-task gaps and reduce memory and computation overhead. Furthermore, we introduce a cross-blocks feature union module to capture global contextual information at different levels and speed up training. This architecture mitigates training costs and memory requirements during inference. Our model strikes a balance between speed and memory efficiency, achieving a 19$\\times$ reduction in FLOPs. Moreover, our model is 9$\\times$ smaller in model size and runs 4.1$\\times$ and 27$\\times$ faster during training and inference, respectively. Comprehensive experiments demonstrate that our design effectively processes additional visual prompts and outperforms baseline methods on standard benchmarks like \\textit{SIDD} and \\textit{LoL} in zero-shot settings, improving performance by 0.4% and 1.2% respectively."
    },
    {
        "title": "Semi-Supervised Neural Network Model For Quadratic Multiparametric Programming",
        "link_suffix": "/forum?id=iiK1vNRo6I",
        "link": "https://openreview.net/forum?id=iiK1vNRo6I",
        "pdf_link": "https://openreview.net/pdf?id=iiK1vNRo6I",
        "keywords": "Multiparametric Optimization, Quadratic Programming, Deep Neural Network, DC-OPF, AI for Sustainability",
        "abstract": "Neural Networks (NN) with ReLU activation functions have been used as surrogate models for multiparametric quadratic problems (mp-QP) for a wide range of engineering applications. Researchers have suggested leveraging the piecewise affine property of deep NN models to solve mp-QP with linear constraints, which also exhibit piecewise affine behaviour. However, traditional deep NN applications to mp-QP fall short of providing optimal and feasible predictions, even when trained with large datasets. This study introduces a semi-supervised NN (SSNN) architecture that directly represents the mathematical structure of the global solution function. In contrast to generic NN training approaches, the proposed SSNN method derives a large proportion of model weights directly from the physical characteristics of the system, producing solutions with higher accuracy despite training on significantly smaller data sets.  Since many energy management problems are formulated as QP, the proposed approach has been applied in energy systems to demonstrate proof of concept. Model performance in terms of solution accuracy and speed of the predictions was compared against a commercial solver and a generic NN model based on classical training. Results show KKT sufficient conditions for SSNN consistently outperform generic NN architectures with classical training using far less data. A similar performance advantage is shown using extreme, out-of-training distribution test data. Given its advantages of speed and reliability, the SSNN model can quickly produce optimal and feasible solutions within a second for millions of input parameters sampled from a distribution of stochastic demands and renewable generator dispatches, which can be used for simulations and long term planning."
    }
]
[{"title": "Bridging the Gap Betweenf-divergences and Bayes Hilbert Spaces", "link_suffix": "/forum?id=m5qpn0KTMZ", "link": "https://openreview.net/forum?id=m5qpn0KTMZ", "pdf_link": "https://openreview.net/pdf?id=m5qpn0KTMZ", "keywords": "f-divergences, Bayes Hilbert spaces, fenchel conjugates, centered-log-ratio, posterior approximation", "abstract": "We introduce a novel framework that generalizes $f$-divergences by incorporating locally non-convex divergence-generating functions.\nUsing this extension, we define a new class of pseudo $f$-divergences, encompassing a wider range of distances between distributions that traditional $f$-divergences cannot capture.\nAmong these, we focus on a particular pseudo divergence obtained by considering the induced metric of Bayes Hilbert spaces.\nBayes Hilbert spaces are frequently used due to their inherent connection to Bayes's theorem. They allow sampling from potentially intractable posterior densities, which has remained challenging until now.\nIn the more general context, we prove that pseudo $f$-divergences are well-defined and introduce a variational estimation framework that can be used in a statistical learning context.\nBy applying this variational estimation framework to $f$-GANs, we achieve improved FID scores over existing $f$-GAN architectures and competitive results with the Wasserstein GAN, highlighting its potential for both theoretical research and practical applications in learning theory.", "title_embedding_index": 9800, "title_abs_embedding_index": 9825}, {"title": "SBSC: Step-by-Step Coding for Improving Mathematical Olympiad Performance", "link_suffix": "/forum?id=wSkvf2WyYz", "link": "https://openreview.net/forum?id=wSkvf2WyYz", "pdf_link": "https://openreview.net/pdf?id=wSkvf2WyYz", "keywords": "math AI, LLM math reasoning", "abstract": "We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework that enables Large Language Models (LLMs) to generate sequence of programs for solving Olympiad level math problems. After each turn/step, by leveraging the code execution outputs and programs of previous steps, the model generates the next sub-task and the corresponding program to complete it. This way, SBSC, sequentially navigates to reach the final answer. SBSC allows more granular, flexible and precise approach to problem-solving compared to existing methods. Extensive experiments highlight the effectiveness of SBSC in tackling competition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe SBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program generation based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME and 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark SBSC\u2019s greedy decoding against self- consistency decoding results of existing SOTA math reasoning strategies and observe performance gain by absolute 6.2% on AMC, 6.7% on AIME and 7.4% on MathOdyssey.", "title_embedding_index": 9801, "title_abs_embedding_index": 9826}, {"title": "Transformers Learn Temporal Difference Methods for In-Context Reinforcement Learning", "link_suffix": "/forum?id=Pj06mxCXPl", "link": "https://openreview.net/forum?id=Pj06mxCXPl", "pdf_link": "https://openreview.net/pdf?id=Pj06mxCXPl", "keywords": "in-context reinforcement learning, policy evaluation, temporal difference learning", "abstract": "Traditionally, reinforcement learning (RL) agents learn to solve new tasks by updating their parameters through interactions with the task environment. However, recent works have demonstrated that transformer-based RL agents, after certain pretraining procedures, can learn to solve new out-of-distribution tasks without parameter updates, a phenomenon known as in-context reinforcement learning (ICRL). The empirical success of ICRL is widely attributed to the hypothesis that the forward pass of these models implements an RL algorithm. However, no prior works have demonstrated a precise equivalence between a forward pass and any specific RL algorithm, even in simplified settings like transformers with linear attention. In this paper, we present the first proof by construction demonstrating that transformers with linear attention can implement temporal difference (TD) learning in the forward pass \u2014 referred to as in-context TD. We also provide theoretical analysis and empirical evidence demonstrating the emergence of in-context TD after training the transformer with a multi-task TD algorithm, offering the first constructive explanation for transformers\u2019 ability to perform in-context reinforcement learning.", "title_embedding_index": 9802, "title_abs_embedding_index": 9827}, {"title": "A mechanistically interpretable neural network for regulatory genomics", "link_suffix": "/forum?id=eR9C6c76j5", "link": "https://openreview.net/forum?id=eR9C6c76j5", "pdf_link": "https://openreview.net/pdf?id=eR9C6c76j5", "keywords": "interpretability, mechanistic interpretability, attention, convolution, regulatory genomics", "abstract": "Deep neural networks excel in mapping genomic DNA sequences to associated readouts (e.g., protein\u2013DNA binding). Beyond prediction, the goal of these networks is to reveal to scientists the underlying motifs (and their syntax) which drive genome regulation. Traditional methods that extract motifs from convolutional filters suffer from the uninterpretable dispersion of information across filters and layers. Other methods which rely on importance scores can be unstable and unreliable. Instead, we designed a novel mechanistically interpretable architecture for regulatory genomics, where motifs and their syntax are directly encoded and readable from the learned weights and activations. We provide theoretical and empirical evidence of our architecture's full expressivity, while still being highly interpretable. Through several experiments, we show that our architecture excels in de novo motif discovery and motif instance calling, is robust to variable sequence contexts, and enables fully interpretable generation of novel functional sequences.", "title_embedding_index": 9803, "title_abs_embedding_index": 9828}, {"title": "Realistic Evaluation of Model Merging for Compositional Generalization", "link_suffix": "/forum?id=Bq3fEAGXUL", "link": "https://openreview.net/forum?id=Bq3fEAGXUL", "pdf_link": "https://openreview.net/pdf?id=Bq3fEAGXUL", "keywords": "model merging, realistic evaluation, compositional generalization", "abstract": "Merging has become a widespread way to cheaply combine individual models into a single model that inherits their capabilities and attains better performance.\nThis popularity has spurred rapid development of many new merging methods, which are typically validated in disparate experimental settings and frequently differ in the assumptions made about model architecture, data availability, and computational budget.\nIn this work, we characterize the relative merits of different merging methods by evaluating them in a shared experimental setting and precisely identifying the practical requirements of each method.\nSpecifically, our setting focuses on using merging for $\\textit{compositional generalization}$ of capabilities in image classification, image generation, and natural language processing.\nAdditionally, we measure the computational costs of different merging methods as well as how they perform when scaling the number of models being merged. \nTaken together, our results clarify the state of the field of model merging and provide a comprehensive and rigorous experimental setup to test new methods.", "title_embedding_index": 9804, "title_abs_embedding_index": 9829}, {"title": "Evaluating Fairness and Mitigating Bias in Machine Learning: A Novel Technique using Tensor Data and Bayesian Regression", "link_suffix": "/forum?id=4G6Q4nJBTQ", "link": "https://openreview.net/forum?id=4G6Q4nJBTQ", "pdf_link": "https://openreview.net/pdf?id=4G6Q4nJBTQ", "keywords": "Fairness, Bias mitigation, Skin color, Computer vision, Bayesian regression", "abstract": "Fairness is a critical component of Trustworthy AI. In this paper, we focus on Machine Learning (ML) and the performance of model predictions when dealing with skin color. Unlike other sensitive attributes, the nature of skin color differs significantly. In computer vision, skin color is represented as tensor data rather than categorical values or single numerical points. However, much of the research on fairness across sensitive groups has focused on categorical features such as gender and race. This paper introduces a new technique for evaluating fairness in ML for image classification tasks, specifically without the use of annotation. To address the limitations of prior work, we handle tensor data, like skin color, without classifying it rigidly. Instead, we convert it into probability distributions and apply statistical distance measures. This novel approach allows us to capture fine-grained nuances in fairness both within and across what would traditionally be considered distinct groups. Additionally, we propose an innovative training method to mitigate the latent biases present in conventional skin tone categorization. This method leverages color distance estimates calculated through Bayesian regression with polynomial functions, ensuring a more nuanced and equitable treatment of skin color in ML models.", "title_embedding_index": 9805, "title_abs_embedding_index": 9830}, {"title": "Balancing Act: Diversity and Consistency in Large Language Model Ensembles", "link_suffix": "/forum?id=Dl6nkKKvlX", "link": "https://openreview.net/forum?id=Dl6nkKKvlX", "pdf_link": "https://openreview.net/pdf?id=Dl6nkKKvlX", "keywords": "LLM, ensembling, diversity, consistency, mixture of agents, self decoding", "abstract": "Ensembling strategies for Large Language Models (LLMs) have demonstrated significant potential in improving performance across various tasks by combining the strengths of individual models. However, identifying the most effective ensembling method remains an open challenge, as neither maximizing output consistency through self-consistency decoding nor enhancing model diversity via frameworks like \"Mixture of Agents\" has proven universally optimal.  Motivated by this, we propose a unified framework to examine the trade-offs between task performance, model diversity, and output consistency in ensembles. More specifically, we introduce a consistency score that defines a gating mechanism for mixtures of agents and an algorithm for mixture refinement to investigate these trade-offs at the semantic and model levels, respectively. We incorporate our insights into a novel inference-time LLM ensembling strategy called the Dynamic Mixture of Agents (DMoA) and demonstrate that it achieves a new state-of-the-art result in the challenging Big Bench Hard mixed evaluations benchmark. Our analysis reveals that cross-validation bias can enhance performance, contingent on the expertise of the constituent models. We further demonstrate that distinct reasoning tasks\u2014such as arithmetic reasoning, commonsense reasoning, and instruction following\u2014require different model capabilities, leading to inherent task-dependent trade-offs that DMoA balances effectively.", "title_embedding_index": 9806, "title_abs_embedding_index": 9831}, {"title": "Improved Algorithms for Kernel Matrix-Vector Multiplication", "link_suffix": "/forum?id=wLnls9LS3x", "link": "https://openreview.net/forum?id=wLnls9LS3x", "pdf_link": "https://openreview.net/pdf?id=wLnls9LS3x", "keywords": "Algorithms, Kernel Matrix, Kernel Density Estimation, Locality Sensitive Hashing, Fast Attention", "abstract": "Motivated by the problem of fast processing of attention matrices, we study fast algorithms for computing matrix-vector products for asymmetric Gaussian Kernel matrices $K\\in \\mathbb{R}^{n\\times n}$. \n$K$'s columns are indexed by a set of $n$ keys $k_1,k_2\\ldots, k_n\\in \\mathbb{R}^d$, rows by a set of $n$ queries $q_1,q_2,\\ldots,q_n\\in \\mathbb{R}^d $, and its $i,j$ entry is $K_{ij} = e^{-|q_i-k_j|_2^2/2\\sigma^2}$ for some bandwidth parameter $\\sigma>0$. Given a vector $x\\in \\mathbb{R}^n$ and error parameter $\\epsilon>0$, our task is to output a $y\\in \\mathbb{R}^n$ such that $|Kx-y|_2\\leq \\epsilon |x|_2$ in time subquadratic in $n$ and linear in $d$. Our algorithms rely on the following modelling assumption about the matrices $K$: the sum of the entries of $K$ scales linearly in $n$, as opposed to worst case quadratic growth. We validate this assumption experimentally, for Gaussian kernel matrices encountered in various settings such as fast attention computation in LLMs. Under this assumption, we obtain the first subquadratic time algorithm for kernel matrix-vector multiplication for unrestricted vectors.", "title_embedding_index": 9807, "title_abs_embedding_index": 9832}, {"title": "NextBestPath: Efficient 3D Mapping of Unseen Environments", "link_suffix": "/forum?id=7WaRh4gCXp", "link": "https://openreview.net/forum?id=7WaRh4gCXp", "pdf_link": "https://openreview.net/pdf?id=7WaRh4gCXp", "keywords": "3D reconstruction, active mapping", "abstract": "This work addresses the problem of active 3D mapping, where an agent must find an efficient trajectory to exhaustively reconstruct a new scene.\nPrevious approaches mainly predict the next best view near the agent's location, which is prone to getting stuck in local areas. Additionally, existing indoor datasets are insufficient due to limited geometric complexity and inaccurate ground truth meshes.\nTo overcome these limitations, we introduce a novel dataset AiMDoom with a map generator for the Doom video game, enabling to better benchmark active 3D mapping in diverse indoor environments.\nMoreover, we propose a new method we call next-best-path (NBP), which predicts long-term goals rather than focusing solely on short-sighted views.\nThe model jointly predicts accumulated surface coverage gains for long-term goals and obstacle maps, allowing it to efficiently plan optimal paths with a unified model.\nBy leveraging online data collection, data augmentation and curriculum learning, NBP significantly outperforms state-of-the-art methods on both the existing MP3D dataset and our AiMDoom dataset, achieving more efficient mapping in indoor environments of varying complexity.", "title_embedding_index": 9808, "title_abs_embedding_index": 9833}, {"title": "Is Large-scale Pretraining the Secret to Good Domain Generalization?", "link_suffix": "/forum?id=wCOJpXm0Me", "link": "https://openreview.net/forum?id=wCOJpXm0Me", "pdf_link": "https://openreview.net/pdf?id=wCOJpXm0Me", "keywords": "Domain Generalization, Robustness, CLIP, Pretraining", "abstract": "Multi-Source Domain Generalization (DG) is the task of training on multiple source domains and achieving high classification performance on unseen target domains. Recent methods combine robust features from web-scale pretrained backbones with new features learned from source data, and this has dramatically improved benchmark results. However, it remains unclear if DG finetuning methods are becoming better over time, or if improved benchmark performance is simply an artifact of stronger pre-training.  Prior studies have shown that perceptual similarity to pre-training data correlates with zero-shot performance, but we find the effect limited in the DG setting. Instead, we posit that  having perceptually similar data in pretraining is not enough; and that it is how well these data were learned that determines performance. This leads us to introduce the Alignment Hypothesis, which states that the final DG performance will  be high if and only if alignment of image and class label text embeddings is high. Our experiments confirm the Alignment Hypothesis is true, and we use it as an analysis tool of existing DG methods evaluated on DomainBed datasets by splitting evaluation data into In-pretraining (IP) and Out-of-pretraining (OOP). We show that all evaluated DG methods struggle on DomainBed-OOP, while recent methods excel on DomainBed-IP. Put together, our findings highlight the need for DG methods which can generalize beyond pretraining alignment.", "title_embedding_index": 9809, "title_abs_embedding_index": 9834}, {"title": "Causal Reinforcement Learning for Spatio-Temporal Point Processes", "link_suffix": "/forum?id=WpjehX0TM2", "link": "https://openreview.net/forum?id=WpjehX0TM2", "pdf_link": "https://openreview.net/pdf?id=WpjehX0TM2", "keywords": "Spatio-Temporal Point Processes, Reinforcement Learning, Causal Inference", "abstract": "Spatio-temporal event sequences are increasingly accessible in various domains such as earthquake forecasting, crime prediction, and healthcare management. These data sources present unique challenges, as they involve both spatial and temporal dimensions, with event sequences exhibiting intricate dependencies over time and space. Neural network-based spatio-temporal point processes offer a sophisticated framework for modeling such event data. Conventional maximum likelihood estimation (MLE) of such data may lead to inaccurate predictions due to model-misspecification and compounding prediction errors. On the other hand, reinforcement learning frameworks, which treat event generation as actions and learn a policy to mimic event generation may alleviate the training/test discrepancy issue. Current reinforcement learning of point processes may have prohibitively poor exploration efficiency. In this paper, we propose the Causal learning improved Reinforcement Learning Spatio-Temporal Point Process (CRLSTPP) framework, which can mitigate the issue of compounding prediction errors and improve exploration efficiency at the same time. Experiments on both synthetic data and real-world data validate the superiority of the proposed model.", "title_embedding_index": 9810, "title_abs_embedding_index": 9835}, {"title": "Grokking at the Edge of Numerical Stability", "link_suffix": "/forum?id=TvfkSyHZRA", "link": "https://openreview.net/forum?id=TvfkSyHZRA", "pdf_link": "https://openreview.net/pdf?id=TvfkSyHZRA", "keywords": "grokking, deep learning, learning theory, floating point, scientific computation, generalization", "abstract": "Grokking, or sudden generalization that occurs after prolonged overfitting, is a surprising phenomenon that has challenged our understanding of deep learning. While a lot of progress has been made in understanding grokking, it is still not clear why generalization is delayed and why grokking often does not happen without regularization. In this work we argue that without regularization, grokking tasks push models to the edge of numerical stability, introducing floating point errors in the Softmax that we refer to asSoftmax Collapse(SC). We show that SC prevents grokking and that mitigating SC leads to grokkingwithoutregularization. Investigating the root cause of SC, we find that beyond the point of overfitting, the gradients strongly align with what we call thena\u00efve loss minimization(NLM) direction. This component of the gradient does not change the predictions of the model but decreases the loss by scaling the logits, usually through the scaling of the weights along their current direction. We show that this scaling of the logits explains the delay in generalization characteristic of grokking, and eventually leads to SC, stopping learning altogether. To validate these hypotheses, we introduce two key contributions that mitigate the issues faced in grokking tasks: (i) $\\mathrm{StableMax}$, a new activation function that prevents SC and enables grokking without regularization, and (ii) $\\perp\\mathrm{Grad}$, a training algorithm that leads to quick generalization in grokking tasks by preventing NLM altogether. These contributions provide new insights into grokking, shedding light on its delayed generalization, reliance on regularization, and the effectiveness of known grokking-inducing methods.", "title_embedding_index": 9811, "title_abs_embedding_index": 9836}, {"title": "Learning from Imperfect  Human Feedback: A Tale from Corruption-Robust Dueling", "link_suffix": "/forum?id=ptjrpEGrGg", "link": "https://openreview.net/forum?id=ptjrpEGrGg", "pdf_link": "https://openreview.net/pdf?id=ptjrpEGrGg", "keywords": "online learning, dueling bandit", "abstract": "This paper studies Learning from Imperfect Human Feedback (LIHF), addressing the potential irrationality or imperfect perception when learning from comparative human feedback. Building on evidences that human's imperfection decays over time (i.e., humans learn to improve), we  cast this problem as a concave-utility continuous-action dueling bandit but under a restricted form of  corruption:  i.e., the corruption scale is decaying over time as $t^{\\rho-1}$ for some ``imperfection rate''  $\\rho \\in [0, 1]$.With $T$ as the total number of iterations, we establish a regret lower bound of $ \\Omega(\\max{\\sqrt{T}, T^{\\rho}})$ for LIHF, even when $\\rho$ is known. For the same setting, we develop the Robustified Stochastic Mirror Descent for Imperfect Dueling (RoSMID) algorithm, which achieves nearly optimal regret $\\tilde{\\mathcal{O}}(\\max{\\sqrt{T}, T^{\\rho}})$. Core to our analysis is a novel framework for analyzing gradient-based algorithms for dueling bandit under corruption, and we demonstrate its general applicability by showing how this framework can be easily applied to obtain corruption-robust guarantees for other popular gradient-based dueling bandit algorithms. Our theoretical results are validated by extensive experiments.", "title_embedding_index": 9812, "title_abs_embedding_index": 9837}, {"title": "Multi-Robot Motion Planning with Diffusion Models", "link_suffix": "/forum?id=AUCYptvAf3", "link": "https://openreview.net/forum?id=AUCYptvAf3", "pdf_link": "https://openreview.net/pdf?id=AUCYptvAf3", "keywords": "Multi-Agent Planning, Robotics, Generative Models", "abstract": "Diffusion models have recently been successfully applied to a wide range of robotics applications for learning complex multi-modal behaviors from data. However, prior works have mostly been confined to single-robot and small-scale environments due to the high sample complexity of learning multi-robot diffusion models. In this paper, we propose a method for generating collision-free multi-robot trajectories that conform to underlying data distributions while using only single-robot data.\nOur algorithm, Multi-robot Multi-model planning Diffusion (MMD), does so by combining learned diffusion models with classical search-based techniques---generating data-driven motions under collision constraints. \nScaling further, we show how to compose multiple diffusion models to plan in large environments where a single diffusion model fails to generalize well. We demonstrate the effectiveness of our approach in planning for dozens of robots in a variety of simulated scenarios motivated by logistics environments. View video demonstrations in our supplementary material, and our code at:https://github.com/<removed_for_review>.", "title_embedding_index": 9813, "title_abs_embedding_index": 9838}, {"title": "Aguvis: Unified Pure Vision Agents for Autonomous GUI Interaction", "link_suffix": "/forum?id=FHtHH4ulEQ", "link": "https://openreview.net/forum?id=FHtHH4ulEQ", "pdf_link": "https://openreview.net/pdf?id=FHtHH4ulEQ", "keywords": "GUI Agent, Visual Language Model, Large Language Model, Grounding, Planning", "abstract": "Graphical User Interfaces (GUIs) are critical to human-computer interaction, yet automating GUI tasks remains challenging due to the complexity and variability of visual environments. \nExisting approaches often rely on textual representations of GUIs, which introduce limitations in generalization, efficiency, and scalability. \nIn this paper, we introduce Aguvis, a unified pure vision-based framework for autonomous GUI agents that operates across various platforms. \nOur approach leverages image-based observations, and grounding instructions in natural language to visual elements, and employs a consistent action space to ensure cross-platform generalization. \nTo address the limitations of previous work, we integrate explicit planning and reasoning within the model, enhancing its ability to autonomously navigate and interact with complex digital environments. \nWe construct a large-scale dataset of GUI agent trajectories, incorporating multimodal reasoning and grounding, and employ a two-stage training pipeline that first focuses on general GUI grounding, followed by planning and reasoning. \nThrough comprehensive experiments, we demonstrate that Aguvis surpasses previous state-of-the-art methods in both offline and real-world online scenarios, achieving, to our knowledge, the first fully autonomous pure vision GUI agent capable of performing tasks independently without collaboration with external closed-source models. \nWe will open-source all datasets, models, and training recipes to facilitate future research.", "title_embedding_index": 9814, "title_abs_embedding_index": 9839}, {"title": "Efficient Expert Pruning for Sparse Mixture-of-Experts Language Models: Enhancing Performance and Reducing Inference Costs", "link_suffix": "/forum?id=TTUtPIpaol", "link": "https://openreview.net/forum?id=TTUtPIpaol", "pdf_link": "https://openreview.net/pdf?id=TTUtPIpaol", "keywords": "Large language model, mixture of experts, pruning", "abstract": "The rapid advancement of large language models (LLMs) has led to architectures with billions to trillions of parameters, posing significant deployment challenges due to their substantial demands on memory, processing power, and energy consumption. Sparse Mixture-of-Experts (SMoE) architectures have emerged as a solution, activating only a subset of parameters per token, thereby achieving faster inference while maintaining performance. However, SMoE models still face limitations in broader deployment due to their large parameter counts and significant GPU memory requirements. \nIn this work, we introduce a gradient-free evolutionary strategy named Efficient Expert Pruning (EEP) to enhance the pruning of experts in SMoE models. Specifically, EEP searches the pruning pattern and use expert merging as an memory-efficient way of fine-tuning the pruned model. EEP relies solely on model inference (i.e., no gradient computation) and achieves greater sparsity while maintaining or even improving performance on downstream tasks. EEP can be used to reduce both the total number of experts (thus saving GPU memory) and the number of active experts (thus accelerating inference).\nFor example, in the task-specific setting, we demonstrate that pruning up to 75% of experts in Mixtral $8\\times7$B-Instruct results in a substantial reduction in parameters with minimal performance loss, or pruning 50% of experts and activating one fewer expert to achieve 1.41$\\times$ speedup. Our experiments include four different model sizes from Mixtral, Qwen1.5 and Qwen2, and utilize more than 10 datasets as well as various settings. Results show that our method outperforms the related baselines by a large margin, demonstrating a significant advancement in this direction. Results of our method can be reproduced using the code provided in the supplementary material.", "title_embedding_index": 9815, "title_abs_embedding_index": 9840}, {"title": "DeepFDM: A scientific computing method for Neural Partial Differential Equation (PDE) operators", "link_suffix": "/forum?id=0zZEbHLTwf", "link": "https://openreview.net/forum?id=0zZEbHLTwf", "pdf_link": "https://openreview.net/pdf?id=0zZEbHLTwf", "keywords": "Partial Differential Equations, neural operators, solution operators, interpretable models, out of distribution, dataset shift, physical models", "abstract": "Solving Partial Differential Equations (PDE) has long been a critical challenge in many scientific and engineering domains. Recently, neural networks have shown great promise in solving PDEs by learning solution operators from data, offering a flexible and adaptive alternative to traditional numerical solvers. Despite these advancements, there is still a need for systematic benchmarking of neural operator methods against conventional approaches and for the development of datasets representing diverse distributions for robust evaluation.\nIn this paper, we introduce DeepFDM, a benchmark method for learning PDE solution operators based on numerical PDE solvers.DeepFDM leverages the structure of the PDE, in order to achieve better accuracy and generalization compared to neural solvers.  It is designed as a solver for a specific class of PDEs and not as a replacement for neural solvers.  Moreover, because DeepFDM learns the coefficients of the PDEs, it offers inherent interpretability.  We also introduce a principled method for generating training and test data for PDE solutions, allowing for a quantifiable measure of distribution shifts.  This method provides a structured approach to evaluate the out-of-distribution (OOD) performance of neural PDE operators. \nOur work sets a foundation for future comparisons of neural operator methods with traditional scientific computing approaches, providing a rigorous framework for performance benchmarking, at the level of the data and at the level of the neural solver.", "title_embedding_index": 9816, "title_abs_embedding_index": 9841}, {"title": "TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes", "link_suffix": "/forum?id=8enWnd6Gp3", "link": "https://openreview.net/forum?id=8enWnd6Gp3", "pdf_link": "https://openreview.net/pdf?id=8enWnd6Gp3", "keywords": "geometry representation, 3D modeling", "abstract": "We introduce TetSphere Splatting, a Lagrangian geometry representation designed for high-quality 3D shape modeling. TetSphere splatting leverages an underused yet powerful geometric primitive -- volumetric tetrahedral meshes. It represents 3D shapes by deforming a collection of tetrahedral spheres, with geometric regularizations and constraints that effectively resolve common mesh issues such as irregular triangles, non-manifoldness, and floating artifacts. Experimental results on multi-view and single-view reconstruction highlight TetSphere splatting's superior mesh quality while maintaining competitive reconstruction accuracy compared to state-of-the-art methods. Additionally, TetSphere splatting demonstrates versatility by seamlessly integrating into generative modeling tasks, such as image-to-3D and text-to-3D generation.", "title_embedding_index": 9817, "title_abs_embedding_index": 9842}, {"title": "Enhancing Group Fairness in Federated Learning through Personalization", "link_suffix": "/forum?id=cXdG5fhZ3w", "link": "https://openreview.net/forum?id=cXdG5fhZ3w", "pdf_link": "https://openreview.net/pdf?id=cXdG5fhZ3w", "keywords": "Federated Learning, Personalization, Fairness", "abstract": "Personalized Federated Learning (FL) algorithms collaboratively train customized models for each client, enhancing the accuracy of the learned models on the client's local data (e.g., by clustering similar clients, by fine-tuning models locally, or by imposing regularization terms). In this paper, we investigate the impact of such personalization techniques on the group fairness of the learned models, and show that personalization can also lead to improved (local) fairness as an unintended benefit. We begin by illustrating these benefits of personalization through numerical experiments comparing several classes of personalized FL algorithms against a baseline FedAvg algorithm, elaborating on the reasons behind improved fairness using personalized FL, and then providing analytical support. Motivated by these, we then show how to build on this (unintended) fairness benefit, by further integrating a fairness metric into the cluster-selection procedure of clustering-based personalized FL algorithms, and improve the fairness-accuracy trade-off attainable through them. Specifically, we propose two new fairness-aware federated clustering algorithms, Fair-FCA and Fair-FL+HC, extending the existing IFCA and FL+HC algorithms, and demonstrate their ability to strike a (tuneable) balance between accuracy and fairness at the client level.", "title_embedding_index": 9818, "title_abs_embedding_index": 9843}, {"title": "Spectral Spatial Traversing in Point Clouds: Enhancing Data Analysis with Mamba Networks", "link_suffix": "/forum?id=SU3lZ8jrRD", "link": "https://openreview.net/forum?id=SU3lZ8jrRD", "pdf_link": "https://openreview.net/pdf?id=SU3lZ8jrRD", "keywords": "State Space Models, Masked Autoencoders, 3D Point Clouds, Spectral Spatial Traversing", "abstract": "State Space Models (SSMs) such as Mamba have shown significant promise for sequence modeling in Natural Language Processing (NLP) and, more recently, computer vision. This paper presents a new methodology for both supervised and self-supervised learning using Mamba and Masked Autoencoder networks specifically designed for point cloud data. We propose three main contributions that enhance the capability of Mamba networks to process and understand the complex structure of this type of data. The first strategy exploits the spectrum of a graph Laplacian capturing the local connectivity of patches to define an isometry-invariant traversal order of tokens in the Mamba network. Compared to existing point cloud Mamba architectures, which traverse point patches based on a 3D grid, our approach is more robust to the viewpoint and better captures the shape manifold of the point cloud. The second contribution adapts our approach to segmentation using a recursive patch partitioning strategy informed by spectral components of the Laplacian. This strategy enables a more precise integration and analysis point cloud segments. Our last contribution tackles a significant issue in Masked\nAutoencoder (MAE)  for Mamba networks by modifying learnable token placement. Instead of adding them at the end, tokens are restored to their original positions, maintaining essential order and improving learning effectiveness. Extensive experiments confirm our method's superiority over State-Of-The-Art (SOTA)  baselines, demonstrating marked improvements in classification, segmentation, and few-shot tasks.", "title_embedding_index": 9819, "title_abs_embedding_index": 9844}, {"title": "Unified Perspectives on Signal-to-Noise Diffusion Models", "link_suffix": "/forum?id=X65IKSuWQo", "link": "https://openreview.net/forum?id=X65IKSuWQo", "pdf_link": "https://openreview.net/pdf?id=X65IKSuWQo", "keywords": "diffusion models, SDE, ODE, continuous variation models", "abstract": "Diffusion models (DM) have become essential components of generative modeling, demonstrating exceptional performance in domains like image synthesis, audio generation, and complex data interpolation. Signal-to-Noise diffusion models represent a broad family encompassing many state-of-the-art models. Although several efforts have been made to explore Signal-to-Noise (S2N) diffusion models from different angles, a comprehensive study that connects these viewpoints and introduces new insights is still needed. In this work, we provide an in-depth perspective on noise schedulers, analyzing their role through the lens of the signal-to-noise ratio (SNR) and its relationship to information theory. Based on this framework, we introduce a generalized backward equation to improve the efficiency of the inference process.", "title_embedding_index": 9820, "title_abs_embedding_index": 9845}, {"title": "Evaluating Graphical Perception of Large Multimodal Models", "link_suffix": "/forum?id=Yqte21dFVS", "link": "https://openreview.net/forum?id=Yqte21dFVS", "pdf_link": "https://openreview.net/pdf?id=Yqte21dFVS", "keywords": "Large Multimodal Models, Graphical Perception, Evaluation", "abstract": "Despite the promising results of large multimodal models (LMMs) in various vision-language tasks, recent benchmarks reveal that these models can struggle with low-level chart perception tasks that require precision.\nHowever, since existing benchmarks primarily focus on end tasks that evaluate models' knowledge and reasoning abilities all together, they provide limited fine-grained insights into how the models' perception abilities affect their performance in chart tasks.\nTo address this gap, we leveragethe theory of graphical perception, an approach used to study how humans decode visual information encoded on charts and graphs, to develop an evaluation framework for analyzing gaps in LLMs' perception abilities in charts. With automated task generation and response evaluation designs, our framework enables comprehensive and controlled testing of LMMs' graphical perception across diverse chart types, visual elements, and task types.\nWe apply our framework to evaluate the perception capabilities of state-of-the-art LMMs at three granularity levels (chart, visual element, and pixel). Our findings underscore several critical limitations of current state-of-the-art LMMs, including GPT-4o: their inability to (1) generalize across chart types, (2) understand fundamental visual elements, and (3) cross reference values within a chart.\nThese insights provide guidance for future improvements in perception abilities of LMMs.\nThe evaluation framework and labeled data will be publicly available upon acceptance.", "title_embedding_index": 9821, "title_abs_embedding_index": 9846}, {"title": "Linear Combination of Saved Checkpoints Makes Consistency and Diffusion Models Better", "link_suffix": "/forum?id=QowsEic1sc", "link": "https://openreview.net/forum?id=QowsEic1sc", "pdf_link": "https://openreview.net/pdf?id=QowsEic1sc", "keywords": "Model merging, consistency model, diffusion model", "abstract": "Diffusion Models (DM) and Consistency Models (CM) are two types of popular generative models with good generation quality on various tasks. When training DM and CM, intermediate weight checkpoints are not fully utilized and only the last converged checkpoint is used. In this work, we find proper checkpoint merging can significantly improve the training convergence and final performance. Specifically, we propose LCSC, a simple but effective and efficient method to enhance the performance of DM and CM, by combining checkpoints along the training trajectory with coefficients deduced from evolutionary search. We demonstrate the value of LCSC through two use cases: (a) Reducing training cost. With LCSC, we only need to train DM/CM with fewer number of iterations and/or lower batch sizes to obtain comparable sample quality with the fully trained model. For example, LCSC achieves considerable training speedups for CM (23$\\times$ on CIFAR-10 and 15$\\times$ on ImageNet-64). (b) Enhancing pre-trained models. When full training is already done, LCSC can further improve the generation quality or efficiency of the final converged models. For example,  LCSC achieves better FID using 1 number of function evaluation (NFE) than the base model with 2 NFE on consistency distillation, and decreases the NFE of DM from 15 to 9 while maintaining the generation quality. Applying LCSC to large text-to-image models, we also observe clearly enhanced generation quality.", "title_embedding_index": 9822, "title_abs_embedding_index": 9847}, {"title": "Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents", "link_suffix": "/forum?id=kxnoqaisCT", "link": "https://openreview.net/forum?id=kxnoqaisCT", "pdf_link": "https://openreview.net/pdf?id=kxnoqaisCT", "keywords": "GUI Agents, Visual Grounding, Multimodal Large Language Models, GUI Grounding, Large Language Model", "abstract": "Multimodal large language models (MLLMs) are transforming the capabilities of graphical user interface (GUI) agents, facilitating their transition from controlled simulations to complex, real-world applications across various platforms. However, the effectiveness of these agents hinges on the robustness of their grounding capability. Current GUI agents predominantly utilize text-based representations such as HTML or accessibility trees, which, despite their utility, often introduce noise, incompleteness, and increased computational overhead. In this paper, we advocate a human-like embodiment for GUI agents that perceive the environment entirely visually and directly take pixel-level operations on the GUI. The key is visual grounding models that can accurately map diverse referring expressions of GUI elements to their coordinates on the GUI across different platforms. We show that a simple recipe, which includes web-based synthetic data and slight adaptation of the LLaVA architecture, is surprisingly effective for training such visual grounding models. We collect the largest dataset for GUI visual grounding so far, containing 19M GUI elements and their referring expressions over 1.3M screenshots, and use it to train UGround, a strong universal visual grounding model for GUI agents. Empirical results on six benchmarks spanning three categories (grounding, offline agent, and online agent) show that 1) UGround substantially outperforms existing visual grounding models for GUI agents, by up to 20% absolute, and 2) agents with UGround outperform state-of-the-art agents, despite the fact that existing agents use additional text-based input while ours only uses visual perception. These results provide strong support for the feasibility and promises of GUI agents that navigate the digital world as humans do.", "title_embedding_index": 9823, "title_abs_embedding_index": 9848}, {"title": "Social Learning: Towards Collaborative Learning with Large Language Models", "link_suffix": "/forum?id=us5riDkeBW", "link": "https://openreview.net/forum?id=us5riDkeBW", "pdf_link": "https://openreview.net/pdf?id=us5riDkeBW", "keywords": "language models, privacy-aware knowledge transfer", "abstract": "We introduce the framework of \"social learning\" in the context of large language models (LLMs), whereby models share knowledge with each other in a privacy-aware manner using natural language. We present and evaluate two approaches for knowledge transfer between LLMs. In the first scenario, we allow the model to generate abstract prompts aiming to teach the task. In our second approach, models transfer knowledge by generating synthetic examples. We evaluate these methods across diverse datasets and quantify memorization as a proxy for privacy loss. These techniques inspired by social learning yield promising results with low memorization of the original data. In particular, we show that performance using these methods is comparable to results with the use of original labels and prompts. Our work demonstrates the viability of social learning for LLMs, establishes baseline approaches and highlights several unexplored areas for future work.", "title_embedding_index": 9824, "title_abs_embedding_index": 9849}]
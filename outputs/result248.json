[
    {
        "title": "Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps",
        "link_suffix": "/forum?id=CGhgB8Kz8i",
        "link": "https://openreview.net/forum?id=CGhgB8Kz8i",
        "pdf_link": "https://openreview.net/pdf?id=CGhgB8Kz8i",
        "keywords": "Large Language Model, humor generation, reinforcement learning",
        "abstract": "Humor is a culturally nuanced aspect of human language that presents challenges for understanding and generation, requiring participants to possess good creativity and strong associative thinking. Similar to reasoning tasks like solving math problems, humor generation requires continuous reflection and revision to foster creative thinking, rather than relying on a sudden flash of inspiration like Creative Leap-of-Thought (CLoT) paradigm.\nAlthough CLoT can realize the ability of remote association generation, this paradigm fails to emphasize the importance of rationales between those seemingly unrelated concepts. \nTherefore, in this paper, we propose a systematic way of thinking about generating humor and based on it, we built Creative Leap of Structured Thought (CLoST) frame. First, a reward model is necessary achieve the purpose of being able to correct errors, since there is currently no expert model of humor and a usable rule to determine whether a piece of content is humorous. Judgement-oriented instructions are designed to improve the capability of a model, and we also propose an open-domain instruction evolutionary method to fully unleash the potential. Then, through reinforcement learning, the model learns to hone its rationales of the thought chain and refine the strategies it uses. Thus, it learns to recognize and correct its mistakes, and finally generate the most humorous and creative answer.\nThese findings deepen our understanding of the creative capabilities of LLMs and provide ways to enhance LLMs' creative abilities for cross-domain innovative applications."
    },
    {
        "title": "A Large-scale Universal Evaluation Benchmark For Face Forgery Detection",
        "link_suffix": "/forum?id=iReypJFqa1",
        "link": "https://openreview.net/forum?id=iReypJFqa1",
        "pdf_link": "https://openreview.net/pdf?id=iReypJFqa1",
        "keywords": "Deepfakes, Face Forgery, Evaluation Benchmark, Forgery Detection",
        "abstract": "With the rapid development of AI-generated content (AIGC) technology, the production of realistic fake facial images and videos that deceive human visual perception has become possible. Consequently, various face forgery detection techniques have been proposed to identify such fake facial content. However, evaluating the effectiveness and generalizability of these detection techniques remains a significant challenge. To address this, we have constructed a large-scale evaluation benchmark called DeepFaceGen, aimed at quantitatively assessing the effectiveness of face forgery detection and facilitating the iterative development of forgery detection technology. DeepFaceGen consists of 776,990 real face image/video samples and 773,812 face forgery image/video samples, generated using 34 mainstream face generation techniques. During the construction process, we carefully consider important factors such as content diversity, fairness across ethnicities, and availability of comprehensive labels, in order to ensure the versatility and convenience of DeepFaceGen. Subsequently, DeepFaceGen is employed in this study to evaluate and analyze the performance of 20 mainstream face forgery detection techniques from various perspectives. Through extensive experimental analysis, we derive significant findings and propose potential directions for future research. The code and dataset for DeepFaceGen are available athttps://anonymous.4open.science/r/DeepFaceGen-47D1."
    },
    {
        "title": "M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models",
        "link_suffix": "/forum?id=GVNYi74t5L",
        "link": "https://openreview.net/forum?id=GVNYi74t5L",
        "pdf_link": "https://openreview.net/pdf?id=GVNYi74t5L",
        "keywords": "Multilingual, Multimodal Reasoning, Large Multimodal Models",
        "abstract": "Multilingual capability is an essential aspect for large multimodal models, since they are usually deployed across various countries and languages. However, most existing benchmarks for multilingual multimodal reasoning struggle to differentiate between models of varying performance; even language models without visual capabilities can easily achieve high scores. This leaves a comprehensive evaluation of leading multilingual multimodal models largely unexplored. In this work, we introduce M4U, a novel and challenging benchmark for assessing the capability of multi-discipline multilingual multimodal understanding and reasoning. M4U contains 8,931 samples covering 64 disciplines across 16 subfields in Science, Engineering, and Healthcare in Chinese, English, and German. Using M4U, we conduct extensive evaluations of 21 leading Large Multimodal Models (LMMs) and Large Language Models (LLMs) with external tools. The evaluation results show that the state-of-the-art model, GPT-4o, achieves only 47.6% average accuracy on M4U. Additionally, we observe that the leading LMMs exhibit significant language preferences. Our in-depth analysis indicates that leading LMMs, including GPT-4o, suffer performance degradation when prompted with cross-lingual multimodal questions, such as images with key textual information in Chinese while the question is in German. We believe that M4U can serve as a crucial tool for systematically evaluating LMMs based on their multilingual multimodal reasoning capabilities and monitoring their development."
    },
    {
        "title": "SKDream: Controllable Multi-view and 3D Generation with Arbitrary Skeletons",
        "link_suffix": "/forum?id=6r1nbspMUl",
        "link": "https://openreview.net/forum?id=6r1nbspMUl",
        "pdf_link": "https://openreview.net/pdf?id=6r1nbspMUl",
        "keywords": "Conditional Generation, Controllable Generation, Multi-view Diffusion, 3D Generation, Skeletons",
        "abstract": "Controllable generation has achieved substantial progress in both 2D and 3D domains, yet current conditioning methods still face limitations in describing detailed shape structures. Skeletons can effectively represent and describe object anatomy and pose. Unfortunately, past studies are often limited to human skeletons. \nIn this work, we generalize skeletal conditioned generation to arbitrary structures. First, we design a reliable mesh skeletonization pipeline to generate a large-scale mesh-skeleton paired dataset.\nBased on the dataset, a multi-view and 3D generation pipeline is built. We propose to represent 3D skeletons by Coordinate Color Encoding as 2D conditional images. A Skeletal Correlation Module is designed to extract global skeletal features for condition injection. After multi-view images are generation, 3D assets can be obtained by incorporating a large reconstruction model, followed with a UV texture refinement stage. \nAs a result, our method achieves instant generation of multi-view and 3D contents which are aligned with given skeletons. The proposed techniques largely improve the object-skeleton alignment and generation quality."
    },
    {
        "title": "Beyond the Alphabet: Deep Signal Embedding for Enhanced DNA Clustering",
        "link_suffix": "/forum?id=BGZQcyA1GO",
        "link": "https://openreview.net/forum?id=BGZQcyA1GO",
        "pdf_link": "https://openreview.net/pdf?id=BGZQcyA1GO",
        "keywords": "Deep learning, DNA storage, Science, Clustering, Sequencing",
        "abstract": "The emerging field of DNA storage employs strands of DNA bases (A/T/C/G) as a storage medium for digital information to enable massive density and durability. The DNA storage pipeline includes: (1) encoding the raw data into sequences of DNA bases; (2) synthesizing the sequences as DNA strands that are stored over time as an unordered set; (3) sequencing the DNA strands to generate DNA reads; and (4) deducing the original data. The DNA synthesis and sequencing stages each generate several independent error-prone duplicates of each strand which are then utilized in the final stage to reconstruct the best estimate for the original strand. Specifically, the reads are first clustered into groups likely originating from the same strand (based on their similarity to each other), and then each group approximates the strand that led to the reads of that group. This work improves the DNA clustering stage by embedding it as part of the DNA sequencing. Traditional DNA storage solutions begin after the DNA sequencing process generates discrete DNA reads (A/T/C/G), yet we identify that there is untapped potential in using the raw signals generated by the Nanopore DNA sequencing machine before they are discretized into bases, a process known as basecalling, which is done using a deep neural network. We propose a deep neural network that clusters these signals directly, demonstrating superior accuracy, and reduced computation times compared to current approaches that cluster after basecalling."
    },
    {
        "title": "FlightBench: Benchmarking Learning-based Methods for Ego-vision-based Quadrotors Navigation",
        "link_suffix": "/forum?id=vrCT5uCdYp",
        "link": "https://openreview.net/forum?id=vrCT5uCdYp",
        "pdf_link": "https://openreview.net/pdf?id=vrCT5uCdYp",
        "keywords": "Ego-vision-based Navigation, Learning-based Quadrotor Methods, Open-source Benchmark",
        "abstract": "Ego-vision-based navigation in cluttered environments is crucial for mobile systems, particularly agile quadrotors. While learning-based methods have shown promise recently, head-to-head comparisons with cutting-edge optimization-based approaches are scarce, leaving open the question of where and to what extent they truly excel. In this paper, we introduce FlightBench, the first comprehensive benchmark that implements various learning-based methods for ego-vision-based navigation and evaluates them against mainstream optimization-based baselines using a broad set of performance metrics. Additionally, we develop a suite of criteria to assess scenario difficulty and design test cases that span different levels of difficulty based on these criteria. Our results show that while learning-based methods excel in high-speed flight and faster inference, they struggle with challenging scenarios like sharp corners or view occlusion. Analytical experiments validate the correlation between our difficulty criteria and flight performance. We hope this benchmark and these criteria will drive future advancements in learning-based navigation for ego-vision quadrotors. The source code and documentation is available athttps://github.com/Anonymous314159265358/FlightBench."
    },
    {
        "title": "Optimal Targets for Concept Erasure in Diffusion Models and Where To Find Them",
        "link_suffix": "/forum?id=tZdqL5FH7w",
        "link": "https://openreview.net/forum?id=tZdqL5FH7w",
        "pdf_link": "https://openreview.net/pdf?id=tZdqL5FH7w",
        "keywords": "Trustworthy Generative AI, Diffusion Models, Unlearning Machine Learning, Erasing Concepts",
        "abstract": "Concept erasure has emerged as a promising technique for mitigating the risk of harmful content generation in diffusion models by selectively unlearning undesirable concepts. \nThe common principle of previous works to remove a specific concept is to map it to a fixed generic concept, such as a neutral concept or just an empty text prompt. \nIn this paper, we demonstrate that this fixed-target strategy is suboptimal, as it fails to account for the impact of erasing one concept on the others. \nTo address this limitation, we model the concept space as a graph and empirically analyze the effects of erasing one concept on the remaining concepts. \nOur analysis uncovers intriguing geometric properties of the concept space, where the influence of erasing a concept is confined to a local region. \nBuilding on this insight, we propose the Adaptive Guided Erasure (AGE) method, which \\emph{dynamically} selects neutral concepts tailored to each undesirable concept, minimizing unintended side effects. \nExperimental results show that AGE significantly outperforms state-of-the-art erasure methods on preserving unrelated concepts while maintaining effective erasure performance."
    },
    {
        "title": "DynamicRTL: RTL Representation Learning for Dynamic Circuit Behavior",
        "link_suffix": "/forum?id=UzpMjtBbit",
        "link": "https://openreview.net/forum?id=UzpMjtBbit",
        "pdf_link": "https://openreview.net/pdf?id=UzpMjtBbit",
        "keywords": "Code Representation Learning, Graph Neural Network, Hardware Design",
        "abstract": "There is a growing body of work on using Graph Neural Networks (GNNs) to learn representations of circuits, focusing primarily on their static characteristics. However, these models fail to capture critical runtime behavior, which is crucial for tasks like hardware verification and optimization. To address this limitation, we introduce DynamicRTL, a novel GNN-based approach that learns circuit representations by incorporating both static structures and multi-cycle execution behaviors. DynamicRTL leverages an operation-level Control Data Flow Graph (CDFG) to represent Register Transfer Level (RTL) circuits, enabling the model to capture dynamic dependencies and runtime execution. To train and evaluate DynamicRTL, we built the first comprehensive dynamic circuit dataset, comprising over 6,300 Verilog modules and 190,000 simulation traces. Our results demonstrate that DynamicRTL consistently outperforms existing models in branch prediction tasks. Furthermore, its learned representations transfer effectively to related tasks, achieving strong performance in assertion prediction and underscoring its transfer learning capabilities for dynamic circuit tasks."
    },
    {
        "title": "Improving Probabilistic Diffusion Models With Optimal Covariance Matching",
        "link_suffix": "/forum?id=fV0t65OBUu",
        "link": "https://openreview.net/forum?id=fV0t65OBUu",
        "pdf_link": "https://openreview.net/pdf?id=fV0t65OBUu",
        "keywords": "Diffusion Model, Generative Model, Probalistic Modelling",
        "abstract": "The probabilistic diffusion model has become highly effective across various domains. Typically, sampling from a diffusion model involves using a denoising distribution characterized by a Gaussian with a learned mean and either fixed or learned covariances. In this paper, we leverage the recently proposed covariance moment matching technique and introduce a novel method for learning the diagonal covariances. Unlike traditional data-driven covariance approximation approaches, our method involves directly regressing the optimal analytic covariance using a new, unbiased objective named Optimal Covariance Matching (OCM). This approach can significantly reduce the approximation error in covariance prediction. We demonstrate how our method can substantially enhance the sampling efficiency, recall rate and likelihood of both diffusion models and latent diffusion models."
    },
    {
        "title": "OpenStereo: A Comprehensive Benchmark for Stereo Matching and Strong Baseline",
        "link_suffix": "/forum?id=kBcpBdGoKc",
        "link": "https://openreview.net/forum?id=kBcpBdGoKc",
        "pdf_link": "https://openreview.net/pdf?id=kBcpBdGoKc",
        "keywords": "stereo matching",
        "abstract": "Stereo matching aims to estimate the disparity between matching pixels in a stereo image pair, which is important to robotics, autonomous driving, and other computer vision tasks. Despite the development of numerous impressive methods in recent years, determining the most suitable architecture for practical application remains challenging. To address this gap, our paper introduces a comprehensive benchmark focusing on practical applicability rather than solely on individual models for optimized performance. Specifically, we develop a flexible and efficient stereo matching codebase, called \\textbf{OpenStereo}. OpenStereo includes training and inference codes of more than 10 network models, making it, to our knowledge, the most complete stereo matching toolbox available. Based on OpenStereo, we conducted experiments and have achieved or surpassed the performance metrics reported in the original paper.\nAdditionally, we conduct an exhaustive analysis and deconstruction of recent developments in stereo matching through comprehensive ablative experiments. These investigations inspired the creation of \\textbf{StereoBase}, a strong baseline model. Our StereoBase ranks 1\\textsuperscript{st} on SceneFlow, KITTI 2015, 2012 (Reflective) among published methods and performs best across all metrics. In addition, StereoBase has strong cross-dataset generalization."
    },
    {
        "title": "TreeDQN: Sample-Efficient Off-Policy Reinforcement Learning for Combinatorial Optimization",
        "link_suffix": "/forum?id=YDuYWjbKDA",
        "link": "https://openreview.net/forum?id=YDuYWjbKDA",
        "pdf_link": "https://openreview.net/pdf?id=YDuYWjbKDA",
        "keywords": "reinforcement learning, combinatorial optimization, branch-and-bound, ML4CO",
        "abstract": "A convenient approach to optimally solving combinatorial optimization tasks is Branch-and-Bound method. The branching heuristic in this method can be learned to solve a large set of similar tasks. The promising results here are achieved by the recently appeared on-policy reinforcement learning (RL) method based on the tree Markov Decision Process (tMDP). To overcome its main disadvantages, namely, very large training time and unstable training, we propose TreeDQN, a sample-efficient off-policy RL method that is trained by optimizing the geometric mean of expected return. To theoretically support the training procedure for our method, we prove the contraction property of the Bellman operator for the tree MDP. As a result, our method requires up to 10 times less training data, performs faster than known on-policy methods on synthetic tasks. Moreover, TreeDQN significantly outperforms the state-of-the-art techniques on a challenging practical task from the ML4CO competition."
    },
    {
        "title": "What Matters for In-Context Learning: A Balancing Act of Look-up and In-Weight Learning",
        "link_suffix": "/forum?id=JVFRwCx3Dy",
        "link": "https://openreview.net/forum?id=JVFRwCx3Dy",
        "pdf_link": "https://openreview.net/pdf?id=JVFRwCx3Dy",
        "keywords": "in-context learning, few-shot learning",
        "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in various tasks, including In-Context Learning (ICL), where the model performs new tasks by conditioning solely on the examples provided in the context, without updating the model's weights. While prior research has explored the roles of pretraining data and model architecture, the key mechanism behind ICL remains unclear. In this work, we systematically uncover properties present in LLMs that support the emergence of ICL. To disambiguate these factors, we conduct a study with a controlled dataset and data sequences using a deep autoregressive model. We show that conceptual repetitions in the data sequences are crucial for ICL, more so than previously indicated training data properties like burstiness or long-tail distribution. Conceptual repetitions could refer to $n$-gram repetitions in textual data or exact image copies in image sequence data. Such repetitions also offer other previously overlooked benefits such as reduced transiency in ICL performance. Furthermore, we show that the emergence of ICL depends on balancing the in-weight learning objective with the in-context solving ability during training."
    },
    {
        "title": "DualFast: Dual-Speedup Framework for Fast Sampling of Diffusion Models",
        "link_suffix": "/forum?id=UACXMKAz0Z",
        "link": "https://openreview.net/forum?id=UACXMKAz0Z",
        "pdf_link": "https://openreview.net/pdf?id=UACXMKAz0Z",
        "keywords": "Generative models, diffusion models, sampling acceleration",
        "abstract": "Diffusion probabilistic models (DPMs) have achieved impressive success in visual generation. While, they suffer from slow inference speed due to iterative sampling. \n   Employing fewer sampling steps is an intuitive solution, but this will also introduces discretization error. Existing fast samplers make inspiring efforts to reduce discretization error through the adoption of high-order solvers, potentially reaching a plateau in terms of optimization. This raises the question: can the sampling process be expedited further?\n   In this paper, we re-examine the nature of sampling errors, discerning that they comprise two distinct elements: the widely recognized discretization error and the less acknowledged approximation error.\n   Our research elucidates the dynamics between these errors and the step by implementing a dual-error disentanglement strategy.\n   Building on these foundations, we introduce an unified and training-free acceleration framework, DualFast, designed to enhance the speed of DPM sampling by concurrently accounting for both error types, thereby minimizing the total sampling error.\n   DualFast is seamlessly compatible with existing samplers and significantly boost their sampling quality and speed, particularly in extremely few sampling steps. \n   We substantiate the effectiveness of our framework through comprehensive experiments, spanning both unconditional and conditional sampling domains, across both pixel-space and latent-space DPMs."
    },
    {
        "title": "Enhance Graph Contrastive Learning with Perturbation Discrimination",
        "link_suffix": "/forum?id=ViY73s6j6Q",
        "link": "https://openreview.net/forum?id=ViY73s6j6Q",
        "pdf_link": "https://openreview.net/pdf?id=ViY73s6j6Q",
        "keywords": "Graph Representation, Contrastive Learning, Predictive Learning, Data Augmentation",
        "abstract": "Self-supervised learning of graph-structured data aims to produce transferable and robust representations that could be transferred to the downstream tasks. Among many, graph contrastive learning (GCL) based on data augmentation has emerged with promising performance in learning graph representation. However, it is observed that some augmentations might change the graph semantics due to the perturbations in the graph structure such as perturbing some nodes/edges. In such cases, existing GCL methods may suffer from performance limitations due to the introduction of noise augmentations. To address this issue, we propose to train a discriminative model to enhance GCL for graph-structured data, called Perturbation Discrimination-Enhanced GCL (PerEG). Specifically, for each perturbed graph, the discriminative model is trained to predict whether each node in the augmentation was perturbed by the perturbation compared to the original graph or not. Based on this, the results of perturbation discrimination are exploited to refine the GCL, enabling its controllable use of augmentation, thereby preferably utilizing augmentation and effectively avoiding the introduction of noise augmentation. Extensive experiments in unsupervised, semi-supervised, and transfer learning scenarios show that our PerEG outperforms the state-of-the-art methods on eight datasets."
    },
    {
        "title": "One Wave to Explain Them All: A Unifying Perspective on Post-hoc Explainability",
        "link_suffix": "/forum?id=50UzaXh0gC",
        "link": "https://openreview.net/forum?id=50UzaXh0gC",
        "pdf_link": "https://openreview.net/pdf?id=50UzaXh0gC",
        "keywords": "interpretability, feature attribution, wavelet, images, audio, 3D shapes",
        "abstract": "Despite the growing use of deep neural networks in safety-critical decision-making, their inherent black-box nature hinders transparency and interpretability. Explainable AI (XAI) methods have thus emerged to understand a model's internal workings, and notably attribution methods also called Saliency maps. Conventional attribution methods typically identify the locations - the where - of significant regions within an input. However, because they overlook the inherent structure of the input data, these methods often fail to interpret what these regions represent in terms of structural components (e.g., textures in images or transients in sounds). Furthermore, existing methods are usually tailored to a single data modality, limiting their generalizability. In this paper, we propose leveraging the wavelet domain as a robust mathematical foundation for attribution. Our approach, the Wavelet Attribution Method (WAM) extends the existing gradient-based feature attributions into the wavelet domain, providing a unified framework for explaining classifiers across images, audio, and 3D shapes. Empirical evaluations demonstrate that WAM matches or surpasses state-of-the-art methods across faithfulness metrics and models in image, audio, and 3D explainability. Finally, we show how our method explains not only the where - the important parts of the input - but also the what - the relevant patterns in terms of structural components."
    },
    {
        "title": "PhyloVAE: Unsupervised Learning of Phylogenetic Trees via Variational Autoencoders",
        "link_suffix": "/forum?id=Z8TglKXDWm",
        "link": "https://openreview.net/forum?id=Z8TglKXDWm",
        "pdf_link": "https://openreview.net/pdf?id=Z8TglKXDWm",
        "keywords": "Variational Autoencoders; Unsupervised Learning; Phylogenetic Trees; Representation Learning",
        "abstract": "Learning informative representations of phylogenetic tree structures is essential for analyzing evolutionary relationships. Classical distance-based methods have been widely used to project phylogenetic trees into Euclidean space, but they are often sensitive to the choice of distance metric and may lack sufficient resolution. In this paper, we introducephylogenetic variational autoencoders(PhyloVAEs), an unsupervised learning framework designed for representation learning and generative modeling of tree topologies. Leveraging an efficient encoding mechanism inspired by autoregressive tree topology generation, we develop a deep latent-variable generative model that facilitates fast, parallelized topology generation. PhyloVAE combines this generative model with a collaborative inference model based on learnable topological features, allowing for high-resolution representations of phylogenetic tree samples. Extensive experiments demonstrate PhyloVAE's robust representation learning capabilities and fast generation of phylogenetic tree topologies."
    },
    {
        "title": "SELF-EVOLVED REWARD LEARNING FOR LLMS",
        "link_suffix": "/forum?id=Zonhl0c9I0",
        "link": "https://openreview.net/forum?id=Zonhl0c9I0",
        "pdf_link": "https://openreview.net/pdf?id=Zonhl0c9I0",
        "keywords": "RLHF, LLM, Self-learning",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for aligning language models with human preferences and is a key factor in the success of modern conversational models like GPT-4, ChatGPT, and Llama 2. A significant challenge in employing RLHF lies in training a reliable RM, which relies on high-quality labels. Typically, these labels are provided by human experts or a stronger AI, both of which can be costly and introduce bias that may affect the language model's responses. As models improve, human input may become less effective in enhancing their performance. This paper explores the potential of using the RM itself to generate additional training data for a more robust RM. Our experiments demonstrate that reinforcement learning from self-feedback outperforms baseline approaches.\nWe conducted extensive experiments with our approach on multiple datasets, such as HH-RLHF and UltraFeedback, and models including Mistral and Llama 3, comparing it against various baselines. Our results indicate that, even with a limited amount of human-labeled data, learning from self-feedback can robustly enhance the performance of the RM, thereby improving the capabilities of large language models."
    },
    {
        "title": "FormulaReasoning: A Dataset for Formula-Based Numerical Reasoning",
        "link_suffix": "/forum?id=SXB9LnJ0SK",
        "link": "https://openreview.net/forum?id=SXB9LnJ0SK",
        "pdf_link": "https://openreview.net/pdf?id=SXB9LnJ0SK",
        "keywords": "formula, numerical reasoning, question answering",
        "abstract": "The application of formulas is a fundamental ability of humans when addressing numerical reasoning problems. However, existing numerical reasoning datasets seldom indicate explicitly the formulas employed during the reasoning steps. To bridge this gap, we construct a dataset for formula-based numerical reasoning called FormulaReasoning, which consists of 5,420 reasoning-based questions. We employ it to conduct evaluations of LLMs with size ranging from 7B to over 100B parameters utilizing zero-shot and few-shot chain-of-thought methods, and we further explore using retrieval-augmented LLMs provided with an external formula database associated with our dataset. We also experiment with supervised methods where we divide the reasoning process into formula generation, parameter extraction, and numerical calculation, and perform data augmentation. Our empirical findings underscore the significant potential for improvement in existing models when applied to our challenging, formula-driven FormulaReasoning."
    },
    {
        "title": "Physics-aligned field reconstruction with diffusion bridge",
        "link_suffix": "/forum?id=D042vFwJAM",
        "link": "https://openreview.net/forum?id=D042vFwJAM",
        "pdf_link": "https://openreview.net/pdf?id=D042vFwJAM",
        "keywords": "Fluid dynamics, diffusion models, super-resolution",
        "abstract": "The reconstruction of physical fields from sparse measurements is pivotal in both scientific research and engineering applications. Traditional methods are increasingly supplemented by deep learning models due to their efficacy in extracting features from data. However, except for the low accuracy on complex physical systems, these models often fail to comply with essential physical constraints, such as governing equations and boundary conditions. To overcome this limitation, we introduce a novel data-driven field reconstruction framework, termed the Physics-aligned Schr\"{o}dinger Bridge (PalSB). This framework leverages a diffusion bridge mechanism that is specifically tailored to align with physical constraints. The PalSB approach incorporates a dual-stage training process designed to address both local reconstruction mapping and global physical principles. Additionally, a boundary-aware sampling technique is implemented to ensure adherence to physical boundary conditions. We demonstrate the effectiveness of PalSB through its application to three complex nonlinear systems: cylinder flow from Particle Image Velocimetry experiments, two-dimensional turbulence, and a reaction-diffusion system. The results reveal that PalSB not only achieves higher accuracy but also exhibits enhanced compliance with physical constraints compared to existing methods. This highlights PalSB's capability to generate high-quality representations of intricate physical interactions, showcasing its potential for advancing field reconstruction techniques."
    },
    {
        "title": "Structured Joint Aleatoric and Epistemic Uncertainty for High Dimensional Output Spaces",
        "link_suffix": "/forum?id=Ilteh48w7m",
        "link": "https://openreview.net/forum?id=Ilteh48w7m",
        "pdf_link": "https://openreview.net/pdf?id=Ilteh48w7m",
        "keywords": "structured uncertainty, aleatoric, epistemic, high-dimensional data",
        "abstract": "Uncertainty estimation plays a vital role in enhancing the reliability of deep learning model predictions, especially in scenarios with high-dimensional output spaces. This paper addresses the dual nature of uncertainty \u2014 aleatoric and epistemic \u2014 focusing on their joint integration in high-dimensional regression tasks. We introduce an approach to approximate joint uncertainty using a low-rank plus diagonal covariance matrix, which preserves essential output correlations while mitigating the computational complexity associated with full covariance matrices. Specifically, our method reduces memory usage and enhances sampling efficiency and log-likelihood calculations. Simultaneously, our representation matches the true posterior better than factorized joint distributions, offering a clear advancement in reliability and explainability for deep learning model predictions. Furthermore, we empirically show that our method can efficiently enhance out of distribution detection in specific applications."
    },
    {
        "title": "Toward Principled Transformers for Knowledge Tracing",
        "link_suffix": "/forum?id=4dtwyV7XyW",
        "link": "https://openreview.net/forum?id=4dtwyV7XyW",
        "pdf_link": "https://openreview.net/pdf?id=4dtwyV7XyW",
        "keywords": "educational data mining, knowledge tracing, transformer",
        "abstract": "Knowledge tracing aims to reason about changes in students' knowledge and to predict students' performance in educational learning settings. We propose knowledge tracing set transformers (KTSTs), a straightforward model class for knowledge tracing prediction tasks. This model class is conceptually simpler than previous state-of-the-art approaches, which are overly complex due to domain-inspired components, and which are in part based on suboptimal design choices and flawed evaluation. In contrast, for KTSTs we propose principled set representations of student interactions and a simplified variant of learnable modification of attention matrices for positional information in a student's learning history. While being largely domain-agnostic, the proposed model class thus accounts for characteristic traits of knowledge tracing tasks. In extensive empirical experiments on standardized benchmark datasets, KTSTs establish new state-of-the-art performance."
    },
    {
        "title": "RAC-LoRA: A Theoretical Optimization Framework for Low-Rank Adaptation",
        "link_suffix": "/forum?id=VSKV3GykuE",
        "link": "https://openreview.net/forum?id=VSKV3GykuE",
        "pdf_link": "https://openreview.net/pdf?id=VSKV3GykuE",
        "keywords": "LORA, optimization, stochastic optimization, low-rank adaptation",
        "abstract": "Fine-tuning has become a popular approach to adapting large foundational models to specific tasks. As the size of models and datasets grows, parameter-efficient fine-tuning techniques are increasingly important. One of the most widely used methods is Low-Rank Adaptation (LoRA), with adaptation update expressed as the product of two low-rank matrices. While LoRA was shown to possess strong performance in fine-tuning, it often underperforms when compared to full-parameter fine-tuning (FPFT). Although many variants of LoRA have been extensively studied empirically, their theoretical optimization analysis is heavily under-explored. The starting point of our work is a demonstration that LoRA and its two extensions, Asymmetric LoRA and Chain of LoRA, indeed encounter convergence issues. To address these issues, we propose a general optimization framework that rigorously analyzes the convergence rates of LoRA-based methods. Our approach inherits the empirical benefits of LoRA-style heuristics, but introduces several small but important algorithmic modifications which turn it into a provably convergent method. Our framework serves as a bridge between FPFT and low-rank adaptation. We provide provable guarantees of convergence to the same solution as FPFT, along with the rate of convergence. Additionally, we present a convergence analysis for smooth, non-convex loss functions, covering gradient descent, stochastic gradient descent, and federated learning settings. Our theoretical findings are supported by experimental results."
    },
    {
        "title": "BOSE-NAS: Differentiable Neural Architecture Search with Bi-Level Optimization Stable Equilibrium",
        "link_suffix": "/forum?id=2l301qUdor",
        "link": "https://openreview.net/forum?id=2l301qUdor",
        "pdf_link": "https://openreview.net/pdf?id=2l301qUdor",
        "keywords": "Neural Architecture Search, Stable Equilibrium State, Equilibrium Influential",
        "abstract": "Differentiable Architecture Search (DARTS) has gained prominence in the neural architecture search community for its efficiency and simplicity, achieved through optimizing architecture parameters via gradient descent. However, the magnitude of these architecture parameters frequently fails to accurately represent the true significance of the corresponding operations, adversely affecting the performance of the resultant architectures. While numerous studies have introduced alternative metrics to evaluate operation significance, the actual role and impact of architecture parameters remain inadequately explored. This lack of understanding creates critical ambiguity in the architecture search process. Resolving these ambiguities is essential for the effective utilization of architecture parameters, thereby facilitating the development of more effective differentiable NAS methodologies. In this work, we first conduct a rigorous theoretical analysis, revealing that the change rate of architecture parameters reflects the sensitivity of the supernet\u2019s validation loss in the architecture space. Building on this foundation, we introduce the concept of the \u2018Stable Equilibrium State\u2019, which offers essential insights into the validation loss trajectory across architectural spaces and elucidates the stability of the supernet\u2019s bi-level optimization process. We further investigate the supernet training dynamics to assess the influence of operations on the Stable Equilibrium State, leading to the proposal of a novel metric for evaluating operation importance, termed Equilibrium Influential ($E_\\mathcal{I}$). Integrating these elements, we introduce BOSE-NAS, an effective differentiable NAS method that utilizes the Stable Equilibrium State to identify the optimal state during the search process, subsequently deriving the final architecture based on the $E_\\mathcal{I}$ metric. Extensive experiments conducted across diverse datasets and search spaces demonstrate that BOSE-NAS achieves competitive test accuracy compared to state-of-the-art methods while significantly reducing search costs."
    },
    {
        "title": "Long-time asymptotics of noisy SVGD outside the population limit",
        "link_suffix": "/forum?id=X7eAhXcps1",
        "link": "https://openreview.net/forum?id=X7eAhXcps1",
        "pdf_link": "https://openreview.net/pdf?id=X7eAhXcps1",
        "keywords": "Stochastic approximation, sampling, convergence, interacting particles system, dynamical systems, Stein Variational Gradient Descent, McKean-Vlasov equation",
        "abstract": "Stein Variational Gradient Descent (SVGD) is a widely used sampling algorithm that has been successfully applied in several areas of Machine Learning. SVGD operates by iteratively moving a set of $n$ interacting particles (which represent the samples) to approximate the target distribution. Despite recent studies on the complexity of SVGD and its variants, their long-time asymptotic behavior (i.e., after numerous iterations $k$) is still not understood in the finite number of particles regime. We study the long-time asymptotic behavior of a noisy variant of SVGD. First, we establish that the limit set of noisy SVGD for large $k$ is well-defined. We then characterize this limit set, showing that it approaches the target distribution as $n$ increases. In particular, noisy SVGD provably avoids the variance collapse observed for SVGD. Our approach involves demonstrating that the trajectories of noisy SVGD closely resemble those described by a McKean-Vlasov process."
    },
    {
        "title": "RegMix: Data Mixture as Regression for Language Model Pre-training",
        "link_suffix": "/forum?id=5BjQOUXq7i",
        "link": "https://openreview.net/forum?id=5BjQOUXq7i",
        "pdf_link": "https://openreview.net/pdf?id=5BjQOUXq7i",
        "keywords": "language model pre-training, data mixture, regression",
        "abstract": "The data mixture for large language model pre-training significantly impacts performance, yet how to determine an effective mixture remains unclear. We propose RegMix to automatically identify a high-performing data mixture by formulating it as a regression task. RegMix involves training a set of small models with diverse data mixtures and fitting a regression model to predict their performance given their respective mixtures. With the fitted regression model, we simulate the top-ranked mixture and use it to train a large-scale model with orders of magnitude more compute. To empirically validate RegMix, we train 512 models with 1M parameters for 1B tokens of different mixtures to fit the regression model and find the optimal mixture. Using this mixture we train a 1B parameter model for 25B tokens (i.e. 1000x larger and 25x longer) which we find performs best among 64 candidate 1B parameter models with other mixtures. Further, our method outperforms both human selection and DoReMi in terms of both validation loss and downstream performance. Our experiments also show that (1) Data mixtures significantly impact performance with single-task performance variations of up to 14.6%; (2) Web corpora rather than data perceived as high-quality like Wikipedia have the strongest positive correlation with downstream performance; (3) Domains interact in complex ways often contradicting common sense, thus automatic approaches like RegMix are needed."
    }
]
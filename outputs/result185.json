[{"title": "Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization", "link_suffix": "/forum?id=D9liZ0D8z8", "link": "https://openreview.net/forum?id=D9liZ0D8z8", "pdf_link": "https://openreview.net/pdf?id=D9liZ0D8z8", "keywords": "time series forecasting, foundation models, wavelets, tokenization, frequency, pretrained model, nonstationary time series", "abstract": "There is a major open question about how to best develop foundation models for time series forecasting. Tokenization is a crucial consideration in this effort: what is an effective discrete vocabulary for a real-valued sequential input? To address this question, we develop WaveToken, a wavelet-based tokenizer that allows models to learn complex representations directly in the space of time-localized frequencies. Our method first scales and decomposes the input time series, then thresholds and quantizes the wavelet coefficients, and finally pre-trains an autoregressive model to forecast coefficients for the horizon window. By decomposing coarse and fine structures in the inputs, wavelets provide an eloquent and compact language for time series forecasting that simplifies learning. Empirical results on a comprehensive benchmark, including 42 datasets for both in-domain and zero-shot settings, show that WaveToken: i) provides better accuracy than recently proposed foundation models for forecasting while using a much smaller vocabulary (1024 tokens), and performs on par or better than modern deep learning models trained specifically on each dataset; and ii) exhibits superior generalization capabilities, achieving the best average rank across all datasets for three complementary metrics. In addition, we show that our method can easily capture complex temporal patterns of practical relevance that are challenging for other recent pre-trained models, including trends, sparse spikes, and non-stationary time series with varying frequencies evolving over time.", "title_embedding_index": 9200, "title_abs_embedding_index": 9225}, {"title": "Local Flow Matching Generative Models", "link_suffix": "/forum?id=MM197t8WlM", "link": "https://openreview.net/forum?id=MM197t8WlM", "pdf_link": "https://openreview.net/pdf?id=MM197t8WlM", "keywords": "flow-based generative modeling, stepwise training, model distillation", "abstract": "Flow Matching (FM) is a simulation-free method for learning a continuous and invertible flow to interpolate between two distributions, and in particular to generate data from noise in generative modeling. In this paper, we introduce Local Flow Matching ($\\texttt{LFM}$), which consecutively learns a sequence of FM sub-models and each matches a diffusion process up to the time of the step size in the data-to-noise direction. In each step, the two distributions to be interpolated by the sub-model are closer to each other than data vs. noise, and this enables the use of smaller models with faster training. The stepwise structure of $\\texttt{LFM}$ is natural to be distilled and different distillation techniques can be adopted to speed up generation. Theoretically, we prove a generation guarantee of the proposed flow model in terms of the $\\chi^2$-divergence between the generated and true data distributions. In experiments, we demonstrate the improved training efficiency and competitive generative performance of $\\texttt{LFM}$ compared to FM on the unconditional generation of tabular data and image datasets, and also on the conditional generation of robotic manipulation policies.", "title_embedding_index": 9201, "title_abs_embedding_index": 9226}, {"title": "IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning", "link_suffix": "/forum?id=XoulHHQGFi", "link": "https://openreview.net/forum?id=XoulHHQGFi", "pdf_link": "https://openreview.net/pdf?id=XoulHHQGFi", "keywords": "reinforcement learning, generalization, benchmarking, eco-driving", "abstract": "Despite the popularity of multi-agent reinforcement learning (RL) in simulated and two-player applications, its success in messy real-world applications has been limited. A key challenge lies in its generalizability across problem variations, a common necessity for many real-world problems. Contextual reinforcement learning (CRL) formalizes learning policies that generalize across problem variations. However, the lack of standardized benchmarks for multi-agent CRL has hindered progress in the field. Such benchmarks are desired to be based on real-world applications to naturally capture the many open challenges of real-world problems that affect generalization. To bridge this gap, we propose IntersectionZoo, a comprehensive benchmark suite for multi-agent CRL through the real-world application of cooperative eco-driving in urban road networks. The task of cooperative eco-driving is to control a fleet of vehicles to reduce fleet-level vehicular emissions. By grounding IntersectionZoo in a real-world application, we naturally capture real-world problem characteristics, such as partial observability and multiple competing objectives. IntersectionZoo is built on data-informed simulations of 16,334 signalized intersections derived from 10 major US cities, modeled in an open-source industry-grade microscopic traffic simulator. By modeling factors affecting vehicular exhaust emissions (e.g., temperature, road conditions, travel demand), IntersectionZoo provides one million data-driven traffic scenarios. Using these traffic scenarios, we benchmark popular multi-agent RL and human-like driving algorithms and demonstrate that the popular multi-agent RL algorithms struggle to generalize in CRL settings.", "title_embedding_index": 9202, "title_abs_embedding_index": 9227}, {"title": "SPDIM: Source-Free Unsupervised Conditional and Label Shift Adaptation in EEG", "link_suffix": "/forum?id=CoQw1dXtGb", "link": "https://openreview.net/forum?id=CoQw1dXtGb", "pdf_link": "https://openreview.net/pdf?id=CoQw1dXtGb", "keywords": "geometric deep learning, transfer learning, source-free adaptation, electroencephalography, neurology, brain-computer interfaces", "abstract": "The non-stationary nature of electroencephalography (EEG) introduces distribution\nshifts across domains (e.g., days and subjects), posing a significant challenge\nto EEG-based neurotechnology generalization. Without labeled calibration data\nfor target domains, the problem corresponds to a source-free unsupervised domain\nadaptation (SFUDA) problem. For scenarios with constant label distribution, Riemannian\ngeometry-aware statistical alignment frameworks on the symmetric positive\ndefinite (SPD) manifold are considered state-of-the-art. However, many practical\nscenarios, including EEG-based sleep staging, exhibit label shifts. Here, we\npropose a geometric deep learning framework for SFUDA problems under specific\ndistribution shifts including label shifts. We introduce a novel, realistic generative\nmodel and show that prior Riemannian statistical alignment methods on the SPD\nmanifold can compensate for specific covariate and conditional distribution shifts\nbut hurt generalization under label shifts. As a remedy, we propose a parameterefficient\nmanifold optimization strategy termed SPDIM. SPDIM uses the information\nmaximization principle to learn a single SPD-manifold-constrained parameter\nper target domain. In simulations, we demonstrate that SPDIM can compensate\nthe shifts under our generative model. Moreover, using public EEG-based braincomputer\ninterface and sleep staging datasets, we show that SPDIM outperforms\nprior approaches.", "title_embedding_index": 9203, "title_abs_embedding_index": 9228}, {"title": "CoMRes: Semi-Supervised Time Series Forecasting Utilizing Consensus Promotion of Multi-Resolution", "link_suffix": "/forum?id=bRa4JLPzii", "link": "https://openreview.net/forum?id=bRa4JLPzii", "pdf_link": "https://openreview.net/pdf?id=bRa4JLPzii", "keywords": "Time series forecasting, Multi-scale, Semi-supervised learning", "abstract": "Long-term time series forecasting poses significant challenges due to the complex dynamics and temporal variations, particularly when dealing with unseen patterns and data scarcity. Traditional supervised learning approaches, which rely on cleaned, labeled data, struggle to capture these unseen characteristics, limiting their effectiveness in real-world applications. In this study, we propose a semi-supervised approach that leverages multi-view setting to address these limitations. By introducing a consensus promotion framework, we enhance agreement among multiple single-view models using unseen augmented data. This approach not only improves forecasting accuracy but also reduces error accumulation in long-horizon predictions. Furthermore, we explore the impact of autoregressive and non-autoregressive decoding schemes on error propagation, demonstrating the robustness of our model in extending prediction horizons. Experimental results demonstrate that our proposed method not only surpasses traditional supervised models in accuracy but also exhibits greater robustness when extending the prediction horizon.", "title_embedding_index": 9204, "title_abs_embedding_index": 9229}, {"title": "Multi-Draft Speculative Sampling: Canonical Architectures and Theoretical Limits", "link_suffix": "/forum?id=N1L5TgtkAw", "link": "https://openreview.net/forum?id=N1L5TgtkAw", "pdf_link": "https://openreview.net/pdf?id=N1L5TgtkAw", "keywords": "speculative decoding, multi draft speculative sampling, large language models, weighted importance sampling, optimal transport", "abstract": "We consider multi-draft speculative sampling, where the proposal sequences are sampled independently from different draft models.  At each step, a  token-level draft selection scheme takes a list of valid tokens as input and produces an output token whose distribution matches that of the target model. Previous works have demonstrated that the optimal scheme (which maximizes the probability of accepting one of the input tokens) can be cast as a solution to a linear program. In this work we show that the optimal scheme can be decomposed into a two-step solution: in the first step an importance sampling (IS) type scheme is used to select one intermediate token; in the second step (single-draft) speculative sampling is applied to generate the output token.  For the case of two identical draft models we further 1) establish a necessary and sufficient condition on the distributions of the target and draft models for the acceptance probability to equal one and 2) provide an explicit expression for the optimal acceptance probability.  Our theoretical analysis also motives a new class of token-level selection scheme based on weighted importance sampling. Our experimental results demonstrate consistent improvements in the achievable block efficiency and token rates over baseline schemes in a number of scenarios.", "title_embedding_index": 9205, "title_abs_embedding_index": 9230}, {"title": "Transformer Block Coupling and its Correlation with Generalization in LLMs", "link_suffix": "/forum?id=kvLenbZZgg", "link": "https://openreview.net/forum?id=kvLenbZZgg", "pdf_link": "https://openreview.net/pdf?id=kvLenbZZgg", "keywords": "large language models, transformers, hidden representations", "abstract": "Large Language Models (LLMs) have made significant strides in natural language\nprocessing, and a precise understanding of the internal mechanisms driving their\nsuccess is essential. In this work, we trace the trajectories of individual tokens as they pass through transformer blocks, and linearize the system along these trajectories through their Jacobian matrices. By examining the relationships between these Jacobians, we uncover atransformer block couplingphenomenon in a variety of LLMs, characterized by the coupling of their top singular vectors across tokens and depth. Our findings reveal that couplingpositively correlateswith model performance, and that this relationship is stronger than with other hyperparameters, namely parameter budget, model depth, and embedding dimension. We further investigate the emergence of these properties through training, noting the development of coupling, as well as an increase in linearity and layer-wise exponential growth in the token trajectories. These collective insights provide a novel perspective on the interactions between token embeddings, and prompt further approaches to study training and generalization in LLMs.", "title_embedding_index": 9206, "title_abs_embedding_index": 9231}, {"title": "Reconciling Model Multiplicity for Downstream Decision Making", "link_suffix": "/forum?id=uy4EavBEwl", "link": "https://openreview.net/forum?id=uy4EavBEwl", "pdf_link": "https://openreview.net/pdf?id=uy4EavBEwl", "keywords": "model multiplicity, multi-calibration, decision-making, uncertainty quantification", "abstract": "We consider the problem of \\emph{model multiplicity} in downstream decision-making, a setting where two predictive models of equivalent accuracy cannot agree on what action to take for a downstream decision-making problem. Prior work attempts to address model multiplicity by resolving prediction disagreement between models. However, we show that even when the two predictive models approximately agree on their individual predictions almost everywhere, these models can lead the downstream decision-maker to take actions with substantially higher losses. We address this issue by proposing a framework that \\emph{calibrates} the predictive models with respect to both a finite set of downstream decision-making problems and the individual probability prediction. Specifically, leveraging tools from multi-calibration, we provide an algorithm that, at each time-step, first reconciles the differences in individual probability prediction, then calibrates the updated models such that they are indistinguishable from the true probability distribution to the decision-makers. We extend our results to the setting where one does not have direct access to the true probability distribution and instead relies on a set of i.i.d data to be the empirical distribution. Furthermore, we generalize our results to the settings where one has more than two predictive models and an infinitely large downstream action set. Finally, we provide a set of experiments to evaluate our methods empirically. Compared to existing work, our proposed algorithm creates a pair of predictive models with improved downstream decision-making losses and agrees on their best-response actions almost everywhere.", "title_embedding_index": 9207, "title_abs_embedding_index": 9232}, {"title": "SePPO: Semi-Policy Preference Optimization for Diffusion Alignment", "link_suffix": "/forum?id=5CHcmVzbAz", "link": "https://openreview.net/forum?id=5CHcmVzbAz", "pdf_link": "https://openreview.net/pdf?id=5CHcmVzbAz", "keywords": "Reinforcement Learning, Diffusion Model, Image Generation, Video Generation", "abstract": "Reinforcement learning from human feedback (RLHF) methods are emerging as a way to fine-tune diffusion models (DMs) for visual generation. However, commonly used on-policy strategies are limited by the generalization capability of the reward model, while off-policy approaches require large amounts of difficult-to-obtain paired human-annotated data, particularly in visual generation tasks. To address the limitations of both on- and off-policy RLHF, we propose a preference optimization method that aligns DMs with preferences without relying on reward models or paired human-annotated data. Specifically, we introduce a Semi-Policy Preference Optimization (SePPO) method. SePPO leverages previous checkpoints as reference models while using them to generate on-policy reference samples, which replace \u201closing images\u201d in preference pairs. This approach allows us to optimize using only off-policy \u201cwinning images\u201d. Furthermore, we design a strategy for reference model selection that expands the exploration in the policy space. Notably, we do not simply treat reference samples as negative examples for learning. Instead, we design an anchor-based criterion to assess whether the reference samples are likely to be winning or losing images, allowing the model to selectively learn from the generated reference samples. This approach mitigates performance degradation caused by the uncertainty in reference sample quality. We validate SePPO across both text-to-image and text-to-video benchmarks. SePPO surpasses all previous approaches on the text-to-image benchmarks and also demonstrates outstanding performance on the text-to-video benchmarks.", "title_embedding_index": 9208, "title_abs_embedding_index": 9233}, {"title": "Robust System Identification: Finite-sample Guarantees and Connection to Regularization", "link_suffix": "/forum?id=ZNnmcddaB3", "link": "https://openreview.net/forum?id=ZNnmcddaB3", "pdf_link": "https://openreview.net/pdf?id=ZNnmcddaB3", "keywords": "dynamical system, time series, system identification, optimization", "abstract": "We address the problem of learning nonlinear dynamical systems from a single sample trajectory. While the least squares estimate (LSE) is commonly used for this task, it suffers from poor identification errors when the sample size is small or the model fails to capture the system's true dynamics. To overcome these limitations, we propose a robust LSE framework, which incorporates robust optimization techniques, and prove that it is equivalent to regularizing LSE using general Schatten $p$-norms. We provide non-asymptotic performance guarantees for linear systems, achieving an error rate of $\\widetilde{\\mathcal{O}}(1/\\sqrt{T})$, and show that it avoids the curse of dimensionality, unlike state-of-the-art Wasserstein robust optimization models. Empirical results demonstrate substantial improvements in real-world system identification and online control tasks, outperforming existing methods.", "title_embedding_index": 9209, "title_abs_embedding_index": 9234}, {"title": "eQMARL: Entangled Quantum Multi-Agent Reinforcement Learning for Distributed Cooperation over Quantum Channels", "link_suffix": "/forum?id=cR5GTis5II", "link": "https://openreview.net/forum?id=cR5GTis5II", "pdf_link": "https://openreview.net/pdf?id=cR5GTis5II", "keywords": "quantum machine learning, multi-agent reinforcement learning, quantum entanglement", "abstract": "Collaboration is a key challenge in distributed multi-agent reinforcement learning (MARL) environments. Learning frameworks for these decentralized systems must weigh the benefits of explicit player coordination against the communication overhead and computational cost of sharing local observations and environmental data. Quantum computing has sparked a potential synergy between quantum entanglement and cooperation in multi-agent environments, which could enable more efficient distributed collaboration with minimal information sharing. This relationship is largely unexplored, however, as current state-of-the-art quantum MARL (QMARL) implementations rely on classical information sharing rather than entanglement over a quantum channel as a coordination medium. In contrast, in this paper, a novel framework dubbed entangled QMARL (eQMARL) is proposed. The proposed eQMARL is a distributed actor-critic framework that facilitates cooperation over a quantum channel and eliminates local observation sharing via a quantum entangled split critic. Introducing a quantum critic uniquely spread across the agents allows coupling of local observation encoders through entangled input qubits over a quantum channel, which requires no explicit sharing of local observations and reduces classical communication overhead. Further, agent policies are tuned through joint observation-value function estimation via joint quantum measurements, thereby reducing the centralized computational burden. Experimental results show that eQMARL with $\\Psi^{+}$ entanglement converges to a cooperative strategy up to $17.8\\%$ faster and with a higher overall score compared to split classical and fully centralized classical and quantum baselines. The results also show that eQMARL achieves this performance with a constant factor of $25$-times fewer centralized parameters compared to the split classical baseline.", "title_embedding_index": 9210, "title_abs_embedding_index": 9235}, {"title": "Meta-learning Representations for Learning from Multiple Annotators", "link_suffix": "/forum?id=TMutFl74tX", "link": "https://openreview.net/forum?id=TMutFl74tX", "pdf_link": "https://openreview.net/pdf?id=TMutFl74tX", "keywords": "Meta-learning, Few-shot learning, Multiple annotators, Noisy labels, Crowdsourcing", "abstract": "We propose a meta-learning method for learning from multiple noisy annotators. In many applications such as crowdsourcing services,\nlabels for supervised learning are given by multiple annotators. Since the annotators have different skills or biases, given labels can be noisy. To learn accurate classifiers, existing methods require many annotated data to deal with noisy labels. However, sufficient data might be unavailable in practice. To overcome the lack of data, the proposed method uses labeled data obtained in different but related tasks. The proposed method embeds each example in tasks to a latent space by using a neural network and constructs a probabilistic model for learning a task-specific classifier while estimating annotators' abilities on the latent space. This neural network is meta-learned to improve the expected test classification performance when the classifier is adapted to a given small amount of annotated data. This classifier adaptation is performed by maximizing the posterior probability via the expectation-maximization (EM) algorithm. Since each step in the EM algorithm is easily computed as a closed-form and is differentiable, the proposed method can efficiently backpropagate the loss through the EM algorithm to meta-learn the neural network. We demonstrate the effectiveness of the proposed method with real-world datasets with synthetic noise and real-world crowdsourcing datasets.", "title_embedding_index": 9211, "title_abs_embedding_index": 9236}, {"title": "A Controlled Study on Long Context  Extension and Generalization in LLMs", "link_suffix": "/forum?id=VkqqZcofEu", "link": "https://openreview.net/forum?id=VkqqZcofEu", "pdf_link": "https://openreview.net/pdf?id=VkqqZcofEu", "keywords": "Controlled Study, Long Context, Extension, Benchmark, Analysis", "abstract": "Broad textual understanding and in-context learning require language models that utilize full document contexts. Due to the implementation challenges associated with directly training long-context models, many methods have been proposed for extending models to handle long contexts. However, owing to differences in data and model classes, it has been challenging to compare these approaches, leading to uncertainty as to how to evaluate long-context performance and whether it differs from standard evaluation. We implement a controlled protocol for extension methods with a standardized evaluation, utilizing consistent base models and extension data. Our study yields several insights into long-context behavior. First, we reaffirm the critical role of perplexity as a general-purpose performance indicator even in longer-context tasks. Second, we find that current approximate attention methods systematically underperform across long-context tasks. Finally, we confirm that exact fine-tuning based methods are generally effective within their extension range, whereas extrapolation remains challenging. All codebases, models, and checkpoints will be made available open-source, promoting transparency and facilitating further research in this critical area of AI development.", "title_embedding_index": 9212, "title_abs_embedding_index": 9237}, {"title": "E(n) Equivariant Topological Neural Networks", "link_suffix": "/forum?id=Ax3uliEBVR", "link": "https://openreview.net/forum?id=Ax3uliEBVR", "pdf_link": "https://openreview.net/pdf?id=Ax3uliEBVR", "keywords": "Topological Deep Learning, Equivariance, Equivariant Neural Networks, Geometric Deep Learning, Geospatial data, Air Pollution Prediction, Molecular Property Prediction", "abstract": "Graph neural networks excel at modeling pairwise interactions, but they cannot flexibly accommodate higher-order interactions and features. Topological deep learning (TDL) has emerged recently as a promising tool for addressing this issue. TDL enables the principled modeling of arbitrary multi-way, hierarchical higher-order interactions by operating on combinatorial topological spaces, such as simplicial or cell complexes, instead of graphs. However, little is known about how to leverage geometric features such as positions and velocities for TDL. This paper introduces E(n)-Equivariant Topological Neural Networks (ETNNs), which are E(n)-equivariant message-passing networks operating on combinatorial complexes, formal objects unifying graphs, hypergraphs, simplicial, path, and cell complexes. ETNNs incorporate geometric node features while respecting rotation, reflection, and translation equivariance. Moreover, ETNNs are natively ready for settings with heterogeneous interactions.  We provide a theoretical analysis to show the improved expressiveness of ETNNs over architectures for geometric graphs. We also show how E(n)-equivariant variants of TDL models can be directly derived from our framework. The broad applicability of ETNNs is demonstrated through two tasks of vastly different scales: i) molecular property prediction on the QM9 benchmark and ii) land-use regression for hyper-local estimation of air pollution with multi-resolution irregular geospatial data.  The results indicate that ETNNs are an effective tool for learning from diverse types of richly structured data, as they match or surpass SotA equivariant TDL models with a significantly smaller computational burden, thus highlighting the benefits of a principled geometric inductive bias.", "title_embedding_index": 9213, "title_abs_embedding_index": 9238}, {"title": "Toward Robust Defenses Against LLM Weight Tampering Attacks", "link_suffix": "/forum?id=4FIjRodbW6", "link": "https://openreview.net/forum?id=4FIjRodbW6", "pdf_link": "https://openreview.net/pdf?id=4FIjRodbW6", "keywords": "ai safety, large language models, tamper-resistance, unlearning, meta-learning", "abstract": "Rapid advances in the capabilities of large language models (LLMs) have raised widespread concerns regarding their potential for malicious use. Open-weight LLMs present unique challenges, as existing safeguards lack robustness to tampering attacks that modify model weights. For example, recent works have demonstrated that refusal and unlearning safeguards can be trivially removed with a few steps of fine-tuning. These vulnerabilities necessitate new approaches for enabling the safe release of open-weight LLMs. We develop a method, called TAR, for building tamper-resistant safeguards into open-weight LLMs such that adversaries cannot remove the safeguards even after thousands of steps of fine-tuning. In extensive evaluations and red teaming analyses, we find that our method greatly improves tamper-resistance while preserving benign capabilities. Our results demonstrate that progress on tamper-resistance is possible, opening up a promising new avenue to improve the safety and security of open-weight LLMs.", "title_embedding_index": 9214, "title_abs_embedding_index": 9239}, {"title": "First-Person Fairness in Chatbots", "link_suffix": "/forum?id=TlAdgeoDTo", "link": "https://openreview.net/forum?id=TlAdgeoDTo", "pdf_link": "https://openreview.net/pdf?id=TlAdgeoDTo", "keywords": "fairness, large language models, chatbots", "abstract": "Some chatbots have access to a user\u2019s name when responding. Prior work has\nshown that large language model outputs can change based on the demographic\ntraits correlated with a name, such as gender or race. In this study, we introduce\na privacy-preserving and scalable method for studying one form offirst-person\nfairness\u2014fairness towards the user based on their demographic information\u2014\nacross a large and heterogeneous corpus of actual chats. We leverage a language\nmodel as an AI \u201cresearch assistant\u201d (AI RA) that can privately and scalably analyze\nchat data, surfacing broader trends without exposing specific examples to the\nresearchers. We corroborate the labels of the AI RA with independent human\nannotations, finding it highly consistent with human ratings of gender bias (less so\nfor racial bias). We apply this methodology to a large set of chats with a commercial\nchatbot.We assess overall quality of responses conditional on different names and\nalso subtle differences in similar-quality responses that may in aggregate reinforce\nharmful stereotypes based on gender or race. The largest detected biases are gender\nbiases in older generations of models and in open-ended tasks, like writing a story.\nFinally, we discuss methods for monitoring and further reducing such biases.\nSome chatbots have access to a user\u2019s name when responding. Prior work has\nshown that large language model outputs can change based on the demographic\ntraits correlated with a name, such as gender or race. In this study, we introduce\na privacy-preserving and scalable method for studying one form of first-person\nfairness\u2014fairness towards the user based on their demographic information\u2014\nacross a large and heterogeneous corpus of actual chats. We leverage a language\nmodel as an AI \u201cresearch assistant\u201d (AI RA) that can privately and scalably analyze\nchat data, surfacing broader trends without exposing specific examples to the\nresearchers. We corroborate the labels of the AI RA with independent human\nannotations, finding it highly consistent with human ratings of gender bias (less so\nfor racial bias). We apply this methodology to a large set of chats with a commercial\nchatbot.We assess overall quality of responses conditional on different names and\nalso subtle differences in similar-quality responses that may in aggregate reinforce\nharmful stereotypes based on gender or race. The largest detected biases are gender\nbiases in older generations of models and in open-ended tasks, like writing a story.\nFinally, we discuss methods for monitoring and further reducing such biases.", "title_embedding_index": 9215, "title_abs_embedding_index": 9240}, {"title": "SHAP-CAT: A interpretable multi-modal framework enhancing WSI classification via virtual staining and shapley-value-based multimodal fusion", "link_suffix": "/forum?id=jHdsZCOouv", "link": "https://openreview.net/forum?id=jHdsZCOouv", "pdf_link": "https://openreview.net/pdf?id=jHdsZCOouv", "keywords": "multimodal, data fusion, computational pathology, shapley value, virtual staining", "abstract": "The multimodal model has demonstrated promise in histopathology. However, most multimodal models are based on H&E and genomics, adopting increasingly complex yet black-box designs. In our paper, we propose a novel interpretable multimodal framework named SHAP-CAT, which uses a Shapley-value-based dimension reduction technique for effective multimodal fusion. Starting with two paired modalities -- H&E and IHC images, we employ virtual staining techniques to enhance limited input data by generating a new clinical-related modality. We extract very lightweight bag-level representations from each image modality and apply a Shapley-value-based mechanism for dimension reduction. Lightweight bag-level representations are extracted from image modalities and a Shapley-value-based mechanism is used for dimension reduction.For each dimension of the bag-level representation, attribution values are calculated to indicate how changes in the specific dimensions of the input affect the model output. In this way, we select a few top important dimensions of bag-level representation for each image modality to late fusion. Our experimental results demonstrate that the proposed SHAP-CAT framework incorporating synthetic modalities significantly enhances model performance, yielding a 5% increase in accuracy for the BCI, an 8% increase for IHC4BC-ER, and an 11% increase for the IHC4BC-PR dataset.", "title_embedding_index": 9216, "title_abs_embedding_index": 9241}, {"title": "Beyond Worst-Case Dimensionality Reduction for Sparse Vectors", "link_suffix": "/forum?id=e8qXTxMgPg", "link": "https://openreview.net/forum?id=e8qXTxMgPg", "pdf_link": "https://openreview.net/pdf?id=e8qXTxMgPg", "keywords": "dimensionality reduction, sparsity, johnson lindenstrauss", "abstract": "We study beyond worst-case dimensionality reduction for $s$-sparse vectors (vectors with at most $s$ non-zero coordinates). Our work is divided into two parts, each focusing on a different facet of beyond worst-case analysis:\\noindent (a)  We first consider average-case guarantees for embedding $s$-sparse vectors. Here, a well-known folklore upper bound based on the birthday-paradox states: For any collection $X$ of $s$-sparse vectors in $\\mathbb{R}^d$, there exists a linear map $A: \\mathbb{R}^d \\rightarrow \\mathbb{R}^{O(s^2)}$ which \\emph{exactly} preserves the norm of $99%$ of the vectors in $X$ in any $\\ell_p$ norm (as opposed to the usual setting where guarantees hold for all vectors). We provide novel lower bounds showing that this is indeed optimal in many settings. Specifically, any oblivious linear map satisfying similar average-case guarantees must map to $\\Omega(s^2)$ dimensions. The same lower bound also holds for a wider class of sufficiently smooth maps, including `encoder-decoder schemes', where we compare the norm of the original vector to that of a smooth function of the embedding. These lower bounds reveal a surprising separation result for smooth embeddings of sparse vectors, as an upper bound of $O(s \\log(d))$ is possible if we instead use arbitrary functions, e.g., via compressed sensing algorithms.(b) Given these lower bounds, we specialize to sparse \\emph{non-negative} vectors to hopes of improved upper bounds. For a dataset $X$ of non-negative $s$-sparse vectors and any $p \\ge 1$, we can non-linearly embed $X$ to $O(s\\log(|X|s)/\\varepsilon^2)$ dimensions while preserving all pairwise distances in $\\ell_p$ norm up to $1\\pm \\varepsilon$, with no dependence on $p$. Surprisingly, the non-negativity assumption enables much smaller embeddings than arbitrary sparse vectors, where the best known bound suffers an exponential $(\\log |X|)^{O(p)}$ dependence. Our map also guarantees \\emph{exact} dimensionality reduction for the $\\ell_{\\infty}$ norm by embedding $X$ into $O(s\\log |X|)$ dimensions, which is tight. We further give separation results showing that both the non-linearity of $f$ and the non-negativity of $X$ are necessary, and provide downstream algorithmic improvements using our embedding.", "title_embedding_index": 9217, "title_abs_embedding_index": 9242}, {"title": "Can Large Language Models Understand Symbolic Graphics Programs?", "link_suffix": "/forum?id=Yk87CwhBDx", "link": "https://openreview.net/forum?id=Yk87CwhBDx", "pdf_link": "https://openreview.net/pdf?id=Yk87CwhBDx", "keywords": "Large Language Models, Symbolic Graphics Programs", "abstract": "Against the backdrop of enthusiasm for large language models (LLMs), there is an urgent need to scientifically assess their capabilities and shortcomings. This is nontrivial in part because it is difficult to find tasks which the models have not encountered during training.\nUtilizing symbolic graphics programs, we propose a domain well-suited to test multiple spatial-semantic reasoning skills of LLMs. Popular in computer graphics, these programs procedurally generate visual data. While LLMs exhibit impressive skills in general program synthesis and analysis, symbolic graphics programs offer a new layer of evaluation: they allow us to test an LLM's ability to answer different-grained semantic-level questions of the images or 3D geometries without a vision encoder. To semantically understand the symbolic programs, LLMs would need to possess the ability to \"imagine\" and reason how the corresponding graphics content would look with only the symbolic description of the local curvatures and strokes. We use this task to evaluate LLMs by creating a large benchmark for the semantic visual understanding of symbolic graphics programs, built procedurally with minimal human effort. Particular emphasis is placed on transformations of images that leave the image level semantics invariant while introducing significant changes to the underlying program. We evaluate commercial and open-source LLMs on our benchmark to assess their ability to reason about visual output of programs, finding that LLMs considered stronger at reasoning generally perform better. Lastly, we introduce a novel method to improve this ability -- Symbolic Instruction Tuning (SIT), in which the LLM is finetuned with pre-collected instruction data on symbolic graphics programs. Interestingly, we find that SIT not only improves LLM's understanding on symbolic programs, but it also improves general reasoning ability on various other benchmarks.", "title_embedding_index": 9218, "title_abs_embedding_index": 9243}, {"title": "Steering Large Language Models between Code Execution and Textual Reasoning", "link_suffix": "/forum?id=5X5Z7Ffrjb", "link": "https://openreview.net/forum?id=5X5Z7Ffrjb", "pdf_link": "https://openreview.net/pdf?id=5X5Z7Ffrjb", "keywords": "Large Language Models, Code Interpreter, Code/text generation, Agent, Textual reasoning", "abstract": "While a lot of recent research focuses on enhancing the textual reasoning capabilities of Large Language Models (LLMs) by optimizing the multi-agent framework or reasoning chains, several benchmark tasks can be solved with 100% success through direct coding, which is more scalable and avoids the computational overhead associated with textual iterating and searching. Textual reasoning has inherent limitations in solving tasks with challenges in math, logics, optimization, and searching, which is unlikely to be solved by simply scaling up the model and data size. The recently released OpenAI GPT Code Interpreter and multi-agent frameworks such as AutoGen have demonstrated remarkable proficiency of integrating code generation and execution to solve complex tasks using LLMs. However, based on our experiments on 7 existing popular methods for steering code/text generation in both single- and multi-turn settings with 14 tasks and 6 types of LLMs, currently there is no optimal method to correctly steer LLMs to write code when needed. We discover some interesting patterns on when models use code vs. textual reasoning with the evolution to task complexity and model sizes, which even result in an astonishingly inverse scaling law. We also discover that results from LLM written code are not always better than using textual reasoning, even if the task could be solved through code. To mitigate the above issues, we propose three methods to better steer LLM code/text generation and achieve a notable improvement. The costs of token lengths and runtime are thoroughly discussed for all the methods. We believe the problem of steering LLM code/text generation is critical for future research and has much space for further improvement.", "title_embedding_index": 9219, "title_abs_embedding_index": 9244}, {"title": "MisspecifiedQ-Learning with Sparse Linear Function Approximation: Tight Bounds on Approximation Error", "link_suffix": "/forum?id=nIEjY4a2Lf", "link": "https://openreview.net/forum?id=nIEjY4a2Lf", "pdf_link": "https://openreview.net/pdf?id=nIEjY4a2Lf", "keywords": "misspecification error, reinforcement learning theory, sample complexity, sparsity", "abstract": "The recent work by Dong and Yang (2023) showed for misspecified sparse linear bandits, one can obtain an $O(\\epsilon)$-optimal policy using a polynomial number of samples when the sparsity is a constant, where $\\epsilon$ is the misspecification error. This result is in sharp contrast to misspecified linear bandits without sparsity, which require an exponential number of samples to get the same guarantee. In order to study whether the analog result is possible in the reinforcement learning setting, we consider the following problem: assuming the optimal $Q$-function is a $d$-dimensional linear function with sparsity $k$ and misspecification error $\\epsilon$, whether we can obtain an $O(\\epsilon)$-optimal policy using number of samples polynomially in the feature dimension $d$. We first demonstrate why the standard approach based on Bellman backup or the existing optimistic value function elimination approach such as OLIVE (Jiang et al., 2017) achieves suboptimal guarantees for this problem. We then design a novel elimination-based algorithm to show one can obtain an \n$O(H\\epsilon)$-optimal policy with sample complexity polynomially in the feature dimension $d$ and planning horizon $H$. Lastly, we complement our upper bound with an $\\tilde \\Omega(H\\epsilon)$ suboptimality lower bound, giving a complete picture of this problem.", "title_embedding_index": 9220, "title_abs_embedding_index": 9245}, {"title": "RankSHAP: Shapley Value Based Feature Attributions for Learning to Rank", "link_suffix": "/forum?id=4011PUI9vm", "link": "https://openreview.net/forum?id=4011PUI9vm", "pdf_link": "https://openreview.net/pdf?id=4011PUI9vm", "keywords": "Feature attributions, Shapley values, Information Retrieval, Passage Reranking", "abstract": "Numerous works propose post-hoc, model-agnostic explanations for learning to rank, focusing on ordering entities by their relevance to a query through feature attribution methods. However, these attributions often weakly correlate or contradict each other, confusing end users.  We adopt an axiomatic game-theoretic approach, popular in the feature attribution community, to identify a set of fundamental axioms that every ranking-based feature attribution method should satisfy. We then introduce Rank-SHAP, extending classical Shapley values to ranking. We evaluate the RankSHAP framework through extensive experiments on two datasets, multiple ranking methods and evaluation metrics. Additionally, a user study confirms RankSHAP\u2019s alignment with human intuition. We also perform an axiomatic analysis of existing rank attribution algorithms to determine their compliance with our proposed axioms. Ultimately, our aim is to equip practitioners with a set of axiomatically backed feature attribution methods for studying IR ranking models, that ensure generality as well as consistency.", "title_embedding_index": 9221, "title_abs_embedding_index": 9246}, {"title": "Annealing Flow Generative Model Towards Sampling High-Dimensional and Multi-Modal Distributions", "link_suffix": "/forum?id=XcAJ0qsMgh", "link": "https://openreview.net/forum?id=XcAJ0qsMgh", "pdf_link": "https://openreview.net/pdf?id=XcAJ0qsMgh", "keywords": "Continuous Normalizing Flow, Generative Model, Optimal Transport, High-Dimensional Sampling, Multi-Modal Sampling", "abstract": "Sampling from high-dimensional, multi-modal distributions remains a fundamental challenge across domains such as statistical Bayesian inference and physics-based machine learning. In this paper, we propose Annealing Flow (AF), a continuous normalizing flow-based approach designed to sample from high-dimensional and multi-modal distributions. The key idea is to learn a continuous normalizing flow-based transport map, guided by annealing, to transition samples from an easy-to-sample distribution to the target distribution, facilitating effective exploration of modes in high-dimensional spaces. Unlike many existing methods, AF training does not rely on samples from the target distribution. AF ensures effective and balanced mode exploration, achieves linear complexity in sample size and dimensions, and circumvents inefficient mixing times. We demonstrate the superior performance of AF compared to state-of-the-art methods through extensive experiments on various challenging distributions and real-world datasets, particularly in high-dimensional and multi-modal settings. We also highlight AF\u2019s potential for sampling the least favorable distributions.", "title_embedding_index": 9222, "title_abs_embedding_index": 9247}, {"title": "A probablistic automata learning approach for analyzing and sampling constrained LLM", "link_suffix": "/forum?id=CIcMuee69B", "link": "https://openreview.net/forum?id=CIcMuee69B", "pdf_link": "https://openreview.net/pdf?id=CIcMuee69B", "keywords": "Grammatical Inference, Probabilistic Deterministic Finite Automata, Active Learning, LLM", "abstract": "We define a congruence that copes with null next-symbol probabilities that arise when the output of a language model is constrained by some means during text generation. We develop an algorithm for efficiently learning the quotient with respect to this congruence and evaluate it on case studies for analyzing statistical properties of LLM.", "title_embedding_index": 9223, "title_abs_embedding_index": 9248}, {"title": "Generative Modeling of Individual Behavior at Scale", "link_suffix": "/forum?id=R9OHszNtpA", "link": "https://openreview.net/forum?id=R9OHszNtpA", "pdf_link": "https://openreview.net/pdf?id=R9OHszNtpA", "keywords": "style, parameter efficient fine-tuning, peft, chess, stylometry, playstyle, representation learning, steerability", "abstract": "Recent years have seen a growing interest in using AI to model human behavior, particularly in domains where humans learn from or collaborate with this technology. While most existing work attempts to model human behavior at an aggregate level, our goal is to model behavior at the individual level. Recent work in the domain of chess has shown that behavioral stylometry, or the task of identifying a person from their actions alone, can be achieved with high accuracy among a pool of a few thousand players. However, this approach cannot generate actions in the style of each player, and hence cannot reason about or influence player behavior in practice. We provide a new perspective on behavioral stylometry that addresses these limitations, by drawing a connection to the vast literature of transfer learning in NLP. Specifically, by casting the stylometry problem as a multi-task learning problem---where each task represents a distinct---we show that parameter-efficient fine-tuning (PEFT) methods can be adapted to model individual behavior in an explicit and generative manner, at unprecedented scale. We apply our approach at scale to two very different games: chess (47,864 players) and Rocket League (2,000 players).Our approach leverages recent modular PEFT methods to learn a shared set of skill parameters that can be combined in different ways via style vectors. Style vectors enable two important capabilities. First, they are generative: we can generate actions in the style of a player simply by conditioning on the player's style vector. Second, they induce a latent style space that we can interpret and manipulate algorithmically. This allows us to compare different player styles, as well as synthesize new (human-like) styles, e.g. by interpolating between the style vectors of two players.", "title_embedding_index": 9224, "title_abs_embedding_index": 9249}]
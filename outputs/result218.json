[{"title": "Narrow Transformer: Mono-lingual Code SLM for Desktop", "link_suffix": "/forum?id=ech9J3xl9X", "link": "https://openreview.net/forum?id=ech9J3xl9X", "pdf_link": "https://openreview.net/pdf?id=ech9J3xl9X", "keywords": "Narrow Transformer, Code SLMs, Desktop Deployment, Lightweight Code Language Models, Small Language Models, Language Specific Models, Monolingual Code Language Model", "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.", "title_embedding_index": 10850, "title_abs_embedding_index": 10875}, {"title": "Enhancing Treatment Effect Estimation with Generation-Driven Data Augmentation", "link_suffix": "/forum?id=K0WzGPTGwx", "link": "https://openreview.net/forum?id=K0WzGPTGwx", "pdf_link": "https://openreview.net/pdf?id=K0WzGPTGwx", "keywords": "treatment effect estimation, causal inference, data augmentation, generative models", "abstract": "We introduce $\\texttt{GATE}$, a framework for improving the estimation of conditional average treatment effects (CATE) from observational data. Our framework leverages generative models to selectively augment datasets with synthetic potential outcomes, thus addressing the covariate shift problem inherent in CATE estimation. However, data augmentation can also introduce bias when the generative model is imperfect; we theoretically analyze this trade-off and demonstrate thatperformance benefits can still be obtained when augmentation is performed only in a carefully chosen subset of the covariate space. To validate our approach, we instantiate $\\texttt{GATE}$ with various generative models, including those trained on the observational dataset and those trained on external data sources, such as large language models (LLMs). Our empirical results show that $\\texttt{GATE}$ effectively improves performance across various CATE models, especially in low-data regimes and under strong covariate shift. By focusing on data manipulation rather than model specification, $\\texttt{GATE}$ offers a flexible, model-agnostic solution capable of enhancinganyCATE learner and reducing the performance gap between different CATE models.", "title_embedding_index": 10851, "title_abs_embedding_index": 10876}, {"title": "Diffusion-based Decoupled Deterministic and Uncertain Framework for Probabilistic Multivariate Time Series Forecasting", "link_suffix": "/forum?id=HdUkF1Qk7g", "link": "https://openreview.net/forum?id=HdUkF1Qk7g", "pdf_link": "https://openreview.net/pdf?id=HdUkF1Qk7g", "keywords": "long-term time series forecasting, deep learning, diffusion model", "abstract": "Diffusion-based denoising models have demonstrated impressive performance in probabilistic forecasting for multivariate time series (MTS). Nonetheless, existing approaches often model the entire data distribution, neglecting the variability in uncertainty across different components of the time series. This paper introduces a Diffusion-based Decoupled Deterministic and Uncertain ($\\mathrm{D^3U}$) framework for probabilistic MTS forecasting. The framework integrates non-probabilistic forecasting with conditional diffusion generation, enabling both accurate point predictions and probabilistic forecasting. $\\mathrm{D^3U}$ utilizes a point forecasting model to non-probabilistically model high-certainty components in the time series, generating embedded representations that are conditionally injected into a diffusion model. To better model high-uncertainty components, a patch-based denoising network (PatchDN) is designed in the conditional diffusion model. Designed as a plug-and-play framework, $\\mathrm{D^3U}$ can be seamlessly integrated into existing point forecasting models to provide probabilistic forecasting capabilities. It can also be applied to other conditional diffusion methods that incorporate point forecasting models. Experiments on six real-world datasets demonstrate that our method achieves over a 20% improvement in both point and probabilistic forecasting performance in MTS long-term forecasting compared to state-of-the-art (SOTA) methods. Additionally, extensive ablation studies further validate the effectiveness of the $\\mathrm{D^3U}$ framework.", "title_embedding_index": 10852, "title_abs_embedding_index": 10877}, {"title": "AugKD: Ingenious Augmentations Empower Knowledge Distillation for Image Super-Resolution", "link_suffix": "/forum?id=AC3713Fmhx", "link": "https://openreview.net/forum?id=AC3713Fmhx", "pdf_link": "https://openreview.net/pdf?id=AC3713Fmhx", "keywords": "Image Super-Resolution, Knowledge Distillation, Model Compression", "abstract": "Knowledge distillation (KD) compresses deep neural networks by transferring task-related knowledge from cumbersome pre-trained teacher models to more compact student models. However, vanilla KD for image super-resolution (SR) networks only yields limited improvements due to the inherent nature of SR tasks, where the outputs of teacher models are noisy approximations of high-quality label images. In this work, we show that the potential of vanilla KD has been underestimated and demonstrate that the ingenious application of data augmentation methods can close the gap between it and more complex, well-designed methods. Unlike conventional training processes typically applying image augmentations simultaneously to both low-quality inputs and high-quality labels, we propose AugKD utilizing unpaired data augmentations to 1) generate auxiliary distillation samples and 2) impose label consistency regularization. Comprehensive experiments show that the AugKD significantly outperforms existing state-of-the-art KD methods across a range of SR tasks.", "title_embedding_index": 10853, "title_abs_embedding_index": 10878}, {"title": "HouseCrafter: Lifting Floorplans to 3D Scenes with 2D Diffusion Model", "link_suffix": "/forum?id=WKKD1Faobu", "link": "https://openreview.net/forum?id=WKKD1Faobu", "pdf_link": "https://openreview.net/pdf?id=WKKD1Faobu", "keywords": "diffusion model, indoor scene generation", "abstract": "We introduce HouseCrafter, a novel approach that can lift a floorplan into a complete large 3D indoor scene (e.g., a house). Our key insight is to adapt a 2D diffusion model, which is trained on web-scale images, to generate consistent multi-view color (RGB) and depth (D) images across different locations of the scene. Specifically, the RGB-D images are generated autoregressively in a batch-wise manner along sampled locations based on the floorplan, where previously generated images are used as condition to the diffusion model to produce images at nearby locations. The global floorplan and attention design in the diffusion model ensures the consistency of the generated images, from which a 3D scene can be reconstructed. Through extensive evaluation on the 3D-Front dataset, we demonstrate that HouseCraft can generate high-quality house-scale 3D scenes. Ablation studies also validate the effectiveness of different design choices. We will release our code and model weights.", "title_embedding_index": 10854, "title_abs_embedding_index": 10879}, {"title": "Multi-Perspective Test-Time Prompt Tuning for Global, Local Visuals, and Language", "link_suffix": "/forum?id=0Xc6o1HKXD", "link": "https://openreview.net/forum?id=0Xc6o1HKXD", "pdf_link": "https://openreview.net/pdf?id=0Xc6o1HKXD", "keywords": "Prompt Learning, Test Time Adaption, Vision-Language Models", "abstract": "Recent advances in vision-language models (VLMs) have demonstrated significant generalization across a broad range of tasks through prompt learning. However, bridging the distribution shift between training and test data remains a significant challenge. Existing researches utilize multiple augmented views of test samples for zero-shot adaptation. While effective, these approaches focus solely on global visual information, neglecting the local contextual details of test images. Moreover, simplistic, single-form textual descriptions limit the understanding of visual concepts, hindering the transfer performance of classes with similar or complex visual features. In this paper, we propose a Multi-Perspective  Test-Time Prompt Tuning method, MP-TPT, building on two key insights: local visual perception and class-specific description augmentation. Specifically, we introduce local visual representations from VLMs during the optimization process to enhance the prompts' ability to perceive local context. On the other hand, we design a data augmentation method at the text feature level that imparts regional visual priors to specific class texts, thereby enriching the class-specific descriptions. Furthermore, we synchronize the multi-view concept during the inference, integrating both local and global visual representations with text features for a deeper understanding of visual concepts. Through extensive experiments across 15 benchmark datasets, we demonstrate the advantages of MP-TPT, particularly achieving a 1% improvement in state-of-the-art TPT accuracy in cross-dataset settings, along with 4.5 times acceleration in inference speed.", "title_embedding_index": 10855, "title_abs_embedding_index": 10880}, {"title": "qNBO: quasi-Newton Meets Bilevel Optimization", "link_suffix": "/forum?id=BTOdzCzSRg", "link": "https://openreview.net/forum?id=BTOdzCzSRg", "pdf_link": "https://openreview.net/pdf?id=BTOdzCzSRg", "keywords": "bilevel optimization, quasi-Newton, convergence analysis, Hessian-free", "abstract": "Bilevel optimization, which addresses challenges in hierarchical learning tasks, has gained significant interest in machine learning. Implementing gradient descent for bilevel optimization presents computational hurdles, notably the need to compute the exact lower-level solution and the inverse Hessian of the lower-level objective. While these two aspects are inherently connected, existing methods typically handle them separately by solving the lower-level problem and a linear system for the inverse Hessian-vector product. In this paper, we introduce a general framework to tackle these computational challenges in a coordinated manner. Specifically, we leverage quasi-Newton algorithms to accelerate the solution of the lower-level problem while efficiently approximating the inverse Hessian-vector product. Furthermore, by leveraging the superlinear convergence properties of BFGS, we establish a non-asymptotic convergence analysis for the BFGS adaptation within our framework. Numerical experiments demonstrate the superior performance of our proposed algorithms in real-world learning tasks, including hyperparameter optimization, data hyper-cleaning, and few-shot meta-learning.", "title_embedding_index": 10856, "title_abs_embedding_index": 10881}, {"title": "FACTOR: Factoring Complexity and Context Length in Long-Context Model Evaluation", "link_suffix": "/forum?id=eNCyY81aW6", "link": "https://openreview.net/forum?id=eNCyY81aW6", "pdf_link": "https://openreview.net/pdf?id=eNCyY81aW6", "keywords": "Long-context reasoning, Language models", "abstract": "Large language models (LLMs) with extended context windows have shown remarkable capabilities, especially with contexts up to 128K tokens. However, whether these resource-intensive LLMs genuinely surpass simpler Retrieval Augmented Generation (RAG) techniques remains debated. \nWe precisely delineate differences between long-context LLMs and RAG methods, emphasizing the unique long-context reasoning abilities of LLMs that RAG cannot replicate. \nExisting benchmarks often focus on retrieval tasks and contain weak if not none complex reasoning tasks, hindering assessment of reasoning over extended contexts. We introduce the \\textbf{FACTOR} benchmark (\\textbf{F}actoring \\textbf{A}nalysis of \\textbf{C}omplexity and \\textbf{T}extual \\textbf{C}ontext in \\textbf{R}easoning), which evaluates LLMs by independently varying task complexity and context length. A comprehensive list of LLMs are evaluated on FACTOR. \nBesides mere accuracy scores, we also model the relationship between accuracy and complexity given the context length. A simple but consistent log-linear model works surprisingly well across various models. Also, the modeling contains two explainable parameters, the slope or Complexity Decay Factor (CDF) and the y-intercept or Contextual Decay Offset (CDO) that are shown to offer separate and insightful measures of the models' complex reasoning and long context innate ability. \nOur findings highlight distinct failure modes linked to task complexity and context length, underscoring the unique reasoning capabilities of long-context LLMs unattainable by RAG methods.", "title_embedding_index": 10857, "title_abs_embedding_index": 10882}, {"title": "Classic but Everlasting: Traditional Gradient-Based Algorithms Converges Fast Even in Time-Varying Multi-Player Games", "link_suffix": "/forum?id=t8FG4cJuL3", "link": "https://openreview.net/forum?id=t8FG4cJuL3", "pdf_link": "https://openreview.net/pdf?id=t8FG4cJuL3", "keywords": "time-varying games, Nash equilibrium, extra gradient algorithm, optimistic gradient algorithm", "abstract": "Last-iterate convergence behaviours of well-known algorithms are intensively investigated in various games, such as two-player bilinear zero-sum games.\nHowever, most known last-iterate convergence properties rely on strict settings where the underlying games must have time-invariant payoffs.\nBesides, the limited known attempts on the games with time-varying payoffs are in two-player bilinear time-varying zero-sum games and strictly monotone games. By contrast, in other time-varying games, the last-iterate behaviours of two classic algorithms, i.e., optimistic gradient (OG) and extra gradient (EG) algorithms,  still lack research, especially the convergence rates in multi-player games.\nIn this paper, we investigate the last-iterate behaviours of OG and EG algorithms for convergent perturbed games, which extend upon the usual model of time-invariant games and incorporate external factors, such as vanishing noises.\nUsing the recently proposed notion of the tangent residual (or its modifications) as the potential function of games and the measure of proximity to the Nash equilibrium, we prove that the last-iterate convergence rates of EG and OG algorithms for perturbed games on bounded convex closed sets are $O({1}/{\\sqrt{T}})$ if such games converge to monotone games at rates fast enough and that such a result holds true for certain unconstrained perturbed games. With this result, we address an open question\nasking for the last-iterate convergence rate of the extra gradient and the optimistic gradient algorithms in constrained and time-varying settings. The above convergence rates are similar to known tight results on corresponding time-invariant games.", "title_embedding_index": 10858, "title_abs_embedding_index": 10883}, {"title": "Toward Escaping Model Collapse: Aligning Generated Images as a New Modality", "link_suffix": "/forum?id=mNkPAY3kvk", "link": "https://openreview.net/forum?id=mNkPAY3kvk", "pdf_link": "https://openreview.net/pdf?id=mNkPAY3kvk", "keywords": "diffusion models, generated visual learning, vision-language models", "abstract": "Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can harm model performance and even cause model collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined $\\textit{GenRA}$ ($\\textbf{Gen}$erated-$\\textbf{R}$eal $\\textbf{A}$lignment), that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the input space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach.\nTo be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image training across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.", "title_embedding_index": 10859, "title_abs_embedding_index": 10884}, {"title": "SVBench: A Benchmark with Temporal Multi-Turn Dialogues for Streaming Video Understanding", "link_suffix": "/forum?id=Hz4BYVY8YM", "link": "https://openreview.net/forum?id=Hz4BYVY8YM", "pdf_link": "https://openreview.net/pdf?id=Hz4BYVY8YM", "keywords": "Multimodal large language model, Streaming video analysis, Video understanding", "abstract": "Despite the significant advancements of Large Vision-Language Models (LVLMs) on established benchmarks, there remains a notable gap in suitable evaluation regarding their applicability in the emerging domain of long-context streaming video understanding. Current benchmarks for video understanding typically emphasize isolated single-instance text inputs and fail to evaluate the capacity to sustain temporal reasoning throughout the entire duration of video streams. To address these limitations, we introduce SVBench, a pioneering benchmark with temporal multi-turn question-answering chains specifically designed to thoroughly assess the capabilities of streaming video understanding of current LVLMs. We design a semi-automated annotation pipeline to obtain 49,979 Question-Answer (QA) pairs of 1,353 streaming videos, which includes generating QA chains that represent a series of consecutive multi-turn dialogues over video segments and constructing temporal linkages between successive QA chains. Our experimental results, obtained from 14 models in dialogue and streaming evaluations, reveal that while the closed-source GPT-4o outperforms others, most open-source LVLMs struggle with long-context streaming video understanding. We also construct a StreamingChat model, which significantly outperforms open-source LVLMs on our SVBench and achieves comparable performance on diverse vision-language benchmarks. We expect SVBench to advance the research of streaming video understanding by providing a comprehensive and in-depth analysis of current LVLMs. Our benchmark and model can be accessed athttps://anonymous.4open.science/r/SVBench-356F.", "title_embedding_index": 10860, "title_abs_embedding_index": 10885}, {"title": "Disentangled and Self-Explainable Node Representation Learning", "link_suffix": "/forum?id=syMZF5fc8y", "link": "https://openreview.net/forum?id=syMZF5fc8y", "pdf_link": "https://openreview.net/pdf?id=syMZF5fc8y", "keywords": "Node representation learning, explainable ai, disentangled learning", "abstract": "Node representations, or embeddings, are low-dimensional vectors that capture node properties, typically learned through unsupervised structural similarity objectives or supervised tasks. While recent efforts have focused on explaining graph model decisions, the interpretability of $\\textit{unsupervised}$ node embeddings remains underexplored. To bridge this gap, we introduce DiSeNE ($\\textbf{Di}$sentangled and $\\textbf{Se}$lf-Explainable $\\textbf{N}$ode $\\textbf{E}$mbedding), a framework that generates self-explainable embeddings in an unsupervised manner. Our method employs disentangled representation learning to produce dimension-wise interpretable embeddings, where each dimension is aligned with distinct topological structure of the graph. We formalize novel desiderata for disentangled and interpretable embeddings, which drive our new objective functions, optimizing simultaneously for both interpretability and disentanglement. Additionally, we propose several new metrics to evaluate representation quality and human interpretability. Extensive experiments across multiple benchmark datasets demonstrate the effectiveness of our approach.", "title_embedding_index": 10861, "title_abs_embedding_index": 10886}, {"title": "Deconstructing Denoising Diffusion Models for Self-Supervised Learning", "link_suffix": "/forum?id=9oMB6wnFYM", "link": "https://openreview.net/forum?id=9oMB6wnFYM", "pdf_link": "https://openreview.net/pdf?id=9oMB6wnFYM", "keywords": "denoising diffusion models, denoising autoencoder, self-supervised learning", "abstract": "In this study, we examine the representation learning abilities of Denoising Diffusion Models (DDM) that were originally purposed for image generation. Our philosophy is to deconstruct a DDM, gradually transforming it into a classical Denoising Autoencoder (DAE). This deconstructive process allows us to explore how various components of modern DDMs influence self-supervised representation learning. We observe that only a very few modern components are critical for learning good representations, while many others are nonessential. Our study ultimately arrives at an approach that is highly simplified and to a large extent resembles a classical DAE. We hope our study will rekindle interest in a family of classical methods within the realm of modern self-supervised learning.", "title_embedding_index": 10862, "title_abs_embedding_index": 10887}, {"title": "TransAdapter: Vision Transformer for Feature-Centric Unsupervised Domain Adaptation", "link_suffix": "/forum?id=ATdshE4yIj", "link": "https://openreview.net/forum?id=ATdshE4yIj", "pdf_link": "https://openreview.net/pdf?id=ATdshE4yIj", "keywords": "Unsupervised Domain Adaptation, Transformer, Domain-Invariant Feature Representations", "abstract": "Unsupervised Domain Adaptation (UDA) aims to leverage labeled data from a source domain to address tasks in a related but unlabeled target domain. This problem is particularly challenging when there is a significant gap between the source and target domains. Traditional methods have largely focused on minimizing this domain gap by learning domain-invariant feature representations using convolutional neural networks (CNNs). However, recent advances in vision transformers, such as the Swin Transformer, have demonstrated superior performance in various vision tasks. In this work, we propose a novel UDA approach based on the Swin Transformer, introducing three key modules to improve domain adaptation. First, we develop a Graph Domain Discriminator that plays a crucial role in domain alignment by capturing pixel-wise correlations through a graph convolutional layer, operating on both shallow and deep features in the transformer. This module also calculates the entropy for the key attention features of the attention block to better distinguish between the source and target domains. Second, we present an Adaptive Double Attention module that simultaneously processes Windows and Shifted Windows attention to increase long-range dependency features. An attention reweighting mechanism is employed to dynamically adjust the contributions of the attention values, thereby improving feature alignment between domains. Finally, we introduce Cross-Feature Transform, where random Swin Transformer blocks are selectively transformed using our proposed transform module, enhancing the model\u2019s ability to generalize across domains by transferring the source to the target features. Extensive experiments demonstrate that our method improves the state-of-the-art on several challenging UDA benchmarks, confirming the effectiveness of our approach. In particular, our model does not include a task-specific domain alignment module, making it more versatile for various applications.", "title_embedding_index": 10863, "title_abs_embedding_index": 10888}, {"title": "KVSharer: Efficient Inference via Layer-Wise Dissimilar KV Cache Sharing", "link_suffix": "/forum?id=2Akf4BBCKo", "link": "https://openreview.net/forum?id=2Akf4BBCKo", "pdf_link": "https://openreview.net/pdf?id=2Akf4BBCKo", "keywords": "Large Language Model, KV Cache, KVSharer", "abstract": "The development of large language models (LLMs) has significantly expanded model sizes, resulting in substantial GPU memory requirements during inference. The key and value storage of the attention map in the KV (key-value) cache accounts for more than 80% of this memory consumption. Nowadays, most existing KV cache compression methods focus on intra-layer compression within a single Transformer layer but few works consider layer-wise compression. In this paper, we propose a plug-and-play method called \\textit{KVSharer}, which shares the KV cache between layers to achieve layer-wise compression. Rather than intuitively sharing based on higher similarity, we discover a counterintuitive phenomenon: sharing dissimilar KV caches better preserves the model performance. Experiments show that \\textit{KVSharer} can reduce KV cache computation by 30%, thereby lowering memory consumption without significantly impacting model performance and it can also achieve at least 1.3 times generation acceleration. Additionally, we verify that \\textit{KVSharer} is compatible with existing intra-layer KV cache compression methods, and combining both can further save memory.", "title_embedding_index": 10864, "title_abs_embedding_index": 10889}, {"title": "Efficient Multi-Level Learning for Dense Object Detection", "link_suffix": "/forum?id=NmP8PvcMtc", "link": "https://openreview.net/forum?id=NmP8PvcMtc", "pdf_link": "https://openreview.net/pdf?id=NmP8PvcMtc", "keywords": "Object Detection, Multi-Level Learning, Head Network", "abstract": "Dense object detection is crucial and favorable in the industry and has been popular for years with the success of the multi-level learning framework. By delivering the learning of objects into a multi-level feature pyramid, such a divide-and-conquer solution eases the optimization difficulty. However, this learning paradigm has a major shortcoming left behind. The shallow levels take tons of computational burden due to their high resolutions of the feature maps, heavily slowing down the inference speed. In this paper, we aim for minimal modifications to exchange a better speed-accuracy trade-off. The outcome is SlimHead, a very simple, efficient, and generalizable head network, which further unleashes the potential of multi-level learning for dense object detectors. It operates in two stages: Slim and Fat, initially plugging interpolator before the head network functions to \"slim'' the feature pyramid, and then recovering the features to original solution space by \"fatting'' the feature pyramid. Thanks to its flexibility, operations with higher computational complexity can be easily integrated to benefit accuracy without loss of inference efficiency. We also extend our SlimHead to multiple high-level vision tasks such as arbitrary-oriented object detection, pedestrian detection, and instance segmentation. Extensive experiments on PASCAL VOC, MS COCO, DOTA, and CrowdHuman demonstrate the broad applicability and the high practical value of our method.", "title_embedding_index": 10865, "title_abs_embedding_index": 10890}, {"title": "Map to Optimal: Adapting Graph Out-of-Distribution in Test Time", "link_suffix": "/forum?id=6j0oKBo196", "link": "https://openreview.net/forum?id=6j0oKBo196", "pdf_link": "https://openreview.net/pdf?id=6j0oKBo196", "keywords": "Out-of-distribution Generalizarion, Test-time Adaptation, Graph Neural Network, Self-supervision", "abstract": "Based on topological proximity message passing, graph neural networks (GNNs) can quickly model data patterns on graphs. However, at test time, when the node feature and topological structure of the graph data are out-of-distribution (OOD), the performance of pre-trained GNNs will be hindered. Existing test-time methods either fine-tune the pre-trained model or overlook the discrepancy between the prior knowledge in pre-trained models and the test graph. We propose a novel self-supervised test-time adaptation paradigm GOAT (https://anonymous.4open.science/r/GOAT-5C0E), through graph augmentation-to-augmentation strategy, that enables a simple adapter can mitigate the distribution gap of training data and test-time data. GOAT reduces generalization error for node classification in various pre-trained settings through experiments on six benchmark datasets spanning three distinct real-world OOD scenarios. Remarkably, GOAT outperforms state-of-the-art test-time methods, and our empirical study further demonstrates the interpretability of the OOD representation generated from our method.", "title_embedding_index": 10866, "title_abs_embedding_index": 10891}, {"title": "Evaluating topological fitness of human brain-inspired sub-circuits in Echo State Networks", "link_suffix": "/forum?id=LD0qz8j8Zm", "link": "https://openreview.net/forum?id=LD0qz8j8Zm", "pdf_link": "https://openreview.net/pdf?id=LD0qz8j8Zm", "keywords": "Computational Neuroscience, Neural Data Analysis, Neuromorphic Computing, Recurrent Neural Networks, Echo-state Networks, Reservoir Computing, Network Topology, Bio-inspired Neural Networks", "abstract": "Recent years have witnessed an emerging trend in neuromorphic computing that centers around the use of brain connectomics as a blueprint for artificial neural networks. Connectomics-based neuromorphic computing has primarily focused on embedding human brain large-scale structural connectomes (SCs), as estimated from diffusion Magnetic Resonance Imaging (dMRI) modality, to echo-state networks (ESNs). A critical step in ESN embedding requires pre-determined read-in and read-out layers constructed by the induced subgraphs (e.g., a priori set of functional sub-circuits/networks) of the embedded reservoir (e.g., SCs). As a priori set of functional sub-circuits are derived from functional MRI (fMRI) modality, it is unknown, till this point, whether the embedding of fMRI-induced sub-circuits/networks onto SCs is well justified from i) the neuro-physiological perspective and ii) ESN performance across a variety of tasks. In this paper, we proposed a pipeline to implement and evaluate ESNs with various embedded topology and processing/memorization tasks. To this end, we showed that different performance optimums are highly dependent on the neuro-physiological characteristics of these pre-determined fMRI-induced sub-circuits. In general, fMRI-induced sub-circuit-embedded ESN outperforms simple bipartite and various null models with feed-forward properties commonly seen in MLP for different tasks and reservoir criticality conditions. Noticeably, we found that the reservoir model performance is heavily dependent on the functional sub-circuits neuro-physiological properties with respect to different cognitive tasks and their corresponding computation-memorization balances. Specifically, we showed that default mode network's superior performance across the majority of tasks is related to its functional dichotomy property. Finally, we provided a thorough analysis of the topological properties of pre-determined fMRI-induced sub-circuits and highlighted their graph-theoretical properties that play significant roles in determining the ESN performance.", "title_embedding_index": 10867, "title_abs_embedding_index": 10892}, {"title": "Knowledge Distillation with Multi-granularity Mixture of Priors for Image Super-Resolution", "link_suffix": "/forum?id=cWHonXThtM", "link": "https://openreview.net/forum?id=cWHonXThtM", "pdf_link": "https://openreview.net/pdf?id=cWHonXThtM", "keywords": "Image Super-Resolution, Knowledge Distillation, Model Compression", "abstract": "Knowledge distillation (KD) is a promising yet challenging model compression technique that transfers rich learning representations from a well-performing but cumbersome teacher model to a compact student model.  Previous methods for image super-resolution (SR) mostly are tailored to the specific teacher-student architectures. And the potential for improvement is limited, which hinders their wide applications. This work presents a novel KD framework for SR models, the multi-granularity mixture of prior knowledge distillation (MiPKD), that is universally applicable to a wide array of architectures at feature and block levels. The teacher\u2019s knowledge is effectively integrated with the student's feature via the Feature Prior Mixer, and the reconstructed feature propagates dynamically in the training phase with the Block Prior Mixer. Extensive experiments demonstrate the effectiveness of the proposed MiPKD method.", "title_embedding_index": 10868, "title_abs_embedding_index": 10893}, {"title": "SONNET: Solar-disaggregation-based Day-ahead Probabilistic Net Load Forecasting with Transformers", "link_suffix": "/forum?id=OMFssKwpyo", "link": "https://openreview.net/forum?id=OMFssKwpyo", "pdf_link": "https://openreview.net/pdf?id=OMFssKwpyo", "keywords": "Net load forecasting, Probabilistic Modeling, Transformers, Solar Disaggregation, Data Augmentation", "abstract": "The global transition towards sustainable energy sources has positioned solar power as a cornerstone of modern electricity systems, underscoring the critical need for advanced forecasting techniques in grid management. Accurate net load forecasting is crucial for efficient and reliable power grid operations, especially with the rapid deployment of behind-the-meter (BTM) renewable energy sources such as rooftop solar. Notably, BTM solar generation is neither controlled nor monitored by utilities and hence only net load data are observed. Different from load forecasting, net load forecasting faces new challenges because BTM solar, a major component of net load, behaves very differently from and is much more variable than loads. To exploit the distinct natures of solar generation and load and unlock their predictive potentials, we propose ${\\bf SONNET}$, which stands for ${\\bf SO}$lar-disaggregatio${\\bf N}$-based ${\\bf NE}$t load forecasting with ${\\bf T}$ransformers. It is a novel probabilistic net load forecasting method based on disaggregating net loads into solar generation and loads and feeding both into the predictors. The method further features a) an enhanced Transformer architecture that integrates both historical and future input data, employing a combination of self-attention and cross-attention mechanisms, and b) a data augmentation method that enhances the robustness of net load forecasts against weather forecast errors. Extensive experiments are conducted based on the comprehensive real-world data set from a recent net load forecasting competition organized by the U.S. Department of Energy (DOE). It is demonstrated that our proposed method both improves the accuracy and reduces the uncertainty of net load forecasts. Notably, our proposed method significantly outperforms the state-of-the-art. The proposed techniques also have broad applications for energy and/or general forecasting-related problems.", "title_embedding_index": 10869, "title_abs_embedding_index": 10894}, {"title": "Auditing Predictive Models for Intersectional Biases", "link_suffix": "/forum?id=0NvSMb7xgC", "link": "https://openreview.net/forum?id=0NvSMb7xgC", "pdf_link": "https://openreview.net/pdf?id=0NvSMb7xgC", "keywords": "predictive bias detection, fairness auditing, intersectional bias, contextual bias, group fairness definitions, subgroup bias, predictive bias", "abstract": "Predictive models that satisfy group fairness criteria in aggregate for members of a protected class, but do not guarantee subgroup fairness, could produce biased predictions for individuals at the intersection of two or more protected classes. To address this risk, we propose Conditional Bias Scan (CBS), an auditing framework for detecting intersectional biases in classification models. CBS identifies the subgroup with the most significant bias against the protected class, compared to the equivalent subgroup in the non-protected class, and can incorporate multiple commonly used fairness definitions for both probabilistic and binarized predictions. We show that this methodology can detect subgroup biases in the COMPAS pre-trial risk assessment tool and in German Credit Data, and has higher bias detection power compared to similar methods that audit for subgroup fairness.", "title_embedding_index": 10870, "title_abs_embedding_index": 10895}, {"title": "W-PCA Based Gradient-Free Proxy for Efficient Search of Lightweight Language Models", "link_suffix": "/forum?id=YkmbJSHjj7", "link": "https://openreview.net/forum?id=YkmbJSHjj7", "pdf_link": "https://openreview.net/pdf?id=YkmbJSHjj7", "keywords": "zero-shot NAS, gradient-free, lightweight language models", "abstract": "The demand for efficient natural language processing (NLP) systems has led to the development of lightweight language models. Previous work in this area has primarily focused on manual design or training-based neural architecture search (NAS) methods. Recently, zero-shot NAS methods have been proposed for evaluating language models without the need for training. However, prevailing approaches to zero-shot NAS often face challenges such as biased evaluation metrics and computational inefficiencies. In this paper, we introduce weight-weighted PCA (W-PCA), a novel zero-shot NAS method specifically tailored for lightweight language models. Our approach utilizes two evaluation proxies: the parameter count and principal component analysis (PCA) value of the feed-forward neural (FFN) layer. Additionally, by eliminating the need for gradient computations, we optimize the evaluation time, thus enhancing the efficiency of designing and evaluating lightweight language models. We conduct a comparative analysis on the GLUE and SQuAD datasets to evaluate our approach. The results demonstrate that our method significantly reduces training time compared to one-shot NAS methods and achieves higher scores in the testing phase compared to previous state-of-the-art training-based methods. Furthermore, we perform ranking evaluations on a dataset sampled from the FlexiBERT search space. Our approach exhibits superior ranking correlation and further reduces solving time compared to other zero-shot NAS methods that require gradient computation.", "title_embedding_index": 10871, "title_abs_embedding_index": 10896}, {"title": "TimeRAF: Retrieval-Augmented Foundation model for Zero-shot Time Series Forecasting", "link_suffix": "/forum?id=zd5Knrtja4", "link": "https://openreview.net/forum?id=zd5Knrtja4", "pdf_link": "https://openreview.net/pdf?id=zd5Knrtja4", "keywords": "time series forecasting, retrieval augmented generation, time series foundation model", "abstract": "Time series forecasting plays a crucial role in data mining, driving rapid advancements across numerous industries. \nWith the emergence of large models, time series foundation models (TSFMs) have exhibited remarkable generalization capabilities, such as zero-shot learning, through large-scale pre-training. \nMeanwhile, Retrieval-Augmented Generation (RAG) methods are widely employed to enhance the performance of foundation models on unseen data, allowing models to access to external knowledge. \nIn this paper, we introduceTimeRAF, aRetrieval-AugmentedForecasting model that enhance zero-shot time series forecasting through retrieval-augmented techniques.\nWe develop customized time series knowledge bases that are tailored to the specific forecasting tasks.\nTimeRAF employs an end-to-end learnable retriever to extract valuable information from the knowledge base.\nAdditionally, we propose Channel Prompting for knowledge integration, which effectively extracts relevant information from the retrieved knowledge along the channel dimension.\nExtensive experiments demonstrate the effectiveness of our model, showing significant improvement across various domains and datasets.", "title_embedding_index": 10872, "title_abs_embedding_index": 10897}, {"title": "Graph Neural Networks for Edge Signals: Orientation Equivariance and Invariance", "link_suffix": "/forum?id=XWBE90OYlH", "link": "https://openreview.net/forum?id=XWBE90OYlH", "pdf_link": "https://openreview.net/pdf?id=XWBE90OYlH", "keywords": "Graph Neural Network, Graph, Edge, Equivariance, Invariance, Topology, Directed Graphs", "abstract": "Many applications in traffic, civil engineering, or electrical engineering revolve around edge-level signals. Such signals can be categorized as inherently directed, for example, the water flow in a pipe network, and undirected, like the diameter of a pipe. Topological methods model edge signals with inherent direction by representing them relative to a so-calledorientationassigned to each edge. \nThese approaches can neither model undirected edge signals nor distinguish if an edge itself is directed or undirected. We address these shortcomings by (i) revising the notion oforientation equivarianceto enable edge direction-aware topological models, (ii) proposingorientation invarianceas an additional requirement to describe signals without inherent direction, and (iii) developing EIGN, an architecture composed of novel direction-aware edge-level graph shift operators, that provably fulfills the aforementioned desiderata. It is the first general-purpose topological GNN for edge-level signals that can model directed and undirected signals while distinguishing between directed and undirected edges. A comprehensive evaluation shows that EIGN outperforms prior work in edge-level tasks, for example, improving in RMSE on flow simulation tasks by up to 43.5%.", "title_embedding_index": 10873, "title_abs_embedding_index": 10898}, {"title": "U3D: Unlocking the Video Prior for High Fidelity Sparse Novel View Synthesis and 3D Generation", "link_suffix": "/forum?id=dyYc8GFdD5", "link": "https://openreview.net/forum?id=dyYc8GFdD5", "pdf_link": "https://openreview.net/pdf?id=dyYc8GFdD5", "keywords": "Image to 3D; Mutli-view Diffusion; Novel View Synthesis", "abstract": "Trained on massive datasets, video diffusion models have shown strong generative priors for novel view synthesis tasks. Existing methods finetune these models to synthesize 360-degree orbit videos from input images. While these methods demonstrate the pretrained models' generalization ability, they are limited by the assumption of temporal attention and struggle to generate highly consistent results. Additionally, generating novel views as a sequence of twenty or more frames incurs high computational costs compared to sparse view synthesis methods. Sparse novel view synthesis methods finetuned from traditional 2D diffusion models, on the other hand, can generate highly consistent images from arbitrary camera positions but suffer from poor generalization, leading to unsatisfactory results on out-of-domain inputs. In this paper, we explore leveraging video diffusion models' rich generative priors to enhance sparse novel view generation models. Specifically, we investigate the generation process of video diffusion models and unearth key observations to extract geometrical priors from them. Based on this, we propose a novel framework, U3D, for sparse novel view synthesis. U3D includes a geometrical reference network to integrate these priors into the sparse novel view synthesis network and a temporal enhanced sparse view generation network to preserve pretrained temporal knowledge. By leveraging the significant generative priors from video diffusion models, our framework can synthesize highly consistent sparse novel views with strong generalization ability, which can be reconstructed into high-quality 3D assets using feed-forward sparse view reconstruction methods.", "title_embedding_index": 10874, "title_abs_embedding_index": 10899}]
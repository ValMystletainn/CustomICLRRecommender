[
    {
        "title": "Subsampled Ensemble Can Improve Generalization Tail Exponentially",
        "link_suffix": "/forum?id=NZC5QgbTSq",
        "link": "https://openreview.net/forum?id=NZC5QgbTSq",
        "pdf_link": "https://openreview.net/pdf?id=NZC5QgbTSq",
        "keywords": "ensemble method, subsampling, heavy tail, exponential convergence, excess risk, generalization",
        "abstract": "Ensemble learning is a popular technique to improve the accuracy of machine learning models. It hinges on the rationale that aggregating multiple weak models can lead to better models with lower variance and hence higher stability, especially for discontinuous base learners. In this paper, we provide a new perspective on ensembling. By selecting the best model trained on subsamples via majority voting, we can attain exponentially decaying tails for the excess risk, even if the base learner suffers from slow (i.e., polynomial) decay rates. This tail enhancement power of ensembling is agnostic to the underlying base learner and is stronger than variance reduction in the sense of exhibiting rate improvement. We demonstrate how our ensemble methods can substantially improve out-of-sample performances in a range of examples involving heavy-tailed data or intrinsically slow rates."
    },
    {
        "title": "CHAMP: Conformalized 3D Human Multi-Hypothesis Pose Estimators",
        "link_suffix": "/forum?id=kPC83HK4br",
        "link": "https://openreview.net/forum?id=kPC83HK4br",
        "pdf_link": "https://openreview.net/pdf?id=kPC83HK4br",
        "keywords": "Human pose estimation, 3d vision, uncertainty quantification",
        "abstract": "We introduce CHAMP, a novel method for learning sequence-to-sequence, multi-hypothesis 3D human poses from 2D keypoints by leveraging a conditional distribution with a diffusion model. To predict a single output 3D pose sequence, we generate and aggregate multiple 3D pose hypotheses. For better aggregation results, we develop a method to score these hypotheses during training, effectively integrating conformal prediction into the learning process. This process results in a differentiable conformal predictor that is trained end-to-end with the 3D pose estimator. Post-training, the learned scoring model is used as the conformity score, and the 3D pose estimator is combined with a conformal predictor to select the most accurate hypotheses for downstream aggregation. Our results indicate that using a simple mean aggregation on the conformal prediction-filtered hypotheses set yields competitive results. When integrated with more sophisticated aggregation techniques, our method achieves state-of-the-art performance across various metrics and datasets while inheriting the probabilistic guarantees of conformal prediction."
    },
    {
        "title": "When to retrain a machine learning model",
        "link_suffix": "/forum?id=iGX0lwpUYj",
        "link": "https://openreview.net/forum?id=iGX0lwpUYj",
        "pdf_link": "https://openreview.net/pdf?id=iGX0lwpUYj",
        "keywords": "retraining;sequence modeling; forecasting performance",
        "abstract": "A significant challenge in maintaining real-world machine learning models is responding to the continuous and unpredictable evolution of data. Most practitioners are faced with the difficult question: when should I retrain or update my machine learning model? This seemingly straightforward problem is particularly challenging for three reasons: 1) decisions must be made based on very limited information - we usually have access to only a few examples, 2) the nature, extent, and impact of the distribution shift are unknown, and 3) it involves specifying a cost ratio between retraining and poor performance, which can be hard to characterize. Existing works address certain aspects of this problem, but none offer a comprehensive solution. Distribution shift detection falls short as it cannot account for the cost trade-off; the scarcity of the data, paired with its unusual structure, makes it a poor fit for existing offline reinforcement learning methods, and the online learning formulation overlooks key practical considerations.\nTo address this, we present a principled formulation of the retraining problem and propose an uncertainty-based method that makes decisions by continually forecasting the evolution of model performance. Our experiments show that the method consistently outperforms existing baselines on 6 datasets. We thoroughly assess its robustness to mis-specified cost trade-off."
    },
    {
        "title": "Grounding Video Models to Actions through Goal Conditioned Exploration",
        "link_suffix": "/forum?id=G6dMvRuhFr",
        "link": "https://openreview.net/forum?id=G6dMvRuhFr",
        "pdf_link": "https://openreview.net/pdf?id=G6dMvRuhFr",
        "keywords": "Embodied AI, Decision Making, Robotics, Video Model",
        "abstract": "Large video models, pretrained on massive quantities of amount of Internet video,  provide a rich source of physical knowledge about the dynamics and motions of objects and tasks.\nHowever, video models are not grounded in the embodiment of an agent, and do not describe how to actuate the world to reach the visual states depicted in a video.\nTo tackle this problem, current methods use a separate vision-based inverse dynamic model trained on embodiment-specific data to map image states to actions. \nGathering data to train such a model is often expensive and challenging, and this model is limited to visual settings similar to the ones in which data is available.\nIn this paper, we investigate how to directly  ground video models to continuous actions through self-exploration in the embodied environment -- using generated video states as visual goals for exploration.\nWe propose a framework that uses trajectory level action generation in combination with video guidance to\nenable an agent to solve complex tasks without any external supervision, e.g., rewards, action labels, or segmentation masks.\nWe validate the proposed approach on 8 tasks in Libero, 6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual Navigation. \nWe show how our approach is on par with or even surpasses multiple behavior cloning baselines trained on expert demonstrations while without requiring any action annotations."
    },
    {
        "title": "Label-Free Coreset Selection with Proxy Training Dynamics",
        "link_suffix": "/forum?id=yklJpvB7Dq",
        "link": "https://openreview.net/forum?id=yklJpvB7Dq",
        "pdf_link": "https://openreview.net/pdf?id=yklJpvB7Dq",
        "keywords": "Coreset Selection, Data pruning, Label free coreset selection",
        "abstract": "High-quality human-annotated data is crucial for modern deep learning pipelines, yet the human annotation process is both costly and time-consuming. Given a constrained human labeling budget, selecting an informative and representative data subset for labeling can significantly reduce human annotation effort. Well-performing state-of-the-art (SOTA) coreset selection methods require ground truth labels over the whole dataset, failing to reduce the human labeling burden. Meanwhile, SOTA label-free coreset selection methods deliver inferior performance due to poor geometry-based difficulty scores. In this paper, we introduce ELFS (Effective Label-Free Coreset Selection), a novel label-free coreset selection method. ELFS significantly improves label-free coreset selection by addressing two challenges: 1) ELFS utilizes deep clustering to estimate training dynamics-based data difficulty scores without ground truth labels; 2) Pseudo-labels introduce a distribution shift in the data difficulty scores, and we propose a simple but effective double-end pruning method to mitigate bias on calculated scores. We evaluate ELFS on four vision benchmarks and show that, given the same vision encoder, ELFS consistently outperforms SOTA label-free baselines. For instance, when using SwAV as the encoder, ELFS outperforms D2 by up to 10.2% in accuracy on ImageNet-1K."
    },
    {
        "title": "On Expert Estimation in Hierarchical Mixture of Experts: Beyond Softmax Gating Functions",
        "link_suffix": "/forum?id=MidXrlkVu1",
        "link": "https://openreview.net/forum?id=MidXrlkVu1",
        "pdf_link": "https://openreview.net/pdf?id=MidXrlkVu1",
        "keywords": "Hierarchical Mixture-of-Experts, Multimodal, Mixture-of-Expert Theory",
        "abstract": "With the growing prominence of the Mixture of Experts (MoE) architecture in developing large-scale foundation models, we investigate the Hierarchical Mixture of Experts (HMoE), a specialized variant of MoE that excels in handling complex inputs and improving performance on targeted tasks. Our investigation highlights the advantages of using varied gating functions, moving beyond softmax gating within HMoE frameworks. We theoretically demonstrate that applying tailored gating functions to each expert group allows HMoE to achieve robust results, even when optimal gating functions are applied only at select hierarchical levels. Empirical validation across diverse scenarios supports these theoretical claims. This includes large-scale multimodal tasks, image classification, and latent domain discovery and prediction tasks, where our modified HMoE models show great performance improvements."
    },
    {
        "title": "Comet: A Communication-efficient and Performant Approximation for Private Transformer Inference",
        "link_suffix": "/forum?id=XoxxZiIJq6",
        "link": "https://openreview.net/forum?id=XoxxZiIJq6",
        "pdf_link": "https://openreview.net/pdf?id=XoxxZiIJq6",
        "keywords": "private inference, secret sharing, Transformer, language model, homomorphic encryption, multi-party computation",
        "abstract": "The prevalent use of Transformer-like models, exemplified by ChatGPT in modern language processing applications, underscores the critical need for enabling private inference essential for many cloud-based services reliant on such models. However, current privacy-preserving frameworks impose significant communication burden, especially for non-linear computation in Transformer model. In this paper, we introduce a novel plug-in method Comet to effectively reduce the communication cost without compromising the inference performance. We second introduce an efficient approximation method to eliminate the heavy communication in finding good initial approximation. We evaluate our Comet on Bert and RoBERTa models with GLUE benchmark datasets, showing up to 3.9 less communication and 3.5 speedups while keep competitive model performance compared to the prior art."
    },
    {
        "title": "Inverse Attention Agent in Multi-Agent System",
        "link_suffix": "/forum?id=OaoDVZntGe",
        "link": "https://openreview.net/forum?id=OaoDVZntGe",
        "pdf_link": "https://openreview.net/pdf?id=OaoDVZntGe",
        "keywords": "multi-agent system, Theory of mind agent",
        "abstract": "A major challenge for Multi-Agent Systems (MAS) is enabling agents to adapt dynamically to diverse environments in which opponents and teammates may continually change. Agents trained using conventional methods tend to excel only within the confines of their training cohorts; their performance drops significantly when confronting unfamiliar agents. To address this shortcoming, we introduce Inverse Attention Agents that adopt concepts from the Theory of Mind (ToM) implemented algorithmically using an attention mechanism trained in an end-to-end manner. Crucial to determining the final actions of these agents, the weights in their attention model explicitly represent attention to different goals. We furthermore propose an inverse attention network that deduces the ToM of agents based on observations and prior actions. The network infers the attentional states of other agents, thereby refining the attention weights to adjust the agent's final action. We conduct experiments in a continuous environment, tackling demanding tasks encompassing cooperation, competition, and a blend of both. They demonstrate that the inverse attention network successfully infers the attention of other agents, and that this information improves agent performance. Additional human experiments show that, compared to baseline agent models, our inverse attention agents exhibit superior cooperation with humans and better emulate human behaviors."
    },
    {
        "title": "dFCExpert: Learning Dynamic Functional Connectivity Patterns with Modularity and State Experts",
        "link_suffix": "/forum?id=sTI75sFQkn",
        "link": "https://openreview.net/forum?id=sTI75sFQkn",
        "pdf_link": "https://openreview.net/pdf?id=sTI75sFQkn",
        "keywords": "fMRI, dynamic brain functional connectome learning, brain modularity, state patterns, mixture of experts",
        "abstract": "Modeling brain dynamic functional connectivity (dFC) patterns from functional Magnetic Resonance Imaging (fMRI) data is of paramount importance in neuroscience and medicine. Recently, many graph neural networks (GNN) models in conjunction with transformers or recurrent neural networks (RNNs) have been proposed and shown great potential for modeling dFC patterns in terms of pattern recognition and prediction performance. Although fruitful, several issues still hinder further performance improvement of these methods, such as neglecting the intrinsic brain modularity mechanism, and the interpretable state information of dFC patterns. To tackle these limitations, we propose dFCExpert to learn effective representations of dFC patterns in fMRI data with modularity experts and state experts. Particularly, using the GNN and mixture of experts (MoE), the modularity experts characterize the brain modularity organization in the graph learning process by optimizing multiple experts, with each expert capturing brain nodes with similar functions (in the same neurocognitive module); and the state experts aggregate temporal dFC features into a set of distinctive connectivity states by a soft prototype clustering methods, where the states can support different brain activities or are affected differently by brain disorders, thus revealing insights for interpretability. Experiments on two large-scale fMRI datasets demonstrate the superiority of our method over known alternatives, and the learned dFC representations show improved explainability and hold promise to improve clinical diagnosis."
    },
    {
        "title": "Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography",
        "link_suffix": "/forum?id=cweehsf2Fn",
        "link": "https://openreview.net/forum?id=cweehsf2Fn",
        "pdf_link": "https://openreview.net/pdf?id=cweehsf2Fn",
        "keywords": "Contrastive Language-Image Pre-training, Medical Image, Mammography, Multi-view & Multi-scale",
        "abstract": "Contrastive Language-Image Pre-training (CLIP) shows promise in medical image analysis but requires substantial data and computational resources. Due to these restrictions, existing CLIP applications in medical imaging focus mainly on modalities like chest X-rays that have abundant image-report data available, leaving many other important modalities under-explored. Here, we propose one of the first adaptations of the full CLIP model to mammography, which presents significant challenges due to labeled data scarcity, high-resolution images with small regions of interest, and data imbalance. We first develop a specialized supervision framework for mammography that leverages its multi-view nature. Furthermore, we design a symmetric local alignment module to better focus on detailed features in high-resolution images. Lastly, we incorporate a parameter-efficient fine-tuning approach for large language models pre-trained with medical knowledge to address data limitations. Our multi-view and multi-scale alignment (MaMA) method outperforms state-of-the-art baselines for three different tasks on two large real-world mammography datasets, EMBED and RSNA-Mammo, with only 52% model size compared with the largest baseline. The code is attached in the supplement file and will be released on GitHub upon acceptance."
    },
    {
        "title": "R2Det: Exploring Relaxed Rotation Equivariance in 2D Object Detection",
        "link_suffix": "/forum?id=EUeNr3e8AV",
        "link": "https://openreview.net/forum?id=EUeNr3e8AV",
        "pdf_link": "https://openreview.net/pdf?id=EUeNr3e8AV",
        "keywords": "Relaxation, Rotation, Equivariance",
        "abstract": "Group Equivariant Convolution (GConv) empowers models to capture equivariant features and explore underlying symmetries in data, improving performance. However, real-world scenarios often deviate from ideal symmetric systems caused by physical permutation, characterized by non-trivial actions of a symmetry group, resulting in asymmetries that affect the outputs, a phenomenon known as symmetry breaking. Traditional GConv-based methods are constrained by rigid operational rules within group space, assuming data remains strictly equivariant under limited group transformations. This limitation makes it difficult to adapt to Symmetry-Breaking and non-rigid transformations. Motivated by this, we mainly focus on a common scenario: rotational Symmetry-Breaking. By relaxing strict group transformations within Strict Rotation-Equivariant group $\\mathbf{C}_n$, we redefine a Relaxed Rotation-Equivariant group $\\mathbf{R}_n$ and introduce a novel Relaxed Rotation-Equivariant GConv (R2GConv) with only a minimal increase of $4n$ parameters compared to GConv. Based on R2GConv, we propose a Relaxed Rotation-Equivariant Network (R2Net) as the backbone and develop a Relaxed Rotationa-Equivariant Object Detector (R2Det) for 2D object detection. Experimental results demonstrate the effectiveness of our R2GConv in natural image classification, and R2Det achieves excellent performance in 2D object detection with improved generalization capabilities and robustness."
    },
    {
        "title": "Computational Limits of Low-Rank Adaptation for Transformer Models",
        "link_suffix": "/forum?id=Lf5znhZmFu",
        "link": "https://openreview.net/forum?id=Lf5znhZmFu",
        "pdf_link": "https://openreview.net/pdf?id=Lf5znhZmFu",
        "keywords": "Parameter Efficient Finetuning, Low-Rank Adaptation, LoRA, Transformer, Foundation Models, Large Language Models, Fine-Grained Complexity, Strong Exponential Time Hypothesis",
        "abstract": "We study the computational limits of Low-Rank Adaptation (LoRA) for finetuning transformer-based models using fine-grained complexity theory.\nOur key observation is that the existence of low-rank decompositions within the gradient computation of LoRA adaptation leads to possible algorithmic speedup.\nThis allows us to (i) identify a phase transition behavior of efficiency and (ii) prove the existence of nearly linear algorithms by controlling the LoRA update computation term by term, assuming the Strong Exponential Time Hypothesis (SETH). \nFor the former, we identify a sharp transition in the efficiency of all possible rank-$r$ LoRA update algorithms for transformers, based on specific norms resulting from the multiplications of the input sequence $X$, pretrained weights ${W^\\star}$, and adapter matrices $\\alpha BA/r$.\nSpecifically, we derive a shared upper bound threshold for such norms, and show that efficient (sub-quadratic) approximation algorithms of LoRA exist only below this threshold. \nFor the latter, we prove the existence of nearly linear approximation algorithms for LoRA adaptation by utilizing the hierarchical low-rank structures of LoRA gradients and approximating the gradients with a series of chained low-rank approximations. \nTo showcase our theory, we consider two practical scenarios: partial (e.g., only $W_V$ and $W_Q$) and full adaptations (e.g., $W_Q$, $W_V$, and $W_K$) of weights in attention heads."
    },
    {
        "title": "Inverse Engineering Diffusion: Deriving Variance Schedules with Rationale",
        "link_suffix": "/forum?id=KR9zrisXDZ",
        "link": "https://openreview.net/forum?id=KR9zrisXDZ",
        "pdf_link": "https://openreview.net/pdf?id=KR9zrisXDZ",
        "keywords": "diffusion models, generative models, score-based generative models, generative modeling, stochastic differential equations",
        "abstract": "A fundamental aspect of diffusion models is the variance schedule, which governs the evolution of variance throughout the diffusion process. Despite numerous studies exploring variance schedules, little effort has been made to understand the variance distributions implied by sampling from these schedules and how it benefits both training and data generation. We introduce a novel perspective on score-based diffusion models, bridging the gap between the variance schedule and its underlying variance distribution. Specifically, we propose the notion of sampling variance according to a probabilistic rationale, which induces a density. Our approach views the inverse of the variance schedule as a cumulative distribution function (CDF) and its first derivative as a probability density function (PDF) of the variance distribution. This formulation not only offers a unified view of variance schedules but also allows for the direct engineering of a variance schedule from the probabilistic rationale of its inverse function. Additionally, our framework is not limited to CDFs with closed-form inverse solutions, enabling the exploration of variance schedules that are unattainable through conventional methods. We present the tools required to obtain a diverse array of novel variance schedules tailored to specific rationales, such as separability metrics or prior beliefs. These schedules may exhibit varied dynamics, ranging from rapid convergence towards zero to prolonged periods in high-variance regions. Through comprehensive empirical evaluation, we demonstrate the efficacy of enhancing the performance of diffusion models with schedules distinct from those encountered during training. We provide a principled and unified approach to variance schedules in diffusion models, revealing the relationship between variance schedules and their underlying probabilistic rationales, which yields notable improvements in image generation performance, as measured by FID."
    },
    {
        "title": "A Simple Approach to Unifying Diffusion-based Conditional Generation",
        "link_suffix": "/forum?id=tAGmxz1TUi",
        "link": "https://openreview.net/forum?id=tAGmxz1TUi",
        "pdf_link": "https://openreview.net/pdf?id=tAGmxz1TUi",
        "keywords": "image generation, controllability, estimation",
        "abstract": "Recent progress in image generation has sparked research into controlling these models through condition signals, with various methods addressing specific challenges in conditional generation. Instead of proposing another specialized technique, we introduce a simple, unified framework to handle diverse conditional generation tasks involving a specific image-condition correlation. By learning a joint distribution over a correlated image pair (e.g. image and depth) with a diffusion model, our approach enables versatile capabilities via different inference-time sampling schemes, including controllable image generation (e.g. depth to image), estimation (e.g. image to depth), signal guidance, joint generation (image & depth), and coarse control. Previous attempts at unification often introduce complexity through multi-stage training, architectural modification, or increased parameter counts. In contrast, our simplified formulation requires a single, computationally efficient training stage, maintains the standard model input, and adds minimal learned parameters (15% of the base model). Moreover, our model supports additional capabilities like non-spatially aligned and coarse conditioning. Extensive results show that our single model can produce comparable results with specialized methods and better results than prior unified methods. We also demonstrate that multiple models can be effectively combined for multi-signal conditional generation."
    },
    {
        "title": "Eligibility Traces for Confounding Robust Off-Policy Evaluation: A Causal Approach",
        "link_suffix": "/forum?id=vI5cjHMzP4",
        "link": "https://openreview.net/forum?id=vI5cjHMzP4",
        "pdf_link": "https://openreview.net/pdf?id=vI5cjHMzP4",
        "keywords": "Causal Inference, Graphical Models",
        "abstract": "A unifying theme in Artificial Intelligence is learning an effective policy to control an agent in an unknown environment in order to optimize a certain performance measure. Off-policy methods can significantly improve the sample efficiency during training since they allow an agent to learn from observed trajectories generated by different behavior policies, without directly deploying the target policies in the underlying environment. This paper studies off-policy evaluation from biased offline data where (1) unobserved confounding bias cannot be ruled out a priori; or (2) the observed trajectories do not overlap with intended behaviors of the learner, i.e., the target and behavior policies do not share a common support. Specifically, we first extend the Bellman's equation to derive effective closed-form bounds over value functions from the observational distribution contaminated with unobserved confounding and no-overlap. Second, we propose two novel algorithms that use eligibility traces to estimate these bounds from finite observational data. Compared to other partial identification methods for off-policy evaluation in sequential environments, these methods are model-free and do not rely on additional parametric knowledge about the system dynamics in the underlying environment."
    },
    {
        "title": "Do LLMs ``know'' internally when they follow instructions?",
        "link_suffix": "/forum?id=qIN5VDdEOr",
        "link": "https://openreview.net/forum?id=qIN5VDdEOr",
        "pdf_link": "https://openreview.net/pdf?id=qIN5VDdEOr",
        "keywords": "Instruction following, Large language models, Linear probing, Representation engineering, Interpretation",
        "abstract": "Instruction-following is crucial for building AI agents with large language models (LLMs), as these models must adhere strictly to user-provided constraints and guidelines. \nHowever, LLMs often fail to follow even simple and clear instructions.\nTo improve instruction-following behavior and prevent undesirable outputs, a deeper understanding of how LLMs' internal states relate to these outcomes is required.\nOur analysis of LLM internal states reveal a dimension in the input embedding space linked to successful instruction-following. \nWe demonstrate that modifying representations along this dimension improves instruction-following success rates compared to random changes, without compromising response quality.\nFurther investigation reveals that this dimension is more closely related to the phrasing of prompts rather than the inherent difficulty of the task or instructions. \nThis discovery also suggests explanations for why LLMs sometimes fail to follow clear instructions and why prompt engineering is often effective, even when the content remains largely unchanged. \nThis work provides insight into the internal workings of LLMs' instruction-following, paving the way for reliable LLM agents."
    },
    {
        "title": "Correcting Flows with Marginal Matching",
        "link_suffix": "/forum?id=kRjLBXWn1T",
        "link": "https://openreview.net/forum?id=kRjLBXWn1T",
        "pdf_link": "https://openreview.net/pdf?id=kRjLBXWn1T",
        "keywords": "flow matching, rectified flow, diffusion, generative models",
        "abstract": "Flow matching models, ODE-based generative models, generate samples by gradually morphing a simple source distribution into a target distribution. \nIn practice, these models still fall short of perfectly replicating the target distribution, mainly due to imperfections of the learned mapping. Previous work mainly focus on alleviating discretization error, which rises from sampling a continuous trajectory with a finite number of steps. In this work we focus on prediction error, an error that is inherent in the model. \nOur main contribution is identifying a trajectory that complies with the imperfect flow model and leads exactly to the target distribution. Based on this finding, we propose Marginal Matching\u2014a simple inference-time correction scheme to steer the generated samples in the direction of the data.\nThis scheme proves to reduce a bound on the distance between the data and the learned distribution, motivating two different implementations for the correction function. We show that our proposed method improves sample quality on CIFAR-10 and ImageNet-64,  with minimal overhead in computation time, or non at all when applying approximated correction."
    },
    {
        "title": "TensorGPT: Efficient Compression of Large Language Models based on Tensor-Train Decomposition",
        "link_suffix": "/forum?id=FVgizbs3o2",
        "link": "https://openreview.net/forum?id=FVgizbs3o2",
        "pdf_link": "https://openreview.net/pdf?id=FVgizbs3o2",
        "keywords": "model compression, low-rank factorization, tensor decomposition",
        "abstract": "High-dimensional token embeddings underpin Large Language Models (LLMs), as they can capture subtle semantic information and significantly enhance the modelling of complex language patterns. \nHowever, this high dimensionality also introduces considerable model parameters and prohibitively high model storage and memory requirements, which is particularly unaffordable for low-end devices.\nTargeting no extra training data and insufficient computation cases, we propose atraining-freemodel compression approach based on the Tensor-Train Decomposition (TTD), \nwhereby each pre-trained token embedding is converted into a lower-dimensional Matrix Product State (MPS).\nWe then comprehensively investigate the low-rank structures extracted by this approach, in terms of the compression ratio, the language task performance, and latency on a typical low-end device (i.e. Raspberry Pi). \nTaking GPT family models (i.e. GPT-2 and CerebrasGPT) as case studies, our approach theoretically results in $46.89$% fewer parameters of the entire model, with a compression ratio $39.38\\times$ - $65.64\\times$ for the embedding layers. With different hyperparameter choices, the model compressed with our approach can achieve a comparable language task performance to the original model with around $2.0\\times$ embedding layer compression. This empirically proves the existence of low-rank structure in GPT family models, and demonstrates that about half of the parameters in the embedding layers are redundant."
    },
    {
        "title": "Complexity-Aware Deep Symbolic Regression with Robust Risk-Seeking Policy Gradients",
        "link_suffix": "/forum?id=krJ73n4Pma",
        "link": "https://openreview.net/forum?id=krJ73n4Pma",
        "pdf_link": "https://openreview.net/pdf?id=krJ73n4Pma",
        "keywords": "symbolic regression, robust risk-seeking, transformers, breadth-first-search",
        "abstract": "This paper proposes a novel deep symbolic regression approach to enhance the robustness and interpretability of data-driven mathematical expression discovery. Despite the success of the state-of-the-art method, DSR, it is built on recurrent neural networks, purely guided by data fitness, and potentially meet tail barriers, which can zero out the policy gradient and cause inefficient model updates. To overcome these limitations, we use transformers in conjunction with breadth-first-search to improve the learning performance. We use Bayesian information criterion (BIC) as the reward function to explicitly account for the expression complexity and optimize the trade-off between interpretability and data fitness. We propose a modified risk-seeking policy  that not only ensures the unbiasness of the gradient, but also removes the tail barriers, thus ensuring effective updates from top performers. Through a series of benchmarks and systematic experiments, we demonstrate the aforementioned advantages of our approach."
    },
    {
        "title": "Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency",
        "link_suffix": "/forum?id=jDpdQPMosW",
        "link": "https://openreview.net/forum?id=jDpdQPMosW",
        "pdf_link": "https://openreview.net/pdf?id=jDpdQPMosW",
        "keywords": "Foundation Model, Prompt Tuning, Transformer, Universal Approximation, Memory Capacity, Computational Efficiency, Fine-Grained Complexity",
        "abstract": "We investigate the statistical and computational limits of prompt tuning for transformer-based foundation models. \nOur key contributions are prompt tuning onsingle-headtransformers with only asingleself-attention layer: \n(i) is universal, and (ii) supports efficient (even nearly-linear time) algorithms under the Strong Exponential Time Hypothesis (SETH).\nStatistically, \nwe prove that prompt tuning on such simplest possible transformers are  universal approximators for sequence-to-sequence Lipschitz functions. \nIn addition, we provide an exponential-in-$dL$ and -in-$(1/\\epsilon)$ lower bound on the required soft-prompt tokens for prompt tuning to memorize any  dataset with 1-layer, 1-head transformers.\nComputationally, we identify a phase transition in the efficiency of prompt tuning, determined by the norm of thesoft-prompt-inducedkeys and queries, and provide an upper bound criterion.\nBeyond this criterion, no sub-quadratic (efficient) algorithm for prompt tuning exists under SETH. \nWithin this criterion, \nwe showcase our theory by proving the existence of almost-linear time prompt tuning inference algorithms.\nThese fundamental limits provide important necessary conditions for designing expressive and efficient prompt tuning methods for practitioners."
    },
    {
        "title": "Disentangling 3D Animal Pose Dynamics with Scrubbed Conditional Latent Variables",
        "link_suffix": "/forum?id=i7drKWhFCo",
        "link": "https://openreview.net/forum?id=i7drKWhFCo",
        "pdf_link": "https://openreview.net/pdf?id=i7drKWhFCo",
        "keywords": "behavioral neuroscience, systems neuroscience",
        "abstract": "Methods for tracking lab animal movements in unconstrained environments have become increasingly common and powerful tools for neuroscience. The prevailing hypothesis is that animal behavior in these environments comprises sequences of discrete stereotyped body movements (\"motifs\" or \"actions\"). However, the same action can occur at different speeds or heading directions, and the same action may manifest slightly differently across subjects due to, for example, variation in body size. These and other forms of nuisance variability complicate attempts to quantify animal behavior in terms of discrete action sequences and draw meaningful comparisons across individual subjects. To address this, we present a framework for motion analysis that uses conditional variational autoencoders in conjunction with adversarial learning paradigms to disentangle behavioral factors. We demonstrate the utility of this approach in downstream tasks such as clustering, decodability, and motion synthesis. Further, we apply our technique to improve disease detection in a Parkinsonian mouse model."
    },
    {
        "title": "Post-Training Sparse Attention with Double Sparsity",
        "link_suffix": "/forum?id=XzU3Xk1Xu2",
        "link": "https://openreview.net/forum?id=XzU3Xk1Xu2",
        "pdf_link": "https://openreview.net/pdf?id=XzU3Xk1Xu2",
        "keywords": "large language models, sparse attention, decoding",
        "abstract": "Long-context inference of Large Language Models (LLMs) is known to be challenging due to the excessive Key-Value(KV) cache accesses. This paper introduces ``Double Sparsity,'' a novel post-training sparse attention technique designed to alleviate this bottleneck by reducing KV cache access. Double Sparsity combines token sparsity, which focuses on using only the important tokens for computing self-attention, with channel sparsity, an approach that uses important feature channels for identifying important tokens. Our key insight is that the pattern of channel sparsity is highly static, allowing us to use offline calibration to make it efficient at runtime, thereby enabling accurate and efficient identification of important tokens. Moreover, this method can be combined with offloading to achieve significant memory usage reduction.\nExperimental results demonstrate that Double Sparsity can achieve (\\frac{1}{16}) sparsity with minimal impact on accuracy across various tasks with different architectures including MHA, GQA, MoE and vision language model.\nIt brings up to a 14.1$\\times$ acceleration in attention operations and a 1.9$\\times$ improvement in end-to-end inference on GPUs with various batch sizes. With CPU offloading under extremely long-context settings (e.g., 256K), it achieves a decoding speed acceleration of 16.3$\\times$ compared to state-of-the-art solutions. Our code is integrated into a widely-used framework SGLang and deployed in real-world workloads."
    },
    {
        "title": "RESuM: A Rare Event Surrogate Model for  Physics Detector Design",
        "link_suffix": "/forum?id=lqTILjL6lP",
        "link": "https://openreview.net/forum?id=lqTILjL6lP",
        "pdf_link": "https://openreview.net/pdf?id=lqTILjL6lP",
        "keywords": "surrogate model, simulation, rare event search, AI4Sci, AI for physics, conditional neural process, Bayesian methods, emulator, Multi-Fidelity Gaussian Process",
        "abstract": "The experimental discovery of neutrinoless double-beta decay (NLDBD) would answer one of the most important questions in physics: Why is there more matter than antimatter in our universe? To maximize the chances of discovery, NLDBD experiments must optimize their detector designs to minimize the probability of background events contaminating the detector. Given that this probability is inherently low, design optimization either requires extremely costly simulations to generate sufficient background counts or contending with significant variance. In this work, we formalize this dilemma as a Rare Event Design (RED) problem: identifying optimal design parameters when the design metric to be minimized is inherently small. We then designed the Rare Event Surrogate Model (RESuM) for physics detector design optimization under RED conditions. RESuM uses a pre-trained Conditional Neural Process (CNP) model to incorporate additional prior knowledge into a Multi-Fidelity Gaussian Process model. We applied RESuM to optimize neutron shielding designs for the LEGEND NLDBD experiment, identifying an optimal design that reduces the neutron background by $(66.5 \\pm 3.5)$% while using only 3.3% of the computational resources compared to traditional methods. Given the prevalence of RED problems in other fields of physical sciences, especially in rare-event searches, the RESuM algorithm has broad potential for accelerating simulation-intensive applications."
    },
    {
        "title": "Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models",
        "link_suffix": "/forum?id=GjM61KRiTG",
        "link": "https://openreview.net/forum?id=GjM61KRiTG",
        "pdf_link": "https://openreview.net/pdf?id=GjM61KRiTG",
        "keywords": "Large Language Models, RLHF, Safety",
        "abstract": "Fine-tuning large language models (LLMs)  on human preferences, typically through reinforcement learning from human feedback (RLHF), has proven successful in enhancing their capabilities.  However, ensuring the safety of LLMs during fine-tuning remains a critical concern, and mitigating the potential conflicts in  safety and helpfulness  is costly in RLHF.  To address this issue, we propose a supervised learning framework called Bi-Factorial Preference Optimization (BFPO), which re-parameterizes a joint RLHF objective of both safety and helpfulness into a single supervised learning objective. In the supervised optimization, a labeling function is used to capture global preferences ranking to balance both safety and helpfulness. To  evaluate BFPO, we  develop a benchmark  including comprehensive discriminative and generative tasks for helpfulness and harmlessness. The results indicate that our method significantly outperforms existing approaches in both safety and helpfulness. Moreover, BFPO eliminates the need for human prompting and annotation in LLM fine-tuning while achieving the same level of safety as methods that heavily rely on human labor, with less than 10% of the computational resources. The training recipes and models will be released."
    },
    {
        "title": "StoryAgent: Customized Storytelling Video Generation via Multi-Agent Collaboration",
        "link_suffix": "/forum?id=TS4BLf951Y",
        "link": "https://openreview.net/forum?id=TS4BLf951Y",
        "pdf_link": "https://openreview.net/pdf?id=TS4BLf951Y",
        "keywords": "storytelling video generation, customization generation, multi-agent system",
        "abstract": "The advent of AI-Generated Content (AIGC) has spurred research into automated video generation to streamline conventional processes. However, automating storytelling video production, particularly for customized narratives, remains challenging due to the complexity of maintaining subject consistency across shots. While existing approaches like Mora and AesopAgent integrate multiple agents for Story-to-Video (S2V) generation, they fall short in preserving protagonist consistency and supporting Customized Storytelling Video Generation (CSVG). To address these limitations, we propose StoryAgent, a multi-agent framework designed for CSVG. StoryAgent decomposes CSVG into distinct subtasks assigned to specialized agents, mirroring the professional production process. Notably, our framework includes agents for story design, storyboard generation, video creation, agent coordination, and result evaluation. Leveraging the strengths of different models, StoryAgent enhances control over the generation process, significantly improving character consistency. Specifically, we introduce a customized Image-to-Video (I2V) method, LoRA-BE, to enhance intra-shot temporal consistency, while a novel storyboard generation pipeline is proposed to maintain subject consistency across shots. Extensive experiments demonstrate the effectiveness of our approach in synthesizing highly consistent storytelling videos, outperforming state-of-the-art methods. Our contributions include the introduction of StoryAgent, a versatile framework for video generation tasks, and novel techniques for preserving protagonist consistency."
    }
]